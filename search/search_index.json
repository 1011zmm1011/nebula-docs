{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Nebula Graph \u00b6 Nebula Graph is an open-source graph database capable of hosting super large scale graphs with dozens of billions of vertices (nodes) and trillions of edges, with milliseconds of latency. Compared with other graph database solutions, Nebula Graph has the following advantages: Symmetrically distributed Storage and computing separation Horizontal scalability Strong data consistency by RAFT protocol SQL-like query language Role-based access control for higher level security Roadmap \u00b6 See our Roadmap for what's coming soon in Nebula Graph . Graph Visualization \u00b6 Visit Graph Visualization for visual exploration of graph data on web UI. Supported Clients \u00b6 Go Python Java Quick start \u00b6 Read the Getting started article for a quick start. Please note that you must install Nebula Graph by installing source code , rpm/deb packages or docker compose , before you can actually start using it. If you prefer a video tutorial, visit our YouTube channel . Getting help \u00b6 In case you encounter any problems playing around Nebula Graph , please reach out for help: Slack channel Stack Overflow Official Forum Documentation \u00b6 English \u7b80\u4f53\u4e2d\u6587 Architecture \u00b6 Contributing \u00b6 Contributions are warmly welcomed and greatly appreciated. And here are a few ways you can contribute: Start by some good first issues . Submit Pull Requests to us. See how-to-contribute . Licensing \u00b6 Nebula Graph is under Apache 2.0 license, so you can freely download, modify, and deploy the source code to meet your needs. You can also freely deploy Nebula Graph as a back-end service to support your SaaS deployment. In order to prevent cloud providers monetizing from the project without contributing back, we added Commons Clause 1.0 to the project. As mentioned above, we fully commit to the open source community. We would love to hear your thoughts on the licensing model and are willing to make it more suitable for the community. Contact \u00b6 Twitter: @NebulaGraph Facebook page LinkedIn page Slack channel email: info@vesoft.com","title":"Home"},{"location":"#what_is_nebula_graph","text":"Nebula Graph is an open-source graph database capable of hosting super large scale graphs with dozens of billions of vertices (nodes) and trillions of edges, with milliseconds of latency. Compared with other graph database solutions, Nebula Graph has the following advantages: Symmetrically distributed Storage and computing separation Horizontal scalability Strong data consistency by RAFT protocol SQL-like query language Role-based access control for higher level security","title":"What is Nebula Graph"},{"location":"#roadmap","text":"See our Roadmap for what's coming soon in Nebula Graph .","title":"Roadmap"},{"location":"#graph_visualization","text":"Visit Graph Visualization for visual exploration of graph data on web UI.","title":"Graph Visualization"},{"location":"#supported_clients","text":"Go Python Java","title":"Supported Clients"},{"location":"#quick_start","text":"Read the Getting started article for a quick start. Please note that you must install Nebula Graph by installing source code , rpm/deb packages or docker compose , before you can actually start using it. If you prefer a video tutorial, visit our YouTube channel .","title":"Quick start"},{"location":"#getting_help","text":"In case you encounter any problems playing around Nebula Graph , please reach out for help: Slack channel Stack Overflow Official Forum","title":"Getting help"},{"location":"#documentation","text":"English \u7b80\u4f53\u4e2d\u6587","title":"Documentation"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#contributing","text":"Contributions are warmly welcomed and greatly appreciated. And here are a few ways you can contribute: Start by some good first issues . Submit Pull Requests to us. See how-to-contribute .","title":"Contributing"},{"location":"#licensing","text":"Nebula Graph is under Apache 2.0 license, so you can freely download, modify, and deploy the source code to meet your needs. You can also freely deploy Nebula Graph as a back-end service to support your SaaS deployment. In order to prevent cloud providers monetizing from the project without contributing back, we added Commons Clause 1.0 to the project. As mentioned above, we fully commit to the open source community. We would love to hear your thoughts on the licensing model and are willing to make it more suitable for the community.","title":"Licensing"},{"location":"#contact","text":"Twitter: @NebulaGraph Facebook page LinkedIn page Slack channel email: info@vesoft.com","title":"Contact"},{"location":"README-CN/","text":"\u4e2d\u6587 | English \u4e16\u754c\u4e0a\u552f\u4e00\u80fd\u591f\u5bb9\u7eb3\u5343\u4ebf\u4e2a\u9876\u70b9\u548c\u4e07\u4ebf\u6761\u8fb9\uff0c\u5e76\u63d0\u4f9b\u6beb\u79d2\u7ea7\u67e5\u8be2\u5ef6\u65f6\u7684\u56fe\u6570\u636e\u5e93\u89e3\u51b3\u65b9\u6848 Nebula Graph\u662f\u4ec0\u4e48\uff1f \u00b6 Nebula Graph \u662f\u4e00\u6b3e\u5f00\u6e90\u7684\u56fe\u6570\u636e\u5e93\uff0c\u64c5\u957f\u5904\u7406\u5343\u4ebf\u4e2a\u9876\u70b9\u548c\u4e07\u4ebf\u6761\u8fb9\u7684\u8d85\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002 \u4e0e\u5176\u4ed6\u56fe\u6570\u636e\u5e93\u4ea7\u54c1\u76f8\u6bd4\uff0c Nebula Graph \u5177\u6709\u5982\u4e0b\u4f18\u52bf\uff1a \u5168\u5bf9\u79f0\u5206\u5e03\u5f0f\u67b6\u6784 \u5b58\u50a8\u4e0e\u8ba1\u7b97\u5206\u79bb \u6c34\u5e73\u53ef\u6269\u5c55\u6027 RAFT \u534f\u8bae\u4e0b\u7684\u6570\u636e\u5f3a\u4e00\u81f4 \u7c7b SQL \u67e5\u8be2\u8bed\u8a00 \u7528\u6237\u9274\u6743 \u4ea7\u54c1\u8def\u7ebf\u56fe \u00b6 Nebula Graph \u4ea7\u54c1\u89c4\u5212\u8def\u7ebf\u56fe\u8bf7\u53c2\u89c1 roadmap \u3002 \u56fe\u53ef\u89c6\u5316 \u00b6 \u67e5\u770b \u56fe\u53ef\u89c6\u5316 \uff0c\u5f00\u542f\u56fe\u6570\u636e\u53ef\u89c6\u5316\u63a2\u7d22\u4e4b\u65c5\u3002 \u652f\u6301\u7684\u5ba2\u6237\u7aef \u00b6 Go Python Java \u5feb\u901f\u4f7f\u7528 \u00b6 \u8bf7\u67e5\u770b \u5feb\u901f\u4f7f\u7528\u624b\u518c \uff0c\u5f00\u59cb\u4f7f\u7528 Nebula Graph \u3002 \u5728\u5f00\u59cb\u4f7f\u7528 Nebula Graph \u4e4b\u524d\uff0c\u5fc5\u987b\u901a\u8fc7 \u7f16\u8bd1\u6e90\u7801 \uff0c rpm/deb \u5305 \u6216\u8005 docker compose \u65b9\u5f0f\u5b89\u88c5 Nebula Graph \u3002\u60a8\u4e5f\u53ef\u4ee5\u89c2\u770b \u89c6\u9891 \u5b66\u4e60\u5982\u4f55\u5b89\u88c5 Nebula Graph \u3002 \u83b7\u53d6\u5e2e\u52a9 \u00b6 \u5728\u4f7f\u7528 Nebula Graph \u8fc7\u7a0b\u4e2d\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u90fd\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u65b9\u5f0f\u5bfb\u6c42\u5e2e\u52a9\uff1a \u77e5\u4e4e SegmentFault \u5b98\u65b9\u8bba\u575b \u6587\u6863 \u00b6 \u7b80\u4f53\u4e2d\u6587 English Nebula Graph \u4ea7\u54c1\u67b6\u6784\u56fe \u00b6 \u5982\u4f55\u8d21\u732e \u00b6 Nebula Graph \u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u9879\u76ee\uff0c\u6b22\u8fce\u5f00\u6e90\u7231\u597d\u8005\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u53c2\u4e0e\u5230 Nebula Graph \u793e\u533a\uff1a \u4ece\u6807\u8bb0\u4e3a good first issues \u7684\u95ee\u9898\u5165\u624b \u8d21\u732e\u4ee3\u7801\uff0c\u8be6\u60c5\u8bf7\u53c2\u89c1 \u5982\u4f55\u8d21\u732e \u76f4\u63a5\u5728GitHub\u4e0a\u63d0 Issue \u8bb8\u53ef\u8bc1 \u00b6 Nebula Graph \u4f7f\u7528 Apache 2.0 \u8bb8\u53ef\u8bc1\uff0c\u60a8\u53ef\u4ee5\u514d\u8d39\u4e0b\u8f7d\uff0c\u4fee\u6539\u4ee5\u53ca\u90e8\u7f72\u6e90\u4ee3\u7801\u3002\u60a8\u8fd8\u53ef\u4ee5\u5c06 Nebula Graph \u4f5c\u4e3a\u540e\u7aef\u670d\u52a1\u90e8\u7f72\u4ee5\u652f\u6301\u60a8\u7684 SaaS \u90e8\u7f72\u3002 \u4e3a\u9632\u6b62\u4e91\u4f9b\u5e94\u5546\u4ece\u9879\u76ee\u8d62\u5229\u800c\u4e0d\u56de\u9988\uff0c Nebula Graph \u5728\u9879\u76ee\u4e2d\u6dfb\u52a0\u4e86 Commons Clause 1.0 \u6761\u6b3e\u3002\u5982\u4e0a\u6240\u8ff0\uff0c Nebula Graph \u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u9879\u76ee\uff0c\u6b22\u8fce\u60a8\u5c31\u8bb8\u53ef\u6a21\u5f0f\u63d0\u51fa\u5efa\u8bae\uff0c\u5e2e\u52a9 Nebula Graph \u793e\u533a\u66f4\u597d\u5730\u53d1\u5c55\u3002 \u8054\u7cfb\u65b9\u5f0f \u00b6 \u8bbf\u95ee\u5b98\u7f51 Home Page \u3002 email: info@vesoft.com","title":"README CN"},{"location":"README-CN/#nebula_graph","text":"Nebula Graph \u662f\u4e00\u6b3e\u5f00\u6e90\u7684\u56fe\u6570\u636e\u5e93\uff0c\u64c5\u957f\u5904\u7406\u5343\u4ebf\u4e2a\u9876\u70b9\u548c\u4e07\u4ebf\u6761\u8fb9\u7684\u8d85\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002 \u4e0e\u5176\u4ed6\u56fe\u6570\u636e\u5e93\u4ea7\u54c1\u76f8\u6bd4\uff0c Nebula Graph \u5177\u6709\u5982\u4e0b\u4f18\u52bf\uff1a \u5168\u5bf9\u79f0\u5206\u5e03\u5f0f\u67b6\u6784 \u5b58\u50a8\u4e0e\u8ba1\u7b97\u5206\u79bb \u6c34\u5e73\u53ef\u6269\u5c55\u6027 RAFT \u534f\u8bae\u4e0b\u7684\u6570\u636e\u5f3a\u4e00\u81f4 \u7c7b SQL \u67e5\u8be2\u8bed\u8a00 \u7528\u6237\u9274\u6743","title":"Nebula Graph\u662f\u4ec0\u4e48\uff1f"},{"location":"README-CN/#_1","text":"Nebula Graph \u4ea7\u54c1\u89c4\u5212\u8def\u7ebf\u56fe\u8bf7\u53c2\u89c1 roadmap \u3002","title":"\u4ea7\u54c1\u8def\u7ebf\u56fe"},{"location":"README-CN/#_2","text":"\u67e5\u770b \u56fe\u53ef\u89c6\u5316 \uff0c\u5f00\u542f\u56fe\u6570\u636e\u53ef\u89c6\u5316\u63a2\u7d22\u4e4b\u65c5\u3002","title":"\u56fe\u53ef\u89c6\u5316"},{"location":"README-CN/#_3","text":"Go Python Java","title":"\u652f\u6301\u7684\u5ba2\u6237\u7aef"},{"location":"README-CN/#_4","text":"\u8bf7\u67e5\u770b \u5feb\u901f\u4f7f\u7528\u624b\u518c \uff0c\u5f00\u59cb\u4f7f\u7528 Nebula Graph \u3002 \u5728\u5f00\u59cb\u4f7f\u7528 Nebula Graph \u4e4b\u524d\uff0c\u5fc5\u987b\u901a\u8fc7 \u7f16\u8bd1\u6e90\u7801 \uff0c rpm/deb \u5305 \u6216\u8005 docker compose \u65b9\u5f0f\u5b89\u88c5 Nebula Graph \u3002\u60a8\u4e5f\u53ef\u4ee5\u89c2\u770b \u89c6\u9891 \u5b66\u4e60\u5982\u4f55\u5b89\u88c5 Nebula Graph \u3002","title":"\u5feb\u901f\u4f7f\u7528"},{"location":"README-CN/#_5","text":"\u5728\u4f7f\u7528 Nebula Graph \u8fc7\u7a0b\u4e2d\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u90fd\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u65b9\u5f0f\u5bfb\u6c42\u5e2e\u52a9\uff1a \u77e5\u4e4e SegmentFault \u5b98\u65b9\u8bba\u575b","title":"\u83b7\u53d6\u5e2e\u52a9"},{"location":"README-CN/#_6","text":"\u7b80\u4f53\u4e2d\u6587 English","title":"\u6587\u6863"},{"location":"README-CN/#nebula_graph_1","text":"","title":"Nebula Graph \u4ea7\u54c1\u67b6\u6784\u56fe"},{"location":"README-CN/#_7","text":"Nebula Graph \u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u9879\u76ee\uff0c\u6b22\u8fce\u5f00\u6e90\u7231\u597d\u8005\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u53c2\u4e0e\u5230 Nebula Graph \u793e\u533a\uff1a \u4ece\u6807\u8bb0\u4e3a good first issues \u7684\u95ee\u9898\u5165\u624b \u8d21\u732e\u4ee3\u7801\uff0c\u8be6\u60c5\u8bf7\u53c2\u89c1 \u5982\u4f55\u8d21\u732e \u76f4\u63a5\u5728GitHub\u4e0a\u63d0 Issue","title":"\u5982\u4f55\u8d21\u732e"},{"location":"README-CN/#_8","text":"Nebula Graph \u4f7f\u7528 Apache 2.0 \u8bb8\u53ef\u8bc1\uff0c\u60a8\u53ef\u4ee5\u514d\u8d39\u4e0b\u8f7d\uff0c\u4fee\u6539\u4ee5\u53ca\u90e8\u7f72\u6e90\u4ee3\u7801\u3002\u60a8\u8fd8\u53ef\u4ee5\u5c06 Nebula Graph \u4f5c\u4e3a\u540e\u7aef\u670d\u52a1\u90e8\u7f72\u4ee5\u652f\u6301\u60a8\u7684 SaaS \u90e8\u7f72\u3002 \u4e3a\u9632\u6b62\u4e91\u4f9b\u5e94\u5546\u4ece\u9879\u76ee\u8d62\u5229\u800c\u4e0d\u56de\u9988\uff0c Nebula Graph \u5728\u9879\u76ee\u4e2d\u6dfb\u52a0\u4e86 Commons Clause 1.0 \u6761\u6b3e\u3002\u5982\u4e0a\u6240\u8ff0\uff0c Nebula Graph \u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u9879\u76ee\uff0c\u6b22\u8fce\u60a8\u5c31\u8bb8\u53ef\u6a21\u5f0f\u63d0\u51fa\u5efa\u8bae\uff0c\u5e2e\u52a9 Nebula Graph \u793e\u533a\u66f4\u597d\u5730\u53d1\u5c55\u3002","title":"\u8bb8\u53ef\u8bc1"},{"location":"README-CN/#_9","text":"\u8bbf\u95ee\u5b98\u7f51 Home Page \u3002 email: info@vesoft.com","title":"\u8054\u7cfb\u65b9\u5f0f"},{"location":"language/","text":"Language \u00b6 Manual \u4e2d\u6587\u624b\u518c","title":"Language"},{"location":"language/#language","text":"Manual \u4e2d\u6587\u624b\u518c","title":"Language"},{"location":"doc-tools/","text":"Generate documentation in PDF \u00b6 This document teaches you how to make documentation in PDF. Step One: Merge \u00b6 Use the provided script merge-all.py to merge all the markdown doc files into one. Step Two: Generate TOC \u00b6 Use pandoc to generated TOC (table of content) for the file you just merged. Firstly, you should make sure that pandoc has been installed on your machine. Open your terminal and run the command: pandoc -v If pandoc is not installed, please install it first. Windows choco install pandoc macOS brew install pandoc If you have any questions on pandoc installation, please check its document here . To generate TOC, you should first change directory to the merged file and type the following command: pandoc -s --toc merged.md -o merged.md Note : The default number of section levels is 3 in the table of contents (which means that level-1, 2, and 3 headings will be listed in the contents), use --toc-depth=NUMBER to specify that number. Step Three: Generate PDF \u00b6 You can convert the merged markdown file into PDF and print it out for easy-reading. Use the following command to generate PDF: pandoc merged.md -o merged.pdf Note: Make sure MiKTeX is installed. Now you've got your PDF documentation and have fun with Nebula Graph .","title":"Generate documentation in PDF"},{"location":"doc-tools/#generate_documentation_in_pdf","text":"This document teaches you how to make documentation in PDF.","title":"Generate documentation in PDF"},{"location":"doc-tools/#step_one_merge","text":"Use the provided script merge-all.py to merge all the markdown doc files into one.","title":"Step One: Merge"},{"location":"doc-tools/#step_two_generate_toc","text":"Use pandoc to generated TOC (table of content) for the file you just merged. Firstly, you should make sure that pandoc has been installed on your machine. Open your terminal and run the command: pandoc -v If pandoc is not installed, please install it first. Windows choco install pandoc macOS brew install pandoc If you have any questions on pandoc installation, please check its document here . To generate TOC, you should first change directory to the merged file and type the following command: pandoc -s --toc merged.md -o merged.md Note : The default number of section levels is 3 in the table of contents (which means that level-1, 2, and 3 headings will be listed in the contents), use --toc-depth=NUMBER to specify that number.","title":"Step Two: Generate TOC"},{"location":"doc-tools/#step_three_generate_pdf","text":"You can convert the merged markdown file into PDF and print it out for easy-reading. Use the following command to generate PDF: pandoc merged.md -o merged.pdf Note: Make sure MiKTeX is installed. Now you've got your PDF documentation and have fun with Nebula Graph .","title":"Step Three: Generate PDF"},{"location":"manual-CN/","text":"\u6b22\u8fce\u4f7f\u7528 Nebula Graph \u624b\u518c \u00b6 Nebula Graph \u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u7684\u53ef\u6269\u5c55\u7684\u9ad8\u6027\u80fd\u7684\u56fe\u6570\u636e\u5e93\u3002 Nebula Graph \u53ef\u4ee5\u5bb9\u7eb3\u767e\u4ebf\u8282\u70b9\u548c\u4e07\u4ebf\u6761\u8fb9\uff0c\u5e76\u8fbe\u5230\u6beb\u79d2\u7ea7\u7684\u65f6\u5ef6\u3002 \u524d\u8a00 \u00b6 \u5173\u4e8e\u672c\u624b\u518c \u53d8\u66f4\u5386\u53f2 \u6982\u89c8 (\u5165\u95e8\u7528\u6237) \u00b6 \u7b80\u4ecb \u57fa\u672c\u6982\u5ff5 \u6570\u636e\u6a21\u578b \u67e5\u8be2\u8bed\u8a00\u6982\u89c8 \u5feb\u901f\u5f00\u59cb\u548c\u5e38\u7528\u94fe\u63a5 \u5f00\u59cb\u8bd5\u7528 \u5e38\u89c1\u95ee\u9898 FAQ \u7f16\u8bd1\u6e90\u4ee3\u7801 \u90e8\u7f72\u96c6\u7fa4 \u5bfc\u5165 .csv \u6587\u4ef6 \u52a0\u8f7d .sst \u6587\u4ef6 Nebula Graph \u5ba2\u6237\u7aef \u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u67b6\u6784 \u8bbe\u8ba1\u603b\u89c8 \u5b58\u50a8\u5c42\u67b6\u6784 \u67e5\u8be2\u5f15\u64ce\u67b6\u6784 \u67e5\u8be2\u8bed\u8a00 (\u6240\u6709\u7528\u6237) \u00b6 \u6570\u636e\u7c7b\u578b \u57fa\u672c\u6570\u636e\u7c7b\u578b \u7c7b\u578b\u8f6c\u6362 \u51fd\u6570\u4e0e\u64cd\u4f5c\u7b26 \u4f4d\u8fd0\u7b97 \u5185\u7f6e\u51fd\u6570 \u6bd4\u8f83\u8fd0\u7b97 \u805a\u5408\u8fd0\u7b97 \u5206\u9875 (Limit) \u903b\u8f91\u8fd0\u7b97 \u6392\u5e8f (Order By) \u96c6\u5408\u8fd0\u7b97 uuid \u51fd\u6570 \u8bed\u8a00\u7ed3\u6784 \u5b57\u9762\u503c\u5e38\u91cf \u5e03\u5c14\u7c7b\u578b \u6570\u503c\u7c7b\u578b \u5b57\u7b26\u4e32\u7c7b\u578b \u6ce8\u91ca\u8bed\u6cd5 \u6807\u8bc6\u7b26\u5927\u5c0f\u5199 \u5173\u952e\u5b57\u548c\u4fdd\u7559\u5b57 \u7ba1\u9053 \u5c5e\u6027\u5f15\u7528 \u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219 \u8bed\u53e5\u7ec4\u5408 \u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf \u8bed\u53e5\u8bed\u6cd5 \u6570\u636e\u5b9a\u4e49\u8bed\u53e5 (DDL) \u65b0\u5efa\u56fe\u7a7a\u95f4 \u65b0\u5efa Tag \u548c Edge \u66f4\u6539 Tag \u548c Edge \u5220\u9664 Tag \u5220\u9664 Edge \u5220\u9664 Space \u7d22\u5f15 TTL (time-to-live) \u6570\u636e\u67e5\u8be2\u4e0e\u64cd\u4f5c\u8bed\u53e5 (DQL \u548c DML) \u5220\u9664\u8fb9 \u5220\u9664\u9876\u70b9 \u83b7\u53d6\u70b9\u548c\u8fb9\u5c5e\u6027 (Fetch) \u56fe\u904d\u5386 (Go) \u63d2\u5165\u8fb9 \u63d2\u5165\u9876\u70b9 \u67e5\u627e\u6570\u636e (Lookup) \u8fd4\u56de\u6ee1\u8db3\u6761\u4ef6\u7684\u8bed\u53e5 (Return) \u66f4\u65b0\u70b9\u548c\u8fb9 Upsert \u8bed\u6cd5 \u6761\u4ef6\u8bed\u53e5 (Where) \u8fd4\u56de\u7ed3\u679c\u8bed\u53e5 (Yield) \u8f85\u52a9\u529f\u80fd\u8bed\u53e5 Show \u8bed\u53e5 Show Charset \u8bed\u6cd5 Show Collation \u8bed\u6cd5 Show Configs \u8bed\u6cd5 Show Create Spaces \u8bed\u6cd5 Show Create Tag/Edge \u8bed\u6cd5 Show Hosts \u8bed\u6cd5 Show Indexes \u8bed\u6cd5 Show Parts \u8bed\u6cd5 Show Roles \u8bed\u6cd5 Show Snapshots \u8bed\u6cd5 Show Spaces \u8bed\u6cd5 Show Tag/Edge \u8bed\u6cd5 Show Users \u8bed\u6cd5 Describe Use \u56fe\u7b97\u6cd5 \u67e5\u627e\u8def\u5f84 \u7f16\u8bd1\u3001\u90e8\u7f72\u4e0e\u8fd0\u7ef4 (\u7a0b\u5e8f\u5458\u548c DBA) \u00b6 \u7f16\u8bd1 \u7f16\u8bd1\u6e90\u4ee3\u7801 \u4f7f\u7528 Docker \u7f16\u8bd1 \u6e90\u7801\u5f00\u53d1\u548c API Key Value \u63a5\u53e3 Nebula Graph \u5ba2\u6237\u7aef \u90e8\u7f72\u4e0e\u8fd0\u7ef4 \u90e8\u7f72 \u914d\u7f6e\u6587\u4ef6\u8bf4\u660e \u7528 Docker \u90e8\u7f72 \u90e8\u7f72\u96c6\u7fa4 rpm \u5b89\u88c5 \u670d\u52a1\u5668\u7ba1\u7406\u64cd\u4f5c \u8d26\u53f7\u7ba1\u7406 Alter User Syntax Built-in Roles Change Password Create User Drop User Grant Role Revoke \u670d\u52a1\u5668\u914d\u7f6e \u670d\u52a1\u5668\u914d\u7f6e \u65e5\u5fd7 \u8ba1\u7b97\u670d\u52a1\u76f8\u5173\u8fd0\u7ef4 \u8ba1\u7b97\u5c42\u8fd0\u884c\u7edf\u8ba1 (metrics) meta \u670d\u52a1\u76f8\u5173\u8fd0\u7ef4 meta \u5c42\u8fd0\u884c\u7edf\u8ba1 (metrics) \u5b58\u50a8\u670d\u52a1\u76f8\u5173\u8fd0\u7ef4 \u79bb\u7ebf\u6570\u636e\u52a0\u8f7d \u52a0\u8f7d .sst \u6587\u4ef6 \u8bfb\u53d6 .csv \u6587\u4ef6 Spark \u5bfc\u5165\u5de5\u5177 \u79bb\u7ebf\u6570\u636e\u8f6c\u50a8 Dump Tool \u8d1f\u8f7d\u5747\u8861\u548c\u6570\u636e\u8fc1\u79fb \u5b58\u50a8\u5c42\u8fd0\u884c\u7edf\u8ba1 (metrics) \u96c6\u7fa4\u5feb\u7167 \u4f5c\u4e1a\u7ba1\u7406 \u793e\u533a\u8d21\u732e (\u5f00\u6e90\u793e\u533a\u7231\u597d\u8005) \u00b6 \u8d21\u732e\u6587\u6863 C++ \u7f16\u7a0b\u98ce\u683c \u5f00\u53d1\u8005\u6587\u6863\u98ce\u683c \u5982\u4f55\u8d21\u732e \u9644\u5f55 \u00b6 Gremlin V.S. nGQL Cypher V.S. nGQL \u5347\u7ea7 Nebula Graph \u5176\u4ed6 \u00b6 \u89c6\u9891 \u00b6 YouTube Bilibili","title":"\u6b22\u8fce\u4f7f\u7528 Nebula Graph \u624b\u518c"},{"location":"manual-CN/#nebula_graph","text":"Nebula Graph \u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u7684\u53ef\u6269\u5c55\u7684\u9ad8\u6027\u80fd\u7684\u56fe\u6570\u636e\u5e93\u3002 Nebula Graph \u53ef\u4ee5\u5bb9\u7eb3\u767e\u4ebf\u8282\u70b9\u548c\u4e07\u4ebf\u6761\u8fb9\uff0c\u5e76\u8fbe\u5230\u6beb\u79d2\u7ea7\u7684\u65f6\u5ef6\u3002","title":"\u6b22\u8fce\u4f7f\u7528 Nebula Graph \u624b\u518c"},{"location":"manual-CN/#_1","text":"\u5173\u4e8e\u672c\u624b\u518c \u53d8\u66f4\u5386\u53f2","title":"\u524d\u8a00"},{"location":"manual-CN/#_2","text":"\u7b80\u4ecb \u57fa\u672c\u6982\u5ff5 \u6570\u636e\u6a21\u578b \u67e5\u8be2\u8bed\u8a00\u6982\u89c8 \u5feb\u901f\u5f00\u59cb\u548c\u5e38\u7528\u94fe\u63a5 \u5f00\u59cb\u8bd5\u7528 \u5e38\u89c1\u95ee\u9898 FAQ \u7f16\u8bd1\u6e90\u4ee3\u7801 \u90e8\u7f72\u96c6\u7fa4 \u5bfc\u5165 .csv \u6587\u4ef6 \u52a0\u8f7d .sst \u6587\u4ef6 Nebula Graph \u5ba2\u6237\u7aef \u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u67b6\u6784 \u8bbe\u8ba1\u603b\u89c8 \u5b58\u50a8\u5c42\u67b6\u6784 \u67e5\u8be2\u5f15\u64ce\u67b6\u6784","title":"\u6982\u89c8 (\u5165\u95e8\u7528\u6237)"},{"location":"manual-CN/#_3","text":"\u6570\u636e\u7c7b\u578b \u57fa\u672c\u6570\u636e\u7c7b\u578b \u7c7b\u578b\u8f6c\u6362 \u51fd\u6570\u4e0e\u64cd\u4f5c\u7b26 \u4f4d\u8fd0\u7b97 \u5185\u7f6e\u51fd\u6570 \u6bd4\u8f83\u8fd0\u7b97 \u805a\u5408\u8fd0\u7b97 \u5206\u9875 (Limit) \u903b\u8f91\u8fd0\u7b97 \u6392\u5e8f (Order By) \u96c6\u5408\u8fd0\u7b97 uuid \u51fd\u6570 \u8bed\u8a00\u7ed3\u6784 \u5b57\u9762\u503c\u5e38\u91cf \u5e03\u5c14\u7c7b\u578b \u6570\u503c\u7c7b\u578b \u5b57\u7b26\u4e32\u7c7b\u578b \u6ce8\u91ca\u8bed\u6cd5 \u6807\u8bc6\u7b26\u5927\u5c0f\u5199 \u5173\u952e\u5b57\u548c\u4fdd\u7559\u5b57 \u7ba1\u9053 \u5c5e\u6027\u5f15\u7528 \u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219 \u8bed\u53e5\u7ec4\u5408 \u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf \u8bed\u53e5\u8bed\u6cd5 \u6570\u636e\u5b9a\u4e49\u8bed\u53e5 (DDL) \u65b0\u5efa\u56fe\u7a7a\u95f4 \u65b0\u5efa Tag \u548c Edge \u66f4\u6539 Tag \u548c Edge \u5220\u9664 Tag \u5220\u9664 Edge \u5220\u9664 Space \u7d22\u5f15 TTL (time-to-live) \u6570\u636e\u67e5\u8be2\u4e0e\u64cd\u4f5c\u8bed\u53e5 (DQL \u548c DML) \u5220\u9664\u8fb9 \u5220\u9664\u9876\u70b9 \u83b7\u53d6\u70b9\u548c\u8fb9\u5c5e\u6027 (Fetch) \u56fe\u904d\u5386 (Go) \u63d2\u5165\u8fb9 \u63d2\u5165\u9876\u70b9 \u67e5\u627e\u6570\u636e (Lookup) \u8fd4\u56de\u6ee1\u8db3\u6761\u4ef6\u7684\u8bed\u53e5 (Return) \u66f4\u65b0\u70b9\u548c\u8fb9 Upsert \u8bed\u6cd5 \u6761\u4ef6\u8bed\u53e5 (Where) \u8fd4\u56de\u7ed3\u679c\u8bed\u53e5 (Yield) \u8f85\u52a9\u529f\u80fd\u8bed\u53e5 Show \u8bed\u53e5 Show Charset \u8bed\u6cd5 Show Collation \u8bed\u6cd5 Show Configs \u8bed\u6cd5 Show Create Spaces \u8bed\u6cd5 Show Create Tag/Edge \u8bed\u6cd5 Show Hosts \u8bed\u6cd5 Show Indexes \u8bed\u6cd5 Show Parts \u8bed\u6cd5 Show Roles \u8bed\u6cd5 Show Snapshots \u8bed\u6cd5 Show Spaces \u8bed\u6cd5 Show Tag/Edge \u8bed\u6cd5 Show Users \u8bed\u6cd5 Describe Use \u56fe\u7b97\u6cd5 \u67e5\u627e\u8def\u5f84","title":"\u67e5\u8be2\u8bed\u8a00 (\u6240\u6709\u7528\u6237)"},{"location":"manual-CN/#dba","text":"\u7f16\u8bd1 \u7f16\u8bd1\u6e90\u4ee3\u7801 \u4f7f\u7528 Docker \u7f16\u8bd1 \u6e90\u7801\u5f00\u53d1\u548c API Key Value \u63a5\u53e3 Nebula Graph \u5ba2\u6237\u7aef \u90e8\u7f72\u4e0e\u8fd0\u7ef4 \u90e8\u7f72 \u914d\u7f6e\u6587\u4ef6\u8bf4\u660e \u7528 Docker \u90e8\u7f72 \u90e8\u7f72\u96c6\u7fa4 rpm \u5b89\u88c5 \u670d\u52a1\u5668\u7ba1\u7406\u64cd\u4f5c \u8d26\u53f7\u7ba1\u7406 Alter User Syntax Built-in Roles Change Password Create User Drop User Grant Role Revoke \u670d\u52a1\u5668\u914d\u7f6e \u670d\u52a1\u5668\u914d\u7f6e \u65e5\u5fd7 \u8ba1\u7b97\u670d\u52a1\u76f8\u5173\u8fd0\u7ef4 \u8ba1\u7b97\u5c42\u8fd0\u884c\u7edf\u8ba1 (metrics) meta \u670d\u52a1\u76f8\u5173\u8fd0\u7ef4 meta \u5c42\u8fd0\u884c\u7edf\u8ba1 (metrics) \u5b58\u50a8\u670d\u52a1\u76f8\u5173\u8fd0\u7ef4 \u79bb\u7ebf\u6570\u636e\u52a0\u8f7d \u52a0\u8f7d .sst \u6587\u4ef6 \u8bfb\u53d6 .csv \u6587\u4ef6 Spark \u5bfc\u5165\u5de5\u5177 \u79bb\u7ebf\u6570\u636e\u8f6c\u50a8 Dump Tool \u8d1f\u8f7d\u5747\u8861\u548c\u6570\u636e\u8fc1\u79fb \u5b58\u50a8\u5c42\u8fd0\u884c\u7edf\u8ba1 (metrics) \u96c6\u7fa4\u5feb\u7167 \u4f5c\u4e1a\u7ba1\u7406","title":"\u7f16\u8bd1\u3001\u90e8\u7f72\u4e0e\u8fd0\u7ef4 (\u7a0b\u5e8f\u5458\u548c DBA)"},{"location":"manual-CN/#_4","text":"\u8d21\u732e\u6587\u6863 C++ \u7f16\u7a0b\u98ce\u683c \u5f00\u53d1\u8005\u6587\u6863\u98ce\u683c \u5982\u4f55\u8d21\u732e","title":"\u793e\u533a\u8d21\u732e (\u5f00\u6e90\u793e\u533a\u7231\u597d\u8005)"},{"location":"manual-CN/#_5","text":"Gremlin V.S. nGQL Cypher V.S. nGQL \u5347\u7ea7 Nebula Graph","title":"\u9644\u5f55"},{"location":"manual-CN/#_6","text":"","title":"\u5176\u4ed6"},{"location":"manual-CN/#_7","text":"YouTube Bilibili","title":"\u89c6\u9891"},{"location":"manual-CN/0.about-this-manual/","text":"\u5173\u4e8e\u672c\u624b\u518c \u00b6 \u6b64\u624b\u518c\u4e3a Nebula Graph \u7684\u7528\u6237\u624b\u518c\uff0c\u7248\u672c\u4e3a R202004_RC4\u3002\u8be6\u7ec6\u7248\u672c\u66f4\u65b0\u4fe1\u606f\u53c2\u89c1 Release Notes \u3002 \u9762\u5411\u7684\u8bfb\u8005 \u00b6 \u672c\u624b\u518c\u9002\u7528\u4e8e \u7b97\u6cd5\u5de5\u7a0b\u5e08 \u3001 \u6570\u636e\u79d1\u5b66\u5bb6 \u3001 \u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458 \u548c DBA \uff0c\u4ee5\u53ca\u6240\u6709\u5bf9 \u56fe\u6570\u636e\u5e93 \u611f\u5174\u8da3\u7684\u4eba\u7fa4\u3002 \u5982\u679c\u5728\u4f7f\u7528 Nebula Graph \u7684\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u6b22\u8fce\u5728 Nebula Graph Community Slack \u63d0\u95ee\u3002 \u5982\u679c\u5bf9\u672c\u624b\u518c\u6709\u4efb\u4f55\u5efa\u8bae\u6216\u7591\u95ee\uff0c\u8bf7\u5728 GitHub \u7ed9\u6211\u4eec\u7559\u8a00\u3002 \u683c\u5f0f\u7ea6\u5b9a \u00b6 Nebula Graph \u5c1a\u5728\u6301\u7eed\u5f00\u53d1\u4e2d\uff0c\u672c\u624b\u518c\u4e5f\u5c06\u6301\u7eed\u66f4\u65b0\u3002 \u672c\u624b\u518c\u4f7f\u7528\u5982\u4e0b\u8bed\u6cd5\u60ef\u4f8b\uff1a \u7b49\u5bbd\u5b57\u4f53 \u7b49\u5bbd\u5b57\u4f53\u7528\u4e8e\u8868\u793a \u547d\u4ee4 \uff0c \u9700\u8981\u7528\u6237\u8f93\u5165\u7684\u547d\u4ee4 \u53ca \u63a5\u53e3 \u3002 \u52a0\u7c97\u5b57\u4f53 \u7528\u4e8e\u547d\u4ee4\u4ee5\u53ca\u5176\u4ed6\u9700\u8981\u7528\u6237\u9010\u5b57\u8f93\u5165\u7684\u6587\u5b57\u3002 UPPERCASE fixed width \u5728\u67e5\u8be2\u8bed\u8a00\u4e2d\uff0c \u4fdd\u7559\u5173\u952e\u5b57 \u548c \u975e\u4fdd\u7559\u5173\u952e\u5b57 \u5747\u4f7f\u7528\u5927\u5199\u7b49\u5bbd\u5b57\u4f53\u8868\u793a\u3002 \u6587\u4ef6\u683c\u5f0f \u00b6 \u672c\u624b\u518c\u6240\u6709\u6587\u4ef6\u5747\u91c7\u7528 Markdown \u7f16\u5199\uff0cHTML \u7f51\u7ad9\u4f7f\u7528 mkdocs \u81ea\u52a8\u751f\u6210\u3002","title":"\u5173\u4e8e\u672c\u624b\u518c"},{"location":"manual-CN/0.about-this-manual/#_1","text":"\u6b64\u624b\u518c\u4e3a Nebula Graph \u7684\u7528\u6237\u624b\u518c\uff0c\u7248\u672c\u4e3a R202004_RC4\u3002\u8be6\u7ec6\u7248\u672c\u66f4\u65b0\u4fe1\u606f\u53c2\u89c1 Release Notes \u3002","title":"\u5173\u4e8e\u672c\u624b\u518c"},{"location":"manual-CN/0.about-this-manual/#_2","text":"\u672c\u624b\u518c\u9002\u7528\u4e8e \u7b97\u6cd5\u5de5\u7a0b\u5e08 \u3001 \u6570\u636e\u79d1\u5b66\u5bb6 \u3001 \u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458 \u548c DBA \uff0c\u4ee5\u53ca\u6240\u6709\u5bf9 \u56fe\u6570\u636e\u5e93 \u611f\u5174\u8da3\u7684\u4eba\u7fa4\u3002 \u5982\u679c\u5728\u4f7f\u7528 Nebula Graph \u7684\u8fc7\u7a0b\u4e2d\u6709\u4efb\u4f55\u95ee\u9898\uff0c\u6b22\u8fce\u5728 Nebula Graph Community Slack \u63d0\u95ee\u3002 \u5982\u679c\u5bf9\u672c\u624b\u518c\u6709\u4efb\u4f55\u5efa\u8bae\u6216\u7591\u95ee\uff0c\u8bf7\u5728 GitHub \u7ed9\u6211\u4eec\u7559\u8a00\u3002","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/0.about-this-manual/#_3","text":"Nebula Graph \u5c1a\u5728\u6301\u7eed\u5f00\u53d1\u4e2d\uff0c\u672c\u624b\u518c\u4e5f\u5c06\u6301\u7eed\u66f4\u65b0\u3002 \u672c\u624b\u518c\u4f7f\u7528\u5982\u4e0b\u8bed\u6cd5\u60ef\u4f8b\uff1a \u7b49\u5bbd\u5b57\u4f53 \u7b49\u5bbd\u5b57\u4f53\u7528\u4e8e\u8868\u793a \u547d\u4ee4 \uff0c \u9700\u8981\u7528\u6237\u8f93\u5165\u7684\u547d\u4ee4 \u53ca \u63a5\u53e3 \u3002 \u52a0\u7c97\u5b57\u4f53 \u7528\u4e8e\u547d\u4ee4\u4ee5\u53ca\u5176\u4ed6\u9700\u8981\u7528\u6237\u9010\u5b57\u8f93\u5165\u7684\u6587\u5b57\u3002 UPPERCASE fixed width \u5728\u67e5\u8be2\u8bed\u8a00\u4e2d\uff0c \u4fdd\u7559\u5173\u952e\u5b57 \u548c \u975e\u4fdd\u7559\u5173\u952e\u5b57 \u5747\u4f7f\u7528\u5927\u5199\u7b49\u5bbd\u5b57\u4f53\u8868\u793a\u3002","title":"\u683c\u5f0f\u7ea6\u5b9a"},{"location":"manual-CN/0.about-this-manual/#_4","text":"\u672c\u624b\u518c\u6240\u6709\u6587\u4ef6\u5747\u91c7\u7528 Markdown \u7f16\u5199\uff0cHTML \u7f51\u7ad9\u4f7f\u7528 mkdocs \u81ea\u52a8\u751f\u6210\u3002","title":"\u6587\u4ef6\u683c\u5f0f"},{"location":"manual-CN/CHANGELOG/","text":"Manual Changes \u00b6 0.1.5 - 1.0 RC1 0.1.4 - 1.0 beta release 0.1.3 - Add files in manual-CN 0.1.2 - Add files in manual-EN 0.1.1 - Initial release","title":"Manual Changes"},{"location":"manual-CN/CHANGELOG/#manual_changes","text":"0.1.5 - 1.0 RC1 0.1.4 - 1.0 beta release 0.1.3 - Add files in manual-CN 0.1.2 - Add files in manual-EN 0.1.1 - Initial release","title":"Manual Changes"},{"location":"manual-CN/1.overview/","text":"\u9762\u5411\u7684\u8bfb\u8005 \u00b6 \u672c\u7ae0\u9762\u5411 Nebula Graph \u7684\u5165\u95e8\u7528\u6237","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/1.overview/#_1","text":"\u672c\u7ae0\u9762\u5411 Nebula Graph \u7684\u5165\u95e8\u7528\u6237","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/1.overview/0.introduction/","text":"Nebula Graph \u6982\u89c8 \u00b6 \u4ec0\u4e48\u662f Nebula Graph \u00b6 Nebula Graph \u662f\u4e00\u4e2a\u5f00\u6e90 (Apache 2.0)\uff0c\u9ad8\u6027\u80fd\u7684\u5206\u5e03\u5f0f\u56fe\u6570\u636e\u5e93\uff0c\u662f\u4e16\u754c\u4e0a\u552f\u4e00\u4e00\u4e2a\u652f\u6301\u767e\u4ebf\u8282\u70b9\uff0c\u4e07\u4ebf\u6761\u8fb9\uff0c\u5e76\u63d0\u4f9b\u6beb\u79d2\u5ef6\u8fdf\u7684\u56fe\u6570\u636e\u5e93\u89e3\u51b3\u65b9\u6848\u3002 Nebula Graph \u7684\u76ee\u6807\u662f\u63d0\u4f9b\u9ad8\u5e76\u53d1\u4f4e\u5ef6\u65f6\u7684\u8bfb\u5199\u53ca\u8ba1\u7b97\u3002 Nebula Graph \u662f\u4e00\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u6211\u4eec\u671f\u5f85\u4e0e\u793e\u533a\u4e00\u8d77\u5171\u540c\u63a8\u8fdb\u884c\u4e1a\u53d1\u5c55\u3002 Nebula Graph \u7279\u70b9 \u00b6 Nebula Graph \u6709\u5982\u4e0b\u91cd\u8981\u7279\u70b9\uff1a \u9ad8\u6027\u80fd \u63d0\u4f9b\u4f4e\u5ef6\u65f6\u9ad8\u5e76\u53d1\u8bfb\u5199 \u7c7b SQL \u67e5\u8be2\u8bed\u8a00 SQL \u5f0f\u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u6613\u5b66\u6613\u7528\uff0c\u6ee1\u8db3\u590d\u6742\u4e1a\u52a1\u9700\u6c42 \u9ad8\u5ea6\u5b89\u5168 \u5b8c\u5584\u7684\u5206\u7ec4\u548c\u7528\u6237\u9274\u6743 \u53ef\u6269\u5c55 \u652f\u6301\u6c34\u5e73\u6269\u5c55\uff0c\u53ef\u81ea\u52a8\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u4e0e\u5f39\u6027\u6269\u5bb9 \u591a\u5b58\u50a8\u540e\u7aef \u652f\u6301 RocksDB\u3001HBase \u7b49\u591a\u79cd\u5b58\u50a8\u540e\u7aef \u667a\u80fd\u9a71\u52a8 \u901a\u8fc7\u7d22\u5f15\u63a8\u8350\u3001\u6307\u6807\u76d1\u63a7\u3001\u6162\u67e5\u8be2\u5206\u6790\u53d1\u73b0\u6027\u80fd\u98ce\u9669 \u9ad8\u53ef\u7528 \u591a\u91cd\u5197\u4f59\u67b6\u6784\u8bbe\u8ba1\uff0c\u4e3a\u6570\u636e\u6301\u4e45\u5b58\u50a8\u63d0\u4f9b\u53ef\u9760\u4fdd\u969c","title":"Nebula Graph \u6982\u89c8"},{"location":"manual-CN/1.overview/0.introduction/#nebula_graph","text":"","title":"Nebula Graph \u6982\u89c8"},{"location":"manual-CN/1.overview/0.introduction/#nebula_graph_1","text":"Nebula Graph \u662f\u4e00\u4e2a\u5f00\u6e90 (Apache 2.0)\uff0c\u9ad8\u6027\u80fd\u7684\u5206\u5e03\u5f0f\u56fe\u6570\u636e\u5e93\uff0c\u662f\u4e16\u754c\u4e0a\u552f\u4e00\u4e00\u4e2a\u652f\u6301\u767e\u4ebf\u8282\u70b9\uff0c\u4e07\u4ebf\u6761\u8fb9\uff0c\u5e76\u63d0\u4f9b\u6beb\u79d2\u5ef6\u8fdf\u7684\u56fe\u6570\u636e\u5e93\u89e3\u51b3\u65b9\u6848\u3002 Nebula Graph \u7684\u76ee\u6807\u662f\u63d0\u4f9b\u9ad8\u5e76\u53d1\u4f4e\u5ef6\u65f6\u7684\u8bfb\u5199\u53ca\u8ba1\u7b97\u3002 Nebula Graph \u662f\u4e00\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u6211\u4eec\u671f\u5f85\u4e0e\u793e\u533a\u4e00\u8d77\u5171\u540c\u63a8\u8fdb\u884c\u4e1a\u53d1\u5c55\u3002","title":"\u4ec0\u4e48\u662f Nebula Graph"},{"location":"manual-CN/1.overview/0.introduction/#nebula_graph_2","text":"Nebula Graph \u6709\u5982\u4e0b\u91cd\u8981\u7279\u70b9\uff1a \u9ad8\u6027\u80fd \u63d0\u4f9b\u4f4e\u5ef6\u65f6\u9ad8\u5e76\u53d1\u8bfb\u5199 \u7c7b SQL \u67e5\u8be2\u8bed\u8a00 SQL \u5f0f\u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u6613\u5b66\u6613\u7528\uff0c\u6ee1\u8db3\u590d\u6742\u4e1a\u52a1\u9700\u6c42 \u9ad8\u5ea6\u5b89\u5168 \u5b8c\u5584\u7684\u5206\u7ec4\u548c\u7528\u6237\u9274\u6743 \u53ef\u6269\u5c55 \u652f\u6301\u6c34\u5e73\u6269\u5c55\uff0c\u53ef\u81ea\u52a8\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u4e0e\u5f39\u6027\u6269\u5bb9 \u591a\u5b58\u50a8\u540e\u7aef \u652f\u6301 RocksDB\u3001HBase \u7b49\u591a\u79cd\u5b58\u50a8\u540e\u7aef \u667a\u80fd\u9a71\u52a8 \u901a\u8fc7\u7d22\u5f15\u63a8\u8350\u3001\u6307\u6807\u76d1\u63a7\u3001\u6162\u67e5\u8be2\u5206\u6790\u53d1\u73b0\u6027\u80fd\u98ce\u9669 \u9ad8\u53ef\u7528 \u591a\u91cd\u5197\u4f59\u67b6\u6784\u8bbe\u8ba1\uff0c\u4e3a\u6570\u636e\u6301\u4e45\u5b58\u50a8\u63d0\u4f9b\u53ef\u9760\u4fdd\u969c","title":"Nebula Graph \u7279\u70b9"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/","text":"\u56fe\u6570\u636e\u5efa\u6a21 \u00b6 \u6b64\u6587\u6863\u4ecb\u7ecd Nebula Graph \u5efa\u6a21\u53ca\u56fe\u6a21\u578b\u7684\u57fa\u672c\u6982\u5ff5\u3002 \u56fe\u7a7a\u95f4 \u00b6 \u56fe\u7a7a\u95f4 \u4e3a\u5f7c\u6b64\u9694\u79bb\u7684\u56fe\u6570\u636e\uff0c\u4e0e MySQL \u4e2d\u7684 database \u6982\u5ff5\u7c7b\u4f3c\u3002 \u6709\u5411\u5c5e\u6027\u56fe \u00b6 Nebula Graph \u5b58\u50a8\u7684\u56fe\u4e3a \u6709\u5411\u5c5e\u6027\u56fe \uff0c\u8fb9\u4e3a\u6709\u5411\u8fb9\uff0c\u70b9\u548c\u8fb9\u5747\u53ef\u5305\u542b\u5c5e\u6027\u3002\u53ef\u8868\u793a\u4e3a\uff1a G = < V, E, P V , P E >, \u5176\u4e2d V \u8868\u793a\u8282\u70b9\uff0c E \u8868\u793a\u6709\u5411\u8fb9\uff0c P V \u8868\u793a\u8282\u70b9\u5c5e\u6027\uff0c P E \u8868\u793a\u8fb9\u5c5e\u6027\u3002 \u6b64\u6587\u6863\u5c06\u4f7f\u7528\u5982\u4e0b\u793a\u4f8b\u56fe\u6570\u636e\u4ecb\u7ecd\u5c5e\u6027\u56fe\u7684\u57fa\u672c\u6982\u5ff5\uff1a \u4e0a\u56fe\u4e3a NBA \u7403\u5458\u53ca\u7403\u961f\u4fe1\u606f\u6570\u636e\uff0c\u56fe\u4e2d\u5305\u542b 2 \u79cd\u7c7b\u578b\u7684 11 \u4e2a\u8282\u70b9\uff0c\u5373 player \u548c team\uff0c2 \u79cd\u7c7b\u578b\u7684\u8fb9\uff0c\u5373 serve \u548c like\u3002 \u4ee5\u4e0b\u4e3a\u793a\u4f8b\u56fe\u6570\u636e\u6d89\u53ca\u5230\u7684\u6982\u5ff5\u4ecb\u7ecd\u3002 \u8282\u70b9 \u00b6 \u8282\u70b9\u7528\u4e8e\u8868\u793a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5b9e\u4f53\uff0c\u672c\u4f8b\u7684\u6570\u636e\u4e2d\u5171\u5305\u542b 11 \u4e2a\u8282\u70b9\u3002 \u6807\u7b7e \u00b6 Nebula Graph \u4f7f\u7528 \u6807\u7b7e \u5bf9\u8282\u70b9\u8fdb\u884c\u5206\u7c7b\uff0c\u672c\u4f8b\u5305\u542b\u7684\u8282\u70b9\u6807\u7b7e\u4e3a player \u548c team \u3002 \u8fb9 \u00b6 \u8fb9\u7528\u6765\u8fde\u63a5\u8282\u70b9\uff0c\u8fb9\u901a\u5e38\u8868\u793a\u4e24\u4e2a\u8282\u70b9\u95f4\u7684\u67d0\u79cd\u5173\u7cfb\u6216\u884c\u4e3a\uff0c\u672c\u4f8b\u4e2d\u7684\u8fb9\u4e3a serve \u548c like \u3002 \u8fb9\u7c7b\u578b \u00b6 \u6bcf\u6761\u8fb9\u90fd\u6709\u4e00\u79cd\u8fb9\u7c7b\u578b\uff0c\u4ee5\u8fb9 serve \u4e3a\u4f8b\uff0c\u8282\u70b9 101 \uff08\u8868\u793a\u4e00\u540d\u7403\u5458\uff09\u4e3a\u8d77\u59cb\u70b9\uff0c\u8282\u70b9 215 \uff08\u8868\u793a\u4e00\u652f\u7403\u961f\uff09\u4e3a\u76ee\u6807\u70b9\u3002\u8282\u70b9 101 \u6709\u4e00\u6761\u51fa\u8fb9\uff0c\u800c\u8282\u70b9 215 \u6709\u4e00\u6761\u5165\u8fb9\u3002 \u5c5e\u6027 \u00b6 \u5c5e\u6027\u4e3a\u70b9\u548c\u8fb9\u5185\u90e8\u7684\u952e\u503c\u5bf9\u3002\u672c\u4f8b\u4e2d\uff0c\u8282\u70b9 player \u62e5\u6709\u5c5e\u6027 id \uff0c name \u548c age \uff0c\u8fb9 _ like \u5219\u62e5\u6709\u5c5e\u6027 likeness \u3002 Schema \u00b6 \u5728 Nebula Graph \u4e2d\uff0cschema \u4e3a\u6807\u7b7e\u53ca\u8fb9\u5bf9\u5e94\u7684\u5c5e\u6027\u3002\u4e0e MySQL \u7c7b\u4f3c\uff0c Nebula Graph \u662f\u4e00\u79cd\u5f3a schema \u7684\u6570\u636e\u5e93\uff0c\u5c5e\u6027\u7684\u540d\u79f0\u548c\u6570\u636e\u7c7b\u578b\u5728\u6570\u636e\u5199\u5165\u524d\u5df2\u786e\u5b9a\u3002","title":"\u56fe\u6570\u636e\u5efa\u6a21"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_1","text":"\u6b64\u6587\u6863\u4ecb\u7ecd Nebula Graph \u5efa\u6a21\u53ca\u56fe\u6a21\u578b\u7684\u57fa\u672c\u6982\u5ff5\u3002","title":"\u56fe\u6570\u636e\u5efa\u6a21"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_2","text":"\u56fe\u7a7a\u95f4 \u4e3a\u5f7c\u6b64\u9694\u79bb\u7684\u56fe\u6570\u636e\uff0c\u4e0e MySQL \u4e2d\u7684 database \u6982\u5ff5\u7c7b\u4f3c\u3002","title":"\u56fe\u7a7a\u95f4"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_3","text":"Nebula Graph \u5b58\u50a8\u7684\u56fe\u4e3a \u6709\u5411\u5c5e\u6027\u56fe \uff0c\u8fb9\u4e3a\u6709\u5411\u8fb9\uff0c\u70b9\u548c\u8fb9\u5747\u53ef\u5305\u542b\u5c5e\u6027\u3002\u53ef\u8868\u793a\u4e3a\uff1a G = < V, E, P V , P E >, \u5176\u4e2d V \u8868\u793a\u8282\u70b9\uff0c E \u8868\u793a\u6709\u5411\u8fb9\uff0c P V \u8868\u793a\u8282\u70b9\u5c5e\u6027\uff0c P E \u8868\u793a\u8fb9\u5c5e\u6027\u3002 \u6b64\u6587\u6863\u5c06\u4f7f\u7528\u5982\u4e0b\u793a\u4f8b\u56fe\u6570\u636e\u4ecb\u7ecd\u5c5e\u6027\u56fe\u7684\u57fa\u672c\u6982\u5ff5\uff1a \u4e0a\u56fe\u4e3a NBA \u7403\u5458\u53ca\u7403\u961f\u4fe1\u606f\u6570\u636e\uff0c\u56fe\u4e2d\u5305\u542b 2 \u79cd\u7c7b\u578b\u7684 11 \u4e2a\u8282\u70b9\uff0c\u5373 player \u548c team\uff0c2 \u79cd\u7c7b\u578b\u7684\u8fb9\uff0c\u5373 serve \u548c like\u3002 \u4ee5\u4e0b\u4e3a\u793a\u4f8b\u56fe\u6570\u636e\u6d89\u53ca\u5230\u7684\u6982\u5ff5\u4ecb\u7ecd\u3002","title":"\u6709\u5411\u5c5e\u6027\u56fe"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_4","text":"\u8282\u70b9\u7528\u4e8e\u8868\u793a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5b9e\u4f53\uff0c\u672c\u4f8b\u7684\u6570\u636e\u4e2d\u5171\u5305\u542b 11 \u4e2a\u8282\u70b9\u3002","title":"\u8282\u70b9"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_5","text":"Nebula Graph \u4f7f\u7528 \u6807\u7b7e \u5bf9\u8282\u70b9\u8fdb\u884c\u5206\u7c7b\uff0c\u672c\u4f8b\u5305\u542b\u7684\u8282\u70b9\u6807\u7b7e\u4e3a player \u548c team \u3002","title":"\u6807\u7b7e"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_6","text":"\u8fb9\u7528\u6765\u8fde\u63a5\u8282\u70b9\uff0c\u8fb9\u901a\u5e38\u8868\u793a\u4e24\u4e2a\u8282\u70b9\u95f4\u7684\u67d0\u79cd\u5173\u7cfb\u6216\u884c\u4e3a\uff0c\u672c\u4f8b\u4e2d\u7684\u8fb9\u4e3a serve \u548c like \u3002","title":"\u8fb9"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_7","text":"\u6bcf\u6761\u8fb9\u90fd\u6709\u4e00\u79cd\u8fb9\u7c7b\u578b\uff0c\u4ee5\u8fb9 serve \u4e3a\u4f8b\uff0c\u8282\u70b9 101 \uff08\u8868\u793a\u4e00\u540d\u7403\u5458\uff09\u4e3a\u8d77\u59cb\u70b9\uff0c\u8282\u70b9 215 \uff08\u8868\u793a\u4e00\u652f\u7403\u961f\uff09\u4e3a\u76ee\u6807\u70b9\u3002\u8282\u70b9 101 \u6709\u4e00\u6761\u51fa\u8fb9\uff0c\u800c\u8282\u70b9 215 \u6709\u4e00\u6761\u5165\u8fb9\u3002","title":"\u8fb9\u7c7b\u578b"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#_8","text":"\u5c5e\u6027\u4e3a\u70b9\u548c\u8fb9\u5185\u90e8\u7684\u952e\u503c\u5bf9\u3002\u672c\u4f8b\u4e2d\uff0c\u8282\u70b9 player \u62e5\u6709\u5c5e\u6027 id \uff0c name \u548c age \uff0c\u8fb9 _ like \u5219\u62e5\u6709\u5c5e\u6027 likeness \u3002","title":"\u5c5e\u6027"},{"location":"manual-CN/1.overview/1.concepts/1.data-model/#schema","text":"\u5728 Nebula Graph \u4e2d\uff0cschema \u4e3a\u6807\u7b7e\u53ca\u8fb9\u5bf9\u5e94\u7684\u5c5e\u6027\u3002\u4e0e MySQL \u7c7b\u4f3c\uff0c Nebula Graph \u662f\u4e00\u79cd\u5f3a schema \u7684\u6570\u636e\u5e93\uff0c\u5c5e\u6027\u7684\u540d\u79f0\u548c\u6570\u636e\u7c7b\u578b\u5728\u6570\u636e\u5199\u5165\u524d\u5df2\u786e\u5b9a\u3002","title":"Schema"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/","text":"Nebula Graph \u67e5\u8be2\u8bed\u8a00 (nGQL) \u00b6 nGQL \u6982\u89c8 \u00b6 nGQL \u662f\u4e00\u79cd\u58f0\u660e\u578b\u7684\u6587\u672c\u67e5\u8be2\u8bed\u8a00\uff0c\u76ee\u524d\u5c1a\u5728\u5f00\u53d1\u4e2d\u3002\u65b0\u7248\u672c\u4f1a\u6dfb\u52a0\u66f4\u591a\u529f\u80fd\u5e76\u4f18\u5316\u5df2\u6709\u529f\u80fd\u3002\u672a\u6765\u7684\u8bed\u6cd5\u89c4\u8303\u53ef\u80fd\u4f1a\u4e0e\u73b0\u884c\u7684\u4e0d\u4e00\u81f4\u3002 \u76ee\u6807 \u00b6 \u6613\u5b66 \u6613\u7528 \u4e13\u6ce8\u7ebf\u4e0a\u67e5\u8be2\uff0c\u540c\u65f6\u4e3a\u79bb\u7ebf\u8ba1\u7b97\u63d0\u4f9b\u57fa\u7840 \u7279\u70b9 \u00b6 \u7c7b SQL\uff0c\u6613\u5b66\u6613\u7528 \u53ef\u6269\u5c55 \u5927\u5c0f\u5199\u4e0d\u654f\u611f \u652f\u6301\u56fe\u904d\u5386 \u652f\u6301\u6a21\u5f0f\u5339\u914d \u652f\u6301\u805a\u5408\u8fd0\u7b97 \u652f\u6301\u56fe\u8ba1\u7b97 \u652f\u6301\u5206\u5e03\u5f0f\u4e8b\u52a1\uff08\u5f00\u53d1\u4e2d\uff09 \u65e0\u5d4c\u5165\u652f\u6301\u7ec4\u5408\u8bed\u53e5\uff0c\u6613\u4e8e\u9605\u8bfb \u672f\u8bed \u00b6 \u56fe\u7a7a\u95f4 \uff1a\u7269\u7406\u9694\u79bb\u7684\u4e0d\u540c\u6570\u636e\u96c6 \u6807\u7b7e \uff1a\u62e5\u6709\u4e00\u79cd\u6216\u591a\u79cd\u5c5e\u6027 \u6bcf\u4e2a\u6807\u7b7e\u90fd\u6709\u4e00\u4e2a\u4eba\u7c7b\u53ef\u8bfb\u7684\u540d\u79f0\uff0c\u5e76\u4e14\u6bcf\u4e2a\u6807\u7b7e\u5185\u90e8\u90fd\u4f1a\u5206\u914d\u4e00\u4e2a 32 \u4f4d\u7684\u6574\u6570 \u6bcf\u4e2a\u6807\u7b7e\u4e0e\u4e00\u4e2a\u5c5e\u6027\u5217\u8868\u76f8\u5173\u8054\uff0c\u6bcf\u4e2a\u5c5e\u6027\u90fd\u6709\u4e00\u4e2a\u540d\u79f0\u548c\u7c7b\u578b \u6807\u7b7e\u4e4b\u95f4\u53ef\u5b58\u5728\u4f9d\u8d56\u5173\u7cfb\u4f5c\u4e3a\u7ea6\u675f\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6807\u7b7e S \u4f9d\u8d56\u4e8e\u6807\u7b7e T\uff0c\u5219\u9664\u975e\u6807\u7b7e T \u5b58\u5728\uff0c\u5426\u5219\u6807\u7b7e S \u65e0\u6cd5\u5b58\u5728\u3002 \u8282\u70b9 \uff1a\u56fe\u6570\u636e\u4e2d\u4ee3\u8868\u5b9e\u4f53\u7684\u70b9 \u6bcf\u4e2a\u8282\u70b9\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u7684 64 \u4f4d\uff08\u6709\u7b26\u53f7\u6574\u6570\uff09ID ( VID ) \u4e00\u4e2a\u8282\u70b9\u53ef\u4ee5\u62e5\u6709\u591a\u4e2a \u6807\u7b7e \u8fb9 \uff1a\u8282\u70b9\u4e4b\u95f4\u7684\u8054\u7cfb\u79f0\u4e3a\u8fb9 \u6bcf\u6761\u8fb9\u7531\u552f\u4e00\u6570\u7ec4 \u6807\u8bc6 \u8fb9\u7c7b\u578b \u662f\u4eba\u7c7b\u53ef\u8bfb\u7684\u5b57\u7b26\u4e32\uff0c\u5e76\u4e14\u6bcf\u6761\u8fb9\u5185\u90e8\u90fd\u4f1a\u5206\u914d\u4e00\u4e2a 32 \u4f4d\u7684\u6574\u6570\u3002\u8fb9\u7c7b\u578b\u51b3\u5b9a\u8fb9\u4e0a\u7684\u5c5e\u6027\uff08\u6a21\u5f0f\uff09 \u8fb9 ranking \u662f\u7528\u6237\u5206\u914d\u7684\u4e0d\u53ef\u53d8\u7684 64 \u4f4d\u5e26\u7b26\u53f7\u6574\u6570\uff0c\u51b3\u5b9a\u4e24\u4e2a\u9876\u70b9\u4e4b\u95f4\u7684\u8fb9\u987a\u5e8f\u3002\u7b49\u7ea7\u503c\u8f83\u9ad8\u7684\u8fb9\u6392\u540d\u9760\u524d\u3002\u5982\u672a\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u7b49\u7ea7\u503c\u4e3a\u96f6\u3002 \u6bcf\u6761\u8fb9\u53ea\u80fd\u6709\u4e00\u79cd\u7c7b\u578b \u8def\u5f84 : \u591a\u4e2a\u8282\u70b9\u4e0e\u8fb9\u7684 \u975e\u5206\u652f \u8fde\u63a5 \u8def\u5f84\u957f\u5ea6\u4e3a\u8be5\u8def\u5f84\u4e0a\u7684\u8fb9\u6570\uff0c\u6bd4\u8282\u70b9\u6570\u5c11 1 \u8def\u5f84\u53ef\u7531\u4e00\u7cfb\u5217\u8282\u70b9\uff0c\u8fb9\u7c7b\u578b\u53ca\u6743\u91cd\u8868\u793a\u3002\u4e00\u6761\u8fb9\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a 1 \u7684\u7279\u6b8a\u8def\u5f84 <vid, <edge_type, rank>, vid, ...> \u67e5\u8be2\u8bed\u8a00\u89c4\u5219\u6982\u89c8 \u00b6 \u4e0d\u719f\u6089 BNF \u7684\u8bfb\u8005\u53ef\u8df3\u8fc7\u672c\u8282 \u603b\u89c8 \u00b6 \u6574\u5957\u8bed\u53e5\u53ef\u5206\u4e3a\u4e09\u90e8\u5206\uff1a \u67e5\u8be2 \u3001 \u66f4\u6539 \u3001 \u7ba1\u7406 \u6bcf\u6761\u8bed\u53e5\u5747\u53ef\u8fd4\u56de\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u7b2c\u4e2a\u6570\u636e\u96c6\u5747\u5305\u542b\u4e00\u4e2a schema \u548c\u591a\u6761\u6570\u636e \u8bed\u53e5\u7ec4\u5408 \u00b6 \u8bed\u53e5\u7ec4\u5408\u6709\u4e24\u79cd\u65b9\u5f0f\uff1a \u8bed\u53e5\u53ef\u4f7f\u7528\u7ba1\u9053\u51fd\u6570 \" | \u8fde\u63a5\uff0c\u524d\u4e00\u6761\u8bed\u53e5\u8fd4\u56de\u7684\u7ed3\u679c\u53ef\u4f5c\u4e3a\u4e0b\u4e00\u6761\u8bed\u53e5\u7684\u67e5\u8be2\u6761\u4ef6 \u652f\u6301\u4f7f\u7528 \" ; \" \u6279\u91cf\u8f93\u5165\u591a\u6761\u8bed\u53e5\uff0c\u6279\u5904\u7406\u65f6\u8fd4\u56de\u6700\u540e\u4e00\u6761\u8bed\u53e5\u7ed3\u679c \u6570\u636e\u7c7b\u578b \u00b6 \u7b80\u5355\u7c7b\u578b\uff1a vid \u3001 double \u3001 int \u3001 bool \u3001 string \u548c timestamp vid \uff1a 64 \u4f4d\u6709\u7b26\u53f7\u6574\u6570\uff0c\u7528\u6765\u8868\u793a\u70b9 ID \u7b80\u5355\u7c7b\u578b\u5217\u8868\uff0c\u5982\uff1a integer[] , double[] , string[] Map : \u952e\u503c\u5bf9\u5217\u8868\u3002\u952e\u7c7b\u578b\u5fc5\u987b\u4e3a \u5b57\u7b26 \uff0c\u503c\u7c7b\u578b\u5fc5\u987b\u4e0e\u7ed9\u5b9a map Object (\u672a\u6765\u7248\u672c\u652f\u6301): \u952e\u503c\u5bf9\u5217\u8868\u3002\u952e\u7c7b\u578b\u5fc5\u987b\u4e3a \u5b57\u7b26 \uff0c\u503c\u53ef\u4ee5\u662f\u4efb\u610f\u7b80\u5355\u7c7b\u578b Tuple List : \u53ea\u9002\u7528\u4e8e\u8fd4\u56de\u503c \u3002\u7531\u5143\u6570\u636e\u548c\u6570\u636e\uff08\u591a\u884c\uff09\u7ec4\u6210 \u3002\u5143\u6570\u636e\u5305\u542b\u5217\u540d\u548c\u7c7b\u578b\u3002 \u7c7b\u578b\u8f6c\u6362 \u00b6 \u4e00\u4e2a\u7b80\u5355\u7684\u7c7b\u578b\u503c\u53ef\u4ee5\u9690\u5f0f\u8f6c\u6362\u4e3a\u5217\u8868 \u5217\u8868\u53ef\u4ee5\u9690\u5f0f\u8f6c\u6362\u4e3a\u5355\u5217\u5143\u7ec4\u5217\u8868 \"<type>_list\" \u53ef\u7528\u6765\u8868\u793a\u5217\u540d \u5e38\u7528 BNF \u00b6 ::= vid | integer | double | float | bool | string | path | timestamp | year | month | date | datetime ::= <type> ::= | ::= vid (, vid )* | \"{\" vid (, vid )* \"}\" <label> ::= [:alpha] ([:alnum:] | \"_\")* ::= (\"_\")* <label> ::= <label> ::= (, )* ::= :<type> ::= \":\" ::= ::= <tuple> (, <tuple>)* | \"{\" <tuple> (, <tuple>)* \"}\" <tuple> ::= \"(\" VALUE (, VALUE )* \")\" <var> ::= \"$\" <label> \u67e5\u8be2\u8bed\u53e5 \u00b6 \u9009\u62e9\u56fe\u7a7a\u95f4 \u00b6 Nebula Graph \u652f\u6301\u591a\u56fe\u7a7a\u95f4\u3002\u4e0d\u540c\u56fe\u7a7a\u95f4\u7684\u6570\u636e\u5f7c\u6b64\u9694\u79bb\u3002\u5728\u8fdb\u884c\u67e5\u8be2\u524d\uff0c\u9700\u6307\u5b9a\u56fe\u7a7a\u95f4\u3002 USE \u8fd4\u56de\u6570\u636e\u96c6 \u00b6 \u8fd4\u56de\u5355\u4e2a\u503c\u6216\u6570\u636e\u96c6 RETURN ::= vid | | | <var> \u521b\u5efa\u6807\u7b7e \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa \u65b0 \u6807\u7b7e CREATE TAG ( ) ::= <label> ::= + ::= ,<type> ::= <label> \u521b\u5efa\u8fb9\u7c7b\u578b \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa \u65b0 \u7684\u8fb9\u7c7b\u578b CREATE EDGE ( ) := <label> \u63d2\u5165\u8282\u70b9 \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u4e00\u4e2a\u6216\u591a\u4e2a\u8282\u70b9 INSERT VERTEX [ NO OVERWRITE ] VALUES ::= ( ) (, ( ))* ::= :( ) (, :( ))* ::= vid ::= (, )* ::= VALUE (, VALUE )* \u63d2\u5165\u8fb9 \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u4e00\u6761\u6216\u591a\u6761\u8fb9 INSERT EDGE [ NO OVERWRITE ] [( )] VALUES ( )+ edge_value ::= -> [@ <weight>] : \u66f4\u65b0\u8282\u70b9 \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0\u8282\u70b9 UPDATE VERTEX SET \\<update_decl> [ WHERE <conditions>] [ YIELD ] ::= | ::= = <expression> {, = <expression>}+ ::= ( ) = ( ) | ( ) = <var> \u66f4\u65b0\u8fb9 \u00b6 \u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0\u8fb9 UPDATE EDGE -> [@<weight>] OF SET [ WHERE <conditions>] [ YIELD ] \u56fe\u904d\u5386 \u00b6 \u6839\u636e\u6307\u5b9a\u6761\u4ef6\u904d\u5386\u7ed9\u5b9a\u8282\u70b9\u7684\u5173\u8054\u8282\u70b9\uff0c\u8fd4\u56de\u8282\u70b9 ID \u5217\u8868\u6216\u6570\u7ec4 GO [ STEPS ] FROM [ OVER [ REVERSELY ] ] [ WHERE ] [ YIELD ] ::= [data_set] [[ AS ] <label>] ::= vid | | | <var> ::= [ AS <label>] ::= {, }* ::= <label> ::= <filter> { AND | OR <filter>}* ::= \\ \\ **>**\\ | \\ **>= | < | <= | == | != <expression> | <expression> IN <value_list> ::= {, }* ::= <expression> [ AS** <label>] WHERE \u8bed\u53e5\u4ec5\u9002\u7528\u4e8e\u6700\u7ec8\u8fd4\u56de\u7ed3\u679c\uff0c\u5bf9\u4e2d\u95f4\u7ed3\u679c\u4e0d\u9002\u7528\u3002 \u8df3\u8fc7 STEP[S] \u8868\u793a \u4e00\u6b65 \u4ece\u8d77\u59cb\u70b9\u51fa\u53d1\u4e00\u8df3\uff0c\u904d\u5386\u6240\u6709\u6ee1\u8db3 WHERE \u8bed\u53e5\u7684\u5173\u8054\u70b9\uff0c\u53ea\u8fd4\u56de\u6ee1\u8db3 WHERE \u8bed\u53e5\u7684\u7ed3\u679c\u3002 \u591a\u8df3\u67e5\u8be2\u65f6\uff0c WHERE \u8bed\u53e5\u53ea\u9002\u7528\u4e8e\u6700\u7ec8\u7ed3\u679c\uff0c\u5bf9\u4e2d\u95f4\u7ed3\u679c\u4e0d\u9002\u7528\u3002\u4f8b\u5982\uff1a GO 2 STEPS FROM me OVER friend WHERE birthday > \"1988/1/1\" \u4ee5\u4e0a\u8bed\u53e5\u67e5\u8be2\u6240\u6709\u751f\u65e5\u5728 1988/1/1 \u4e4b\u540e\u7684\u4e8c\u5ea6\u597d\u53cb\u3002 \u641c\u7d22 \u00b6 \u4ee5\u4e0b\u8bed\u53e5\u5bf9\u6ee1\u8db3\u7b5b\u9009\u6761\u4ef6\u7684\u8282\u70b9\u6216\u8fb9\u8fdb\u884c\u641c\u7d22\u3002 FIND VERTEX WHERE [ YIELD ] FIND EDGE WHERE [ YIELD ] \u5c5e\u6027\u5173\u8054 \u00b6 \u5c5e\u6027\u5173\u8054\u5f88\u5e38\u89c1\uff0c\u5982 WHERE \u8bed\u53e5\u548c YIELD \u8bed\u53e5\u3002nGQL \u91c7\u7528\u5982\u4e0b\u65b9\u5f0f\u5b9a\u4e49\u5c5e\u6027\u5173\u8054\uff1a ::= <object> \".\" <object> ::= | | <var> ::= <label> ::= '[' \"]\" <var> \u4ee5 \"$\" \u5f00\u59cb\uff0c\u7279\u6b8a\u53d8\u91cf\u6709\u4e24\u7c7b\uff1a$- \u548c $$\u3002 $- \u4e3a\u8f93\u5165\u503c\uff0c $$ \u4e3a\u76ee\u6807\u503c\u3002 \u6240\u6709\u5c5e\u6027\u540d\u4ee5\u5b57\u6bcd\u5f00\u5934\u3002\u4e2a\u522b\u7cfb\u7edf\u5c5e\u6027\u4ee5 \"_\" \u5f00\u5934\u3002 \"_\" \u4fdd\u7559\u503c\u3002 \u5185\u5efa\u5c5e\u6027 \u00b6 _id\uff1a \u8282\u70b9 ID _type\uff1a \u8fb9\u7c7b\u578b _src\uff1a \u8fb9\u8d77\u59cb\u70b9 ID _dst\uff1a \u8fb9\u7ec8\u70b9 ID _rank\uff1a \u8fb9 ranking","title":"Nebula Graph \u67e5\u8be2\u8bed\u8a00 (nGQL)"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#nebula_graph_ngql","text":"","title":"Nebula Graph \u67e5\u8be2\u8bed\u8a00 (nGQL)"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#ngql","text":"nGQL \u662f\u4e00\u79cd\u58f0\u660e\u578b\u7684\u6587\u672c\u67e5\u8be2\u8bed\u8a00\uff0c\u76ee\u524d\u5c1a\u5728\u5f00\u53d1\u4e2d\u3002\u65b0\u7248\u672c\u4f1a\u6dfb\u52a0\u66f4\u591a\u529f\u80fd\u5e76\u4f18\u5316\u5df2\u6709\u529f\u80fd\u3002\u672a\u6765\u7684\u8bed\u6cd5\u89c4\u8303\u53ef\u80fd\u4f1a\u4e0e\u73b0\u884c\u7684\u4e0d\u4e00\u81f4\u3002","title":"nGQL \u6982\u89c8"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_1","text":"\u6613\u5b66 \u6613\u7528 \u4e13\u6ce8\u7ebf\u4e0a\u67e5\u8be2\uff0c\u540c\u65f6\u4e3a\u79bb\u7ebf\u8ba1\u7b97\u63d0\u4f9b\u57fa\u7840","title":"\u76ee\u6807"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_2","text":"\u7c7b SQL\uff0c\u6613\u5b66\u6613\u7528 \u53ef\u6269\u5c55 \u5927\u5c0f\u5199\u4e0d\u654f\u611f \u652f\u6301\u56fe\u904d\u5386 \u652f\u6301\u6a21\u5f0f\u5339\u914d \u652f\u6301\u805a\u5408\u8fd0\u7b97 \u652f\u6301\u56fe\u8ba1\u7b97 \u652f\u6301\u5206\u5e03\u5f0f\u4e8b\u52a1\uff08\u5f00\u53d1\u4e2d\uff09 \u65e0\u5d4c\u5165\u652f\u6301\u7ec4\u5408\u8bed\u53e5\uff0c\u6613\u4e8e\u9605\u8bfb","title":"\u7279\u70b9"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_3","text":"\u56fe\u7a7a\u95f4 \uff1a\u7269\u7406\u9694\u79bb\u7684\u4e0d\u540c\u6570\u636e\u96c6 \u6807\u7b7e \uff1a\u62e5\u6709\u4e00\u79cd\u6216\u591a\u79cd\u5c5e\u6027 \u6bcf\u4e2a\u6807\u7b7e\u90fd\u6709\u4e00\u4e2a\u4eba\u7c7b\u53ef\u8bfb\u7684\u540d\u79f0\uff0c\u5e76\u4e14\u6bcf\u4e2a\u6807\u7b7e\u5185\u90e8\u90fd\u4f1a\u5206\u914d\u4e00\u4e2a 32 \u4f4d\u7684\u6574\u6570 \u6bcf\u4e2a\u6807\u7b7e\u4e0e\u4e00\u4e2a\u5c5e\u6027\u5217\u8868\u76f8\u5173\u8054\uff0c\u6bcf\u4e2a\u5c5e\u6027\u90fd\u6709\u4e00\u4e2a\u540d\u79f0\u548c\u7c7b\u578b \u6807\u7b7e\u4e4b\u95f4\u53ef\u5b58\u5728\u4f9d\u8d56\u5173\u7cfb\u4f5c\u4e3a\u7ea6\u675f\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6807\u7b7e S \u4f9d\u8d56\u4e8e\u6807\u7b7e T\uff0c\u5219\u9664\u975e\u6807\u7b7e T \u5b58\u5728\uff0c\u5426\u5219\u6807\u7b7e S \u65e0\u6cd5\u5b58\u5728\u3002 \u8282\u70b9 \uff1a\u56fe\u6570\u636e\u4e2d\u4ee3\u8868\u5b9e\u4f53\u7684\u70b9 \u6bcf\u4e2a\u8282\u70b9\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u7684 64 \u4f4d\uff08\u6709\u7b26\u53f7\u6574\u6570\uff09ID ( VID ) \u4e00\u4e2a\u8282\u70b9\u53ef\u4ee5\u62e5\u6709\u591a\u4e2a \u6807\u7b7e \u8fb9 \uff1a\u8282\u70b9\u4e4b\u95f4\u7684\u8054\u7cfb\u79f0\u4e3a\u8fb9 \u6bcf\u6761\u8fb9\u7531\u552f\u4e00\u6570\u7ec4 \u6807\u8bc6 \u8fb9\u7c7b\u578b \u662f\u4eba\u7c7b\u53ef\u8bfb\u7684\u5b57\u7b26\u4e32\uff0c\u5e76\u4e14\u6bcf\u6761\u8fb9\u5185\u90e8\u90fd\u4f1a\u5206\u914d\u4e00\u4e2a 32 \u4f4d\u7684\u6574\u6570\u3002\u8fb9\u7c7b\u578b\u51b3\u5b9a\u8fb9\u4e0a\u7684\u5c5e\u6027\uff08\u6a21\u5f0f\uff09 \u8fb9 ranking \u662f\u7528\u6237\u5206\u914d\u7684\u4e0d\u53ef\u53d8\u7684 64 \u4f4d\u5e26\u7b26\u53f7\u6574\u6570\uff0c\u51b3\u5b9a\u4e24\u4e2a\u9876\u70b9\u4e4b\u95f4\u7684\u8fb9\u987a\u5e8f\u3002\u7b49\u7ea7\u503c\u8f83\u9ad8\u7684\u8fb9\u6392\u540d\u9760\u524d\u3002\u5982\u672a\u6307\u5b9a\uff0c\u5219\u9ed8\u8ba4\u7b49\u7ea7\u503c\u4e3a\u96f6\u3002 \u6bcf\u6761\u8fb9\u53ea\u80fd\u6709\u4e00\u79cd\u7c7b\u578b \u8def\u5f84 : \u591a\u4e2a\u8282\u70b9\u4e0e\u8fb9\u7684 \u975e\u5206\u652f \u8fde\u63a5 \u8def\u5f84\u957f\u5ea6\u4e3a\u8be5\u8def\u5f84\u4e0a\u7684\u8fb9\u6570\uff0c\u6bd4\u8282\u70b9\u6570\u5c11 1 \u8def\u5f84\u53ef\u7531\u4e00\u7cfb\u5217\u8282\u70b9\uff0c\u8fb9\u7c7b\u578b\u53ca\u6743\u91cd\u8868\u793a\u3002\u4e00\u6761\u8fb9\u662f\u4e00\u4e2a\u957f\u5ea6\u4e3a 1 \u7684\u7279\u6b8a\u8def\u5f84 <vid, <edge_type, rank>, vid, ...>","title":"\u672f\u8bed"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_4","text":"\u4e0d\u719f\u6089 BNF \u7684\u8bfb\u8005\u53ef\u8df3\u8fc7\u672c\u8282","title":"\u67e5\u8be2\u8bed\u8a00\u89c4\u5219\u6982\u89c8"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_5","text":"\u6574\u5957\u8bed\u53e5\u53ef\u5206\u4e3a\u4e09\u90e8\u5206\uff1a \u67e5\u8be2 \u3001 \u66f4\u6539 \u3001 \u7ba1\u7406 \u6bcf\u6761\u8bed\u53e5\u5747\u53ef\u8fd4\u56de\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u7b2c\u4e2a\u6570\u636e\u96c6\u5747\u5305\u542b\u4e00\u4e2a schema \u548c\u591a\u6761\u6570\u636e","title":"\u603b\u89c8"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_6","text":"\u8bed\u53e5\u7ec4\u5408\u6709\u4e24\u79cd\u65b9\u5f0f\uff1a \u8bed\u53e5\u53ef\u4f7f\u7528\u7ba1\u9053\u51fd\u6570 \" | \u8fde\u63a5\uff0c\u524d\u4e00\u6761\u8bed\u53e5\u8fd4\u56de\u7684\u7ed3\u679c\u53ef\u4f5c\u4e3a\u4e0b\u4e00\u6761\u8bed\u53e5\u7684\u67e5\u8be2\u6761\u4ef6 \u652f\u6301\u4f7f\u7528 \" ; \" \u6279\u91cf\u8f93\u5165\u591a\u6761\u8bed\u53e5\uff0c\u6279\u5904\u7406\u65f6\u8fd4\u56de\u6700\u540e\u4e00\u6761\u8bed\u53e5\u7ed3\u679c","title":"\u8bed\u53e5\u7ec4\u5408"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_7","text":"\u7b80\u5355\u7c7b\u578b\uff1a vid \u3001 double \u3001 int \u3001 bool \u3001 string \u548c timestamp vid \uff1a 64 \u4f4d\u6709\u7b26\u53f7\u6574\u6570\uff0c\u7528\u6765\u8868\u793a\u70b9 ID \u7b80\u5355\u7c7b\u578b\u5217\u8868\uff0c\u5982\uff1a integer[] , double[] , string[] Map : \u952e\u503c\u5bf9\u5217\u8868\u3002\u952e\u7c7b\u578b\u5fc5\u987b\u4e3a \u5b57\u7b26 \uff0c\u503c\u7c7b\u578b\u5fc5\u987b\u4e0e\u7ed9\u5b9a map Object (\u672a\u6765\u7248\u672c\u652f\u6301): \u952e\u503c\u5bf9\u5217\u8868\u3002\u952e\u7c7b\u578b\u5fc5\u987b\u4e3a \u5b57\u7b26 \uff0c\u503c\u53ef\u4ee5\u662f\u4efb\u610f\u7b80\u5355\u7c7b\u578b Tuple List : \u53ea\u9002\u7528\u4e8e\u8fd4\u56de\u503c \u3002\u7531\u5143\u6570\u636e\u548c\u6570\u636e\uff08\u591a\u884c\uff09\u7ec4\u6210 \u3002\u5143\u6570\u636e\u5305\u542b\u5217\u540d\u548c\u7c7b\u578b\u3002","title":"\u6570\u636e\u7c7b\u578b"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_8","text":"\u4e00\u4e2a\u7b80\u5355\u7684\u7c7b\u578b\u503c\u53ef\u4ee5\u9690\u5f0f\u8f6c\u6362\u4e3a\u5217\u8868 \u5217\u8868\u53ef\u4ee5\u9690\u5f0f\u8f6c\u6362\u4e3a\u5355\u5217\u5143\u7ec4\u5217\u8868 \"<type>_list\" \u53ef\u7528\u6765\u8868\u793a\u5217\u540d","title":"\u7c7b\u578b\u8f6c\u6362"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#bnf","text":"::= vid | integer | double | float | bool | string | path | timestamp | year | month | date | datetime ::= <type> ::= | ::= vid (, vid )* | \"{\" vid (, vid )* \"}\" <label> ::= [:alpha] ([:alnum:] | \"_\")* ::= (\"_\")* <label> ::= <label> ::= (, )* ::= :<type> ::= \":\" ::= ::= <tuple> (, <tuple>)* | \"{\" <tuple> (, <tuple>)* \"}\" <tuple> ::= \"(\" VALUE (, VALUE )* \")\" <var> ::= \"$\" <label>","title":"\u5e38\u7528 BNF"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_9","text":"","title":"\u67e5\u8be2\u8bed\u53e5"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_10","text":"Nebula Graph \u652f\u6301\u591a\u56fe\u7a7a\u95f4\u3002\u4e0d\u540c\u56fe\u7a7a\u95f4\u7684\u6570\u636e\u5f7c\u6b64\u9694\u79bb\u3002\u5728\u8fdb\u884c\u67e5\u8be2\u524d\uff0c\u9700\u6307\u5b9a\u56fe\u7a7a\u95f4\u3002 USE","title":"\u9009\u62e9\u56fe\u7a7a\u95f4"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_11","text":"\u8fd4\u56de\u5355\u4e2a\u503c\u6216\u6570\u636e\u96c6 RETURN ::= vid | | | <var>","title":"\u8fd4\u56de\u6570\u636e\u96c6"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_12","text":"\u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa \u65b0 \u6807\u7b7e CREATE TAG ( ) ::= <label> ::= + ::= ,<type> ::= <label>","title":"\u521b\u5efa\u6807\u7b7e"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_13","text":"\u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa \u65b0 \u7684\u8fb9\u7c7b\u578b CREATE EDGE ( ) := <label>","title":"\u521b\u5efa\u8fb9\u7c7b\u578b"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_14","text":"\u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u4e00\u4e2a\u6216\u591a\u4e2a\u8282\u70b9 INSERT VERTEX [ NO OVERWRITE ] VALUES ::= ( ) (, ( ))* ::= :( ) (, :( ))* ::= vid ::= (, )* ::= VALUE (, VALUE )*","title":"\u63d2\u5165\u8282\u70b9"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_15","text":"\u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u4e00\u6761\u6216\u591a\u6761\u8fb9 INSERT EDGE [ NO OVERWRITE ] [( )] VALUES ( )+ edge_value ::= -> [@ <weight>] :","title":"\u63d2\u5165\u8fb9"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_16","text":"\u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0\u8282\u70b9 UPDATE VERTEX SET \\<update_decl> [ WHERE <conditions>] [ YIELD ] ::= | ::= = <expression> {, = <expression>}+ ::= ( ) = ( ) | ( ) = <var>","title":"\u66f4\u65b0\u8282\u70b9"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_17","text":"\u4f7f\u7528\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0\u8fb9 UPDATE EDGE -> [@<weight>] OF SET [ WHERE <conditions>] [ YIELD ]","title":"\u66f4\u65b0\u8fb9"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_18","text":"\u6839\u636e\u6307\u5b9a\u6761\u4ef6\u904d\u5386\u7ed9\u5b9a\u8282\u70b9\u7684\u5173\u8054\u8282\u70b9\uff0c\u8fd4\u56de\u8282\u70b9 ID \u5217\u8868\u6216\u6570\u7ec4 GO [ STEPS ] FROM [ OVER [ REVERSELY ] ] [ WHERE ] [ YIELD ] ::= [data_set] [[ AS ] <label>] ::= vid | | | <var> ::= [ AS <label>] ::= {, }* ::= <label> ::= <filter> { AND | OR <filter>}* ::= \\ \\ **>**\\ | \\ **>= | < | <= | == | != <expression> | <expression> IN <value_list> ::= {, }* ::= <expression> [ AS** <label>] WHERE \u8bed\u53e5\u4ec5\u9002\u7528\u4e8e\u6700\u7ec8\u8fd4\u56de\u7ed3\u679c\uff0c\u5bf9\u4e2d\u95f4\u7ed3\u679c\u4e0d\u9002\u7528\u3002 \u8df3\u8fc7 STEP[S] \u8868\u793a \u4e00\u6b65 \u4ece\u8d77\u59cb\u70b9\u51fa\u53d1\u4e00\u8df3\uff0c\u904d\u5386\u6240\u6709\u6ee1\u8db3 WHERE \u8bed\u53e5\u7684\u5173\u8054\u70b9\uff0c\u53ea\u8fd4\u56de\u6ee1\u8db3 WHERE \u8bed\u53e5\u7684\u7ed3\u679c\u3002 \u591a\u8df3\u67e5\u8be2\u65f6\uff0c WHERE \u8bed\u53e5\u53ea\u9002\u7528\u4e8e\u6700\u7ec8\u7ed3\u679c\uff0c\u5bf9\u4e2d\u95f4\u7ed3\u679c\u4e0d\u9002\u7528\u3002\u4f8b\u5982\uff1a GO 2 STEPS FROM me OVER friend WHERE birthday > \"1988/1/1\" \u4ee5\u4e0a\u8bed\u53e5\u67e5\u8be2\u6240\u6709\u751f\u65e5\u5728 1988/1/1 \u4e4b\u540e\u7684\u4e8c\u5ea6\u597d\u53cb\u3002","title":"\u56fe\u904d\u5386"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_19","text":"\u4ee5\u4e0b\u8bed\u53e5\u5bf9\u6ee1\u8db3\u7b5b\u9009\u6761\u4ef6\u7684\u8282\u70b9\u6216\u8fb9\u8fdb\u884c\u641c\u7d22\u3002 FIND VERTEX WHERE [ YIELD ] FIND EDGE WHERE [ YIELD ]","title":"\u641c\u7d22"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_20","text":"\u5c5e\u6027\u5173\u8054\u5f88\u5e38\u89c1\uff0c\u5982 WHERE \u8bed\u53e5\u548c YIELD \u8bed\u53e5\u3002nGQL \u91c7\u7528\u5982\u4e0b\u65b9\u5f0f\u5b9a\u4e49\u5c5e\u6027\u5173\u8054\uff1a ::= <object> \".\" <object> ::= | | <var> ::= <label> ::= '[' \"]\" <var> \u4ee5 \"$\" \u5f00\u59cb\uff0c\u7279\u6b8a\u53d8\u91cf\u6709\u4e24\u7c7b\uff1a$- \u548c $$\u3002 $- \u4e3a\u8f93\u5165\u503c\uff0c $$ \u4e3a\u76ee\u6807\u503c\u3002 \u6240\u6709\u5c5e\u6027\u540d\u4ee5\u5b57\u6bcd\u5f00\u5934\u3002\u4e2a\u522b\u7cfb\u7edf\u5c5e\u6027\u4ee5 \"_\" \u5f00\u5934\u3002 \"_\" \u4fdd\u7559\u503c\u3002","title":"\u5c5e\u6027\u5173\u8054"},{"location":"manual-CN/1.overview/1.concepts/2.nGQL-overview/#_21","text":"_id\uff1a \u8282\u70b9 ID _type\uff1a \u8fb9\u7c7b\u578b _src\uff1a \u8fb9\u8d77\u59cb\u70b9 ID _dst\uff1a \u8fb9\u7ec8\u70b9 ID _rank\uff1a \u8fb9 ranking","title":"\u5185\u5efa\u5c5e\u6027"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/","text":"\u5feb\u901f\u5165\u95e8 \u00b6 \u672c\u624b\u518c\u5c06\u9010\u6b65\u6307\u5bfc\u60a8\u4f7f\u7528 Nebula Graph \u3002\u6211\u4eec\u5c06\u6307\u5bfc\u60a8\u5982\u4f55 \u521b\u5efa\u5e76\u4f7f\u7528\u56fe\u7a7a\u95f4 \uff0c \u5b9a\u4e49\u6570\u636e\u7684schema \uff0c \u63d2\u5165\u6570\u636e \uff0c \u83b7\u53d6\u6570\u636e \uff0c \u66f4\u65b0\u6570\u636e \u4ee5\u53ca \u5220\u9664\u6570\u636e \u3002\u6700\u540e\u6211\u4eec\u5c06\u6307\u5bfc\u60a8\u5982\u4f55\u901a\u8fc7 .ngql \u6587\u4ef6\u6765 \u6279\u91cf\u63d2\u5165 \u6570\u636e\u3002 \u524d\u63d0\u6761\u4ef6 \u00b6 \u5728\u4f7f\u7528 Nebula Graph \u524d\uff0c\u8bf7\u786e\u4fdd\u5df2\u5b89\u88c5 Nebula Graph \u3002\u60a8\u53ef\u4ee5\u9009\u62e9 \u7f16\u8bd1\u6e90\u7801 \uff0c rpm/deb \u5305 \u6216\u8005 docker compose \u65b9\u5f0f\u5b89\u88c5 Nebula Graph \u3002\u6b64\u5904\u5efa\u8bae\u4f7f\u7528 docker compose \u3002 \u6982\u8ff0 \u00b6 \u6211\u4eec\u5c06\u901a\u8fc7\u4e0b\u56fe\u4e2d\u4e0d\u540c\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u5411\u60a8\u5c55\u793a\u5982\u4f55\u4f7f\u7528 Nebula Graph \u6570\u636e\u5e93\u3002 \u4e0a\u56fe\u4e2d\u6709\u4e24\u4e2a\u6807\u7b7e\uff08 player \u3001 team \uff09\u4ee5\u53ca\u4e24\u6761\u8fb9\u7c7b\u578b\uff08 serve \u3001 follow \uff09\u3002 \u521b\u5efa\u5e76\u4f7f\u7528\u56fe\u7a7a\u95f4 \u00b6 Nebula Graph \u4e2d\u7684\u56fe\u7a7a\u95f4\u7c7b\u4f3c\u4e8e\u4f20\u7edf\u6570\u636e\u5e93\u4e2d\u521b\u5efa\u7684\u72ec\u7acb\u6570\u636e\u5e93\uff0c\u4f8b\u5982\u5728 MySQL \u4e2d\u521b\u5efa\u7684\u6570\u636e\u5e93\u3002\u9996\u5148\uff0c\u60a8\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u56fe\u7a7a\u95f4\u5e76\u4f7f\u7528\u5b83\uff0c\u7136\u540e\u624d\u80fd\u6267\u884c\u5176\u4ed6\u64cd\u4f5c\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u521b\u5efa\u5e76\u4f7f\u7528\u56fe\u7a7a\u95f4\uff1a \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa\u56fe\u7a7a\u95f4\uff1a nebula> CREATE SPACE nba(partition_num=10, replica_factor=1); \u6ce8\u610f \uff1a partition_num \uff1a\u6307\u5b9a\u4e00\u4e2a\u526f\u672c\u4e2d\u7684\u5206\u533a\u6570\u3002 replica_factor \uff1a\u6307\u5b9a\u96c6\u7fa4\u4e2d\u526f\u672c\u7684\u6570\u91cf\u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u4f7f\u7528\u56fe\u7a7a\u95f4\uff1a nebula> USE nba; \u73b0\u5728\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u8bed\u53e5\u67e5\u770b\u521a\u521b\u5efa\u7684\u7a7a\u95f4\uff1a nebula> SHOW SPACES; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ======== | Name | ======== | nba | -------- \u5b9a\u4e49\u6570\u636e\u7684 Schema \u00b6 \u5728 Nebula Graph \u4e2d\uff0c\u6211\u4eec\u5c06\u5177\u6709\u76f8\u540c\u5c5e\u6027\u7684\u70b9\u5206\u4e3a\u4e00\u7ec4\uff0c\u8be5\u7ec4\u5373\u4e3a\u4e00\u4e2a\u6807\u7b7e\u3002 CREATE TAG \u8bed\u53e5\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6807\u7b7e\uff0c\u6807\u7b7e\u540d\u79f0\u540e\u9762\u7684\u62ec\u53f7\u4e2d\u662f\u6807\u7b7e\u7684\u5c5e\u6027\u548c\u5c5e\u6027\u7c7b\u578b\u3002 CREATE EDGE \u8bed\u53e5\u5b9a\u4e49\u8fb9\u7c7b\u578b\uff0c\u7c7b\u578b\u540d\u79f0\u540e\u9762\u7684\u62ec\u53f7\u4e2d\u662f\u8fb9\u7684\u5c5e\u6027\u548c\u5c5e\u6027\u7c7b\u578b\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u521b\u5efa\u6807\u7b7e\u548c\u8fb9\u7c7b\u578b\uff1a \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa player \u6807\u7b7e\uff1a nebula> CREATE TAG player(name string, age int); \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa team \u6807\u7b7e\uff1a nebula> CREATE TAG team(name string); \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa follow \u8fb9\u7c7b\u578b\uff1a nebula> CREATE EDGE follow(degree int); \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa serve \u8fb9\u7c7b\u578b\uff1a nebula> CREATE EDGE serve(start_year int, end_year int); \u73b0\u5728\uff0c\u60a8\u53ef\u4ee5\u67e5\u770b\u521a\u521a\u521b\u5efa\u7684\u6807\u7b7e\u548c\u8fb9\u7c7b\u578b\u3002 \u8981\u83b7\u53d6\u521a\u521b\u5efa\u7684\u6807\u7b7e\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> SHOW TAGS; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ============ | Name | ============ | player | ------------ | team | ------------ \u8981\u663e\u793a\u521a\u521b\u5efa\u7684\u8fb9\u7c7b\u578b\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> SHOW EDGES; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ========== | Name | ========== | serve | ---------- | follow | ---------- \u8981\u663e\u793a player \u6807\u7b7e\u7684\u5c5e\u6027\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DESCRIBE TAG player; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a =================== | Field | Type | =================== | name | string | ------------------- | age | int | ------------------- \u8981\u83b7\u53d6 follow \u8fb9\u7c7b\u578b\u7684\u5c5e\u6027\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DESCRIBE EDGE follow; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ===================== | Field | Type | ===================== | degree | int | --------------------- \u63d2\u5165\u6570\u636e \u00b6 \u60a8\u53ef\u4ee5\u6839\u636e \u793a\u610f\u56fe \u4e2d\u7684\u5173\u7cfb\u63d2\u5165\u70b9\u548c\u8fb9\u6570\u636e\u3002 \u63d2\u5165\u70b9 \u00b6 INSERT VERTEX \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u70b9\u7684\u6807\u7b7e\u3001\u5c5e\u6027\u3001\u70b9 ID \u548c\u5c5e\u6027\u503c\u6765\u63d2\u5165\u4e00\u4e2a\u70b9\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u70b9\uff1a nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); nebula> INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); nebula> INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); nebula> INSERT VERTEX team(name) VALUES 200:(\"Warriors\"); nebula> INSERT VERTEX team(name) VALUES 201:(\"Nuggets\"); nebula> INSERT VERTEX player(name, age) VALUES 121:(\"Useless\", 60); \u6ce8\u610f \uff1a \u5728\u4e0a\u9762\u63d2\u5165\u7684\u70b9\u4e2d\uff0c\u5173\u952e\u8bcd VALUES \u4e4b\u540e\u7684\u6570\u5b57\u662f\u70b9\u7684 ID\uff08\u7f29\u5199\u4e3a VID \uff09\u3002\u56fe\u7a7a\u95f4\u4e2d\u7684 VID \u5fc5\u987b\u662f\u552f\u4e00\u7684\u3002 \u6700\u540e\u63d2\u5165\u7684\u70b9\u5c06\u5728 \u5220\u9664\u6570\u636e \u90e8\u5206\u4e2d\u5220\u9664\u3002 \u5982\u679c\u60a8\u60f3\u4e00\u6b21\u63d2\u5165\u591a\u4e2a\u540c\u7c7b\u578b\u7684\u70b9\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42), \\ 101:(\"Tony Parker\", 36), 102:(\"LaMarcus Aldridge\", 33); \u63d2\u5165\u8fb9 \u00b6 INSERT EDGE \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u8fb9\u7c7b\u578b\u540d\u79f0\u3001\u5c5e\u6027\u3001\u8d77\u59cb\u70b9ID\u548c\u76ee\u6807\u70b9ID\u4ee5\u53ca\u5c5e\u6027\u503c\u6765\u63d2\u5165\u8fb9\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u8fb9\uff1a nebula> INSERT EDGE follow(degree) VALUES 100 -> 101:(95); nebula> INSERT EDGE follow(degree) VALUES 100 -> 102:(90); nebula> INSERT EDGE follow(degree) VALUES 102 -> 101:(75); nebula> INSERT EDGE serve(start_year, end_year) VALUES 100 -> 200:(1997, 2016); nebula> INSERT EDGE serve(start_year, end_year) VALUES 101 -> 201:(1999, 2018); \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u60f3\u4e00\u6b21\u63d2\u5165\u591a\u6761\u540c\u7c7b\u578b\u7684\u8fb9\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u8bed\u53e5\uff1a INSERT EDGE follow(degree) VALUES 100 -> 101:(95),100 -> 102:(90),102 -> 101:(75); \u83b7\u53d6\u6570\u636e \u00b6 \u5728 Nebula Graph \u4e2d\u63d2\u5165\u6570\u636e\u540e\uff0c\u60a8\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u68c0\u7d22\u5230\u63d2\u5165\u7684\u6570\u636e\u3002 FETCH PROP ON \u8bed\u53e5\u4ece\u56fe\u7a7a\u95f4\u68c0\u7d22\u6570\u636e\u3002\u5982\u679c\u8981\u83b7\u53d6\u70b9\u6570\u636e\uff0c\u5219\u5fc5\u987b\u6307\u5b9a\u70b9\u6807\u7b7e\u548c\u70b9 ID\uff1b\u5982\u679c\u8981\u83b7\u53d6\u8fb9\u6570\u636e\uff0c\u5219\u5fc5\u987b\u6307\u5b9a\u8fb9\u7c7b\u578b\u540d\u79f0\u3001\u8d77\u59cb\u70b9 ID \u548c\u76ee\u6807\u70b9 ID\u3002 \u8981\u83b7\u53d6 VID \u4e3a 100 \u7684\u9009\u624b\u7684\u6570\u636e\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON player 100; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim Duncan | 42 | --------------------------------------- \u8981\u83b7\u53d6 VID 100 \u548c VID 200 \u4e4b\u95f4\u7684 serve \u8fb9\u7684\u6570\u636e\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON serve 100 -> 200; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ============================================================================= | serve._src | serve._dst | serve._rank | serve.start_year | serve.end_year | ============================================================================= | 100 | 200 | 0 | 1997 | 2016 | ----------------------------------------------------------------------------- \u66f4\u65b0\u6570\u636e \u00b6 \u60a8\u53ef\u4ee5\u66f4\u65b0\u521a\u63d2\u5165\u7684\u70b9\u548c\u8fb9\u6570\u636e\u3002 \u66f4\u65b0\u70b9\u6570\u636e \u00b6 UPDATE VERTEX \u8bed\u53e5\u9996\u5148\u9009\u62e9\u8981\u66f4\u65b0\u7684\u70b9\uff0c\u7136\u540e\u901a\u8fc7\u5728\u7b49\u53f7\u53f3\u4fa7\u4e3a\u5176\u5206\u914d\u65b0\u503c\u6765\u66f4\u65b0\u70b9\u7684\u6570\u636e\u3002 \u4ee5\u4e0b\u793a\u4f8b\u8bf4\u660e\u5982\u4f55\u5c06 VID 100 \u7684 name \u503c\u4ece Tim Duncan \u66f4\u6539\u4e3a Tim \u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0 name \u503c\uff1a nebula> UPDATE VERTEX 100 SET player.name = \"Tim\"; \u8981\u68c0\u67e5 name \u503c\u662f\u5426\u5df2\u66f4\u65b0\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON player 100; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim | 42 | --------------------------------------- \u66f4\u65b0\u8fb9\u6570\u636e \u00b6 UPDATE EDGE \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u8fb9\u7684\u8d77\u59cb\u70b9ID\u548c\u76ee\u6807\u70b9ID\uff0c\u7136\u540e\u5728\u7b49\u53f7\u53f3\u4fa7\u4e3a\u5176\u5206\u914d\u65b0\u503c\u6765\u66f4\u65b0\u8fb9\u7684\u6570\u636e\u3002 \u4ee5\u4e0b\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u66f4\u6539 VID 100 \u548c VID 101 \u4e4b\u95f4 follow \u8fb9\u7684\u503c\u3002\u73b0\u5728\uff0c\u6211\u4eec\u5c06 degree \u7684\u503c\u4ece 95 \u66f4\u6539\u4e3a 96 \u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0 degree \u7684\u503c\uff1a nebula> UPDATE EDGE 100 -> 101 OF follow SET degree = follow.degree + 1; \u8981\u68c0\u67e5 degree \u7684\u503c\u662f\u5426\u5df2\u66f4\u65b0\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON follow 100 -> 101; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ============================================================ | follow._src | follow._dst | follow._rank | follow.degree | ============================================================ | 100 | 101 | 0 | 96 | ------------------------------------------------------------ \u5220\u9664\u6570\u636e \u00b6 \u5982\u679c\u60a8\u6709\u4e0d\u9700\u8981\u7684\u70b9\u6216\u8fb9\u6570\u636e\uff0c\u5219\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u5c06\u5176\u5220\u9664\u3002 \u5220\u9664\u70b9 \u00b6 \u60a8\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u5220\u9664\u4efb\u4f55\u70b9\u3002 DELETE VERTEX \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u70b9ID\u6765\u5220\u9664\u70b9\u3002 \u8981\u5220\u9664 VID \u4e3a 121 \u7684\u70b9\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DELETE VERTEX 121; \u8981\u68c0\u67e5\u662f\u5426\u5220\u9664\u4e86\u8be5\u70b9\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1b nebula> FETCH PROP ON player 121; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a Execution succeeded (Time spent: 1571/1910 us) \u6ce8\u610f \uff1a\u4e0a\u9762\u8fd4\u56de\u7ed3\u679c\u4e3a\u7a7a\u7684\u4fe1\u606f\u8868\u793a\u67e5\u8be2\u64cd\u4f5c\u6210\u529f\uff0c\u4f46\u662f\u7531\u4e8e\u6570\u636e\u5df2\u88ab\u5220\u9664\uff0c\u56e0\u6b64\u672a\u80fd\u4ece\u56fe\u7a7a\u95f4\u4e2d\u67e5\u8be2\u5230\u4efb\u4f55\u6570\u636e\u3002 \u5220\u9664\u8fb9 \u00b6 \u60a8\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u5220\u9664\u4efb\u4f55\u8fb9\u3002 DELETE EDGE \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u8fb9\u7c7b\u578b\u540d\u79f0\u4ee5\u53ca\u8d77\u59cb\u70b9ID\u548c\u76ee\u6807\u70b9ID\u6765\u5220\u9664\u8fb9\u3002 \u8981\u5220\u9664 VID 100 \u548c VID 200 \u4e4b\u95f4\u7684 follow \u8fb9\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DELETE EDGE follow 100 -> 200; \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u5220\u9664\u4e86\u4e00\u4e2a\u70b9\uff0c\u5219\u8be5\u70b9\u6240\u6709\u7684\u5165\u8fb9\u548c\u51fa\u8fb9\u90fd\u5c06\u88ab\u5220\u9664\u3002 \u67e5\u8be2\u793a\u4f8b \u00b6 \u672c\u8282\u63d0\u4f9b\u4e86\u66f4\u591a\u67e5\u8be2\u793a\u4f8b\u4f9b\u60a8\u53c2\u8003\u3002 \u793a\u4f8b\u4e00 : \u67e5\u8be2 VID 100 \u5173\u6ce8\u7684\u70b9\u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> GO FROM 100 OVER follow; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a =============== | follow._dst | =============== | 101 | --------------- | 102 | --------------- \u793a\u4f8b\u4e8c : \u67e5\u8be2 VID 100 \u5173\u6ce8\u7684\u70b9\u4e14\u8be5\u70b9\u5e74\u9f84\u5927\u4e8e 35 \u5c81\u3002 \u8fd4\u56de\u5176\u59d3\u540d\u548c\u5e74\u9f84\u5e76\u5206\u522b\u628a\u5217\u7684\u540d\u79f0\u8bbe\u7f6e\u4e3a Teammate \u548c Age \u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> GO FROM 100 OVER follow WHERE $$.player.age >= 35 \\ YIELD $$.player.name AS Teammate, $$.player.age AS Age; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ===================== | Teammate | Age | ===================== | Tony Parker | 36 | --------------------- \u6ce8\u610f \uff1a YIELD \u6307\u5b9a\u60a8\u5e0c\u671b\u4ece\u67e5\u8be2\u4e2d\u8fd4\u56de\u7684\u503c\u6216\u7ed3\u679c\u3002 $$ \u8868\u793a\u76ee\u7684\u70b9\u3002 \\ \u8868\u793a\u6362\u884c\u7b26\u3002 \u793a\u4f8b\u4e09 : \u67e5\u8be2\u7403\u5458 100 \u5173\u6ce8\u7684\u7403\u5458\u6240\u6548\u529b\u7684\u7403\u961f\u3002 \u6709\u4e24\u79cd\u65b9\u6cd5\u53ef\u83b7\u5f97\u76f8\u540c\u7684\u7ed3\u679c\u3002\u9996\u5148\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \u7ba1\u9053 \u6765\u68c0\u7d22\u7403\u961f\u3002\u7136\u540e\uff0c\u6211\u4eec\u4f7f\u7528 \u4e34\u65f6\u53d8\u91cf \u6765\u68c0\u7d22\u540c\u4e00\u652f\u7403\u961f\u3002 \u8f93\u5165\u5e26 \u7ba1\u9053 \u7684\u8bed\u53e5\uff1a nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; \u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\uff1a =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- \u8f93\u5165\u5e26 \u4e34\u65f6\u53d8\u91cf \u7684\u8bed\u53e5\uff1a nebula> $var=GO FROM 100 OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- \u6ce8\u610f \uff1a $^ \u8868\u793a\u8d77\u59cb\u70b9\u3002 | \u8868\u793a\u7ba1\u9053\u3002\u4e0a\u4e00\u4e2a\u67e5\u8be2\u7684\u8f93\u51fa\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u67e5\u8be2\u7684\u8f93\u5165\u3002 $- \u8868\u793a\u8f93\u5165\u6d41\u3002 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u91c7\u7528\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u53d8\u91cf $var \u3002\u8be5\u53d8\u91cf\u7684\u8303\u56f4\u4ec5\u5728\u590d\u5408\u8bed\u53e5\u5185\u3002 \u6279\u91cf\u63d2\u5165 \u00b6 \u8981\u63d2\u5165\u591a\u6761\u6570\u636e\uff0c\u53ef\u4ee5\u5c06\u6240\u6709 DDL\uff08\u6570\u636e\u5b9a\u4e49\u8bed\u8a00\uff09\u8bed\u53e5\u653e\u5165 .ngql \u6587\u4ef6\u4e2d\uff0c\u5982\u4e0b\u6240\u793a\u3002 CREATE SPACE nba(partition_num=10, replica_factor=1); USE nba; CREATE TAG player(name string, age int); CREATE TAG team(name string); CREATE EDGE follow(degree int); CREATE EDGE serve(start_year int, end_year int); \u5982\u679c\u60a8\u662f\u901a\u8fc7\u7f16\u8bd1\u6e90\u4ee3\u7801\u6765\u5b89\u88c5 Nebula Graph \uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6279\u91cf\u5199\u5165console\uff1a $ cat schema.ngql | ./bin/nebula -u user -p password \u5982\u679c\u60a8\u901a\u8fc7 docker-compose \u6765\u4f7f\u7528 Nebula Graph \uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6279\u91cf\u5199\u5165console\uff1a $ cat nba.ngql | sudo docker run --rm -i --network = host \\ vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 \u6ce8\u610f \uff1a \u60a8\u5fc5\u987b\u5c06 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u3002 \u60a8\u53ef\u4ee5\u5728 \u8fd9\u91cc \u4e0b\u8f7d nba.ngql \u6587\u4ef6\u3002 \u540c\u6837\uff0c\u60a8\u53ef\u4ee5\u5728 data.ngql \u6587\u4ef6\u4e2d\u653e\u7f6e\u6570\u767e\u6216\u6570\u5343\u4e2a DML\uff08\u6570\u636e\u64cd\u4f5c\u8bed\u8a00\uff09\u8bed\u53e5\u6765\u63d2\u5165\u6570\u636e\u3002\u5982\u679c\u60a8\u8981\u63d2\u5165\u6570\u767e\u4e07\u6761\u8bb0\u5f55\uff0c\u5efa\u8bae\u4f7f\u7528 csv \u5bfc\u5165\u5de5\u5177 \uff08\u6216 sst \u63d0\u53d6\u5de5\u5177 \uff09\u3002 \u83b7\u5f97\u5e2e\u52a9 \u00b6 \u6b22\u8fce\u4f7f\u7528\u6211\u4eec\u7684 \u5b98\u65b9\u8bba\u575b \u8fdb\u884c\u63d0\u95ee\u6216\u8ba8\u8bba\u95ee\u9898\u3002 \u8bf7\u5728 GitHub Issues \u4e0a\u63d0 bug \u6216 feature\u3002 \u6b22\u8fce\u5173\u6ce8\u6211\u4eec\u7684 Stack Overflow \u3002","title":"\u5feb\u901f\u5165\u95e8"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_1","text":"\u672c\u624b\u518c\u5c06\u9010\u6b65\u6307\u5bfc\u60a8\u4f7f\u7528 Nebula Graph \u3002\u6211\u4eec\u5c06\u6307\u5bfc\u60a8\u5982\u4f55 \u521b\u5efa\u5e76\u4f7f\u7528\u56fe\u7a7a\u95f4 \uff0c \u5b9a\u4e49\u6570\u636e\u7684schema \uff0c \u63d2\u5165\u6570\u636e \uff0c \u83b7\u53d6\u6570\u636e \uff0c \u66f4\u65b0\u6570\u636e \u4ee5\u53ca \u5220\u9664\u6570\u636e \u3002\u6700\u540e\u6211\u4eec\u5c06\u6307\u5bfc\u60a8\u5982\u4f55\u901a\u8fc7 .ngql \u6587\u4ef6\u6765 \u6279\u91cf\u63d2\u5165 \u6570\u636e\u3002","title":"\u5feb\u901f\u5165\u95e8"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_2","text":"\u5728\u4f7f\u7528 Nebula Graph \u524d\uff0c\u8bf7\u786e\u4fdd\u5df2\u5b89\u88c5 Nebula Graph \u3002\u60a8\u53ef\u4ee5\u9009\u62e9 \u7f16\u8bd1\u6e90\u7801 \uff0c rpm/deb \u5305 \u6216\u8005 docker compose \u65b9\u5f0f\u5b89\u88c5 Nebula Graph \u3002\u6b64\u5904\u5efa\u8bae\u4f7f\u7528 docker compose \u3002","title":"\u524d\u63d0\u6761\u4ef6"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_3","text":"\u6211\u4eec\u5c06\u901a\u8fc7\u4e0b\u56fe\u4e2d\u4e0d\u540c\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\u5411\u60a8\u5c55\u793a\u5982\u4f55\u4f7f\u7528 Nebula Graph \u6570\u636e\u5e93\u3002 \u4e0a\u56fe\u4e2d\u6709\u4e24\u4e2a\u6807\u7b7e\uff08 player \u3001 team \uff09\u4ee5\u53ca\u4e24\u6761\u8fb9\u7c7b\u578b\uff08 serve \u3001 follow \uff09\u3002","title":"\u6982\u8ff0"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_4","text":"Nebula Graph \u4e2d\u7684\u56fe\u7a7a\u95f4\u7c7b\u4f3c\u4e8e\u4f20\u7edf\u6570\u636e\u5e93\u4e2d\u521b\u5efa\u7684\u72ec\u7acb\u6570\u636e\u5e93\uff0c\u4f8b\u5982\u5728 MySQL \u4e2d\u521b\u5efa\u7684\u6570\u636e\u5e93\u3002\u9996\u5148\uff0c\u60a8\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u56fe\u7a7a\u95f4\u5e76\u4f7f\u7528\u5b83\uff0c\u7136\u540e\u624d\u80fd\u6267\u884c\u5176\u4ed6\u64cd\u4f5c\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u521b\u5efa\u5e76\u4f7f\u7528\u56fe\u7a7a\u95f4\uff1a \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa\u56fe\u7a7a\u95f4\uff1a nebula> CREATE SPACE nba(partition_num=10, replica_factor=1); \u6ce8\u610f \uff1a partition_num \uff1a\u6307\u5b9a\u4e00\u4e2a\u526f\u672c\u4e2d\u7684\u5206\u533a\u6570\u3002 replica_factor \uff1a\u6307\u5b9a\u96c6\u7fa4\u4e2d\u526f\u672c\u7684\u6570\u91cf\u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u4f7f\u7528\u56fe\u7a7a\u95f4\uff1a nebula> USE nba; \u73b0\u5728\uff0c\u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u8bed\u53e5\u67e5\u770b\u521a\u521b\u5efa\u7684\u7a7a\u95f4\uff1a nebula> SHOW SPACES; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ======== | Name | ======== | nba | --------","title":"\u521b\u5efa\u5e76\u4f7f\u7528\u56fe\u7a7a\u95f4"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#schema","text":"\u5728 Nebula Graph \u4e2d\uff0c\u6211\u4eec\u5c06\u5177\u6709\u76f8\u540c\u5c5e\u6027\u7684\u70b9\u5206\u4e3a\u4e00\u7ec4\uff0c\u8be5\u7ec4\u5373\u4e3a\u4e00\u4e2a\u6807\u7b7e\u3002 CREATE TAG \u8bed\u53e5\u5b9a\u4e49\u4e86\u4e00\u4e2a\u6807\u7b7e\uff0c\u6807\u7b7e\u540d\u79f0\u540e\u9762\u7684\u62ec\u53f7\u4e2d\u662f\u6807\u7b7e\u7684\u5c5e\u6027\u548c\u5c5e\u6027\u7c7b\u578b\u3002 CREATE EDGE \u8bed\u53e5\u5b9a\u4e49\u8fb9\u7c7b\u578b\uff0c\u7c7b\u578b\u540d\u79f0\u540e\u9762\u7684\u62ec\u53f7\u4e2d\u662f\u8fb9\u7684\u5c5e\u6027\u548c\u5c5e\u6027\u7c7b\u578b\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u521b\u5efa\u6807\u7b7e\u548c\u8fb9\u7c7b\u578b\uff1a \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa player \u6807\u7b7e\uff1a nebula> CREATE TAG player(name string, age int); \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa team \u6807\u7b7e\uff1a nebula> CREATE TAG team(name string); \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa follow \u8fb9\u7c7b\u578b\uff1a nebula> CREATE EDGE follow(degree int); \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u521b\u5efa serve \u8fb9\u7c7b\u578b\uff1a nebula> CREATE EDGE serve(start_year int, end_year int); \u73b0\u5728\uff0c\u60a8\u53ef\u4ee5\u67e5\u770b\u521a\u521a\u521b\u5efa\u7684\u6807\u7b7e\u548c\u8fb9\u7c7b\u578b\u3002 \u8981\u83b7\u53d6\u521a\u521b\u5efa\u7684\u6807\u7b7e\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> SHOW TAGS; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ============ | Name | ============ | player | ------------ | team | ------------ \u8981\u663e\u793a\u521a\u521b\u5efa\u7684\u8fb9\u7c7b\u578b\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> SHOW EDGES; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ========== | Name | ========== | serve | ---------- | follow | ---------- \u8981\u663e\u793a player \u6807\u7b7e\u7684\u5c5e\u6027\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DESCRIBE TAG player; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a =================== | Field | Type | =================== | name | string | ------------------- | age | int | ------------------- \u8981\u83b7\u53d6 follow \u8fb9\u7c7b\u578b\u7684\u5c5e\u6027\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DESCRIBE EDGE follow; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ===================== | Field | Type | ===================== | degree | int | ---------------------","title":"\u5b9a\u4e49\u6570\u636e\u7684 Schema"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_5","text":"\u60a8\u53ef\u4ee5\u6839\u636e \u793a\u610f\u56fe \u4e2d\u7684\u5173\u7cfb\u63d2\u5165\u70b9\u548c\u8fb9\u6570\u636e\u3002","title":"\u63d2\u5165\u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_6","text":"INSERT VERTEX \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u70b9\u7684\u6807\u7b7e\u3001\u5c5e\u6027\u3001\u70b9 ID \u548c\u5c5e\u6027\u503c\u6765\u63d2\u5165\u4e00\u4e2a\u70b9\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u70b9\uff1a nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); nebula> INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); nebula> INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); nebula> INSERT VERTEX team(name) VALUES 200:(\"Warriors\"); nebula> INSERT VERTEX team(name) VALUES 201:(\"Nuggets\"); nebula> INSERT VERTEX player(name, age) VALUES 121:(\"Useless\", 60); \u6ce8\u610f \uff1a \u5728\u4e0a\u9762\u63d2\u5165\u7684\u70b9\u4e2d\uff0c\u5173\u952e\u8bcd VALUES \u4e4b\u540e\u7684\u6570\u5b57\u662f\u70b9\u7684 ID\uff08\u7f29\u5199\u4e3a VID \uff09\u3002\u56fe\u7a7a\u95f4\u4e2d\u7684 VID \u5fc5\u987b\u662f\u552f\u4e00\u7684\u3002 \u6700\u540e\u63d2\u5165\u7684\u70b9\u5c06\u5728 \u5220\u9664\u6570\u636e \u90e8\u5206\u4e2d\u5220\u9664\u3002 \u5982\u679c\u60a8\u60f3\u4e00\u6b21\u63d2\u5165\u591a\u4e2a\u540c\u7c7b\u578b\u7684\u70b9\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42), \\ 101:(\"Tony Parker\", 36), 102:(\"LaMarcus Aldridge\", 33);","title":"\u63d2\u5165\u70b9"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_7","text":"INSERT EDGE \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u8fb9\u7c7b\u578b\u540d\u79f0\u3001\u5c5e\u6027\u3001\u8d77\u59cb\u70b9ID\u548c\u76ee\u6807\u70b9ID\u4ee5\u53ca\u5c5e\u6027\u503c\u6765\u63d2\u5165\u8fb9\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u8bed\u53e5\u63d2\u5165\u8fb9\uff1a nebula> INSERT EDGE follow(degree) VALUES 100 -> 101:(95); nebula> INSERT EDGE follow(degree) VALUES 100 -> 102:(90); nebula> INSERT EDGE follow(degree) VALUES 102 -> 101:(75); nebula> INSERT EDGE serve(start_year, end_year) VALUES 100 -> 200:(1997, 2016); nebula> INSERT EDGE serve(start_year, end_year) VALUES 101 -> 201:(1999, 2018); \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u60f3\u4e00\u6b21\u63d2\u5165\u591a\u6761\u540c\u7c7b\u578b\u7684\u8fb9\uff0c\u53ef\u4ee5\u6267\u884c\u4ee5\u4e0b\u8bed\u53e5\uff1a INSERT EDGE follow(degree) VALUES 100 -> 101:(95),100 -> 102:(90),102 -> 101:(75);","title":"\u63d2\u5165\u8fb9"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_8","text":"\u5728 Nebula Graph \u4e2d\u63d2\u5165\u6570\u636e\u540e\uff0c\u60a8\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u68c0\u7d22\u5230\u63d2\u5165\u7684\u6570\u636e\u3002 FETCH PROP ON \u8bed\u53e5\u4ece\u56fe\u7a7a\u95f4\u68c0\u7d22\u6570\u636e\u3002\u5982\u679c\u8981\u83b7\u53d6\u70b9\u6570\u636e\uff0c\u5219\u5fc5\u987b\u6307\u5b9a\u70b9\u6807\u7b7e\u548c\u70b9 ID\uff1b\u5982\u679c\u8981\u83b7\u53d6\u8fb9\u6570\u636e\uff0c\u5219\u5fc5\u987b\u6307\u5b9a\u8fb9\u7c7b\u578b\u540d\u79f0\u3001\u8d77\u59cb\u70b9 ID \u548c\u76ee\u6807\u70b9 ID\u3002 \u8981\u83b7\u53d6 VID \u4e3a 100 \u7684\u9009\u624b\u7684\u6570\u636e\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON player 100; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim Duncan | 42 | --------------------------------------- \u8981\u83b7\u53d6 VID 100 \u548c VID 200 \u4e4b\u95f4\u7684 serve \u8fb9\u7684\u6570\u636e\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON serve 100 -> 200; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ============================================================================= | serve._src | serve._dst | serve._rank | serve.start_year | serve.end_year | ============================================================================= | 100 | 200 | 0 | 1997 | 2016 | -----------------------------------------------------------------------------","title":"\u83b7\u53d6\u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_9","text":"\u60a8\u53ef\u4ee5\u66f4\u65b0\u521a\u63d2\u5165\u7684\u70b9\u548c\u8fb9\u6570\u636e\u3002","title":"\u66f4\u65b0\u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_10","text":"UPDATE VERTEX \u8bed\u53e5\u9996\u5148\u9009\u62e9\u8981\u66f4\u65b0\u7684\u70b9\uff0c\u7136\u540e\u901a\u8fc7\u5728\u7b49\u53f7\u53f3\u4fa7\u4e3a\u5176\u5206\u914d\u65b0\u503c\u6765\u66f4\u65b0\u70b9\u7684\u6570\u636e\u3002 \u4ee5\u4e0b\u793a\u4f8b\u8bf4\u660e\u5982\u4f55\u5c06 VID 100 \u7684 name \u503c\u4ece Tim Duncan \u66f4\u6539\u4e3a Tim \u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0 name \u503c\uff1a nebula> UPDATE VERTEX 100 SET player.name = \"Tim\"; \u8981\u68c0\u67e5 name \u503c\u662f\u5426\u5df2\u66f4\u65b0\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON player 100; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim | 42 | ---------------------------------------","title":"\u66f4\u65b0\u70b9\u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_11","text":"UPDATE EDGE \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u8fb9\u7684\u8d77\u59cb\u70b9ID\u548c\u76ee\u6807\u70b9ID\uff0c\u7136\u540e\u5728\u7b49\u53f7\u53f3\u4fa7\u4e3a\u5176\u5206\u914d\u65b0\u503c\u6765\u66f4\u65b0\u8fb9\u7684\u6570\u636e\u3002 \u4ee5\u4e0b\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u66f4\u6539 VID 100 \u548c VID 101 \u4e4b\u95f4 follow \u8fb9\u7684\u503c\u3002\u73b0\u5728\uff0c\u6211\u4eec\u5c06 degree \u7684\u503c\u4ece 95 \u66f4\u6539\u4e3a 96 \u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\u66f4\u65b0 degree \u7684\u503c\uff1a nebula> UPDATE EDGE 100 -> 101 OF follow SET degree = follow.degree + 1; \u8981\u68c0\u67e5 degree \u7684\u503c\u662f\u5426\u5df2\u66f4\u65b0\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> FETCH PROP ON follow 100 -> 101; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ============================================================ | follow._src | follow._dst | follow._rank | follow.degree | ============================================================ | 100 | 101 | 0 | 96 | ------------------------------------------------------------","title":"\u66f4\u65b0\u8fb9\u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_12","text":"\u5982\u679c\u60a8\u6709\u4e0d\u9700\u8981\u7684\u70b9\u6216\u8fb9\u6570\u636e\uff0c\u5219\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u5c06\u5176\u5220\u9664\u3002","title":"\u5220\u9664\u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_13","text":"\u60a8\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u5220\u9664\u4efb\u4f55\u70b9\u3002 DELETE VERTEX \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u70b9ID\u6765\u5220\u9664\u70b9\u3002 \u8981\u5220\u9664 VID \u4e3a 121 \u7684\u70b9\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DELETE VERTEX 121; \u8981\u68c0\u67e5\u662f\u5426\u5220\u9664\u4e86\u8be5\u70b9\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1b nebula> FETCH PROP ON player 121; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a Execution succeeded (Time spent: 1571/1910 us) \u6ce8\u610f \uff1a\u4e0a\u9762\u8fd4\u56de\u7ed3\u679c\u4e3a\u7a7a\u7684\u4fe1\u606f\u8868\u793a\u67e5\u8be2\u64cd\u4f5c\u6210\u529f\uff0c\u4f46\u662f\u7531\u4e8e\u6570\u636e\u5df2\u88ab\u5220\u9664\uff0c\u56e0\u6b64\u672a\u80fd\u4ece\u56fe\u7a7a\u95f4\u4e2d\u67e5\u8be2\u5230\u4efb\u4f55\u6570\u636e\u3002","title":"\u5220\u9664\u70b9"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_14","text":"\u60a8\u53ef\u4ee5\u4ece\u56fe\u7a7a\u95f4\u4e2d\u5220\u9664\u4efb\u4f55\u8fb9\u3002 DELETE EDGE \u8bed\u53e5\u901a\u8fc7\u6307\u5b9a\u8fb9\u7c7b\u578b\u540d\u79f0\u4ee5\u53ca\u8d77\u59cb\u70b9ID\u548c\u76ee\u6807\u70b9ID\u6765\u5220\u9664\u8fb9\u3002 \u8981\u5220\u9664 VID 100 \u548c VID 200 \u4e4b\u95f4\u7684 follow \u8fb9\uff0c\u8bf7\u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> DELETE EDGE follow 100 -> 200; \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u5220\u9664\u4e86\u4e00\u4e2a\u70b9\uff0c\u5219\u8be5\u70b9\u6240\u6709\u7684\u5165\u8fb9\u548c\u51fa\u8fb9\u90fd\u5c06\u88ab\u5220\u9664\u3002","title":"\u5220\u9664\u8fb9"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_15","text":"\u672c\u8282\u63d0\u4f9b\u4e86\u66f4\u591a\u67e5\u8be2\u793a\u4f8b\u4f9b\u60a8\u53c2\u8003\u3002 \u793a\u4f8b\u4e00 : \u67e5\u8be2 VID 100 \u5173\u6ce8\u7684\u70b9\u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> GO FROM 100 OVER follow; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a =============== | follow._dst | =============== | 101 | --------------- | 102 | --------------- \u793a\u4f8b\u4e8c : \u67e5\u8be2 VID 100 \u5173\u6ce8\u7684\u70b9\u4e14\u8be5\u70b9\u5e74\u9f84\u5927\u4e8e 35 \u5c81\u3002 \u8fd4\u56de\u5176\u59d3\u540d\u548c\u5e74\u9f84\u5e76\u5206\u522b\u628a\u5217\u7684\u540d\u79f0\u8bbe\u7f6e\u4e3a Teammate \u548c Age \u3002 \u8f93\u5165\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> GO FROM 100 OVER follow WHERE $$.player.age >= 35 \\ YIELD $$.player.name AS Teammate, $$.player.age AS Age; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a ===================== | Teammate | Age | ===================== | Tony Parker | 36 | --------------------- \u6ce8\u610f \uff1a YIELD \u6307\u5b9a\u60a8\u5e0c\u671b\u4ece\u67e5\u8be2\u4e2d\u8fd4\u56de\u7684\u503c\u6216\u7ed3\u679c\u3002 $$ \u8868\u793a\u76ee\u7684\u70b9\u3002 \\ \u8868\u793a\u6362\u884c\u7b26\u3002 \u793a\u4f8b\u4e09 : \u67e5\u8be2\u7403\u5458 100 \u5173\u6ce8\u7684\u7403\u5458\u6240\u6548\u529b\u7684\u7403\u961f\u3002 \u6709\u4e24\u79cd\u65b9\u6cd5\u53ef\u83b7\u5f97\u76f8\u540c\u7684\u7ed3\u679c\u3002\u9996\u5148\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \u7ba1\u9053 \u6765\u68c0\u7d22\u7403\u961f\u3002\u7136\u540e\uff0c\u6211\u4eec\u4f7f\u7528 \u4e34\u65f6\u53d8\u91cf \u6765\u68c0\u7d22\u540c\u4e00\u652f\u7403\u961f\u3002 \u8f93\u5165\u5e26 \u7ba1\u9053 \u7684\u8bed\u53e5\uff1a nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; \u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\uff1a =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- \u8f93\u5165\u5e26 \u4e34\u65f6\u53d8\u91cf \u7684\u8bed\u53e5\uff1a nebula> $var=GO FROM 100 OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; \u8fd4\u56de\u4ee5\u4e0b\u4fe1\u606f\uff1a =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- \u6ce8\u610f \uff1a $^ \u8868\u793a\u8d77\u59cb\u70b9\u3002 | \u8868\u793a\u7ba1\u9053\u3002\u4e0a\u4e00\u4e2a\u67e5\u8be2\u7684\u8f93\u51fa\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u67e5\u8be2\u7684\u8f93\u5165\u3002 $- \u8868\u793a\u8f93\u5165\u6d41\u3002 \u7b2c\u4e8c\u79cd\u65b9\u6cd5\u91c7\u7528\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u53d8\u91cf $var \u3002\u8be5\u53d8\u91cf\u7684\u8303\u56f4\u4ec5\u5728\u590d\u5408\u8bed\u53e5\u5185\u3002","title":"\u67e5\u8be2\u793a\u4f8b"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_16","text":"\u8981\u63d2\u5165\u591a\u6761\u6570\u636e\uff0c\u53ef\u4ee5\u5c06\u6240\u6709 DDL\uff08\u6570\u636e\u5b9a\u4e49\u8bed\u8a00\uff09\u8bed\u53e5\u653e\u5165 .ngql \u6587\u4ef6\u4e2d\uff0c\u5982\u4e0b\u6240\u793a\u3002 CREATE SPACE nba(partition_num=10, replica_factor=1); USE nba; CREATE TAG player(name string, age int); CREATE TAG team(name string); CREATE EDGE follow(degree int); CREATE EDGE serve(start_year int, end_year int); \u5982\u679c\u60a8\u662f\u901a\u8fc7\u7f16\u8bd1\u6e90\u4ee3\u7801\u6765\u5b89\u88c5 Nebula Graph \uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6279\u91cf\u5199\u5165console\uff1a $ cat schema.ngql | ./bin/nebula -u user -p password \u5982\u679c\u60a8\u901a\u8fc7 docker-compose \u6765\u4f7f\u7528 Nebula Graph \uff0c\u5219\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6279\u91cf\u5199\u5165console\uff1a $ cat nba.ngql | sudo docker run --rm -i --network = host \\ vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 \u6ce8\u610f \uff1a \u60a8\u5fc5\u987b\u5c06 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u3002 \u60a8\u53ef\u4ee5\u5728 \u8fd9\u91cc \u4e0b\u8f7d nba.ngql \u6587\u4ef6\u3002 \u540c\u6837\uff0c\u60a8\u53ef\u4ee5\u5728 data.ngql \u6587\u4ef6\u4e2d\u653e\u7f6e\u6570\u767e\u6216\u6570\u5343\u4e2a DML\uff08\u6570\u636e\u64cd\u4f5c\u8bed\u8a00\uff09\u8bed\u53e5\u6765\u63d2\u5165\u6570\u636e\u3002\u5982\u679c\u60a8\u8981\u63d2\u5165\u6570\u767e\u4e07\u6761\u8bb0\u5f55\uff0c\u5efa\u8bae\u4f7f\u7528 csv \u5bfc\u5165\u5de5\u5177 \uff08\u6216 sst \u63d0\u53d6\u5de5\u5177 \uff09\u3002","title":"\u6279\u91cf\u63d2\u5165"},{"location":"manual-CN/1.overview/2.quick-start/1.get-started/#_17","text":"\u6b22\u8fce\u4f7f\u7528\u6211\u4eec\u7684 \u5b98\u65b9\u8bba\u575b \u8fdb\u884c\u63d0\u95ee\u6216\u8ba8\u8bba\u95ee\u9898\u3002 \u8bf7\u5728 GitHub Issues \u4e0a\u63d0 bug \u6216 feature\u3002 \u6b22\u8fce\u5173\u6ce8\u6211\u4eec\u7684 Stack Overflow \u3002","title":"\u83b7\u5f97\u5e2e\u52a9"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/","text":"\u5e38\u89c1\u95ee\u9898 \u00b6 \u672c\u6587\u6863\u5217\u51fa\u4e86 Nebula Graph \u5e38\u89c1\u95ee\u9898\u3002 \u5e38\u89c1\u95ee\u9898 Trouble Shooting graphd \u7684\u914d\u7f6e\u6ca1\u6709\u6ce8\u518c\u5230 meta server \u5f53\u521b\u5efa tag \u6216\u8005 edge \u7c7b\u578b\u540e\uff0c\u63d2\u5165\u6570\u636e\u65f6\u62a5\u9519 \u4f7f\u7528 Docker \u542f\u52a8\u540e\uff0c\u6267\u884c\u547d\u4ee4\u65f6\u62a5\u9519 storaged \u670d\u52a1\u65e0\u6cd5\u6b63\u5e38\u542f\u52a8 Connection Refused \u8fdb\u7a0b\u5f02\u5e38 crash \u672a\u627e\u5230\u65e5\u5fd7\u548c\u66f4\u6539\u65e5\u5fd7\u7ea7\u522b \u914d\u7f6e\u6587\u4ef6 \u8fd0\u884c\u65f6\u53c2\u6570 Could not create logging file:... Too many open files \u5982\u4f55\u67e5\u770b Nebula Graph \u7248\u672c\u4fe1\u606f \u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u4e0d\u751f\u6548 \u4fee\u6539 RocksDB block cache General Information \u67e5\u8be2\u8fd4\u56de\u65f6\u95f4\u89e3\u91ca Trouble Shooting \u00b6 Trouble Shooting \u90e8\u5206\u5217\u51fa\u4e86 Nebula Graph \u64cd\u4f5c\u4e2d\u7684\u5e38\u89c1\u9519\u8bef\u3002 graphd \u7684\u914d\u7f6e\u6ca1\u6709\u6ce8\u518c\u5230 meta server \u00b6 \u7528 nebula.service \u811a\u672c\u542f\u52a8\u670d\u52a1\u65f6\uff0c graphd \u3001 metad \u548c storaged \u8fdb\u7a0b\u542f\u52a8\u901f\u5ea6\u592a\u5feb\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4 graphd \u7684\u914d\u7f6e\u6ca1\u6709\u6ce8\u518c\u5230 meta server\u3002restart \u7684\u65f6\u5019\u4e5f\u6709\u6b64\u95ee\u9898\u3002 beta \u7248\u672c\u7528\u6237\u53ef\u4ee5\u5148\u542f\u52a8 metad\uff0c\u518d\u542f\u52a8 storaged \u548c graphd \u6765\u907f\u514d\u6b64\u95ee\u9898\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u4e2a\u7248\u672c\u89e3\u51b3\u6b64\u95ee\u9898\u3002 \u5148\u542f\u52a8 metad\uff1a $ scripts/nebula.service start metad [ INFO ] Starting nebula-metad... [ INFO ] Done \u518d\u542f\u52a8 storaged \u548c graphd\uff1a $ scripts/nebula.service start storaged [ INFO ] Starting nebula-storaged... [ INFO ] Done $ scripts/nebula.service start graphd [ INFO ] Starting nebula-graphd... [ INFO ] Done [\u2191] \u56de\u5230\u9876\u90e8 \u5f53\u521b\u5efa tag \u6216\u8005 edge \u7c7b\u578b\u540e\uff0c\u63d2\u5165\u6570\u636e\u65f6\u62a5\u9519 \u00b6 \u53ef\u80fd\u539f\u56e0\uff0c heartbeat_interval_secs \u8bbe\u7f6e\u4e86\u4ece meta server \u83b7\u53d6\u5143\u6570\u636e\u65f6\u95f4\u95f4\u9694\u3002\u66f4\u6539\u65b9\u5f0f: \u5982\u679c meta \u6ce8\u518c\u8fc7\u914d\u7f6e\uff0c\u8bf7\u5728 console \u4e2d\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b\u53c2\u6570 heartbeat_interval_secs \u7684\u503c\u3002 nebula> GET CONFIGS storage:heartbeat_interval_secs; nebula> GET CONFIGS graph:heartbeat_interval_secs; \u5982\u679c\u503c\u8fc7\u5927\uff0c\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u5c06\u503c\u66f4\u6539\u4e3a 1s ngql nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1; nebula> UPDATE CONFIGS graph:heartbeat_interval_secs=1; \u6ce8\u610f\uff0c\u66f4\u6539\u4e0d\u4f1a\u7acb\u5373\u751f\u6548\uff0c\u9700\u5728\u4e0b\u4e2a\u5468\u671f\u751f\u6548\u3002 [\u2191] \u56de\u5230\u9876\u90e8 \u4f7f\u7528 Docker \u542f\u52a8\u540e\uff0c\u6267\u884c\u547d\u4ee4\u65f6\u62a5\u9519 \u00b6 \u53ef\u80fd\u7684\u539f\u56e0\u662f Docker \u7684 IP \u5730\u5740\u548c\u9ed8\u8ba4\u914d\u7f6e\u4e2d\u7684\u76d1\u542c\u5730\u5740\u4e0d\u4e00\u81f4(\u9ed8\u8ba4\u662f 172.17.0.2)\uff0c\u56e0\u6b64\u8fd9\u91cc\u9700\u8981\u4fee\u6539\u9ed8\u8ba4\u914d\u7f6e\u4e2d\u7684\u76d1\u542c\u5730\u5740\u3002 \u9996\u5148\u5728\u5bb9\u5668\u4e2d\u6267\u884c ifconfig \u547d\u4ee4\uff0c\u67e5\u770b\u60a8\u7684\u5bb9\u5668\u5730\u5740\uff0c\u8fd9\u91cc\u5047\u8bbe\u60a8\u7684\u5bb9\u5668\u5730\u5740\u662f172.17.0.3\uff0c\u90a3\u4e48\u5c31\u610f\u5473\u7740\u60a8\u9700\u8981\u4fee\u6539\u9ed8\u8ba4\u914d\u7f6e\u7684IP\u5730\u5740\u3002 \u7136\u540e\u8fdb\u5165\u914d\u7f6e\u76ee\u5f55(cd /usr/local/nebula/etc), \u67e5\u627e\u6240\u6709IP\u5730\u5740\u914d\u7f6e\u7684\u4f4d\u7f6e(grep \"172.17.0.2\" . -r)\u3002 \u4fee\u6539\u4e0a\u4e00\u6b65\u67e5\u5230\u7684\u6240\u6709IP\u5730\u5740\u4e3a\u60a8\u7684\u5bb9\u5668\u5730\u5740(172.17.0.3)\u3002 \u6700\u540e\u91cd\u65b0\u542f\u52a8\u6240\u6709\u670d\u52a1(/usr/local/nebula/scripts/nebula.service restart all)\u3002 [\u2191] \u56de\u5230\u9876\u90e8 storaged \u670d\u52a1\u65e0\u6cd5\u6b63\u5e38\u542f\u52a8 \u00b6 \u540c\u4e00\u53f0\u4e3b\u673a\u5148\u540e\u7528\u4e8e\u5355\u673a\u6d4b\u8bd5\u548c\u96c6\u7fa4\u6d4b\u8bd5\uff0cstoraged \u670d\u52a1\u65e0\u6cd5\u6b63\u5e38\u542f\u52a8\uff08\u7ec8\u7aef\u4e0a\u663e\u793a\u7684 storaged \u670d\u52a1\u7684\u76d1\u542c\u7aef\u53e3\u662f\u7ea2\u8272\u7684\uff09\u3002\u67e5\u770b storged \u670d\u52a1\u7684\u65e5\u5fd7(/usr/local/nebula/nebula-storaged.ERROR)\uff0c\u82e5\u53d1\u73b0 \"wrong cluster\" \u7684\u62a5\u9519\u4fe1\u606f\uff0c\u5219\u53ef\u80fd\u7684\u51fa\u9519\u539f\u56e0\u662f\u5355\u673a\u6d4b\u8bd5\u548c\u96c6\u7fa4\u6d4b\u8bd5\u65f6\u7684 Nebula Graph \u751f\u6210\u7684 cluster id \u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u5220\u9664 Nebula Graph \u5b89\u88c5\u76ee\u5f55(/usr/local/nebula)\u4e0b\u7684 cluster.id \u6587\u4ef6\u548c data \u76ee\u5f55\u540e\uff0c\u91cd\u542f\u670d\u52a1\u3002 [\u2191] \u56de\u5230\u9876\u90e8 Connection Refused \u00b6 E1121 04:49:34.563858 256 GraphClient.cpp:54] Thrift rpc call failed: AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused): Connection refused \u68c0\u67e5\u670d\u52a1\u662f\u5426\u5b58\u5728 $ /usr/local/nebula/scripts/nebula.service status all [\u2191] \u56de\u5230\u9876\u90e8 \u8fdb\u7a0b\u5f02\u5e38 crash \u00b6 \u68c0\u67e5\u786c\u76d8\u7a7a\u95f4 df -h \u68c0\u67e5\u5185\u5b58\u662f\u5426\u8db3\u591f free -h [\u2191] \u56de\u5230\u9876\u90e8 \u672a\u627e\u5230\u65e5\u5fd7\u548c\u66f4\u6539\u65e5\u5fd7\u7ea7\u522b \u00b6 \u65e5\u5fd7\u6587\u4ef6\u9ed8\u8ba4\u5728 /usr/local/nebula/logs/ \u4e0b\u3002 \u53c2\u89c1 \u8fd9\u91cc [\u2191] \u56de\u5230\u9876\u90e8 \u914d\u7f6e\u6587\u4ef6 \u00b6 \u914d\u7f6e\u6587\u4ef6\u9ed8\u8ba4\u5728 /usr/local/nebula/etc/ \u4e0b\u3002 [\u2191] \u56de\u5230\u9876\u90e8 \u8fd0\u884c\u65f6\u53c2\u6570 \u00b6 \u5728 Nebula console \u4e2d\u8fd0\u884c nebula> SHOW CONFIGS; \u53c2\u89c1 \u8fd9\u91cc [\u2191] \u56de\u5230\u9876\u90e8 Could not create logging file:... Too many open files \u00b6 \u68c0\u67e5\u786c\u76d8\u7a7a\u95f4 df -h \u68c0\u67e5\u65e5\u5fd7\u76ee\u5f55 /usr/local/nebula/logs/ \u4fee\u6539\u5141\u8bb8\u6253\u5f00\u7684\u6700\u5927\u6587\u4ef6\u6570 ulimit -n 65536 [\u2191] \u56de\u5230\u9876\u90e8 \u5982\u4f55\u67e5\u770b Nebula Graph \u7248\u672c\u4fe1\u606f \u00b6 \u4f7f\u7528 curl http://ip:port/status \u547d\u4ee4\u83b7\u53d6 git_info_sha\u3001binary \u5305\u7684 commitID\u3002 [\u2191] \u56de\u5230\u9876\u90e8 \u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u4e0d\u751f\u6548 \u00b6 Nebula Graph \u4f7f\u7528\u5982\u4e0b\u4e24\u79cd\u65b9\u5f0f\u83b7\u53d6\u914d\u7f6e\uff1a \u4ece\u914d\u7f6e\u6587\u4ef6\u4e2d\uff08\u9700\u8981\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f\u670d\u52a1\uff09\uff1b \u4ece Meta \u670d\u52a1\u4e2d\u3002\u901a\u8fc7 CLI \u8bbe\u7f6e\uff0c\u5e76\u6301\u4e45\u5316\u4fdd\u5b58\u5728 Meta \u670d\u52a1\u4e2d\uff0c\u8be6\u60c5\u53c2\u8003 \u670d\u52a1\u5668\u914d\u7f6e \uff1b \u4fee\u6539\u4e86\u914d\u7f6e\u6587\u4ef6\u4e0d\u751f\u6548\uff0c\u662f\u56e0\u4e3a\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c Nebula Graph \u7684\u914d\u7f6e\u53c2\u6570\u7ba1\u7406\u91c7\u7528\u7b2c\u4e8c\u79cd\u65b9\u5f0f (Meta)\uff0c\u5982\u679c\u5e0c\u671b\u91c7\u7528\u7b2c\u4e00\u79cd\u65b9\u5f0f\uff0c\u9700\u8981\u5728 /home/user/nebula/build/install/etc \u914d\u7f6e\u6587\u4ef6 metad.conf \u3001 storaged.conf \u3001 graphd.conf \u4e2d\u5206\u522b\u6dfb\u52a0 --local_config=true \u9009\u9879\u3002 [\u2191] \u56de\u5230\u9876\u90e8 \u4fee\u6539 RocksDB block cache \u00b6 \u66f4\u6539 storage \u7684\u914d\u7f6e\u6587\u4ef6 storaged.conf \uff08\u9ed8\u8ba4\u8def\u5f84\u4e3a /usr/local/nebula/etc/ \uff0c\u8def\u5f84\u53ef\u80fd\u56e0\u4eba\u800c\u5f02\uff09\u5e76\u91cd\u542f\uff0c\u4f8b\u5982\uff1a # Change rocksdb_block_cache to 1024 MB --rocksdb_block_cache = 1024 # Stop storaged and restart /usr/local/nebula/scripts/nebula.service stop storaged /usr/local/nebula/scripts/nebula.service start storaged \u5728\u7ec8\u7aef\u8fd0\u884c curl 127.0.0.1:12000/get_flags | grep rocksdb_block_cache \u67e5\u770b\u914d\u7f6e\u662f\u5426\u751f\u6548\u3002 $ curl 127 .0.0.1:12000/get_flags | grep rocksdb_block_cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3041 100 3041 0 0 989k 0 --:--:-- --:--:-- --:--:-- 989k rocksdb_block_cache = 1024 [\u2191] \u56de\u5230\u9876\u90e8 General Information \u00b6 General Information \u90e8\u5206\u5217\u51fa\u4e86\u5173\u4e8e Nebula Graph \u7684\u6982\u5ff5\u6027\u95ee\u9898\u3002 \u67e5\u8be2\u8fd4\u56de\u65f6\u95f4\u89e3\u91ca \u00b6 nebula> GO FROM 101 OVER follow; =============== | follow._dst | =============== | 100 | --------------- | 102 | --------------- | 125 | --------------- Got 3 rows (Time spent: 7431/10406 us) \u4ee5\u4e0a\u8ff0\u67e5\u8be2\u4e3a\u4f8b\uff0cTime spent \u4e2d\u524d\u4e00\u4e2a\u6570\u5b57 7431 \u4e3a\u6570\u636e\u5e93\u672c\u8eab\u6240\u82b1\u8d39\u7684\u65f6\u95f4\uff0c\u5373 query engine \u4ece console \u6536\u5230\u8fd9\u6761\u67e5\u8be2\u8bed\u53e5\uff0c\u5230\u5b58\u50a8\u62ff\u5230\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u4e00\u7cfb\u5217\u8ba1\u7b97\u6240\u82b1\u7684\u65f6\u95f4\uff1b\u540e\u4e00\u4e2a\u6570\u5b57 10406 \u662f\u4ece\u5ba2\u6237\u7aef\u89d2\u5ea6\u770b\u82b1\u8d39\u7684\u65f6\u95f4\uff0c\u5373 console \u4ece\u53d1\u9001\u8bf7\u6c42\uff0c\u5230\u6536\u5230\u54cd\u5e94\uff0c\u5e76\u5c06\u7ed3\u679c\u8f93\u51fa\u5230\u5c4f\u5e55\u7684\u65f6\u95f4\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u5e38\u89c1\u95ee\u9898"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#_1","text":"\u672c\u6587\u6863\u5217\u51fa\u4e86 Nebula Graph \u5e38\u89c1\u95ee\u9898\u3002 \u5e38\u89c1\u95ee\u9898 Trouble Shooting graphd \u7684\u914d\u7f6e\u6ca1\u6709\u6ce8\u518c\u5230 meta server \u5f53\u521b\u5efa tag \u6216\u8005 edge \u7c7b\u578b\u540e\uff0c\u63d2\u5165\u6570\u636e\u65f6\u62a5\u9519 \u4f7f\u7528 Docker \u542f\u52a8\u540e\uff0c\u6267\u884c\u547d\u4ee4\u65f6\u62a5\u9519 storaged \u670d\u52a1\u65e0\u6cd5\u6b63\u5e38\u542f\u52a8 Connection Refused \u8fdb\u7a0b\u5f02\u5e38 crash \u672a\u627e\u5230\u65e5\u5fd7\u548c\u66f4\u6539\u65e5\u5fd7\u7ea7\u522b \u914d\u7f6e\u6587\u4ef6 \u8fd0\u884c\u65f6\u53c2\u6570 Could not create logging file:... Too many open files \u5982\u4f55\u67e5\u770b Nebula Graph \u7248\u672c\u4fe1\u606f \u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u4e0d\u751f\u6548 \u4fee\u6539 RocksDB block cache General Information \u67e5\u8be2\u8fd4\u56de\u65f6\u95f4\u89e3\u91ca","title":"\u5e38\u89c1\u95ee\u9898"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#trouble_shooting","text":"Trouble Shooting \u90e8\u5206\u5217\u51fa\u4e86 Nebula Graph \u64cd\u4f5c\u4e2d\u7684\u5e38\u89c1\u9519\u8bef\u3002","title":"Trouble Shooting"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#graphd_meta_server","text":"\u7528 nebula.service \u811a\u672c\u542f\u52a8\u670d\u52a1\u65f6\uff0c graphd \u3001 metad \u548c storaged \u8fdb\u7a0b\u542f\u52a8\u901f\u5ea6\u592a\u5feb\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4 graphd \u7684\u914d\u7f6e\u6ca1\u6709\u6ce8\u518c\u5230 meta server\u3002restart \u7684\u65f6\u5019\u4e5f\u6709\u6b64\u95ee\u9898\u3002 beta \u7248\u672c\u7528\u6237\u53ef\u4ee5\u5148\u542f\u52a8 metad\uff0c\u518d\u542f\u52a8 storaged \u548c graphd \u6765\u907f\u514d\u6b64\u95ee\u9898\u3002\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u4e2a\u7248\u672c\u89e3\u51b3\u6b64\u95ee\u9898\u3002 \u5148\u542f\u52a8 metad\uff1a $ scripts/nebula.service start metad [ INFO ] Starting nebula-metad... [ INFO ] Done \u518d\u542f\u52a8 storaged \u548c graphd\uff1a $ scripts/nebula.service start storaged [ INFO ] Starting nebula-storaged... [ INFO ] Done $ scripts/nebula.service start graphd [ INFO ] Starting nebula-graphd... [ INFO ] Done [\u2191] \u56de\u5230\u9876\u90e8","title":"graphd \u7684\u914d\u7f6e\u6ca1\u6709\u6ce8\u518c\u5230 meta server"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#tag_edge","text":"\u53ef\u80fd\u539f\u56e0\uff0c heartbeat_interval_secs \u8bbe\u7f6e\u4e86\u4ece meta server \u83b7\u53d6\u5143\u6570\u636e\u65f6\u95f4\u95f4\u9694\u3002\u66f4\u6539\u65b9\u5f0f: \u5982\u679c meta \u6ce8\u518c\u8fc7\u914d\u7f6e\uff0c\u8bf7\u5728 console \u4e2d\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b\u53c2\u6570 heartbeat_interval_secs \u7684\u503c\u3002 nebula> GET CONFIGS storage:heartbeat_interval_secs; nebula> GET CONFIGS graph:heartbeat_interval_secs; \u5982\u679c\u503c\u8fc7\u5927\uff0c\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u5c06\u503c\u66f4\u6539\u4e3a 1s ngql nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1; nebula> UPDATE CONFIGS graph:heartbeat_interval_secs=1; \u6ce8\u610f\uff0c\u66f4\u6539\u4e0d\u4f1a\u7acb\u5373\u751f\u6548\uff0c\u9700\u5728\u4e0b\u4e2a\u5468\u671f\u751f\u6548\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u5f53\u521b\u5efa tag \u6216\u8005 edge \u7c7b\u578b\u540e\uff0c\u63d2\u5165\u6570\u636e\u65f6\u62a5\u9519"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#docker","text":"\u53ef\u80fd\u7684\u539f\u56e0\u662f Docker \u7684 IP \u5730\u5740\u548c\u9ed8\u8ba4\u914d\u7f6e\u4e2d\u7684\u76d1\u542c\u5730\u5740\u4e0d\u4e00\u81f4(\u9ed8\u8ba4\u662f 172.17.0.2)\uff0c\u56e0\u6b64\u8fd9\u91cc\u9700\u8981\u4fee\u6539\u9ed8\u8ba4\u914d\u7f6e\u4e2d\u7684\u76d1\u542c\u5730\u5740\u3002 \u9996\u5148\u5728\u5bb9\u5668\u4e2d\u6267\u884c ifconfig \u547d\u4ee4\uff0c\u67e5\u770b\u60a8\u7684\u5bb9\u5668\u5730\u5740\uff0c\u8fd9\u91cc\u5047\u8bbe\u60a8\u7684\u5bb9\u5668\u5730\u5740\u662f172.17.0.3\uff0c\u90a3\u4e48\u5c31\u610f\u5473\u7740\u60a8\u9700\u8981\u4fee\u6539\u9ed8\u8ba4\u914d\u7f6e\u7684IP\u5730\u5740\u3002 \u7136\u540e\u8fdb\u5165\u914d\u7f6e\u76ee\u5f55(cd /usr/local/nebula/etc), \u67e5\u627e\u6240\u6709IP\u5730\u5740\u914d\u7f6e\u7684\u4f4d\u7f6e(grep \"172.17.0.2\" . -r)\u3002 \u4fee\u6539\u4e0a\u4e00\u6b65\u67e5\u5230\u7684\u6240\u6709IP\u5730\u5740\u4e3a\u60a8\u7684\u5bb9\u5668\u5730\u5740(172.17.0.3)\u3002 \u6700\u540e\u91cd\u65b0\u542f\u52a8\u6240\u6709\u670d\u52a1(/usr/local/nebula/scripts/nebula.service restart all)\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u4f7f\u7528 Docker \u542f\u52a8\u540e\uff0c\u6267\u884c\u547d\u4ee4\u65f6\u62a5\u9519"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#storaged","text":"\u540c\u4e00\u53f0\u4e3b\u673a\u5148\u540e\u7528\u4e8e\u5355\u673a\u6d4b\u8bd5\u548c\u96c6\u7fa4\u6d4b\u8bd5\uff0cstoraged \u670d\u52a1\u65e0\u6cd5\u6b63\u5e38\u542f\u52a8\uff08\u7ec8\u7aef\u4e0a\u663e\u793a\u7684 storaged \u670d\u52a1\u7684\u76d1\u542c\u7aef\u53e3\u662f\u7ea2\u8272\u7684\uff09\u3002\u67e5\u770b storged \u670d\u52a1\u7684\u65e5\u5fd7(/usr/local/nebula/nebula-storaged.ERROR)\uff0c\u82e5\u53d1\u73b0 \"wrong cluster\" \u7684\u62a5\u9519\u4fe1\u606f\uff0c\u5219\u53ef\u80fd\u7684\u51fa\u9519\u539f\u56e0\u662f\u5355\u673a\u6d4b\u8bd5\u548c\u96c6\u7fa4\u6d4b\u8bd5\u65f6\u7684 Nebula Graph \u751f\u6210\u7684 cluster id \u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u5220\u9664 Nebula Graph \u5b89\u88c5\u76ee\u5f55(/usr/local/nebula)\u4e0b\u7684 cluster.id \u6587\u4ef6\u548c data \u76ee\u5f55\u540e\uff0c\u91cd\u542f\u670d\u52a1\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"storaged \u670d\u52a1\u65e0\u6cd5\u6b63\u5e38\u542f\u52a8"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#connection_refused","text":"E1121 04:49:34.563858 256 GraphClient.cpp:54] Thrift rpc call failed: AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused): Connection refused \u68c0\u67e5\u670d\u52a1\u662f\u5426\u5b58\u5728 $ /usr/local/nebula/scripts/nebula.service status all [\u2191] \u56de\u5230\u9876\u90e8","title":"Connection Refused"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#crash","text":"\u68c0\u67e5\u786c\u76d8\u7a7a\u95f4 df -h \u68c0\u67e5\u5185\u5b58\u662f\u5426\u8db3\u591f free -h [\u2191] \u56de\u5230\u9876\u90e8","title":"\u8fdb\u7a0b\u5f02\u5e38 crash"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#_2","text":"\u65e5\u5fd7\u6587\u4ef6\u9ed8\u8ba4\u5728 /usr/local/nebula/logs/ \u4e0b\u3002 \u53c2\u89c1 \u8fd9\u91cc [\u2191] \u56de\u5230\u9876\u90e8","title":"\u672a\u627e\u5230\u65e5\u5fd7\u548c\u66f4\u6539\u65e5\u5fd7\u7ea7\u522b"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#_3","text":"\u914d\u7f6e\u6587\u4ef6\u9ed8\u8ba4\u5728 /usr/local/nebula/etc/ \u4e0b\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u914d\u7f6e\u6587\u4ef6"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#_4","text":"\u5728 Nebula console \u4e2d\u8fd0\u884c nebula> SHOW CONFIGS; \u53c2\u89c1 \u8fd9\u91cc [\u2191] \u56de\u5230\u9876\u90e8","title":"\u8fd0\u884c\u65f6\u53c2\u6570"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#could_not_create_logging_file_too_many_open_files","text":"\u68c0\u67e5\u786c\u76d8\u7a7a\u95f4 df -h \u68c0\u67e5\u65e5\u5fd7\u76ee\u5f55 /usr/local/nebula/logs/ \u4fee\u6539\u5141\u8bb8\u6253\u5f00\u7684\u6700\u5927\u6587\u4ef6\u6570 ulimit -n 65536 [\u2191] \u56de\u5230\u9876\u90e8","title":"Could not create logging file:... Too many open files"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#nebula_graph","text":"\u4f7f\u7528 curl http://ip:port/status \u547d\u4ee4\u83b7\u53d6 git_info_sha\u3001binary \u5305\u7684 commitID\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u5982\u4f55\u67e5\u770b Nebula Graph \u7248\u672c\u4fe1\u606f"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#_5","text":"Nebula Graph \u4f7f\u7528\u5982\u4e0b\u4e24\u79cd\u65b9\u5f0f\u83b7\u53d6\u914d\u7f6e\uff1a \u4ece\u914d\u7f6e\u6587\u4ef6\u4e2d\uff08\u9700\u8981\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f\u670d\u52a1\uff09\uff1b \u4ece Meta \u670d\u52a1\u4e2d\u3002\u901a\u8fc7 CLI \u8bbe\u7f6e\uff0c\u5e76\u6301\u4e45\u5316\u4fdd\u5b58\u5728 Meta \u670d\u52a1\u4e2d\uff0c\u8be6\u60c5\u53c2\u8003 \u670d\u52a1\u5668\u914d\u7f6e \uff1b \u4fee\u6539\u4e86\u914d\u7f6e\u6587\u4ef6\u4e0d\u751f\u6548\uff0c\u662f\u56e0\u4e3a\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c Nebula Graph \u7684\u914d\u7f6e\u53c2\u6570\u7ba1\u7406\u91c7\u7528\u7b2c\u4e8c\u79cd\u65b9\u5f0f (Meta)\uff0c\u5982\u679c\u5e0c\u671b\u91c7\u7528\u7b2c\u4e00\u79cd\u65b9\u5f0f\uff0c\u9700\u8981\u5728 /home/user/nebula/build/install/etc \u914d\u7f6e\u6587\u4ef6 metad.conf \u3001 storaged.conf \u3001 graphd.conf \u4e2d\u5206\u522b\u6dfb\u52a0 --local_config=true \u9009\u9879\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u4e0d\u751f\u6548"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#rocksdb_block_cache","text":"\u66f4\u6539 storage \u7684\u914d\u7f6e\u6587\u4ef6 storaged.conf \uff08\u9ed8\u8ba4\u8def\u5f84\u4e3a /usr/local/nebula/etc/ \uff0c\u8def\u5f84\u53ef\u80fd\u56e0\u4eba\u800c\u5f02\uff09\u5e76\u91cd\u542f\uff0c\u4f8b\u5982\uff1a # Change rocksdb_block_cache to 1024 MB --rocksdb_block_cache = 1024 # Stop storaged and restart /usr/local/nebula/scripts/nebula.service stop storaged /usr/local/nebula/scripts/nebula.service start storaged \u5728\u7ec8\u7aef\u8fd0\u884c curl 127.0.0.1:12000/get_flags | grep rocksdb_block_cache \u67e5\u770b\u914d\u7f6e\u662f\u5426\u751f\u6548\u3002 $ curl 127 .0.0.1:12000/get_flags | grep rocksdb_block_cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3041 100 3041 0 0 989k 0 --:--:-- --:--:-- --:--:-- 989k rocksdb_block_cache = 1024 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u4fee\u6539  RocksDB block cache"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#general_information","text":"General Information \u90e8\u5206\u5217\u51fa\u4e86\u5173\u4e8e Nebula Graph \u7684\u6982\u5ff5\u6027\u95ee\u9898\u3002","title":"General Information"},{"location":"manual-CN/1.overview/2.quick-start/2.FAQ/#_6","text":"nebula> GO FROM 101 OVER follow; =============== | follow._dst | =============== | 100 | --------------- | 102 | --------------- | 125 | --------------- Got 3 rows (Time spent: 7431/10406 us) \u4ee5\u4e0a\u8ff0\u67e5\u8be2\u4e3a\u4f8b\uff0cTime spent \u4e2d\u524d\u4e00\u4e2a\u6570\u5b57 7431 \u4e3a\u6570\u636e\u5e93\u672c\u8eab\u6240\u82b1\u8d39\u7684\u65f6\u95f4\uff0c\u5373 query engine \u4ece console \u6536\u5230\u8fd9\u6761\u67e5\u8be2\u8bed\u53e5\uff0c\u5230\u5b58\u50a8\u62ff\u5230\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u4e00\u7cfb\u5217\u8ba1\u7b97\u6240\u82b1\u7684\u65f6\u95f4\uff1b\u540e\u4e00\u4e2a\u6570\u5b57 10406 \u662f\u4ece\u5ba2\u6237\u7aef\u89d2\u5ea6\u770b\u82b1\u8d39\u7684\u65f6\u95f4\uff0c\u5373 console \u4ece\u53d1\u9001\u8bf7\u6c42\uff0c\u5230\u6536\u5230\u54cd\u5e94\uff0c\u5e76\u5c06\u7ed3\u679c\u8f93\u51fa\u5230\u5c4f\u5e55\u7684\u65f6\u95f4\u3002 [\u2191] \u56de\u5230\u9876\u90e8","title":"\u67e5\u8be2\u8fd4\u56de\u65f6\u95f4\u89e3\u91ca"},{"location":"manual-CN/1.overview/2.quick-start/3.supported-clients/","text":"Nebula Graph \u652f\u6301\u7684\u5ba2\u6237\u7aef \u00b6 \u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u5982\u4e0b\u5ba2\u6237\u7aef\uff1a Go \u5ba2\u6237\u7aef Python \u5ba2\u6237\u7aef Java \u5ba2\u6237\u7aef","title":"Nebula Graph \u652f\u6301\u7684\u5ba2\u6237\u7aef"},{"location":"manual-CN/1.overview/2.quick-start/3.supported-clients/#nebula_graph","text":"\u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u5982\u4e0b\u5ba2\u6237\u7aef\uff1a Go \u5ba2\u6237\u7aef Python \u5ba2\u6237\u7aef Java \u5ba2\u6237\u7aef","title":"Nebula Graph \u652f\u6301\u7684\u5ba2\u6237\u7aef"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/","text":"CSV\u6587\u4ef6\u5bfc\u5165\u793a\u4f8b \u00b6 \u4ee5\u4e0b\u793a\u4f8b\u5c06\u6307\u5bfc\u60a8\u5982\u4f55\u4f7f\u7528 Nebula Importer \u5c06 CSV \u6570\u636e\u5bfc\u5165\u5230 Nebula Graph \u4e2d\u3002\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c Nebula Graph \u901a\u8fc7 Docker \u548c Docker Compose \u5b89\u88c5\u3002\u6211\u4eec\u5c06\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5f15\u5bfc\u60a8\u5b8c\u6210\u8be5\u793a\u4f8b\uff1a \u542f\u52a8 Nebula Graph \u670d\u52a1 \u521b\u5efa\u70b9\u548c\u8fb9\u7684 Schema \u51c6\u5907\u914d\u7f6e\u6587\u4ef6 \u51c6\u5907 CSV \u6570\u636e \u5bfc\u5165 CSV \u6570\u636e \u542f\u52a8 Nebula Graph \u670d\u52a1 \u00b6 \u60a8\u53ef\u4ee5\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u542f\u52a8 Nebula Graph \u670d\u52a1\uff1a \u5728\u547d\u4ee4\u884c\u754c\u9762\u4e0a\uff0c\u8fdb\u5165 nebula-docker-compose \u76ee\u5f55\u3002 \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u542f\u52a8 Nebula Graph \u670d\u52a1\uff1a $ sudo docker-compose up -d \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u628a Nebula Graph \u955c\u50cf\u6587\u4ef6\u4e0b\u62c9\u5230\u672c\u5730\uff1a $ sudo docker pull vesoft/nebula-console:nightly \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u8fde\u63a5 Nebula Graph \u670d\u52a1\u5668\uff1a $ sudo docker run --rm -ti --network = host vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 \u6ce8\u610f \uff1a\u60a8\u5fc5\u987b\u786e\u4fdd IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u914d\u7f6e\u6b63\u786e\u3002 \u521b\u5efa\u70b9\u548c\u8fb9\u7684 Schema \u00b6 \u5728\u8f93\u5165 schema \u4e4b\u524d\uff0c\u5fc5\u987b\u521b\u5efa\u4e00\u4e2a\u7a7a\u95f4\u5e76\u4f7f\u7528\u5b83\u3002\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a nba \u7a7a\u95f4\u5e76\u4f7f\u7528\u5b83\u3002 \u6211\u4eec\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u521b\u5efa\u4e24\u4e2a\u6807\u7b7e\u548c\u4e24\u4e2a\u8fb9\u7c7b\u578b\uff1a nebula> CREATE TAG player (name string, age int); nebula> CREATE TAG team (name string); nebula> CREATE EDGE serve (start_year int, end_year int); nebula> CREATE EDGE follow (degree, int); \u51c6\u5907\u914d\u7f6e\u6587\u4ef6 \u00b6 \u60a8\u5fc5\u987b\u914d\u7f6e .yaml \u914d\u7f6e\u6587\u4ef6\uff0c\u8be5\u6587\u4ef6\u89c4\u5b9a\u4e86 CSV \u6587\u4ef6\u4e2d\u6570\u636e\u7684\u683c\u5f0f\u3002\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a config.yaml \u7684\u914d\u7f6e\u6587\u4ef6\u3002 \u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u6309\u4ee5\u4e0b\u65b9\u5f0f\u914d\u7f6e config.yaml \u6587\u4ef6\uff1a version: v1rc1 description: example clientSettings: concurrency: 2 # number of graph clients channelBufferSize: 1 space: nba connection: user: user password: password address: 127.0.0.1:3699 logPath: ./err/test.log files: - path: /home/nebula/serve.csv failDataPath: ./err/serve.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: serve withRanking: false props: - name: start_year type: int - name: end_year type: int - path: /home/nebula/follow.csv failDataPath: ./err/follow.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: follow withRanking: false props: - name: degree type: int - path: /home/nebula/player.csv failDataPath: ./err/player.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: player props: - name: name type: string - name: age type: int - path: /home/nebula/team.csv failDataPath: ./err/team.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: team props: - name: name type: string \u6ce8\u610f \uff1a \u5728\u4e0a\u9762\u7684\u914d\u7f6e\u6587\u4ef6\u4e2d\uff0c\u60a8\u5fc5\u987b\u5c06IP\u5730\u5740\u548c\u7aef\u53e3\u53f7\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u3002 \u60a8\u5fc5\u987b\u5c06 CSV \u6587\u4ef6\u7684\u76ee\u5f55\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684\u76ee\u5f55\uff0c\u5426\u5219\uff0c Nebula Importer \u65e0\u6cd5\u627e\u5230 CSV \u6587\u4ef6\u3002 \u51c6\u5907 CSV \u6570\u636e \u00b6 \u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u51c6\u5907\u4e86\u56db\u4e2a CSV \u6570\u636e\u6587\u4ef6\uff1a player.csv \u3001 team.csv \u3001 serve.csv \u4ee5\u53ca follow.csv \u3002 serve.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 100,200,1997,2016 101,201,1999,2018 102,203,2006,2015 102,204,2015,2019 103,204,2017,2019 104,200,2007,2009 follow.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 100,101,95 100,102,90 101,100,95 102,101,75 102,100,75 103,102,70 104,101,50 104,105,60 105,104,83 player.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 100,Tim Duncan,42 101,Tony Parker,36 102,LaMarcus Aldridge,33 103,Rudy Gay,32 104,Marco Belinelli,32 105,Danny Green,31 106,Kyle Anderson,25 107,Aron Baynes,32 108,Boris Diaw,36 team.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 200,Warriors 201,Nuggets 202,Rockets 203,Trail 204,Spurs 205,Thunders 206,Jazz 207,Clippers 208,Kings \u6ce8\u610f \uff1a \u5728 serve \u548c follow CSV \u6587\u4ef6\u4e2d\uff0c\u7b2c\u4e00\u5217\u662f\u8d77\u59cb\u70b9 ID\u3001\u7b2c\u4e8c\u5217\u662f\u76ee\u6807\u70b9 ID\uff0c\u5176\u4ed6\u5217\u4e0e config.yaml \u6587\u4ef6\u4e00\u81f4\u3002 \u5728 player \u548c team CSV \u6587\u4ef6\u4e2d\uff0c\u7b2c\u4e00\u5217\u662f\u70b9 ID\uff0c\u5176\u4ed6\u5217\u4e0e config.yaml \u6587\u4ef6\u4e00\u81f4\u3002 \u5bfc\u5165 CSV \u6570\u636e \u00b6 \u5b8c\u6210\u4e0a\u8ff0\u6240\u6709\u56db\u4e2a\u6b65\u9aa4\u540e\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528 Docker \u6216 Go \u5bfc\u5165 CSV \u6570\u636e\u3002 \u4f7f\u7528 Go \u5bfc\u5165 CSV \u6570\u636e \u00b6 \u5728\u4f7f\u7528 Go \u5bfc\u5165 CSV \u6570\u636e\u4e4b\u524d\uff0c\u5fc5\u987b\u786e\u4fdd\u5df2\u5b89\u88c5 Go \u5e76\u914d\u7f6e\u4e86 Go \u7684\u73af\u5883\u53d8\u91cf\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5bfc\u5165 CSV \u6570\u636e\uff1a \u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u5c06\u5f53\u524d\u76ee\u5f55\u66f4\u6539\u4e3a import.go \u6587\u4ef6\u6240\u5728\u7684\u76ee\u5f55\uff1a $ cd /home/nebula/nebula-importer/cmd \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5bfc\u5165 CSV \u6570\u636e\uff1a $ go run importer.go --config /home/nebula/config.yaml \u6ce8\u610f \uff1a\u60a8\u5fc5\u987b\u5c06 import.go \u6587\u4ef6\u7684\u76ee\u5f55\u548c config.yaml \u6587\u4ef6\u7684\u76ee\u5f55\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684\u76ee\u5f55\uff0c\u5426\u5219\uff0c\u5bfc\u5165\u64cd\u4f5c\u53ef\u80fd\u4f1a\u5931\u8d25\u3002 \u4f7f\u7528 Docker \u5bfc\u5165 CSV \u6570\u636e \u00b6 \u5728\u4f7f\u7528 Docker \u5bfc\u5165CSV\u6570\u636e\u4e4b\u524d\uff0c\u5fc5\u987b\u786e\u4fdd Docker \u5df2\u542f\u52a8\u5e76\u8fd0\u884c\u6b63\u5e38\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u4f7f\u7528 Docker \u5bfc\u5165 CSV \u6570\u636e\uff1a $ sudo docker run --rm -ti --network = host \\ -v /home/nebula/config.yaml:/home/nebula/config.yaml \\ -v /home/nebula/:/home/nebula/ vesoft/nebula-importer \\ --config /home/nebula/config.yaml \u6ce8\u610f \uff1a\u60a8\u5fc5\u987b\u5c06 config.yaml \u6587\u4ef6\u7684\u76ee\u5f55\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684\u76ee\u5f55\uff0c\u5426\u5219\u5bfc\u5165\u64cd\u4f5c\u53ef\u80fd\u4f1a\u5931\u8d25\u3002","title":"CSV\u6587\u4ef6\u5bfc\u5165\u793a\u4f8b"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#csv","text":"\u4ee5\u4e0b\u793a\u4f8b\u5c06\u6307\u5bfc\u60a8\u5982\u4f55\u4f7f\u7528 Nebula Importer \u5c06 CSV \u6570\u636e\u5bfc\u5165\u5230 Nebula Graph \u4e2d\u3002\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c Nebula Graph \u901a\u8fc7 Docker \u548c Docker Compose \u5b89\u88c5\u3002\u6211\u4eec\u5c06\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5f15\u5bfc\u60a8\u5b8c\u6210\u8be5\u793a\u4f8b\uff1a \u542f\u52a8 Nebula Graph \u670d\u52a1 \u521b\u5efa\u70b9\u548c\u8fb9\u7684 Schema \u51c6\u5907\u914d\u7f6e\u6587\u4ef6 \u51c6\u5907 CSV \u6570\u636e \u5bfc\u5165 CSV \u6570\u636e","title":"CSV\u6587\u4ef6\u5bfc\u5165\u793a\u4f8b"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#nebula_graph","text":"\u60a8\u53ef\u4ee5\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u542f\u52a8 Nebula Graph \u670d\u52a1\uff1a \u5728\u547d\u4ee4\u884c\u754c\u9762\u4e0a\uff0c\u8fdb\u5165 nebula-docker-compose \u76ee\u5f55\u3002 \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u542f\u52a8 Nebula Graph \u670d\u52a1\uff1a $ sudo docker-compose up -d \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u628a Nebula Graph \u955c\u50cf\u6587\u4ef6\u4e0b\u62c9\u5230\u672c\u5730\uff1a $ sudo docker pull vesoft/nebula-console:nightly \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u8fde\u63a5 Nebula Graph \u670d\u52a1\u5668\uff1a $ sudo docker run --rm -ti --network = host vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 \u6ce8\u610f \uff1a\u60a8\u5fc5\u987b\u786e\u4fdd IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u914d\u7f6e\u6b63\u786e\u3002","title":"\u542f\u52a8 Nebula Graph \u670d\u52a1"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#schema","text":"\u5728\u8f93\u5165 schema \u4e4b\u524d\uff0c\u5fc5\u987b\u521b\u5efa\u4e00\u4e2a\u7a7a\u95f4\u5e76\u4f7f\u7528\u5b83\u3002\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a nba \u7a7a\u95f4\u5e76\u4f7f\u7528\u5b83\u3002 \u6211\u4eec\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u521b\u5efa\u4e24\u4e2a\u6807\u7b7e\u548c\u4e24\u4e2a\u8fb9\u7c7b\u578b\uff1a nebula> CREATE TAG player (name string, age int); nebula> CREATE TAG team (name string); nebula> CREATE EDGE serve (start_year int, end_year int); nebula> CREATE EDGE follow (degree, int);","title":"\u521b\u5efa\u70b9\u548c\u8fb9\u7684 Schema"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#_1","text":"\u60a8\u5fc5\u987b\u914d\u7f6e .yaml \u914d\u7f6e\u6587\u4ef6\uff0c\u8be5\u6587\u4ef6\u89c4\u5b9a\u4e86 CSV \u6587\u4ef6\u4e2d\u6570\u636e\u7684\u683c\u5f0f\u3002\u5728\u672c\u4f8b\u4e2d\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a config.yaml \u7684\u914d\u7f6e\u6587\u4ef6\u3002 \u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u6309\u4ee5\u4e0b\u65b9\u5f0f\u914d\u7f6e config.yaml \u6587\u4ef6\uff1a version: v1rc1 description: example clientSettings: concurrency: 2 # number of graph clients channelBufferSize: 1 space: nba connection: user: user password: password address: 127.0.0.1:3699 logPath: ./err/test.log files: - path: /home/nebula/serve.csv failDataPath: ./err/serve.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: serve withRanking: false props: - name: start_year type: int - name: end_year type: int - path: /home/nebula/follow.csv failDataPath: ./err/follow.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: follow withRanking: false props: - name: degree type: int - path: /home/nebula/player.csv failDataPath: ./err/player.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: player props: - name: name type: string - name: age type: int - path: /home/nebula/team.csv failDataPath: ./err/team.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: team props: - name: name type: string \u6ce8\u610f \uff1a \u5728\u4e0a\u9762\u7684\u914d\u7f6e\u6587\u4ef6\u4e2d\uff0c\u60a8\u5fc5\u987b\u5c06IP\u5730\u5740\u548c\u7aef\u53e3\u53f7\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684 IP \u5730\u5740\u548c\u7aef\u53e3\u53f7\u3002 \u60a8\u5fc5\u987b\u5c06 CSV \u6587\u4ef6\u7684\u76ee\u5f55\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684\u76ee\u5f55\uff0c\u5426\u5219\uff0c Nebula Importer \u65e0\u6cd5\u627e\u5230 CSV \u6587\u4ef6\u3002","title":"\u51c6\u5907\u914d\u7f6e\u6587\u4ef6"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#csv_1","text":"\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u51c6\u5907\u4e86\u56db\u4e2a CSV \u6570\u636e\u6587\u4ef6\uff1a player.csv \u3001 team.csv \u3001 serve.csv \u4ee5\u53ca follow.csv \u3002 serve.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 100,200,1997,2016 101,201,1999,2018 102,203,2006,2015 102,204,2015,2019 103,204,2017,2019 104,200,2007,2009 follow.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 100,101,95 100,102,90 101,100,95 102,101,75 102,100,75 103,102,70 104,101,50 104,105,60 105,104,83 player.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 100,Tim Duncan,42 101,Tony Parker,36 102,LaMarcus Aldridge,33 103,Rudy Gay,32 104,Marco Belinelli,32 105,Danny Green,31 106,Kyle Anderson,25 107,Aron Baynes,32 108,Boris Diaw,36 team.csv \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5982\u4e0b\uff1a 200,Warriors 201,Nuggets 202,Rockets 203,Trail 204,Spurs 205,Thunders 206,Jazz 207,Clippers 208,Kings \u6ce8\u610f \uff1a \u5728 serve \u548c follow CSV \u6587\u4ef6\u4e2d\uff0c\u7b2c\u4e00\u5217\u662f\u8d77\u59cb\u70b9 ID\u3001\u7b2c\u4e8c\u5217\u662f\u76ee\u6807\u70b9 ID\uff0c\u5176\u4ed6\u5217\u4e0e config.yaml \u6587\u4ef6\u4e00\u81f4\u3002 \u5728 player \u548c team CSV \u6587\u4ef6\u4e2d\uff0c\u7b2c\u4e00\u5217\u662f\u70b9 ID\uff0c\u5176\u4ed6\u5217\u4e0e config.yaml \u6587\u4ef6\u4e00\u81f4\u3002","title":"\u51c6\u5907 CSV \u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#csv_2","text":"\u5b8c\u6210\u4e0a\u8ff0\u6240\u6709\u56db\u4e2a\u6b65\u9aa4\u540e\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528 Docker \u6216 Go \u5bfc\u5165 CSV \u6570\u636e\u3002","title":"\u5bfc\u5165 CSV \u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#go_csv","text":"\u5728\u4f7f\u7528 Go \u5bfc\u5165 CSV \u6570\u636e\u4e4b\u524d\uff0c\u5fc5\u987b\u786e\u4fdd\u5df2\u5b89\u88c5 Go \u5e76\u914d\u7f6e\u4e86 Go \u7684\u73af\u5883\u53d8\u91cf\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5bfc\u5165 CSV \u6570\u636e\uff1a \u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u5c06\u5f53\u524d\u76ee\u5f55\u66f4\u6539\u4e3a import.go \u6587\u4ef6\u6240\u5728\u7684\u76ee\u5f55\uff1a $ cd /home/nebula/nebula-importer/cmd \u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5bfc\u5165 CSV \u6570\u636e\uff1a $ go run importer.go --config /home/nebula/config.yaml \u6ce8\u610f \uff1a\u60a8\u5fc5\u987b\u5c06 import.go \u6587\u4ef6\u7684\u76ee\u5f55\u548c config.yaml \u6587\u4ef6\u7684\u76ee\u5f55\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684\u76ee\u5f55\uff0c\u5426\u5219\uff0c\u5bfc\u5165\u64cd\u4f5c\u53ef\u80fd\u4f1a\u5931\u8d25\u3002","title":"\u4f7f\u7528 Go \u5bfc\u5165 CSV \u6570\u636e"},{"location":"manual-CN/1.overview/2.quick-start/4.import-csv-file/#docker_csv","text":"\u5728\u4f7f\u7528 Docker \u5bfc\u5165CSV\u6570\u636e\u4e4b\u524d\uff0c\u5fc5\u987b\u786e\u4fdd Docker \u5df2\u542f\u52a8\u5e76\u8fd0\u884c\u6b63\u5e38\u3002 \u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u4f7f\u7528 Docker \u5bfc\u5165 CSV \u6570\u636e\uff1a $ sudo docker run --rm -ti --network = host \\ -v /home/nebula/config.yaml:/home/nebula/config.yaml \\ -v /home/nebula/:/home/nebula/ vesoft/nebula-importer \\ --config /home/nebula/config.yaml \u6ce8\u610f \uff1a\u60a8\u5fc5\u987b\u5c06 config.yaml \u6587\u4ef6\u7684\u76ee\u5f55\u66f4\u6539\u4e3a\u60a8\u81ea\u5df1\u7684\u76ee\u5f55\uff0c\u5426\u5219\u5bfc\u5165\u64cd\u4f5c\u53ef\u80fd\u4f1a\u5931\u8d25\u3002","title":"\u4f7f\u7528 Docker \u5bfc\u5165 CSV \u6570\u636e"},{"location":"manual-CN/1.overview/3.design-and-architecture/1.design-and-architecture/","text":"Nebula Graph \u7684\u6574\u4f53\u67b6\u6784 \u00b6 \u4e00\u4e2a\u5b8c\u6574\u7684 Nebula Graph \u90e8\u7f72\u96c6\u7fa4\u5305\u542b\u4e09\u4e2a\u670d\u52a1\uff0c\u5373 Query Service\uff0cStorage Service \u548c Meta Service\u3002\u6bcf\u4e2a\u670d\u52a1\u90fd\u6709\u5176\u5404\u81ea\u7684\u53ef\u6267\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u6587\u4ef6\u65e2\u53ef\u4ee5\u90e8\u7f72\u5728\u540c\u4e00\u7ec4\u8282\u70b9\u4e0a\uff0c\u4e5f\u53ef\u4ee5\u90e8\u7f72\u5728\u4e0d\u540c\u7684\u8282\u70b9\u4e0a\u3002 Meta Service \u00b6 \u4e0a\u56fe\u4e3a Nebula Graph \u7684\u67b6\u6784\u56fe\uff0c\u5176\u53f3\u4fa7\u4e3a Meta Service \u96c6\u7fa4\uff0c\u5b83\u91c7\u7528 leader/follower \u67b6\u6784\u3002Leader \u7531\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Meta Service \u8282\u70b9\u9009\u51fa\uff0c\u7136\u540e\u5bf9\u5916\u63d0\u4f9b\u670d\u52a1\u3002Followers \u5904\u4e8e\u5f85\u547d\u72b6\u6001\u5e76\u4ece leader \u590d\u5236\u66f4\u65b0\u7684\u6570\u636e\u3002\u4e00\u65e6 leader \u8282\u70b9 down \u6389\uff0c\u4f1a\u518d\u9009\u4e3e\u5176\u4e2d\u4e00\u4e2a follower \u6210\u4e3a\u65b0\u7684 leader\u3002 Meta Service \u4e0d\u4ec5\u8d1f\u8d23\u5b58\u50a8\u548c\u63d0\u4f9b\u56fe\u6570\u636e\u7684 meta \u4fe1\u606f\uff0c\u5982 schema\u3001partition \u4fe1\u606f\u7b49\uff0c\u8fd8\u540c\u65f6\u8d1f\u8d23\u6307\u6325\u6570\u636e\u8fc1\u79fb\u53ca leader \u7684\u53d8\u66f4\u7b49\u8fd0\u7ef4\u64cd\u4f5c\u3002 \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb \u00b6 \u5728\u67b6\u6784\u56fe\u4e2d Meta Service \u7684\u5de6\u4fa7\uff0c\u4e3a Nebula Graph \u7684\u4e3b\u8981\u670d\u52a1\uff0c Nebula Graph \u91c7\u7528\u5b58\u50a8\u4e0e\u8ba1\u7b97\u5206\u79bb\u7684\u67b6\u6784\uff0c\u865a\u7ebf\u4ee5\u4e0a\u4e3a\u8ba1\u7b97\uff0c\u4ee5\u4e0b\u4e3a\u5b58\u50a8\u3002 \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\u6709\u8bf8\u591a\u4f18\u52bf\uff0c\u6700\u76f4\u63a5\u7684\u4f18\u52bf\u5c31\u662f\uff0c\u8ba1\u7b97\u5c42\u548c\u5b58\u50a8\u5c42\u53ef\u4ee5\u6839\u636e\u5404\u81ea\u7684\u60c5\u51b5\u5f39\u6027\u6269\u5bb9\u3001\u7f29\u5bb9\u3002 \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\u8fd8\u6709\u53e6\u4e00\u4e2a\u4f18\u52bf\uff1a\u4f7f\u6c34\u5e73\u6269\u5c55\u6210\u4e3a\u53ef\u80fd\u3002 \u6b64\u5916\uff0c\u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\u4f7f\u5f97 Storage Service \u53ef\u4ee5\u4e3a\u591a\u79cd\u7c7b\u578b\u7684\u4e2a\u8ba1\u7b97\u5c42\u6216\u8005\u8ba1\u7b97\u5f15\u64ce\u63d0\u4f9b\u670d\u52a1\u3002\u5f53\u524d Query Service \u662f\u4e00\u4e2a\u9ad8\u4f18\u5148\u7ea7\u7684\u8ba1\u7b97\u5c42\uff0c\u800c\u5404\u79cd\u8fed\u4ee3\u8ba1\u7b97\u6846\u67b6\u4f1a\u662f\u53e6\u5916\u4e00\u4e2a\u8ba1\u7b97\u5c42\u3002 \u65e0\u72b6\u6001\u8ba1\u7b97\u5c42 \u00b6 \u73b0\u5728\u6765\u770b\u4e0b\u8ba1\u7b97\u5c42\uff0c\u6bcf\u4e2a\u8ba1\u7b97\u8282\u70b9\u90fd\u8fd0\u884c\u7740\u4e00\u4e2a\u65e0\u72b6\u6001\u7684\u67e5\u8be2\u8ba1\u7b97\u5f15\u64ce\uff0c\u800c\u8282\u70b9\u5f7c\u6b64\u95f4\u65e0\u4efb\u4f55\u901a\u4fe1\u5173\u7cfb\u3002\u8ba1\u7b97\u8282\u70b9\u4ec5\u4ece Meta Service \u8bfb\u53d6 meta \u4fe1\u606f\uff0c\u4ee5\u53ca\u548c Storage Service \u8fdb\u884c\u4ea4\u4e92\u3002\u8fd9\u6837\u8bbe\u8ba1\u4f7f\u5f97\u8ba1\u7b97\u5c42\u96c6\u7fa4\u66f4\u5bb9\u6613\u4f7f\u7528 K8s \u7ba1\u7406\u6216\u90e8\u7f72\u5728\u4e91\u4e0a\u3002 \u8ba1\u7b97\u5c42\u7684\u8d1f\u8f7d\u5747\u8861\u6709\u4e24\u79cd\u5f62\u5f0f\uff0c\u6700\u5e38\u89c1\u7684\u65b9\u5f0f\u662f\u5728\u8ba1\u7b97\u5c42\u4e0a\u52a0\u4e00\u4e2a\u8d1f\u8f7d\u5747\u8861 (balance)\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662f\u5c06\u8ba1\u7b97\u5c42\u6240\u6709\u8282\u70b9\u7684 IP \u5730\u5740\u914d\u7f6e\u5728\u5ba2\u6237\u7aef\u4e2d\uff0c\u8fd9\u6837\u5ba2\u6237\u7aef\u53ef\u4ee5\u968f\u673a\u9009\u53d6\u8ba1\u7b97\u8282\u70b9\u8fdb\u884c\u8fde\u63a5\u3002 \u6bcf\u4e2a\u67e5\u8be2\u8ba1\u7b97\u5f15\u64ce\u90fd\u80fd\u63a5\u6536\u5ba2\u6237\u7aef\u7684\u8bf7\u6c42\uff0c\u89e3\u6790\u67e5\u8be2\u8bed\u53e5\uff0c\u751f\u6210\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u5e76\u5c06 AST \u4f20\u9012\u7ed9\u6267\u884c\u8ba1\u5212\u5668\u548c\u4f18\u5316\u5668\uff0c\u6700\u540e\u518d\u4ea4\u7531\u6267\u884c\u5668\u6267\u884c\u3002 Shared-nothing \u5206\u5e03\u5f0f\u5b58\u50a8\u5c42 \u00b6 Storage Service \u91c7\u7528 shared-nothing \u7684\u5206\u5e03\u5f0f\u67b6\u6784\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u5b58\u50a8\u8282\u70b9\u90fd\u6709\u591a\u4e2a\u672c\u5730 KV \u5b58\u50a8\u5b9e\u4f8b\u4f5c\u4e3a\u7269\u7406\u5b58\u50a8\u3002 Nebula Graph \u91c7\u7528\u591a\u6570\u6d3e\u534f\u8bae Raft \u6765\u4fdd\u8bc1\u8fd9\u4e9b KV \u5b58\u50a8\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff08\u7531\u4e8e Raft \u6bd4 Paxos \u66f4\u7b80\u6d01\uff0c\u6211\u4eec\u9009\u7528\u4e86 Raft \uff09\u3002\u5728 KVStore \u4e4b\u4e0a\u662f\u56fe\u8bed\u4e49\u5c42\uff0c\u7528\u4e8e\u5c06\u56fe\u64cd\u4f5c\u8f6c\u6362\u4e3a\u4e0b\u5c42 KV \u64cd\u4f5c\u3002 \u56fe\u6570\u636e\uff08\u70b9\u548c\u8fb9\uff09\u901a\u8fc7 Hash \u7684\u65b9\u5f0f\u5b58\u50a8\u5728\u4e0d\u540c Partition \u4e2d\u3002\u8fd9\u91cc\u7528\u7684 Hash \u51fd\u6570\u5b9e\u73b0\u5f88\u76f4\u63a5\uff0c\u5373 vertex_id \u53d6\u4f59 Partition \u6570\u3002\u5728 Nebula Graph \u4e2d\uff0cPartition \u8868\u793a\u4e00\u4e2a\u865a\u62df\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b Partition \u5206\u5e03\u5728\u6240\u6709\u7684\u5b58\u50a8\u8282\u70b9\uff0c\u5206\u5e03\u4fe1\u606f\u5b58\u50a8\u5728 Meta Service \u4e2d\uff08\u56e0\u6b64\u6240\u6709\u7684\u5b58\u50a8\u8282\u70b9\u548c\u8ba1\u7b97\u8282\u70b9\u90fd\u80fd\u83b7\u53d6\u5230\u8fd9\u4e2a\u5206\u5e03\u4fe1\u606f\uff09\u3002","title":"Nebula Graph \u7684\u6574\u4f53\u67b6\u6784"},{"location":"manual-CN/1.overview/3.design-and-architecture/1.design-and-architecture/#nebula_graph","text":"\u4e00\u4e2a\u5b8c\u6574\u7684 Nebula Graph \u90e8\u7f72\u96c6\u7fa4\u5305\u542b\u4e09\u4e2a\u670d\u52a1\uff0c\u5373 Query Service\uff0cStorage Service \u548c Meta Service\u3002\u6bcf\u4e2a\u670d\u52a1\u90fd\u6709\u5176\u5404\u81ea\u7684\u53ef\u6267\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u6587\u4ef6\u65e2\u53ef\u4ee5\u90e8\u7f72\u5728\u540c\u4e00\u7ec4\u8282\u70b9\u4e0a\uff0c\u4e5f\u53ef\u4ee5\u90e8\u7f72\u5728\u4e0d\u540c\u7684\u8282\u70b9\u4e0a\u3002","title":"Nebula Graph \u7684\u6574\u4f53\u67b6\u6784"},{"location":"manual-CN/1.overview/3.design-and-architecture/1.design-and-architecture/#meta_service","text":"\u4e0a\u56fe\u4e3a Nebula Graph \u7684\u67b6\u6784\u56fe\uff0c\u5176\u53f3\u4fa7\u4e3a Meta Service \u96c6\u7fa4\uff0c\u5b83\u91c7\u7528 leader/follower \u67b6\u6784\u3002Leader \u7531\u96c6\u7fa4\u4e2d\u6240\u6709\u7684 Meta Service \u8282\u70b9\u9009\u51fa\uff0c\u7136\u540e\u5bf9\u5916\u63d0\u4f9b\u670d\u52a1\u3002Followers \u5904\u4e8e\u5f85\u547d\u72b6\u6001\u5e76\u4ece leader \u590d\u5236\u66f4\u65b0\u7684\u6570\u636e\u3002\u4e00\u65e6 leader \u8282\u70b9 down \u6389\uff0c\u4f1a\u518d\u9009\u4e3e\u5176\u4e2d\u4e00\u4e2a follower \u6210\u4e3a\u65b0\u7684 leader\u3002 Meta Service \u4e0d\u4ec5\u8d1f\u8d23\u5b58\u50a8\u548c\u63d0\u4f9b\u56fe\u6570\u636e\u7684 meta \u4fe1\u606f\uff0c\u5982 schema\u3001partition \u4fe1\u606f\u7b49\uff0c\u8fd8\u540c\u65f6\u8d1f\u8d23\u6307\u6325\u6570\u636e\u8fc1\u79fb\u53ca leader \u7684\u53d8\u66f4\u7b49\u8fd0\u7ef4\u64cd\u4f5c\u3002","title":"Meta Service"},{"location":"manual-CN/1.overview/3.design-and-architecture/1.design-and-architecture/#_1","text":"\u5728\u67b6\u6784\u56fe\u4e2d Meta Service \u7684\u5de6\u4fa7\uff0c\u4e3a Nebula Graph \u7684\u4e3b\u8981\u670d\u52a1\uff0c Nebula Graph \u91c7\u7528\u5b58\u50a8\u4e0e\u8ba1\u7b97\u5206\u79bb\u7684\u67b6\u6784\uff0c\u865a\u7ebf\u4ee5\u4e0a\u4e3a\u8ba1\u7b97\uff0c\u4ee5\u4e0b\u4e3a\u5b58\u50a8\u3002 \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\u6709\u8bf8\u591a\u4f18\u52bf\uff0c\u6700\u76f4\u63a5\u7684\u4f18\u52bf\u5c31\u662f\uff0c\u8ba1\u7b97\u5c42\u548c\u5b58\u50a8\u5c42\u53ef\u4ee5\u6839\u636e\u5404\u81ea\u7684\u60c5\u51b5\u5f39\u6027\u6269\u5bb9\u3001\u7f29\u5bb9\u3002 \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\u8fd8\u6709\u53e6\u4e00\u4e2a\u4f18\u52bf\uff1a\u4f7f\u6c34\u5e73\u6269\u5c55\u6210\u4e3a\u53ef\u80fd\u3002 \u6b64\u5916\uff0c\u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\u4f7f\u5f97 Storage Service \u53ef\u4ee5\u4e3a\u591a\u79cd\u7c7b\u578b\u7684\u4e2a\u8ba1\u7b97\u5c42\u6216\u8005\u8ba1\u7b97\u5f15\u64ce\u63d0\u4f9b\u670d\u52a1\u3002\u5f53\u524d Query Service \u662f\u4e00\u4e2a\u9ad8\u4f18\u5148\u7ea7\u7684\u8ba1\u7b97\u5c42\uff0c\u800c\u5404\u79cd\u8fed\u4ee3\u8ba1\u7b97\u6846\u67b6\u4f1a\u662f\u53e6\u5916\u4e00\u4e2a\u8ba1\u7b97\u5c42\u3002","title":"\u5b58\u50a8\u8ba1\u7b97\u5206\u79bb"},{"location":"manual-CN/1.overview/3.design-and-architecture/1.design-and-architecture/#_2","text":"\u73b0\u5728\u6765\u770b\u4e0b\u8ba1\u7b97\u5c42\uff0c\u6bcf\u4e2a\u8ba1\u7b97\u8282\u70b9\u90fd\u8fd0\u884c\u7740\u4e00\u4e2a\u65e0\u72b6\u6001\u7684\u67e5\u8be2\u8ba1\u7b97\u5f15\u64ce\uff0c\u800c\u8282\u70b9\u5f7c\u6b64\u95f4\u65e0\u4efb\u4f55\u901a\u4fe1\u5173\u7cfb\u3002\u8ba1\u7b97\u8282\u70b9\u4ec5\u4ece Meta Service \u8bfb\u53d6 meta \u4fe1\u606f\uff0c\u4ee5\u53ca\u548c Storage Service \u8fdb\u884c\u4ea4\u4e92\u3002\u8fd9\u6837\u8bbe\u8ba1\u4f7f\u5f97\u8ba1\u7b97\u5c42\u96c6\u7fa4\u66f4\u5bb9\u6613\u4f7f\u7528 K8s \u7ba1\u7406\u6216\u90e8\u7f72\u5728\u4e91\u4e0a\u3002 \u8ba1\u7b97\u5c42\u7684\u8d1f\u8f7d\u5747\u8861\u6709\u4e24\u79cd\u5f62\u5f0f\uff0c\u6700\u5e38\u89c1\u7684\u65b9\u5f0f\u662f\u5728\u8ba1\u7b97\u5c42\u4e0a\u52a0\u4e00\u4e2a\u8d1f\u8f7d\u5747\u8861 (balance)\uff0c\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662f\u5c06\u8ba1\u7b97\u5c42\u6240\u6709\u8282\u70b9\u7684 IP \u5730\u5740\u914d\u7f6e\u5728\u5ba2\u6237\u7aef\u4e2d\uff0c\u8fd9\u6837\u5ba2\u6237\u7aef\u53ef\u4ee5\u968f\u673a\u9009\u53d6\u8ba1\u7b97\u8282\u70b9\u8fdb\u884c\u8fde\u63a5\u3002 \u6bcf\u4e2a\u67e5\u8be2\u8ba1\u7b97\u5f15\u64ce\u90fd\u80fd\u63a5\u6536\u5ba2\u6237\u7aef\u7684\u8bf7\u6c42\uff0c\u89e3\u6790\u67e5\u8be2\u8bed\u53e5\uff0c\u751f\u6210\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u5e76\u5c06 AST \u4f20\u9012\u7ed9\u6267\u884c\u8ba1\u5212\u5668\u548c\u4f18\u5316\u5668\uff0c\u6700\u540e\u518d\u4ea4\u7531\u6267\u884c\u5668\u6267\u884c\u3002","title":"\u65e0\u72b6\u6001\u8ba1\u7b97\u5c42"},{"location":"manual-CN/1.overview/3.design-and-architecture/1.design-and-architecture/#shared-nothing","text":"Storage Service \u91c7\u7528 shared-nothing \u7684\u5206\u5e03\u5f0f\u67b6\u6784\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u5b58\u50a8\u8282\u70b9\u90fd\u6709\u591a\u4e2a\u672c\u5730 KV \u5b58\u50a8\u5b9e\u4f8b\u4f5c\u4e3a\u7269\u7406\u5b58\u50a8\u3002 Nebula Graph \u91c7\u7528\u591a\u6570\u6d3e\u534f\u8bae Raft \u6765\u4fdd\u8bc1\u8fd9\u4e9b KV \u5b58\u50a8\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff08\u7531\u4e8e Raft \u6bd4 Paxos \u66f4\u7b80\u6d01\uff0c\u6211\u4eec\u9009\u7528\u4e86 Raft \uff09\u3002\u5728 KVStore \u4e4b\u4e0a\u662f\u56fe\u8bed\u4e49\u5c42\uff0c\u7528\u4e8e\u5c06\u56fe\u64cd\u4f5c\u8f6c\u6362\u4e3a\u4e0b\u5c42 KV \u64cd\u4f5c\u3002 \u56fe\u6570\u636e\uff08\u70b9\u548c\u8fb9\uff09\u901a\u8fc7 Hash \u7684\u65b9\u5f0f\u5b58\u50a8\u5728\u4e0d\u540c Partition \u4e2d\u3002\u8fd9\u91cc\u7528\u7684 Hash \u51fd\u6570\u5b9e\u73b0\u5f88\u76f4\u63a5\uff0c\u5373 vertex_id \u53d6\u4f59 Partition \u6570\u3002\u5728 Nebula Graph \u4e2d\uff0cPartition \u8868\u793a\u4e00\u4e2a\u865a\u62df\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b Partition \u5206\u5e03\u5728\u6240\u6709\u7684\u5b58\u50a8\u8282\u70b9\uff0c\u5206\u5e03\u4fe1\u606f\u5b58\u50a8\u5728 Meta Service \u4e2d\uff08\u56e0\u6b64\u6240\u6709\u7684\u5b58\u50a8\u8282\u70b9\u548c\u8ba1\u7b97\u8282\u70b9\u90fd\u80fd\u83b7\u53d6\u5230\u8fd9\u4e2a\u5206\u5e03\u4fe1\u606f\uff09\u3002","title":"Shared-nothing \u5206\u5e03\u5f0f\u5b58\u50a8\u5c42"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/","text":"\u5b58\u50a8\u5c42\u8bbe\u8ba1 \u00b6 \u6458\u8981 \u00b6 Nebula Graph \u7684 Storage \u5305\u542b\u4e24\u4e2a\u90e8\u5206\uff0c \u4e00\u662f meta \u76f8\u5173\u7684\u5b58\u50a8\uff0c \u79f0\u4e4b\u4e3a Meta Service \uff0c\u53e6\u4e00\u4e2a\u662f data \u76f8\u5173\u7684\u5b58\u50a8\uff0c \u79f0\u4e4b\u4e3a Storage Service \u3002 \u8fd9\u4e24\u4e2a\u670d\u52a1\u662f\u4e24\u4e2a\u72ec\u7acb\u7684\u8fdb\u7a0b\uff0c\u6570\u636e\u4e5f\u5b8c\u5168\u9694\u79bb\uff0c\u5f53\u7136\u90e8\u7f72\u4e5f\u662f\u5206\u522b\u90e8\u7f72\uff0c \u4e0d\u8fc7\u4e24\u8005\u6574\u4f53\u67b6\u6784\u76f8\u5dee\u4e0d\u5927\u3002 \u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u672c\u6587\u4e2d Storage Service \u4ee3\u6307 data \u7684\u5b58\u50a8\u670d\u52a1\u3002 \u67b6\u6784 \u00b6 \u56fe\u4e00 storage service \u67b6\u6784\u56fe \u5982\u56fe1 \u6240\u793a\uff0cStorage Service \u5171\u6709\u4e09\u5c42\uff0c\u6700\u5e95\u5c42\u662f Store Engine\uff0c\u5b83\u662f\u4e00\u4e2a\u5355\u673a\u7248 local store engine\uff0c\u63d0\u4f9b\u4e86\u5bf9\u672c\u5730\u6570\u636e\u7684 get / put / scan / delete \u64cd\u4f5c\uff0c\u76f8\u5173\u7684\u63a5\u53e3\u653e\u5728 KVStore/KVEngine.h \u6587\u4ef6\u91cc\u9762\uff0c\u7528\u6237\u5b8c\u5168\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u5b9a\u5236\u5f00\u53d1\u76f8\u5173 local store plugin\uff0c\u76ee\u524d Nebula Graph \u63d0\u4f9b\u4e86\u57fa\u4e8e RocksDB \u5b9e\u73b0\u7684 Store Engine\u3002 \u5728 local store engine \u4e4b\u4e0a\uff0c\u4fbf\u662f Consensus \u5c42\uff0c\u5b9e\u73b0\u4e86 Multi Group Raft\uff0c\u6bcf\u4e00\u4e2a Partition \u90fd\u5bf9\u5e94\u4e86\u4e00\u7ec4 Raft Group\uff0c\u8fd9\u91cc\u7684 Partition \u4fbf\u662f\u6570\u636e\u5206\u7247\u3002\u76ee\u524d Nebula Graph \u7684\u5206\u7247\u7b56\u7565\u91c7\u7528\u4e86 \u9759\u6001 Hash \u7684\u65b9\u5f0f\u3002\u7528\u6237\u5728\u521b\u5efa SPACE \u65f6\u9700\u6307\u5b9a Partition \u6570\uff0cPartition \u6570\u91cf\u4e00\u65e6\u8bbe\u7f6e\u4fbf\u4e0d\u53ef\u66f4\u6539\uff0c\u4e00\u822c\u6765\u8bb2\uff0cPartition \u6570\u76ee\u8981\u80fd\u6ee1\u8db3\u4e1a\u52a1\u5c06\u6765\u7684\u6269\u5bb9\u9700\u6c42\u3002 \u5728 Consensus \u5c42\u4e0a\u9762\u4e5f\u5c31\u662f Storage Service \u7684\u6700\u4e0a\u5c42\uff0c\u4fbf\u662f Storage interfaces\uff0c\u8fd9\u4e00\u5c42\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u548c\u56fe\u76f8\u5173\u7684 API\u3002 \u8fd9\u4e9b API \u8bf7\u6c42\u4f1a\u5728\u8fd9\u4e00\u5c42\u88ab\u7ffb\u8bd1\u6210\u4e00\u7ec4\u9488\u5bf9\u76f8\u5e94 Partition \u7684 kv \u64cd\u4f5c\u3002\u6b63\u662f\u8fd9\u4e00\u5c42\u7684\u5b58\u5728\uff0c\u4f7f\u5f97\u5b58\u50a8\u670d\u52a1\u53d8\u6210\u4e86\u771f\u6b63\u7684\u56fe\u5b58\u50a8\uff0c\u5426\u5219\uff0cStorage Service \u53ea\u662f\u4e00\u4e2a kv \u5b58\u50a8\u3002\u800c Nebula Graph \u6ca1\u628a kv \u4f5c\u4e3a\u4e00\u4e2a\u670d\u52a1\u5355\u72ec\u63d0\u51fa\uff0c\u5176\u6700\u4e3b\u8981\u7684\u539f\u56e0\u4fbf\u662f\u56fe\u67e5\u8be2\u8fc7\u7a0b\u4e2d\u4f1a\u6d89\u53ca\u5230\u5927\u91cf\u8ba1\u7b97\uff0c\u8fd9\u4e9b\u8ba1\u7b97\u5f80\u5f80\u9700\u8981\u4f7f\u7528\u56fe\u7684 schema\uff0c\u800c kv \u5c42\u662f\u6ca1\u6709\u6570\u636e schema \u6982\u5ff5\uff0c\u8fd9\u6837\u8bbe\u8ba1\u4f1a\u6bd4\u8f83\u5bb9\u6613\u5b9e\u73b0\u8ba1\u7b97\u4e0b\u63a8\u3002 Schema & Partition \u00b6 \u6570\u636e\u7ed3\u6784\u4e0a\uff0c\u56fe\u7684\u4e3b\u8981\u6570\u636e\u662f\u70b9\u548c\u8fb9\u3002\u4f46 Nebula Graph \u5b58\u50a8\u7684\u662f\u5c5e\u6027\u56fe\uff1a\u9664\u4e86\u70b9\u548c\u8fb9\u4ee5\u5916\uff0c\u8fd8\u5b58\u50a8\u4e86\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u4ee5\u4fbf\u66f4\u9ad8\u6548\u5730\u4f7f\u7528\u5c5e\u6027\u8fc7\u6ee4\u3002 \u5bf9\u4e8e\u70b9\u6765\u8bf4\uff0c Nebula Graph \u4f7f\u7528\u4e0d\u540c\u7684 Tag \u8868\u793a\u4e0d\u540c\u7c7b\u578b\u7684\u70b9\uff0c\u540c\u4e00\u4e2a VertexID \u53ef\u4ee5\u5173\u8054\u591a\u4e2a Tag\uff0c\u800c\u6bcf\u4e00\u4e2a Tag \u90fd\u6709\u81ea\u5df1\u5bf9\u5e94\u7684\u5c5e\u6027\u3002\u5bf9\u5e94\u5230 kv \u5b58\u50a8\u91cc\u9762\uff0c Nebula Graph \u4f7f\u7528 vertexID + TagID \u6765\u8868\u793a key, \u628a\u76f8\u5173\u7684\u5c5e\u6027\u7f16\u7801\u540e\u653e\u5728 value \u91cc\u9762\uff0c\u5177\u4f53 key \u7684 format \u5982\u56fe2 \u6240\u793a\uff1a \u56fe\u4e8c Vertex Key Format Type : 1 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a key \u7c7b\u578b\uff0c\u5f53\u524d\u7684\u7c7b\u578b\u6709 data, index, system \u7b49 Part ID : 3 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u6570\u636e\u5206\u7247 Partition\uff0c\u6b64\u5b57\u6bb5\u4e3b\u8981\u7528\u4e8e Partition \u91cd\u65b0\u5206\u5e03 (balance) \u65f6\u65b9\u4fbf\u6839\u636e\u524d\u7f00\u626b\u63cf\u6574\u4e2a Partition \u6570\u636e Vertex ID : 8 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u70b9\u7684 ID Tag ID : 4 \u4e2a\u5b57\u8282, \u7528\u6765\u8868\u793a\u5173\u8054\u7684\u67d0\u4e2a tag Timestamp : 8 \u4e2a\u5b57\u8282\uff0c\u5bf9\u7528\u6237\u4e0d\u53ef\u89c1\uff0c\u672a\u6765\u5b9e\u73b0\u5206\u5e03\u5f0f\u4e8b\u52a1 (MVCC) \u65f6\u4f7f\u7528 \u5728\u4e00\u4e2a\u56fe\u4e2d\uff0c\u6bcf\u4e00\u6761\u903b\u8f91\u610f\u4e49\u4e0a\u7684\u8fb9\uff0c\u5728 Nebula Graph \u4e2d\u4f1a\u5efa\u6a21\u6210\u4e24\u4e2a\u72ec\u7acb\u7684 key-value\uff0c\u5206\u522b\u79f0\u4e3a out-key \u548c in-key\u3002out-key \u4e0e\u8fd9\u6761\u8fb9\u6240\u5bf9\u5e94\u7684\u8d77\u70b9\u5b58\u50a8\u5728\u540c\u4e00\u4e2a partition \u4e0a\uff0cin-key \u4e0e\u8fd9\u6761\u8fb9\u6240\u5bf9\u5e94\u7684\u7ec8\u70b9\u5b58\u50a8\u5728\u540c\u4e00\u4e2apartition \u4e0a\u3002\u901a\u5e38\u6765\u8bf4\uff0cout-key \u548c in-key \u4f1a\u5206\u5e03\u5728\u4e24\u4e2a\u4e0d\u540c\u7684 Partition \u4e2d\u3002 \u4e24\u4e2a\u70b9\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u591a\u79cd\u7c7b\u578b\u7684\u8fb9\uff0c Nebula Graph \u7528 Edge Type \u6765\u8868\u793a\u8fb9\u7c7b\u578b\u3002\u800c\u540c\u4e00\u7c7b\u578b\u7684\u8fb9\u53ef\u80fd\u5b58\u5728\u591a\u6761\uff0c\u6bd4\u5982\uff0c\u5b9a\u4e49\u4e00\u4e2a edge type \"\u8f6c\u8d26\"\uff0c\u7528\u6237 A \u53ef\u80fd\u591a\u6b21\u8f6c\u8d26\u7ed9 B\uff0c \u6240\u4ee5 Nebula Graph \u53c8\u589e\u52a0\u4e86\u4e00\u4e2a Rank \u5b57\u6bb5\u6765\u505a\u533a\u5206\uff0c\u8868\u793a A \u5230 B \u4e4b\u95f4\u591a\u6b21\u8f6c\u8d26\u8bb0\u5f55\u3002 Edge key \u7684 format \u5982\u56fe 3 \u6240\u793a\uff1a \u56fe\u4e09 Edge Key Format Type \uff1a1 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a key \u7684\u7c7b\u578b\uff0c\u5f53\u524d\u7684\u7c7b\u578b\u6709 data, index, system \u7b49\u3002 Part ID \uff1a3 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u6570\u636e\u5206\u7247 Partition\uff0c\u6b64\u5b57\u6bb5\u4e3b\u8981\u7528\u4e8e Partition \u91cd\u65b0\u5206\u5e03 (balance) \u65f6\u65b9\u4fbf\u6839\u636e\u524d\u7f00\u626b\u63cf\u6574\u4e2a Partition \u6570\u636e Vertex ID \uff1a8 \u4e2a\u5b57\u8282\uff0c\u51fa\u8fb9\u91cc\u9762\u7528\u6765\u8868\u793a\u6e90\u70b9\u7684 ID\uff0c \u5165\u8fb9\u91cc\u9762\u8868\u793a\u76ee\u6807\u70b9\u7684 ID\u3002 Edge Type \uff1a4 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u8fd9\u6761\u8fb9\u7684\u7c7b\u578b\uff0c\u5982\u679c\u5927\u4e8e 0 \u8868\u793a\u51fa\u8fb9\uff0c\u5c0f\u4e8e 0 \u8868\u793a\u5165\u8fb9\u3002 Rank \uff1a8 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u5904\u7406\u540c\u4e00\u79cd\u7c7b\u578b\u7684\u8fb9\u5b58\u5728\u591a\u6761\u7684\u60c5\u51b5\u3002\u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u8fdb\u884c\u8bbe\u7f6e\uff0c\u8fd9\u4e2a\u5b57\u6bb5\u53ef \u5b58\u653e\u4ea4\u6613\u65f6\u95f4 \u3001 \u4ea4\u6613\u6d41\u6c34\u53f7 \u3001\u6216 \u67d0\u4e2a\u6392\u5e8f Vertex ID \uff1a8 \u4e2a\u5b57\u8282\uff0c\u51fa\u8fb9\u91cc\u9762\u7528\u6765\u8868\u793a\u76ee\u6807\u70b9\u7684 ID\uff0c \u5165\u8fb9\u91cc\u9762\u8868\u793a\u6e90\u70b9\u7684 ID\u3002 Timestamp \uff1a8 \u4e2a\u5b57\u8282\uff0c\u5bf9\u7528\u6237\u4e0d\u53ef\u89c1\uff0c\u672a\u6765\u5b9e\u73b0\u5206\u5e03\u5f0f\u505a\u4e8b\u52a1\u7684\u65f6\u5019\u4f7f\u7528\u3002 \u9488\u5bf9 Edge Type \u7684\u503c\uff0c\u82e5\u5982\u679c\u5927\u4e8e 0 \u8868\u793a\u51fa\u8fb9\uff0c\u5219\u5bf9\u5e94\u7684 edge key format \u5982\u56fe4 \u6240\u793a\uff1b\u82e5 Edge Type \u7684\u503c\u5c0f\u4e8e 0\uff0c\u5219\u5bf9\u5e94\u7684 edge key format \u5982\u56fe5 \u6240\u793a \u56fe4 \u51fa\u8fb9\u7684 Key Format \u56fe5 \u5165\u8fb9\u7684 Key Format \u5bf9\u4e8e\u70b9\u6216\u8fb9\u7684\u5c5e\u6027\u4fe1\u606f\uff0c\u6709\u5bf9\u5e94\u7684\u4e00\u7ec4 kv pairs\uff0c Nebula Graph \u5c06\u5b83\u4eec\u7f16\u7801\u540e\u5b58\u5728\u5bf9\u5e94\u7684 value \u91cc\u3002\u7531\u4e8e Nebula Graph \u4f7f\u7528\u5f3a\u7c7b\u578b schema\uff0c\u6240\u4ee5\u5728\u89e3\u7801\u4e4b\u524d\uff0c\u9700\u8981\u5148\u53bb Meta Service \u4e2d\u53d6\u5177\u4f53\u7684 schema \u4fe1\u606f\u3002\u53e6\u5916\uff0c\u4e3a\u4e86\u652f\u6301\u5728\u7ebf\u53d8\u66f4 schema\uff0c\u5728\u7f16\u7801\u5c5e\u6027\u65f6\uff0c\u4f1a\u52a0\u5165\u5bf9\u5e94\u7684 schema \u7248\u672c\u4fe1\u606f\u3002 \u6570\u636e\u7684\u5206\u7247\u65b9\u5f0f\u4e3a\u5bf9 Vertex ID \u53d6\u6a21 \u3002\u901a\u8fc7\u5bf9 Vertex ID \u53d6\u6a21\uff0c\u540c\u4e00\u4e2a\u70b9\u7684\u6240\u6709 \u51fa\u8fb9 \uff0c \u5165\u8fb9 \u4ee5\u53ca\u8fd9\u4e2a\u70b9\u4e0a\u6240\u6709\u5173\u8054\u7684 Tag \u4fe1\u606f \u90fd\u4f1a\u88ab\u5206\u5230\u540c\u4e00\u4e2a Partition\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5927\u5927\u5730\u63d0\u5347\u4e86\u67e5\u8be2\u6548\u7387\u3002\u5bf9\u4e8e\u5728\u7ebf\u56fe\u67e5\u8be2\u6765\u8bb2\uff0c\u6700\u5e38\u89c1\u7684\u64cd\u4f5c\u4fbf\u662f\u4ece\u4e00\u4e2a\u70b9\u5f00\u59cb\u5411\u5916 BFS\uff08\u5e7f\u5ea6\u4f18\u5148\uff09\u62d3\u5c55\uff0c\u4e8e\u662f\u62ff\u4e00\u4e2a\u70b9\u7684\u51fa\u8fb9\u6216\u8005\u5165\u8fb9\u662f\u6700\u57fa\u672c\u7684\u64cd\u4f5c\uff0c\u800c\u8fd9\u4e2a\u64cd\u4f5c\u7684\u6027\u80fd\u4e5f\u51b3\u5b9a\u4e86\u6574\u4e2a\u904d\u5386\u7684\u6027\u80fd\u3002BFS \u4e2d\u53ef\u80fd\u4f1a\u51fa\u73b0\u6309\u7167\u67d0\u4e9b\u5c5e\u6027\u8fdb\u884c\u526a\u679d\u7684\u60c5\u51b5\uff0c Nebula Graph \u901a\u8fc7\u5c06\u5c5e\u6027\u4e0e\u70b9\u8fb9\u5b58\u5728\u4e00\u8d77\uff0c\u6765\u4fdd\u8bc1\u6574\u4e2a\u64cd\u4f5c\u7684\u9ad8\u6548\u3002\u5728\u5b9e\u9645\u7684\u573a\u666f\u4e2d\uff0c\u5927\u90e8\u5206\u60c5\u51b5\u90fd\u662f\u5c5e\u6027\u56fe\uff0c\u5e76\u4e14\u5b9e\u9645\u4e2d\u7684 BFS \u4e5f\u9700\u8981\u8fdb\u884c\u5927\u91cf\u7684\u526a\u679d\u64cd\u4f5c\u3002 KVStore \u00b6 \u5bf9\u4e8eKVStore\u7684\u8981\u6c42\uff1a \u6027\u80fd \uff1b \u4ee5 library \u7684\u5f62\u5f0f\u63d0\u4f9b \uff1a\u5bf9\u4e8e\u5f3a schema \u7684 Nebula Graph \u6765\u8bb2\uff0c\u8ba1\u7b97\u4e0b\u63a8\u9700\u8981 schema \u4fe1\u606f\uff0c\u800c\u8ba1\u7b97\u4e0b\u63a8\u5b9e\u73b0\u7684\u597d\u574f\uff0c\u662f Nebula Graph \u662f\u5426\u9ad8\u6548\u7684\u5173\u952e\uff1b \u6570\u636e\u5f3a\u4e00\u81f4 \uff1a\u8fd9\u662f\u5206\u5e03\u5f0f\u7cfb\u7edf\u51b3\u5b9a\u7684\uff1b \u4f7f\u7528 C++\u5b9e\u73b0 \uff1a\u8fd9\u7531\u56e2\u961f\u7684\u6280\u672f\u7279\u70b9\u51b3\u5b9a\uff1b \u57fa\u4e8e\u4e0a\u8ff0\u8981\u6c42\uff0c Nebula Graph \u5b9e\u73b0\u4e86\u81ea\u5df1\u7684 KVStore\u3002\u5f53\u7136\uff0c\u5bf9\u4e8e\u6027\u80fd\u5b8c\u5168\u4e0d\u654f\u611f\u4e14\u4e0d\u592a\u5e0c\u671b\u642c\u8fc1\u6570\u636e\u7684\u7528\u6237\u6765\u8bf4\uff0c Nebula Graph \u4e5f\u63d0\u4f9b\u4e86\u6574\u4e2a KVStore \u5c42\u7684 plugin\uff0c\u76f4\u63a5\u5c06 Storage Service \u642d\u5efa\u5728\u7b2c\u4e09\u65b9\u7684 KVStore \u4e0a\u9762\uff0c\u76ee\u524d\u5b98\u65b9\u63d0\u4f9b\u7684\u662f HBase \u7684 plugin\u3002 Nebula Graph KVStore \u4e3b\u8981\u91c7\u7528 RocksDB \u4f5c\u4e3a\u672c\u5730\u7684\u5b58\u50a8\u5f15\u64ce\uff0c\u5bf9\u4e8e\u591a\u786c\u76d8\u673a\u5668\uff0c\u4e3a\u4e86\u5145\u5206\u5229\u7528\u591a\u786c\u76d8\u7684\u5e76\u53d1\u80fd\u529b\uff0c Nebula Graph \u652f\u6301\u81ea\u5df1\u7ba1\u7406\u591a\u5757\u76d8\uff0c\u7528\u6237\u53ea\u9700\u914d\u7f6e\u591a\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u76ee\u5f55\u5373\u53ef\u3002 \u5206\u5e03\u5f0f KVStore \u7684\u7ba1\u7406\u7531 Meta Service \u6765\u7edf\u4e00\u8c03\u5ea6\uff0c\u5b83\u8bb0\u5f55\u4e86\u6240\u6709 Partition \u7684\u5206\u5e03\u60c5\u51b5\uff0c\u4ee5\u53ca\u5f53\u524d\u673a\u5668\u7684\u72b6\u6001\uff0c\u5f53\u7528\u6237\u589e\u51cf\u673a\u5668\u65f6\uff0c\u53ea\u9700\u8981\u901a\u8fc7 console \u8f93\u5165\u76f8\u5e94\u7684\u6307\u4ee4\uff0cMeta Service \u4fbf\u80fd\u591f\u751f\u6210\u6574\u4e2a balance plan \u5e76\u6267\u884c\u3002\uff08\u4e4b\u6240\u4ee5\u6ca1\u6709\u91c7\u7528\u5b8c\u5168\u81ea\u52a8 balance \u7684\u65b9\u5f0f\uff0c\u4e3b\u8981\u662f\u4e3a\u4e86\u51cf\u5c11\u6570\u636e\u642c\u8fc1\u5bf9\u4e8e\u7ebf\u4e0a\u670d\u52a1\u7684\u5f71\u54cd\uff0cbalance \u7684\u65f6\u673a\u7531\u7528\u6237\u81ea\u5df1\u63a7\u5236\uff0c\u901a\u5e38\u4f1a\u5728\u4e1a\u52a1\u4f4e\u8c37\u8fdb\u884c\u3002\uff09 \u4e3a\u4e86\u65b9\u4fbf\u5bf9\u4e8e WAL \u8fdb\u884c\u5b9a\u5236\uff0c Nebula Graph KVStore \u5b9e\u73b0\u4e86\u81ea\u5df1\u7684 WAL \u6a21\u5757\uff0c\u6bcf\u4e2a partition \u90fd\u6709\u81ea\u5df1\u7684 WAL\uff0c\u8fd9\u6837\u5728\u8ffd\u6570\u636e\u65f6\uff0c\u4e0d\u9700\u8981\u8fdb\u884c wal split \u64cd\u4f5c\uff0c \u66f4\u52a0\u9ad8\u6548\u3002 \u53e6\u5916\uff0c\u4e3a\u4e86\u5b9e\u73b0\u4e00\u4e9b\u7279\u6b8a\u7684\u64cd\u4f5c\uff0c\u4e13\u95e8\u5b9a\u4e49\u4e86 Command Log \u8fd9\u4e2a\u7c7b\u522b\uff0c\u8fd9\u4e9b log \u53ea\u4e3a\u4e86\u4f7f\u7528 Raft \u6765\u901a\u77e5\u6240\u6709 replica \u6267\u884c\u67d0\u4e00\u4e2a\u7279\u5b9a\u64cd\u4f5c\uff0c\u5e76\u6ca1\u6709\u771f\u6b63\u7684\u6570\u636e\u3002\u9664\u4e86 Command Log \u5916\uff0c Nebula Graph \u8fd8\u63d0\u4f9b\u4e86\u4e00\u7c7b\u65e5\u5fd7\u6765\u5b9e\u73b0\u9488\u5bf9\u67d0\u4e2a Partition \u7684 atomic operation\uff0c\u4f8b\u5982 CAS\uff0cread-modify-write, \u5b83\u5145\u5206\u5229\u7528\u4e86Raft \u4e32\u884c\u7684\u7279\u6027\u3002 \u5173\u4e8e\u591a\u56fe\u7a7a\u95f4\uff08space\uff09\u7684\u652f\u6301\uff1a\u4e00\u4e2a Nebula Graph KVStore \u96c6\u7fa4\u53ef\u4ee5\u652f\u6301\u591a\u4e2a space\uff0c\u6bcf\u4e2a space \u53ef\u8bbe\u7f6e\u81ea\u5df1\u7684 partition \u6570\u548c replica \u6570\u3002\u4e0d\u540c space \u5728\u7269\u7406\u4e0a\u662f\u5b8c\u5168\u9694\u79bb\u7684\uff0c\u800c\u4e14\u5728\u540c\u4e00\u4e2a\u96c6\u7fa4\u4e0a\u7684\u4e0d\u540c space \u53ef\u652f\u6301\u4e0d\u540c\u7684 store engine \u53ca\u5206\u7247\u7b56\u7565\u3002 Raft \u00b6 \u4f5c\u4e3a\u4e00\u4e2a\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0cKVStore \u7684 replication\u3001scale out \u7b49\u529f\u80fd\u9700 Raft \u7684\u652f\u6301\u3002\u4e3b\u8981\u4ecb\u7ecd Nebula Graph Raft \u7684\u4e00\u4e9b\u7279\u70b9\u4ee5\u53ca\u5de5\u7a0b\u5b9e\u73b0\u3002 Multi Raft Group \u00b6 \u7531\u4e8e Raft \u7684\u65e5\u5fd7\u4e0d\u5141\u8bb8\u7a7a\u6d1e\uff0c\u51e0\u4e4e\u6240\u6709\u7684\u5b9e\u73b0\u90fd\u4f1a\u91c7\u7528 Multi Raft Group \u6765\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u56e0\u6b64 partition \u7684\u6570\u76ee\u51e0\u4e4e\u51b3\u5b9a\u4e86\u6574\u4e2a Raft Group \u7684\u6027\u80fd\u3002\u4f46\u8fd9\u4e5f\u5e76\u4e0d\u662f\u8bf4 Partition \u7684\u6570\u76ee\u8d8a\u591a\u8d8a\u597d\uff1a\u6bcf\u4e00\u4e2a Raft Group \u5185\u90e8\u90fd\u8981\u5b58\u50a8\u4e00\u7cfb\u5217\u7684\u72b6\u6001\u4fe1\u606f\uff0c\u5e76\u4e14\u6bcf\u4e00\u4e2a Raft Group \u6709\u81ea\u5df1\u7684 WAL \u6587\u4ef6\uff0c\u56e0\u6b64 Partition \u6570\u76ee\u592a\u591a\u4f1a\u589e\u52a0\u5f00\u9500\u3002\u6b64\u5916\uff0c\u5f53 Partition \u592a\u591a\u65f6\uff0c \u5982\u679c\u8d1f\u8f7d\u6ca1\u6709\u8db3\u591f\u9ad8\uff0cbatch \u64cd\u4f5c\u662f\u6ca1\u6709\u610f\u4e49\u7684\u3002\u6bd4\u5982\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6709 1\u4e07 TPS \u7684\u7ebf\u4e0a\u7cfb\u7edf\uff0c\u5373\u4f7f\u5b83\u7684\u6bcf\u53f0\u673a\u5668\u4e0a partition \u7684\u6570\u76ee\u8d85\u8fc7 1\u4e07\uff0c\u4f46\u5f88\u6709\u53ef\u80fd\u6bcf\u4e2a partition TPS \u53ea\u6709 1\uff0c\u8fd9\u6837 batch \u64cd\u4f5c\u5c31\u5931\u53bb\u4e86\u610f\u4e49\uff0c\u8fd8\u589e\u52a0\u4e86 CPU \u5f00\u9500\u3002 \u5b9e\u73b0 Multi Raft Group \u7684\u6700\u5173\u952e\u4e4b\u5904\u6709\u4e24\u70b9\uff0c \u7b2c\u4e00\u662f\u5171\u4eab Transport \u5c42 \uff0c\u56e0\u4e3a\u6bcf\u4e00\u4e2a Raft Group \u5185\u90e8\u90fd\u9700\u8981\u5411\u5bf9\u5e94\u7684 peer \u53d1\u9001\u6d88\u606f\uff0c\u5982\u679c\u4e0d\u80fd\u5171\u4eab Transport \u5c42\uff0c\u8fde\u63a5\u7684\u5f00\u9500\u5de8\u5927\uff1b \u7b2c\u4e8c\u662f\u7ebf\u7a0b\u6a21\u578b \uff0cMulti Raft Group \u4e00\u5b9a\u8981\u5171\u4eab\u4e00\u7ec4\u7ebf\u7a0b\u6c60\uff0c\u5426\u5219\u4f1a\u9020\u6210\u7cfb\u7edf\u7684\u7ebf\u7a0b\u6570\u76ee\u8fc7\u591a\uff0c\u5bfc\u81f4\u5927\u91cf\u7684 context switch \u5f00\u9500\u3002 Batch \u00b6 \u5bf9\u4e8e\u6bcf\u4e2a Partition\u6765\u8bf4\uff0c\u7531\u4e8e\u4e32\u884c\u5199 WAL\uff0c\u4e3a\u4e86\u63d0\u9ad8\u541e\u5410\uff0c\u505a batch \u662f\u5341\u5206\u5fc5\u8981\u7684\u3002Nebula Graph \u5229\u7528\u6bcf\u4e2a part \u4e32\u884c\u7684\u7279\u70b9\uff0c\u505a\u4e86\u4e00\u4e9b\u7279\u6b8a\u7c7b\u578b\u7684 WAL\uff0c\u5e26\u6765\u4e86\u4e00\u4e9b\u5de5\u7a0b\u4e0a\u7684\u6311\u6218\u3002 \u4e3e\u4e2a\u4f8b\u5b50\uff0cNebula Graph \u5229\u7528 WAL \u5b9e\u73b0\u4e86\u65e0\u9501\u7684 CAS \u64cd\u4f5c\uff0c\u800c\u6bcf\u4e2a CAS \u64cd\u4f5c\u9700\u8981\u4e4b\u524d\u7684 WAL \u5168\u90e8 commit \u4e4b\u540e\u624d\u80fd\u6267\u884c\uff0c\u6240\u4ee5\u5bf9\u4e8e\u4e00\u4e2a batch\uff0c\u5982\u679c\u4e2d\u95f4\u5939\u6742\u4e86\u51e0\u6761 CAS \u7c7b\u578b\u7684 WAL, \u8fd8\u9700\u8981\u628a\u8fd9\u4e2a batch \u5206\u6210\u7c92\u5ea6\u66f4\u5c0f\u7684\u51e0\u4e2a group\uff0cgroup \u4e4b\u95f4\u4fdd\u8bc1\u4e32\u884c\u3002\u8fd8\u6709\uff0ccommand \u7c7b\u578b\u7684 WAL \u9700\u8981\u5b83\u540e\u9762\u7684 WAL \u5728\u5176 commit \u4e4b\u540e\u624d\u80fd\u6267\u884c\uff0c\u6240\u4ee5\u6574\u4e2a batch \u5212\u5206 group \u7684\u64cd\u4f5c\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u6bd4\u8f83\u6709\u7279\u8272\u3002 Learner \u00b6 Learner \u8fd9\u4e2a\u89d2\u8272\u7684\u5b58\u5728\u4e3b\u8981\u662f\u4e3a\u4e86 \u5e94\u5bf9\u6269\u5bb9 \u65f6\uff0c\u65b0\u673a\u5668\u9700\u8981\u201c\u8ffd\u201d\u76f8\u5f53\u957f\u4e00\u6bb5\u65f6\u95f4\u7684\u6570\u636e\uff0c\u800c\u8fd9\u6bb5\u65f6\u95f4\u6709\u53ef\u80fd\u4f1a\u53d1\u751f\u610f\u5916\u3002\u5982\u679c\u76f4\u63a5\u4ee5 follower \u7684\u8eab\u4efd\u5f00\u59cb\u8ffd\u6570\u636e\uff0c\u5c31\u4f1a\u4f7f\u5f97\u6574\u4e2a\u96c6\u7fa4\u7684 HA \u80fd\u529b\u4e0b\u964d\u3002 Nebula Graph \u91cc\u9762 learner \u7684\u5b9e\u73b0\u5c31\u662f\u91c7\u7528\u4e86\u4e0a\u9762\u63d0\u5230\u7684 command wal\u3002 Leader \u5728\u5199 wal \u65f6\u5982\u679c\u78b0\u5230 add learner \u7684 command\uff0c \u5c31\u4f1a\u5c06 learner \u52a0\u5165\u81ea\u5df1\u7684 peers\uff0c\u5e76\u628a\u5b83\u6807\u8bb0\u4e3a learner\uff0c\u8fd9\u6837\u5728\u7edf\u8ba1\u591a\u6570\u6d3e\u7684\u65f6\u5019\uff0c\u5c31\u4e0d\u4f1a\u7b97\u4e0a learner\uff0c\u4f46\u662f\u65e5\u5fd7\u8fd8\u662f\u4f1a\u7167\u5e38\u53d1\u9001\u7ed9\u5b83\u4eec\u3002\u5f53\u7136 learner \u4e5f\u4e0d\u4f1a\u4e3b\u52a8\u53d1\u8d77\u9009\u4e3e\u3002 Transfer Leadership \u00b6 Transfer leadership \u8fd9\u4e2a\u64cd\u4f5c\u5bf9\u4e8e balance \u6765\u8bb2\u81f3\u5173\u91cd\u8981\uff0c\u5f53\u628a\u67d0\u4e2a Partition \u4ece\u4e00\u53f0\u673a\u5668\u632a\u5230\u53e6\u4e00\u53f0\u673a\u5668\u65f6\uff0c\u9996\u5148\u4fbf\u4f1a\u68c0\u67e5 source \u662f\u4e0d\u662f leader\uff0c\u5982\u679c\u662f\u7684\u8bdd\uff0c\u9700\u8981\u5148\u628a\u4ed6\u632a\u5230\u53e6\u5916\u7684 peer \u4e0a\u9762\uff1b\u5728\u642c\u8fc1\u6570\u636e\u5b8c\u6bd5\u4e4b\u540e\uff0c\u901a\u5e38\u8fd8\u8981\u628a leader \u8fdb\u884c\u4e00\u6b21 balance\uff0c\u8fd9\u6837\u6bcf\u53f0\u673a\u5668\u627f\u62c5\u7684\u8d1f\u8f7d\u4e5f\u80fd\u4fdd\u8bc1\u5747\u8861\u3002 \u5b9e\u73b0 transfer leadership\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f leader \u653e\u5f03\u81ea\u5df1\u7684 leadership\uff0c\u548c follower \u5f00\u59cb\u8fdb\u884c leader election \u7684\u65f6\u673a\u3002\u5bf9\u4e8e leader \u6765\u8bb2\uff0c\u5f53 transfer leadership command \u5728 commit \u7684\u65f6\u5019\uff0c\u5b83\u653e\u5f03 leadership\uff1b\u800c\u5bf9\u4e8e follower \u6765\u8bb2\uff0c\u5f53\u6536\u5230\u6b64 command \u7684\u65f6\u5019\u5c31\u8981\u5f00\u59cb\u8fdb\u884c leader election\uff0c \u8fd9\u5957\u5b9e\u73b0\u8981\u548c Raft \u672c\u8eab\u7684 leader election \u8d70\u4e00\u5957\u8def\u5f84\uff0c\u5426\u5219\u5f88\u5bb9\u6613\u51fa\u73b0\u4e00\u4e9b\u96be\u4ee5\u5904\u7406\u7684 corner case\u3002 Membership change \u00b6 \u4e3a\u4e86\u907f\u514d\u8111\u88c2\uff0c\u5f53\u4e00\u4e2a Raft Group \u7684\u6210\u5458\u53d1\u751f\u53d8\u5316\u65f6\uff0c\u9700\u8981\u6709\u4e00\u4e2a\u4e2d\u95f4\u72b6\u6001\uff0c \u8fd9\u4e2a\u72b6\u6001\u4e0b old group \u7684\u591a\u6570\u6d3e\u4e0e new group \u7684\u591a\u6570\u6d3e\u603b\u662f\u6709 overlap\uff0c\u8fd9\u6837\u5c31\u9632\u6b62\u4e86 old group \u6216\u8005\u65b0 group \u5355\u65b9\u9762\u505a\u51fa\u51b3\u5b9a\uff0c\u8fd9\u5c31\u662f \u8bba\u6587 \u4e2d\u63d0\u5230\u7684 joint consensus \u3002\u4e3a\u4e86\u66f4\u52a0\u7b80\u5316\uff0cDiego Ongaro \u5728\u81ea\u5df1\u7684\u535a\u58eb\u8bba\u6587\u4e2d\u63d0\u51fa \u6bcf\u6b21\u589e\u51cf\u4e00\u4e2a peer \u7684\u65b9\u5f0f \uff0c \u4ee5\u4fdd\u8bc1 old group \u7684\u591a\u6570\u6d3e\u603b\u662f\u4e0e new group \u7684\u591a\u6570\u6d3e\u6709 overlap \u3002 Nebula Graph \u7684\u5b9e\u73b0\u4e5f\u91c7\u7528\u4e86\u8fd9\u4e2a\u65b9\u5f0f\uff0c\u53ea\u4e0d\u8fc7 add member \u4e0e remove member \u7684\u5b9e\u73b0\u6709\u6240\u533a\u522b\uff0c\u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f\u53ef\u4ee5\u53c2\u8003 Raft Part class \u91cc\u9762 addPeer/removePeer \u7684\u5b9e\u73b0\u3002 Snapshot \u00b6 Snapshot \u5982\u4f55\u4e0e Raft \u6d41\u7a0b\u7ed3\u5408\u8d77\u6765\uff0c \u8bba\u6587 \u4e2d\u5e76\u6ca1\u6709\u7ec6\u8bb2\uff0c\u4f46\u662f\u8fd9\u4e00\u90e8\u5206\u662f\u4e00\u4e2a Raft \u5b9e\u73b0\u91cc\u6700\u5bb9\u6613\u51fa\u9519\u7684\u5730\u65b9\uff0c\u56e0\u4e3a\u8fd9\u91cc\u4f1a\u4ea7\u751f\u5927\u91cf\u7684 corner case\u3002 \u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5f53 leader \u53d1\u9001 snapshot \u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c leader \u53d1\u751f\u4e86\u53d8\u5316\uff0c\u8be5\u600e\u4e48\u529e\uff1f \u8fd9\u4e2a\u65f6\u5019\uff0c\u6709\u53ef\u80fd follower \u53ea\u63a5\u5230\u4e86\u4e00\u534a\u7684 snapshot \u6570\u636e\u3002 \u6240\u4ee5\u9700\u8981\u6709\u4e00\u4e2a Partition \u6570\u636e\u6e05\u7406\u8fc7\u7a0b\uff0c\u7531\u4e8e\u591a\u4e2a Partition \u5171\u4eab\u4e00\u4efd\u5b58\u50a8\uff0c\u56e0\u6b64\u5982\u4f55\u6e05\u7406\u6570\u636e\u53c8\u662f\u4e00\u4e2a\u5f88\u9ebb\u70e6\u7684\u95ee\u9898\u3002\u53e6\u5916\uff0csnapshot \u8fc7\u7a0b\u4e2d\uff0c\u4f1a\u4ea7\u751f\u5927\u91cf\u7684 IO\uff0c\u4e3a\u4e86\u6027\u80fd\u8003\u8651\uff0c\u4e0d\u5e0c\u671b\u8fd9\u4e2a\u8fc7\u7a0b\u4e0e\u6b63\u5e38\u7684 Raft \u5171\u7528\u4e00\u4e2a IO threadPool\uff0c\u5e76\u4e14\u6574\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u8fd8\u9700\u8981\u4f7f\u7528\u5927\u91cf\u7684\u5185\u5b58\uff0c\u5982\u4f55\u4f18\u5316\u5185\u5b58\u7684\u4f7f\u7528\uff0c\u5bf9\u4e8e\u6027\u80fd\u5341\u5206\u5173\u952e\u3002\u7531\u4e8e\u7bc7\u5e45\u539f\u56e0\uff0c\u5e76\u4e0d\u4f1a\u5728\u672c\u6587\u5bf9\u8fd9\u4e9b\u95ee\u9898\u5c55\u5f00\u8bb2\u8ff0\uff0c\u53ef\u4ee5\u53c2\u8003 SnapshotManager \u7684\u5b9e\u73b0\u3002 Storage Service \u00b6 \u5728 KVStore \u7684\u63a5\u53e3\u4e4b\u4e0a\uff0cNebula Graph \u5c01\u88c5\u6709\u56fe\u8bed\u4e49\u63a5\u53e3\uff0c\u4e3b\u8981\u7684\u63a5\u53e3\u5982\u4e0b\uff1a getNeighbors \uff1a\u67e5\u8be2\u4e00\u6279\u70b9\u7684\u51fa\u8fb9\u6216\u8005\u5165\u8fb9\uff0c\u8fd4\u56de\u8fb9\u4ee5\u53ca\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u5e76\u4e14\u9700\u8981\u652f\u6301\u6761\u4ef6\u8fc7\u6ee4\uff1b Insert vertex/edge \uff1a\u63d2\u5165\u4e00\u6761\u70b9\u6216\u8005\u8fb9\u53ca\u5176\u5c5e\u6027\uff1b getProps \uff1a\u53d6\u4e00\u4e2a\u70b9\u6216\u8005\u4e00\u6761\u8fb9\u7684\u5c5e\u6027\uff1b \u8fd9\u4e00\u5c42\u4f1a\u5c06\u56fe\u8bed\u4e49\u7684\u63a5\u53e3\u8f6c\u5316\u6210 kv \u64cd\u4f5c\u3002\u4e3a\u4e86\u63d0\u9ad8\u904d\u5386\u7684\u6027\u80fd\uff0c\u8fd8\u8981\u505a\u5e76\u53d1\u64cd\u4f5c\u3002 Meta Service \u00b6 \u5728 KVStore \u7684\u63a5\u53e3\u4e0a\uff0cNebula Graph \u4e5f\u540c\u65f6\u5c01\u88c5\u4e86\u4e00\u5957 meta \u76f8\u5173\u7684\u63a5\u53e3\u3002Meta Service \u4e0d\u4f46\u63d0\u4f9b\u4e86\u56fe schema \u7684\u589e\u5220\u67e5\u6539\u7684\u529f\u80fd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u96c6\u7fa4\u7684\u7ba1\u7406\u529f\u80fd\u4ee5\u53ca\u7528\u6237\u9274\u6743\u76f8\u5173\u7684\u529f\u80fd\u3002Meta Service \u652f\u6301\u5355\u72ec\u90e8\u7f72\uff0c\u4e5f\u652f\u6301\u4f7f\u7528\u591a\u526f\u672c\u6765\u4fdd\u8bc1\u6570\u636e\u7684\u5b89\u5168\u3002","title":"\u5b58\u50a8\u5c42\u8bbe\u8ba1"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#_1","text":"","title":"\u5b58\u50a8\u5c42\u8bbe\u8ba1"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#_2","text":"Nebula Graph \u7684 Storage \u5305\u542b\u4e24\u4e2a\u90e8\u5206\uff0c \u4e00\u662f meta \u76f8\u5173\u7684\u5b58\u50a8\uff0c \u79f0\u4e4b\u4e3a Meta Service \uff0c\u53e6\u4e00\u4e2a\u662f data \u76f8\u5173\u7684\u5b58\u50a8\uff0c \u79f0\u4e4b\u4e3a Storage Service \u3002 \u8fd9\u4e24\u4e2a\u670d\u52a1\u662f\u4e24\u4e2a\u72ec\u7acb\u7684\u8fdb\u7a0b\uff0c\u6570\u636e\u4e5f\u5b8c\u5168\u9694\u79bb\uff0c\u5f53\u7136\u90e8\u7f72\u4e5f\u662f\u5206\u522b\u90e8\u7f72\uff0c \u4e0d\u8fc7\u4e24\u8005\u6574\u4f53\u67b6\u6784\u76f8\u5dee\u4e0d\u5927\u3002 \u5982\u679c\u6ca1\u6709\u7279\u6b8a\u8bf4\u660e\uff0c\u672c\u6587\u4e2d Storage Service \u4ee3\u6307 data \u7684\u5b58\u50a8\u670d\u52a1\u3002","title":"\u6458\u8981"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#_3","text":"\u56fe\u4e00 storage service \u67b6\u6784\u56fe \u5982\u56fe1 \u6240\u793a\uff0cStorage Service \u5171\u6709\u4e09\u5c42\uff0c\u6700\u5e95\u5c42\u662f Store Engine\uff0c\u5b83\u662f\u4e00\u4e2a\u5355\u673a\u7248 local store engine\uff0c\u63d0\u4f9b\u4e86\u5bf9\u672c\u5730\u6570\u636e\u7684 get / put / scan / delete \u64cd\u4f5c\uff0c\u76f8\u5173\u7684\u63a5\u53e3\u653e\u5728 KVStore/KVEngine.h \u6587\u4ef6\u91cc\u9762\uff0c\u7528\u6237\u5b8c\u5168\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u5b9a\u5236\u5f00\u53d1\u76f8\u5173 local store plugin\uff0c\u76ee\u524d Nebula Graph \u63d0\u4f9b\u4e86\u57fa\u4e8e RocksDB \u5b9e\u73b0\u7684 Store Engine\u3002 \u5728 local store engine \u4e4b\u4e0a\uff0c\u4fbf\u662f Consensus \u5c42\uff0c\u5b9e\u73b0\u4e86 Multi Group Raft\uff0c\u6bcf\u4e00\u4e2a Partition \u90fd\u5bf9\u5e94\u4e86\u4e00\u7ec4 Raft Group\uff0c\u8fd9\u91cc\u7684 Partition \u4fbf\u662f\u6570\u636e\u5206\u7247\u3002\u76ee\u524d Nebula Graph \u7684\u5206\u7247\u7b56\u7565\u91c7\u7528\u4e86 \u9759\u6001 Hash \u7684\u65b9\u5f0f\u3002\u7528\u6237\u5728\u521b\u5efa SPACE \u65f6\u9700\u6307\u5b9a Partition \u6570\uff0cPartition \u6570\u91cf\u4e00\u65e6\u8bbe\u7f6e\u4fbf\u4e0d\u53ef\u66f4\u6539\uff0c\u4e00\u822c\u6765\u8bb2\uff0cPartition \u6570\u76ee\u8981\u80fd\u6ee1\u8db3\u4e1a\u52a1\u5c06\u6765\u7684\u6269\u5bb9\u9700\u6c42\u3002 \u5728 Consensus \u5c42\u4e0a\u9762\u4e5f\u5c31\u662f Storage Service \u7684\u6700\u4e0a\u5c42\uff0c\u4fbf\u662f Storage interfaces\uff0c\u8fd9\u4e00\u5c42\u5b9a\u4e49\u4e86\u4e00\u7cfb\u5217\u548c\u56fe\u76f8\u5173\u7684 API\u3002 \u8fd9\u4e9b API \u8bf7\u6c42\u4f1a\u5728\u8fd9\u4e00\u5c42\u88ab\u7ffb\u8bd1\u6210\u4e00\u7ec4\u9488\u5bf9\u76f8\u5e94 Partition \u7684 kv \u64cd\u4f5c\u3002\u6b63\u662f\u8fd9\u4e00\u5c42\u7684\u5b58\u5728\uff0c\u4f7f\u5f97\u5b58\u50a8\u670d\u52a1\u53d8\u6210\u4e86\u771f\u6b63\u7684\u56fe\u5b58\u50a8\uff0c\u5426\u5219\uff0cStorage Service \u53ea\u662f\u4e00\u4e2a kv \u5b58\u50a8\u3002\u800c Nebula Graph \u6ca1\u628a kv \u4f5c\u4e3a\u4e00\u4e2a\u670d\u52a1\u5355\u72ec\u63d0\u51fa\uff0c\u5176\u6700\u4e3b\u8981\u7684\u539f\u56e0\u4fbf\u662f\u56fe\u67e5\u8be2\u8fc7\u7a0b\u4e2d\u4f1a\u6d89\u53ca\u5230\u5927\u91cf\u8ba1\u7b97\uff0c\u8fd9\u4e9b\u8ba1\u7b97\u5f80\u5f80\u9700\u8981\u4f7f\u7528\u56fe\u7684 schema\uff0c\u800c kv \u5c42\u662f\u6ca1\u6709\u6570\u636e schema \u6982\u5ff5\uff0c\u8fd9\u6837\u8bbe\u8ba1\u4f1a\u6bd4\u8f83\u5bb9\u6613\u5b9e\u73b0\u8ba1\u7b97\u4e0b\u63a8\u3002","title":"\u67b6\u6784"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#schema_partition","text":"\u6570\u636e\u7ed3\u6784\u4e0a\uff0c\u56fe\u7684\u4e3b\u8981\u6570\u636e\u662f\u70b9\u548c\u8fb9\u3002\u4f46 Nebula Graph \u5b58\u50a8\u7684\u662f\u5c5e\u6027\u56fe\uff1a\u9664\u4e86\u70b9\u548c\u8fb9\u4ee5\u5916\uff0c\u8fd8\u5b58\u50a8\u4e86\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u4ee5\u4fbf\u66f4\u9ad8\u6548\u5730\u4f7f\u7528\u5c5e\u6027\u8fc7\u6ee4\u3002 \u5bf9\u4e8e\u70b9\u6765\u8bf4\uff0c Nebula Graph \u4f7f\u7528\u4e0d\u540c\u7684 Tag \u8868\u793a\u4e0d\u540c\u7c7b\u578b\u7684\u70b9\uff0c\u540c\u4e00\u4e2a VertexID \u53ef\u4ee5\u5173\u8054\u591a\u4e2a Tag\uff0c\u800c\u6bcf\u4e00\u4e2a Tag \u90fd\u6709\u81ea\u5df1\u5bf9\u5e94\u7684\u5c5e\u6027\u3002\u5bf9\u5e94\u5230 kv \u5b58\u50a8\u91cc\u9762\uff0c Nebula Graph \u4f7f\u7528 vertexID + TagID \u6765\u8868\u793a key, \u628a\u76f8\u5173\u7684\u5c5e\u6027\u7f16\u7801\u540e\u653e\u5728 value \u91cc\u9762\uff0c\u5177\u4f53 key \u7684 format \u5982\u56fe2 \u6240\u793a\uff1a \u56fe\u4e8c Vertex Key Format Type : 1 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a key \u7c7b\u578b\uff0c\u5f53\u524d\u7684\u7c7b\u578b\u6709 data, index, system \u7b49 Part ID : 3 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u6570\u636e\u5206\u7247 Partition\uff0c\u6b64\u5b57\u6bb5\u4e3b\u8981\u7528\u4e8e Partition \u91cd\u65b0\u5206\u5e03 (balance) \u65f6\u65b9\u4fbf\u6839\u636e\u524d\u7f00\u626b\u63cf\u6574\u4e2a Partition \u6570\u636e Vertex ID : 8 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u70b9\u7684 ID Tag ID : 4 \u4e2a\u5b57\u8282, \u7528\u6765\u8868\u793a\u5173\u8054\u7684\u67d0\u4e2a tag Timestamp : 8 \u4e2a\u5b57\u8282\uff0c\u5bf9\u7528\u6237\u4e0d\u53ef\u89c1\uff0c\u672a\u6765\u5b9e\u73b0\u5206\u5e03\u5f0f\u4e8b\u52a1 (MVCC) \u65f6\u4f7f\u7528 \u5728\u4e00\u4e2a\u56fe\u4e2d\uff0c\u6bcf\u4e00\u6761\u903b\u8f91\u610f\u4e49\u4e0a\u7684\u8fb9\uff0c\u5728 Nebula Graph \u4e2d\u4f1a\u5efa\u6a21\u6210\u4e24\u4e2a\u72ec\u7acb\u7684 key-value\uff0c\u5206\u522b\u79f0\u4e3a out-key \u548c in-key\u3002out-key \u4e0e\u8fd9\u6761\u8fb9\u6240\u5bf9\u5e94\u7684\u8d77\u70b9\u5b58\u50a8\u5728\u540c\u4e00\u4e2a partition \u4e0a\uff0cin-key \u4e0e\u8fd9\u6761\u8fb9\u6240\u5bf9\u5e94\u7684\u7ec8\u70b9\u5b58\u50a8\u5728\u540c\u4e00\u4e2apartition \u4e0a\u3002\u901a\u5e38\u6765\u8bf4\uff0cout-key \u548c in-key \u4f1a\u5206\u5e03\u5728\u4e24\u4e2a\u4e0d\u540c\u7684 Partition \u4e2d\u3002 \u4e24\u4e2a\u70b9\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u591a\u79cd\u7c7b\u578b\u7684\u8fb9\uff0c Nebula Graph \u7528 Edge Type \u6765\u8868\u793a\u8fb9\u7c7b\u578b\u3002\u800c\u540c\u4e00\u7c7b\u578b\u7684\u8fb9\u53ef\u80fd\u5b58\u5728\u591a\u6761\uff0c\u6bd4\u5982\uff0c\u5b9a\u4e49\u4e00\u4e2a edge type \"\u8f6c\u8d26\"\uff0c\u7528\u6237 A \u53ef\u80fd\u591a\u6b21\u8f6c\u8d26\u7ed9 B\uff0c \u6240\u4ee5 Nebula Graph \u53c8\u589e\u52a0\u4e86\u4e00\u4e2a Rank \u5b57\u6bb5\u6765\u505a\u533a\u5206\uff0c\u8868\u793a A \u5230 B \u4e4b\u95f4\u591a\u6b21\u8f6c\u8d26\u8bb0\u5f55\u3002 Edge key \u7684 format \u5982\u56fe 3 \u6240\u793a\uff1a \u56fe\u4e09 Edge Key Format Type \uff1a1 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a key \u7684\u7c7b\u578b\uff0c\u5f53\u524d\u7684\u7c7b\u578b\u6709 data, index, system \u7b49\u3002 Part ID \uff1a3 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u6570\u636e\u5206\u7247 Partition\uff0c\u6b64\u5b57\u6bb5\u4e3b\u8981\u7528\u4e8e Partition \u91cd\u65b0\u5206\u5e03 (balance) \u65f6\u65b9\u4fbf\u6839\u636e\u524d\u7f00\u626b\u63cf\u6574\u4e2a Partition \u6570\u636e Vertex ID \uff1a8 \u4e2a\u5b57\u8282\uff0c\u51fa\u8fb9\u91cc\u9762\u7528\u6765\u8868\u793a\u6e90\u70b9\u7684 ID\uff0c \u5165\u8fb9\u91cc\u9762\u8868\u793a\u76ee\u6807\u70b9\u7684 ID\u3002 Edge Type \uff1a4 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u8868\u793a\u8fd9\u6761\u8fb9\u7684\u7c7b\u578b\uff0c\u5982\u679c\u5927\u4e8e 0 \u8868\u793a\u51fa\u8fb9\uff0c\u5c0f\u4e8e 0 \u8868\u793a\u5165\u8fb9\u3002 Rank \uff1a8 \u4e2a\u5b57\u8282\uff0c\u7528\u6765\u5904\u7406\u540c\u4e00\u79cd\u7c7b\u578b\u7684\u8fb9\u5b58\u5728\u591a\u6761\u7684\u60c5\u51b5\u3002\u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u9700\u6c42\u8fdb\u884c\u8bbe\u7f6e\uff0c\u8fd9\u4e2a\u5b57\u6bb5\u53ef \u5b58\u653e\u4ea4\u6613\u65f6\u95f4 \u3001 \u4ea4\u6613\u6d41\u6c34\u53f7 \u3001\u6216 \u67d0\u4e2a\u6392\u5e8f Vertex ID \uff1a8 \u4e2a\u5b57\u8282\uff0c\u51fa\u8fb9\u91cc\u9762\u7528\u6765\u8868\u793a\u76ee\u6807\u70b9\u7684 ID\uff0c \u5165\u8fb9\u91cc\u9762\u8868\u793a\u6e90\u70b9\u7684 ID\u3002 Timestamp \uff1a8 \u4e2a\u5b57\u8282\uff0c\u5bf9\u7528\u6237\u4e0d\u53ef\u89c1\uff0c\u672a\u6765\u5b9e\u73b0\u5206\u5e03\u5f0f\u505a\u4e8b\u52a1\u7684\u65f6\u5019\u4f7f\u7528\u3002 \u9488\u5bf9 Edge Type \u7684\u503c\uff0c\u82e5\u5982\u679c\u5927\u4e8e 0 \u8868\u793a\u51fa\u8fb9\uff0c\u5219\u5bf9\u5e94\u7684 edge key format \u5982\u56fe4 \u6240\u793a\uff1b\u82e5 Edge Type \u7684\u503c\u5c0f\u4e8e 0\uff0c\u5219\u5bf9\u5e94\u7684 edge key format \u5982\u56fe5 \u6240\u793a \u56fe4 \u51fa\u8fb9\u7684 Key Format \u56fe5 \u5165\u8fb9\u7684 Key Format \u5bf9\u4e8e\u70b9\u6216\u8fb9\u7684\u5c5e\u6027\u4fe1\u606f\uff0c\u6709\u5bf9\u5e94\u7684\u4e00\u7ec4 kv pairs\uff0c Nebula Graph \u5c06\u5b83\u4eec\u7f16\u7801\u540e\u5b58\u5728\u5bf9\u5e94\u7684 value \u91cc\u3002\u7531\u4e8e Nebula Graph \u4f7f\u7528\u5f3a\u7c7b\u578b schema\uff0c\u6240\u4ee5\u5728\u89e3\u7801\u4e4b\u524d\uff0c\u9700\u8981\u5148\u53bb Meta Service \u4e2d\u53d6\u5177\u4f53\u7684 schema \u4fe1\u606f\u3002\u53e6\u5916\uff0c\u4e3a\u4e86\u652f\u6301\u5728\u7ebf\u53d8\u66f4 schema\uff0c\u5728\u7f16\u7801\u5c5e\u6027\u65f6\uff0c\u4f1a\u52a0\u5165\u5bf9\u5e94\u7684 schema \u7248\u672c\u4fe1\u606f\u3002 \u6570\u636e\u7684\u5206\u7247\u65b9\u5f0f\u4e3a\u5bf9 Vertex ID \u53d6\u6a21 \u3002\u901a\u8fc7\u5bf9 Vertex ID \u53d6\u6a21\uff0c\u540c\u4e00\u4e2a\u70b9\u7684\u6240\u6709 \u51fa\u8fb9 \uff0c \u5165\u8fb9 \u4ee5\u53ca\u8fd9\u4e2a\u70b9\u4e0a\u6240\u6709\u5173\u8054\u7684 Tag \u4fe1\u606f \u90fd\u4f1a\u88ab\u5206\u5230\u540c\u4e00\u4e2a Partition\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5927\u5927\u5730\u63d0\u5347\u4e86\u67e5\u8be2\u6548\u7387\u3002\u5bf9\u4e8e\u5728\u7ebf\u56fe\u67e5\u8be2\u6765\u8bb2\uff0c\u6700\u5e38\u89c1\u7684\u64cd\u4f5c\u4fbf\u662f\u4ece\u4e00\u4e2a\u70b9\u5f00\u59cb\u5411\u5916 BFS\uff08\u5e7f\u5ea6\u4f18\u5148\uff09\u62d3\u5c55\uff0c\u4e8e\u662f\u62ff\u4e00\u4e2a\u70b9\u7684\u51fa\u8fb9\u6216\u8005\u5165\u8fb9\u662f\u6700\u57fa\u672c\u7684\u64cd\u4f5c\uff0c\u800c\u8fd9\u4e2a\u64cd\u4f5c\u7684\u6027\u80fd\u4e5f\u51b3\u5b9a\u4e86\u6574\u4e2a\u904d\u5386\u7684\u6027\u80fd\u3002BFS \u4e2d\u53ef\u80fd\u4f1a\u51fa\u73b0\u6309\u7167\u67d0\u4e9b\u5c5e\u6027\u8fdb\u884c\u526a\u679d\u7684\u60c5\u51b5\uff0c Nebula Graph \u901a\u8fc7\u5c06\u5c5e\u6027\u4e0e\u70b9\u8fb9\u5b58\u5728\u4e00\u8d77\uff0c\u6765\u4fdd\u8bc1\u6574\u4e2a\u64cd\u4f5c\u7684\u9ad8\u6548\u3002\u5728\u5b9e\u9645\u7684\u573a\u666f\u4e2d\uff0c\u5927\u90e8\u5206\u60c5\u51b5\u90fd\u662f\u5c5e\u6027\u56fe\uff0c\u5e76\u4e14\u5b9e\u9645\u4e2d\u7684 BFS \u4e5f\u9700\u8981\u8fdb\u884c\u5927\u91cf\u7684\u526a\u679d\u64cd\u4f5c\u3002","title":"Schema &amp; Partition"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#kvstore","text":"\u5bf9\u4e8eKVStore\u7684\u8981\u6c42\uff1a \u6027\u80fd \uff1b \u4ee5 library \u7684\u5f62\u5f0f\u63d0\u4f9b \uff1a\u5bf9\u4e8e\u5f3a schema \u7684 Nebula Graph \u6765\u8bb2\uff0c\u8ba1\u7b97\u4e0b\u63a8\u9700\u8981 schema \u4fe1\u606f\uff0c\u800c\u8ba1\u7b97\u4e0b\u63a8\u5b9e\u73b0\u7684\u597d\u574f\uff0c\u662f Nebula Graph \u662f\u5426\u9ad8\u6548\u7684\u5173\u952e\uff1b \u6570\u636e\u5f3a\u4e00\u81f4 \uff1a\u8fd9\u662f\u5206\u5e03\u5f0f\u7cfb\u7edf\u51b3\u5b9a\u7684\uff1b \u4f7f\u7528 C++\u5b9e\u73b0 \uff1a\u8fd9\u7531\u56e2\u961f\u7684\u6280\u672f\u7279\u70b9\u51b3\u5b9a\uff1b \u57fa\u4e8e\u4e0a\u8ff0\u8981\u6c42\uff0c Nebula Graph \u5b9e\u73b0\u4e86\u81ea\u5df1\u7684 KVStore\u3002\u5f53\u7136\uff0c\u5bf9\u4e8e\u6027\u80fd\u5b8c\u5168\u4e0d\u654f\u611f\u4e14\u4e0d\u592a\u5e0c\u671b\u642c\u8fc1\u6570\u636e\u7684\u7528\u6237\u6765\u8bf4\uff0c Nebula Graph \u4e5f\u63d0\u4f9b\u4e86\u6574\u4e2a KVStore \u5c42\u7684 plugin\uff0c\u76f4\u63a5\u5c06 Storage Service \u642d\u5efa\u5728\u7b2c\u4e09\u65b9\u7684 KVStore \u4e0a\u9762\uff0c\u76ee\u524d\u5b98\u65b9\u63d0\u4f9b\u7684\u662f HBase \u7684 plugin\u3002 Nebula Graph KVStore \u4e3b\u8981\u91c7\u7528 RocksDB \u4f5c\u4e3a\u672c\u5730\u7684\u5b58\u50a8\u5f15\u64ce\uff0c\u5bf9\u4e8e\u591a\u786c\u76d8\u673a\u5668\uff0c\u4e3a\u4e86\u5145\u5206\u5229\u7528\u591a\u786c\u76d8\u7684\u5e76\u53d1\u80fd\u529b\uff0c Nebula Graph \u652f\u6301\u81ea\u5df1\u7ba1\u7406\u591a\u5757\u76d8\uff0c\u7528\u6237\u53ea\u9700\u914d\u7f6e\u591a\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u76ee\u5f55\u5373\u53ef\u3002 \u5206\u5e03\u5f0f KVStore \u7684\u7ba1\u7406\u7531 Meta Service \u6765\u7edf\u4e00\u8c03\u5ea6\uff0c\u5b83\u8bb0\u5f55\u4e86\u6240\u6709 Partition \u7684\u5206\u5e03\u60c5\u51b5\uff0c\u4ee5\u53ca\u5f53\u524d\u673a\u5668\u7684\u72b6\u6001\uff0c\u5f53\u7528\u6237\u589e\u51cf\u673a\u5668\u65f6\uff0c\u53ea\u9700\u8981\u901a\u8fc7 console \u8f93\u5165\u76f8\u5e94\u7684\u6307\u4ee4\uff0cMeta Service \u4fbf\u80fd\u591f\u751f\u6210\u6574\u4e2a balance plan \u5e76\u6267\u884c\u3002\uff08\u4e4b\u6240\u4ee5\u6ca1\u6709\u91c7\u7528\u5b8c\u5168\u81ea\u52a8 balance \u7684\u65b9\u5f0f\uff0c\u4e3b\u8981\u662f\u4e3a\u4e86\u51cf\u5c11\u6570\u636e\u642c\u8fc1\u5bf9\u4e8e\u7ebf\u4e0a\u670d\u52a1\u7684\u5f71\u54cd\uff0cbalance \u7684\u65f6\u673a\u7531\u7528\u6237\u81ea\u5df1\u63a7\u5236\uff0c\u901a\u5e38\u4f1a\u5728\u4e1a\u52a1\u4f4e\u8c37\u8fdb\u884c\u3002\uff09 \u4e3a\u4e86\u65b9\u4fbf\u5bf9\u4e8e WAL \u8fdb\u884c\u5b9a\u5236\uff0c Nebula Graph KVStore \u5b9e\u73b0\u4e86\u81ea\u5df1\u7684 WAL \u6a21\u5757\uff0c\u6bcf\u4e2a partition \u90fd\u6709\u81ea\u5df1\u7684 WAL\uff0c\u8fd9\u6837\u5728\u8ffd\u6570\u636e\u65f6\uff0c\u4e0d\u9700\u8981\u8fdb\u884c wal split \u64cd\u4f5c\uff0c \u66f4\u52a0\u9ad8\u6548\u3002 \u53e6\u5916\uff0c\u4e3a\u4e86\u5b9e\u73b0\u4e00\u4e9b\u7279\u6b8a\u7684\u64cd\u4f5c\uff0c\u4e13\u95e8\u5b9a\u4e49\u4e86 Command Log \u8fd9\u4e2a\u7c7b\u522b\uff0c\u8fd9\u4e9b log \u53ea\u4e3a\u4e86\u4f7f\u7528 Raft \u6765\u901a\u77e5\u6240\u6709 replica \u6267\u884c\u67d0\u4e00\u4e2a\u7279\u5b9a\u64cd\u4f5c\uff0c\u5e76\u6ca1\u6709\u771f\u6b63\u7684\u6570\u636e\u3002\u9664\u4e86 Command Log \u5916\uff0c Nebula Graph \u8fd8\u63d0\u4f9b\u4e86\u4e00\u7c7b\u65e5\u5fd7\u6765\u5b9e\u73b0\u9488\u5bf9\u67d0\u4e2a Partition \u7684 atomic operation\uff0c\u4f8b\u5982 CAS\uff0cread-modify-write, \u5b83\u5145\u5206\u5229\u7528\u4e86Raft \u4e32\u884c\u7684\u7279\u6027\u3002 \u5173\u4e8e\u591a\u56fe\u7a7a\u95f4\uff08space\uff09\u7684\u652f\u6301\uff1a\u4e00\u4e2a Nebula Graph KVStore \u96c6\u7fa4\u53ef\u4ee5\u652f\u6301\u591a\u4e2a space\uff0c\u6bcf\u4e2a space \u53ef\u8bbe\u7f6e\u81ea\u5df1\u7684 partition \u6570\u548c replica \u6570\u3002\u4e0d\u540c space \u5728\u7269\u7406\u4e0a\u662f\u5b8c\u5168\u9694\u79bb\u7684\uff0c\u800c\u4e14\u5728\u540c\u4e00\u4e2a\u96c6\u7fa4\u4e0a\u7684\u4e0d\u540c space \u53ef\u652f\u6301\u4e0d\u540c\u7684 store engine \u53ca\u5206\u7247\u7b56\u7565\u3002","title":"KVStore"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#raft","text":"\u4f5c\u4e3a\u4e00\u4e2a\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0cKVStore \u7684 replication\u3001scale out \u7b49\u529f\u80fd\u9700 Raft \u7684\u652f\u6301\u3002\u4e3b\u8981\u4ecb\u7ecd Nebula Graph Raft \u7684\u4e00\u4e9b\u7279\u70b9\u4ee5\u53ca\u5de5\u7a0b\u5b9e\u73b0\u3002","title":"Raft"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#multi_raft_group","text":"\u7531\u4e8e Raft \u7684\u65e5\u5fd7\u4e0d\u5141\u8bb8\u7a7a\u6d1e\uff0c\u51e0\u4e4e\u6240\u6709\u7684\u5b9e\u73b0\u90fd\u4f1a\u91c7\u7528 Multi Raft Group \u6765\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u56e0\u6b64 partition \u7684\u6570\u76ee\u51e0\u4e4e\u51b3\u5b9a\u4e86\u6574\u4e2a Raft Group \u7684\u6027\u80fd\u3002\u4f46\u8fd9\u4e5f\u5e76\u4e0d\u662f\u8bf4 Partition \u7684\u6570\u76ee\u8d8a\u591a\u8d8a\u597d\uff1a\u6bcf\u4e00\u4e2a Raft Group \u5185\u90e8\u90fd\u8981\u5b58\u50a8\u4e00\u7cfb\u5217\u7684\u72b6\u6001\u4fe1\u606f\uff0c\u5e76\u4e14\u6bcf\u4e00\u4e2a Raft Group \u6709\u81ea\u5df1\u7684 WAL \u6587\u4ef6\uff0c\u56e0\u6b64 Partition \u6570\u76ee\u592a\u591a\u4f1a\u589e\u52a0\u5f00\u9500\u3002\u6b64\u5916\uff0c\u5f53 Partition \u592a\u591a\u65f6\uff0c \u5982\u679c\u8d1f\u8f7d\u6ca1\u6709\u8db3\u591f\u9ad8\uff0cbatch \u64cd\u4f5c\u662f\u6ca1\u6709\u610f\u4e49\u7684\u3002\u6bd4\u5982\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u6709 1\u4e07 TPS \u7684\u7ebf\u4e0a\u7cfb\u7edf\uff0c\u5373\u4f7f\u5b83\u7684\u6bcf\u53f0\u673a\u5668\u4e0a partition \u7684\u6570\u76ee\u8d85\u8fc7 1\u4e07\uff0c\u4f46\u5f88\u6709\u53ef\u80fd\u6bcf\u4e2a partition TPS \u53ea\u6709 1\uff0c\u8fd9\u6837 batch \u64cd\u4f5c\u5c31\u5931\u53bb\u4e86\u610f\u4e49\uff0c\u8fd8\u589e\u52a0\u4e86 CPU \u5f00\u9500\u3002 \u5b9e\u73b0 Multi Raft Group \u7684\u6700\u5173\u952e\u4e4b\u5904\u6709\u4e24\u70b9\uff0c \u7b2c\u4e00\u662f\u5171\u4eab Transport \u5c42 \uff0c\u56e0\u4e3a\u6bcf\u4e00\u4e2a Raft Group \u5185\u90e8\u90fd\u9700\u8981\u5411\u5bf9\u5e94\u7684 peer \u53d1\u9001\u6d88\u606f\uff0c\u5982\u679c\u4e0d\u80fd\u5171\u4eab Transport \u5c42\uff0c\u8fde\u63a5\u7684\u5f00\u9500\u5de8\u5927\uff1b \u7b2c\u4e8c\u662f\u7ebf\u7a0b\u6a21\u578b \uff0cMulti Raft Group \u4e00\u5b9a\u8981\u5171\u4eab\u4e00\u7ec4\u7ebf\u7a0b\u6c60\uff0c\u5426\u5219\u4f1a\u9020\u6210\u7cfb\u7edf\u7684\u7ebf\u7a0b\u6570\u76ee\u8fc7\u591a\uff0c\u5bfc\u81f4\u5927\u91cf\u7684 context switch \u5f00\u9500\u3002","title":"Multi Raft Group"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#batch","text":"\u5bf9\u4e8e\u6bcf\u4e2a Partition\u6765\u8bf4\uff0c\u7531\u4e8e\u4e32\u884c\u5199 WAL\uff0c\u4e3a\u4e86\u63d0\u9ad8\u541e\u5410\uff0c\u505a batch \u662f\u5341\u5206\u5fc5\u8981\u7684\u3002Nebula Graph \u5229\u7528\u6bcf\u4e2a part \u4e32\u884c\u7684\u7279\u70b9\uff0c\u505a\u4e86\u4e00\u4e9b\u7279\u6b8a\u7c7b\u578b\u7684 WAL\uff0c\u5e26\u6765\u4e86\u4e00\u4e9b\u5de5\u7a0b\u4e0a\u7684\u6311\u6218\u3002 \u4e3e\u4e2a\u4f8b\u5b50\uff0cNebula Graph \u5229\u7528 WAL \u5b9e\u73b0\u4e86\u65e0\u9501\u7684 CAS \u64cd\u4f5c\uff0c\u800c\u6bcf\u4e2a CAS \u64cd\u4f5c\u9700\u8981\u4e4b\u524d\u7684 WAL \u5168\u90e8 commit \u4e4b\u540e\u624d\u80fd\u6267\u884c\uff0c\u6240\u4ee5\u5bf9\u4e8e\u4e00\u4e2a batch\uff0c\u5982\u679c\u4e2d\u95f4\u5939\u6742\u4e86\u51e0\u6761 CAS \u7c7b\u578b\u7684 WAL, \u8fd8\u9700\u8981\u628a\u8fd9\u4e2a batch \u5206\u6210\u7c92\u5ea6\u66f4\u5c0f\u7684\u51e0\u4e2a group\uff0cgroup \u4e4b\u95f4\u4fdd\u8bc1\u4e32\u884c\u3002\u8fd8\u6709\uff0ccommand \u7c7b\u578b\u7684 WAL \u9700\u8981\u5b83\u540e\u9762\u7684 WAL \u5728\u5176 commit \u4e4b\u540e\u624d\u80fd\u6267\u884c\uff0c\u6240\u4ee5\u6574\u4e2a batch \u5212\u5206 group \u7684\u64cd\u4f5c\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u6bd4\u8f83\u6709\u7279\u8272\u3002","title":"Batch"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#learner","text":"Learner \u8fd9\u4e2a\u89d2\u8272\u7684\u5b58\u5728\u4e3b\u8981\u662f\u4e3a\u4e86 \u5e94\u5bf9\u6269\u5bb9 \u65f6\uff0c\u65b0\u673a\u5668\u9700\u8981\u201c\u8ffd\u201d\u76f8\u5f53\u957f\u4e00\u6bb5\u65f6\u95f4\u7684\u6570\u636e\uff0c\u800c\u8fd9\u6bb5\u65f6\u95f4\u6709\u53ef\u80fd\u4f1a\u53d1\u751f\u610f\u5916\u3002\u5982\u679c\u76f4\u63a5\u4ee5 follower \u7684\u8eab\u4efd\u5f00\u59cb\u8ffd\u6570\u636e\uff0c\u5c31\u4f1a\u4f7f\u5f97\u6574\u4e2a\u96c6\u7fa4\u7684 HA \u80fd\u529b\u4e0b\u964d\u3002 Nebula Graph \u91cc\u9762 learner \u7684\u5b9e\u73b0\u5c31\u662f\u91c7\u7528\u4e86\u4e0a\u9762\u63d0\u5230\u7684 command wal\u3002 Leader \u5728\u5199 wal \u65f6\u5982\u679c\u78b0\u5230 add learner \u7684 command\uff0c \u5c31\u4f1a\u5c06 learner \u52a0\u5165\u81ea\u5df1\u7684 peers\uff0c\u5e76\u628a\u5b83\u6807\u8bb0\u4e3a learner\uff0c\u8fd9\u6837\u5728\u7edf\u8ba1\u591a\u6570\u6d3e\u7684\u65f6\u5019\uff0c\u5c31\u4e0d\u4f1a\u7b97\u4e0a learner\uff0c\u4f46\u662f\u65e5\u5fd7\u8fd8\u662f\u4f1a\u7167\u5e38\u53d1\u9001\u7ed9\u5b83\u4eec\u3002\u5f53\u7136 learner \u4e5f\u4e0d\u4f1a\u4e3b\u52a8\u53d1\u8d77\u9009\u4e3e\u3002","title":"Learner"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#transfer_leadership","text":"Transfer leadership \u8fd9\u4e2a\u64cd\u4f5c\u5bf9\u4e8e balance \u6765\u8bb2\u81f3\u5173\u91cd\u8981\uff0c\u5f53\u628a\u67d0\u4e2a Partition \u4ece\u4e00\u53f0\u673a\u5668\u632a\u5230\u53e6\u4e00\u53f0\u673a\u5668\u65f6\uff0c\u9996\u5148\u4fbf\u4f1a\u68c0\u67e5 source \u662f\u4e0d\u662f leader\uff0c\u5982\u679c\u662f\u7684\u8bdd\uff0c\u9700\u8981\u5148\u628a\u4ed6\u632a\u5230\u53e6\u5916\u7684 peer \u4e0a\u9762\uff1b\u5728\u642c\u8fc1\u6570\u636e\u5b8c\u6bd5\u4e4b\u540e\uff0c\u901a\u5e38\u8fd8\u8981\u628a leader \u8fdb\u884c\u4e00\u6b21 balance\uff0c\u8fd9\u6837\u6bcf\u53f0\u673a\u5668\u627f\u62c5\u7684\u8d1f\u8f7d\u4e5f\u80fd\u4fdd\u8bc1\u5747\u8861\u3002 \u5b9e\u73b0 transfer leadership\uff0c \u9700\u8981\u6ce8\u610f\u7684\u662f leader \u653e\u5f03\u81ea\u5df1\u7684 leadership\uff0c\u548c follower \u5f00\u59cb\u8fdb\u884c leader election \u7684\u65f6\u673a\u3002\u5bf9\u4e8e leader \u6765\u8bb2\uff0c\u5f53 transfer leadership command \u5728 commit \u7684\u65f6\u5019\uff0c\u5b83\u653e\u5f03 leadership\uff1b\u800c\u5bf9\u4e8e follower \u6765\u8bb2\uff0c\u5f53\u6536\u5230\u6b64 command \u7684\u65f6\u5019\u5c31\u8981\u5f00\u59cb\u8fdb\u884c leader election\uff0c \u8fd9\u5957\u5b9e\u73b0\u8981\u548c Raft \u672c\u8eab\u7684 leader election \u8d70\u4e00\u5957\u8def\u5f84\uff0c\u5426\u5219\u5f88\u5bb9\u6613\u51fa\u73b0\u4e00\u4e9b\u96be\u4ee5\u5904\u7406\u7684 corner case\u3002","title":"Transfer Leadership"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#membership_change","text":"\u4e3a\u4e86\u907f\u514d\u8111\u88c2\uff0c\u5f53\u4e00\u4e2a Raft Group \u7684\u6210\u5458\u53d1\u751f\u53d8\u5316\u65f6\uff0c\u9700\u8981\u6709\u4e00\u4e2a\u4e2d\u95f4\u72b6\u6001\uff0c \u8fd9\u4e2a\u72b6\u6001\u4e0b old group \u7684\u591a\u6570\u6d3e\u4e0e new group \u7684\u591a\u6570\u6d3e\u603b\u662f\u6709 overlap\uff0c\u8fd9\u6837\u5c31\u9632\u6b62\u4e86 old group \u6216\u8005\u65b0 group \u5355\u65b9\u9762\u505a\u51fa\u51b3\u5b9a\uff0c\u8fd9\u5c31\u662f \u8bba\u6587 \u4e2d\u63d0\u5230\u7684 joint consensus \u3002\u4e3a\u4e86\u66f4\u52a0\u7b80\u5316\uff0cDiego Ongaro \u5728\u81ea\u5df1\u7684\u535a\u58eb\u8bba\u6587\u4e2d\u63d0\u51fa \u6bcf\u6b21\u589e\u51cf\u4e00\u4e2a peer \u7684\u65b9\u5f0f \uff0c \u4ee5\u4fdd\u8bc1 old group \u7684\u591a\u6570\u6d3e\u603b\u662f\u4e0e new group \u7684\u591a\u6570\u6d3e\u6709 overlap \u3002 Nebula Graph \u7684\u5b9e\u73b0\u4e5f\u91c7\u7528\u4e86\u8fd9\u4e2a\u65b9\u5f0f\uff0c\u53ea\u4e0d\u8fc7 add member \u4e0e remove member \u7684\u5b9e\u73b0\u6709\u6240\u533a\u522b\uff0c\u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f\u53ef\u4ee5\u53c2\u8003 Raft Part class \u91cc\u9762 addPeer/removePeer \u7684\u5b9e\u73b0\u3002","title":"Membership change"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#snapshot","text":"Snapshot \u5982\u4f55\u4e0e Raft \u6d41\u7a0b\u7ed3\u5408\u8d77\u6765\uff0c \u8bba\u6587 \u4e2d\u5e76\u6ca1\u6709\u7ec6\u8bb2\uff0c\u4f46\u662f\u8fd9\u4e00\u90e8\u5206\u662f\u4e00\u4e2a Raft \u5b9e\u73b0\u91cc\u6700\u5bb9\u6613\u51fa\u9519\u7684\u5730\u65b9\uff0c\u56e0\u4e3a\u8fd9\u91cc\u4f1a\u4ea7\u751f\u5927\u91cf\u7684 corner case\u3002 \u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5f53 leader \u53d1\u9001 snapshot \u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c leader \u53d1\u751f\u4e86\u53d8\u5316\uff0c\u8be5\u600e\u4e48\u529e\uff1f \u8fd9\u4e2a\u65f6\u5019\uff0c\u6709\u53ef\u80fd follower \u53ea\u63a5\u5230\u4e86\u4e00\u534a\u7684 snapshot \u6570\u636e\u3002 \u6240\u4ee5\u9700\u8981\u6709\u4e00\u4e2a Partition \u6570\u636e\u6e05\u7406\u8fc7\u7a0b\uff0c\u7531\u4e8e\u591a\u4e2a Partition \u5171\u4eab\u4e00\u4efd\u5b58\u50a8\uff0c\u56e0\u6b64\u5982\u4f55\u6e05\u7406\u6570\u636e\u53c8\u662f\u4e00\u4e2a\u5f88\u9ebb\u70e6\u7684\u95ee\u9898\u3002\u53e6\u5916\uff0csnapshot \u8fc7\u7a0b\u4e2d\uff0c\u4f1a\u4ea7\u751f\u5927\u91cf\u7684 IO\uff0c\u4e3a\u4e86\u6027\u80fd\u8003\u8651\uff0c\u4e0d\u5e0c\u671b\u8fd9\u4e2a\u8fc7\u7a0b\u4e0e\u6b63\u5e38\u7684 Raft \u5171\u7528\u4e00\u4e2a IO threadPool\uff0c\u5e76\u4e14\u6574\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u8fd8\u9700\u8981\u4f7f\u7528\u5927\u91cf\u7684\u5185\u5b58\uff0c\u5982\u4f55\u4f18\u5316\u5185\u5b58\u7684\u4f7f\u7528\uff0c\u5bf9\u4e8e\u6027\u80fd\u5341\u5206\u5173\u952e\u3002\u7531\u4e8e\u7bc7\u5e45\u539f\u56e0\uff0c\u5e76\u4e0d\u4f1a\u5728\u672c\u6587\u5bf9\u8fd9\u4e9b\u95ee\u9898\u5c55\u5f00\u8bb2\u8ff0\uff0c\u53ef\u4ee5\u53c2\u8003 SnapshotManager \u7684\u5b9e\u73b0\u3002","title":"Snapshot"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#storage_service","text":"\u5728 KVStore \u7684\u63a5\u53e3\u4e4b\u4e0a\uff0cNebula Graph \u5c01\u88c5\u6709\u56fe\u8bed\u4e49\u63a5\u53e3\uff0c\u4e3b\u8981\u7684\u63a5\u53e3\u5982\u4e0b\uff1a getNeighbors \uff1a\u67e5\u8be2\u4e00\u6279\u70b9\u7684\u51fa\u8fb9\u6216\u8005\u5165\u8fb9\uff0c\u8fd4\u56de\u8fb9\u4ee5\u53ca\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u5e76\u4e14\u9700\u8981\u652f\u6301\u6761\u4ef6\u8fc7\u6ee4\uff1b Insert vertex/edge \uff1a\u63d2\u5165\u4e00\u6761\u70b9\u6216\u8005\u8fb9\u53ca\u5176\u5c5e\u6027\uff1b getProps \uff1a\u53d6\u4e00\u4e2a\u70b9\u6216\u8005\u4e00\u6761\u8fb9\u7684\u5c5e\u6027\uff1b \u8fd9\u4e00\u5c42\u4f1a\u5c06\u56fe\u8bed\u4e49\u7684\u63a5\u53e3\u8f6c\u5316\u6210 kv \u64cd\u4f5c\u3002\u4e3a\u4e86\u63d0\u9ad8\u904d\u5386\u7684\u6027\u80fd\uff0c\u8fd8\u8981\u505a\u5e76\u53d1\u64cd\u4f5c\u3002","title":"Storage Service"},{"location":"manual-CN/1.overview/3.design-and-architecture/2.storage-design/#meta_service","text":"\u5728 KVStore \u7684\u63a5\u53e3\u4e0a\uff0cNebula Graph \u4e5f\u540c\u65f6\u5c01\u88c5\u4e86\u4e00\u5957 meta \u76f8\u5173\u7684\u63a5\u53e3\u3002Meta Service \u4e0d\u4f46\u63d0\u4f9b\u4e86\u56fe schema \u7684\u589e\u5220\u67e5\u6539\u7684\u529f\u80fd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u96c6\u7fa4\u7684\u7ba1\u7406\u529f\u80fd\u4ee5\u53ca\u7528\u6237\u9274\u6743\u76f8\u5173\u7684\u529f\u80fd\u3002Meta Service \u652f\u6301\u5355\u72ec\u90e8\u7f72\uff0c\u4e5f\u652f\u6301\u4f7f\u7528\u591a\u526f\u672c\u6765\u4fdd\u8bc1\u6570\u636e\u7684\u5b89\u5168\u3002","title":"Meta Service"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/","text":"\u67e5\u8be2\u5f15\u64ce\u8bbe\u8ba1 \u00b6 \u5728 Nebula Graph \u4e2d\uff0cQuery Engine \u7528\u6765\u5904\u7406 Nebula Graph \u67e5\u8be2\u8bed\u8a00\u8bed\u53e5\uff08nGQL\uff09\u3002\u672c\u7bc7\u6587\u7ae0\u5c06\u5e26\u4f60\u4e86\u89e3 Nebula Query Engine \u7684\u67b6\u6784\u3002 \u4e0a\u56fe\u4e3a\u67e5\u8be2\u5f15\u64ce\u7684\u67b6\u6784\u56fe\uff0c\u5982\u679c\u4f60\u5bf9 SQL \u7684\u6267\u884c\u5f15\u64ce\u6bd4\u8f83\u719f\u6089\uff0c\u90a3\u4e48\u5bf9\u4e0a\u56fe\u4e00\u5b9a\u4e0d\u4f1a\u964c\u751f\u3002 Nebula Graph \u7684 Query Engine \u67b6\u6784\u56fe\u548c\u73b0\u4ee3 SQL \u7684\u6267\u884c\u5f15\u64ce\u7c7b\u4f3c\uff0c\u53ea\u662f\u5728\u67e5\u8be2\u8bed\u8a00\u89e3\u6790\u5668\u548c\u5177\u4f53\u7684\u6267\u884c\u8ba1\u5212\u6709\u6240\u533a\u522b\u3002 Session Manager \u00b6 Nebula Graph \u6743\u9650\u7ba1\u7406\u91c7\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u6743\u9650\u63a7\u5236\uff08Role Based Access Control\uff09\u3002\u5ba2\u6237\u7aef\u7b2c\u4e00\u6b21\u8fde\u63a5\u5230 Query Engine \u65f6\u9700\u4f5c\u8ba4\u8bc1\uff0c\u5f53\u8ba4\u8bc1\u6210\u529f\u4e4b\u540e Query Engine \u4f1a\u521b\u5efa\u4e00\u4e2a\u65b0 session\uff0c\u5e76\u5c06\u8be5 session ID \u8fd4\u56de\u7ed9\u5ba2\u6237\u7aef\u3002\u6240\u6709\u7684 session \u7edf\u4e00\u7531 Session Manager \u7ba1\u7406\u3002session \u4f1a\u8bb0\u5f55\u5f53\u524d\u7684 graph space \u4fe1\u606f\u53ca\u5bf9\u8be5 space \u7684\u6743\u9650\u3002\u6b64\u5916\uff0csession \u8fd8\u4f1a\u8bb0\u5f55\u4e00\u4e9b\u4f1a\u8bdd\u76f8\u5173\u7684\u914d\u7f6e\u4fe1\u606f\uff0c\u5e76\u4e34\u65f6\u4fdd\u5b58\u540c\u4e00 session \u5185\u7684\u8de8\u591a\u4e2a\u8bf7\u6c42\u7684\u4e00\u4e9b\u4fe1\u606f\u3002 \u5ba2\u6237\u7aef\u8fde\u63a5\u7ed3\u675f\u4e4b\u540e session \u4f1a\u5173\u95ed\uff0c\u6216\u8005\u5982\u679c\u957f\u65f6\u95f4\u6ca1\u901a\u4fe1\u4f1a\u5207\u6362\u4e3a\u7a7a\u95f2\u72b6\u6001\u3002\u8fd9\u4e2a\u7a7a\u95f2\u65f6\u957f\u662f\u53ef\u4ee5\u914d\u7f6e\u7684\u3002 \u5ba2\u6237\u7aef\u7684\u6bcf\u6b21\u8bf7\u6c42\u90fd\u5fc5\u987b\u5e26\u4e0a\u6b64 session ID\uff0c\u5426\u5219 Query Engine \u4f1a\u62d2\u7edd\u6b64\u8bf7\u6c42\u3002 Storage Engine \u4e0d\u7ba1\u7406 session\uff0cQuery Engine \u5728\u8bbf\u95ee\u5b58\u50a8\u5f15\u64ce\u65f6\uff0c\u4f1a\u5e26\u4e0a session \u4fe1\u606f\u3002 Parser \u00b6 Query Engine \u89e3\u6790\u6765\u81ea\u5ba2\u6237\u7aef\u7684 nGQL \u8bed\u53e5\uff0c\u5206\u6790\u5668\uff08parser\uff09\u4e3b\u8981\u57fa\u4e8e\u8457\u540d\u7684 flex / bison \u5de5\u5177\u96c6\u3002\u5b57\u5178\u6587\u4ef6\uff08lexicon\uff09\u548c\u8bed\u6cd5\u89c4\u5219\uff08syntax\uff09\u5728 Nebula Graph \u6e90\u4ee3\u7801\u7684 src/parser \u76ee\u5f55\u4e0b\u3002\u8bbe\u8ba1\u4e0a\uff0cnGQL \u7684\u8bed\u6cd5\u975e\u5e38\u63a5\u8fd1 SQL\uff0c\u76ee\u7684\u662f\u964d\u4f4e\u5b66\u4e60\u6210\u672c\u3002 \u56fe\u6570\u636e\u5e93\u76ee\u524d\u6ca1\u6709\u7edf\u4e00\u7684\u67e5\u8be2\u8bed\u8a00\u56fd\u9645\u6807\u51c6\uff0c\u4e00\u65e6 ISO/IEC \u7684\u56fe\u67e5\u8be2\u8bed\u8a00\uff08GQL\uff09\u59d4\u5458\u4f1a\u53d1\u5e03 GQL \u56fd\u9645\u6807\u51c6\uff0cnGQL \u4f1a\u5c3d\u5feb\u53bb\u5b9e\u73b0\u517c\u5bb9\u3002 Parser \u6784\u5efa\u4ea7\u51fa\u7684\u62bd\u8c61\u8bed\u6cd5\u6811\uff08Abstract Syntax Tree\uff0c\u7b80\u79f0 AST\uff09\u4f1a\u4ea4\u7ed9\u4e0b\u4e00\u6a21\u5757\uff1aExecution Planner\u3002 Execution Planner \u00b6 \u6267\u884c\u8ba1\u5212\u5668\uff08Execution Planner\uff09\u8d1f\u8d23\u5c06\u62bd\u8c61\u6811 AST \u89e3\u6790\u6210\u4e00\u7cfb\u5217\u6267\u884c\u52a8\u4f5c action\uff08\u53ef\u6267\u884c\u8ba1\u5212\uff09\u3002action \u4e3a\u6700\u5c0f\u53ef\u6267\u884c\u5355\u5143\u3002\u4f8b\u5982\uff0c\u5178\u578b\u7684 action \u53ef\u4ee5\u662f\u83b7\u53d6\u67d0\u4e2a\u8282\u70b9\u7684\u6240\u6709\u90bb\u8282\u70b9\uff0c\u6216\u8005\u83b7\u5f97\u67d0\u6761\u8fb9\u7684\u5c5e\u6027\uff0c\u6216\u57fa\u4e8e\u7279\u5b9a\u8fc7\u6ee4\u6761\u4ef6\u7b5b\u9009\u8282\u70b9\u6216\u8fb9\u3002 \u5f53\u62bd\u8c61\u6811 AST \u88ab\u8f6c\u6362\u6210\u6267\u884c\u8ba1\u5212\u65f6\uff0c\u6240\u6709 ID \u4fe1\u606f\u4f1a\u88ab\u62bd\u53d6\u51fa\u6765\u4ee5\u4fbf\u6267\u884c\u8ba1\u5212\u7684\u590d\u7528\u3002\u8fd9\u4e9b ID \u4fe1\u606f\u4f1a\u653e\u7f6e\u5728\u5f53\u524d\u8bf7\u6c42 context \u4e2d\uff0ccontext \u4e5f\u4f1a\u4fdd\u5b58\u53d8\u91cf\u548c\u4e2d\u95f4\u7ed3\u679c\u3002 Optimization \u00b6 \u7ecf\u7531 Execution Planner \u4ea7\u751f\u7684\u6267\u884c\u8ba1\u5212\u4f1a\u4ea4\u7ed9\u4f18\u5316\u6846\u67b6 Optimization Framework\u3002\u4f18\u5316\u6846\u67b6\u4e2d\u6ce8\u518c\u6709\u591a\u4e2a Optimizer\u3002Optimizer \u4f1a\u4f9d\u6b21\u88ab\u8c03\u7528\u5bf9\u6267\u884c\u8ba1\u5212\u8fdb\u884c\u4f18\u5316\uff0c\u8fd9\u6837\u6bcf\u4e2a Optimizer \u90fd\u6709\u673a\u4f1a\u4fee\u6539\uff08\u4f18\u5316\uff09\u6267\u884c\u8ba1\u5212\u3002 \u6700\u540e\uff0c\u4f18\u5316\u8fc7\u7684\u6267\u884c\u8ba1\u5212\u53ef\u80fd\u548c\u539f\u59cb\u6267\u884c\u8ba1\u5212\u5b8c\u5168\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u4f18\u5316\u540e\u7684\u6267\u884c\u7ed3\u679c\u5fc5\u987b\u548c\u539f\u59cb\u6267\u884c\u8ba1\u5212\u7684\u7ed3\u679c\u4e00\u6837\u3002 Execution \u00b6 Query Engine \u6700\u540e\u4e00\u6b65\u662f\u53bb\u6267\u884c\u4f18\u5316\u540e\u7684\u6267\u884c\u8ba1\u5212\uff0c\u8fd9\u6b65\u662f\u6267\u884c\u6846\u67b6\uff08Execution Framework\uff09\u5b8c\u6210\u7684\u3002\u6267\u884c\u5c42\u7684\u6bcf\u4e2a\u6267\u884c\u5668\u4e00\u6b21\u53ea\u5904\u7406\u4e00\u4e2a\u6267\u884c\u8ba1\u5212\uff0c\u8ba1\u5212\u4e2d\u7684 action \u4f1a\u4f9d\u6b21\u6267\u884c\u3002\u6267\u884c\u5668\u4e5f\u4f1a\u505a\u4e00\u4e9b\u6709\u9650\u7684\u5c40\u90e8\u4f18\u5316\uff0c\u6bd4\u5982\uff1a\u51b3\u5b9a\u662f\u5426\u5e76\u53d1\u6267\u884c\u3002 \u9488\u5bf9\u4e0d\u540c action\uff0c\u6267\u884c\u5668\u5c06\u901a\u8fc7\u5ba2\u6237\u7aef\u4e0e meta service \u6216 storage engine \u8fdb\u884c\u901a\u4fe1\u3002","title":"\u67e5\u8be2\u5f15\u64ce\u8bbe\u8ba1"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/#_1","text":"\u5728 Nebula Graph \u4e2d\uff0cQuery Engine \u7528\u6765\u5904\u7406 Nebula Graph \u67e5\u8be2\u8bed\u8a00\u8bed\u53e5\uff08nGQL\uff09\u3002\u672c\u7bc7\u6587\u7ae0\u5c06\u5e26\u4f60\u4e86\u89e3 Nebula Query Engine \u7684\u67b6\u6784\u3002 \u4e0a\u56fe\u4e3a\u67e5\u8be2\u5f15\u64ce\u7684\u67b6\u6784\u56fe\uff0c\u5982\u679c\u4f60\u5bf9 SQL \u7684\u6267\u884c\u5f15\u64ce\u6bd4\u8f83\u719f\u6089\uff0c\u90a3\u4e48\u5bf9\u4e0a\u56fe\u4e00\u5b9a\u4e0d\u4f1a\u964c\u751f\u3002 Nebula Graph \u7684 Query Engine \u67b6\u6784\u56fe\u548c\u73b0\u4ee3 SQL \u7684\u6267\u884c\u5f15\u64ce\u7c7b\u4f3c\uff0c\u53ea\u662f\u5728\u67e5\u8be2\u8bed\u8a00\u89e3\u6790\u5668\u548c\u5177\u4f53\u7684\u6267\u884c\u8ba1\u5212\u6709\u6240\u533a\u522b\u3002","title":"\u67e5\u8be2\u5f15\u64ce\u8bbe\u8ba1"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/#session_manager","text":"Nebula Graph \u6743\u9650\u7ba1\u7406\u91c7\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u6743\u9650\u63a7\u5236\uff08Role Based Access Control\uff09\u3002\u5ba2\u6237\u7aef\u7b2c\u4e00\u6b21\u8fde\u63a5\u5230 Query Engine \u65f6\u9700\u4f5c\u8ba4\u8bc1\uff0c\u5f53\u8ba4\u8bc1\u6210\u529f\u4e4b\u540e Query Engine \u4f1a\u521b\u5efa\u4e00\u4e2a\u65b0 session\uff0c\u5e76\u5c06\u8be5 session ID \u8fd4\u56de\u7ed9\u5ba2\u6237\u7aef\u3002\u6240\u6709\u7684 session \u7edf\u4e00\u7531 Session Manager \u7ba1\u7406\u3002session \u4f1a\u8bb0\u5f55\u5f53\u524d\u7684 graph space \u4fe1\u606f\u53ca\u5bf9\u8be5 space \u7684\u6743\u9650\u3002\u6b64\u5916\uff0csession \u8fd8\u4f1a\u8bb0\u5f55\u4e00\u4e9b\u4f1a\u8bdd\u76f8\u5173\u7684\u914d\u7f6e\u4fe1\u606f\uff0c\u5e76\u4e34\u65f6\u4fdd\u5b58\u540c\u4e00 session \u5185\u7684\u8de8\u591a\u4e2a\u8bf7\u6c42\u7684\u4e00\u4e9b\u4fe1\u606f\u3002 \u5ba2\u6237\u7aef\u8fde\u63a5\u7ed3\u675f\u4e4b\u540e session \u4f1a\u5173\u95ed\uff0c\u6216\u8005\u5982\u679c\u957f\u65f6\u95f4\u6ca1\u901a\u4fe1\u4f1a\u5207\u6362\u4e3a\u7a7a\u95f2\u72b6\u6001\u3002\u8fd9\u4e2a\u7a7a\u95f2\u65f6\u957f\u662f\u53ef\u4ee5\u914d\u7f6e\u7684\u3002 \u5ba2\u6237\u7aef\u7684\u6bcf\u6b21\u8bf7\u6c42\u90fd\u5fc5\u987b\u5e26\u4e0a\u6b64 session ID\uff0c\u5426\u5219 Query Engine \u4f1a\u62d2\u7edd\u6b64\u8bf7\u6c42\u3002 Storage Engine \u4e0d\u7ba1\u7406 session\uff0cQuery Engine \u5728\u8bbf\u95ee\u5b58\u50a8\u5f15\u64ce\u65f6\uff0c\u4f1a\u5e26\u4e0a session \u4fe1\u606f\u3002","title":"Session Manager"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/#parser","text":"Query Engine \u89e3\u6790\u6765\u81ea\u5ba2\u6237\u7aef\u7684 nGQL \u8bed\u53e5\uff0c\u5206\u6790\u5668\uff08parser\uff09\u4e3b\u8981\u57fa\u4e8e\u8457\u540d\u7684 flex / bison \u5de5\u5177\u96c6\u3002\u5b57\u5178\u6587\u4ef6\uff08lexicon\uff09\u548c\u8bed\u6cd5\u89c4\u5219\uff08syntax\uff09\u5728 Nebula Graph \u6e90\u4ee3\u7801\u7684 src/parser \u76ee\u5f55\u4e0b\u3002\u8bbe\u8ba1\u4e0a\uff0cnGQL \u7684\u8bed\u6cd5\u975e\u5e38\u63a5\u8fd1 SQL\uff0c\u76ee\u7684\u662f\u964d\u4f4e\u5b66\u4e60\u6210\u672c\u3002 \u56fe\u6570\u636e\u5e93\u76ee\u524d\u6ca1\u6709\u7edf\u4e00\u7684\u67e5\u8be2\u8bed\u8a00\u56fd\u9645\u6807\u51c6\uff0c\u4e00\u65e6 ISO/IEC \u7684\u56fe\u67e5\u8be2\u8bed\u8a00\uff08GQL\uff09\u59d4\u5458\u4f1a\u53d1\u5e03 GQL \u56fd\u9645\u6807\u51c6\uff0cnGQL \u4f1a\u5c3d\u5feb\u53bb\u5b9e\u73b0\u517c\u5bb9\u3002 Parser \u6784\u5efa\u4ea7\u51fa\u7684\u62bd\u8c61\u8bed\u6cd5\u6811\uff08Abstract Syntax Tree\uff0c\u7b80\u79f0 AST\uff09\u4f1a\u4ea4\u7ed9\u4e0b\u4e00\u6a21\u5757\uff1aExecution Planner\u3002","title":"Parser"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/#execution_planner","text":"\u6267\u884c\u8ba1\u5212\u5668\uff08Execution Planner\uff09\u8d1f\u8d23\u5c06\u62bd\u8c61\u6811 AST \u89e3\u6790\u6210\u4e00\u7cfb\u5217\u6267\u884c\u52a8\u4f5c action\uff08\u53ef\u6267\u884c\u8ba1\u5212\uff09\u3002action \u4e3a\u6700\u5c0f\u53ef\u6267\u884c\u5355\u5143\u3002\u4f8b\u5982\uff0c\u5178\u578b\u7684 action \u53ef\u4ee5\u662f\u83b7\u53d6\u67d0\u4e2a\u8282\u70b9\u7684\u6240\u6709\u90bb\u8282\u70b9\uff0c\u6216\u8005\u83b7\u5f97\u67d0\u6761\u8fb9\u7684\u5c5e\u6027\uff0c\u6216\u57fa\u4e8e\u7279\u5b9a\u8fc7\u6ee4\u6761\u4ef6\u7b5b\u9009\u8282\u70b9\u6216\u8fb9\u3002 \u5f53\u62bd\u8c61\u6811 AST \u88ab\u8f6c\u6362\u6210\u6267\u884c\u8ba1\u5212\u65f6\uff0c\u6240\u6709 ID \u4fe1\u606f\u4f1a\u88ab\u62bd\u53d6\u51fa\u6765\u4ee5\u4fbf\u6267\u884c\u8ba1\u5212\u7684\u590d\u7528\u3002\u8fd9\u4e9b ID \u4fe1\u606f\u4f1a\u653e\u7f6e\u5728\u5f53\u524d\u8bf7\u6c42 context \u4e2d\uff0ccontext \u4e5f\u4f1a\u4fdd\u5b58\u53d8\u91cf\u548c\u4e2d\u95f4\u7ed3\u679c\u3002","title":"Execution Planner"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/#optimization","text":"\u7ecf\u7531 Execution Planner \u4ea7\u751f\u7684\u6267\u884c\u8ba1\u5212\u4f1a\u4ea4\u7ed9\u4f18\u5316\u6846\u67b6 Optimization Framework\u3002\u4f18\u5316\u6846\u67b6\u4e2d\u6ce8\u518c\u6709\u591a\u4e2a Optimizer\u3002Optimizer \u4f1a\u4f9d\u6b21\u88ab\u8c03\u7528\u5bf9\u6267\u884c\u8ba1\u5212\u8fdb\u884c\u4f18\u5316\uff0c\u8fd9\u6837\u6bcf\u4e2a Optimizer \u90fd\u6709\u673a\u4f1a\u4fee\u6539\uff08\u4f18\u5316\uff09\u6267\u884c\u8ba1\u5212\u3002 \u6700\u540e\uff0c\u4f18\u5316\u8fc7\u7684\u6267\u884c\u8ba1\u5212\u53ef\u80fd\u548c\u539f\u59cb\u6267\u884c\u8ba1\u5212\u5b8c\u5168\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u4f18\u5316\u540e\u7684\u6267\u884c\u7ed3\u679c\u5fc5\u987b\u548c\u539f\u59cb\u6267\u884c\u8ba1\u5212\u7684\u7ed3\u679c\u4e00\u6837\u3002","title":"Optimization"},{"location":"manual-CN/1.overview/3.design-and-architecture/3.query-engine/#execution","text":"Query Engine \u6700\u540e\u4e00\u6b65\u662f\u53bb\u6267\u884c\u4f18\u5316\u540e\u7684\u6267\u884c\u8ba1\u5212\uff0c\u8fd9\u6b65\u662f\u6267\u884c\u6846\u67b6\uff08Execution Framework\uff09\u5b8c\u6210\u7684\u3002\u6267\u884c\u5c42\u7684\u6bcf\u4e2a\u6267\u884c\u5668\u4e00\u6b21\u53ea\u5904\u7406\u4e00\u4e2a\u6267\u884c\u8ba1\u5212\uff0c\u8ba1\u5212\u4e2d\u7684 action \u4f1a\u4f9d\u6b21\u6267\u884c\u3002\u6267\u884c\u5668\u4e5f\u4f1a\u505a\u4e00\u4e9b\u6709\u9650\u7684\u5c40\u90e8\u4f18\u5316\uff0c\u6bd4\u5982\uff1a\u51b3\u5b9a\u662f\u5426\u5e76\u53d1\u6267\u884c\u3002 \u9488\u5bf9\u4e0d\u540c action\uff0c\u6267\u884c\u5668\u5c06\u901a\u8fc7\u5ba2\u6237\u7aef\u4e0e meta service \u6216 storage engine \u8fdb\u884c\u901a\u4fe1\u3002","title":"Execution"},{"location":"manual-CN/2.query-language/0.README/","text":"\u9762\u5411\u7684\u8bfb\u8005 \u00b6 \u672c\u7ae0\u4ecb\u7ecd Nebula Graph \u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u9002\u5408\u6240\u6709\u4f7f\u7528 Nebula Graph \u7684\u7528\u6237\u3002 \u793a\u4f8b\u6570\u636e \u00b6 Nebula Graph \u67e5\u8be2\u8bed\u53e5\u4e2d\u4f7f\u7528\u7684\u793a\u4f8b\u6570\u636e\u53ef\u4ee5\u5728 \u6b64\u5904 \u4e0b\u8f7d\u3002\u793a\u4f8b\u6570\u636e\u4e0b\u8f7d\u5b8c\u6210\u540e\u53ef\u4ee5\u901a\u8fc7 Nebula Graph Studio \u628a\u6570\u636e\u5bfc\u5165\u5230 Nebula Graph \u6570\u636e\u5e93\u4e2d\u3002 \u5360\u4f4d\u6807\u8bc6\u7b26\u548c\u5360\u4f4d\u7b26\u503c \u00b6 Nebula Graph \u67e5\u8be2\u8bed\u8a00 nGQL \u53c2\u7167\u4ee5\u4e0b\u6807\u51c6\u8bbe\u8ba1\uff1a ISO/IEC 10646 ISO/IEC 39075 ISO/IEC NP 39075 (Draft) \u5728\u6a21\u677f\u4ee3\u7801\u4e2d\uff0c\u4efb\u4f55\u975e\u5173\u952e\u8bcd\uff0c\u6587\u5b57\u6216\u6807\u70b9\u7b26\u53f7\u7684\u6807\u8bb0\u5747\u4e3a\u5360\u4f4d\u6807\u8bc6\u7b26\u6216\u5360\u4f4d\u7b26\u503c\u3002 \u7b26\u53f7\u6807\u8bb0\u4f7f\u7528\u89c1\u4e0b\u8868\uff1a \u7b26\u53f7 \u542b\u4e49 < > \u5fc5\u9009\u9879 ::= \u5b9a\u4e49\u5143\u7d20\u7684\u516c\u5f0f [ ] \u53ef\u9009\u9879 { } \u660e\u786e\u6307\u5b9a\u7684\u5143\u7d20 | \u8868\u793a\u5728\u5176\u5de6\u53f3\u4e24\u8fb9\u4efb\u9009\u4e00\u9879 ... \u5143\u7d20\u53ef\u91cd\u590d\u591a\u6b21","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/2.query-language/0.README/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd Nebula Graph \u7684\u67e5\u8be2\u8bed\u8a00\uff0c\u9002\u5408\u6240\u6709\u4f7f\u7528 Nebula Graph \u7684\u7528\u6237\u3002","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/2.query-language/0.README/#_2","text":"Nebula Graph \u67e5\u8be2\u8bed\u53e5\u4e2d\u4f7f\u7528\u7684\u793a\u4f8b\u6570\u636e\u53ef\u4ee5\u5728 \u6b64\u5904 \u4e0b\u8f7d\u3002\u793a\u4f8b\u6570\u636e\u4e0b\u8f7d\u5b8c\u6210\u540e\u53ef\u4ee5\u901a\u8fc7 Nebula Graph Studio \u628a\u6570\u636e\u5bfc\u5165\u5230 Nebula Graph \u6570\u636e\u5e93\u4e2d\u3002","title":"\u793a\u4f8b\u6570\u636e"},{"location":"manual-CN/2.query-language/0.README/#_3","text":"Nebula Graph \u67e5\u8be2\u8bed\u8a00 nGQL \u53c2\u7167\u4ee5\u4e0b\u6807\u51c6\u8bbe\u8ba1\uff1a ISO/IEC 10646 ISO/IEC 39075 ISO/IEC NP 39075 (Draft) \u5728\u6a21\u677f\u4ee3\u7801\u4e2d\uff0c\u4efb\u4f55\u975e\u5173\u952e\u8bcd\uff0c\u6587\u5b57\u6216\u6807\u70b9\u7b26\u53f7\u7684\u6807\u8bb0\u5747\u4e3a\u5360\u4f4d\u6807\u8bc6\u7b26\u6216\u5360\u4f4d\u7b26\u503c\u3002 \u7b26\u53f7\u6807\u8bb0\u4f7f\u7528\u89c1\u4e0b\u8868\uff1a \u7b26\u53f7 \u542b\u4e49 < > \u5fc5\u9009\u9879 ::= \u5b9a\u4e49\u5143\u7d20\u7684\u516c\u5f0f [ ] \u53ef\u9009\u9879 { } \u660e\u786e\u6307\u5b9a\u7684\u5143\u7d20 | \u8868\u793a\u5728\u5176\u5de6\u53f3\u4e24\u8fb9\u4efb\u9009\u4e00\u9879 ... \u5143\u7d20\u53ef\u91cd\u590d\u591a\u6b21","title":"\u5360\u4f4d\u6807\u8bc6\u7b26\u548c\u5360\u4f4d\u7b26\u503c"},{"location":"manual-CN/2.query-language/1.data-types/data-types/","text":"\u6570\u636e\u7c7b\u578b \u00b6 Nebula Graph \u652f\u6301\u7684\u5185\u5efa\u6570\u636e\u7c7b\u578b\u5982\u4e0b\uff1a \u6570\u503c\u578b \u00b6 \u6574\u578b \u00b6 \u6574\u578b\u7684\u5173\u952e\u5b57\u4e3a int \uff0c\u4e3a 64 \u4f4d \u6709\u7b26\u53f7 \u6574\u578b\uff0c\u8303\u56f4\u662f [-9223372036854775808, 9223372036854775807] \uff0c\u4e14\u5728\u57fa\u4e8e int64 \u7684\u8ba1\u7b97\u4e2d\u4e0d\u5b58\u5728\u6ea2\u51fa\u3002\u6574\u578b\u5e38\u91cf\u652f\u6301\u591a\u79cd\u683c\u5f0f\uff1a 1. \u5341\u8fdb\u5236\uff0c\u4f8b\u5982 123456 1. \u5341\u516d\u8fdb\u5236\uff0c\u4f8b\u5982 0xdeadbeaf 1. \u516b\u8fdb\u5236\uff0c\u4f8b\u5982 01234567 \u5e03\u5c14\u578b \u00b6 \u5e03\u5c14\u578b\u5173\u952e\u5b57\u4e3a bool \uff0c\u5b57\u9762\u5e38\u91cf\u4e3a true \u548c false \u3002 \u5b57\u7b26\u578b \u00b6 \u5b57\u7b26\u578b\u5173\u952e\u5b57\u4e3a string \uff0c\u5b57\u9762\u5e38\u91cf\u4e3a\u53cc\u5f15\u53f7\u6216\u5355\u5f15\u53f7\u5305\u56f4\u7684\u4efb\u610f\u957f\u5ea6\u7684\u5b57\u7b26\u5e8f\u5217\uff0c\u5b57\u7b26\u4e32\u4e2d\u95f4\u4e0d\u5141\u8bb8\u6362\u884c\u3002\u4f8b\u5982 \"Shaquile O'Neal\" \uff0c '\"This is a double-quoted literal string\"' \u3002\u5b57\u7b26\u4e32\u5185\u652f\u6301\u5d4c\u5165\u8f6c\u4e49\u5e8f\u5217\uff0c\u4f8b\u5982\uff1a 1. \"\\n\\t\\r\\b\\f\" 1. \"\\110ello world\" \u65f6\u95f4\u6233\u7c7b\u578b \u00b6 \u65f6\u95f4\u6233\u7c7b\u578b\u7684\u53d6\u503c\u8303\u56f4\u4e3a 1970-01-01 00:00:01 UTC \u5230 2262-04-11 23:47:16 UTC \u65f6\u95f4\u6233\u5355\u4f4d\u4e3a\u79d2 \u63d2\u5165\u6570\u636e\u7684\u65f6\u5019\uff0c\u652f\u6301\u63d2\u5165\u65b9\u5f0f \u8c03\u7528\u51fd\u6570 now() \u65f6\u95f4\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982\uff1a\"2019-10-01 10:00:00\" \u76f4\u63a5\u8f93\u5165\u65f6\u95f4\u6233\uff0c\u5373\u4ece 1970-01-01 00:00:00 \u5f00\u59cb\u7684\u79d2\u6570 \u505a\u6570\u636e\u5b58\u50a8\u7684\u65f6\u5019\uff0c\u4f1a\u5148\u5c06\u65f6\u95f4\u8f6c\u5316\u4e3a UTC \u65f6\u95f4 \uff0c\u8bfb\u53d6\u7684\u65f6\u5019\u4f1a\u5c06\u5b58\u50a8\u7684 UTC \u65f6\u95f4 \u8f6c\u6362\u4e3a \u672c\u5730\u65f6\u95f4 \u7ed9\u7528\u6237 \u5e95\u5c42\u5b58\u50a8\u6570\u636e\u7c7b\u578b\u4e3a: int64 \u793a\u4f8b \u00b6 \u5148\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a school \u7684 tag nebula> CREATE TAG school(name string , create_time timestamp); \u63d2\u5165\u4e00\u4e2a\u70b9\uff0c\u540d\u4e3a \"xiwang\"\uff0c\u5efa\u6821\u65f6\u95f4\u4e3a \"2010-09-01 08:00:00\" nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"xiwang\"):(\"xiwang\", \"2010-09-01 08:00:00\"); \u63d2\u5165\u4e00\u4e2a\u70b9\uff0c\u540d\u4e3a \"guangming\"\uff0c\u5efa\u6821\u65f6\u95f4\u4e3a\u73b0\u5728 nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"guangming\"):(\"guangming\", now());","title":"\u6570\u636e\u7c7b\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_1","text":"Nebula Graph \u652f\u6301\u7684\u5185\u5efa\u6570\u636e\u7c7b\u578b\u5982\u4e0b\uff1a","title":"\u6570\u636e\u7c7b\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_2","text":"","title":"\u6570\u503c\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_3","text":"\u6574\u578b\u7684\u5173\u952e\u5b57\u4e3a int \uff0c\u4e3a 64 \u4f4d \u6709\u7b26\u53f7 \u6574\u578b\uff0c\u8303\u56f4\u662f [-9223372036854775808, 9223372036854775807] \uff0c\u4e14\u5728\u57fa\u4e8e int64 \u7684\u8ba1\u7b97\u4e2d\u4e0d\u5b58\u5728\u6ea2\u51fa\u3002\u6574\u578b\u5e38\u91cf\u652f\u6301\u591a\u79cd\u683c\u5f0f\uff1a 1. \u5341\u8fdb\u5236\uff0c\u4f8b\u5982 123456 1. \u5341\u516d\u8fdb\u5236\uff0c\u4f8b\u5982 0xdeadbeaf 1. \u516b\u8fdb\u5236\uff0c\u4f8b\u5982 01234567","title":"\u6574\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_4","text":"\u5e03\u5c14\u578b\u5173\u952e\u5b57\u4e3a bool \uff0c\u5b57\u9762\u5e38\u91cf\u4e3a true \u548c false \u3002","title":"\u5e03\u5c14\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_5","text":"\u5b57\u7b26\u578b\u5173\u952e\u5b57\u4e3a string \uff0c\u5b57\u9762\u5e38\u91cf\u4e3a\u53cc\u5f15\u53f7\u6216\u5355\u5f15\u53f7\u5305\u56f4\u7684\u4efb\u610f\u957f\u5ea6\u7684\u5b57\u7b26\u5e8f\u5217\uff0c\u5b57\u7b26\u4e32\u4e2d\u95f4\u4e0d\u5141\u8bb8\u6362\u884c\u3002\u4f8b\u5982 \"Shaquile O'Neal\" \uff0c '\"This is a double-quoted literal string\"' \u3002\u5b57\u7b26\u4e32\u5185\u652f\u6301\u5d4c\u5165\u8f6c\u4e49\u5e8f\u5217\uff0c\u4f8b\u5982\uff1a 1. \"\\n\\t\\r\\b\\f\" 1. \"\\110ello world\"","title":"\u5b57\u7b26\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_6","text":"\u65f6\u95f4\u6233\u7c7b\u578b\u7684\u53d6\u503c\u8303\u56f4\u4e3a 1970-01-01 00:00:01 UTC \u5230 2262-04-11 23:47:16 UTC \u65f6\u95f4\u6233\u5355\u4f4d\u4e3a\u79d2 \u63d2\u5165\u6570\u636e\u7684\u65f6\u5019\uff0c\u652f\u6301\u63d2\u5165\u65b9\u5f0f \u8c03\u7528\u51fd\u6570 now() \u65f6\u95f4\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982\uff1a\"2019-10-01 10:00:00\" \u76f4\u63a5\u8f93\u5165\u65f6\u95f4\u6233\uff0c\u5373\u4ece 1970-01-01 00:00:00 \u5f00\u59cb\u7684\u79d2\u6570 \u505a\u6570\u636e\u5b58\u50a8\u7684\u65f6\u5019\uff0c\u4f1a\u5148\u5c06\u65f6\u95f4\u8f6c\u5316\u4e3a UTC \u65f6\u95f4 \uff0c\u8bfb\u53d6\u7684\u65f6\u5019\u4f1a\u5c06\u5b58\u50a8\u7684 UTC \u65f6\u95f4 \u8f6c\u6362\u4e3a \u672c\u5730\u65f6\u95f4 \u7ed9\u7528\u6237 \u5e95\u5c42\u5b58\u50a8\u6570\u636e\u7c7b\u578b\u4e3a: int64","title":"\u65f6\u95f4\u6233\u7c7b\u578b"},{"location":"manual-CN/2.query-language/1.data-types/data-types/#_7","text":"\u5148\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a school \u7684 tag nebula> CREATE TAG school(name string , create_time timestamp); \u63d2\u5165\u4e00\u4e2a\u70b9\uff0c\u540d\u4e3a \"xiwang\"\uff0c\u5efa\u6821\u65f6\u95f4\u4e3a \"2010-09-01 08:00:00\" nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"xiwang\"):(\"xiwang\", \"2010-09-01 08:00:00\"); \u63d2\u5165\u4e00\u4e2a\u70b9\uff0c\u540d\u4e3a \"guangming\"\uff0c\u5efa\u6821\u65f6\u95f4\u4e3a\u73b0\u5728 nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"guangming\"):(\"guangming\", now());","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/1.data-types/type-conversion/","text":"\u7c7b\u578b\u8f6c\u6362 \u00b6 \u5728 nGQL \u4e2d\uff0c\u7c7b\u578b\u8f6c\u6362\u5206\u4e3a\u9690\u5f0f\u8f6c\u6362\u548c\u663e\u5f0f\u8f6c\u6362\u3002 \u9690\u5f0f\u8f6c\u6362 \u00b6 \u5728\u8868\u8fbe\u5f0f\u4e2d\uff0c\u517c\u5bb9\u7c7b\u578b\u95f4\u53ef\u81ea\u52a8\u5b8c\u6210\u7c7b\u578b\u8f6c\u6362\uff1a \u4ee5\u4e0b\u7c7b\u578b\u5747\u53ef\u9690\u5f0f\u8f6c\u6362\u81f3 bool \u7c7b\u578b\uff1a \u5f53\u4e14\u4ec5\u5f53\u5b57\u7b26\u4e32\u957f\u5ea6\u4e3a 0 \u65f6\uff0c\u53ef\u88ab\u9690\u5f0f\u8f6c\u6362\u4e3a false \uff0c\u5426\u5219\u4e3a true \u5f53\u4e14\u4ec5\u5f53\u6574\u578b\u6570\u503c\u4e3a 0 \u65f6\uff0c\u53ef\u88ab\u9690\u5f0f\u8f6c\u6362\u4e3a false \uff0c\u5426\u5219\u4e3a true \u5f53\u4e14\u4ec5\u5f53\u6d6e\u70b9\u7c7b\u578b\u6570\u503c\u4e3a 0.0 \u65f6\uff0c\u53ef\u88ab\u9690\u5f0f\u8f6c\u6362\u4e3a false \uff0c\u5426\u5219\u4e3a true int \u7c7b\u578b\u53ef\u9690\u5f0f\u8f6c\u6362\u4e3a double \u7c7b\u578b \u663e\u5f0f\u8f6c\u6362 \u00b6 \u9664\u9690\u5f0f\u7c7b\u578b\u8f6c\u6362\u5916\uff0c\u5728\u7b26\u5408\u8bed\u4e49\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528\u663e\u5f0f\u7c7b\u578b\u8f6c\u6362\u3002\u8bed\u6cd5\u89c4\u5219\u7c7b\u4f3c C \u8bed\u8a00\uff1a (type_name)expression \u3002\u4f8b\u5982\uff0c YIELD length((string)(123)), (int)\"123\" + 1 \u6267\u884c\u7ed3\u679c\u4e3a 3, 124 \u3002 YIELD (int)(\"12ab3\") \u5219\u4f1a\u8f6c\u6362\u5931\u8d25\u3002","title":"\u7c7b\u578b\u8f6c\u6362"},{"location":"manual-CN/2.query-language/1.data-types/type-conversion/#_1","text":"\u5728 nGQL \u4e2d\uff0c\u7c7b\u578b\u8f6c\u6362\u5206\u4e3a\u9690\u5f0f\u8f6c\u6362\u548c\u663e\u5f0f\u8f6c\u6362\u3002","title":"\u7c7b\u578b\u8f6c\u6362"},{"location":"manual-CN/2.query-language/1.data-types/type-conversion/#_2","text":"\u5728\u8868\u8fbe\u5f0f\u4e2d\uff0c\u517c\u5bb9\u7c7b\u578b\u95f4\u53ef\u81ea\u52a8\u5b8c\u6210\u7c7b\u578b\u8f6c\u6362\uff1a \u4ee5\u4e0b\u7c7b\u578b\u5747\u53ef\u9690\u5f0f\u8f6c\u6362\u81f3 bool \u7c7b\u578b\uff1a \u5f53\u4e14\u4ec5\u5f53\u5b57\u7b26\u4e32\u957f\u5ea6\u4e3a 0 \u65f6\uff0c\u53ef\u88ab\u9690\u5f0f\u8f6c\u6362\u4e3a false \uff0c\u5426\u5219\u4e3a true \u5f53\u4e14\u4ec5\u5f53\u6574\u578b\u6570\u503c\u4e3a 0 \u65f6\uff0c\u53ef\u88ab\u9690\u5f0f\u8f6c\u6362\u4e3a false \uff0c\u5426\u5219\u4e3a true \u5f53\u4e14\u4ec5\u5f53\u6d6e\u70b9\u7c7b\u578b\u6570\u503c\u4e3a 0.0 \u65f6\uff0c\u53ef\u88ab\u9690\u5f0f\u8f6c\u6362\u4e3a false \uff0c\u5426\u5219\u4e3a true int \u7c7b\u578b\u53ef\u9690\u5f0f\u8f6c\u6362\u4e3a double \u7c7b\u578b","title":"\u9690\u5f0f\u8f6c\u6362"},{"location":"manual-CN/2.query-language/1.data-types/type-conversion/#_3","text":"\u9664\u9690\u5f0f\u7c7b\u578b\u8f6c\u6362\u5916\uff0c\u5728\u7b26\u5408\u8bed\u4e49\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528\u663e\u5f0f\u7c7b\u578b\u8f6c\u6362\u3002\u8bed\u6cd5\u89c4\u5219\u7c7b\u4f3c C \u8bed\u8a00\uff1a (type_name)expression \u3002\u4f8b\u5982\uff0c YIELD length((string)(123)), (int)\"123\" + 1 \u6267\u884c\u7ed3\u679c\u4e3a 3, 124 \u3002 YIELD (int)(\"12ab3\") \u5219\u4f1a\u8f6c\u6362\u5931\u8d25\u3002","title":"\u663e\u5f0f\u8f6c\u6362"},{"location":"manual-CN/2.query-language/2.functions-and-operators/bitwise-operators/","text":"\u4f4d\u8fd0\u7b97\u7b26 \u00b6 \u540d\u79f0 \u63cf\u8ff0 & \u6309\u4f4d\u4e0e | \u6309\u4f4d\u6216 ^ \u6309\u4f4d\u5f02\u6216","title":"\u4f4d\u8fd0\u7b97\u7b26"},{"location":"manual-CN/2.query-language/2.functions-and-operators/bitwise-operators/#_1","text":"\u540d\u79f0 \u63cf\u8ff0 & \u6309\u4f4d\u4e0e | \u6309\u4f4d\u6216 ^ \u6309\u4f4d\u5f02\u6216","title":"\u4f4d\u8fd0\u7b97\u7b26"},{"location":"manual-CN/2.query-language/2.functions-and-operators/built-in-functions/","text":"\u5185\u5efa\u51fd\u6570 \u00b6 Nebula Graph \u652f\u6301\u5728\u8868\u8fbe\u5f0f\u4e2d\u8c03\u7528\u5982\u4e0b\u7c7b\u578b\u7684\u5185\u5efa\u51fd\u6570\u3002 \u6570\u5b66\u76f8\u5173 \u00b6 \u51fd\u6570 \u63cf\u8ff0 double abs(double x) \u8fd4\u56de\u7edd\u5bf9\u503c double floor(double x) \u8fd4\u56de\u5c0f\u4e8e\u53c2\u6570\u7684\u6700\u5927\u6574\u6570\uff08\u5411\u4e0b\u53d6\u6574\uff09 double ceil(double x) \u8fd4\u56de\u5927\u4e8e\u53c2\u6570\u7684\u6700\u5c0f\u6574\u6570\uff08\u5411\u4e0a\u53d6\u6574\uff09 double round(double x) \u5bf9\u53c2\u6570\u53d6\u6574\uff0c\u5982\u679c\u53c2\u6570\u4f4d\u4e8e\u4e2d\u95f4\u4f4d\u7f6e\uff0c\u5219\u8fd4\u56de\u8fdc\u79bb 0 \u7684\u6570\u5b57 double sqrt(double x) \u8fd4\u56de\u53c2\u6570\u7684\u5e73\u65b9\u6839 double cbrt(double x) \u8fd4\u56de\u53c2\u6570\u7684\u7acb\u65b9\u6839 double hypot(double x, double x) \u8fd4\u56de\u4e00\u4e2a\u6b63\u4e09\u89d2\u5f62\u7684\u659c\u8fb9 double pow(double x, double y) \u8fd4\u56de x \u7684 y \u6b21\u5e42 double exp(double x) \u8ba1\u7b97 e \u7684 x \u6b21\u5e42 double exp2(double x) \u8fd4\u56de 2 \u7684\u6307\u5b9a\u6b21\u65b9 double log(double x) \u8fd4\u56de\u53c2\u6570\u7684\u81ea\u7136\u5bf9\u6570 double log2(double x) \u8fd4\u56de\u5e95\u6570\u4e3a 2 \u7684\u5bf9\u6570 double log10(double x) \u8fd4\u56de\u5e95\u6570\u4e3a 10 \u7684\u5bf9\u6570 double sin(double x) \u8fd4\u56de\u6b63\u5f26\u51fd\u6570\u503c double asin(double x) \u8fd4\u56de\u53cd\u6b63\u5f26\u51fd\u6570\u503c double cos(double x) \u8fd4\u56de\u4f59\u5f26\u51fd\u6570\u503c double acos(double x) \u8fd4\u56de\u53cd\u4f59\u5f26\u51fd\u6570\u503c double tan(double x) \u8fd4\u56de\u6b63\u5207\u51fd\u6570\u503c double atan(double x) \u8fd4\u56de\u53cd\u6b63\u5207\u51fd\u6570\u503c int rand32() \u8fd4\u56de 32bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand32(int max) \u8fd4\u56de [0, max) \u533a\u95f4\u5185\u7684 32bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand32(int min, int max) \u8fd4\u56de [min, max) \u533a\u95f4\u5185\u7684 32bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand64() \u8fd4\u56de 64bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand64(int max) \u8fd4\u56de [0, max) \u533a\u95f4\u5185\u7684 64bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand64(int min, int max) \u8fd4\u56de [min, max) \u533a\u95f4\u5185\u7684 64bit \u6574\u578b\u4f2a\u968f\u673a\u6570 \u5b57\u7b26\u4e32\u76f8\u5173 \u00b6 \u6ce8\u610f\uff1a \u548c SQL \u4e00\u6837\uff0cnGQL \u7684\u5b57\u7b26\u7d22\u5f15\uff08\u4f4d\u7f6e\uff09\u4ece 1 \u5f00\u59cb\uff0c\u800c\u4e0d\u662f\u7c7b\u4f3c C \u8bed\u8a00\u4ece 0 \u5f00\u59cb\u3002 \u51fd\u6570 \u63cf\u8ff0 int strcasecmp(string a, string b) \u5927\u5c0f\u5199\u4e0d\u654f\u611f\u7684\u5b57\u7b26\u4e32\u6bd4\u8f83\uff0c\u76f8\u7b49\u65f6\u8fd4\u56de\u96f6\uff0ca > b \u65f6\u8fd4\u56de\u503c\u5927\u4e8e\u96f6\uff0c\u5426\u5219\u8fd4\u56de\u503c\u5c0f\u4e8e\u96f6 string lower(string a) \u5c06\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5c0f\u5199 string upper(string a) \u5c06\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5927\u5199 int length(string a) \u8fd4\u56de\u5b57\u7b26\u4e32\u957f\u5ea6\uff08\u6574\u6570\uff09\uff08\u76ee\u524d\u5b9e\u73b0\u4e3a\uff0c\u8fd4\u56de\u5360\u7528\u5b57\u8282\u6570\uff09 string trim(string a) \u5220\u9664\u5b57\u7b26\u4e32\u4e24\u7aef\u7684\u7a7a\u767d\u5b57\u7b26\uff08\u7a7a\u683c\uff0c\u6362\u884c\uff0c\u5236\u8868\u7b26\u7b49\uff09 string ltrim(string a) \u5220\u9664\u5b57\u7b26\u4e32\u8d77\u59cb\u7684\u7a7a\u767d\u5b57\u7b26 string rtrim(string a) \u5220\u9664\u5b57\u7b26\u4e32\u672b\u5c3e\u7684\u7a7a\u767d\u5b57\u7b26 string left(string a, int count) \u8fd4\u56de [1, count] \u8303\u56f4\u5185\u7684\u5b50\u4e32\uff0c\u82e5\u5b57\u7b26\u4e32\u957f\u5ea6\u5c0f\u4e8e count \uff0c\u5219\u8fd4\u56de\u539f\u5b57\u7b26\u4e32 string right(string a, int count) \u8fd4\u56de [size - count + 1, size] \u8303\u56f4\u5185\u7684\u5b50\u4e32\uff0c\u82e5\u5b57\u7b26\u4e32\u957f\u5ea6\u5c0f\u4e8e count \uff0c\u5219\u8fd4\u56de\u539f\u5b57\u7b26\u4e32 string lpad(string a, int size, string letters) \u4f7f\u7528\u5b57\u7b26\u4e32 letters \u4ece\u5de6\u4fa7\u586b\u5145\u5b57\u7b26\u4e32\u81f3\u5176\u957f\u5ea6\u4e0d\u5c0f\u4e8e size string rpad(string a, int size, string letters) \u4f7f\u7528\u5b57\u7b26\u4e32 letters \u4ece\u53f3\u4fa7\u586b\u5145\u5b57\u7b26\u4e32\u81f3\u5176\u957f\u5ea6\u4e0d\u5c0f\u4e8e size string substr(string a, int pos, int count) \u4ece\u6307\u5b9a\u8d77\u59cb\u4f4d\u7f6e pos \u5f00\u59cb\uff0c\u83b7\u53d6\u957f\u5ea6\u4e3a count \u7684\u5b50\u4e32 int hash(string a) \u5bf9\u6570\u503c\u8fdb\u884c hash\uff0c\u8fd4\u56de\u503c\u7c7b\u578b\u4e3a\u6574\u6570 \u51fd\u6570 substr \u8fd4\u56de\u7ed3\u679c \u6ce8\u91ca \uff1a \u5982\u679c pos \u7b49\u4e8e 0 \uff0c\u8fd4\u56de\u7a7a\u4e32 \u5982\u679c pos \u7edd\u5bf9\u503c\u5927\u4e8e\u539f\u5b57\u7b26\u4e32\u7684\u957f\u5ea6\uff0c\u8fd4\u56de\u7a7a\u4e32 \u5982\u679c pos \u5927\u4e8e 0 \uff0c\u8fd4\u56de [pos, pos + count) \u8303\u56f4\u5185\u7684\u5b50\u4e32 \u5982\u679c pos \u5c0f\u4e8e 0 \uff0c\u8bbe\u8d77\u59cb\u4f4d\u7f6e N \u4e3a length(a) + pos + 1 \uff0c\u8fd4\u56de [N, N + count) \u8303\u56f4\u5185\u7684\u5b50\u4e32 \u5982\u679c count \u5927\u4e8e length(a) \uff0c\u5219\u8fd4\u56de\u6574\u4e2a\u5b57\u7b26\u4e32 \u65f6\u95f4\u76f8\u5173 \u00b6 \u51fd\u6570 \u63cf\u8ff0 int now() \u8fd4\u56de\u5f53\u524d\u65f6\u95f4\u6233","title":"\u5185\u5efa\u51fd\u6570"},{"location":"manual-CN/2.query-language/2.functions-and-operators/built-in-functions/#_1","text":"Nebula Graph \u652f\u6301\u5728\u8868\u8fbe\u5f0f\u4e2d\u8c03\u7528\u5982\u4e0b\u7c7b\u578b\u7684\u5185\u5efa\u51fd\u6570\u3002","title":"\u5185\u5efa\u51fd\u6570"},{"location":"manual-CN/2.query-language/2.functions-and-operators/built-in-functions/#_2","text":"\u51fd\u6570 \u63cf\u8ff0 double abs(double x) \u8fd4\u56de\u7edd\u5bf9\u503c double floor(double x) \u8fd4\u56de\u5c0f\u4e8e\u53c2\u6570\u7684\u6700\u5927\u6574\u6570\uff08\u5411\u4e0b\u53d6\u6574\uff09 double ceil(double x) \u8fd4\u56de\u5927\u4e8e\u53c2\u6570\u7684\u6700\u5c0f\u6574\u6570\uff08\u5411\u4e0a\u53d6\u6574\uff09 double round(double x) \u5bf9\u53c2\u6570\u53d6\u6574\uff0c\u5982\u679c\u53c2\u6570\u4f4d\u4e8e\u4e2d\u95f4\u4f4d\u7f6e\uff0c\u5219\u8fd4\u56de\u8fdc\u79bb 0 \u7684\u6570\u5b57 double sqrt(double x) \u8fd4\u56de\u53c2\u6570\u7684\u5e73\u65b9\u6839 double cbrt(double x) \u8fd4\u56de\u53c2\u6570\u7684\u7acb\u65b9\u6839 double hypot(double x, double x) \u8fd4\u56de\u4e00\u4e2a\u6b63\u4e09\u89d2\u5f62\u7684\u659c\u8fb9 double pow(double x, double y) \u8fd4\u56de x \u7684 y \u6b21\u5e42 double exp(double x) \u8ba1\u7b97 e \u7684 x \u6b21\u5e42 double exp2(double x) \u8fd4\u56de 2 \u7684\u6307\u5b9a\u6b21\u65b9 double log(double x) \u8fd4\u56de\u53c2\u6570\u7684\u81ea\u7136\u5bf9\u6570 double log2(double x) \u8fd4\u56de\u5e95\u6570\u4e3a 2 \u7684\u5bf9\u6570 double log10(double x) \u8fd4\u56de\u5e95\u6570\u4e3a 10 \u7684\u5bf9\u6570 double sin(double x) \u8fd4\u56de\u6b63\u5f26\u51fd\u6570\u503c double asin(double x) \u8fd4\u56de\u53cd\u6b63\u5f26\u51fd\u6570\u503c double cos(double x) \u8fd4\u56de\u4f59\u5f26\u51fd\u6570\u503c double acos(double x) \u8fd4\u56de\u53cd\u4f59\u5f26\u51fd\u6570\u503c double tan(double x) \u8fd4\u56de\u6b63\u5207\u51fd\u6570\u503c double atan(double x) \u8fd4\u56de\u53cd\u6b63\u5207\u51fd\u6570\u503c int rand32() \u8fd4\u56de 32bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand32(int max) \u8fd4\u56de [0, max) \u533a\u95f4\u5185\u7684 32bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand32(int min, int max) \u8fd4\u56de [min, max) \u533a\u95f4\u5185\u7684 32bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand64() \u8fd4\u56de 64bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand64(int max) \u8fd4\u56de [0, max) \u533a\u95f4\u5185\u7684 64bit \u6574\u578b\u4f2a\u968f\u673a\u6570 int rand64(int min, int max) \u8fd4\u56de [min, max) \u533a\u95f4\u5185\u7684 64bit \u6574\u578b\u4f2a\u968f\u673a\u6570","title":"\u6570\u5b66\u76f8\u5173"},{"location":"manual-CN/2.query-language/2.functions-and-operators/built-in-functions/#_3","text":"\u6ce8\u610f\uff1a \u548c SQL \u4e00\u6837\uff0cnGQL \u7684\u5b57\u7b26\u7d22\u5f15\uff08\u4f4d\u7f6e\uff09\u4ece 1 \u5f00\u59cb\uff0c\u800c\u4e0d\u662f\u7c7b\u4f3c C \u8bed\u8a00\u4ece 0 \u5f00\u59cb\u3002 \u51fd\u6570 \u63cf\u8ff0 int strcasecmp(string a, string b) \u5927\u5c0f\u5199\u4e0d\u654f\u611f\u7684\u5b57\u7b26\u4e32\u6bd4\u8f83\uff0c\u76f8\u7b49\u65f6\u8fd4\u56de\u96f6\uff0ca > b \u65f6\u8fd4\u56de\u503c\u5927\u4e8e\u96f6\uff0c\u5426\u5219\u8fd4\u56de\u503c\u5c0f\u4e8e\u96f6 string lower(string a) \u5c06\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5c0f\u5199 string upper(string a) \u5c06\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u5927\u5199 int length(string a) \u8fd4\u56de\u5b57\u7b26\u4e32\u957f\u5ea6\uff08\u6574\u6570\uff09\uff08\u76ee\u524d\u5b9e\u73b0\u4e3a\uff0c\u8fd4\u56de\u5360\u7528\u5b57\u8282\u6570\uff09 string trim(string a) \u5220\u9664\u5b57\u7b26\u4e32\u4e24\u7aef\u7684\u7a7a\u767d\u5b57\u7b26\uff08\u7a7a\u683c\uff0c\u6362\u884c\uff0c\u5236\u8868\u7b26\u7b49\uff09 string ltrim(string a) \u5220\u9664\u5b57\u7b26\u4e32\u8d77\u59cb\u7684\u7a7a\u767d\u5b57\u7b26 string rtrim(string a) \u5220\u9664\u5b57\u7b26\u4e32\u672b\u5c3e\u7684\u7a7a\u767d\u5b57\u7b26 string left(string a, int count) \u8fd4\u56de [1, count] \u8303\u56f4\u5185\u7684\u5b50\u4e32\uff0c\u82e5\u5b57\u7b26\u4e32\u957f\u5ea6\u5c0f\u4e8e count \uff0c\u5219\u8fd4\u56de\u539f\u5b57\u7b26\u4e32 string right(string a, int count) \u8fd4\u56de [size - count + 1, size] \u8303\u56f4\u5185\u7684\u5b50\u4e32\uff0c\u82e5\u5b57\u7b26\u4e32\u957f\u5ea6\u5c0f\u4e8e count \uff0c\u5219\u8fd4\u56de\u539f\u5b57\u7b26\u4e32 string lpad(string a, int size, string letters) \u4f7f\u7528\u5b57\u7b26\u4e32 letters \u4ece\u5de6\u4fa7\u586b\u5145\u5b57\u7b26\u4e32\u81f3\u5176\u957f\u5ea6\u4e0d\u5c0f\u4e8e size string rpad(string a, int size, string letters) \u4f7f\u7528\u5b57\u7b26\u4e32 letters \u4ece\u53f3\u4fa7\u586b\u5145\u5b57\u7b26\u4e32\u81f3\u5176\u957f\u5ea6\u4e0d\u5c0f\u4e8e size string substr(string a, int pos, int count) \u4ece\u6307\u5b9a\u8d77\u59cb\u4f4d\u7f6e pos \u5f00\u59cb\uff0c\u83b7\u53d6\u957f\u5ea6\u4e3a count \u7684\u5b50\u4e32 int hash(string a) \u5bf9\u6570\u503c\u8fdb\u884c hash\uff0c\u8fd4\u56de\u503c\u7c7b\u578b\u4e3a\u6574\u6570 \u51fd\u6570 substr \u8fd4\u56de\u7ed3\u679c \u6ce8\u91ca \uff1a \u5982\u679c pos \u7b49\u4e8e 0 \uff0c\u8fd4\u56de\u7a7a\u4e32 \u5982\u679c pos \u7edd\u5bf9\u503c\u5927\u4e8e\u539f\u5b57\u7b26\u4e32\u7684\u957f\u5ea6\uff0c\u8fd4\u56de\u7a7a\u4e32 \u5982\u679c pos \u5927\u4e8e 0 \uff0c\u8fd4\u56de [pos, pos + count) \u8303\u56f4\u5185\u7684\u5b50\u4e32 \u5982\u679c pos \u5c0f\u4e8e 0 \uff0c\u8bbe\u8d77\u59cb\u4f4d\u7f6e N \u4e3a length(a) + pos + 1 \uff0c\u8fd4\u56de [N, N + count) \u8303\u56f4\u5185\u7684\u5b50\u4e32 \u5982\u679c count \u5927\u4e8e length(a) \uff0c\u5219\u8fd4\u56de\u6574\u4e2a\u5b57\u7b26\u4e32","title":"\u5b57\u7b26\u4e32\u76f8\u5173"},{"location":"manual-CN/2.query-language/2.functions-and-operators/built-in-functions/#_4","text":"\u51fd\u6570 \u63cf\u8ff0 int now() \u8fd4\u56de\u5f53\u524d\u65f6\u95f4\u6233","title":"\u65f6\u95f4\u76f8\u5173"},{"location":"manual-CN/2.query-language/2.functions-and-operators/comparison-functions-and-operators/","text":"\u6bd4\u8f83\u51fd\u6570\u548c\u8fd0\u7b97\u7b26 \u00b6 \u8fd0\u7b97\u7b26 \u63cf\u8ff0 = \u8d4b\u503c\u8fd0\u7b97\u7b26 / \u9664\u6cd5\u8fd0\u7b97\u7b26 == \u7b49\u4e8e\u8fd0\u7b97\u7b26 != \u4e0d\u7b49\u4e8e\u8fd0\u7b97\u7b26 < \u5c0f\u4e8e\u8fd0\u7b97\u7b26 <= \u5c0f\u4e8e\u6216\u7b49\u4e8e\u8fd0\u7b97\u7b26 - \u51cf\u6cd5\u8fd0\u7b97\u7b26 % \u4f59\u6570\u8fd0\u7b97\u7b26 + \u52a0\u6cd5\u8fd0\u7b97\u7b26 * \u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u8d1f\u53f7\u8fd0\u7b97\u7b26 udf_is_in() \u6bd4\u8f83\u51fd\u6570\uff0c\u5224\u65ad\u503c\u662f\u5426\u5728\u6307\u5b9a\u7684\u5217\u8868\u4e2d \u6bd4\u8f83\u8fd0\u7b97\u7684\u7ed3\u679c\u662f true \u6216 false \u3002 == \u7b49\u4e8e\u3002String\u7684\u6bd4\u8f83\u5927\u5c0f\u5199\u654f\u611f\u3002\u4e0d\u540c\u7c7b\u7684\u503c\u4e0d\u76f8\u540c\uff1a nebula> YIELD 'A' == 'a'; ============== | (\"A\"==\"a\") | ============== | false | -------------- nebula> YIELD '2' == 2; [ERROR (-8)]: A string type can not be compared with a non-string type. > \u5927\u4e8e\uff1a nebula> YIELD 3 > 2; ========= | (3>2) | ========= | true | --------- \u2265 \u5927\u4e8e\u6216\u7b49\u4e8e\uff1a nebula> YIELD 2 >= 2; ========== | (2>=2) | ========== | true | ---------- < \u5c0f\u4e8e\uff1a nebula> YIELD 2.0 < 1.9; ======================= | (2.000000<1.900000) | ======================= | false | ----------------------- \u2264 \u5c0f\u4e8e\u6216\u7b49\u4e8e\uff1a nebula> YIELD 0.11 <= 0.11; ======================== | (0.110000<=0.110000) | ======================== | true | ------------------------ != \u4e0d\u7b49\u4e8e\uff1a nebula> YIELD 1 != '1'; [ERROR (-8)]: A string type can not be compared with a non-string type. udf_is_in() \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u8981\u6bd4\u8f83\u7684\u503c\u3002 nebula> YIELD udf_is_in(1,0,1,2); ====================== | udf_is_in(1,0,1,2) | ====================== | true | ---------------------- nebula> GO FROM 100 OVER follow WHERE udf_is_in($$.player.name, \"Tony Parker\"); /*\u7531\u4e8eudf_is_in \u540e\u9762\u53ef\u80fd\u53d8\u66f4\uff0c\u6240\u4ee5\u8be5\u793a\u4f8b\u53ef\u80fd\u5931\u6548\u3002*/ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | GO FROM $-.id OVER follow WHERE udf_is_in($-.id, 102, 102 + 1); =============== | follow._dst | =============== | 100 | --------------- | 101 | ---------------","title":"\u6bd4\u8f83\u51fd\u6570\u548c\u8fd0\u7b97\u7b26"},{"location":"manual-CN/2.query-language/2.functions-and-operators/comparison-functions-and-operators/#_1","text":"\u8fd0\u7b97\u7b26 \u63cf\u8ff0 = \u8d4b\u503c\u8fd0\u7b97\u7b26 / \u9664\u6cd5\u8fd0\u7b97\u7b26 == \u7b49\u4e8e\u8fd0\u7b97\u7b26 != \u4e0d\u7b49\u4e8e\u8fd0\u7b97\u7b26 < \u5c0f\u4e8e\u8fd0\u7b97\u7b26 <= \u5c0f\u4e8e\u6216\u7b49\u4e8e\u8fd0\u7b97\u7b26 - \u51cf\u6cd5\u8fd0\u7b97\u7b26 % \u4f59\u6570\u8fd0\u7b97\u7b26 + \u52a0\u6cd5\u8fd0\u7b97\u7b26 * \u4e58\u6cd5\u8fd0\u7b97\u7b26 - \u8d1f\u53f7\u8fd0\u7b97\u7b26 udf_is_in() \u6bd4\u8f83\u51fd\u6570\uff0c\u5224\u65ad\u503c\u662f\u5426\u5728\u6307\u5b9a\u7684\u5217\u8868\u4e2d \u6bd4\u8f83\u8fd0\u7b97\u7684\u7ed3\u679c\u662f true \u6216 false \u3002 == \u7b49\u4e8e\u3002String\u7684\u6bd4\u8f83\u5927\u5c0f\u5199\u654f\u611f\u3002\u4e0d\u540c\u7c7b\u7684\u503c\u4e0d\u76f8\u540c\uff1a nebula> YIELD 'A' == 'a'; ============== | (\"A\"==\"a\") | ============== | false | -------------- nebula> YIELD '2' == 2; [ERROR (-8)]: A string type can not be compared with a non-string type. > \u5927\u4e8e\uff1a nebula> YIELD 3 > 2; ========= | (3>2) | ========= | true | --------- \u2265 \u5927\u4e8e\u6216\u7b49\u4e8e\uff1a nebula> YIELD 2 >= 2; ========== | (2>=2) | ========== | true | ---------- < \u5c0f\u4e8e\uff1a nebula> YIELD 2.0 < 1.9; ======================= | (2.000000<1.900000) | ======================= | false | ----------------------- \u2264 \u5c0f\u4e8e\u6216\u7b49\u4e8e\uff1a nebula> YIELD 0.11 <= 0.11; ======================== | (0.110000<=0.110000) | ======================== | true | ------------------------ != \u4e0d\u7b49\u4e8e\uff1a nebula> YIELD 1 != '1'; [ERROR (-8)]: A string type can not be compared with a non-string type. udf_is_in() \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u8981\u6bd4\u8f83\u7684\u503c\u3002 nebula> YIELD udf_is_in(1,0,1,2); ====================== | udf_is_in(1,0,1,2) | ====================== | true | ---------------------- nebula> GO FROM 100 OVER follow WHERE udf_is_in($$.player.name, \"Tony Parker\"); /*\u7531\u4e8eudf_is_in \u540e\u9762\u53ef\u80fd\u53d8\u66f4\uff0c\u6240\u4ee5\u8be5\u793a\u4f8b\u53ef\u80fd\u5931\u6548\u3002*/ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | GO FROM $-.id OVER follow WHERE udf_is_in($-.id, 102, 102 + 1); =============== | follow._dst | =============== | 100 | --------------- | 101 | ---------------","title":"\u6bd4\u8f83\u51fd\u6570\u548c\u8fd0\u7b97\u7b26"},{"location":"manual-CN/2.query-language/2.functions-and-operators/group-by-function/","text":"\u805a\u5408\u51fd\u6570 (Group By) \u00b6 GROUP BY \u51fd\u6570\u7c7b\u4f3c\u4e8e SQL\u3002 \u53ea\u80fd\u4e0e YIELD \u8bed\u53e5\u4e00\u8d77\u4f7f\u7528\u3002 \u540d\u79f0 \u63cf\u8ff0 AVG() \u8fd4\u56de\u53c2\u6570\u7684\u5e73\u5747\u503c COUNT() \u8fd4\u56de\u8bb0\u5f55\u503c\u603b\u6570 COUNT_DISTINCT()) \u8fd4\u56de\u72ec\u7acb\u8bb0\u5f55\u503c\u7684\u603b\u6570 MAX() \u8fd4\u56de\u6700\u5927\u503c MIN() \u8fd4\u56de\u6700\u5c0f\u503c STD() \u8fd4\u56de\u603b\u4f53\u6807\u51c6\u5dee SUM() \u8fd4\u56de\u603b\u5408 BIT_AND() \u6309\u4f4d\u4e0e BIT_OR() \u6309\u4f4d\u6216 BIT_XOR() \u6309\u4f4d\u5f02\u6216 \u4ee5\u4e0a\u51fd\u6570\u53ea\u4f5c\u7528\u4e8e int64 \u548c double\u3002 \u793a\u4f8b \u00b6 nebula> GO FROM 100 OVER follow YIELD $$.player.name as Name | GROUP BY $-.Name YIELD $-.Name, COUNT(*); -- \u4ece\u8282\u70b9 100 \u51fa\u53d1\uff0c\u67e5\u627e\u5176\u5173\u6ce8\u7684\u7403\u5458\u5e76\u8fd4\u56de\u7403\u5458\u7684\u59d3\u540d\u4f5c\u4e3a Name\uff0c\u6309\u7167\u59d3\u540d\u5bf9\u7403\u5458\u5206\u7ec4\u5e76\u7edf\u8ba1\u6bcf\u4e2a\u5206\u7ec4\u7684\u4eba\u6570\u3002 -- \u8fd4\u56de\u4ee5\u4e0b\u7ed3\u679c\uff1a ================================ | $-.Name | COUNT(*) | ================================ | Kyle Anderson | 1 | -------------------------------- | Tony Parker | 1 | -------------------------------- | LaMarcus Aldridge | 1 | -------------------------------- nebula> GO FROM 101 OVER follow YIELD follow._src AS player, follow.degree AS degree | GROUP BY $-.player YIELD SUM($-.degree); -- \u4ece\u8282\u70b9 101 \u51fa\u53d1\u627e\u5230\u5176\u5173\u6ce8\u7684\u7403\u5458\uff0c\u8fd4\u56de\u8fd9\u4e9b\u7403\u5458\u4f5c\u4e3a player\uff0c\u8fb9\uff08follow\uff09\u7684\u5c5e\u6027\u503c\u4f5c\u4e3a degree\uff0c\u5bf9\u8fd9\u4e9b\u7403\u5458\u5206\u7ec4\u5e76\u8fd4\u56de\u5206\u7ec4\u7403\u5458\u5c5e\u6027 degree \u76f8\u52a0\u7684\u503c\u3002 -- \u8fd4\u56de\u4ee5\u4e0b\u7ed3\u679c\uff1a ================== | SUM($-.degree) | ================== | 186 | ------------------","title":"\u805a\u5408\u51fd\u6570 (Group By)"},{"location":"manual-CN/2.query-language/2.functions-and-operators/group-by-function/#group_by","text":"GROUP BY \u51fd\u6570\u7c7b\u4f3c\u4e8e SQL\u3002 \u53ea\u80fd\u4e0e YIELD \u8bed\u53e5\u4e00\u8d77\u4f7f\u7528\u3002 \u540d\u79f0 \u63cf\u8ff0 AVG() \u8fd4\u56de\u53c2\u6570\u7684\u5e73\u5747\u503c COUNT() \u8fd4\u56de\u8bb0\u5f55\u503c\u603b\u6570 COUNT_DISTINCT()) \u8fd4\u56de\u72ec\u7acb\u8bb0\u5f55\u503c\u7684\u603b\u6570 MAX() \u8fd4\u56de\u6700\u5927\u503c MIN() \u8fd4\u56de\u6700\u5c0f\u503c STD() \u8fd4\u56de\u603b\u4f53\u6807\u51c6\u5dee SUM() \u8fd4\u56de\u603b\u5408 BIT_AND() \u6309\u4f4d\u4e0e BIT_OR() \u6309\u4f4d\u6216 BIT_XOR() \u6309\u4f4d\u5f02\u6216 \u4ee5\u4e0a\u51fd\u6570\u53ea\u4f5c\u7528\u4e8e int64 \u548c double\u3002","title":"\u805a\u5408\u51fd\u6570 (Group By)"},{"location":"manual-CN/2.query-language/2.functions-and-operators/group-by-function/#_1","text":"nebula> GO FROM 100 OVER follow YIELD $$.player.name as Name | GROUP BY $-.Name YIELD $-.Name, COUNT(*); -- \u4ece\u8282\u70b9 100 \u51fa\u53d1\uff0c\u67e5\u627e\u5176\u5173\u6ce8\u7684\u7403\u5458\u5e76\u8fd4\u56de\u7403\u5458\u7684\u59d3\u540d\u4f5c\u4e3a Name\uff0c\u6309\u7167\u59d3\u540d\u5bf9\u7403\u5458\u5206\u7ec4\u5e76\u7edf\u8ba1\u6bcf\u4e2a\u5206\u7ec4\u7684\u4eba\u6570\u3002 -- \u8fd4\u56de\u4ee5\u4e0b\u7ed3\u679c\uff1a ================================ | $-.Name | COUNT(*) | ================================ | Kyle Anderson | 1 | -------------------------------- | Tony Parker | 1 | -------------------------------- | LaMarcus Aldridge | 1 | -------------------------------- nebula> GO FROM 101 OVER follow YIELD follow._src AS player, follow.degree AS degree | GROUP BY $-.player YIELD SUM($-.degree); -- \u4ece\u8282\u70b9 101 \u51fa\u53d1\u627e\u5230\u5176\u5173\u6ce8\u7684\u7403\u5458\uff0c\u8fd4\u56de\u8fd9\u4e9b\u7403\u5458\u4f5c\u4e3a player\uff0c\u8fb9\uff08follow\uff09\u7684\u5c5e\u6027\u503c\u4f5c\u4e3a degree\uff0c\u5bf9\u8fd9\u4e9b\u7403\u5458\u5206\u7ec4\u5e76\u8fd4\u56de\u5206\u7ec4\u7403\u5458\u5c5e\u6027 degree \u76f8\u52a0\u7684\u503c\u3002 -- \u8fd4\u56de\u4ee5\u4e0b\u7ed3\u679c\uff1a ================== | SUM($-.degree) | ================== | 186 | ------------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/2.functions-and-operators/limit-syntax/","text":"LIMIT \u8bed\u6cd5 \u00b6 LIMIT \u7528\u6cd5\u4e0e SQL \u4e2d\u7684\u76f8\u540c\uff0c\u4e14\u53ea\u80fd\u4e0e | \u7ed3\u5408\u4f7f\u7528\u3002 LIMIT \u5b50\u53e5\u63a5\u53d7\u4e00\u4e2a\u6216\u4e24\u4e2a\u53c2\u6570,\u4e24\u4e2a\u53c2\u6570\u7684\u503c\u90fd\u5fc5\u987b\u662f\u96f6\u6216\u6b63\u6574\u6570\u3002 ORDER BY <expressions> [ASC | DESC] LIMIT [<offset_value>,] <number_rows> expressions \u5f85\u6392\u5e8f\u7684\u5217\u6216\u8ba1\u7b97\u3002 number_rows number_rows \u6307\u5b9a\u8fd4\u56de\u7ed3\u679c\u884c\u6570\u3002\u4f8b\u5982\uff0cLIMIT 10 \u8fd4\u56de\u524d 10 \u884c\u7ed3\u679c\u3002\u7531\u4e8e\u6392\u5e8f\u987a\u5e8f\u4f1a\u5f71\u54cd\u8fd4\u56de\u7ed3\u679c\uff0c\u6240\u4ee5\u4f7f\u7528 ORDER BY \u65f6\u8bf7\u6ce8\u610f\u6392\u5e8f\u987a\u5e8f\u3002 offset_value \u53ef\u9009\u9009\u9879\uff0c\u7528\u6765\u8df3\u8fc7\u6307\u5b9a\u884c\u6570\u8fd4\u56de\u7ed3\u679c\uff0coffset \u4ece 0 \u5f00\u59cb\u3002 \u5f53\u4f7f\u7528 LIMIT \u65f6\uff0c\u8bf7\u4f7f\u7528 ORDER BY \u5b50\u53e5\u5bf9\u8fd4\u56de\u7ed3\u679c\u8fdb\u884c\u552f\u4e00\u6392\u5e8f\u3002\u5426\u5219\uff0c\u5c06\u8fd4\u56de\u96be\u4ee5\u9884\u6d4b\u7684\u5b50\u96c6\u3002 \u4f8b\u5982\uff1a nebula> GO FROM 200 OVER serve REVERSELY YIELD $$.player.name AS Friend, $$.player.age AS Age | ORDER BY Age, Friend | LIMIT 3; ========================= | Friend | Age | ========================= | Kyle Anderson | 25 | ------------------------- | Aron Baynes | 32 | ------------------------- | Marco Belinelli | 32 |","title":"LIMIT \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/2.functions-and-operators/limit-syntax/#limit","text":"LIMIT \u7528\u6cd5\u4e0e SQL \u4e2d\u7684\u76f8\u540c\uff0c\u4e14\u53ea\u80fd\u4e0e | \u7ed3\u5408\u4f7f\u7528\u3002 LIMIT \u5b50\u53e5\u63a5\u53d7\u4e00\u4e2a\u6216\u4e24\u4e2a\u53c2\u6570,\u4e24\u4e2a\u53c2\u6570\u7684\u503c\u90fd\u5fc5\u987b\u662f\u96f6\u6216\u6b63\u6574\u6570\u3002 ORDER BY <expressions> [ASC | DESC] LIMIT [<offset_value>,] <number_rows> expressions \u5f85\u6392\u5e8f\u7684\u5217\u6216\u8ba1\u7b97\u3002 number_rows number_rows \u6307\u5b9a\u8fd4\u56de\u7ed3\u679c\u884c\u6570\u3002\u4f8b\u5982\uff0cLIMIT 10 \u8fd4\u56de\u524d 10 \u884c\u7ed3\u679c\u3002\u7531\u4e8e\u6392\u5e8f\u987a\u5e8f\u4f1a\u5f71\u54cd\u8fd4\u56de\u7ed3\u679c\uff0c\u6240\u4ee5\u4f7f\u7528 ORDER BY \u65f6\u8bf7\u6ce8\u610f\u6392\u5e8f\u987a\u5e8f\u3002 offset_value \u53ef\u9009\u9009\u9879\uff0c\u7528\u6765\u8df3\u8fc7\u6307\u5b9a\u884c\u6570\u8fd4\u56de\u7ed3\u679c\uff0coffset \u4ece 0 \u5f00\u59cb\u3002 \u5f53\u4f7f\u7528 LIMIT \u65f6\uff0c\u8bf7\u4f7f\u7528 ORDER BY \u5b50\u53e5\u5bf9\u8fd4\u56de\u7ed3\u679c\u8fdb\u884c\u552f\u4e00\u6392\u5e8f\u3002\u5426\u5219\uff0c\u5c06\u8fd4\u56de\u96be\u4ee5\u9884\u6d4b\u7684\u5b50\u96c6\u3002 \u4f8b\u5982\uff1a nebula> GO FROM 200 OVER serve REVERSELY YIELD $$.player.name AS Friend, $$.player.age AS Age | ORDER BY Age, Friend | LIMIT 3; ========================= | Friend | Age | ========================= | Kyle Anderson | 25 | ------------------------- | Aron Baynes | 32 | ------------------------- | Marco Belinelli | 32 |","title":"LIMIT \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/2.functions-and-operators/logical-operators/","text":"\u903b\u8f91\u8fd0\u7b97\u7b26 \u00b6 \u540d\u79f0 \u63cf\u8ff0 && \u903b\u8f91\u4e0e AND ! \u903b\u8f91\u975e NOT || \u903b\u8f91\u6216 OR XOR \u903b\u8f91\u5f02\u6216 XOR \u5728 nGQL \u4e2d\uff0c\u975e 0 \u6570\u5b57\u5c06\u88ab\u89c6\u4e3a true \u3002\u903b\u8f91\u8fd0\u7b97\u7b26\u7684\u4f18\u5148\u7ea7\u53c2\u89c1 Operator Precedence \u3002 && \u903b\u8f91\u4e0e AND: nebula> YIELD -1 && true; ================ | (-(1)&&true) | ================ | true | ---------------- ! \u903b\u8f91\u975e NOT: nebula> YIELD !(-1); =========== | !(-(1)) | =========== | false | ----------- || \u903b\u8f91\u6216 OR: nebula> YIELD 1 || !1; ============= | (1||!(1)) | ============= | true | XOR \u903b\u8f91\u5f02\u6216 XOR: nebula> YIELD (NOT 0 || 0) AND 0 XOR 1 AS ret; ========= | ret | ========= | true | ---------","title":"\u903b\u8f91\u8fd0\u7b97\u7b26"},{"location":"manual-CN/2.query-language/2.functions-and-operators/logical-operators/#_1","text":"\u540d\u79f0 \u63cf\u8ff0 && \u903b\u8f91\u4e0e AND ! \u903b\u8f91\u975e NOT || \u903b\u8f91\u6216 OR XOR \u903b\u8f91\u5f02\u6216 XOR \u5728 nGQL \u4e2d\uff0c\u975e 0 \u6570\u5b57\u5c06\u88ab\u89c6\u4e3a true \u3002\u903b\u8f91\u8fd0\u7b97\u7b26\u7684\u4f18\u5148\u7ea7\u53c2\u89c1 Operator Precedence \u3002 && \u903b\u8f91\u4e0e AND: nebula> YIELD -1 && true; ================ | (-(1)&&true) | ================ | true | ---------------- ! \u903b\u8f91\u975e NOT: nebula> YIELD !(-1); =========== | !(-(1)) | =========== | false | ----------- || \u903b\u8f91\u6216 OR: nebula> YIELD 1 || !1; ============= | (1||!(1)) | ============= | true | XOR \u903b\u8f91\u5f02\u6216 XOR: nebula> YIELD (NOT 0 || 0) AND 0 XOR 1 AS ret; ========= | ret | ========= | true | ---------","title":"\u903b\u8f91\u8fd0\u7b97\u7b26"},{"location":"manual-CN/2.query-language/2.functions-and-operators/operator-precedence/","text":"\u8fd0\u7b97\u7b26\u4f18\u5148\u7ea7 \u00b6 \u4e0b\u9762\u7684\u5217\u8868\u5c55\u793a\u4e86 nGQL \u8fd0\u7b97\u7b26\u7684\u4f18\u5148\u7ea7\uff08\u964d\u5e8f\uff09\u3002\u540c\u4e00\u884c\u7684\u8fd0\u7b97\u7b26\u62e5\u6709\u4e00\u81f4\u7684\u4f18\u5148\u7ea7\u3002 ! - ( \u51cf\u6cd5 ) * , / , % - , + == , >= , > , <= , < , <> , != && || = ( \u8d4b\u503c ) \u5728\u4e00\u4e2a\u8868\u8fbe\u5f0f\u4e2d\uff0c\u540c\u7b49\u4f18\u5148\u7ea7\u7684\u8fd0\u7b97\u7b26\u5c06\u6309\u7167\u4ece\u5de6\u5230\u53f3\u7684\u987a\u5e8f\u6267\u884c\uff0c\u552f\u4e00\u4f8b\u5916\u662f\u8d4b\u503c\u6309\u7167\u4ece\u53f3\u5f80\u5de6\u7684\u987a\u5e8f\u6267\u884c\u3002\u4f46\u662f\uff0c\u53ef\u4ee5\u4f7f\u7528\u62ec\u53f7\u6765\u4fee\u6539\u6267\u884c\u987a\u5e8f\u3002 \u793a\u4f8b: nebula> YIELD 2+3*5; nebula> YIELD (2+3)*5;","title":"\u8fd0\u7b97\u7b26\u4f18\u5148\u7ea7"},{"location":"manual-CN/2.query-language/2.functions-and-operators/operator-precedence/#_1","text":"\u4e0b\u9762\u7684\u5217\u8868\u5c55\u793a\u4e86 nGQL \u8fd0\u7b97\u7b26\u7684\u4f18\u5148\u7ea7\uff08\u964d\u5e8f\uff09\u3002\u540c\u4e00\u884c\u7684\u8fd0\u7b97\u7b26\u62e5\u6709\u4e00\u81f4\u7684\u4f18\u5148\u7ea7\u3002 ! - ( \u51cf\u6cd5 ) * , / , % - , + == , >= , > , <= , < , <> , != && || = ( \u8d4b\u503c ) \u5728\u4e00\u4e2a\u8868\u8fbe\u5f0f\u4e2d\uff0c\u540c\u7b49\u4f18\u5148\u7ea7\u7684\u8fd0\u7b97\u7b26\u5c06\u6309\u7167\u4ece\u5de6\u5230\u53f3\u7684\u987a\u5e8f\u6267\u884c\uff0c\u552f\u4e00\u4f8b\u5916\u662f\u8d4b\u503c\u6309\u7167\u4ece\u53f3\u5f80\u5de6\u7684\u987a\u5e8f\u6267\u884c\u3002\u4f46\u662f\uff0c\u53ef\u4ee5\u4f7f\u7528\u62ec\u53f7\u6765\u4fee\u6539\u6267\u884c\u987a\u5e8f\u3002 \u793a\u4f8b: nebula> YIELD 2+3*5; nebula> YIELD (2+3)*5;","title":"\u8fd0\u7b97\u7b26\u4f18\u5148\u7ea7"},{"location":"manual-CN/2.query-language/2.functions-and-operators/order-by-function/","text":"Order By \u51fd\u6570 \u00b6 \u7c7b\u4f3c\u4e8e SQL\uff0c ORDER BY \u53ef\u4ee5\u8fdb\u884c\u5347\u5e8f ( ASC ) \u6216\u964d\u5e8f ( DESC ) \u6392\u5e8f\u5e76\u8fd4\u56de\u7ed3\u679c\uff0c\u5e76\u4e14\u5b83\u53ea\u80fd\u5728 PIPE \u8bed\u53e5 ( | ) \u4e2d\u4f7f\u7528\u3002 ORDER BY <expression> [ASC | DESC] [, <expression> [ASC | DESC] ...] \u5982\u679c\u6ca1\u6709\u6307\u660e ASC \u6216 DESC\uff0c ORDER BY \u5c06\u9ed8\u8ba4\u8fdb\u884c\u5347\u5e8f\u6392\u5e8f\u3002 \u793a\u4f8b \u00b6 nebula> FETCH PROP ON player 100,101,102,103 YIELD player.age AS age, player.name AS name | ORDER BY age, name DESC; -- \u53d6 4 \u4e2a\u9876\u70b9\u5e76\u5c06\u4ed6\u4eec\u4ee5 age \u4ece\u5c0f\u5230\u5927\u7684\u987a\u5e8f\u6392\u5217\uff0c\u5982 age \u76f8\u540c\uff0c\u5219 name \u6309\u964d\u5e8f\u6392\u5217\u3002 -- \u8fd4\u56de\u5982\u4e0b\u7ed3\u679c: ====================================== | VertexID | age | name | ====================================== | 103 | 32 | Rudy Gay | -------------------------------------- | 102 | 33 | LaMarcus Aldridge | -------------------------------------- | 101 | 36 | Tony Parker | -------------------------------------- | 100 | 42 | Tim Duncan | -------------------------------------- (\u4f7f\u7528\u65b9\u6cd5\u53c2\u89c1 FETCH \u6587\u6863) nebula> GO FROM 100 OVER follow YIELD $$.player.age AS age, $$.player.name AS name | ORDER BY age DESC, name ASC; -- \u4ece\u9876\u70b9 100 \u51fa\u53d1\u67e5\u627e\u5176\u5173\u6ce8\u7684\u7403\u5458\uff0c\u8fd4\u56de\u7403\u5458\u7684 age \u548c name\uff0cage \u6309\u964d\u5e8f\u6392\u5217\uff0c\u5982 age \u76f8\u540c\uff0c\u5219 name \u6309\u5347\u5e8f\u6392\u5217\u3002 -- \u8fd4\u56de\u5982\u4e0b\u7ed3\u679c\uff1a =========================== | age | name | =========================== | 36 | Tony Parker | --------------------------- | 33 | LaMarcus Aldridge | --------------------------- | 25 | Kyle Anderson | ---------------------------","title":"Order By \u51fd\u6570"},{"location":"manual-CN/2.query-language/2.functions-and-operators/order-by-function/#order_by","text":"\u7c7b\u4f3c\u4e8e SQL\uff0c ORDER BY \u53ef\u4ee5\u8fdb\u884c\u5347\u5e8f ( ASC ) \u6216\u964d\u5e8f ( DESC ) \u6392\u5e8f\u5e76\u8fd4\u56de\u7ed3\u679c\uff0c\u5e76\u4e14\u5b83\u53ea\u80fd\u5728 PIPE \u8bed\u53e5 ( | ) \u4e2d\u4f7f\u7528\u3002 ORDER BY <expression> [ASC | DESC] [, <expression> [ASC | DESC] ...] \u5982\u679c\u6ca1\u6709\u6307\u660e ASC \u6216 DESC\uff0c ORDER BY \u5c06\u9ed8\u8ba4\u8fdb\u884c\u5347\u5e8f\u6392\u5e8f\u3002","title":"Order By \u51fd\u6570"},{"location":"manual-CN/2.query-language/2.functions-and-operators/order-by-function/#_1","text":"nebula> FETCH PROP ON player 100,101,102,103 YIELD player.age AS age, player.name AS name | ORDER BY age, name DESC; -- \u53d6 4 \u4e2a\u9876\u70b9\u5e76\u5c06\u4ed6\u4eec\u4ee5 age \u4ece\u5c0f\u5230\u5927\u7684\u987a\u5e8f\u6392\u5217\uff0c\u5982 age \u76f8\u540c\uff0c\u5219 name \u6309\u964d\u5e8f\u6392\u5217\u3002 -- \u8fd4\u56de\u5982\u4e0b\u7ed3\u679c: ====================================== | VertexID | age | name | ====================================== | 103 | 32 | Rudy Gay | -------------------------------------- | 102 | 33 | LaMarcus Aldridge | -------------------------------------- | 101 | 36 | Tony Parker | -------------------------------------- | 100 | 42 | Tim Duncan | -------------------------------------- (\u4f7f\u7528\u65b9\u6cd5\u53c2\u89c1 FETCH \u6587\u6863) nebula> GO FROM 100 OVER follow YIELD $$.player.age AS age, $$.player.name AS name | ORDER BY age DESC, name ASC; -- \u4ece\u9876\u70b9 100 \u51fa\u53d1\u67e5\u627e\u5176\u5173\u6ce8\u7684\u7403\u5458\uff0c\u8fd4\u56de\u7403\u5458\u7684 age \u548c name\uff0cage \u6309\u964d\u5e8f\u6392\u5217\uff0c\u5982 age \u76f8\u540c\uff0c\u5219 name \u6309\u5347\u5e8f\u6392\u5217\u3002 -- \u8fd4\u56de\u5982\u4e0b\u7ed3\u679c\uff1a =========================== | age | name | =========================== | 36 | Tony Parker | --------------------------- | 33 | LaMarcus Aldridge | --------------------------- | 25 | Kyle Anderson | ---------------------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/2.functions-and-operators/set-operations/","text":"\u96c6\u5408\u64cd\u4f5c ( UNION \uff0c INTERSECT \uff0c MINUS ) \u00b6 UNION\uff0cUNION DISTINCT\uff0cUNION ALL \u00b6 UNION DISTINCT (\u7b80\u79f0 UNION )\u8fd4\u56de\u6570\u636e\u96c6 A \u548c B \u7684\u5e76\u96c6\uff08\u4e0d\u5305\u542b\u91cd\u590d\u5143\u7d20\uff09\u3002 UNION ALL \u8fd4\u56de\u6570\u636e\u96c6 A \u548c B \u7684\u5e76\u96c6\uff08\u5305\u542b\u91cd\u590d\u5143\u7d20\uff09\u3002 UNION \u8bed\u6cd5\u4e3a <left> UNION [DISTINCT | ALL] <right> [ UNION [DISTINCT | ALL] <right> ...] <left> \u548c <right> \u5fc5\u987b\u5217\u6570\u76f8\u540c\uff0c\u4e14\u6570\u636e\u7c7b\u578b\u76f8\u540c\u3002\u5982\u679c\u6570\u636e\u7c7b\u578b\u4e0d\u540c\uff0c\u5c06\u6309\u7167 \u7c7b\u578b\u8f6c\u6362 \u8fdb\u884c\u8f6c\u6362\u3002 \u793a\u4f8b \u00b6 nebula> GO FROM 1 OVER e1 \\ UNION \\ GO FROM 2 OVER e1; \u4ee5\u4e0a\u8bed\u53e5\u8fd4\u56de\u70b9 1 \u548c 2 (\u6cbf\u8fb9 e1 ) \u5173\u8054\u7684\u552f\u4e00\u7684\u70b9\u3002 nebula> GO FROM 1 OVER e1 \\ UNION ALL\\ GO FROM 2 OVER e1; \u4ee5\u4e0a\u8bed\u53e5\u8fd4\u56de\u70b9 1 \u548c 2 \u5173\u8054\u7684\u6240\u6709\u70b9\uff0c\u5176\u4e2d\u5b58\u5728\u91cd\u590d\u70b9\u3002 UNION \u4ea6\u53ef\u4e0e YIELD \u540c\u65f6\u4f7f\u7528\uff0c\u4f8b\u5982\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 -- query 1 ========================== | id | left_1 | left_2 | ========================== | 104 | 1 | 2 | -- line 1 -------------------------- | 215 | 4 | 3 | -- line 3 -------------------------- nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; -- query 2 =========================== | id | right_1 | right_2 | =========================== | 104 | 1 | 2 | -- line 1 --------------------------- | 104 | 2 | 2 | -- line 2 --------------------------- nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION /* DISTINCT */ \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; \u4ee5\u4e0a\u8bed\u53e5\u8fd4\u56de ========================= | id | left_1 | left_2 | -- UNION or UNION DISTINCT. The column names come from query 1 ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 ------------------------- \u8bf7\u6ce8\u610f\u7b2c\u4e00\u884c\u4e0e\u7b2c\u4e8c\u884c\u8fd4\u56de\u76f8\u540c id \u7684\u70b9\uff0c\u4f46\u662f\u8fd4\u56de\u7684\u503c\u4e0d\u540c\u3002 DISTINCT \u68c0\u67e5\u8fd4\u56de\u7ed3\u679c\u4e2d\u7684\u91cd\u590d\u503c\u3002\u6240\u4ee5\u7b2c\u4e00\u884c\u4e0e\u7b2c\u4e8c\u884c\u7684\u8fd4\u56de\u7ed3\u679c\u4e0d\u540c\u3002 UNION ALL \u8fd4\u56de\u7ed3\u679c\u4e3a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION ALL \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; ========================= | id | left_1 | left_2 | -- UNION ALL ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 ------------------------- INTERSECT \u00b6 INTERSECT \u8fd4\u56de\u96c6\u5408 A \u548c B ( A \u22c2 B)\u7684\u4ea4\u96c6\u3002 <left> INTERSECT <right> \u4e0e UNION \u7c7b\u4f3c\uff0c <left> \u548c <right> \u5fc5\u987b\u5217\u6570\u76f8\u540c\uff0c\u4e14\u6570\u636e\u7c7b\u578b\u76f8\u540c\u3002 \u6b64\u5916\uff0c\u53ea\u8fd4\u56de <left> \u53f3 <right> \u76f8\u540c\u7684\u884c\u3002\u4f8b\u5982\uff1a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 INTERSECT GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; \u8fd4\u56de ========================= | id | left_1 | left_2 | ========================= | 104 | 1 | 2 | -- line 1 ------------------------- MINUS \u00b6 \u8fd4\u56de A - B \u6570\u636e\u7684\u5dee\u96c6\uff0c\u6b64\u5904\u8bf7\u6ce8\u610f\u8fd0\u7b97\u987a\u5e8f\u3002\u4f8b\u5982\uff1a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 MINUS GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; \u8fd4\u56de ========================== | id | left_1 | left_2 | ========================== | 215 | 4 | 3 | -- line 3 -------------------------- \u5982\u679c\u66f4\u6539 MINUS \u987a\u5e8f nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 MINUS GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2; \u5219\u8fd4\u56de =========================== | id | right_1 | right_2 | -- column named from query 2 =========================== | 104 | 2 | 2 | -- line 2 ---------------------------","title":"\u96c6\u5408\u64cd\u4f5c (`UNION`\uff0c`INTERSECT`\uff0c `MINUS`)"},{"location":"manual-CN/2.query-language/2.functions-and-operators/set-operations/#unionintersect_minus","text":"","title":"\u96c6\u5408\u64cd\u4f5c (UNION\uff0cINTERSECT\uff0c MINUS)"},{"location":"manual-CN/2.query-language/2.functions-and-operators/set-operations/#unionunion_distinctunion_all","text":"UNION DISTINCT (\u7b80\u79f0 UNION )\u8fd4\u56de\u6570\u636e\u96c6 A \u548c B \u7684\u5e76\u96c6\uff08\u4e0d\u5305\u542b\u91cd\u590d\u5143\u7d20\uff09\u3002 UNION ALL \u8fd4\u56de\u6570\u636e\u96c6 A \u548c B \u7684\u5e76\u96c6\uff08\u5305\u542b\u91cd\u590d\u5143\u7d20\uff09\u3002 UNION \u8bed\u6cd5\u4e3a <left> UNION [DISTINCT | ALL] <right> [ UNION [DISTINCT | ALL] <right> ...] <left> \u548c <right> \u5fc5\u987b\u5217\u6570\u76f8\u540c\uff0c\u4e14\u6570\u636e\u7c7b\u578b\u76f8\u540c\u3002\u5982\u679c\u6570\u636e\u7c7b\u578b\u4e0d\u540c\uff0c\u5c06\u6309\u7167 \u7c7b\u578b\u8f6c\u6362 \u8fdb\u884c\u8f6c\u6362\u3002","title":"UNION\uff0cUNION DISTINCT\uff0cUNION ALL"},{"location":"manual-CN/2.query-language/2.functions-and-operators/set-operations/#_1","text":"nebula> GO FROM 1 OVER e1 \\ UNION \\ GO FROM 2 OVER e1; \u4ee5\u4e0a\u8bed\u53e5\u8fd4\u56de\u70b9 1 \u548c 2 (\u6cbf\u8fb9 e1 ) \u5173\u8054\u7684\u552f\u4e00\u7684\u70b9\u3002 nebula> GO FROM 1 OVER e1 \\ UNION ALL\\ GO FROM 2 OVER e1; \u4ee5\u4e0a\u8bed\u53e5\u8fd4\u56de\u70b9 1 \u548c 2 \u5173\u8054\u7684\u6240\u6709\u70b9\uff0c\u5176\u4e2d\u5b58\u5728\u91cd\u590d\u70b9\u3002 UNION \u4ea6\u53ef\u4e0e YIELD \u540c\u65f6\u4f7f\u7528\uff0c\u4f8b\u5982\u4ee5\u4e0b\u8bed\u53e5\uff1a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 -- query 1 ========================== | id | left_1 | left_2 | ========================== | 104 | 1 | 2 | -- line 1 -------------------------- | 215 | 4 | 3 | -- line 3 -------------------------- nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; -- query 2 =========================== | id | right_1 | right_2 | =========================== | 104 | 1 | 2 | -- line 1 --------------------------- | 104 | 2 | 2 | -- line 2 --------------------------- nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION /* DISTINCT */ \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; \u4ee5\u4e0a\u8bed\u53e5\u8fd4\u56de ========================= | id | left_1 | left_2 | -- UNION or UNION DISTINCT. The column names come from query 1 ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 ------------------------- \u8bf7\u6ce8\u610f\u7b2c\u4e00\u884c\u4e0e\u7b2c\u4e8c\u884c\u8fd4\u56de\u76f8\u540c id \u7684\u70b9\uff0c\u4f46\u662f\u8fd4\u56de\u7684\u503c\u4e0d\u540c\u3002 DISTINCT \u68c0\u67e5\u8fd4\u56de\u7ed3\u679c\u4e2d\u7684\u91cd\u590d\u503c\u3002\u6240\u4ee5\u7b2c\u4e00\u884c\u4e0e\u7b2c\u4e8c\u884c\u7684\u8fd4\u56de\u7ed3\u679c\u4e0d\u540c\u3002 UNION ALL \u8fd4\u56de\u7ed3\u679c\u4e3a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION ALL \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; ========================= | id | left_1 | left_2 | -- UNION ALL ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 -------------------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/2.functions-and-operators/set-operations/#intersect","text":"INTERSECT \u8fd4\u56de\u96c6\u5408 A \u548c B ( A \u22c2 B)\u7684\u4ea4\u96c6\u3002 <left> INTERSECT <right> \u4e0e UNION \u7c7b\u4f3c\uff0c <left> \u548c <right> \u5fc5\u987b\u5217\u6570\u76f8\u540c\uff0c\u4e14\u6570\u636e\u7c7b\u578b\u76f8\u540c\u3002 \u6b64\u5916\uff0c\u53ea\u8fd4\u56de <left> \u53f3 <right> \u76f8\u540c\u7684\u884c\u3002\u4f8b\u5982\uff1a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 INTERSECT GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; \u8fd4\u56de ========================= | id | left_1 | left_2 | ========================= | 104 | 1 | 2 | -- line 1 -------------------------","title":"INTERSECT"},{"location":"manual-CN/2.query-language/2.functions-and-operators/set-operations/#minus","text":"\u8fd4\u56de A - B \u6570\u636e\u7684\u5dee\u96c6\uff0c\u6b64\u5904\u8bf7\u6ce8\u610f\u8fd0\u7b97\u987a\u5e8f\u3002\u4f8b\u5982\uff1a nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 MINUS GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2; \u8fd4\u56de ========================== | id | left_1 | left_2 | ========================== | 215 | 4 | 3 | -- line 3 -------------------------- \u5982\u679c\u66f4\u6539 MINUS \u987a\u5e8f nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 MINUS GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2; \u5219\u8fd4\u56de =========================== | id | right_1 | right_2 | -- column named from query 2 =========================== | 104 | 2 | 2 | -- line 2 ---------------------------","title":"MINUS"},{"location":"manual-CN/2.query-language/2.functions-and-operators/uuid/","text":"UUID \u00b6 UUID \u7528\u4e8e\u751f\u6210\u5168\u5c40\u552f\u4e00\u7684\u6807\u8bc6\u7b26\u3002 \u5f53\u9876\u70b9\u6570\u91cf\u5230\u8fbe\u5341\u4ebf\u7ea7\u522b\u65f6\uff0c\u7528 hash \u51fd\u6570\u751f\u6210 vid \u6709\u4e00\u5b9a\u7684\u51b2\u7a81\u6982\u7387\u3002\u56e0\u6b64 Nebula Graph \u63d0\u4f9b UUID \u51fd\u6570\u6765\u907f\u514d\u5927\u91cf\u9876\u70b9\u65f6\u7684 vid \u51b2\u7a81\u3002 UUID \u51fd\u6570\u7531 Murmurhash \u4e0e\u5f53\u524d\u65f6\u95f4\u6233\uff08\u5355\u4f4d\u4e3a\u79d2\uff09\u7ec4\u5408\u800c\u6210\u3002 UUID \u4ea7\u751f\u7684\u503c\u4f1a\u4ee5 key-value \u65b9\u5f0f\u5b58\u50a8\u5728 Nebula Graph \u7684 Storage \u670d\u52a1\u4e2d\uff0c\u8c03\u7528\u65f6\u4f1a\u68c0\u67e5\u8fd9\u4e2a key \u662f\u5426\u5b58\u5728\u6216\u51b2\u7a81\u3002\u56e0\u6b64\u76f8\u6bd4 hash\uff0c\u6027\u80fd\u53ef\u80fd\u4f1a\u66f4\u6162\u3002 \u63d2\u5165 UUID \uff1a -- \u4f7f\u7528 UUID \u51fd\u6570\u63d2\u5165\u4e00\u4e2a\u70b9\u3002 nebula> INSERT VERTEX player (name, age) VALUES uuid(\"n0\"):(\"n0\", 21); -- \u4f7f\u7528 UUID \u51fd\u6570\u63d2\u5165\u4e00\u6761\u8fb9\u3002 nebula> INSERT EDGE follow(degree) VALUES uuid(\"n0\") -> uuid(\"n1\"): (90); \u83b7\u53d6 UUID \uff1a nebula> FETCH PROP ON player uuid(\"n0\") YIELD player.name, player.age; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =================================================== | VertexID | player.name | player.age | =================================================== | -5057115778034027261 | n0 | 21 | --------------------------------------------------- nebula> FETCH PROP ON follow uuid(\"n0\") -> uuid(\"n1\"); -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a ============================================================================= | follow._src | follow._dst | follow._rank | follow.degree | ============================================================================= | -5057115778034027261 | 4039977434270020867 | 0 | 90 | ----------------------------------------------------------------------------- \u7ed3\u5408 Go \u4f7f\u7528 UUID : nebula> GO FROM uuid(\"n0\") OVER follow; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a ======================= | follow._dst | ======================= | 4039977434270020867 | -----------------------","title":"UUID"},{"location":"manual-CN/2.query-language/2.functions-and-operators/uuid/#uuid","text":"UUID \u7528\u4e8e\u751f\u6210\u5168\u5c40\u552f\u4e00\u7684\u6807\u8bc6\u7b26\u3002 \u5f53\u9876\u70b9\u6570\u91cf\u5230\u8fbe\u5341\u4ebf\u7ea7\u522b\u65f6\uff0c\u7528 hash \u51fd\u6570\u751f\u6210 vid \u6709\u4e00\u5b9a\u7684\u51b2\u7a81\u6982\u7387\u3002\u56e0\u6b64 Nebula Graph \u63d0\u4f9b UUID \u51fd\u6570\u6765\u907f\u514d\u5927\u91cf\u9876\u70b9\u65f6\u7684 vid \u51b2\u7a81\u3002 UUID \u51fd\u6570\u7531 Murmurhash \u4e0e\u5f53\u524d\u65f6\u95f4\u6233\uff08\u5355\u4f4d\u4e3a\u79d2\uff09\u7ec4\u5408\u800c\u6210\u3002 UUID \u4ea7\u751f\u7684\u503c\u4f1a\u4ee5 key-value \u65b9\u5f0f\u5b58\u50a8\u5728 Nebula Graph \u7684 Storage \u670d\u52a1\u4e2d\uff0c\u8c03\u7528\u65f6\u4f1a\u68c0\u67e5\u8fd9\u4e2a key \u662f\u5426\u5b58\u5728\u6216\u51b2\u7a81\u3002\u56e0\u6b64\u76f8\u6bd4 hash\uff0c\u6027\u80fd\u53ef\u80fd\u4f1a\u66f4\u6162\u3002 \u63d2\u5165 UUID \uff1a -- \u4f7f\u7528 UUID \u51fd\u6570\u63d2\u5165\u4e00\u4e2a\u70b9\u3002 nebula> INSERT VERTEX player (name, age) VALUES uuid(\"n0\"):(\"n0\", 21); -- \u4f7f\u7528 UUID \u51fd\u6570\u63d2\u5165\u4e00\u6761\u8fb9\u3002 nebula> INSERT EDGE follow(degree) VALUES uuid(\"n0\") -> uuid(\"n1\"): (90); \u83b7\u53d6 UUID \uff1a nebula> FETCH PROP ON player uuid(\"n0\") YIELD player.name, player.age; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =================================================== | VertexID | player.name | player.age | =================================================== | -5057115778034027261 | n0 | 21 | --------------------------------------------------- nebula> FETCH PROP ON follow uuid(\"n0\") -> uuid(\"n1\"); -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a ============================================================================= | follow._src | follow._dst | follow._rank | follow.degree | ============================================================================= | -5057115778034027261 | 4039977434270020867 | 0 | 90 | ----------------------------------------------------------------------------- \u7ed3\u5408 Go \u4f7f\u7528 UUID : nebula> GO FROM uuid(\"n0\") OVER follow; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a ======================= | follow._dst | ======================= | 4039977434270020867 | -----------------------","title":"UUID"},{"location":"manual-CN/2.query-language/3.language-structure/comment-syntax/","text":"\u6ce8\u91ca \u00b6 Nebula Graph \u652f\u6301\u56db\u79cd\u6ce8\u91ca\u65b9\u5f0f\uff1a \u5728\u884c\u672b\u52a0 # \u5728\u884c\u672b\u52a0 -- \u5728\u884c\u672b\u52a0 //\uff0c\u4e0e C \u8bed\u8a00\u7c7b\u4f3c \u6dfb\u52a0 /* */ \u7b26\u53f7\uff0c\u5176\u5f00\u59cb\u548c\u7ed3\u675f\u5e8f\u5217\u65e0\u9700\u5728\u540c\u4e00\u884c\uff0c\u56e0\u6b64\u6b64\u7c7b\u6ce8\u91ca\u65b9\u5f0f\u652f\u6301\u6362\u884c\u3002 \u5c1a\u4e0d\u652f\u6301\u5d4c\u5957\u6ce8\u91ca\u3002 \u6ce8\u91ca\u65b9\u5f0f\u793a\u4f8b\u5982\u4e0b\uff1a nebula> -- Do nothing in this line nebula> YIELD 1+1; # \u6ce8\u91ca\u5728\u672c\u884c\u672b\u7ed3\u675f nebula> YIELD 1+1; -- \u6ce8\u91ca\u5728\u672c\u884c\u672b\u7ed3\u675f nebula> YIELD 1+1; // \u6ce8\u91ca\u5728\u672c\u884c\u672b\u7ed3\u675f nebula> YIELD 1 /* \u8fd9\u662f\u884c\u5185\u6ce8\u91ca */ + 1; nebula> YIELD 11 + \\ /* \u591a\u884c\u6ce8\u91ca\u4f7f\u7528 \\ \u9694\u5f00 \\ */ 12; \u884c\u5185 \\ \u8868\u793a\u6362\u884c\u7b26\u3002","title":"\u6ce8\u91ca"},{"location":"manual-CN/2.query-language/3.language-structure/comment-syntax/#_1","text":"Nebula Graph \u652f\u6301\u56db\u79cd\u6ce8\u91ca\u65b9\u5f0f\uff1a \u5728\u884c\u672b\u52a0 # \u5728\u884c\u672b\u52a0 -- \u5728\u884c\u672b\u52a0 //\uff0c\u4e0e C \u8bed\u8a00\u7c7b\u4f3c \u6dfb\u52a0 /* */ \u7b26\u53f7\uff0c\u5176\u5f00\u59cb\u548c\u7ed3\u675f\u5e8f\u5217\u65e0\u9700\u5728\u540c\u4e00\u884c\uff0c\u56e0\u6b64\u6b64\u7c7b\u6ce8\u91ca\u65b9\u5f0f\u652f\u6301\u6362\u884c\u3002 \u5c1a\u4e0d\u652f\u6301\u5d4c\u5957\u6ce8\u91ca\u3002 \u6ce8\u91ca\u65b9\u5f0f\u793a\u4f8b\u5982\u4e0b\uff1a nebula> -- Do nothing in this line nebula> YIELD 1+1; # \u6ce8\u91ca\u5728\u672c\u884c\u672b\u7ed3\u675f nebula> YIELD 1+1; -- \u6ce8\u91ca\u5728\u672c\u884c\u672b\u7ed3\u675f nebula> YIELD 1+1; // \u6ce8\u91ca\u5728\u672c\u884c\u672b\u7ed3\u675f nebula> YIELD 1 /* \u8fd9\u662f\u884c\u5185\u6ce8\u91ca */ + 1; nebula> YIELD 11 + \\ /* \u591a\u884c\u6ce8\u91ca\u4f7f\u7528 \\ \u9694\u5f00 \\ */ 12; \u884c\u5185 \\ \u8868\u793a\u6362\u884c\u7b26\u3002","title":"\u6ce8\u91ca"},{"location":"manual-CN/2.query-language/3.language-structure/identifier-case-sensitivity/","text":"\u6807\u8bc6\u7b26\u5927\u5c0f\u5199 \u00b6 \u7528\u6237\u81ea\u5b9a\u4e49\u7684\u6807\u8bc6\u7b26\u4e3a\u5927\u5c0f\u5199\u654f\u611f \u00b6 \u4e0b\u65b9\u793a\u4f8b\u8bed\u53e5\u6709\u9519\uff0c\u56e0\u4e3a my_space \u548c MY_SPACE \u4e3a\u4e24\u4e2a\u4e0d\u540c\u7684\u53d8\u91cf\u540d\u3002 nebula> CREATE SPACE my_space; nebula> USE MY_SPACE; ---- my_space \u548c MY_SPACE \u662f\u4e24\u4e2a\u4e0d\u540c\u7684 space \u5173\u952e\u8bcd\u548c\u4fdd\u7559\u5173\u952e\u8bcd\u4e3a\u5927\u5c0f\u5199\u4e0d\u654f\u611f \u00b6 \u4e0b\u9762\u56db\u6761\u8bed\u53e5\u662f\u7b49\u4ef7\u7684\uff08\u56e0\u4e3a show \u548c spaces \u90fd\u662f\u4fdd\u7559\u5b57\uff09 nebula> show spaces; nebula> SHOW SPACES; nebula> SHOW spaces; nebula> show SPACES;","title":"\u6807\u8bc6\u7b26\u5927\u5c0f\u5199"},{"location":"manual-CN/2.query-language/3.language-structure/identifier-case-sensitivity/#_1","text":"","title":"\u6807\u8bc6\u7b26\u5927\u5c0f\u5199"},{"location":"manual-CN/2.query-language/3.language-structure/identifier-case-sensitivity/#_2","text":"\u4e0b\u65b9\u793a\u4f8b\u8bed\u53e5\u6709\u9519\uff0c\u56e0\u4e3a my_space \u548c MY_SPACE \u4e3a\u4e24\u4e2a\u4e0d\u540c\u7684\u53d8\u91cf\u540d\u3002 nebula> CREATE SPACE my_space; nebula> USE MY_SPACE; ---- my_space \u548c MY_SPACE \u662f\u4e24\u4e2a\u4e0d\u540c\u7684 space","title":"\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u6807\u8bc6\u7b26\u4e3a\u5927\u5c0f\u5199\u654f\u611f"},{"location":"manual-CN/2.query-language/3.language-structure/identifier-case-sensitivity/#_3","text":"\u4e0b\u9762\u56db\u6761\u8bed\u53e5\u662f\u7b49\u4ef7\u7684\uff08\u56e0\u4e3a show \u548c spaces \u90fd\u662f\u4fdd\u7559\u5b57\uff09 nebula> show spaces; nebula> SHOW SPACES; nebula> SHOW spaces; nebula> show SPACES;","title":"\u5173\u952e\u8bcd\u548c\u4fdd\u7559\u5173\u952e\u8bcd\u4e3a\u5927\u5c0f\u5199\u4e0d\u654f\u611f"},{"location":"manual-CN/2.query-language/3.language-structure/keywords-and-reserved-words/","text":"\u5173\u952e\u5b57\u548c\u4fdd\u7559\u5b57 \u00b6 \u5173\u952e\u5b57\u662f\u5728 nGQL \u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u7684\u5355\u8bcd\u3002\u4fdd\u7559\u5173\u952e\u5b57\u9700\u5f15\u7528\u65b9\u53ef\u4f7f\u7528\u3002 \u975e\u4fdd\u7559\u5173\u952e\u5b57\u65e0\u9700\u5f15\u7528\u53ef\u76f4\u63a5\u4f7f\u7528\uff0c\u4e14\u6240\u6709\u975e\u4fdd\u7559\u5b57\u90fd\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u5c0f\u5199\uff0c\u6240\u4ee5\u975e\u4fdd\u7559\u5b57\u4e0d\u533a\u5206\u5927\u5c0f\u5199\u3002\u4fdd\u7559\u5173\u952e\u5b57\u9700\u4f7f\u7528\u53cd\u5f15\u53f7\u6807\u6ce8\u65b9\u53ef\u4f7f\u7528\uff0c\u4f8b\u5982 `AND`\u3002 nebula> CREATE TAG TAG(name string); [ERROR (-7)]: SyntaxError: syntax error near `TAG' nebula> CREATE TAG SPACE(name string); -- SPACE \u4e3a\u975e\u4fdd\u7559\u5173\u952e\u5b57 Execution succeeded nebula> SHOW TAGS; -- \u6240\u6709\u975e\u4fdd\u7559\u5b57\u90fd\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u5c0f\u5199 ============= | ID | Name | ============= | 25 | space| ------------- TAG \u4e3a\u4fdd\u7559\u5b57\u4f7f\u7528\u65f6\u5fc5\u987b\u4f7f\u7528\u53cd\u5f15\u53f7\u3002 SPACE \u4e3a\u975e\u4fdd\u7559\u5b57\u4f7f\u7528\u65f6\u65e0\u9700\u52a0\u53cd\u5f15\u53f7\u3002 nebula> CREATE TAG `TAG` (name string); -- \u6b64\u5904 TAG \u4e3a\u4fdd\u7559\u5b57 Execution succeeded \u4fdd\u7559\u5b57 \u00b6 \u4ee5\u4e0b\u5217\u8868\u4e3a nGQL \u4e2d\u7684\u4fdd\u7559\u5b57\u3002 ADD ALTER AND AS ASC BALANCE BIGINT BOOL BY CHANGE COMPACT CREATE DELETE DESC DESCRIBE DISTINCT DOUBLE DOWNLOAD DROP EDGE EDGES EXISTS FETCH FIND FLUSH FROM GET GO GRANT IF IN INDEX INDEXES INGEST INSERT INT INTERSECT IS LIMIT LOOKUP MATCH MINUS NO NOT NULL OF OFFSET ON OR ORDER OVER OVERWRITE PROP REBUILD RECOVER REMOVE RETURN REVERSELY REVOKE SET SHOW STEPS STOP STRING SUBMIT TAG TAGS TIMESTAMP TO UNION UPDATE UPSERT UPTO USE VERTEX WHEN WHERE WITH XOR YIELD \u975e\u4fdd\u7559\u5173\u952e\u5b57 \u00b6 ACCOUNT ADMIN ALL AVG BIDIRECT BIT_AND BIT_OR BIT_XOR CHARSET COLLATE COLLATION CONFIGS COUNT COUNT_DISTINCT DATA DBA DEFAULT FORCE GOD GRAPH GROUP GUEST HDFS HOSTS JOB JOBS LEADER MAX META MIN OFFLINE PART PARTITION_NUM PARTS PASSWORD PATH REPLICA_FACTOR ROLE ROLES SHORTEST SNAPSHOT SNAPSHOTS SPACE SPACES STATUS STD STORAGE SUM TTL_COL TTL_DURATION USER USERS UUID VALUES","title":"\u5173\u952e\u5b57\u548c\u4fdd\u7559\u5b57"},{"location":"manual-CN/2.query-language/3.language-structure/keywords-and-reserved-words/#_1","text":"\u5173\u952e\u5b57\u662f\u5728 nGQL \u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u7684\u5355\u8bcd\u3002\u4fdd\u7559\u5173\u952e\u5b57\u9700\u5f15\u7528\u65b9\u53ef\u4f7f\u7528\u3002 \u975e\u4fdd\u7559\u5173\u952e\u5b57\u65e0\u9700\u5f15\u7528\u53ef\u76f4\u63a5\u4f7f\u7528\uff0c\u4e14\u6240\u6709\u975e\u4fdd\u7559\u5b57\u90fd\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u5c0f\u5199\uff0c\u6240\u4ee5\u975e\u4fdd\u7559\u5b57\u4e0d\u533a\u5206\u5927\u5c0f\u5199\u3002\u4fdd\u7559\u5173\u952e\u5b57\u9700\u4f7f\u7528\u53cd\u5f15\u53f7\u6807\u6ce8\u65b9\u53ef\u4f7f\u7528\uff0c\u4f8b\u5982 `AND`\u3002 nebula> CREATE TAG TAG(name string); [ERROR (-7)]: SyntaxError: syntax error near `TAG' nebula> CREATE TAG SPACE(name string); -- SPACE \u4e3a\u975e\u4fdd\u7559\u5173\u952e\u5b57 Execution succeeded nebula> SHOW TAGS; -- \u6240\u6709\u975e\u4fdd\u7559\u5b57\u90fd\u4f1a\u81ea\u52a8\u8f6c\u6362\u6210\u5c0f\u5199 ============= | ID | Name | ============= | 25 | space| ------------- TAG \u4e3a\u4fdd\u7559\u5b57\u4f7f\u7528\u65f6\u5fc5\u987b\u4f7f\u7528\u53cd\u5f15\u53f7\u3002 SPACE \u4e3a\u975e\u4fdd\u7559\u5b57\u4f7f\u7528\u65f6\u65e0\u9700\u52a0\u53cd\u5f15\u53f7\u3002 nebula> CREATE TAG `TAG` (name string); -- \u6b64\u5904 TAG \u4e3a\u4fdd\u7559\u5b57 Execution succeeded","title":"\u5173\u952e\u5b57\u548c\u4fdd\u7559\u5b57"},{"location":"manual-CN/2.query-language/3.language-structure/keywords-and-reserved-words/#_2","text":"\u4ee5\u4e0b\u5217\u8868\u4e3a nGQL \u4e2d\u7684\u4fdd\u7559\u5b57\u3002 ADD ALTER AND AS ASC BALANCE BIGINT BOOL BY CHANGE COMPACT CREATE DELETE DESC DESCRIBE DISTINCT DOUBLE DOWNLOAD DROP EDGE EDGES EXISTS FETCH FIND FLUSH FROM GET GO GRANT IF IN INDEX INDEXES INGEST INSERT INT INTERSECT IS LIMIT LOOKUP MATCH MINUS NO NOT NULL OF OFFSET ON OR ORDER OVER OVERWRITE PROP REBUILD RECOVER REMOVE RETURN REVERSELY REVOKE SET SHOW STEPS STOP STRING SUBMIT TAG TAGS TIMESTAMP TO UNION UPDATE UPSERT UPTO USE VERTEX WHEN WHERE WITH XOR YIELD","title":"\u4fdd\u7559\u5b57"},{"location":"manual-CN/2.query-language/3.language-structure/keywords-and-reserved-words/#_3","text":"ACCOUNT ADMIN ALL AVG BIDIRECT BIT_AND BIT_OR BIT_XOR CHARSET COLLATE COLLATION CONFIGS COUNT COUNT_DISTINCT DATA DBA DEFAULT FORCE GOD GRAPH GROUP GUEST HDFS HOSTS JOB JOBS LEADER MAX META MIN OFFLINE PART PARTITION_NUM PARTS PASSWORD PATH REPLICA_FACTOR ROLE ROLES SHORTEST SNAPSHOT SNAPSHOTS SPACE SPACES STATUS STD STORAGE SUM TTL_COL TTL_DURATION USER USERS UUID VALUES","title":"\u975e\u4fdd\u7559\u5173\u952e\u5b57"},{"location":"manual-CN/2.query-language/3.language-structure/pipe-syntax/","text":"\u7ba1\u9053 \u00b6 nGQL \u548c SQL \u7684\u4e3b\u8981\u533a\u522b\u4e4b\u4e00\u662f\u5b50\u67e5\u8be2\u7684\u7ec4\u5408\u65b9\u5f0f\u3002 SQL \u4e2d\u7684\u67e5\u8be2\u8bed\u53e5\u901a\u5e38\u7531\u5b50\u67e5\u8be2\u5d4c\u5957\u7ec4\u6210\uff0c\u800c nGQL \u5219\u4f7f\u7528\u7c7b\u4f3c\u4e8e shell \u7684\u7ba1\u9053\u65b9\u5f0f PIPE(|) \u6765\u7ec4\u5408\u5b50\u67e5\u8be2\u3002 \u793a\u4f8b \u00b6 nebula> GO FROM 100 OVER follow YIELD follow._dst AS dstid, $$.player.name AS Name | \\ GO FROM $-.dstid OVER follow YIELD follow._dst, follow.degree, $-.Name; \u5982\u672a\u4f7f\u7528 YIELD \uff0c\u5219\u9ed8\u8ba4\u8fd4\u56de\u7ec8\u70b9 id \u3002 \u5982\u679c\u4f7f\u7528 YIELD \u660e\u786e\u58f0\u660e\u8fd4\u56de\u7ed3\u679c\uff0c\u5219\u4e0d\u4f1a\u8fd4\u56de\u9ed8\u8ba4\u503c id \u3002 $-. \u540e\u7684\u522b\u540d\u5fc5\u987b\u4e3a\u524d\u4e00\u4e2a\u5b50\u53e5 YIELD \u5b9a\u4e49\u7684\u503c\uff0c\u5982\u672c\u4f8b\u4e2d\u7684 dstid \u548c Name \u3002","title":"\u7ba1\u9053"},{"location":"manual-CN/2.query-language/3.language-structure/pipe-syntax/#_1","text":"nGQL \u548c SQL \u7684\u4e3b\u8981\u533a\u522b\u4e4b\u4e00\u662f\u5b50\u67e5\u8be2\u7684\u7ec4\u5408\u65b9\u5f0f\u3002 SQL \u4e2d\u7684\u67e5\u8be2\u8bed\u53e5\u901a\u5e38\u7531\u5b50\u67e5\u8be2\u5d4c\u5957\u7ec4\u6210\uff0c\u800c nGQL \u5219\u4f7f\u7528\u7c7b\u4f3c\u4e8e shell \u7684\u7ba1\u9053\u65b9\u5f0f PIPE(|) \u6765\u7ec4\u5408\u5b50\u67e5\u8be2\u3002","title":"\u7ba1\u9053"},{"location":"manual-CN/2.query-language/3.language-structure/pipe-syntax/#_2","text":"nebula> GO FROM 100 OVER follow YIELD follow._dst AS dstid, $$.player.name AS Name | \\ GO FROM $-.dstid OVER follow YIELD follow._dst, follow.degree, $-.Name; \u5982\u672a\u4f7f\u7528 YIELD \uff0c\u5219\u9ed8\u8ba4\u8fd4\u56de\u7ec8\u70b9 id \u3002 \u5982\u679c\u4f7f\u7528 YIELD \u660e\u786e\u58f0\u660e\u8fd4\u56de\u7ed3\u679c\uff0c\u5219\u4e0d\u4f1a\u8fd4\u56de\u9ed8\u8ba4\u503c id \u3002 $-. \u540e\u7684\u522b\u540d\u5fc5\u987b\u4e3a\u524d\u4e00\u4e2a\u5b50\u53e5 YIELD \u5b9a\u4e49\u7684\u503c\uff0c\u5982\u672c\u4f8b\u4e2d\u7684 dstid \u548c Name \u3002","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/","text":"\u5c5e\u6027\u5f15\u7528 \u00b6 WHERE \u548c YIELD \u53ef\u5f15\u7528\u8282\u70b9\u6216\u8fb9\u7684\u5c5e\u6027\u3002 \u5f15\u7528\u70b9\u7684\u5c5e\u6027 \u00b6 \u5f15\u7528\u8d77\u70b9\u7684\u5c5e\u6027 \u00b6 $^.tag_name.prop_name \u5176\u4e2d\u7b26\u53f7 $^ \u7528\u4e8e\u83b7\u53d6\u8d77\u70b9\u5c5e\u6027\uff0c tag_name \u8868\u793a\u8d77\u70b9\u7684 tag \uff0c prop_name \u4e3a\u6307\u5b9a\u5c5e\u6027\u7684\u540d\u79f0\u3002 \u5f15\u7528\u7ec8\u70b9\u7684\u5c5e\u6027 \u00b6 $$.tag_name.prop_name \u5176\u4e2d\u7b26\u53f7 $$ \u7528\u4e8e\u83b7\u53d6\u7ec8\u70b9\u5c5e\u6027\uff0c tag_name \u8868\u793a\u7ec8\u70b9\u7684 tag \uff0c prop_name \u4e3a\u6307\u5b9a\u5c5e\u6027\u7684\u540d\u79f0\u3002 \u793a\u4f8b \u00b6 nebula> GO FROM 100 OVER follow YIELD $^.player.name AS startName, $$.player.age AS endAge; \u8be5\u8bed\u53e5\u7528\u4e8e\u83b7\u53d6\u8d77\u70b9\u7684\u5c5e\u6027\u540d\u79f0\u548c\u7ec8\u70b9\u7684\u5c5e\u6027\u5e74\u9f84\u3002 \u5f15\u7528\u8fb9 \u00b6 \u5f15\u7528\u8fb9\u7684\u5c5e\u6027 \u00b6 \u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\u83b7\u53d6\u8fb9\u5c5e\u6027\uff1a edge_type.edge_prop \u6b64\u5904\uff0c edge_type \u4e3a\u8fb9\u7684\u7c7b\u578b\uff0c edge_prop \u4e3a\u5c5e\u6027\uff0c\u4f8b\u5982\uff1a nebula> GO FROM 100 OVER follow YIELD follow.degree; \u5f15\u7528\u8fb9\u7684\u5185\u7f6e\u5c5e\u6027 \u00b6 \u4e00\u6761\u8fb9\u6709\u56db\u4e2a\u5185\u7f6e\u5c5e\u6027\uff1a _src: \u8fb9\u8d77\u70b9 ID _dst: \u8fb9\u7ec8\u70b9 ID _type: \u8fb9\u7c7b\u578b _ranking: \u8fb9\u7684 ranking \u503c \u83b7\u53d6\u8d77\u70b9\u548c\u7ec8\u70b9 ID \u53ef\u901a\u8fc7 _src \u548c _dst \u83b7\u53d6\uff0c\u8fd9\u5728\u663e\u793a\u56fe\u8def\u5f84\u65f6\u7ecf\u5e38\u4f1a\u7528\u5230\u3002 \u4f8b\u5982\uff1a nebula> GO FROM 100 OVER follow YIELD follow._src AS startVID /* \u8d77\u70b9\u4e3a100 */, follow._dst AS endVID; \u8be5\u8bed\u53e5\u901a\u8fc7\u5f15\u7528 follow._src \u4f5c\u4e3a\u8d77\u70b9 ID \u548c follow._dst \u4f5c\u4e3a\u7ec8\u70b9 ID\uff0c\u8fd4\u56de\u8d77\u70b9 100 follow \u7684\u6240\u6709\u90bb\u5c45\u8282\u70b9\u3002\u5176\u4e2d follow._src \u8fd4\u56de\u8d77\u70b9 ID\uff0c follow._dst \u8fd4\u56de\u7ec8\u70b9 ID\u3002","title":"\u5c5e\u6027\u5f15\u7528"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_1","text":"WHERE \u548c YIELD \u53ef\u5f15\u7528\u8282\u70b9\u6216\u8fb9\u7684\u5c5e\u6027\u3002","title":"\u5c5e\u6027\u5f15\u7528"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_2","text":"","title":"\u5f15\u7528\u70b9\u7684\u5c5e\u6027"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_3","text":"$^.tag_name.prop_name \u5176\u4e2d\u7b26\u53f7 $^ \u7528\u4e8e\u83b7\u53d6\u8d77\u70b9\u5c5e\u6027\uff0c tag_name \u8868\u793a\u8d77\u70b9\u7684 tag \uff0c prop_name \u4e3a\u6307\u5b9a\u5c5e\u6027\u7684\u540d\u79f0\u3002","title":"\u5f15\u7528\u8d77\u70b9\u7684\u5c5e\u6027"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_4","text":"$$.tag_name.prop_name \u5176\u4e2d\u7b26\u53f7 $$ \u7528\u4e8e\u83b7\u53d6\u7ec8\u70b9\u5c5e\u6027\uff0c tag_name \u8868\u793a\u7ec8\u70b9\u7684 tag \uff0c prop_name \u4e3a\u6307\u5b9a\u5c5e\u6027\u7684\u540d\u79f0\u3002","title":"\u5f15\u7528\u7ec8\u70b9\u7684\u5c5e\u6027"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_5","text":"nebula> GO FROM 100 OVER follow YIELD $^.player.name AS startName, $$.player.age AS endAge; \u8be5\u8bed\u53e5\u7528\u4e8e\u83b7\u53d6\u8d77\u70b9\u7684\u5c5e\u6027\u540d\u79f0\u548c\u7ec8\u70b9\u7684\u5c5e\u6027\u5e74\u9f84\u3002","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_6","text":"","title":"\u5f15\u7528\u8fb9"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_7","text":"\u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\u83b7\u53d6\u8fb9\u5c5e\u6027\uff1a edge_type.edge_prop \u6b64\u5904\uff0c edge_type \u4e3a\u8fb9\u7684\u7c7b\u578b\uff0c edge_prop \u4e3a\u5c5e\u6027\uff0c\u4f8b\u5982\uff1a nebula> GO FROM 100 OVER follow YIELD follow.degree;","title":"\u5f15\u7528\u8fb9\u7684\u5c5e\u6027"},{"location":"manual-CN/2.query-language/3.language-structure/property-reference/#_8","text":"\u4e00\u6761\u8fb9\u6709\u56db\u4e2a\u5185\u7f6e\u5c5e\u6027\uff1a _src: \u8fb9\u8d77\u70b9 ID _dst: \u8fb9\u7ec8\u70b9 ID _type: \u8fb9\u7c7b\u578b _ranking: \u8fb9\u7684 ranking \u503c \u83b7\u53d6\u8d77\u70b9\u548c\u7ec8\u70b9 ID \u53ef\u901a\u8fc7 _src \u548c _dst \u83b7\u53d6\uff0c\u8fd9\u5728\u663e\u793a\u56fe\u8def\u5f84\u65f6\u7ecf\u5e38\u4f1a\u7528\u5230\u3002 \u4f8b\u5982\uff1a nebula> GO FROM 100 OVER follow YIELD follow._src AS startVID /* \u8d77\u70b9\u4e3a100 */, follow._dst AS endVID; \u8be5\u8bed\u53e5\u901a\u8fc7\u5f15\u7528 follow._src \u4f5c\u4e3a\u8d77\u70b9 ID \u548c follow._dst \u4f5c\u4e3a\u7ec8\u70b9 ID\uff0c\u8fd4\u56de\u8d77\u70b9 100 follow \u7684\u6240\u6709\u90bb\u5c45\u8282\u70b9\u3002\u5176\u4e2d follow._src \u8fd4\u56de\u8d77\u70b9 ID\uff0c follow._dst \u8fd4\u56de\u7ec8\u70b9 ID\u3002","title":"\u5f15\u7528\u8fb9\u7684\u5185\u7f6e\u5c5e\u6027"},{"location":"manual-CN/2.query-language/3.language-structure/schema-object-names/","text":"\u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219 \u00b6 Nebula Graph \u4e2d\u7684\u6807\u8bc6\u7b26\u5305\u62ec\u56fe\u7a7a\u95f4\u3001\u6807\u7b7e\u3001\u8fb9\u3001\u522b\u540d\u3001\u81ea\u5b9a\u4e49\u53d8\u91cf\u7b49\u3002\u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219\u4e3a\uff1a \u6807\u8bc6\u7b26\u4e2d\u5141\u8bb8\u7684\u5b57\u7b26\uff1a ASCII: [ 0-9,a-z,A-Z, ] (\u57fa\u672c\u62c9\u4e01\u5b57\u6bcd\uff0c\u6570\u5b57 0 - 9\uff0c\u4e0b\u5212\u7ebf)\uff0c\u4e0d\u652f\u6301\u5176\u4ed6\u6807\u70b9\u5b57\u7b26\u3002 \u6240\u6709\u6807\u8bc6\u7b26\u5fc5\u987b\u4ee5\u5b57\u6bcd\u5f00\u5934\u3002 \u6807\u8bc6\u7b26\u533a\u5206\u5927\u5c0f\u5199\u3002 \u4e0d\u53ef\u4f7f\u7528\u5173\u952e\u5b57\u6216\u4fdd\u7559\u5173\u952e\u5b57\u505a\u6807\u8bc6\u7b26\u3002","title":"\u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219"},{"location":"manual-CN/2.query-language/3.language-structure/schema-object-names/#_1","text":"Nebula Graph \u4e2d\u7684\u6807\u8bc6\u7b26\u5305\u62ec\u56fe\u7a7a\u95f4\u3001\u6807\u7b7e\u3001\u8fb9\u3001\u522b\u540d\u3001\u81ea\u5b9a\u4e49\u53d8\u91cf\u7b49\u3002\u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219\u4e3a\uff1a \u6807\u8bc6\u7b26\u4e2d\u5141\u8bb8\u7684\u5b57\u7b26\uff1a ASCII: [ 0-9,a-z,A-Z, ] (\u57fa\u672c\u62c9\u4e01\u5b57\u6bcd\uff0c\u6570\u5b57 0 - 9\uff0c\u4e0b\u5212\u7ebf)\uff0c\u4e0d\u652f\u6301\u5176\u4ed6\u6807\u70b9\u5b57\u7b26\u3002 \u6240\u6709\u6807\u8bc6\u7b26\u5fc5\u987b\u4ee5\u5b57\u6bcd\u5f00\u5934\u3002 \u6807\u8bc6\u7b26\u533a\u5206\u5927\u5c0f\u5199\u3002 \u4e0d\u53ef\u4f7f\u7528\u5173\u952e\u5b57\u6216\u4fdd\u7559\u5173\u952e\u5b57\u505a\u6807\u8bc6\u7b26\u3002","title":"\u6807\u8bc6\u7b26\u547d\u540d\u89c4\u5219"},{"location":"manual-CN/2.query-language/3.language-structure/statement-composition/","text":"\u8bed\u53e5\u7ec4\u5408 \u00b6 \u7ec4\u5408\u8bed\u53e5\uff08\u6216\u5b50\u67e5\u8be2\uff09\u7684\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a \u5c06\u591a\u4e2a\u8bed\u53e5\u653e\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u8fdb\u884c\u6279\u5904\u7406\uff0c\u4ee5\u82f1\u6587\u5206\u53f7\uff08;\uff09\u9694\u5f00\uff0c\u6700\u540e\u4e00\u4e2a\u8bed\u53e5\u7684\u7ed3\u679c\u5c06\u4f5c\u4e3a\u6279\u5904\u7406\u7684\u7ed3\u679c\u8fd4\u56de\u3002 \u5c06\u591a\u4e2a\u8bed\u53e5\u901a\u8fc7\u8fd0\u7b97\u7b26\uff08|\uff09\u8fde\u63a5\u5728\u4e00\u8d77\uff0c\u7c7b\u4f3c\u4e8e shell \u811a\u672c\u4e2d\u7684\u7ba1\u9053\u3002\u524d\u4e00\u4e2a\u8bed\u53e5\u5f97\u5230\u7684\u7ed3\u679c\u53ef\u4ee5\u91cd\u5b9a\u5411\u5230\u4e0b\u4e00\u4e2a\u8bed\u53e5\u4f5c\u4e3a\u8f93\u5165\u3002 \u6ce8\u610f\u590d\u5408\u8bed\u53e5\u5e76\u4e0d\u80fd\u4fdd\u8bc1 \u4e8b\u52a1\u6027 \u3002 \u4f8b\u5982\uff0c\u7531\u4e09\u4e2a\u5b50\u67e5\u8be2\u7ec4\u6210\u7684\u8bed\u53e5\uff1aA | B | C\uff0c\u5176\u4e2d A \u662f\u8bfb\u64cd\u4f5c\uff0cB \u662f\u8ba1\u7b97\uff0cC \u662f\u5199\u64cd\u4f5c\u3002 \u5982\u679c\u4efb\u4f55\u90e8\u5206\u5728\u6267\u884c\u4e2d\u5931\u8d25\uff0c\u6574\u4e2a\u7ed3\u679c\u5c06\u672a\u88ab\u5b9a\u4e49--\u5c1a\u4e0d\u652f\u6301\u8c03\u7528\u56de\u6eda\u3002 \u793a\u4f8b \u00b6 \u5206\u53f7\u590d\u5408\u8bed\u53e5 \u00b6 nebula> SHOW TAGS; SHOW EDGES; -- \u4ec5\u5217\u51fa\u8fb9 nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); \\ INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); \\ INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); /* \u901a\u8fc7\u590d\u5408\u8bed\u53e5\u63d2\u5165\u591a\u4e2a\u70b9*/ \u7ba1\u9053\u590d\u5408\u8bed\u53e5 \u00b6 nebula> GO FROM 201 OVER edge_serve | GO FROM $-.id OVER edge_fans | GO FROM $-.id ... \u5360\u4f4d\u7b26 $-.id \u83b7\u53d6\u7b2c\u4e00\u4e2a\u8bed\u53e5 GO FROM 201 OVER edge_serve YIELD edge_serve._dst AS id \u8fd4\u56de\u7684\u7ed3\u679c\u3002","title":"\u8bed\u53e5\u7ec4\u5408"},{"location":"manual-CN/2.query-language/3.language-structure/statement-composition/#_1","text":"\u7ec4\u5408\u8bed\u53e5\uff08\u6216\u5b50\u67e5\u8be2\uff09\u7684\u65b9\u6cd5\u6709\u4e24\u79cd\uff1a \u5c06\u591a\u4e2a\u8bed\u53e5\u653e\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u8fdb\u884c\u6279\u5904\u7406\uff0c\u4ee5\u82f1\u6587\u5206\u53f7\uff08;\uff09\u9694\u5f00\uff0c\u6700\u540e\u4e00\u4e2a\u8bed\u53e5\u7684\u7ed3\u679c\u5c06\u4f5c\u4e3a\u6279\u5904\u7406\u7684\u7ed3\u679c\u8fd4\u56de\u3002 \u5c06\u591a\u4e2a\u8bed\u53e5\u901a\u8fc7\u8fd0\u7b97\u7b26\uff08|\uff09\u8fde\u63a5\u5728\u4e00\u8d77\uff0c\u7c7b\u4f3c\u4e8e shell \u811a\u672c\u4e2d\u7684\u7ba1\u9053\u3002\u524d\u4e00\u4e2a\u8bed\u53e5\u5f97\u5230\u7684\u7ed3\u679c\u53ef\u4ee5\u91cd\u5b9a\u5411\u5230\u4e0b\u4e00\u4e2a\u8bed\u53e5\u4f5c\u4e3a\u8f93\u5165\u3002 \u6ce8\u610f\u590d\u5408\u8bed\u53e5\u5e76\u4e0d\u80fd\u4fdd\u8bc1 \u4e8b\u52a1\u6027 \u3002 \u4f8b\u5982\uff0c\u7531\u4e09\u4e2a\u5b50\u67e5\u8be2\u7ec4\u6210\u7684\u8bed\u53e5\uff1aA | B | C\uff0c\u5176\u4e2d A \u662f\u8bfb\u64cd\u4f5c\uff0cB \u662f\u8ba1\u7b97\uff0cC \u662f\u5199\u64cd\u4f5c\u3002 \u5982\u679c\u4efb\u4f55\u90e8\u5206\u5728\u6267\u884c\u4e2d\u5931\u8d25\uff0c\u6574\u4e2a\u7ed3\u679c\u5c06\u672a\u88ab\u5b9a\u4e49--\u5c1a\u4e0d\u652f\u6301\u8c03\u7528\u56de\u6eda\u3002","title":"\u8bed\u53e5\u7ec4\u5408"},{"location":"manual-CN/2.query-language/3.language-structure/statement-composition/#_2","text":"","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/3.language-structure/statement-composition/#_3","text":"nebula> SHOW TAGS; SHOW EDGES; -- \u4ec5\u5217\u51fa\u8fb9 nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); \\ INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); \\ INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); /* \u901a\u8fc7\u590d\u5408\u8bed\u53e5\u63d2\u5165\u591a\u4e2a\u70b9*/","title":"\u5206\u53f7\u590d\u5408\u8bed\u53e5"},{"location":"manual-CN/2.query-language/3.language-structure/statement-composition/#_4","text":"nebula> GO FROM 201 OVER edge_serve | GO FROM $-.id OVER edge_fans | GO FROM $-.id ... \u5360\u4f4d\u7b26 $-.id \u83b7\u53d6\u7b2c\u4e00\u4e2a\u8bed\u53e5 GO FROM 201 OVER edge_serve YIELD edge_serve._dst AS id \u8fd4\u56de\u7684\u7ed3\u679c\u3002","title":"\u7ba1\u9053\u590d\u5408\u8bed\u53e5"},{"location":"manual-CN/2.query-language/3.language-structure/user-defined-variables/","text":"\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf \u00b6 Nebula Graph \u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf\uff0c\u5176\u683c\u5f0f\u4e3a $var_name \u3002\u5176\u4e2d\u53d8\u91cf\u540d var_name \u7531\u5b57\u6bcd\u5b57\u7b26\u7ec4\u6210\u3002\u76ee\u524d\u4e0d\u5efa\u8bae\u4f7f\u7528\u4efb\u4f55\u5176\u4ed6\u5b57\u7b26\u3002\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf\u53ef\u6682\u65f6\u5c06\u503c\u5b58\u50a8\u5728\u524d\u4e00\u4e2a\u8bed\u53e5\u4e2d\u7684\u81ea\u5b9a\u4e49\u53d8\u91cf\u4e2d\uff0c\u5e76\u5728\uff08\u968f\u540e\u7684\uff09\u53e6\u4e00\u4e2a\u8bed\u53e5\u4e2d\u4f7f\u7528\uff0c\u4ece\u800c\u53ef\u5c06\u4e2d\u95f4\u7ed3\u679c\u4ece\u4e00\u4e2a\u8bed\u53e5\u4f20\u9012\u5230\u53e6\u4e00\u4e2a\u8bed\u53e5\u3002 \u7528\u6237\u5b9a\u4e49\u53d8\u91cf\u53ea\u80fd\u5728\u4e00\u6b21\u6267\u884c\u4e2d\u4f7f\u7528\uff08\u7531\u5206\u53f7 ; \u6216\u7ba1\u9053 | \u9694\u5f00\u7684\u590d\u5408\u8bed\u53e5\uff0c\u5e76\u63d0\u4ea4\u7ed9\u670d\u52a1\u5668\u4e00\u8d77\u6267\u884c\uff09\u3002 \u8bf7\u6ce8\u610f\uff0c\u81ea\u5b9a\u4e49\u7684\u53d8\u91cf\u4ec5\u5728\u5f53\u524d\u4f1a\u8bdd\u7684\u5f53\u524d\u67e5\u8be2\u6709\u6548\u3002\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u5b9a\u4e49\u7684\u81ea\u5b9a\u4e49\u53d8\u91cf\u4e0d\u80fd\u5728\u5176\u4ed6\u5ba2\u6237\u7aef\u548c\u5176\u4ed6\u6267\u884c\u4e2d\u4f7f\u7528\uff0c\u4e5f\u5c31\u662f\u8bf4\u5b9a\u4e49\u8bed\u53e5\u548c\u4f7f\u7528\u5b83\u7684\u8bed\u53e5\u5e94\u8be5\u4e00\u8d77\u63d0\u4ea4\u3002\u5f53\u5ba2\u6237\u7aef\u53d1\u9001\u6267\u884c\u65f6\uff0c\u53d8\u91cf\u4f1a\u81ea\u52a8\u91ca\u653e\u3002 \u7528\u6237\u53d8\u91cf\u540d\u79f0\u533a\u5206\u5927\u5c0f\u5199\u3002 \u793a\u4f8b\uff1a nebula> $var = GO FROM hash('curry') OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve;","title":"\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf"},{"location":"manual-CN/2.query-language/3.language-structure/user-defined-variables/#_1","text":"Nebula Graph \u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf\uff0c\u5176\u683c\u5f0f\u4e3a $var_name \u3002\u5176\u4e2d\u53d8\u91cf\u540d var_name \u7531\u5b57\u6bcd\u5b57\u7b26\u7ec4\u6210\u3002\u76ee\u524d\u4e0d\u5efa\u8bae\u4f7f\u7528\u4efb\u4f55\u5176\u4ed6\u5b57\u7b26\u3002\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf\u53ef\u6682\u65f6\u5c06\u503c\u5b58\u50a8\u5728\u524d\u4e00\u4e2a\u8bed\u53e5\u4e2d\u7684\u81ea\u5b9a\u4e49\u53d8\u91cf\u4e2d\uff0c\u5e76\u5728\uff08\u968f\u540e\u7684\uff09\u53e6\u4e00\u4e2a\u8bed\u53e5\u4e2d\u4f7f\u7528\uff0c\u4ece\u800c\u53ef\u5c06\u4e2d\u95f4\u7ed3\u679c\u4ece\u4e00\u4e2a\u8bed\u53e5\u4f20\u9012\u5230\u53e6\u4e00\u4e2a\u8bed\u53e5\u3002 \u7528\u6237\u5b9a\u4e49\u53d8\u91cf\u53ea\u80fd\u5728\u4e00\u6b21\u6267\u884c\u4e2d\u4f7f\u7528\uff08\u7531\u5206\u53f7 ; \u6216\u7ba1\u9053 | \u9694\u5f00\u7684\u590d\u5408\u8bed\u53e5\uff0c\u5e76\u63d0\u4ea4\u7ed9\u670d\u52a1\u5668\u4e00\u8d77\u6267\u884c\uff09\u3002 \u8bf7\u6ce8\u610f\uff0c\u81ea\u5b9a\u4e49\u7684\u53d8\u91cf\u4ec5\u5728\u5f53\u524d\u4f1a\u8bdd\u7684\u5f53\u524d\u67e5\u8be2\u6709\u6548\u3002\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u5b9a\u4e49\u7684\u81ea\u5b9a\u4e49\u53d8\u91cf\u4e0d\u80fd\u5728\u5176\u4ed6\u5ba2\u6237\u7aef\u548c\u5176\u4ed6\u6267\u884c\u4e2d\u4f7f\u7528\uff0c\u4e5f\u5c31\u662f\u8bf4\u5b9a\u4e49\u8bed\u53e5\u548c\u4f7f\u7528\u5b83\u7684\u8bed\u53e5\u5e94\u8be5\u4e00\u8d77\u63d0\u4ea4\u3002\u5f53\u5ba2\u6237\u7aef\u53d1\u9001\u6267\u884c\u65f6\uff0c\u53d8\u91cf\u4f1a\u81ea\u52a8\u91ca\u653e\u3002 \u7528\u6237\u53d8\u91cf\u540d\u79f0\u533a\u5206\u5927\u5c0f\u5199\u3002 \u793a\u4f8b\uff1a nebula> $var = GO FROM hash('curry') OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve;","title":"\u7528\u6237\u81ea\u5b9a\u4e49\u53d8\u91cf"},{"location":"manual-CN/2.query-language/3.language-structure/literal-values/boolean-literals/","text":"\u5e03\u5c14\u5b57\u9762\u503c \u00b6 \u5e03\u5c14\u5b57\u9762\u503c TRUE \u548c FALSE \u5bf9\u5927\u5c0f\u5199\u4e0d\u654f\u611f\u3002 nebula> yield TRUE, true, FALSE, false, FalsE; ========================================= | true | true | false | false | false | ========================================= | true | true | false | false | false | -----------------------------------------","title":"\u5e03\u5c14\u5b57\u9762\u503c"},{"location":"manual-CN/2.query-language/3.language-structure/literal-values/boolean-literals/#_1","text":"\u5e03\u5c14\u5b57\u9762\u503c TRUE \u548c FALSE \u5bf9\u5927\u5c0f\u5199\u4e0d\u654f\u611f\u3002 nebula> yield TRUE, true, FALSE, false, FalsE; ========================================= | true | true | false | false | false | ========================================= | true | true | false | false | false | -----------------------------------------","title":"\u5e03\u5c14\u5b57\u9762\u503c"},{"location":"manual-CN/2.query-language/3.language-structure/literal-values/numeric-literals/","text":"\u6570\u503c\u5b57\u9762\u503c \u00b6 \u6570\u503c\u5b57\u9762\u503c\u5305\u62ec\u6574\u6570\u5b57\u9762\u503c\u548c\u6d6e\u70b9\u5b57\u9762\u503c\u3002 \u6574\u6570\u4e3a 64 \u4f4d\uff0c\u5e76\u4e14\u53ef\u4ee5\u7528 + \u548c - \u6765\u8868\u660e\u6b63\u8d1f\u6027\u3002\u5b83\u4eec\u548c C \u8bed\u8a00\u4e2d\u7684 int64_t \u662f\u4e00\u81f4\u7684\u3002 \u6d6e\u70b9\u6570\u548c C \u8bed\u8a00\u4e2d\u7684 double \u662f\u4e00\u81f4\u7684\u3002 \u4ee5\u4e0b\u4e3a\u51e0\u4e2a\u4f8b\u5b50\uff1a 1 , - 5 , + 10000100000 - 2.3 , + 1.00000000000 \u6ce8\u610f\u6574\u6570\u7684\u6700\u5927\u503c\u4e3a 9223372036854775807 \u3002\u8f93\u5165\u4efb\u4f55\u5927\u4e8e\u6b64\u6700\u5927\u503c\u7684\u6574\u6570\u4e3a\u8bed\u6cd5\u9519\u8bef\u3002\u6574\u6570\u7684\u6700\u5c0f\u503c -9223372036854775808 \u540c\u7406\u3002 \u7136\u800c\u6d6e\u70b9\u6570\u6ca1\u6709\u4e0a\u9650\u548c\u4e0b\u9650\u3002 \u79d1\u5b66\u8ba1\u6570\u6cd5\u4f1a\u5728\u4e0b\u4e2a release \u7248\u672c\u4e2d\u652f\u6301\u3002","title":"\u6570\u503c\u5b57\u9762\u503c"},{"location":"manual-CN/2.query-language/3.language-structure/literal-values/numeric-literals/#_1","text":"\u6570\u503c\u5b57\u9762\u503c\u5305\u62ec\u6574\u6570\u5b57\u9762\u503c\u548c\u6d6e\u70b9\u5b57\u9762\u503c\u3002 \u6574\u6570\u4e3a 64 \u4f4d\uff0c\u5e76\u4e14\u53ef\u4ee5\u7528 + \u548c - \u6765\u8868\u660e\u6b63\u8d1f\u6027\u3002\u5b83\u4eec\u548c C \u8bed\u8a00\u4e2d\u7684 int64_t \u662f\u4e00\u81f4\u7684\u3002 \u6d6e\u70b9\u6570\u548c C \u8bed\u8a00\u4e2d\u7684 double \u662f\u4e00\u81f4\u7684\u3002 \u4ee5\u4e0b\u4e3a\u51e0\u4e2a\u4f8b\u5b50\uff1a 1 , - 5 , + 10000100000 - 2.3 , + 1.00000000000 \u6ce8\u610f\u6574\u6570\u7684\u6700\u5927\u503c\u4e3a 9223372036854775807 \u3002\u8f93\u5165\u4efb\u4f55\u5927\u4e8e\u6b64\u6700\u5927\u503c\u7684\u6574\u6570\u4e3a\u8bed\u6cd5\u9519\u8bef\u3002\u6574\u6570\u7684\u6700\u5c0f\u503c -9223372036854775808 \u540c\u7406\u3002 \u7136\u800c\u6d6e\u70b9\u6570\u6ca1\u6709\u4e0a\u9650\u548c\u4e0b\u9650\u3002 \u79d1\u5b66\u8ba1\u6570\u6cd5\u4f1a\u5728\u4e0b\u4e2a release \u7248\u672c\u4e2d\u652f\u6301\u3002","title":"\u6570\u503c\u5b57\u9762\u503c"},{"location":"manual-CN/2.query-language/3.language-structure/literal-values/string-literals/","text":"\u5b57\u7b26\u4e32\u5b57\u9762\u503c \u00b6 \u5b57\u7b26\u4e32\u7531\u4e00\u4e32\u5b57\u8282\u6216\u5b57\u7b26\u7ec4\u6210\uff0c\u5e76\u7531\u4e00\u5bf9\u5355\u5f15\u53f7 (') \u6216\u53cc\u5f15\u53f7 (\") \u5305\u88c5\u3002 nebula> YIELD 'a string'; nebula> YIELD \"another string\"; \u4e00\u4e9b\u8f6c\u4e49\u5b57\u7b26 (\\) \u5df2\u88ab\u652f\u6301\uff0c\u5982\u4e0b\u8868\u6240\u793a: \u8f6c\u4e49\u5b57\u7b26 \u5bf9\u5e94\u7684\u5b57\u7b26 \\' \u5355\u5f15\u53f7 (') \\\" \u53cc\u5f15\u53f7 (\") \\t \u5236\u8868\u7b26 \\n \u6362\u884c\u7b26 \\b \u9000\u683c\u7b26 \\ \u53cd\u659c\u6760 (\\) \u793a\u4f8b: nebula> YIELD 'This\\nIs\\nFour\\nLines'; ======================== | \"This Is Four Lines\" | ======================== | This Is Four Lines | ------------------------ nebula> YIELD 'disappearing\\ backslash'; ============================ | \"disappearing backslash\" | ============================ | disappearing backslash | ----------------------------","title":"\u5b57\u7b26\u4e32\u5b57\u9762\u503c"},{"location":"manual-CN/2.query-language/3.language-structure/literal-values/string-literals/#_1","text":"\u5b57\u7b26\u4e32\u7531\u4e00\u4e32\u5b57\u8282\u6216\u5b57\u7b26\u7ec4\u6210\uff0c\u5e76\u7531\u4e00\u5bf9\u5355\u5f15\u53f7 (') \u6216\u53cc\u5f15\u53f7 (\") \u5305\u88c5\u3002 nebula> YIELD 'a string'; nebula> YIELD \"another string\"; \u4e00\u4e9b\u8f6c\u4e49\u5b57\u7b26 (\\) \u5df2\u88ab\u652f\u6301\uff0c\u5982\u4e0b\u8868\u6240\u793a: \u8f6c\u4e49\u5b57\u7b26 \u5bf9\u5e94\u7684\u5b57\u7b26 \\' \u5355\u5f15\u53f7 (') \\\" \u53cc\u5f15\u53f7 (\") \\t \u5236\u8868\u7b26 \\n \u6362\u884c\u7b26 \\b \u9000\u683c\u7b26 \\ \u53cd\u659c\u6760 (\\) \u793a\u4f8b: nebula> YIELD 'This\\nIs\\nFour\\nLines'; ======================== | \"This Is Four Lines\" | ======================== | This Is Four Lines | ------------------------ nebula> YIELD 'disappearing\\ backslash'; ============================ | \"disappearing backslash\" | ============================ | disappearing backslash | ----------------------------","title":"\u5b57\u7b26\u4e32\u5b57\u9762\u503c"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/","text":"Schema \u7d22\u5f15 \u00b6 CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] <index_name> ON {<tag_name> | <edge_name>} (prop_name_list) schema \u7d22\u5f15\u53ef\u7528\u4e8e\u5feb\u901f\u5904\u7406\u56fe\u67e5\u8be2\u3002 Nebula Graph \u652f\u6301\u4e24\u79cd\u7c7b\u578b\u7684\u7d22\u5f15\uff1a Tag \u7d22\u5f15 \u548c Edge Type \u7d22\u5f15 \u3002 \u591a\u6570\u56fe\u67e5\u8be2\u90fd\u4ece\u62e5\u6709\u5171\u540c\u5c5e\u6027\u7684\u540c\u4e00\u7c7b\u578b\u7684\u70b9\u6216\u8fb9\u5f00\u59cb\u904d\u5386\u3002schema \u7d22\u5f15\u4f7f\u5f97\u8fd9\u4e9b\u5168\u5c40\u68c0\u7d22\u64cd\u4f5c\u5728\u5927\u578b\u56fe\u4e0a\u66f4\u4e3a\u9ad8\u6548\u3002 \u4e00\u822c\u5730\uff0c\u5728\u4f7f\u7528 CREATE TAG/EDGE \u8bed\u53e5\u5c06 Tag/Edge-type \u521b\u5efa\u597d\u4e4b\u540e\uff0c\u5373\u53ef\u4e3a\u5176\u521b\u5efa\u7d22\u5f15\u3002 \u521b\u5efa\u7d22\u5f15 \u00b6 CREATE INDEX \u7528\u4e8e\u4e3a\u5df2\u6709 Tag/Edge-type \u521b\u5efa\u7d22\u5f15\u3002 \u521b\u5efa\u5355\u5c5e\u6027\u7d22\u5f15 \u00b6 nebula> CREATE TAG INDEX player_index_0 on player(name); \u4e0a\u8ff0\u8bed\u53e5\u5728\u6240\u6709\u6807\u7b7e\u4e3a player \u7684\u9876\u70b9\u4e0a\u4e3a\u5c5e\u6027 name \u521b\u5efa\u4e86\u4e00\u4e2a\u7d22\u5f15\u3002 nebula> CREATE EDGE INDEX follow_index_0 on follow(degree); \u4e0a\u8ff0\u8bed\u53e5\u5728 follow \u8fb9\u7c7b\u578b\u7684\u6240\u6709\u8fb9\u4e0a\u4e3a\u5c5e\u6027 degree \u521b\u5efa\u4e86\u4e00\u4e2a\u7d22\u5f15\u3002 \u521b\u5efa\u7ec4\u5408\u7d22\u5f15 \u00b6 schema \u7d22\u5f15\u8fd8\u652f\u6301\u4e3a\u76f8\u540c tag \u6216 edge \u4e2d\u7684\u591a\u4e2a\u5c5e\u6027\u540c\u65f6\u521b\u5efa\u7d22\u5f15\u3002\u8fd9\u79cd\u5305\u542b\u591a\u79cd\u5c5e\u6027\u7684\u7d22\u5f15\u5728 Nebula Graph \u4e2d\u79f0\u4e3a\u7ec4\u5408\u7d22\u5f15\u3002 \u6ce8\u610f\uff1a \u76ee\u524d\u5c1a\u4e0d\u652f\u6301\u8de8\u591a\u4e2a tag \u521b\u5efa\u590d\u5408\u7d22\u5f15\u3002 nebula> CREATE TAG INDEX player_index_1 on player(name,age); \u4e0a\u8ff0\u8bed\u53e5\u5728\u6240\u6709\u6807\u7b7e\u4e3a player \u7684\u9876\u70b9\u4e0a\u4e3a\u5c5e\u6027 name \u548c age \u521b\u5efa\u4e86\u4e00\u4e2a\u590d\u5408\u7d22\u5f15\u3002 \u5217\u51fa\u7d22\u5f15 \u00b6 SHOW {TAG | EDGE} INDEXES SHOW INDEXES \u7528\u4e8e\u5217\u51fa\u5df2\u521b\u5efa\u5b8c\u6210\u7684 Tag/Edge-type \u7684\u7d22\u5f15\u4fe1\u606f\u3002\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5217\u51fa\u7d22\u5f15\uff1a nebula> SHOW TAG INDEXES; ============================= | Index ID | Index Name | ============================= | 22 | player_index_0 | ----------------------------- | 23 | player_index_1 | ----------------------------- nebula> SHOW EDGE INDEXES; ============================= | Index ID | Index Name | ============================= | 24 | follow_index_0 | ----------------------------- \u8fd4\u56de\u7d22\u5f15\u4fe1\u606f \u00b6 DESCRIBE {TAG | EDGE} INDEX <index_name> DESCRIBE INDEX \u7528\u4e8e\u8fd4\u56de\u6307\u5b9a\u7d22\u5f15\u4fe1\u606f\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u8fd4\u56de\u7d22\u5f15\u4fe1\u606f\uff1a nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------ nebula> DESCRIBE TAG INDEX player_index_1; ================== | Field | Type | ================== | name | string | ------------------ | age | int | ------------------ \u5220\u9664\u7d22\u5f15 \u00b6 DROP {TAG | EDGE} INDEX [IF EXISTS] <index_name> DROP INDEX \u7528\u4e8e\u5220\u9664\u6307\u5b9a\u540d\u79f0\u7684 Tag/Edge-type \u7d22\u5f15\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5220\u9664\u540d\u4e3a player_index_0 \u7684\u7d22\u5f15\uff1a nebula> DROP TAG INDEX player_index_0; \u91cd\u6784\u7d22\u5f15 \u00b6 REBUILD {TAG | EDGE} INDEX <index_name> [OFFLINE] \u521b\u5efa\u7d22\u5f15 \u90e8\u5206\u4ecb\u7ecd\u4e86\u5982\u4f55\u521b\u5efa\u7d22\u5f15\u4ee5\u63d0\u9ad8\u67e5\u8be2\u6027\u80fd\u3002\u5982\u679c\u7d22\u5f15\u5728\u63d2\u5165\u6570\u636e\u4e4b\u524d\u521b\u5efa\uff0c\u6b64\u65f6\u65e0\u9700\u6267\u884c\u7d22\u5f15\u91cd\u6784\u64cd\u4f5c\uff1b\u5982\u679c\u521b\u5efa\u7d22\u5f15\u65f6\uff0c\u6570\u636e\u5e93\u91cc\u5df2\u7ecf\u5b58\u6709\u6570\u636e\uff0c\u5219\u4e0d\u4f1a\u81ea\u52a8\u5bf9\u65e7\u7684\u6570\u636e\u8fdb\u884c\u7d22\u5f15\uff0c\u6b64\u65f6\u9700\u8981\u5bf9\u6574\u4e2a\u56fe\u4e2d\u4e0e\u7d22\u5f15\u76f8\u5173\u7684\u6570\u636e\u6267\u884c\u7d22\u5f15\u91cd\u6784\u64cd\u4f5c\u4ee5\u4fdd\u8bc1\u7d22\u5f15\u5305\u542b\u4e86\u4e4b\u524d\u7684\u6570\u636e\u3002\u82e5\u5f53\u524d\u6570\u636e\u5e93\u6ca1\u6709\u5bf9\u5916\u63d0\u4f9b\u670d\u52a1\uff0c\u5219\u53ef\u5728\u7d22\u5f15\u91cd\u6784\u65f6\u4f7f\u7528 OFFLINE \u5173\u952e\u5b57\u52a0\u5feb\u91cd\u6784\u901f\u5ea6\u3002 \u91cd\u6784\u5b8c\u6210\u540e\uff0c\u53ef\u4f7f\u7528 SHOW {TAG | EDGE} INDEX STATUS \u547d\u4ee4\u67e5\u770b\u7d22\u5f15\u662f\u5426\u91cd\u6784\u6210\u529f\u3002\u4f8b\u5982\uff1a nebula> CREATE TAG person(name string, age int, gender string, email string); Execution succeeded (Time spent: 10.051/11.397 ms) nebula> CREATE TAG INDEX single_person_index ON person(name); Execution succeeded (Time spent: 2.168/3.379 ms) nebula> REBUILD TAG INDEX single_person_index OFFLINE; Execution succeeded (Time spent: 2.352/3.568 ms) nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------ \u4f7f\u7528\u7d22\u5f15 \u00b6 \u7d22\u5f15\u521b\u5efa\u5b8c\u6210\u5e76\u63d2\u5165\u76f8\u5173\u6570\u636e\u540e\uff0c\u5373\u53ef\u4f7f\u7528 LOOKUP \u8bed\u53e5\u8fdb\u884c\u6570\u636e\u67e5\u8be2\u3002 \u901a\u5e38\u65e0\u9700\u6307\u5b9a\u5728\u67e5\u8be2\u4e2d\u5177\u4f53\u4f7f\u7528\u7684\u7d22\u5f15\uff0c Nebula Graph \u4f1a\u81ea\u884c\u9009\u62e9\u3002","title":"Schema \u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#schema","text":"CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] <index_name> ON {<tag_name> | <edge_name>} (prop_name_list) schema \u7d22\u5f15\u53ef\u7528\u4e8e\u5feb\u901f\u5904\u7406\u56fe\u67e5\u8be2\u3002 Nebula Graph \u652f\u6301\u4e24\u79cd\u7c7b\u578b\u7684\u7d22\u5f15\uff1a Tag \u7d22\u5f15 \u548c Edge Type \u7d22\u5f15 \u3002 \u591a\u6570\u56fe\u67e5\u8be2\u90fd\u4ece\u62e5\u6709\u5171\u540c\u5c5e\u6027\u7684\u540c\u4e00\u7c7b\u578b\u7684\u70b9\u6216\u8fb9\u5f00\u59cb\u904d\u5386\u3002schema \u7d22\u5f15\u4f7f\u5f97\u8fd9\u4e9b\u5168\u5c40\u68c0\u7d22\u64cd\u4f5c\u5728\u5927\u578b\u56fe\u4e0a\u66f4\u4e3a\u9ad8\u6548\u3002 \u4e00\u822c\u5730\uff0c\u5728\u4f7f\u7528 CREATE TAG/EDGE \u8bed\u53e5\u5c06 Tag/Edge-type \u521b\u5efa\u597d\u4e4b\u540e\uff0c\u5373\u53ef\u4e3a\u5176\u521b\u5efa\u7d22\u5f15\u3002","title":"Schema \u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_1","text":"CREATE INDEX \u7528\u4e8e\u4e3a\u5df2\u6709 Tag/Edge-type \u521b\u5efa\u7d22\u5f15\u3002","title":"\u521b\u5efa\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_2","text":"nebula> CREATE TAG INDEX player_index_0 on player(name); \u4e0a\u8ff0\u8bed\u53e5\u5728\u6240\u6709\u6807\u7b7e\u4e3a player \u7684\u9876\u70b9\u4e0a\u4e3a\u5c5e\u6027 name \u521b\u5efa\u4e86\u4e00\u4e2a\u7d22\u5f15\u3002 nebula> CREATE EDGE INDEX follow_index_0 on follow(degree); \u4e0a\u8ff0\u8bed\u53e5\u5728 follow \u8fb9\u7c7b\u578b\u7684\u6240\u6709\u8fb9\u4e0a\u4e3a\u5c5e\u6027 degree \u521b\u5efa\u4e86\u4e00\u4e2a\u7d22\u5f15\u3002","title":"\u521b\u5efa\u5355\u5c5e\u6027\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_3","text":"schema \u7d22\u5f15\u8fd8\u652f\u6301\u4e3a\u76f8\u540c tag \u6216 edge \u4e2d\u7684\u591a\u4e2a\u5c5e\u6027\u540c\u65f6\u521b\u5efa\u7d22\u5f15\u3002\u8fd9\u79cd\u5305\u542b\u591a\u79cd\u5c5e\u6027\u7684\u7d22\u5f15\u5728 Nebula Graph \u4e2d\u79f0\u4e3a\u7ec4\u5408\u7d22\u5f15\u3002 \u6ce8\u610f\uff1a \u76ee\u524d\u5c1a\u4e0d\u652f\u6301\u8de8\u591a\u4e2a tag \u521b\u5efa\u590d\u5408\u7d22\u5f15\u3002 nebula> CREATE TAG INDEX player_index_1 on player(name,age); \u4e0a\u8ff0\u8bed\u53e5\u5728\u6240\u6709\u6807\u7b7e\u4e3a player \u7684\u9876\u70b9\u4e0a\u4e3a\u5c5e\u6027 name \u548c age \u521b\u5efa\u4e86\u4e00\u4e2a\u590d\u5408\u7d22\u5f15\u3002","title":"\u521b\u5efa\u7ec4\u5408\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_4","text":"SHOW {TAG | EDGE} INDEXES SHOW INDEXES \u7528\u4e8e\u5217\u51fa\u5df2\u521b\u5efa\u5b8c\u6210\u7684 Tag/Edge-type \u7684\u7d22\u5f15\u4fe1\u606f\u3002\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5217\u51fa\u7d22\u5f15\uff1a nebula> SHOW TAG INDEXES; ============================= | Index ID | Index Name | ============================= | 22 | player_index_0 | ----------------------------- | 23 | player_index_1 | ----------------------------- nebula> SHOW EDGE INDEXES; ============================= | Index ID | Index Name | ============================= | 24 | follow_index_0 | -----------------------------","title":"\u5217\u51fa\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_5","text":"DESCRIBE {TAG | EDGE} INDEX <index_name> DESCRIBE INDEX \u7528\u4e8e\u8fd4\u56de\u6307\u5b9a\u7d22\u5f15\u4fe1\u606f\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u8fd4\u56de\u7d22\u5f15\u4fe1\u606f\uff1a nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------ nebula> DESCRIBE TAG INDEX player_index_1; ================== | Field | Type | ================== | name | string | ------------------ | age | int | ------------------","title":"\u8fd4\u56de\u7d22\u5f15\u4fe1\u606f"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_6","text":"DROP {TAG | EDGE} INDEX [IF EXISTS] <index_name> DROP INDEX \u7528\u4e8e\u5220\u9664\u6307\u5b9a\u540d\u79f0\u7684 Tag/Edge-type \u7d22\u5f15\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5220\u9664\u540d\u4e3a player_index_0 \u7684\u7d22\u5f15\uff1a nebula> DROP TAG INDEX player_index_0;","title":"\u5220\u9664\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_7","text":"REBUILD {TAG | EDGE} INDEX <index_name> [OFFLINE] \u521b\u5efa\u7d22\u5f15 \u90e8\u5206\u4ecb\u7ecd\u4e86\u5982\u4f55\u521b\u5efa\u7d22\u5f15\u4ee5\u63d0\u9ad8\u67e5\u8be2\u6027\u80fd\u3002\u5982\u679c\u7d22\u5f15\u5728\u63d2\u5165\u6570\u636e\u4e4b\u524d\u521b\u5efa\uff0c\u6b64\u65f6\u65e0\u9700\u6267\u884c\u7d22\u5f15\u91cd\u6784\u64cd\u4f5c\uff1b\u5982\u679c\u521b\u5efa\u7d22\u5f15\u65f6\uff0c\u6570\u636e\u5e93\u91cc\u5df2\u7ecf\u5b58\u6709\u6570\u636e\uff0c\u5219\u4e0d\u4f1a\u81ea\u52a8\u5bf9\u65e7\u7684\u6570\u636e\u8fdb\u884c\u7d22\u5f15\uff0c\u6b64\u65f6\u9700\u8981\u5bf9\u6574\u4e2a\u56fe\u4e2d\u4e0e\u7d22\u5f15\u76f8\u5173\u7684\u6570\u636e\u6267\u884c\u7d22\u5f15\u91cd\u6784\u64cd\u4f5c\u4ee5\u4fdd\u8bc1\u7d22\u5f15\u5305\u542b\u4e86\u4e4b\u524d\u7684\u6570\u636e\u3002\u82e5\u5f53\u524d\u6570\u636e\u5e93\u6ca1\u6709\u5bf9\u5916\u63d0\u4f9b\u670d\u52a1\uff0c\u5219\u53ef\u5728\u7d22\u5f15\u91cd\u6784\u65f6\u4f7f\u7528 OFFLINE \u5173\u952e\u5b57\u52a0\u5feb\u91cd\u6784\u901f\u5ea6\u3002 \u91cd\u6784\u5b8c\u6210\u540e\uff0c\u53ef\u4f7f\u7528 SHOW {TAG | EDGE} INDEX STATUS \u547d\u4ee4\u67e5\u770b\u7d22\u5f15\u662f\u5426\u91cd\u6784\u6210\u529f\u3002\u4f8b\u5982\uff1a nebula> CREATE TAG person(name string, age int, gender string, email string); Execution succeeded (Time spent: 10.051/11.397 ms) nebula> CREATE TAG INDEX single_person_index ON person(name); Execution succeeded (Time spent: 2.168/3.379 ms) nebula> REBUILD TAG INDEX single_person_index OFFLINE; Execution succeeded (Time spent: 2.352/3.568 ms) nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------","title":"\u91cd\u6784\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/#_8","text":"\u7d22\u5f15\u521b\u5efa\u5b8c\u6210\u5e76\u63d2\u5165\u76f8\u5173\u6570\u636e\u540e\uff0c\u5373\u53ef\u4f7f\u7528 LOOKUP \u8bed\u53e5\u8fdb\u884c\u6570\u636e\u67e5\u8be2\u3002 \u901a\u5e38\u65e0\u9700\u6307\u5b9a\u5728\u67e5\u8be2\u4e2d\u5177\u4f53\u4f7f\u7528\u7684\u7d22\u5f15\uff0c Nebula Graph \u4f1a\u81ea\u884c\u9009\u62e9\u3002","title":"\u4f7f\u7528\u7d22\u5f15"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/","text":"TTL (time-to-live) \u00b6 Nebula Graph \u652f\u6301 TTL \uff0c\u5728\u4e00\u5b9a\u65f6\u95f4\u540e\u81ea\u52a8\u4ece\u6570\u636e\u5e93\u4e2d\u5220\u9664\u70b9\u6216\u8005\u8fb9\u3002\u8fc7\u671f\u6570\u636e\u4f1a\u5728\u4e0b\u6b21 compaction \u65f6\u88ab\u5220\u9664\uff0c\u5728\u4e0b\u6b21 compaction \u524d\uff0cquery \u4f1a\u8fc7\u6ee4\u6389\u8fc7\u671f\u7684\u70b9\u548c\u8fb9\u3002 ttl \u529f\u80fd\u9700\u8981 ttl_col \u548c ttl_duration \u4e00\u8d77\u4f7f\u7528\u3002\u81ea\u4ece ttl_col \u6307\u5b9a\u7684\u5b57\u6bb5\u7684\u503c\u8d77\uff0c\u7ecf\u8fc7 ttl_duration \u6307\u5b9a\u7684\u79d2\u6570\u540e\uff0c\u8be5\u6761\u6570\u636e\u8fc7\u671f\u3002\u5373\uff0c\u5230\u671f\u9608\u503c\u662f ttl_col \u6307\u5b9a\u7684 property \u7684\u503c\u52a0\u4e0a ttl_duration \u8bbe\u7f6e\u7684\u79d2\u6570\u3002\u5176\u4e2d ttl_col \u6307\u5b9a\u7684\u5b57\u6bb5\u7684\u7c7b\u578b\u9700\u4e3a integer \u6216\u8005 timestamp\u3002 TTL \u914d\u7f6e \u00b6 ttl_duration \u5355\u4f4d\u4e3a\u79d2\uff0c\u8303\u56f4\u4e3a 0 ~ max(int64)\uff0c\u5f53 ttl_duration \u88ab\u8bbe\u7f6e\u4e3a 0\uff0c\u5219\u70b9\u7684\u6b64 tag \u5c5e\u6027\u4e0d\u4f1a\u8fc7\u671f\u3002 \u5f53 ttl_col \u6307\u5b9a\u7684\u5b57\u6bb5\u7684\u503c + ttl_duration \u503c < \u5f53\u524d\u65f6\u95f4\u65f6\uff0c\u8be5\u6761\u6570\u636e\u6b64 tag \u5c5e\u6027\u503c\u8fc7\u671f\u3002 \u5f53\u8be5\u6761\u6570\u636e\u6709\u591a\u4e2a tag\uff0c\u6bcf\u4e2a tag \u7684 ttl \u5355\u72ec\u5904\u7406\u3002 \u8bbe\u7f6e TTL \u00b6 \u5bf9\u5df2\u7ecf\u521b\u5efa\u7684 tag\uff0c\u8bbe\u7f6e TTL\u3002 nebula> CREATE TAG t1(a timestamp); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 5; -- \u521b\u5efa ttl nebula> INSERT VERTEX t1(a) values 101:(now()); \u70b9 101 \u7684 TAG t1 \u5c5e\u6027\u4f1a\u5728 now() \u4e4b\u540e\uff0c\u7ecf\u8fc7 5s \u540e\u8fc7\u671f\u3002 \u5728\u521b\u5efa tag \u65f6\u8bbe\u7f6e TTL\u3002 nebula> CREATE TAG t2(a int, b int, c string) ttl_duration= 100, ttl_col = \"a\"; nebula> INSERT VERTEX t2(a, b, c) values 102:(1584441231, 30, \"Word\"); \u70b9 102 \u7684 TAG t2 \u5c5e\u6027\u4f1a\u5728 2020\u5e743\u670817\u65e5 18\u65f633\u520651\u79d2 CST \uff08\u5373\u65f6\u95f4\u6233\u4e3a 1584441231\uff09\uff0c\u7ecf\u8fc7 100s \u540e\u8fc7\u671f\u3002 \u5f53\u70b9\u6709\u591a\u4e2a TAG \u65f6\uff0c\u5404 TAG \u7684 TTL \u76f8\u4e92\u72ec\u7acb\u3002 nebula> CREATE TAG t3(a string); nebula> INSERT VERTEX t1(a),t3(a) values 200:(now(), \"hello\"); 5s \u540e, \u70b9 Vertex 200 \u7684 t1 \u5c5e\u6027\u8fc7\u671f\u3002 nebula> FETCH PROP ON t1 200; Execution succeeded (Time spent: 5.945/7.492 ms) nebula> FETCH PROP ON t3 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ---------------------- nebula> FETCH PROP ON * 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ---------------------- \u5220\u9664 TTL \u00b6 \u5982\u679c\u60f3\u8981\u5220\u9664 TTL\uff0c\u53ef\u4ee5\u8bbe\u7f6e ttl_col \u5b57\u6bb5\u4e3a\u7a7a\uff0c\u6216\u5220\u9664\u914d\u7f6e\u7684 ttl_col \u5b57\u6bb5\uff0c\u6216\u8005\u8bbe\u7f6e ttl_duration \u4e3a 0\u3002 nebula> ALTER TAG t1 ttl_col = \"\"; -- drop ttl attribute; \u5220\u9664\u914d\u7f6e\u7684 ttl_col \u5b57\u6bb5\uff1a nebula> ALTER TAG t1 DROP (a); -- drop ttl_col \u8bbe\u7f6e ttl_duration \u4e3a 0\uff1a nebula> ALTER TAG t1 ttl_duration = 0; -- keep the ttl but the data never expires TTL \u4f7f\u7528\u6ce8\u610f\u4e8b\u9879 \u00b6 \u5982\u679c ttl_col \u503c\u4e3a\u975e\u7a7a\uff0c\u5219\u4e0d\u652f\u6301\u5bf9 ttl_col \u503c\u6307\u5b9a\u7684\u5217\u8fdb\u884c\u66f4\u6539\u64cd\u4f5c\u3002 nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> ALTER TAG t1 CHANGE (a string); -- failed \u6ce8\u610f\u4e00\u4e2a tag \u6216 edge \u4e0d\u80fd\u540c\u65f6\u62e5\u6709 TTL \u548c\u7d22\u5f15\uff0c\u53ea\u80fd\u4e8c\u8005\u62e9\u5176\u4e00\uff0c\u5373\u4f7f ttl_col \u914d\u7f6e\u7684\u5b57\u6bb5\u4e0e\u8981\u521b\u5efa\u7d22\u5f15\u7684\u5b57\u6bb5\u4e0d\u540c\u3002 nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(a); -- failed nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(b); -- failed nebula> CREATE TAG t1(a int, b int, c string); nebula> CREATE TAG INDEX id1 ON t1(a); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 100; -- failed \u5bf9 edge \u914d\u7f6e TTL \u4e0e tag \u7c7b\u4f3c\u3002","title":"TTL (time-to-live)"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl_time-to-live","text":"Nebula Graph \u652f\u6301 TTL \uff0c\u5728\u4e00\u5b9a\u65f6\u95f4\u540e\u81ea\u52a8\u4ece\u6570\u636e\u5e93\u4e2d\u5220\u9664\u70b9\u6216\u8005\u8fb9\u3002\u8fc7\u671f\u6570\u636e\u4f1a\u5728\u4e0b\u6b21 compaction \u65f6\u88ab\u5220\u9664\uff0c\u5728\u4e0b\u6b21 compaction \u524d\uff0cquery \u4f1a\u8fc7\u6ee4\u6389\u8fc7\u671f\u7684\u70b9\u548c\u8fb9\u3002 ttl \u529f\u80fd\u9700\u8981 ttl_col \u548c ttl_duration \u4e00\u8d77\u4f7f\u7528\u3002\u81ea\u4ece ttl_col \u6307\u5b9a\u7684\u5b57\u6bb5\u7684\u503c\u8d77\uff0c\u7ecf\u8fc7 ttl_duration \u6307\u5b9a\u7684\u79d2\u6570\u540e\uff0c\u8be5\u6761\u6570\u636e\u8fc7\u671f\u3002\u5373\uff0c\u5230\u671f\u9608\u503c\u662f ttl_col \u6307\u5b9a\u7684 property \u7684\u503c\u52a0\u4e0a ttl_duration \u8bbe\u7f6e\u7684\u79d2\u6570\u3002\u5176\u4e2d ttl_col \u6307\u5b9a\u7684\u5b57\u6bb5\u7684\u7c7b\u578b\u9700\u4e3a integer \u6216\u8005 timestamp\u3002","title":"TTL (time-to-live)"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl","text":"ttl_duration \u5355\u4f4d\u4e3a\u79d2\uff0c\u8303\u56f4\u4e3a 0 ~ max(int64)\uff0c\u5f53 ttl_duration \u88ab\u8bbe\u7f6e\u4e3a 0\uff0c\u5219\u70b9\u7684\u6b64 tag \u5c5e\u6027\u4e0d\u4f1a\u8fc7\u671f\u3002 \u5f53 ttl_col \u6307\u5b9a\u7684\u5b57\u6bb5\u7684\u503c + ttl_duration \u503c < \u5f53\u524d\u65f6\u95f4\u65f6\uff0c\u8be5\u6761\u6570\u636e\u6b64 tag \u5c5e\u6027\u503c\u8fc7\u671f\u3002 \u5f53\u8be5\u6761\u6570\u636e\u6709\u591a\u4e2a tag\uff0c\u6bcf\u4e2a tag \u7684 ttl \u5355\u72ec\u5904\u7406\u3002","title":"TTL \u914d\u7f6e"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl_1","text":"\u5bf9\u5df2\u7ecf\u521b\u5efa\u7684 tag\uff0c\u8bbe\u7f6e TTL\u3002 nebula> CREATE TAG t1(a timestamp); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 5; -- \u521b\u5efa ttl nebula> INSERT VERTEX t1(a) values 101:(now()); \u70b9 101 \u7684 TAG t1 \u5c5e\u6027\u4f1a\u5728 now() \u4e4b\u540e\uff0c\u7ecf\u8fc7 5s \u540e\u8fc7\u671f\u3002 \u5728\u521b\u5efa tag \u65f6\u8bbe\u7f6e TTL\u3002 nebula> CREATE TAG t2(a int, b int, c string) ttl_duration= 100, ttl_col = \"a\"; nebula> INSERT VERTEX t2(a, b, c) values 102:(1584441231, 30, \"Word\"); \u70b9 102 \u7684 TAG t2 \u5c5e\u6027\u4f1a\u5728 2020\u5e743\u670817\u65e5 18\u65f633\u520651\u79d2 CST \uff08\u5373\u65f6\u95f4\u6233\u4e3a 1584441231\uff09\uff0c\u7ecf\u8fc7 100s \u540e\u8fc7\u671f\u3002 \u5f53\u70b9\u6709\u591a\u4e2a TAG \u65f6\uff0c\u5404 TAG \u7684 TTL \u76f8\u4e92\u72ec\u7acb\u3002 nebula> CREATE TAG t3(a string); nebula> INSERT VERTEX t1(a),t3(a) values 200:(now(), \"hello\"); 5s \u540e, \u70b9 Vertex 200 \u7684 t1 \u5c5e\u6027\u8fc7\u671f\u3002 nebula> FETCH PROP ON t1 200; Execution succeeded (Time spent: 5.945/7.492 ms) nebula> FETCH PROP ON t3 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ---------------------- nebula> FETCH PROP ON * 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ----------------------","title":"\u8bbe\u7f6e TTL"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl_2","text":"\u5982\u679c\u60f3\u8981\u5220\u9664 TTL\uff0c\u53ef\u4ee5\u8bbe\u7f6e ttl_col \u5b57\u6bb5\u4e3a\u7a7a\uff0c\u6216\u5220\u9664\u914d\u7f6e\u7684 ttl_col \u5b57\u6bb5\uff0c\u6216\u8005\u8bbe\u7f6e ttl_duration \u4e3a 0\u3002 nebula> ALTER TAG t1 ttl_col = \"\"; -- drop ttl attribute; \u5220\u9664\u914d\u7f6e\u7684 ttl_col \u5b57\u6bb5\uff1a nebula> ALTER TAG t1 DROP (a); -- drop ttl_col \u8bbe\u7f6e ttl_duration \u4e3a 0\uff1a nebula> ALTER TAG t1 ttl_duration = 0; -- keep the ttl but the data never expires","title":"\u5220\u9664 TTL"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl_3","text":"\u5982\u679c ttl_col \u503c\u4e3a\u975e\u7a7a\uff0c\u5219\u4e0d\u652f\u6301\u5bf9 ttl_col \u503c\u6307\u5b9a\u7684\u5217\u8fdb\u884c\u66f4\u6539\u64cd\u4f5c\u3002 nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> ALTER TAG t1 CHANGE (a string); -- failed \u6ce8\u610f\u4e00\u4e2a tag \u6216 edge \u4e0d\u80fd\u540c\u65f6\u62e5\u6709 TTL \u548c\u7d22\u5f15\uff0c\u53ea\u80fd\u4e8c\u8005\u62e9\u5176\u4e00\uff0c\u5373\u4f7f ttl_col \u914d\u7f6e\u7684\u5b57\u6bb5\u4e0e\u8981\u521b\u5efa\u7d22\u5f15\u7684\u5b57\u6bb5\u4e0d\u540c\u3002 nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(a); -- failed nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(b); -- failed nebula> CREATE TAG t1(a int, b int, c string); nebula> CREATE TAG INDEX id1 ON t1(a); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 100; -- failed \u5bf9 edge \u914d\u7f6e TTL \u4e0e tag \u7c7b\u4f3c\u3002","title":"TTL \u4f7f\u7528\u6ce8\u610f\u4e8b\u9879"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/alter-tag-edge-syntax/","text":"\u4fee\u6539 Tag / Edge \u00b6 ALTER TAG | EDGE <tag_name> | <edge_name> <alter_definition> [, alter_definition] ...] [ttl_definition [, ttl_definition] ... ] alter_definition: | ADD (prop_name data_type) | DROP (prop_name) | CHANGE (prop_name data_type) ttl_definition: TTL_DURATION = ttl_duration, TTL_COL = prop_name ALTER \u8bed\u53e5\u53ef\u6539\u53d8\u6807\u7b7e\u6216\u8fb9\u7684\u7ed3\u6784\uff0c\u4f8b\u5982\uff0c\u53ef\u4ee5\u6dfb\u52a0\u6216\u5220\u9664\u5c5e\u6027\uff0c\u66f4\u6539\u5df2\u6709\u5c5e\u6027\u7684\u7c7b\u578b\uff0c\u4e5f\u53ef\u5c06\u5c5e\u6027\u8bbe\u7f6e\u4e3a TTL\uff08\u751f\u5b58\u65f6\u95f4\uff09\uff0c\u6216\u66f4\u6539 TTL \u65f6\u95f4\u3002 \u6ce8\u610f\uff1a \u4fee\u6539\u6807\u7b7e\u6216\u8fb9\u7ed3\u6784\u65f6\uff0c Nebula Graph \u5c06\u81ea\u52a8\u68c0\u6d4b\u662f\u5426\u5b58\u5728\u7d22\u5f15\u3002\u4fee\u6539\u65f6\u9700\u8981\u4e24\u6b65\u5224\u65ad\u3002\u9996\u5148\uff0c\u5224\u65ad\u8fd9\u4e2a tag \u6216 edge \u662f\u5426\u5173\u8054\u7d22\u5f15\u3002\u5176\u6b21\uff0c\u68c0\u67e5\u6240\u6709\u5173\u8054\u7684\u7d22\u5f15\uff0c\u5224\u65ad\u5f85\u5220\u9664\u6216\u66f4\u6539\u7684 column item \u662f\u5426\u5b58\u5728\u4e8e\u7d22\u5f15\u7684 column \u4e2d\uff0c\u5982\u679c\u5b58\u5728\u5219\u62d2\u7edd\u4fee\u6539\u3002\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5373\u4f7f\u6709\u5173\u8054\u7684\u7d22\u5f15\u4e5f\u5141\u8bb8\u4fee\u6539\u3002 \u8bf7\u53c2\u8003 \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u7d22\u5f15\u8be6\u60c5\u3002 \u4e00\u4e2a ALTER \u8bed\u53e5\u5141\u8bb8\u4f7f\u7528\u591a\u4e2a ADD \uff0c DROP \uff0c CHANGE \u8bed\u53e5\uff0c\u8bed\u53e5\u4e4b\u95f4\u9700\u7528\u9017\u53f7\u9694\u5f00\u3002\u4f46\u662f\u4e0d\u8981\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u6dfb\u52a0\uff0c\u5220\u9664\u6216\u66f4\u6539\u76f8\u540c\u7684\u5c5e\u6027\u3002\u5982\u679c\u5fc5\u987b\u8fdb\u884c\u6b64\u64cd\u4f5c\uff0c\u8bf7\u5c06\u5176\u4f5c\u4e3a ALTER \u8bed\u53e5\u7684\u5b50\u8bed\u53e5\u3002 nebula> CREATE TAG t1 (name string, age int); nebula> ALTER TAG t1 ADD (id int, address string); nebula> CREATE EDGE e1 (prop3 int, prop4 int, prop5 int); nebula> ALTER EDGE e1 ADD (prop1 int, prop2 string), /* \u6dfb\u52a0 prop1 */ CHANGE (prop3 string), /* \u5c06 prop3 \u7c7b\u578b\u66f4\u6539\u4e3a\u5b57\u7b26 */ DROP (prop4, prop5); /* \u5220\u9664 prop4 \u548c prop5 */ nebula> ALTER EDGE e1 TTL_DURATION = 2, TTL_COL = prop1; \u6ce8\u610f TTL_COL \u4ec5\u652f\u6301 INT \u548c TIMESTAMP \u7c7b\u578b\u3002","title":"\u4fee\u6539 Tag / Edge"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/alter-tag-edge-syntax/#tag_edge","text":"ALTER TAG | EDGE <tag_name> | <edge_name> <alter_definition> [, alter_definition] ...] [ttl_definition [, ttl_definition] ... ] alter_definition: | ADD (prop_name data_type) | DROP (prop_name) | CHANGE (prop_name data_type) ttl_definition: TTL_DURATION = ttl_duration, TTL_COL = prop_name ALTER \u8bed\u53e5\u53ef\u6539\u53d8\u6807\u7b7e\u6216\u8fb9\u7684\u7ed3\u6784\uff0c\u4f8b\u5982\uff0c\u53ef\u4ee5\u6dfb\u52a0\u6216\u5220\u9664\u5c5e\u6027\uff0c\u66f4\u6539\u5df2\u6709\u5c5e\u6027\u7684\u7c7b\u578b\uff0c\u4e5f\u53ef\u5c06\u5c5e\u6027\u8bbe\u7f6e\u4e3a TTL\uff08\u751f\u5b58\u65f6\u95f4\uff09\uff0c\u6216\u66f4\u6539 TTL \u65f6\u95f4\u3002 \u6ce8\u610f\uff1a \u4fee\u6539\u6807\u7b7e\u6216\u8fb9\u7ed3\u6784\u65f6\uff0c Nebula Graph \u5c06\u81ea\u52a8\u68c0\u6d4b\u662f\u5426\u5b58\u5728\u7d22\u5f15\u3002\u4fee\u6539\u65f6\u9700\u8981\u4e24\u6b65\u5224\u65ad\u3002\u9996\u5148\uff0c\u5224\u65ad\u8fd9\u4e2a tag \u6216 edge \u662f\u5426\u5173\u8054\u7d22\u5f15\u3002\u5176\u6b21\uff0c\u68c0\u67e5\u6240\u6709\u5173\u8054\u7684\u7d22\u5f15\uff0c\u5224\u65ad\u5f85\u5220\u9664\u6216\u66f4\u6539\u7684 column item \u662f\u5426\u5b58\u5728\u4e8e\u7d22\u5f15\u7684 column \u4e2d\uff0c\u5982\u679c\u5b58\u5728\u5219\u62d2\u7edd\u4fee\u6539\u3002\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5373\u4f7f\u6709\u5173\u8054\u7684\u7d22\u5f15\u4e5f\u5141\u8bb8\u4fee\u6539\u3002 \u8bf7\u53c2\u8003 \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u7d22\u5f15\u8be6\u60c5\u3002 \u4e00\u4e2a ALTER \u8bed\u53e5\u5141\u8bb8\u4f7f\u7528\u591a\u4e2a ADD \uff0c DROP \uff0c CHANGE \u8bed\u53e5\uff0c\u8bed\u53e5\u4e4b\u95f4\u9700\u7528\u9017\u53f7\u9694\u5f00\u3002\u4f46\u662f\u4e0d\u8981\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u6dfb\u52a0\uff0c\u5220\u9664\u6216\u66f4\u6539\u76f8\u540c\u7684\u5c5e\u6027\u3002\u5982\u679c\u5fc5\u987b\u8fdb\u884c\u6b64\u64cd\u4f5c\uff0c\u8bf7\u5c06\u5176\u4f5c\u4e3a ALTER \u8bed\u53e5\u7684\u5b50\u8bed\u53e5\u3002 nebula> CREATE TAG t1 (name string, age int); nebula> ALTER TAG t1 ADD (id int, address string); nebula> CREATE EDGE e1 (prop3 int, prop4 int, prop5 int); nebula> ALTER EDGE e1 ADD (prop1 int, prop2 string), /* \u6dfb\u52a0 prop1 */ CHANGE (prop3 string), /* \u5c06 prop3 \u7c7b\u578b\u66f4\u6539\u4e3a\u5b57\u7b26 */ DROP (prop4, prop5); /* \u5220\u9664 prop4 \u548c prop5 */ nebula> ALTER EDGE e1 TTL_DURATION = 2, TTL_COL = prop1; \u6ce8\u610f TTL_COL \u4ec5\u652f\u6301 INT \u548c TIMESTAMP \u7c7b\u578b\u3002","title":"\u4fee\u6539 Tag / Edge"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/","text":"CREATE SPACE \u8bed\u6cd5 \u00b6 CREATE SPACE [IF NOT EXISTS] <space_name> [(partition_num = <part_num>, replica_factor = <raft_copy>, charset = <charset>, collate = <collate>)] \u4ee5\u4e0a\u8bed\u53e5\u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u56fe\u7a7a\u95f4\u3002\u4e0d\u540c\u7684\u56fe\u7a7a\u95f4\u662f\u7269\u7406\u9694\u79bb\u7684\u3002 IF NOT EXISTS \u00b6 \u521b\u5efa\u56fe\u7a7a\u95f4\u53ef\u4f7f\u7528 IF NOT EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u56fe\u7a7a\u95f4\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u521b\u5efa\u65b0\u7684\uff0c\u5982\u679c\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u6ce8\u610f\uff1a \u8fd9\u91cc\u5224\u65ad\u56fe\u7a7a\u95f4\u662f\u5426\u5b58\u5728\u53ea\u662f\u6bd4\u8f83\u56fe\u7a7a\u95f4\u7684\u540d\u5b57(\u4e0d\u5305\u62ec\u5c5e\u6027)\u3002 Space Name \u56fe\u7a7a\u95f4\u540d \u00b6 space_name \u56fe\u7a7a\u95f4\u7684\u540d\u79f0\u5728\u96c6\u7fa4\u4e2d\u6807\u660e\u4e86\u4e00\u4e2a\u552f\u4e00\u7684\u7a7a\u95f4\u3002\u547d\u540d\u89c4\u5219\u8be6\u89c1 Schema Object Names \u81ea\u5b9a\u4e49\u56fe\u7a7a\u95f4\u9009\u9879 \u00b6 \u5728\u521b\u5efa\u56fe\u7a7a\u95f4\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u4f20\u5165\u5982\u4e0b\u4e24\u4e2a\u81ea\u5b9a\u4e49\u9009\u9879\uff1a partition_num partition_num \u8868\u793a\u6570\u636e\u5206\u7247\u6570\u91cf\u3002\u9ed8\u8ba4\u503c\u4e3a 100\u3002 replica_factor replica_factor \u8868\u793a\u526f\u672c\u6570\u91cf\u3002\u9ed8\u8ba4\u503c\u662f 1\uff0c\u96c6\u7fa4\u5efa\u8bae\u4e3a 3\u3002 charset charset \u8868\u793a\u5b57\u7b26\u96c6\uff0c\u5b9a\u4e49\u4e86\u5b57\u7b26\u4ee5\u53ca\u5b57\u7b26\u7684\u7f16\u7801\uff0c\u9ed8\u8ba4\u4e3a utf8\u3002 collate collate \u8868\u793a\u5b57\u7b26\u5e8f\uff0c\u5b9a\u4e49\u4e86\u5b57\u7b26\u7684\u6bd4\u8f83\u89c4\u5219\uff0c\u9ed8\u8ba4\u4e3a utf8_bin\u3002 \u5982\u679c\u6ca1\u6709\u81ea\u5b9a\u4e49\u9009\u9879\uff0c Nebula Graph \u4f1a\u4f7f\u7528\u9ed8\u8ba4\u7684\u503c\uff08partition_number\u3001replica_factor\u3001charset \u548c collate\uff09\u6765\u521b\u5efa\u56fe\u7a7a\u95f4\u3002 \u793a\u4f8b \u00b6 nebula> CREATE SPACE my_space_1; -- \u4f7f\u7528\u9ed8\u8ba4\u9009\u9879\u521b\u5efa\u56fe\u7a7a\u95f4 nebula> CREATE SPACE my_space_2(partition_num=10); -- \u4f7f\u7528\u9ed8\u8ba4 replica_factor \u521b\u5efa\u56fe\u7a7a\u95f4 nebula> CREATE SPACE my_space_3(replica_factor=1); -- \u4f7f\u7528\u9ed8\u8ba4 partition_number \u521b\u5efa\u56fe\u7a7a\u95f4 nebula> CREATE SPACE my_space_4(partition_num=10, replica_factor=1);","title":"CREATE SPACE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#create_space","text":"CREATE SPACE [IF NOT EXISTS] <space_name> [(partition_num = <part_num>, replica_factor = <raft_copy>, charset = <charset>, collate = <collate>)] \u4ee5\u4e0a\u8bed\u53e5\u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u56fe\u7a7a\u95f4\u3002\u4e0d\u540c\u7684\u56fe\u7a7a\u95f4\u662f\u7269\u7406\u9694\u79bb\u7684\u3002","title":"CREATE SPACE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#if_not_exists","text":"\u521b\u5efa\u56fe\u7a7a\u95f4\u53ef\u4f7f\u7528 IF NOT EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u56fe\u7a7a\u95f4\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u521b\u5efa\u65b0\u7684\uff0c\u5982\u679c\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u6ce8\u610f\uff1a \u8fd9\u91cc\u5224\u65ad\u56fe\u7a7a\u95f4\u662f\u5426\u5b58\u5728\u53ea\u662f\u6bd4\u8f83\u56fe\u7a7a\u95f4\u7684\u540d\u5b57(\u4e0d\u5305\u62ec\u5c5e\u6027)\u3002","title":"IF NOT EXISTS"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#space_name","text":"space_name \u56fe\u7a7a\u95f4\u7684\u540d\u79f0\u5728\u96c6\u7fa4\u4e2d\u6807\u660e\u4e86\u4e00\u4e2a\u552f\u4e00\u7684\u7a7a\u95f4\u3002\u547d\u540d\u89c4\u5219\u8be6\u89c1 Schema Object Names","title":"Space Name \u56fe\u7a7a\u95f4\u540d"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#_1","text":"\u5728\u521b\u5efa\u56fe\u7a7a\u95f4\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u4f20\u5165\u5982\u4e0b\u4e24\u4e2a\u81ea\u5b9a\u4e49\u9009\u9879\uff1a partition_num partition_num \u8868\u793a\u6570\u636e\u5206\u7247\u6570\u91cf\u3002\u9ed8\u8ba4\u503c\u4e3a 100\u3002 replica_factor replica_factor \u8868\u793a\u526f\u672c\u6570\u91cf\u3002\u9ed8\u8ba4\u503c\u662f 1\uff0c\u96c6\u7fa4\u5efa\u8bae\u4e3a 3\u3002 charset charset \u8868\u793a\u5b57\u7b26\u96c6\uff0c\u5b9a\u4e49\u4e86\u5b57\u7b26\u4ee5\u53ca\u5b57\u7b26\u7684\u7f16\u7801\uff0c\u9ed8\u8ba4\u4e3a utf8\u3002 collate collate \u8868\u793a\u5b57\u7b26\u5e8f\uff0c\u5b9a\u4e49\u4e86\u5b57\u7b26\u7684\u6bd4\u8f83\u89c4\u5219\uff0c\u9ed8\u8ba4\u4e3a utf8_bin\u3002 \u5982\u679c\u6ca1\u6709\u81ea\u5b9a\u4e49\u9009\u9879\uff0c Nebula Graph \u4f1a\u4f7f\u7528\u9ed8\u8ba4\u7684\u503c\uff08partition_number\u3001replica_factor\u3001charset \u548c collate\uff09\u6765\u521b\u5efa\u56fe\u7a7a\u95f4\u3002","title":"\u81ea\u5b9a\u4e49\u56fe\u7a7a\u95f4\u9009\u9879"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#_2","text":"nebula> CREATE SPACE my_space_1; -- \u4f7f\u7528\u9ed8\u8ba4\u9009\u9879\u521b\u5efa\u56fe\u7a7a\u95f4 nebula> CREATE SPACE my_space_2(partition_num=10); -- \u4f7f\u7528\u9ed8\u8ba4 replica_factor \u521b\u5efa\u56fe\u7a7a\u95f4 nebula> CREATE SPACE my_space_3(replica_factor=1); -- \u4f7f\u7528\u9ed8\u8ba4 partition_number \u521b\u5efa\u56fe\u7a7a\u95f4 nebula> CREATE SPACE my_space_4(partition_num=10, replica_factor=1);","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/","text":"CREATE TAG / EDGE \u8bed\u6cd5 \u00b6 CREATE {TAG | EDGE} [IF NOT EXISTS] {<tag_name> | <edge_name>} ([<create_definition>, ...]) [tag_edge_options] <create_definition> ::= <prop_name> <data_type> <tag_edge_options> ::= <option> [, <option> ...] <option> ::= TTL_DURATION [=] <ttl_duration> | TTL_COL [=] <prop_name> | DEFAULT <default_value> Nebula Graph \u7684\u56fe\u7ed3\u6784\u7531\u5e26\u6709\u5c5e\u6027\u7684 tags \u548c edges \u7ec4\u6210\u3002 CREATE TAG \u4f7f\u7528\u4e00\u4e2a\u7ed9\u5b9a\u7684\u540d\u79f0\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 tag\u3002 CREATE EDGE \u5219\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 edge type\u3002 CREATE TAG/EDGE \u8bed\u6cd5\u6709\u4e00\u4e9b\u7279\u70b9\uff0c\u5728\u5982\u4e0b\u5206\u5757\u4e2d\u5c06\u5bf9\u8fd9\u4e9b\u7279\u70b9\u8fdb\u884c\u8ba8\u8bba\uff1a IF NOT EXISTS \u00b6 \u521b\u5efa tag \u6216 edge \u53ef\u4f7f\u7528 IF NOT EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684 tag \u6216 edge \u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u521b\u5efa\u65b0\u7684\uff0c\u5982\u679c\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u6ce8\u610f\uff1a \u8fd9\u91cc\u5224\u65ad tag \u6216 edge \u662f\u5426\u5b58\u5728\u53ea\u662f\u6bd4\u8f83 tag \u6216 edge \u7684\u540d\u5b57(\u4e0d\u5305\u62ec\u5c5e\u6027)\u3002 Tag \u540d\u79f0\u548c Edge Type \u540d\u79f0 \u00b6 tag_name \u548c edge_name tags \u548c edgeTypes \u7684\u540d\u79f0\u5728\u56fe\u4e2d\u5fc5\u987b \u552f\u4e00 \uff0c\u4e14\u540d\u79f0\u88ab\u5b9a\u4e49\u540e\u65e0\u6cd5\u88ab\u4fee\u6539\u3002Tag \u548c edgeType \u7684\u547d\u540d\u89c4\u5219\u548c space \u7684\u547d\u540d\u89c4\u5219\u4e00\u81f4\u3002\u53c2\u89c1 Schema Object Name \u3002 \u5c5e\u6027\u540d\u548c\u6570\u636e\u7c7b\u578b \u00b6 prop_name prop_name \u8868\u793a\u6bcf\u4e2a\u5c5e\u6027\u7684\u540d\u79f0\u3002\u5728\u6bcf\u4e2a tag \u548c edgeType \u4e2d\u5fc5\u987b\u552f\u4e00\u3002 data_type data_type \u8868\u793a\u6bcf\u4e2a\u5c5e\u6027\u7684\u6570\u636e\u7c7b\u578b\u3002\u66f4\u591a\u5173\u4e8e Nebula Graph \u652f\u6301\u7684\u6570\u636e\u7c7b\u578b\u4fe1\u606f\u8bf7\u53c2\u89c1 data-type \u3002 NULL \u548c NOT NULL \u5728\u521b\u5efa tag \u548c edge \u65f6\u4e0d\u53ef\u7528\u3002(\u76f8\u6bd4\u4e8e\u5173\u7cfb\u578b\u6570\u636e\u5e93)\u3002 \u9ed8\u8ba4\u503c\u7ea6\u675f \u60a8\u53ef\u4ee5\u5728\u521b\u5efa\u6807\u7b7e/\u8fb9\u65f6\u4f7f\u7528 DEFAULT \u7ea6\u675f\u8bbe\u7f6e\u5c5e\u6027\u7684\u9ed8\u8ba4\u503c\u3002\u5982\u679c\u6ca1\u6709\u6307\u5b9a\u5176\u4ed6\u503c\uff0c\u90a3\u4e48\u4f1a\u5c06\u9ed8\u8ba4\u503c\u63d2\u5165\u65b0\u7684\u9876\u70b9\u6216\u8fb9\u3002\u9ed8\u8ba4\u503c\u53ef\u4ee5\u4e3a Nebula Graph \u652f\u6301\u7684\u4efb\u4e00\u6570\u636e\u7c7b\u578b\uff0c\u4e14\u652f\u6301\u8868\u8fbe\u5f0f\u3002\u5982\u679c\u60a8\u4e0d\u60f3\u4f7f\u7528\u9ed8\u8ba4\u503c\uff0c\u4e5f\u53ef\u4ee5\u5199\u4e00\u4e2a\u7528\u6237\u6307\u5b9a\u7684\u503c\u3002 \u6682\u65f6\u4e0d\u652f\u6301\u4f7f\u7528 Alter \u66f4\u6539\u9ed8\u8ba4\u503c\u3002 Time-to-Live (TTL) \u8bed\u6cd5 \u00b6 TTL_DURATION TTL_DURATION \u6307\u5b9a\u4e86 vertices \u548c edges \u7684\u6709\u6548\u671f\uff0c\u8d85\u8fc7\u6709\u6548\u671f\u7684\u6570\u636e\u4f1a\u5931\u6548\u3002\u5931\u6548\u65f6\u95f4\u4e3a TTL_COL \u8bbe\u7f6e\u7684\u5c5e\u6027\u503c\u52a0 TTL_DURATION \u8bbe\u7f6e\u7684\u79d2\u6570\u3002 \u5982\u679c TTL_DURATION \u7684\u503c\u4e3a\u8d1f\u6216 0\uff0c\u5219\u8be5 edge \u4e0d\u4f1a\u5931\u6548\u3002 TTL_COL \u6307\u5b9a\u7684\u5217\uff08\u6216\u8005\u5c5e\u6027\uff09\u5fc5\u987b\u662f int64 \u6216\u8005 timestamp\u3002 \u5355 TTL \u5b9a\u4e49 \u4ec5\u652f\u6301\u6307\u5b9a\u5355\u4e2a TTL_COL \u5b57\u6bb5\u3002 TTL \u8be6\u7ec6\u7528\u6cd5\u53c2\u89c1 TTL \u6587\u6863 \u3002 \u793a\u4f8b \u00b6 nebula> CREATE TAG course(name string, credits int); nebula> CREATE TAG notag(); -- \u5c5e\u6027\u4e3a\u7a7a nebula> CREATE EDGE follow(start_time timestamp, grade double); nebula> CREATE EDGE noedge(); -- \u5c5e\u6027\u4e3a\u7a7a nebula> CREATE TAG player_with_default(name string, age int DEFAULT 20); -- \u9ed8\u8ba4\u5e74\u9f84\u8bbe\u7f6e\u4e3a 20 \u5c81 nebula> CREATE EDGE follow_with_default(start_time timestamp DEFAULT 0, grade double DEFAULT 0.0); -- \u9ed8\u8ba4 start_time \u8bbe\u7f6e\u4e3a 0\uff0c\u9ed8\u8ba4 grade \u8bbe\u7f6e\u4e3a 0.0 nebula> CREATE TAG woman(name string, age int, married bool, salary double, create_time timestamp) TTL_DURATION = 100, TTL_COL = \"create_time\"; -- \u65f6\u95f4\u95f4\u9694\u662f 100s\uff0c\u4ece create_time \u5b57\u6bb5\u7684\u503c\u5f00\u59cb nebula> CREATE EDGE marriage(location string, since timestamp) TTL_DURATION = 0, TTL_COL = \"since\"; -- \u8d1f\u503c\u6216 0 \u6570\u636e\u4e0d\u4f1a\u5931\u6548 nebula> CREATE TAG icecream(made timestamp, temperature int) TTL_DURATION = 100, TTL_COL = \"made\"; -- \u8d85\u8fc7 TTL_DURATION \u6570\u636e\u5373\u5931\u6548","title":"CREATE TAG / EDGE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#create_tag_edge","text":"CREATE {TAG | EDGE} [IF NOT EXISTS] {<tag_name> | <edge_name>} ([<create_definition>, ...]) [tag_edge_options] <create_definition> ::= <prop_name> <data_type> <tag_edge_options> ::= <option> [, <option> ...] <option> ::= TTL_DURATION [=] <ttl_duration> | TTL_COL [=] <prop_name> | DEFAULT <default_value> Nebula Graph \u7684\u56fe\u7ed3\u6784\u7531\u5e26\u6709\u5c5e\u6027\u7684 tags \u548c edges \u7ec4\u6210\u3002 CREATE TAG \u4f7f\u7528\u4e00\u4e2a\u7ed9\u5b9a\u7684\u540d\u79f0\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 tag\u3002 CREATE EDGE \u5219\u521b\u5efa\u4e00\u4e2a\u65b0\u7684 edge type\u3002 CREATE TAG/EDGE \u8bed\u6cd5\u6709\u4e00\u4e9b\u7279\u70b9\uff0c\u5728\u5982\u4e0b\u5206\u5757\u4e2d\u5c06\u5bf9\u8fd9\u4e9b\u7279\u70b9\u8fdb\u884c\u8ba8\u8bba\uff1a","title":"CREATE TAG / EDGE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#if_not_exists","text":"\u521b\u5efa tag \u6216 edge \u53ef\u4f7f\u7528 IF NOT EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684 tag \u6216 edge \u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u521b\u5efa\u65b0\u7684\uff0c\u5982\u679c\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u6ce8\u610f\uff1a \u8fd9\u91cc\u5224\u65ad tag \u6216 edge \u662f\u5426\u5b58\u5728\u53ea\u662f\u6bd4\u8f83 tag \u6216 edge \u7684\u540d\u5b57(\u4e0d\u5305\u62ec\u5c5e\u6027)\u3002","title":"IF NOT EXISTS"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#tag_edge_type","text":"tag_name \u548c edge_name tags \u548c edgeTypes \u7684\u540d\u79f0\u5728\u56fe\u4e2d\u5fc5\u987b \u552f\u4e00 \uff0c\u4e14\u540d\u79f0\u88ab\u5b9a\u4e49\u540e\u65e0\u6cd5\u88ab\u4fee\u6539\u3002Tag \u548c edgeType \u7684\u547d\u540d\u89c4\u5219\u548c space \u7684\u547d\u540d\u89c4\u5219\u4e00\u81f4\u3002\u53c2\u89c1 Schema Object Name \u3002","title":"Tag \u540d\u79f0\u548c Edge Type \u540d\u79f0"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#_1","text":"prop_name prop_name \u8868\u793a\u6bcf\u4e2a\u5c5e\u6027\u7684\u540d\u79f0\u3002\u5728\u6bcf\u4e2a tag \u548c edgeType \u4e2d\u5fc5\u987b\u552f\u4e00\u3002 data_type data_type \u8868\u793a\u6bcf\u4e2a\u5c5e\u6027\u7684\u6570\u636e\u7c7b\u578b\u3002\u66f4\u591a\u5173\u4e8e Nebula Graph \u652f\u6301\u7684\u6570\u636e\u7c7b\u578b\u4fe1\u606f\u8bf7\u53c2\u89c1 data-type \u3002 NULL \u548c NOT NULL \u5728\u521b\u5efa tag \u548c edge \u65f6\u4e0d\u53ef\u7528\u3002(\u76f8\u6bd4\u4e8e\u5173\u7cfb\u578b\u6570\u636e\u5e93)\u3002 \u9ed8\u8ba4\u503c\u7ea6\u675f \u60a8\u53ef\u4ee5\u5728\u521b\u5efa\u6807\u7b7e/\u8fb9\u65f6\u4f7f\u7528 DEFAULT \u7ea6\u675f\u8bbe\u7f6e\u5c5e\u6027\u7684\u9ed8\u8ba4\u503c\u3002\u5982\u679c\u6ca1\u6709\u6307\u5b9a\u5176\u4ed6\u503c\uff0c\u90a3\u4e48\u4f1a\u5c06\u9ed8\u8ba4\u503c\u63d2\u5165\u65b0\u7684\u9876\u70b9\u6216\u8fb9\u3002\u9ed8\u8ba4\u503c\u53ef\u4ee5\u4e3a Nebula Graph \u652f\u6301\u7684\u4efb\u4e00\u6570\u636e\u7c7b\u578b\uff0c\u4e14\u652f\u6301\u8868\u8fbe\u5f0f\u3002\u5982\u679c\u60a8\u4e0d\u60f3\u4f7f\u7528\u9ed8\u8ba4\u503c\uff0c\u4e5f\u53ef\u4ee5\u5199\u4e00\u4e2a\u7528\u6237\u6307\u5b9a\u7684\u503c\u3002 \u6682\u65f6\u4e0d\u652f\u6301\u4f7f\u7528 Alter \u66f4\u6539\u9ed8\u8ba4\u503c\u3002","title":"\u5c5e\u6027\u540d\u548c\u6570\u636e\u7c7b\u578b"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#time-to-live_ttl","text":"TTL_DURATION TTL_DURATION \u6307\u5b9a\u4e86 vertices \u548c edges \u7684\u6709\u6548\u671f\uff0c\u8d85\u8fc7\u6709\u6548\u671f\u7684\u6570\u636e\u4f1a\u5931\u6548\u3002\u5931\u6548\u65f6\u95f4\u4e3a TTL_COL \u8bbe\u7f6e\u7684\u5c5e\u6027\u503c\u52a0 TTL_DURATION \u8bbe\u7f6e\u7684\u79d2\u6570\u3002 \u5982\u679c TTL_DURATION \u7684\u503c\u4e3a\u8d1f\u6216 0\uff0c\u5219\u8be5 edge \u4e0d\u4f1a\u5931\u6548\u3002 TTL_COL \u6307\u5b9a\u7684\u5217\uff08\u6216\u8005\u5c5e\u6027\uff09\u5fc5\u987b\u662f int64 \u6216\u8005 timestamp\u3002 \u5355 TTL \u5b9a\u4e49 \u4ec5\u652f\u6301\u6307\u5b9a\u5355\u4e2a TTL_COL \u5b57\u6bb5\u3002 TTL \u8be6\u7ec6\u7528\u6cd5\u53c2\u89c1 TTL \u6587\u6863 \u3002","title":"Time-to-Live (TTL) \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#_2","text":"nebula> CREATE TAG course(name string, credits int); nebula> CREATE TAG notag(); -- \u5c5e\u6027\u4e3a\u7a7a nebula> CREATE EDGE follow(start_time timestamp, grade double); nebula> CREATE EDGE noedge(); -- \u5c5e\u6027\u4e3a\u7a7a nebula> CREATE TAG player_with_default(name string, age int DEFAULT 20); -- \u9ed8\u8ba4\u5e74\u9f84\u8bbe\u7f6e\u4e3a 20 \u5c81 nebula> CREATE EDGE follow_with_default(start_time timestamp DEFAULT 0, grade double DEFAULT 0.0); -- \u9ed8\u8ba4 start_time \u8bbe\u7f6e\u4e3a 0\uff0c\u9ed8\u8ba4 grade \u8bbe\u7f6e\u4e3a 0.0 nebula> CREATE TAG woman(name string, age int, married bool, salary double, create_time timestamp) TTL_DURATION = 100, TTL_COL = \"create_time\"; -- \u65f6\u95f4\u95f4\u9694\u662f 100s\uff0c\u4ece create_time \u5b57\u6bb5\u7684\u503c\u5f00\u59cb nebula> CREATE EDGE marriage(location string, since timestamp) TTL_DURATION = 0, TTL_COL = \"since\"; -- \u8d1f\u503c\u6216 0 \u6570\u636e\u4e0d\u4f1a\u5931\u6548 nebula> CREATE TAG icecream(made timestamp, temperature int) TTL_DURATION = 100, TTL_COL = \"made\"; -- \u8d85\u8fc7 TTL_DURATION \u6570\u636e\u5373\u5931\u6548","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-edge-syntax/","text":"DROP EDGE \u8bed\u6cd5 \u00b6 DROP EDGE [IF EXISTS] <edge_type_name> \u4ec5\u652f\u6301\u6709 DROP \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 \u6ce8\u610f\uff1a \u5220\u9664\u8fb9\u65f6 Nebula Graph \u5c06\u5224\u65ad\u76f8\u5e94\u8fb9\u662f\u5426\u6709\u5173\u8054\u7684\u7d22\u5f15\uff0c\u5982\u679c\u6709\u5219\u62d2\u7edd\u5220\u9664\u3002 \u8bf7\u53c2\u8003 \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u7d22\u5f15\u8be6\u60c5\u3002 \u5220\u9664\u8fb9\u53ef\u4f7f\u7528 IF EXISTS \u5173\u952e\u8bcd\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u8fb9\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u5220\u9664\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u6b64\u64cd\u4f5c\u5c06\u79fb\u9664\u6307\u5b9a\u7c7b\u578b\u7684\u6240\u6709\u8fb9\u3002 \u6b64\u64cd\u4f5c\u4ec5\u5220\u9664 Schema \u4fe1\u606f\uff0c\u786c\u76d8\u4e2d\u6240\u6709\u6587\u4ef6\u53ca\u76ee\u5f55\u5747 \u672a\u88ab\u76f4\u63a5\u5220\u9664 \uff0c\u6570\u636e\u4f1a\u5728\u4e0b\u6b21 compaction \u65f6\u5220\u9664\u3002","title":"DROP EDGE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-edge-syntax/#drop_edge","text":"DROP EDGE [IF EXISTS] <edge_type_name> \u4ec5\u652f\u6301\u6709 DROP \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 \u6ce8\u610f\uff1a \u5220\u9664\u8fb9\u65f6 Nebula Graph \u5c06\u5224\u65ad\u76f8\u5e94\u8fb9\u662f\u5426\u6709\u5173\u8054\u7684\u7d22\u5f15\uff0c\u5982\u679c\u6709\u5219\u62d2\u7edd\u5220\u9664\u3002 \u8bf7\u53c2\u8003 \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u7d22\u5f15\u8be6\u60c5\u3002 \u5220\u9664\u8fb9\u53ef\u4f7f\u7528 IF EXISTS \u5173\u952e\u8bcd\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u8fb9\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u5220\u9664\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u6b64\u64cd\u4f5c\u5c06\u79fb\u9664\u6307\u5b9a\u7c7b\u578b\u7684\u6240\u6709\u8fb9\u3002 \u6b64\u64cd\u4f5c\u4ec5\u5220\u9664 Schema \u4fe1\u606f\uff0c\u786c\u76d8\u4e2d\u6240\u6709\u6587\u4ef6\u53ca\u76ee\u5f55\u5747 \u672a\u88ab\u76f4\u63a5\u5220\u9664 \uff0c\u6570\u636e\u4f1a\u5728\u4e0b\u6b21 compaction \u65f6\u5220\u9664\u3002","title":"DROP EDGE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-space-syntax/","text":"DROP SPACE \u8bed\u6cd5 \u00b6 DROP SPACE [IF EXISTS] <space_name> \u4ec5\u652f\u6301\u6709 DROP \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 DROP SPACE \u5c06\u5220\u9664\u6307\u5b9a space \u5185\u7684\u6240\u6709\u70b9\u548c\u8fb9\u3002 \u5220\u9664\u56fe\u7a7a\u95f4\u53ef\u4f7f\u7528 IF EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u56fe\u7a7a\u95f4\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u5220\u9664\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u5176\u4ed6 space \u4e0d\u53d7\u5f71\u54cd\u3002 \u8be5\u8bed\u53e5\u4e0d\u4f1a\u7acb\u5373\u5220\u9664\u5b58\u50a8\u5f15\u64ce\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u548c\u76ee\u5f55\uff08\u5e76\u91ca\u653e\u78c1\u76d8\u7a7a\u95f4\uff09\u3002\u5220\u9664\u64cd\u4f5c\u53d6\u51b3\u4e8e\u4e0d\u540c\u5b58\u50a8\u5f15\u64ce\u7684\u5b9e\u73b0\u3002 \u8bf7 \u8c28\u614e \u8fdb\u884c\u6b64\u64cd\u4f5c\u3002","title":"DROP SPACE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-space-syntax/#drop_space","text":"DROP SPACE [IF EXISTS] <space_name> \u4ec5\u652f\u6301\u6709 DROP \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 DROP SPACE \u5c06\u5220\u9664\u6307\u5b9a space \u5185\u7684\u6240\u6709\u70b9\u548c\u8fb9\u3002 \u5220\u9664\u56fe\u7a7a\u95f4\u53ef\u4f7f\u7528 IF EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u56fe\u7a7a\u95f4\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u5220\u9664\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u5176\u4ed6 space \u4e0d\u53d7\u5f71\u54cd\u3002 \u8be5\u8bed\u53e5\u4e0d\u4f1a\u7acb\u5373\u5220\u9664\u5b58\u50a8\u5f15\u64ce\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u548c\u76ee\u5f55\uff08\u5e76\u91ca\u653e\u78c1\u76d8\u7a7a\u95f4\uff09\u3002\u5220\u9664\u64cd\u4f5c\u53d6\u51b3\u4e8e\u4e0d\u540c\u5b58\u50a8\u5f15\u64ce\u7684\u5b9e\u73b0\u3002 \u8bf7 \u8c28\u614e \u8fdb\u884c\u6b64\u64cd\u4f5c\u3002","title":"DROP SPACE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-tag-syntax/","text":"DROP TAG \u8bed\u6cd5 \u00b6 DROP TAG [IF EXISTS] <tag_name> \u4ec5\u652f\u6301\u6709 DROP \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 \u8bf7\u8c28\u614e\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 \u6ce8\u610f\uff1a \u5220\u9664\u6807\u7b7e\u65f6 Nebula Graph \u5c06\u5224\u65ad\u76f8\u5e94\u6807\u7b7e\u662f\u5426\u6709\u5173\u8054\u7684\u7d22\u5f15\uff0c\u5982\u679c\u6709\u5219\u62d2\u7edd\u5220\u9664\u3002 \u8bf7\u53c2\u8003 \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u7d22\u5f15\u8be6\u60c5\u3002 \u5220\u9664\u6807\u7b7e\u53ef\u4f7f\u7528 IF EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u6807\u7b7e\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u5220\u9664\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u4e00\u4e2a\u8282\u70b9\u53ef\u4ee5\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u7b7e\uff08\u7c7b\u578b\uff09\u3002 \u5220\u9664\u6240\u6709\u6807\u7b7e\u540e\uff0c\u8282\u70b9\u5c06\u4e0d\u53ef\u8bbf\u95ee\uff0c\u540c\u65f6\u4e0e\u8282\u70b9\u8fde\u63a5\u7684\u8fb9\u4e5f\u4e0d\u53ef\u4f7f\u7528\u3002 \u5220\u9664\u5355\u4e2a\u6807\u7b7e\u540e\uff0c\u8282\u70b9\u4ecd\u53ef\u8bbf\u95ee\uff0c\u4f46\u662f\u5df2\u5220\u9664\u6807\u7b7e\u7684\u5c5e\u6027\u4e0d\u53ef\u8bbf\u95ee\u3002 \u6b64\u64cd\u4f5c\u4ec5\u5220\u9664 Schema \u4fe1\u606f\uff0c\u786c\u76d8\u4e2d\u6240\u6709\u6587\u4ef6\u53ca\u76ee\u5f55\u5747 \u672a\u88ab\u76f4\u63a5\u5220\u9664 \uff0c\u6570\u636e\u4f1a\u5728\u4e0b\u6b21 compaction \u65f6\u5220\u9664\u3002","title":"DROP TAG \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-tag-syntax/#drop_tag","text":"DROP TAG [IF EXISTS] <tag_name> \u4ec5\u652f\u6301\u6709 DROP \u6743\u9650\u7684\u7528\u6237\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 \u8bf7\u8c28\u614e\u8fdb\u884c\u6b64\u64cd\u4f5c\u3002 \u6ce8\u610f\uff1a \u5220\u9664\u6807\u7b7e\u65f6 Nebula Graph \u5c06\u5224\u65ad\u76f8\u5e94\u6807\u7b7e\u662f\u5426\u6709\u5173\u8054\u7684\u7d22\u5f15\uff0c\u5982\u679c\u6709\u5219\u62d2\u7edd\u5220\u9664\u3002 \u8bf7\u53c2\u8003 \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u7d22\u5f15\u8be6\u60c5\u3002 \u5220\u9664\u6807\u7b7e\u53ef\u4f7f\u7528 IF EXISTS \u5173\u952e\u5b57\uff0c\u8fd9\u4e2a\u5173\u952e\u5b57\u4f1a\u81ea\u52a8\u68c0\u6d4b\u5bf9\u5e94\u7684\u6807\u7b7e\u662f\u5426\u5b58\u5728\uff0c\u5982\u679c\u5b58\u5728\u5219\u5220\u9664\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u76f4\u63a5\u8fd4\u56de\u3002 \u4e00\u4e2a\u8282\u70b9\u53ef\u4ee5\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u7b7e\uff08\u7c7b\u578b\uff09\u3002 \u5220\u9664\u6240\u6709\u6807\u7b7e\u540e\uff0c\u8282\u70b9\u5c06\u4e0d\u53ef\u8bbf\u95ee\uff0c\u540c\u65f6\u4e0e\u8282\u70b9\u8fde\u63a5\u7684\u8fb9\u4e5f\u4e0d\u53ef\u4f7f\u7528\u3002 \u5220\u9664\u5355\u4e2a\u6807\u7b7e\u540e\uff0c\u8282\u70b9\u4ecd\u53ef\u8bbf\u95ee\uff0c\u4f46\u662f\u5df2\u5220\u9664\u6807\u7b7e\u7684\u5c5e\u6027\u4e0d\u53ef\u8bbf\u95ee\u3002 \u6b64\u64cd\u4f5c\u4ec5\u5220\u9664 Schema \u4fe1\u606f\uff0c\u786c\u76d8\u4e2d\u6240\u6709\u6587\u4ef6\u53ca\u76ee\u5f55\u5747 \u672a\u88ab\u76f4\u63a5\u5220\u9664 \uff0c\u6570\u636e\u4f1a\u5728\u4e0b\u6b21 compaction \u65f6\u5220\u9664\u3002","title":"DROP TAG \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-edge-syntax/","text":"Delete Edge \u8bed\u6cd5 \u00b6 DELETE EDGE \u8bed\u53e5\u7528\u4e8e\u5220\u9664\u8fb9\u3002\u7ed9\u5b9a\u4e00\u4e2a edge \u7c7b\u578b\uff0c\u53ca\u5176\u8d77\u70b9\u4e0e\u7ec8\u70b9\uff0c Nebula Graph \u652f\u6301\u5220\u9664\u8fd9\u6761\u8fb9\u53ca\u5176\u76f8\u5173\u5c5e\u6027\u548c ranking\uff0c\u4e5f\u652f\u6301\u6307\u5b9a ranking \u5220\u9664\u8fb9\uff0c\u8bed\u6cd5\u5982\u4e0b\uff1a DELETE EDGE <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] \u7cfb\u7edf\u5185\u90e8\u4f1a\u627e\u51fa\u4e0e\u8fd9\u6761\u8fb9\u76f8\u5173\u8054\u7684\u5c5e\u6027\uff0c\u5e76\u5c06\u5176\u5168\u90e8\u5220\u9664\u3002\u6574\u4e2a\u8fc7\u7a0b\u5f53\u524d\u8fd8\u65e0\u6cd5\u4fdd\u8bc1\u539f\u5b50\u6027\uff0c\u56e0\u6b64\u5f53\u9047\u5230\u5931\u8d25\u65f6\u8bf7\u91cd\u8bd5\u3002","title":"Delete Edge \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-edge-syntax/#delete_edge","text":"DELETE EDGE \u8bed\u53e5\u7528\u4e8e\u5220\u9664\u8fb9\u3002\u7ed9\u5b9a\u4e00\u4e2a edge \u7c7b\u578b\uff0c\u53ca\u5176\u8d77\u70b9\u4e0e\u7ec8\u70b9\uff0c Nebula Graph \u652f\u6301\u5220\u9664\u8fd9\u6761\u8fb9\u53ca\u5176\u76f8\u5173\u5c5e\u6027\u548c ranking\uff0c\u4e5f\u652f\u6301\u6307\u5b9a ranking \u5220\u9664\u8fb9\uff0c\u8bed\u6cd5\u5982\u4e0b\uff1a DELETE EDGE <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] \u7cfb\u7edf\u5185\u90e8\u4f1a\u627e\u51fa\u4e0e\u8fd9\u6761\u8fb9\u76f8\u5173\u8054\u7684\u5c5e\u6027\uff0c\u5e76\u5c06\u5176\u5168\u90e8\u5220\u9664\u3002\u6574\u4e2a\u8fc7\u7a0b\u5f53\u524d\u8fd8\u65e0\u6cd5\u4fdd\u8bc1\u539f\u5b50\u6027\uff0c\u56e0\u6b64\u5f53\u9047\u5230\u5931\u8d25\u65f6\u8bf7\u91cd\u8bd5\u3002","title":"Delete Edge \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-vertex-syntax/","text":"Delete Vertex \u8bed\u6cd5 \u00b6 Nebula Graph \u652f\u6301\u7ed9\u5b9a\u70b9 ID\uff08\u6216 hash ID\u3001UUID\uff09\uff0c\u5220\u9664\u8fd9\u4e9b\u9876\u70b9\u548c\u4e0e\u5176\u76f8\u5173\u8054\u7684\u5165\u8fb9\u548c\u51fa\u8fb9\uff0c\u8bed\u6cd5\u5982\u4e0b\uff1a DELETE VERTEX <vid_list> \u7cfb\u7edf\u5185\u90e8\u4f1a\u627e\u51fa\u4e0e\u8fd9\u4e9b\u9876\u70b9\u76f8\u5173\u8054\u7684\u51fa\u8fb9\u548c\u5165\u8fb9\uff0c\u5e76\u5c06\u5176\u5168\u90e8\u5220\u9664\uff0c\u7136\u540e\u518d\u5220\u9664\u70b9\u76f8\u5173\u7684\u4fe1\u606f\u3002\u6574\u4e2a\u8fc7\u7a0b\u5f53\u524d\u8fd8\u65e0\u6cd5\u4fdd\u8bc1\u539f\u5b50\u6027\uff0c\u56e0\u6b64\u82e5\u64cd\u4f5c\u5931\u8d25\u8bf7\u91cd\u8bd5\u3002","title":"Delete Vertex \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-vertex-syntax/#delete_vertex","text":"Nebula Graph \u652f\u6301\u7ed9\u5b9a\u70b9 ID\uff08\u6216 hash ID\u3001UUID\uff09\uff0c\u5220\u9664\u8fd9\u4e9b\u9876\u70b9\u548c\u4e0e\u5176\u76f8\u5173\u8054\u7684\u5165\u8fb9\u548c\u51fa\u8fb9\uff0c\u8bed\u6cd5\u5982\u4e0b\uff1a DELETE VERTEX <vid_list> \u7cfb\u7edf\u5185\u90e8\u4f1a\u627e\u51fa\u4e0e\u8fd9\u4e9b\u9876\u70b9\u76f8\u5173\u8054\u7684\u51fa\u8fb9\u548c\u5165\u8fb9\uff0c\u5e76\u5c06\u5176\u5168\u90e8\u5220\u9664\uff0c\u7136\u540e\u518d\u5220\u9664\u70b9\u76f8\u5173\u7684\u4fe1\u606f\u3002\u6574\u4e2a\u8fc7\u7a0b\u5f53\u524d\u8fd8\u65e0\u6cd5\u4fdd\u8bc1\u539f\u5b50\u6027\uff0c\u56e0\u6b64\u82e5\u64cd\u4f5c\u5931\u8d25\u8bf7\u91cd\u8bd5\u3002","title":"Delete Vertex \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/","text":"Fetch \u8bed\u6cd5 \u00b6 FETCH \u8bed\u53e5\u7528\u4e8e\u83b7\u53d6\u70b9\u548c\u8fb9\u7684\u5c5e\u6027\u3002 \u83b7\u53d6\u70b9\u5c5e\u6027 \u00b6 FETCH PROP ON \u53ef\u8fd4\u56de\u8282\u70b9\u7684\u4e00\u7cfb\u5217\u5c5e\u6027\uff0c\u76ee\u524d\u5df2\u652f\u6301\u4e00\u6761\u8bed\u53e5\u8fd4\u56de\u591a\u4e2a\u8282\u70b9\u5c5e\u6027\u3002 FETCH PROP ON <tag_name> <vertex_id_list> [YIELD [DISTINCT] <return_list>] FETCH PROP ON * <vertex_id> * \u8fd4\u56de\u6307\u5b9a ID \u70b9\u7684\u6240\u6709\u5c5e\u6027\u3002 <tag_name> \u4e3a\u6807\u7b7e\u540d\u79f0\uff0c\u4e0e return_list \u4e2d\u7684\u6807\u7b7e\u76f8\u540c\u3002 <vertex_id_list>::=[vertex_id [, vertex_id]] \u662f\u4e00\u7ec4\u7528 \",\" \u5206\u9694\u5f00\u7684\u9876\u70b9 ID \u5217\u8868\u3002 [YIELD [DISTINCT] <return_list>] \u4e3a\u8fd4\u56de\u7684\u5c5e\u6027\u5217\u8868\uff0c YIELD \u8bed\u6cd5\u53c2\u770b YIELD Syntax \u3002 \u793a\u4f8b \u00b6 -- \u8fd4\u56de\u8282\u70b9 100 \u7684\u6240\u6709\u5c5e\u6027\u3002 nebula> FETCH PROP ON * 100; -- \u5982\u672a\u6307\u5b9a YIELD \u5b57\u6bb5\uff0c\u5219\u8fd4\u56de\u8282\u70b9 100, tag \u4e3a player \u7684\u6240\u6709\u5c5e\u6027\u3002 nebula> FETCH PROP ON player 100; -- \u8fd4\u56de\u8282\u70b9 100 \u7684\u59d3\u540d\u4e0e\u5e74\u9f84\u5c5e\u6027\u3002 nebula> FETCH PROP ON player 100 YIELD player.name, player.age; -- \u901a\u8fc7 hash \u751f\u6210 int64 \u8282\u70b9 ID\uff0c\u8fd4\u56de\u5176\u59d3\u540d\u548c\u5e74\u9f84\u5c5e\u6027\u3002 nebula> FETCH PROP ON player hash(\"nebula\") YIELD player.name, player.age; -- \u6cbf\u8fb9 follow \u5bfb\u627e\u8282\u70b9 100 \u7684\u6240\u6709\u8fd1\u90bb\uff0c\u8fd4\u56de\u5176\u59d3\u540d\u548c\u5e74\u9f84\u5c5e\u6027\u3002 nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | FETCH PROP ON player $-.id YIELD player.name, player.age; -- \u4e0e\u4e0a\u8ff0\u8bed\u6cd5\u76f8\u540c\u3002 nebula> $var = GO FROM 100 OVER follow YIELD follow._dst AS id; FETCH PROP ON player $var.id YIELD player.name, player.age; -- \u83b7\u53d6 100\u3001101\u3001102 \u4e09\u4e2a\u8282\u70b9\uff0c\u8fd4\u56de\u59d3\u540d\u548c\u5e74\u9f84\u90fd\u4e0d\u76f8\u540c\u7684\u8bb0\u5f55\u3002 nebula> FETCH PROP ON player 100,101,102 YIELD DISTINCT player.name, player.age; \u83b7\u53d6\u8fb9\u5c5e\u6027 \u00b6 \u4f7f\u7528 FETCH \u83b7\u53d6\u8fb9\u5c5e\u6027\u7684\u7528\u6cd5\u4e0e\u70b9\u5c5e\u6027\u5927\u81f4\u76f8\u540c\uff0c\u4e14\u53ef\u540c\u65f6\u83b7\u53d6\u76f8\u540c\u7c7b\u578b\u591a\u6761\u8fb9\u7684\u5c5e\u6027\u3002 FETCH PROP ON <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] [YIELD [DISTINCT] <return_list>] <edge_type> \u6307\u5b9a\u8fb9\u7684\u7c7b\u578b\uff0c\u9700\u4e0e <return_list> \u76f8\u540c\u3002 <vid> -> <vid> \u4ece\u8d77\u59cb\u8282\u70b9\u5230\u7ec8\u6b62\u8282\u70b9\uff0c\u591a\u6761\u8fb9\u9700\u4f7f\u7528\u9017\u53f7\u9694\u5f00\u3002 <ranking> \u6307\u5b9a\u76f8\u540c\u7c7b\u578b\u8fb9 ranking\uff0c\u53ef\u9009\u3002 [YIELD [DISTINCT] <return_list>] \u4e3a\u8fd4\u56de\u7684\u5c5e\u6027\u5217\u8868\u3002 \u83b7\u53d6\u8fb9\u5c5e\u6027\u793a\u4f8b \u00b6 -- \u672c\u8bed\u53e5\u672a\u6307\u5b9a YIELD\uff0c\u56e0\u6b64\u83b7\u53d6\u4ece\u8282\u70b9 100 \u5230\u8282\u70b9 200 \u8fb9 serve \u7684\u6240\u6709\u5c5e\u6027\u3002 nebula> FETCH PROP ON serve 100 -> 200; -- \u4ec5\u8fd4\u56de\u5c5e\u6027 start_year\u3002 nebula> FETCH PROP ON serve 100 -> 200 YIELD serve.start_year; -- \u83b7\u53d6\u8282\u70b9 100 \u51fa\u8fb9 follow \u7684 degree \u5c5e\u6027\u3002 nebula> GO FROM 100 OVER follow YIELD follow.degree; -- \u540c\u4e0a\u8ff0\u8bed\u53e5\u3002 nebula> GO FROM 100 OVER follow YIELD follow._src AS s, serve._dst AS d \\ | FETCH PROP ON follow $-.s -> $-.d YIELD follow.degree; -- \u540c\u4e0a\u8ff0\u8bed\u53e5\u3002 nebula> $var = GO FROM 100 OVER follow YIELD follow._src AS s, follow._dst AS d;\\ FETCH PROP ON follow $var.s -> $var.d YIELD follow.degree;","title":"Fetch \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#fetch","text":"FETCH \u8bed\u53e5\u7528\u4e8e\u83b7\u53d6\u70b9\u548c\u8fb9\u7684\u5c5e\u6027\u3002","title":"Fetch \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#_1","text":"FETCH PROP ON \u53ef\u8fd4\u56de\u8282\u70b9\u7684\u4e00\u7cfb\u5217\u5c5e\u6027\uff0c\u76ee\u524d\u5df2\u652f\u6301\u4e00\u6761\u8bed\u53e5\u8fd4\u56de\u591a\u4e2a\u8282\u70b9\u5c5e\u6027\u3002 FETCH PROP ON <tag_name> <vertex_id_list> [YIELD [DISTINCT] <return_list>] FETCH PROP ON * <vertex_id> * \u8fd4\u56de\u6307\u5b9a ID \u70b9\u7684\u6240\u6709\u5c5e\u6027\u3002 <tag_name> \u4e3a\u6807\u7b7e\u540d\u79f0\uff0c\u4e0e return_list \u4e2d\u7684\u6807\u7b7e\u76f8\u540c\u3002 <vertex_id_list>::=[vertex_id [, vertex_id]] \u662f\u4e00\u7ec4\u7528 \",\" \u5206\u9694\u5f00\u7684\u9876\u70b9 ID \u5217\u8868\u3002 [YIELD [DISTINCT] <return_list>] \u4e3a\u8fd4\u56de\u7684\u5c5e\u6027\u5217\u8868\uff0c YIELD \u8bed\u6cd5\u53c2\u770b YIELD Syntax \u3002","title":"\u83b7\u53d6\u70b9\u5c5e\u6027"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#_2","text":"-- \u8fd4\u56de\u8282\u70b9 100 \u7684\u6240\u6709\u5c5e\u6027\u3002 nebula> FETCH PROP ON * 100; -- \u5982\u672a\u6307\u5b9a YIELD \u5b57\u6bb5\uff0c\u5219\u8fd4\u56de\u8282\u70b9 100, tag \u4e3a player \u7684\u6240\u6709\u5c5e\u6027\u3002 nebula> FETCH PROP ON player 100; -- \u8fd4\u56de\u8282\u70b9 100 \u7684\u59d3\u540d\u4e0e\u5e74\u9f84\u5c5e\u6027\u3002 nebula> FETCH PROP ON player 100 YIELD player.name, player.age; -- \u901a\u8fc7 hash \u751f\u6210 int64 \u8282\u70b9 ID\uff0c\u8fd4\u56de\u5176\u59d3\u540d\u548c\u5e74\u9f84\u5c5e\u6027\u3002 nebula> FETCH PROP ON player hash(\"nebula\") YIELD player.name, player.age; -- \u6cbf\u8fb9 follow \u5bfb\u627e\u8282\u70b9 100 \u7684\u6240\u6709\u8fd1\u90bb\uff0c\u8fd4\u56de\u5176\u59d3\u540d\u548c\u5e74\u9f84\u5c5e\u6027\u3002 nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | FETCH PROP ON player $-.id YIELD player.name, player.age; -- \u4e0e\u4e0a\u8ff0\u8bed\u6cd5\u76f8\u540c\u3002 nebula> $var = GO FROM 100 OVER follow YIELD follow._dst AS id; FETCH PROP ON player $var.id YIELD player.name, player.age; -- \u83b7\u53d6 100\u3001101\u3001102 \u4e09\u4e2a\u8282\u70b9\uff0c\u8fd4\u56de\u59d3\u540d\u548c\u5e74\u9f84\u90fd\u4e0d\u76f8\u540c\u7684\u8bb0\u5f55\u3002 nebula> FETCH PROP ON player 100,101,102 YIELD DISTINCT player.name, player.age;","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#_3","text":"\u4f7f\u7528 FETCH \u83b7\u53d6\u8fb9\u5c5e\u6027\u7684\u7528\u6cd5\u4e0e\u70b9\u5c5e\u6027\u5927\u81f4\u76f8\u540c\uff0c\u4e14\u53ef\u540c\u65f6\u83b7\u53d6\u76f8\u540c\u7c7b\u578b\u591a\u6761\u8fb9\u7684\u5c5e\u6027\u3002 FETCH PROP ON <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] [YIELD [DISTINCT] <return_list>] <edge_type> \u6307\u5b9a\u8fb9\u7684\u7c7b\u578b\uff0c\u9700\u4e0e <return_list> \u76f8\u540c\u3002 <vid> -> <vid> \u4ece\u8d77\u59cb\u8282\u70b9\u5230\u7ec8\u6b62\u8282\u70b9\uff0c\u591a\u6761\u8fb9\u9700\u4f7f\u7528\u9017\u53f7\u9694\u5f00\u3002 <ranking> \u6307\u5b9a\u76f8\u540c\u7c7b\u578b\u8fb9 ranking\uff0c\u53ef\u9009\u3002 [YIELD [DISTINCT] <return_list>] \u4e3a\u8fd4\u56de\u7684\u5c5e\u6027\u5217\u8868\u3002","title":"\u83b7\u53d6\u8fb9\u5c5e\u6027"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#_4","text":"-- \u672c\u8bed\u53e5\u672a\u6307\u5b9a YIELD\uff0c\u56e0\u6b64\u83b7\u53d6\u4ece\u8282\u70b9 100 \u5230\u8282\u70b9 200 \u8fb9 serve \u7684\u6240\u6709\u5c5e\u6027\u3002 nebula> FETCH PROP ON serve 100 -> 200; -- \u4ec5\u8fd4\u56de\u5c5e\u6027 start_year\u3002 nebula> FETCH PROP ON serve 100 -> 200 YIELD serve.start_year; -- \u83b7\u53d6\u8282\u70b9 100 \u51fa\u8fb9 follow \u7684 degree \u5c5e\u6027\u3002 nebula> GO FROM 100 OVER follow YIELD follow.degree; -- \u540c\u4e0a\u8ff0\u8bed\u53e5\u3002 nebula> GO FROM 100 OVER follow YIELD follow._src AS s, serve._dst AS d \\ | FETCH PROP ON follow $-.s -> $-.d YIELD follow.degree; -- \u540c\u4e0a\u8ff0\u8bed\u53e5\u3002 nebula> $var = GO FROM 100 OVER follow YIELD follow._src AS s, follow._dst AS d;\\ FETCH PROP ON follow $var.s -> $var.d YIELD follow.degree;","title":"\u83b7\u53d6\u8fb9\u5c5e\u6027\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/","text":"GO \u8bed\u6cd5 \u00b6 GO \u662f Nebula Graph \u4e2d\u6700\u5e38\u7528\u7684\u5173\u952e\u5b57\uff0c\u53ef\u4ee5\u6307\u5b9a\u8fc7\u6ee4\u6761\u4ef6\uff08\u5982 WHERE \uff09\u904d\u5386\u56fe\u6570\u636e\u5e76\u83b7\u53d6\u70b9\u548c\u8fb9\u7684\u5c5e\u6027\uff0c\u8fd8\u80fd\u4ee5\u6307\u5b9a\u987a\u5e8f\uff08 ORDER BY ASC | DESC \uff09\u8fd4\u56de\u6307\u5b9a\u6570\u76ee\uff08 LIMIT \uff09\u7684\u7ed3\u679c\u3002 GO \u7684\u7528\u6cd5\u4e0e SQL \u4e2d\u7684 SELECT \u7c7b\u4f3c\uff0c\u91cd\u8981\u533a\u522b\u662f GO \u5fc5\u987b\u4ece\u904d\u5386\u4e00\u7cfb\u5217\u7684\u8282\u70b9\u5f00\u59cb\u3002 GO [ <N> STEPS ] FROM <node_list> OVER <edge_type_list> [REVERSELY] [BIDIRECT] [ WHERE <expression> [ AND | OR expression ...]) ] YIELD [DISTINCT] <return_list> <node_list> | <vid> [, <vid> ...] | $-.id <edge_type_list> edge_type [, edge_type ...] <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [ \\ STEPS ] \u6307\u5b9a\u67e5\u8be2 N \u8df3\u3002 \u4e3a\u9017\u53f7\u9694\u5f00\u7684\u8282\u70b9 ID\uff0c\u6216\u7279\u6b8a\u5360\u4f4d\u7b26 $-.id (\u53c2\u770b PIPE \u7528\u6cd5)\u3002 \u4e3a\u56fe\u904d\u5386\u8fd4\u56de\u7684\u8fb9\u7c7b\u578b\u5217\u8868\u3002 [ WHERE \\ ] \u6307\u5b9a\u88ab\u7b5b\u9009\u7684\u903b\u8f91\u6761\u4ef6\uff0cWHERE \u53ef\u7528\u4e8e\u8d77\u70b9\uff0c\u8fb9\u53ca\u7ec8\u70b9\uff0c\u540c\u6837\u652f\u6301\u903b\u8f91\u5173\u952e\u8bcd AND\u3001OR\u3001NOT\uff0c\u8be6\u60c5\u53c2\u89c1 WHERE \u7684\u7528\u6cd5\u3002 YIELD [DISTINCT] \u4ee5\u5217\u7684\u5f62\u5f0f\u8fd4\u56de\u7ed3\u679c\uff0c\u5e76\u53ef\u5bf9\u5217\u8fdb\u884c\u91cd\u547d\u540d\u3002\u8be6\u60c5\u53c2\u770b YIELD \u7528\u6cd5\u3002 DISTINCT \u7684\u7528\u6cd5\u4e0e SQL \u76f8\u540c\u3002 \u793a\u4f8b \u00b6 nebula> GO FROM 107 OVER serve; \\ /* \u4ece\u70b9 107 \u51fa\u53d1\uff0c\u6cbf\u8fb9 serve\uff0c\u627e\u5230\u70b9 200\uff0c201 */ ============== | serve._dst | ============== | 200 | -------------- | 201 | -------------- nebula> GO 2 STEPS FROM 103 OVER follow; \\ /* \u8fd4\u56de\u70b9 103 \u7684 2 \u5ea6\u7684\u597d\u53cb */ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 109 OVER serve \\ WHERE serve.start_year > 1990 /* \u7b5b\u9009\u8fb9 serve \u7684 start_year \u5c5e\u6027 */ \\ YIELD $$.team.name AS team_name, serve.start_year as start_year; /* \u76ee\u6807\u70b9 team \u7684 serve.start_year \u5c5e\u6027 serve.start_year */ ========================== | team_name | start_year | ========================== | Nuggets | 2011 | -------------------------- | Rockets | 2017 | -------------------------- nebula> GO FROM 100,102 OVER serve \\ WHERE serve.start_year > 1995 /* \u7b5b\u9009\u8fb9\u5c5e\u6027*/ \\ YIELD DISTINCT $$.team.name AS team_name, /* DISTINCT \u4e0e SQL \u7528\u6cd5\u76f8\u540c */ \\ serve.start_year as start_year, /* \u8fb9\u5c5e\u6027 */ \\ $^.player.name AS player_name; /* \u8d77\u70b9 (player) \u5c5e\u6027 */ ============================================== | team_name | start_year | player_name | ============================================== | Warriors | 2001 | LaMarcus Aldridge | ---------------------------------------------- | Warriors | 1997 | Tim Duncan | ---------------------------------------------- \u6cbf\u7740\u591a\u79cd\u7c7b\u578b\u7684\u8fb9\u8fdb\u884c\u904d\u5386 \u00b6 \u76ee\u524d Nebula Graph \u8fd8\u652f\u6301 GO \u6cbf\u7740\u591a\u6761\u8fb9\u904d\u5386\uff0c\u8bed\u6cd5\u4e3a\uff1a GO FROM <node_list> OVER <edge_type_list | *> YIELD [DISTINCT] <return_list> \u4f8b\u5982\uff1a nebula> GO FROM <node_list> OVER edge1, edge2.... //\u6cbf\u7740 edge1 \u548c edge2 \u904d\u5386\uff0c\u6216\u8005 nebula> GO FROM <node_list> OVER * //\u8fd9\u91cc * \u610f\u5473\u7740\u6cbf\u7740\u4efb\u610f\u7c7b\u578b\u7684\u8fb9\u904d\u5386 \u8bf7\u6ce8\u610f\uff0c\u5f53\u6cbf\u7740\u591a\u79cd\u7c7b\u578b\u8fb9\u904d\u5386\u65f6\uff0c\u5bf9\u4e8e\u4f7f\u7528\u8fc7\u6ee4\u6761\u4ef6\u6709\u7279\u522b\u9650\u5236(\u4e5f\u5373 WHERE \u8bed\u53e5\uff09\uff0c\u6bd4\u5982 WHERE edge1.prop1 > edge2.prop2 \u8fd9\u79cd\u8fc7\u6ee4\u6761\u4ef6\u662f\u4e0d\u652f\u6301\u7684\u3002 \u5bf9\u4e8e\u8fd4\u56de\u7684\u7ed3\u679c\uff0c\u5982\u679c\u5b58\u5728\u591a\u6761\u8fb9\u7684\u5c5e\u6027\u9700\u8981\u8fd4\u56de\uff0c\u4f1a\u628a\u4ed6\u4eec\u653e\u5728\u4e0d\u540c\u7684\u884c\u3002\u6bd4\u5982\uff1a nebula> GO FROM 100 OVER follow, serve YIELD follow.degree, serve.start_year; \u8fd4\u56de\u5982\u4e0b\u7ed3\u679c\uff1a ==================================== | follow.degree | serve.start_year | ==================================== | 0 | 1997 | ------------------------------------ | 95 | 0 | ------------------------------------ | 89 | 0 | ------------------------------------ | 90 | 0 | ------------------------------------ \u6ca1\u6709\u7684\u5c5e\u6027\u5f53\u524d\u4f1a\u586b\u5145\u9ed8\u8ba4\u503c\uff0c \u6570\u503c\u578b\u7684\u9ed8\u8ba4\u503c\u4e3a 0\uff0c \u5b57\u7b26\u578b\u7684\u9ed8\u8ba4\u503c\u4e3a\u7a7a\u5b57\u7b26\u4e32\u3002bool \u7c7b\u578b\u9ed8\u8ba4\u503c\u4e3a false\uff0ctimestamp \u7c7b\u578b\u9ed8\u8ba4\u503c\u4e3a 0 (\u5373 \"1970-01-01 00:00:00\")\uff0cdouble \u7c7b\u578b\u9ed8\u8ba4\u503c\u4e3a 0.0\u3002 \u5f53\u7136\u4e5f\u53ef\u4ee5\u4e0d\u6307\u5b9a YIELD \uff0c \u8fd9\u65f6\u4f1a\u8fd4\u56de\u6bcf\u6761\u8fb9\u76ee\u6807\u70b9\u7684 vid\u3002\u5982\u679c\u76ee\u6807\u70b9\u4e0d\u5b58\u5728\uff0c\u540c\u6837\u7528\u9ed8\u8ba4\u503c(\u6b64\u5904\u4e3a 0)\u586b\u5145\u3002\u6bd4\u5982 GO FROM 100 OVER follow, serve; \uff0c\u8fd4\u56de\u7ed3\u679c\u5982\u4e0b\uff1a ============================ | follow._dst | serve._dst | ============================ | 0 | 200 | ---------------------------- | 101 | 0 | ---------------------------- | 102 | 0 | ---------------------------- | 106 | 0 | ---------------------------- \u5bf9\u4e8e GO FROM 100 OVER * \u8fd9\u6837\u7684\u4f8b\u5b50\u6765\u8bf4\uff0c\u8fd4\u56de\u7ed3\u679c\u4e5f\u548c\u4e0a\u9762\u4f8b\u5b50\u7c7b\u4f3c\uff1a\u4e0d\u5b58\u5728\u7684\u5c5e\u6027\u6216\u8005 vid \u4f7f\u7528\u9ed8\u8ba4\u503c\u6765\u586b\u5145\u3002 \u8bf7\u6ce8\u610f\u4ece\u7ed3\u679c\u4e2d\u65e0\u6cd5\u5206\u8fa8\u6bcf\u4e00\u884c\u5c5e\u4e8e\u54ea\u6761\u8fb9\uff0c\u672a\u6765\u7248\u672c\u4f1a\u5728\u7ed3\u679c\u4e2d\u628a edge type \u8868\u793a\u51fa\u6765\u3002 \u53cd\u5411\u904d\u5386 \u00b6 \u76ee\u524d Nebula Graph \u652f\u6301\u4f7f\u7528\u5173\u952e\u8bcd REVERSELY \u8fdb\u884c\u53cd\u5411\u904d\u5386\uff0c\u8bed\u6cd5\u4e3a\uff1a GO FROM <node_list> OVER <edge_type_list> REVERSELY WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> \u4f8b\u5982\uff1a nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._src; -- \u8fd4\u56de 100 nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve WHERE $^.player.age > 20 YIELD $^.player.name AS FriendOf, $$.team.name AS Team; ============================ | FriendOf | Team | ============================ | Tony Parker | Warriors | ---------------------------- | Kyle Anderson | Warriors | ---------------------------- \u904d\u5386\u6240\u6709\u5173\u6ce8 100 \u53f7\u7403\u5458\u7684\u7403\u5458\uff0c\u627e\u51fa\u8fd9\u4e9b\u7403\u5458\u670d\u5f79\u7684\u7403\u961f\uff0c\u7b5b\u9009\u5e74\u9f84\u5927\u4e8e 20 \u5c81\u7684\u7403\u5458\u5e76\u8fd4\u56de\u8fd9\u4e9b\u7403\u5458\u59d3\u540d\u548c\u5176\u670d\u5f79\u7684\u7403\u961f\u540d\u79f0\u3002\u5982\u679c\u6b64\u5904\u4e0d\u6307\u5b9a YIELD \uff0c\u5219\u9ed8\u8ba4\u8fd4\u56de\u6bcf\u6761\u8fb9\u76ee\u6807\u70b9\u7684 vid \u3002 \u53cc\u5411\u904d\u5386 \u00b6 \u76ee\u524d Nebula Graph \u652f\u6301\u4f7f\u7528\u5173\u952e\u8bcd BIDIRECT \u8fdb\u884c\u53cc\u5411\u904d\u5386\uff0c\u8bed\u6cd5\u4e3a\uff1a GO FROM <node_list> OVER <edge_type_list> BIDIRECT WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> \u4f8b\u5982\uff1a nebula> GO FROM 102 OVER follow BIDIRECT; =============== | follow._dst | =============== | 101 | --------------- | 103 | --------------- | 135 | --------------- \u4e0a\u8ff0\u8bed\u53e5\u540c\u65f6\u8fd4\u56de 102 \u5173\u6ce8\u7684\u7403\u5458\u53ca\u5173\u6ce8 102 \u7684\u7403\u5458\u3002","title":"GO \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#go","text":"GO \u662f Nebula Graph \u4e2d\u6700\u5e38\u7528\u7684\u5173\u952e\u5b57\uff0c\u53ef\u4ee5\u6307\u5b9a\u8fc7\u6ee4\u6761\u4ef6\uff08\u5982 WHERE \uff09\u904d\u5386\u56fe\u6570\u636e\u5e76\u83b7\u53d6\u70b9\u548c\u8fb9\u7684\u5c5e\u6027\uff0c\u8fd8\u80fd\u4ee5\u6307\u5b9a\u987a\u5e8f\uff08 ORDER BY ASC | DESC \uff09\u8fd4\u56de\u6307\u5b9a\u6570\u76ee\uff08 LIMIT \uff09\u7684\u7ed3\u679c\u3002 GO \u7684\u7528\u6cd5\u4e0e SQL \u4e2d\u7684 SELECT \u7c7b\u4f3c\uff0c\u91cd\u8981\u533a\u522b\u662f GO \u5fc5\u987b\u4ece\u904d\u5386\u4e00\u7cfb\u5217\u7684\u8282\u70b9\u5f00\u59cb\u3002 GO [ <N> STEPS ] FROM <node_list> OVER <edge_type_list> [REVERSELY] [BIDIRECT] [ WHERE <expression> [ AND | OR expression ...]) ] YIELD [DISTINCT] <return_list> <node_list> | <vid> [, <vid> ...] | $-.id <edge_type_list> edge_type [, edge_type ...] <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [ \\ STEPS ] \u6307\u5b9a\u67e5\u8be2 N \u8df3\u3002 \u4e3a\u9017\u53f7\u9694\u5f00\u7684\u8282\u70b9 ID\uff0c\u6216\u7279\u6b8a\u5360\u4f4d\u7b26 $-.id (\u53c2\u770b PIPE \u7528\u6cd5)\u3002 \u4e3a\u56fe\u904d\u5386\u8fd4\u56de\u7684\u8fb9\u7c7b\u578b\u5217\u8868\u3002 [ WHERE \\ ] \u6307\u5b9a\u88ab\u7b5b\u9009\u7684\u903b\u8f91\u6761\u4ef6\uff0cWHERE \u53ef\u7528\u4e8e\u8d77\u70b9\uff0c\u8fb9\u53ca\u7ec8\u70b9\uff0c\u540c\u6837\u652f\u6301\u903b\u8f91\u5173\u952e\u8bcd AND\u3001OR\u3001NOT\uff0c\u8be6\u60c5\u53c2\u89c1 WHERE \u7684\u7528\u6cd5\u3002 YIELD [DISTINCT] \u4ee5\u5217\u7684\u5f62\u5f0f\u8fd4\u56de\u7ed3\u679c\uff0c\u5e76\u53ef\u5bf9\u5217\u8fdb\u884c\u91cd\u547d\u540d\u3002\u8be6\u60c5\u53c2\u770b YIELD \u7528\u6cd5\u3002 DISTINCT \u7684\u7528\u6cd5\u4e0e SQL \u76f8\u540c\u3002","title":"GO \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#_1","text":"nebula> GO FROM 107 OVER serve; \\ /* \u4ece\u70b9 107 \u51fa\u53d1\uff0c\u6cbf\u8fb9 serve\uff0c\u627e\u5230\u70b9 200\uff0c201 */ ============== | serve._dst | ============== | 200 | -------------- | 201 | -------------- nebula> GO 2 STEPS FROM 103 OVER follow; \\ /* \u8fd4\u56de\u70b9 103 \u7684 2 \u5ea6\u7684\u597d\u53cb */ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 109 OVER serve \\ WHERE serve.start_year > 1990 /* \u7b5b\u9009\u8fb9 serve \u7684 start_year \u5c5e\u6027 */ \\ YIELD $$.team.name AS team_name, serve.start_year as start_year; /* \u76ee\u6807\u70b9 team \u7684 serve.start_year \u5c5e\u6027 serve.start_year */ ========================== | team_name | start_year | ========================== | Nuggets | 2011 | -------------------------- | Rockets | 2017 | -------------------------- nebula> GO FROM 100,102 OVER serve \\ WHERE serve.start_year > 1995 /* \u7b5b\u9009\u8fb9\u5c5e\u6027*/ \\ YIELD DISTINCT $$.team.name AS team_name, /* DISTINCT \u4e0e SQL \u7528\u6cd5\u76f8\u540c */ \\ serve.start_year as start_year, /* \u8fb9\u5c5e\u6027 */ \\ $^.player.name AS player_name; /* \u8d77\u70b9 (player) \u5c5e\u6027 */ ============================================== | team_name | start_year | player_name | ============================================== | Warriors | 2001 | LaMarcus Aldridge | ---------------------------------------------- | Warriors | 1997 | Tim Duncan | ----------------------------------------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#_2","text":"\u76ee\u524d Nebula Graph \u8fd8\u652f\u6301 GO \u6cbf\u7740\u591a\u6761\u8fb9\u904d\u5386\uff0c\u8bed\u6cd5\u4e3a\uff1a GO FROM <node_list> OVER <edge_type_list | *> YIELD [DISTINCT] <return_list> \u4f8b\u5982\uff1a nebula> GO FROM <node_list> OVER edge1, edge2.... //\u6cbf\u7740 edge1 \u548c edge2 \u904d\u5386\uff0c\u6216\u8005 nebula> GO FROM <node_list> OVER * //\u8fd9\u91cc * \u610f\u5473\u7740\u6cbf\u7740\u4efb\u610f\u7c7b\u578b\u7684\u8fb9\u904d\u5386 \u8bf7\u6ce8\u610f\uff0c\u5f53\u6cbf\u7740\u591a\u79cd\u7c7b\u578b\u8fb9\u904d\u5386\u65f6\uff0c\u5bf9\u4e8e\u4f7f\u7528\u8fc7\u6ee4\u6761\u4ef6\u6709\u7279\u522b\u9650\u5236(\u4e5f\u5373 WHERE \u8bed\u53e5\uff09\uff0c\u6bd4\u5982 WHERE edge1.prop1 > edge2.prop2 \u8fd9\u79cd\u8fc7\u6ee4\u6761\u4ef6\u662f\u4e0d\u652f\u6301\u7684\u3002 \u5bf9\u4e8e\u8fd4\u56de\u7684\u7ed3\u679c\uff0c\u5982\u679c\u5b58\u5728\u591a\u6761\u8fb9\u7684\u5c5e\u6027\u9700\u8981\u8fd4\u56de\uff0c\u4f1a\u628a\u4ed6\u4eec\u653e\u5728\u4e0d\u540c\u7684\u884c\u3002\u6bd4\u5982\uff1a nebula> GO FROM 100 OVER follow, serve YIELD follow.degree, serve.start_year; \u8fd4\u56de\u5982\u4e0b\u7ed3\u679c\uff1a ==================================== | follow.degree | serve.start_year | ==================================== | 0 | 1997 | ------------------------------------ | 95 | 0 | ------------------------------------ | 89 | 0 | ------------------------------------ | 90 | 0 | ------------------------------------ \u6ca1\u6709\u7684\u5c5e\u6027\u5f53\u524d\u4f1a\u586b\u5145\u9ed8\u8ba4\u503c\uff0c \u6570\u503c\u578b\u7684\u9ed8\u8ba4\u503c\u4e3a 0\uff0c \u5b57\u7b26\u578b\u7684\u9ed8\u8ba4\u503c\u4e3a\u7a7a\u5b57\u7b26\u4e32\u3002bool \u7c7b\u578b\u9ed8\u8ba4\u503c\u4e3a false\uff0ctimestamp \u7c7b\u578b\u9ed8\u8ba4\u503c\u4e3a 0 (\u5373 \"1970-01-01 00:00:00\")\uff0cdouble \u7c7b\u578b\u9ed8\u8ba4\u503c\u4e3a 0.0\u3002 \u5f53\u7136\u4e5f\u53ef\u4ee5\u4e0d\u6307\u5b9a YIELD \uff0c \u8fd9\u65f6\u4f1a\u8fd4\u56de\u6bcf\u6761\u8fb9\u76ee\u6807\u70b9\u7684 vid\u3002\u5982\u679c\u76ee\u6807\u70b9\u4e0d\u5b58\u5728\uff0c\u540c\u6837\u7528\u9ed8\u8ba4\u503c(\u6b64\u5904\u4e3a 0)\u586b\u5145\u3002\u6bd4\u5982 GO FROM 100 OVER follow, serve; \uff0c\u8fd4\u56de\u7ed3\u679c\u5982\u4e0b\uff1a ============================ | follow._dst | serve._dst | ============================ | 0 | 200 | ---------------------------- | 101 | 0 | ---------------------------- | 102 | 0 | ---------------------------- | 106 | 0 | ---------------------------- \u5bf9\u4e8e GO FROM 100 OVER * \u8fd9\u6837\u7684\u4f8b\u5b50\u6765\u8bf4\uff0c\u8fd4\u56de\u7ed3\u679c\u4e5f\u548c\u4e0a\u9762\u4f8b\u5b50\u7c7b\u4f3c\uff1a\u4e0d\u5b58\u5728\u7684\u5c5e\u6027\u6216\u8005 vid \u4f7f\u7528\u9ed8\u8ba4\u503c\u6765\u586b\u5145\u3002 \u8bf7\u6ce8\u610f\u4ece\u7ed3\u679c\u4e2d\u65e0\u6cd5\u5206\u8fa8\u6bcf\u4e00\u884c\u5c5e\u4e8e\u54ea\u6761\u8fb9\uff0c\u672a\u6765\u7248\u672c\u4f1a\u5728\u7ed3\u679c\u4e2d\u628a edge type \u8868\u793a\u51fa\u6765\u3002","title":"\u6cbf\u7740\u591a\u79cd\u7c7b\u578b\u7684\u8fb9\u8fdb\u884c\u904d\u5386"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#_3","text":"\u76ee\u524d Nebula Graph \u652f\u6301\u4f7f\u7528\u5173\u952e\u8bcd REVERSELY \u8fdb\u884c\u53cd\u5411\u904d\u5386\uff0c\u8bed\u6cd5\u4e3a\uff1a GO FROM <node_list> OVER <edge_type_list> REVERSELY WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> \u4f8b\u5982\uff1a nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._src; -- \u8fd4\u56de 100 nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve WHERE $^.player.age > 20 YIELD $^.player.name AS FriendOf, $$.team.name AS Team; ============================ | FriendOf | Team | ============================ | Tony Parker | Warriors | ---------------------------- | Kyle Anderson | Warriors | ---------------------------- \u904d\u5386\u6240\u6709\u5173\u6ce8 100 \u53f7\u7403\u5458\u7684\u7403\u5458\uff0c\u627e\u51fa\u8fd9\u4e9b\u7403\u5458\u670d\u5f79\u7684\u7403\u961f\uff0c\u7b5b\u9009\u5e74\u9f84\u5927\u4e8e 20 \u5c81\u7684\u7403\u5458\u5e76\u8fd4\u56de\u8fd9\u4e9b\u7403\u5458\u59d3\u540d\u548c\u5176\u670d\u5f79\u7684\u7403\u961f\u540d\u79f0\u3002\u5982\u679c\u6b64\u5904\u4e0d\u6307\u5b9a YIELD \uff0c\u5219\u9ed8\u8ba4\u8fd4\u56de\u6bcf\u6761\u8fb9\u76ee\u6807\u70b9\u7684 vid \u3002","title":"\u53cd\u5411\u904d\u5386"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#_4","text":"\u76ee\u524d Nebula Graph \u652f\u6301\u4f7f\u7528\u5173\u952e\u8bcd BIDIRECT \u8fdb\u884c\u53cc\u5411\u904d\u5386\uff0c\u8bed\u6cd5\u4e3a\uff1a GO FROM <node_list> OVER <edge_type_list> BIDIRECT WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> \u4f8b\u5982\uff1a nebula> GO FROM 102 OVER follow BIDIRECT; =============== | follow._dst | =============== | 101 | --------------- | 103 | --------------- | 135 | --------------- \u4e0a\u8ff0\u8bed\u53e5\u540c\u65f6\u8fd4\u56de 102 \u5173\u6ce8\u7684\u7403\u5458\u53ca\u5173\u6ce8 102 \u7684\u7403\u5458\u3002","title":"\u53cc\u5411\u904d\u5386"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-edge-syntax/","text":"INSERT EDGE \u8bed\u6cd5 \u00b6 INSERT EDGE <edge_name> ( <prop_name_list> ) VALUES | VALUE <src_vid> -> <dst_vid>[@<ranking>] : ( <prop_value_list> ) [, <src_vid> -> <dst_vid> : ( <prop_value_list> ), ...] <prop_name_list>: [ <prop_name> [, <prop_name> ] ...] <prop_value_list>: [ <prop_value> [, <prop_value> ] ...] INSERT EDGE \u7528\u4e8e\u63d2\u5165\u4ece\u8d77\u70b9\uff08 src_vid \uff09\u5230\u7ec8\u70b9\uff08 dst_vid \uff09\u7684\u4e00\u6761\u8fb9\u3002 <edge_name> \u8868\u793a\u8fb9\u7c7b\u578b\uff0c\u5728\u8fdb\u884c INSERT EDGE \u64cd\u4f5c\u524d\u9700\u521b\u5efa\u597d\u3002 <prop_name_list> \u4e3a\u6307\u5b9a\u8fb9\u7684\u5c5e\u6027\u5217\u8868\u3002 <prop_value_list> \u987b\u6839\u636e \u5217\u51fa\u5c5e\u6027\uff0c\u5982\u65e0\u5339\u914d\u7c7b\u578b\uff0c\u5219\u8fd4\u56de\u9519\u8bef\u3002 ranking \u6307\u5b9a\u8fb9 ranking\uff0c\u53ef\u5728\u63d2\u5165\u540c\u4e00\u7c7b\u578b\u7684\u591a\u6761\u8fb9\u65f6\u4f7f\u7528\uff0c\u53ef\u9009\uff0c\u4e0d\u6307\u5b9a\u65f6\u9ed8\u8ba4\u4e3a 0\u3002 \u793a\u4f8b \u00b6 nebula> CREATE EDGE e1(); -- \u521b\u5efa\u7a7a\u5c5e\u6027\u8fb9 t1 nebula> INSERT EDGE e1 () VALUES 10->11:(); -- \u63d2\u5165\u4e00\u6761\u4ece\u70b9 10 \u5230\u70b9 11 \u7684\u7a7a\u5c5e\u6027\u8fb9 nebula> INSERT EDGE e1 () VALUES 10->11@1:(); -- \u63d2\u5165\u4e00\u6761\u4ece\u70b9 10 \u5230\u70b9 11 \u7684\u7a7a\u5c5e\u6027\u8fb9\uff0cranking \u503c\u4e3a 1 nebula> CREATE EDGE e2 (name string, age int); -- \u521b\u5efa\u6709\u4e24\u79cd\u5c5e\u6027\u7684\u8fb9 e2 nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 1); -- \u63d2\u5165\u4e00\u6761\u4ece\u70b9 11 \u5230\u70b9 13 \u7684\u6709\u4e24\u6761\u5c5e\u6027\u7684\u8fb9 nebula> INSERT EDGE e2 (name, age) VALUES \\ 12->13:(\"n1\", 1), 13->14:(\"n2\", 2); -- \u63d2\u5165\u4e24\u6761\u8fb9 nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", \"a13\"); -- \u9519\u8bef\u64cd\u4f5c\uff0c\"a13\" \u4e0d\u662f int \u7c7b\u578b \u540c\u4e00\u6761\u8fb9\u53ef\u88ab\u591a\u6b21\u63d2\u5165\u6216\u5199\u5165\uff0c\u8bfb\u53d6\u65f6\u4ee5\u6700\u540e\u4e00\u6b21\u63d2\u5165\u4e3a\u51c6\u3002 -- \u4e3a\u63d2\u5165\u8fb9\u8d4b\u65b0\u503c insert edge with new version of values. nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 12); nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 13); nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 14); -- \u8bfb\u53d6\u6700\u540e\u63d2\u5165\u7684\u503c","title":"INSERT EDGE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-edge-syntax/#insert_edge","text":"INSERT EDGE <edge_name> ( <prop_name_list> ) VALUES | VALUE <src_vid> -> <dst_vid>[@<ranking>] : ( <prop_value_list> ) [, <src_vid> -> <dst_vid> : ( <prop_value_list> ), ...] <prop_name_list>: [ <prop_name> [, <prop_name> ] ...] <prop_value_list>: [ <prop_value> [, <prop_value> ] ...] INSERT EDGE \u7528\u4e8e\u63d2\u5165\u4ece\u8d77\u70b9\uff08 src_vid \uff09\u5230\u7ec8\u70b9\uff08 dst_vid \uff09\u7684\u4e00\u6761\u8fb9\u3002 <edge_name> \u8868\u793a\u8fb9\u7c7b\u578b\uff0c\u5728\u8fdb\u884c INSERT EDGE \u64cd\u4f5c\u524d\u9700\u521b\u5efa\u597d\u3002 <prop_name_list> \u4e3a\u6307\u5b9a\u8fb9\u7684\u5c5e\u6027\u5217\u8868\u3002 <prop_value_list> \u987b\u6839\u636e \u5217\u51fa\u5c5e\u6027\uff0c\u5982\u65e0\u5339\u914d\u7c7b\u578b\uff0c\u5219\u8fd4\u56de\u9519\u8bef\u3002 ranking \u6307\u5b9a\u8fb9 ranking\uff0c\u53ef\u5728\u63d2\u5165\u540c\u4e00\u7c7b\u578b\u7684\u591a\u6761\u8fb9\u65f6\u4f7f\u7528\uff0c\u53ef\u9009\uff0c\u4e0d\u6307\u5b9a\u65f6\u9ed8\u8ba4\u4e3a 0\u3002","title":"INSERT EDGE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-edge-syntax/#_1","text":"nebula> CREATE EDGE e1(); -- \u521b\u5efa\u7a7a\u5c5e\u6027\u8fb9 t1 nebula> INSERT EDGE e1 () VALUES 10->11:(); -- \u63d2\u5165\u4e00\u6761\u4ece\u70b9 10 \u5230\u70b9 11 \u7684\u7a7a\u5c5e\u6027\u8fb9 nebula> INSERT EDGE e1 () VALUES 10->11@1:(); -- \u63d2\u5165\u4e00\u6761\u4ece\u70b9 10 \u5230\u70b9 11 \u7684\u7a7a\u5c5e\u6027\u8fb9\uff0cranking \u503c\u4e3a 1 nebula> CREATE EDGE e2 (name string, age int); -- \u521b\u5efa\u6709\u4e24\u79cd\u5c5e\u6027\u7684\u8fb9 e2 nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 1); -- \u63d2\u5165\u4e00\u6761\u4ece\u70b9 11 \u5230\u70b9 13 \u7684\u6709\u4e24\u6761\u5c5e\u6027\u7684\u8fb9 nebula> INSERT EDGE e2 (name, age) VALUES \\ 12->13:(\"n1\", 1), 13->14:(\"n2\", 2); -- \u63d2\u5165\u4e24\u6761\u8fb9 nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", \"a13\"); -- \u9519\u8bef\u64cd\u4f5c\uff0c\"a13\" \u4e0d\u662f int \u7c7b\u578b \u540c\u4e00\u6761\u8fb9\u53ef\u88ab\u591a\u6b21\u63d2\u5165\u6216\u5199\u5165\uff0c\u8bfb\u53d6\u65f6\u4ee5\u6700\u540e\u4e00\u6b21\u63d2\u5165\u4e3a\u51c6\u3002 -- \u4e3a\u63d2\u5165\u8fb9\u8d4b\u65b0\u503c insert edge with new version of values. nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 12); nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 13); nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 14); -- \u8bfb\u53d6\u6700\u540e\u63d2\u5165\u7684\u503c","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-vertex-syntax/","text":"INSERT VERTEX \u8bed\u6cd5 \u00b6 INSERT VERTEX <tag_name> [, <tag_name>, ...] (prop_name_list[, prop_name_list]) {VALUES | VALUE} vid: (prop_value_list[, prop_value_list]) prop_name_list: [prop_name [, prop_name] ...] prop_value_list: [prop_value [, prop_value] ...] INSERT VERTEX \u53ef\u5411 Nebula Graph \u63d2\u5165\u8282\u70b9\u3002 tag_name \u8868\u793a\u6807\u7b7e\uff08\u8282\u70b9\u7c7b\u578b\uff09\uff0c\u5728\u8fdb\u884c INSERT VERTEX \u64cd\u4f5c\u524d\u9700\u521b\u5efa\u597d\u3002 prop_name_list \u6307\u5b9a\u6807\u7b7e\u7684\u5c5e\u6027\u5217\u8868\u3002 prop_value_list \u987b\u6839\u636e \u5217\u51fa\u5c5e\u6027\uff0c\u5982\u65e0\u5339\u914d\u7c7b\u578b\uff0c\u5219\u8fd4\u56de\u9519\u8bef\u3002 \u793a\u4f8b \u00b6 nebula> CREATE TAG t1(); -- \u521b\u5efa\u7a7a\u5c5e\u6027\u6807\u7b7e t1 nebula> INSERT VERTEX t1 () VALUES 10:(); -- \u63d2\u5165\u7a7a\u5c5e\u6027\u70b9 10 nebula> CREATE TAG t2 (name string, age int); -- \u521b\u5efa\u6709\u4e24\u79cd\u5c5e\u6027\u7684\u6807\u7b7e t2 nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n1\", 12); -- \u63d2\u5165\u6709\u4e24\u79cd\u5c5e\u6027\u7684\u70b9 11 nebula> INSERT VERTEX t2 (name, age) VALUES 12:(\"n1\", \"a13\"); -- \u9519\u8bef\u64cd\u4f5c\uff0c\"a13\" \u4e0d\u662f int \u7c7b\u578b nebula> INSERT VERTEX t2 (name, age) VALUES 13:(\"n3\", 12), 14:(\"n4\", 8); -- \u63d2\u5165\u4e24\u4e2a\u70b9 nebula> CREATE TAG t1(i1 int); nebula> CREATE TAG t2(s2 string); nebula> INSERT VERTEX t1 (i1), t2(s2) VALUES 21: (321, \"hello\"); -- \u63d2\u5165\u6709\u4e24\u4e2a\u6807\u7b7e\u7684\u70b9 21 \u540c\u4e00\u8282\u70b9\u53ef\u88ab\u591a\u6b21\u63d2\u5165\u6216\u5199\u5165\uff0c\u8bfb\u53d6\u65f6\u4ee5\u6700\u540e\u4e00\u6b21\u63d2\u5165\u4e3a\u51c6\u3002 -- \u4e3a\u70b9 11 \u591a\u6b21\u63d2\u5165\u65b0\u503c nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n2\", 13); nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n3\", 14); nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n4\", 15); -- \u8bfb\u53d6\u6700\u540e\u63d2\u5165\u7684\u503c","title":"INSERT VERTEX \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-vertex-syntax/#insert_vertex","text":"INSERT VERTEX <tag_name> [, <tag_name>, ...] (prop_name_list[, prop_name_list]) {VALUES | VALUE} vid: (prop_value_list[, prop_value_list]) prop_name_list: [prop_name [, prop_name] ...] prop_value_list: [prop_value [, prop_value] ...] INSERT VERTEX \u53ef\u5411 Nebula Graph \u63d2\u5165\u8282\u70b9\u3002 tag_name \u8868\u793a\u6807\u7b7e\uff08\u8282\u70b9\u7c7b\u578b\uff09\uff0c\u5728\u8fdb\u884c INSERT VERTEX \u64cd\u4f5c\u524d\u9700\u521b\u5efa\u597d\u3002 prop_name_list \u6307\u5b9a\u6807\u7b7e\u7684\u5c5e\u6027\u5217\u8868\u3002 prop_value_list \u987b\u6839\u636e \u5217\u51fa\u5c5e\u6027\uff0c\u5982\u65e0\u5339\u914d\u7c7b\u578b\uff0c\u5219\u8fd4\u56de\u9519\u8bef\u3002","title":"INSERT VERTEX \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-vertex-syntax/#_1","text":"nebula> CREATE TAG t1(); -- \u521b\u5efa\u7a7a\u5c5e\u6027\u6807\u7b7e t1 nebula> INSERT VERTEX t1 () VALUES 10:(); -- \u63d2\u5165\u7a7a\u5c5e\u6027\u70b9 10 nebula> CREATE TAG t2 (name string, age int); -- \u521b\u5efa\u6709\u4e24\u79cd\u5c5e\u6027\u7684\u6807\u7b7e t2 nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n1\", 12); -- \u63d2\u5165\u6709\u4e24\u79cd\u5c5e\u6027\u7684\u70b9 11 nebula> INSERT VERTEX t2 (name, age) VALUES 12:(\"n1\", \"a13\"); -- \u9519\u8bef\u64cd\u4f5c\uff0c\"a13\" \u4e0d\u662f int \u7c7b\u578b nebula> INSERT VERTEX t2 (name, age) VALUES 13:(\"n3\", 12), 14:(\"n4\", 8); -- \u63d2\u5165\u4e24\u4e2a\u70b9 nebula> CREATE TAG t1(i1 int); nebula> CREATE TAG t2(s2 string); nebula> INSERT VERTEX t1 (i1), t2(s2) VALUES 21: (321, \"hello\"); -- \u63d2\u5165\u6709\u4e24\u4e2a\u6807\u7b7e\u7684\u70b9 21 \u540c\u4e00\u8282\u70b9\u53ef\u88ab\u591a\u6b21\u63d2\u5165\u6216\u5199\u5165\uff0c\u8bfb\u53d6\u65f6\u4ee5\u6700\u540e\u4e00\u6b21\u63d2\u5165\u4e3a\u51c6\u3002 -- \u4e3a\u70b9 11 \u591a\u6b21\u63d2\u5165\u65b0\u503c nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n2\", 13); nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n3\", 14); nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n4\", 15); -- \u8bfb\u53d6\u6700\u540e\u63d2\u5165\u7684\u503c","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/","text":"LOOKUP \u8bed\u6cd5 \u00b6 LOOKUP \u8bed\u53e5\u6307\u5b9a\u8fc7\u6ee4\u6761\u4ef6\u5bf9\u6570\u636e\u8fdb\u884c\u67e5\u8be2\u3002 LOOKUP \u8bed\u53e5\u4e4b\u540e\u901a\u5e38\u8ddf\u7740 WHERE \u5b50\u53e5\u3002 WHERE \u5b50\u53e5\u7528\u4e8e\u5411\u6761\u4ef6\u4e2d\u6dfb\u52a0\u8fc7\u6ee4\u6027\u7684\u8c13\u8bcd\uff0c\u4ece\u800c\u5bf9\u6570\u636e\u8fdb\u884c\u8fc7\u6ee4\u3002 \u6ce8\u610f\uff1a \u5728\u4f7f\u7528 LOOKUP \u8bed\u53e5\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u5df2\u521b\u5efa\u7d22\u5f15\u3002\u67e5\u770b \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u6709\u5173\u7d22\u5f15\u7684\u66f4\u591a\u4fe1\u606f\u3002 LOOKUP ON {<vertex_tag> | <edge_type>} WHERE <expression> [ AND | OR expression ...]) ] [YIELD <return_list>] <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] LOOKUP \u8bed\u53e5\u7528\u4e8e\u5bfb\u627e\u70b9\u6216\u8fb9\u7684\u96c6\u5408\u3002 WHERE \u6307\u5b9a\u88ab\u7b5b\u9009\u7684\u903b\u8f91\u6761\u4ef6\u3002\u540c\u6837\u652f\u6301\u903b\u8f91\u5173\u952e\u8bcd AND\u3001OR\u3001NOT\uff0c\u8be6\u60c5\u53c2\u89c1 WHERE \u7684\u7528\u6cd5\u3002 \u6ce8\u610f\uff1a WHERE \u5b50\u53e5\u5728 LOOKUP \u4e2d\u6682\u4e0d\u652f\u6301\u5982\u4e0b\u64cd\u4f5c\uff1a $- \u548c $^ \u5728\u5173\u7cfb\u8868\u8fbe\u5f0f\u4e2d\uff0c\u6682\u4e0d\u652f\u6301\u64cd\u4f5c\u7b26\u4e24\u8fb9\u90fd\u662ffield-name \u7684\u8868\u8fbe\u5f0f\uff0c\u5982 (tagName.column1 > tagName.column2) \u6682\u4e0d\u652f\u6301\u8fd0\u7b97\u8868\u8fbe\u5f0f\u548c function \u8868\u8fbe\u5f0f\u4e2d\u5d4c\u5957 AliasProp \u8868\u8fbe\u5f0f\u3002 YIELD \u6307\u5b9a\u8fd4\u56de\u7ed3\u679c\u3002\u5982\u672a\u6307\u5b9a\uff0c\u5219\u5728 LOOKUP \u6807\u7b7e\u65f6\u8fd4\u56de\u70b9 ID\uff0c\u5728 LOOKUP \u8fb9\u7c7b\u578b\u65f6\u8fd4\u56de\u8fb9\u7684\u8d77\u70b9 ID\u3001\u7ec8\u70b9 ID \u548c ranking \u503c\u3002 \u70b9\u67e5\u8be2 \u00b6 \u5982\u4e0b\u793a\u4f8b\u8fd4\u56de\u540d\u79f0\u4e3a Tony Parker \uff0c\u6807\u7b7e\u4e3a player \u7684\u9876\u70b9\u3002 nebula> CREATE TAG INDEX index_player ON player(name, age); nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\"; ============ | VertexID | ============ | 101 | ------------ nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\" \\ YIELD player.name, player.age; ======================================= | VertexID | player.name | player.age | ======================================= | 101 | Tony Parker | 36 | --------------------------------------- nebula> LOOKUP ON player WHERE player.name== \"Kobe Bryant\" YIELD player.name AS name | \\ GO FROM $-.VertexID OVER serve YIELD $-.name, serve.start_year, serve.end_year, $$.team.name; ================================================================== | $-.name | serve.start_year | serve.end_year | $$.team.name | ================================================================== | Kobe Bryant | 1996 | 2016 | Lakers | ------------------------------------------------------------------ \u8fb9\u67e5\u8be2 \u00b6 \u5982\u4e0b\u793a\u4f8b\u8fd4\u56de degree \u4e3a 90\uff0c\u8fb9\u7c7b\u578b\u4e3a follow \u7684\u8fb9\u3002 nebula> CREATE EDGE INDEX index_follow ON follow(degree); nebula> LOOKUP ON follow WHERE follow.degree == 90; ============================= | SrcVID | DstVID | Ranking | ============================= | 100 | 106 | 0 | ----------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 90 YIELD follow.degree; ============================================= | SrcVID | DstVID | Ranking | follow.degree | ============================================= | 100 | 106 | 0 | 90 | --------------------------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 60 YIELD follow.degree AS Degree | \\ GO FROM $-.DstVID OVER serve YIELD $-.DstVID, serve.start_year, serve.end_year, $$.team.name; ================================================================ | $-.DstVID | serve.start_year | serve.end_year | $$.team.name | ================================================================ | 105 | 2010 | 2018 | Spurs | ---------------------------------------------------------------- | 105 | 2009 | 2010 | Cavaliers | ---------------------------------------------------------------- | 105 | 2018 | 2019 | Raptors | ----------------------------------------------------------------","title":"LOOKUP \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/#lookup","text":"LOOKUP \u8bed\u53e5\u6307\u5b9a\u8fc7\u6ee4\u6761\u4ef6\u5bf9\u6570\u636e\u8fdb\u884c\u67e5\u8be2\u3002 LOOKUP \u8bed\u53e5\u4e4b\u540e\u901a\u5e38\u8ddf\u7740 WHERE \u5b50\u53e5\u3002 WHERE \u5b50\u53e5\u7528\u4e8e\u5411\u6761\u4ef6\u4e2d\u6dfb\u52a0\u8fc7\u6ee4\u6027\u7684\u8c13\u8bcd\uff0c\u4ece\u800c\u5bf9\u6570\u636e\u8fdb\u884c\u8fc7\u6ee4\u3002 \u6ce8\u610f\uff1a \u5728\u4f7f\u7528 LOOKUP \u8bed\u53e5\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u5df2\u521b\u5efa\u7d22\u5f15\u3002\u67e5\u770b \u7d22\u5f15\u6587\u6863 \u4e86\u89e3\u6709\u5173\u7d22\u5f15\u7684\u66f4\u591a\u4fe1\u606f\u3002 LOOKUP ON {<vertex_tag> | <edge_type>} WHERE <expression> [ AND | OR expression ...]) ] [YIELD <return_list>] <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] LOOKUP \u8bed\u53e5\u7528\u4e8e\u5bfb\u627e\u70b9\u6216\u8fb9\u7684\u96c6\u5408\u3002 WHERE \u6307\u5b9a\u88ab\u7b5b\u9009\u7684\u903b\u8f91\u6761\u4ef6\u3002\u540c\u6837\u652f\u6301\u903b\u8f91\u5173\u952e\u8bcd AND\u3001OR\u3001NOT\uff0c\u8be6\u60c5\u53c2\u89c1 WHERE \u7684\u7528\u6cd5\u3002 \u6ce8\u610f\uff1a WHERE \u5b50\u53e5\u5728 LOOKUP \u4e2d\u6682\u4e0d\u652f\u6301\u5982\u4e0b\u64cd\u4f5c\uff1a $- \u548c $^ \u5728\u5173\u7cfb\u8868\u8fbe\u5f0f\u4e2d\uff0c\u6682\u4e0d\u652f\u6301\u64cd\u4f5c\u7b26\u4e24\u8fb9\u90fd\u662ffield-name \u7684\u8868\u8fbe\u5f0f\uff0c\u5982 (tagName.column1 > tagName.column2) \u6682\u4e0d\u652f\u6301\u8fd0\u7b97\u8868\u8fbe\u5f0f\u548c function \u8868\u8fbe\u5f0f\u4e2d\u5d4c\u5957 AliasProp \u8868\u8fbe\u5f0f\u3002 YIELD \u6307\u5b9a\u8fd4\u56de\u7ed3\u679c\u3002\u5982\u672a\u6307\u5b9a\uff0c\u5219\u5728 LOOKUP \u6807\u7b7e\u65f6\u8fd4\u56de\u70b9 ID\uff0c\u5728 LOOKUP \u8fb9\u7c7b\u578b\u65f6\u8fd4\u56de\u8fb9\u7684\u8d77\u70b9 ID\u3001\u7ec8\u70b9 ID \u548c ranking \u503c\u3002","title":"LOOKUP \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/#_1","text":"\u5982\u4e0b\u793a\u4f8b\u8fd4\u56de\u540d\u79f0\u4e3a Tony Parker \uff0c\u6807\u7b7e\u4e3a player \u7684\u9876\u70b9\u3002 nebula> CREATE TAG INDEX index_player ON player(name, age); nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\"; ============ | VertexID | ============ | 101 | ------------ nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\" \\ YIELD player.name, player.age; ======================================= | VertexID | player.name | player.age | ======================================= | 101 | Tony Parker | 36 | --------------------------------------- nebula> LOOKUP ON player WHERE player.name== \"Kobe Bryant\" YIELD player.name AS name | \\ GO FROM $-.VertexID OVER serve YIELD $-.name, serve.start_year, serve.end_year, $$.team.name; ================================================================== | $-.name | serve.start_year | serve.end_year | $$.team.name | ================================================================== | Kobe Bryant | 1996 | 2016 | Lakers | ------------------------------------------------------------------","title":"\u70b9\u67e5\u8be2"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/#_2","text":"\u5982\u4e0b\u793a\u4f8b\u8fd4\u56de degree \u4e3a 90\uff0c\u8fb9\u7c7b\u578b\u4e3a follow \u7684\u8fb9\u3002 nebula> CREATE EDGE INDEX index_follow ON follow(degree); nebula> LOOKUP ON follow WHERE follow.degree == 90; ============================= | SrcVID | DstVID | Ranking | ============================= | 100 | 106 | 0 | ----------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 90 YIELD follow.degree; ============================================= | SrcVID | DstVID | Ranking | follow.degree | ============================================= | 100 | 106 | 0 | 90 | --------------------------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 60 YIELD follow.degree AS Degree | \\ GO FROM $-.DstVID OVER serve YIELD $-.DstVID, serve.start_year, serve.end_year, $$.team.name; ================================================================ | $-.DstVID | serve.start_year | serve.end_year | $$.team.name | ================================================================ | 105 | 2010 | 2018 | Spurs | ---------------------------------------------------------------- | 105 | 2009 | 2010 | Cavaliers | ---------------------------------------------------------------- | 105 | 2018 | 2019 | Raptors | ----------------------------------------------------------------","title":"\u8fb9\u67e5\u8be2"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/return-syntax/","text":"Return \u8bed\u6cd5 \u00b6 Return \u8bed\u53e5\u7528\u4e8e\u8fd4\u56de\u6761\u4ef6\u6210\u7acb\u65f6\u7684\u7ed3\u679c\u3002\u5982\u679c\u6761\u4ef6\u4e0d\u6210\u7acb\uff0c\u5219\u65e0\u8fd4\u56de\u7ed3\u679c\u3002 RETURN <var_ref> IF <var_ref> IS NOT NULL \u4e3a\u53d8\u91cf\u540d\u79f0\uff0c\u793a\u4f8b\uff1a$var \u793a\u4f8b \u00b6 nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 101; \\ RETURN $rA IF $rA is NOT NULL; \\ /* $rA \u4e3a\u975e\u7a7a\uff0c\u8fd4\u56de $rA */ GO FROM $A.dst OVER follow; /* \u56e0\u4e3a RETURN \u8bed\u53e5\u8fd4\u56de\u4e86\u7ed3\u679c\uff0c\u6240\u4ee5GO FROM \u8bed\u53e5\u4e0d\u6267\u884c */ ========== | $A.dst | ========== | 101 | ---------- nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 300; \\ RETURN $rA IF $rA is NOT NULL; \\ /* $rA \u4e3a\u7a7a\uff0c\u4e0d\u8fd4\u56de\u4efb\u4f55\u503c */ GO FROM $A.dst OVER follow; /* \u56e0\u4e3a RETURN \u8bed\u53e5\u65e0\u8fd4\u56de\u7ed3\u679c\uff0c\u6240\u4ee5 GO FROM \u8bed\u53e5\u5c06\u6267\u884c */ =============== | follow._dst | =============== | 100 | --------------- | 101 | --------------- | 100 | --------------- | 102 | --------------- | 100 | --------------- | 107 | ---------------","title":"Return \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/return-syntax/#return","text":"Return \u8bed\u53e5\u7528\u4e8e\u8fd4\u56de\u6761\u4ef6\u6210\u7acb\u65f6\u7684\u7ed3\u679c\u3002\u5982\u679c\u6761\u4ef6\u4e0d\u6210\u7acb\uff0c\u5219\u65e0\u8fd4\u56de\u7ed3\u679c\u3002 RETURN <var_ref> IF <var_ref> IS NOT NULL \u4e3a\u53d8\u91cf\u540d\u79f0\uff0c\u793a\u4f8b\uff1a$var","title":"Return \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/return-syntax/#_1","text":"nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 101; \\ RETURN $rA IF $rA is NOT NULL; \\ /* $rA \u4e3a\u975e\u7a7a\uff0c\u8fd4\u56de $rA */ GO FROM $A.dst OVER follow; /* \u56e0\u4e3a RETURN \u8bed\u53e5\u8fd4\u56de\u4e86\u7ed3\u679c\uff0c\u6240\u4ee5GO FROM \u8bed\u53e5\u4e0d\u6267\u884c */ ========== | $A.dst | ========== | 101 | ---------- nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 300; \\ RETURN $rA IF $rA is NOT NULL; \\ /* $rA \u4e3a\u7a7a\uff0c\u4e0d\u8fd4\u56de\u4efb\u4f55\u503c */ GO FROM $A.dst OVER follow; /* \u56e0\u4e3a RETURN \u8bed\u53e5\u65e0\u8fd4\u56de\u7ed3\u679c\uff0c\u6240\u4ee5 GO FROM \u8bed\u53e5\u5c06\u6267\u884c */ =============== | follow._dst | =============== | 100 | --------------- | 101 | --------------- | 100 | --------------- | 102 | --------------- | 100 | --------------- | 107 | ---------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/","text":"UPDATE \u8bed\u6cd5 \u00b6 Nebula Graph \u652f\u6301 UPDATE \u4e00\u4e2a\u70b9\u6216\u8005\u4e00\u6761\u8fb9\u7684\u5c5e\u6027\uff0c\u652f\u6301 CAS \u64cd\u4f5c\uff0c\u652f\u6301\u8fd4\u56de\u76f8\u5173\u7684\u5c5e\u6027\u3002 \u66f4\u65b0\u70b9 \u00b6 UPDATE VERTEX <vid> SET <update_columns> [WHEN <condition>] [YIELD <columns>] \u6ce8\u610f\uff1a WHEN \u548c YIELD \u662f\u53ef\u9009\u7684\u3002 vid \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 vertex ID\u3002 update_columns \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 tag \u4e0a\u7684 columns\uff0c\u6bd4\u5982 tag1.col1 = $^.tag2.col2 + 1 \u8868\u793a\u628a\u8fd9\u4e2a\u70b9\u7684 tag1.col1 \u66f4\u65b0\u6210 tag2.col2 + 1 \u3002 \u6ce8\u610f\uff1a $^ \u8868\u793a UPDATE \u4e2d\u9700\u8981\u66f4\u65b0\u7684\u70b9\u3002 condition \u662f\u4e00\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u53ea\u6709\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\uff0c UPDATE \u624d\u4f1a\u771f\u6b63\u6267\u884c\uff0c\u652f\u6301\u8868\u8fbe\u5f0f\u64cd\u4f5c\u3002 columns \u8868\u793a\u9700\u8981\u8fd4\u56de\u7684 columns\uff0c\u6b64\u5904 YIELD \u53ef\u8fd4\u56de update \u4ee5\u540e\u6700\u65b0\u7684 columns \u503c\u3002 \u4e3e\u4f8b\u5982\u4e0b\uff1a nebula> UPDATE VERTEX 101 SET player.age = $^.player.age + 1 \\ WHEN $^.player.name == \"Tony Parker\" \\ YIELD $^.player.name AS name, $^.player.age AS age; \u8fd9\u4e2a\u4f8b\u5b50\u91cc\u9762\uff0c101 \u6709\u4e00\u4e2a tag\uff0c\u5373 player\u3002 \u66f4\u65b0\u8fb9 \u00b6 UPDATE EDGE <edge> SET <update_columns> [WHEN <condition>] [YIELD <columns>] \u6ce8\u610f\uff1a WHEN \u548c YIELD \u662f\u53ef\u9009\u7684\u3002 edge \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 edge\uff0cedge \u7684\u683c\u5f0f\u4e3a <src> -> <dst> [@ranking] OF <edge_type> \u3002 update_columns \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 edge \u4e0a\u7684\u5c5e\u6027\u3002 condition \u662f\u4e00\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u53ea\u6709\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\uff0cupdate \u624d\u4f1a\u771f\u6b63\u6267\u884c\uff0c\u652f\u6301\u8868\u8fbe\u5f0f\u64cd\u4f5c\u3002 columns \u8868\u793a\u9700\u8981\u8fd4\u56de\u7684 columns\uff0c\u6b64\u5904 YIELD \u53ef\u8fd4\u56de update \u4ee5\u540e\u6700\u65b0\u7684 columns \u503c\u3002 \u4e3e\u4f8b\u5982\u4e0b\uff1a nebula> UPDATE EDGE 100 -> 200@0 OF serve SET start_year = serve.start_year + 1 \\ YIELD $^.player.name AS name, serve.start_year AS start;","title":"UPDATE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/#update","text":"Nebula Graph \u652f\u6301 UPDATE \u4e00\u4e2a\u70b9\u6216\u8005\u4e00\u6761\u8fb9\u7684\u5c5e\u6027\uff0c\u652f\u6301 CAS \u64cd\u4f5c\uff0c\u652f\u6301\u8fd4\u56de\u76f8\u5173\u7684\u5c5e\u6027\u3002","title":"UPDATE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/#_1","text":"UPDATE VERTEX <vid> SET <update_columns> [WHEN <condition>] [YIELD <columns>] \u6ce8\u610f\uff1a WHEN \u548c YIELD \u662f\u53ef\u9009\u7684\u3002 vid \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 vertex ID\u3002 update_columns \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 tag \u4e0a\u7684 columns\uff0c\u6bd4\u5982 tag1.col1 = $^.tag2.col2 + 1 \u8868\u793a\u628a\u8fd9\u4e2a\u70b9\u7684 tag1.col1 \u66f4\u65b0\u6210 tag2.col2 + 1 \u3002 \u6ce8\u610f\uff1a $^ \u8868\u793a UPDATE \u4e2d\u9700\u8981\u66f4\u65b0\u7684\u70b9\u3002 condition \u662f\u4e00\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u53ea\u6709\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\uff0c UPDATE \u624d\u4f1a\u771f\u6b63\u6267\u884c\uff0c\u652f\u6301\u8868\u8fbe\u5f0f\u64cd\u4f5c\u3002 columns \u8868\u793a\u9700\u8981\u8fd4\u56de\u7684 columns\uff0c\u6b64\u5904 YIELD \u53ef\u8fd4\u56de update \u4ee5\u540e\u6700\u65b0\u7684 columns \u503c\u3002 \u4e3e\u4f8b\u5982\u4e0b\uff1a nebula> UPDATE VERTEX 101 SET player.age = $^.player.age + 1 \\ WHEN $^.player.name == \"Tony Parker\" \\ YIELD $^.player.name AS name, $^.player.age AS age; \u8fd9\u4e2a\u4f8b\u5b50\u91cc\u9762\uff0c101 \u6709\u4e00\u4e2a tag\uff0c\u5373 player\u3002","title":"\u66f4\u65b0\u70b9"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/#_2","text":"UPDATE EDGE <edge> SET <update_columns> [WHEN <condition>] [YIELD <columns>] \u6ce8\u610f\uff1a WHEN \u548c YIELD \u662f\u53ef\u9009\u7684\u3002 edge \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 edge\uff0cedge \u7684\u683c\u5f0f\u4e3a <src> -> <dst> [@ranking] OF <edge_type> \u3002 update_columns \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 edge \u4e0a\u7684\u5c5e\u6027\u3002 condition \u662f\u4e00\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u53ea\u6709\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\uff0cupdate \u624d\u4f1a\u771f\u6b63\u6267\u884c\uff0c\u652f\u6301\u8868\u8fbe\u5f0f\u64cd\u4f5c\u3002 columns \u8868\u793a\u9700\u8981\u8fd4\u56de\u7684 columns\uff0c\u6b64\u5904 YIELD \u53ef\u8fd4\u56de update \u4ee5\u540e\u6700\u65b0\u7684 columns \u503c\u3002 \u4e3e\u4f8b\u5982\u4e0b\uff1a nebula> UPDATE EDGE 100 -> 200@0 OF serve SET start_year = serve.start_year + 1 \\ YIELD $^.player.name AS name, serve.start_year AS start;","title":"\u66f4\u65b0\u8fb9"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/upsert-syntax/","text":"UPSERT \u8bed\u6cd5 \u00b6 UPSERT \u7528\u4e8e\u63d2\u5165\u65b0\u7684\u9876\u70b9\u6216\u8fb9\u6216\u66f4\u65b0\u73b0\u6709\u7684\u9876\u70b9\u6216\u8fb9\u3002\u5982\u679c\u9876\u70b9\u6216\u8fb9\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u65b0\u5efa\u8be5\u9876\u70b9\u6216\u8fb9\u3002 UPSERT \u662f INSERT \u548c UPDATE \u7684\u7ec4\u5408\u3002 \u5982\u679c\u9876\u70b9\u6216\u8fb9\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u65b0\u5efa\u8be5\u9876\u70b9\u6216\u8fb9\uff0c\u65e0\u8bba WHEN \u6761\u4ef6\u662f\u5426\u6ee1\u8db3\uff1b \u5982\u679c\u8be5\u9876\u70b9\u6216\u8005\u8fb9\u5b58\u5728\uff0c\u5e76\u4e14 WHEN \u6761\u4ef6\u6ee1\u8db3\uff0c\u5219\u4f1a\u66f4\u65b0\uff1b \u5982\u679c\u8be5\u9876\u70b9\u6216\u8005\u8fb9\u5b58\u5728, \u5e76\u4e14 WHEN \u6761\u4ef6\u4e0d\u6ee1\u8db3\uff0c\u5219\u4e0d\u4f1a\u6709\u4efb\u4f55\u64cd\u4f5c\u3002 UPSERT {VERTEX <vid> | EDGE <edge>} SET <update_columns> [WHEN <condition>] [YIELD <columns>] vid \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 vertex ID\u3002 edge \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 edge\uff0cedge \u7684\u683c\u5f0f\u4e3a <src> -> <dst> [@ranking] OF <edge_type> \u3002 update_columns \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 tag \u6216 edge \u4e0a\u7684 columns\uff0c\u6bd4\u5982 tag1.col1 = $^.tag2.col2 + 1 \u8868\u793a\u628a\u8fd9\u4e2a\u70b9\u7684 tag1.col1 \u66f4\u65b0\u6210 tag2.col2 + 1 \u3002 \u6ce8\u610f\uff1a $^ \u8868\u793a UPDATE \u4e2d\u9700\u8981\u66f4\u65b0\u7684\u70b9\u3002 condition \u662f\u4e00\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u53ea\u6709\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\uff0c UPDATE \u624d\u4f1a\u771f\u6b63\u6267\u884c\uff0c\u652f\u6301\u8868\u8fbe\u5f0f\u64cd\u4f5c\u3002 columns \u8868\u793a\u9700\u8981\u8fd4\u56de\u7684 columns\uff0c\u6b64\u5904 YIELD \u53ef\u8fd4\u56de update \u4ee5\u540e\u6700\u65b0\u7684 columns \u503c\u3002 \u4f8b\u5982\uff1a nebula> INSERT VERTEX player(name, age) VALUES 111:(\"Ben Simmons\", 22); -- \u63d2\u5165\u4e00\u4e2a\u65b0\u70b9\u3002 nebula> UPSERT VERTEX 111 SET player.name = \"Dwight Howard\", player.age = $^.player.age + 11 WHEN $^.player.name == \"Ben Simmons\" && $^.player.age > 20 YIELD $^.player.name AS Name, $^.player.age AS Age; -- \u5bf9\u8be5\u70b9\u8fdb\u884c UPSERT \u64cd\u4f5c\u3002 ======================= | Name | Age | ======================= | Dwight Howard | 33 | -----------------------","title":"UPSERT \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/upsert-syntax/#upsert","text":"UPSERT \u7528\u4e8e\u63d2\u5165\u65b0\u7684\u9876\u70b9\u6216\u8fb9\u6216\u66f4\u65b0\u73b0\u6709\u7684\u9876\u70b9\u6216\u8fb9\u3002\u5982\u679c\u9876\u70b9\u6216\u8fb9\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u65b0\u5efa\u8be5\u9876\u70b9\u6216\u8fb9\u3002 UPSERT \u662f INSERT \u548c UPDATE \u7684\u7ec4\u5408\u3002 \u5982\u679c\u9876\u70b9\u6216\u8fb9\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u65b0\u5efa\u8be5\u9876\u70b9\u6216\u8fb9\uff0c\u65e0\u8bba WHEN \u6761\u4ef6\u662f\u5426\u6ee1\u8db3\uff1b \u5982\u679c\u8be5\u9876\u70b9\u6216\u8005\u8fb9\u5b58\u5728\uff0c\u5e76\u4e14 WHEN \u6761\u4ef6\u6ee1\u8db3\uff0c\u5219\u4f1a\u66f4\u65b0\uff1b \u5982\u679c\u8be5\u9876\u70b9\u6216\u8005\u8fb9\u5b58\u5728, \u5e76\u4e14 WHEN \u6761\u4ef6\u4e0d\u6ee1\u8db3\uff0c\u5219\u4e0d\u4f1a\u6709\u4efb\u4f55\u64cd\u4f5c\u3002 UPSERT {VERTEX <vid> | EDGE <edge>} SET <update_columns> [WHEN <condition>] [YIELD <columns>] vid \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 vertex ID\u3002 edge \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 edge\uff0cedge \u7684\u683c\u5f0f\u4e3a <src> -> <dst> [@ranking] OF <edge_type> \u3002 update_columns \u8868\u793a\u9700\u8981\u66f4\u65b0\u7684 tag \u6216 edge \u4e0a\u7684 columns\uff0c\u6bd4\u5982 tag1.col1 = $^.tag2.col2 + 1 \u8868\u793a\u628a\u8fd9\u4e2a\u70b9\u7684 tag1.col1 \u66f4\u65b0\u6210 tag2.col2 + 1 \u3002 \u6ce8\u610f\uff1a $^ \u8868\u793a UPDATE \u4e2d\u9700\u8981\u66f4\u65b0\u7684\u70b9\u3002 condition \u662f\u4e00\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u53ea\u6709\u6ee1\u8db3\u8fd9\u4e2a\u6761\u4ef6\uff0c UPDATE \u624d\u4f1a\u771f\u6b63\u6267\u884c\uff0c\u652f\u6301\u8868\u8fbe\u5f0f\u64cd\u4f5c\u3002 columns \u8868\u793a\u9700\u8981\u8fd4\u56de\u7684 columns\uff0c\u6b64\u5904 YIELD \u53ef\u8fd4\u56de update \u4ee5\u540e\u6700\u65b0\u7684 columns \u503c\u3002 \u4f8b\u5982\uff1a nebula> INSERT VERTEX player(name, age) VALUES 111:(\"Ben Simmons\", 22); -- \u63d2\u5165\u4e00\u4e2a\u65b0\u70b9\u3002 nebula> UPSERT VERTEX 111 SET player.name = \"Dwight Howard\", player.age = $^.player.age + 11 WHEN $^.player.name == \"Ben Simmons\" && $^.player.age > 20 YIELD $^.player.name AS Name, $^.player.age AS Age; -- \u5bf9\u8be5\u70b9\u8fdb\u884c UPSERT \u64cd\u4f5c\u3002 ======================= | Name | Age | ======================= | Dwight Howard | 33 | -----------------------","title":"UPSERT \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/where-syntax/","text":"WHERE \u8bed\u6cd5 \u00b6 \u76ee\u524d\uff0c WHERE \u8bed\u53e5\u4ec5\u9002\u7528\u4e8e GO \u8bed\u53e5\u3002 WHERE <expression> [ AND | OR <expression> ...]) \u901a\u5e38\uff0c\u7b5b\u9009\u6761\u4ef6\u662f\u5173\u4e8e\u8282\u70b9\u3001\u8fb9\u7684\u8868\u8fbe\u5f0f\u7684\u903b\u8f91\u7ec4\u5408\u3002 \u4f5c\u4e3a\u8bed\u6cd5\u7cd6\uff0c\u903b\u8f91\u4e0e\u53ef\u7528 AND \u6216 && \uff0c\u540c\u7406\uff0c\u903b\u8f91\u6216\u53ef\u7528 OR \u6216 || \u8868\u793a\u3002 \u793a\u4f8b \u00b6 -- \u8fb9 follow \u7684 degree \u5c5e\u6027\u5927\u4e8e 90\u3002 nebula> GO FROM 100 OVER follow WHERE follow.degree > 90; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 101 | --------------- -- \u627e\u5230\u4e0e\u8d77\u70b9 player 104 \u7684 age \u503c\u76f8\u7b49\u7684\u70b9\u3002 nebula> GO FROM 104 OVER follow WHERE $^.player.age == $$.player.age; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 103 | --------------- -- \u591a\u79cd\u903b\u8f91\u7ec4\u5408\u3002 nebula> GO FROM 100 OVER follow WHERE follow.degree > 90 OR $$.player.age != 33 AND $$.player.name != \"Tony Parker\"; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 101 | --------------- | 106 | --------------- --\u4e0b\u9762 WHERE \u8bed\u53e5\u4e2d\u7684\u6761\u4ef6\u603b\u662f\u4e3a TRUE\u3002 nebula> GO FROM 101 OVER follow WHERE 1 == 1 OR TRUE; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 100 | --------------- | 102 | ---------------","title":"WHERE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/where-syntax/#where","text":"\u76ee\u524d\uff0c WHERE \u8bed\u53e5\u4ec5\u9002\u7528\u4e8e GO \u8bed\u53e5\u3002 WHERE <expression> [ AND | OR <expression> ...]) \u901a\u5e38\uff0c\u7b5b\u9009\u6761\u4ef6\u662f\u5173\u4e8e\u8282\u70b9\u3001\u8fb9\u7684\u8868\u8fbe\u5f0f\u7684\u903b\u8f91\u7ec4\u5408\u3002 \u4f5c\u4e3a\u8bed\u6cd5\u7cd6\uff0c\u903b\u8f91\u4e0e\u53ef\u7528 AND \u6216 && \uff0c\u540c\u7406\uff0c\u903b\u8f91\u6216\u53ef\u7528 OR \u6216 || \u8868\u793a\u3002","title":"WHERE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/where-syntax/#_1","text":"-- \u8fb9 follow \u7684 degree \u5c5e\u6027\u5927\u4e8e 90\u3002 nebula> GO FROM 100 OVER follow WHERE follow.degree > 90; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 101 | --------------- -- \u627e\u5230\u4e0e\u8d77\u70b9 player 104 \u7684 age \u503c\u76f8\u7b49\u7684\u70b9\u3002 nebula> GO FROM 104 OVER follow WHERE $^.player.age == $$.player.age; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 103 | --------------- -- \u591a\u79cd\u903b\u8f91\u7ec4\u5408\u3002 nebula> GO FROM 100 OVER follow WHERE follow.degree > 90 OR $$.player.age != 33 AND $$.player.name != \"Tony Parker\"; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 101 | --------------- | 106 | --------------- --\u4e0b\u9762 WHERE \u8bed\u53e5\u4e2d\u7684\u6761\u4ef6\u603b\u662f\u4e3a TRUE\u3002 nebula> GO FROM 101 OVER follow WHERE 1 == 1 OR TRUE; -- \u8fd4\u56de\u4ee5\u4e0b\u503c\uff1a =============== | follow._dst | =============== | 100 | --------------- | 102 | ---------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/","text":"YIELD \u5b50\u53e5\u3001\u8bed\u53e5 \u00b6 YIELD \u5173\u952e\u8bcd\u53ef\u4ee5\u5728 FETCH \u3001 GO \u8bed\u53e5\u4e2d\u4f5c\u4e3a\u5b50\u53e5\u4f7f\u7528\uff0c\u4e5f\u53ef\u4ee5\u5728 PIPE ( | ) \u4e2d\u4f5c\u4e3a\u72ec\u7acb\u7684\u8bed\u53e5\u4f7f\u7528\uff0c\u540c\u65f6\u53ef\u4ee5\u4f5c\u4e3a\u7528\u4e8e\u8ba1\u7b97\u7684\u5355\u53e5\u4f7f\u7528\u3002 \u4f5c\u4e3a\u5b50\u53e5 \u00b6 YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] \u5e38\u7528\u4e8e\u8fd4\u56de\u7531 GO \uff08\u8be6\u60c5\u8bf7\u53c2\u9605 GO \u7528\u6cd5\uff09\u8bed\u53e5\u751f\u6210\u7684\u7ed3\u679c\u3002 nebula> GO FROM 100 OVER follow YIELD $$.player.name AS Friend, $$.player.age AS Age; =========================== | Friend | Age | =========================== | Tony Parker | 36 | --------------------------- | LaMarcus Aldridge | 33 | --------------------------- | Kyle Anderson | 25 | --------------------------- \u4f8b\u5982\uff0c $$.player.name \u7528\u6765\u83b7\u53d6\u76ee\u6807\u70b9\uff08$$\uff09\u7684\u5c5e\u6027\u3002 \u4f5c\u4e3a\u8bed\u53e5 \u00b6 \u5f15\u7528\u8f93\u5165\u6216\u8005\u53d8\u91cf \u00b6 \u53ef\u4ee5\u5728 PIPE \u4e2d\u4f7f\u7528 YIELD \u8bed\u53e5\u3002 \u53ef\u4ee5\u7528\u4e8e\u5f15\u7528\u53d8\u91cf\u3002 \u5bf9\u4e8e\u90a3\u4e9b\u4e0d\u652f\u6301 YIELD \u5b50\u53e5\u7684\u8bed\u53e5\uff0c\u53ef\u4ee5\u4f7f\u7528 YIELD \u8bed\u53e5\u4f5c\u4e3a\u4e00\u4e2a\u5de5\u5177\uff0c\u63a7\u5236\u8f93\u51fa\u3002 YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [WHERE <conditions>] nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | YIELD $-.* WHERE $-.id == 106; ========= | $-.id | ========= | 106 | --------- nebula> $var1 = GO FROM 101 OVER follow; $var2 = GO FROM 105 OVER follow; YIELD $var1.* UNION YIELD $var2.*; ===================== | $var1.follow._dst | ===================== | 100 | --------------------- | 102 | --------------------- | 104 | --------------------- | 110 | --------------------- \u4f5c\u4e3a\u72ec\u7acb\u7684\u8bed\u53e5 \u00b6 YIELD \u8bed\u53e5\u53ef\u4ee5\u72ec\u7acb\u4f7f\u7528\uff0c\u7528\u4e8e\u4e00\u4e9b\u7b80\u5355\u7684\u8ba1\u7b97\u3002\u60a8\u53ef\u4ee5\u4f7f\u7528 AS \u91cd\u547d\u540d\u8fd4\u56de\u7684\u5217\u3002 nebula> YIELD 1 + 1; ========= | (1+1) | ========= | 2 | --------- nebula> YIELD \"Hel\" + \"\\tlo\" AS HELLO_1, \", World!\" AS WORLD_2; ====================== | HELLO_1 | WORLD_2 | ====================== | Hel lo | , World! | ---------------------- nebula> YIELD hash(\"Tim\") % 100; ===================== | (hash(\"Tim\")%100) | ===================== | 42 | --------------------- \u6ce8\u610f\uff1a \u4e0d\u652f\u6301 YIELD DISTINCT \u5728\u5355\u53e5\u4e2d\u4f7f\u7528\u3002 nebula> YIELD DISTINCT 1; --- \u8bed\u6cd5\u9519\u8bef","title":"YIELD \u5b50\u53e5\u3001\u8bed\u53e5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#yield","text":"YIELD \u5173\u952e\u8bcd\u53ef\u4ee5\u5728 FETCH \u3001 GO \u8bed\u53e5\u4e2d\u4f5c\u4e3a\u5b50\u53e5\u4f7f\u7528\uff0c\u4e5f\u53ef\u4ee5\u5728 PIPE ( | ) \u4e2d\u4f5c\u4e3a\u72ec\u7acb\u7684\u8bed\u53e5\u4f7f\u7528\uff0c\u540c\u65f6\u53ef\u4ee5\u4f5c\u4e3a\u7528\u4e8e\u8ba1\u7b97\u7684\u5355\u53e5\u4f7f\u7528\u3002","title":"YIELD \u5b50\u53e5\u3001\u8bed\u53e5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#_1","text":"YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] \u5e38\u7528\u4e8e\u8fd4\u56de\u7531 GO \uff08\u8be6\u60c5\u8bf7\u53c2\u9605 GO \u7528\u6cd5\uff09\u8bed\u53e5\u751f\u6210\u7684\u7ed3\u679c\u3002 nebula> GO FROM 100 OVER follow YIELD $$.player.name AS Friend, $$.player.age AS Age; =========================== | Friend | Age | =========================== | Tony Parker | 36 | --------------------------- | LaMarcus Aldridge | 33 | --------------------------- | Kyle Anderson | 25 | --------------------------- \u4f8b\u5982\uff0c $$.player.name \u7528\u6765\u83b7\u53d6\u76ee\u6807\u70b9\uff08$$\uff09\u7684\u5c5e\u6027\u3002","title":"\u4f5c\u4e3a\u5b50\u53e5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#_2","text":"","title":"\u4f5c\u4e3a\u8bed\u53e5"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#_3","text":"\u53ef\u4ee5\u5728 PIPE \u4e2d\u4f7f\u7528 YIELD \u8bed\u53e5\u3002 \u53ef\u4ee5\u7528\u4e8e\u5f15\u7528\u53d8\u91cf\u3002 \u5bf9\u4e8e\u90a3\u4e9b\u4e0d\u652f\u6301 YIELD \u5b50\u53e5\u7684\u8bed\u53e5\uff0c\u53ef\u4ee5\u4f7f\u7528 YIELD \u8bed\u53e5\u4f5c\u4e3a\u4e00\u4e2a\u5de5\u5177\uff0c\u63a7\u5236\u8f93\u51fa\u3002 YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [WHERE <conditions>] nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | YIELD $-.* WHERE $-.id == 106; ========= | $-.id | ========= | 106 | --------- nebula> $var1 = GO FROM 101 OVER follow; $var2 = GO FROM 105 OVER follow; YIELD $var1.* UNION YIELD $var2.*; ===================== | $var1.follow._dst | ===================== | 100 | --------------------- | 102 | --------------------- | 104 | --------------------- | 110 | ---------------------","title":"\u5f15\u7528\u8f93\u5165\u6216\u8005\u53d8\u91cf"},{"location":"manual-CN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#_4","text":"YIELD \u8bed\u53e5\u53ef\u4ee5\u72ec\u7acb\u4f7f\u7528\uff0c\u7528\u4e8e\u4e00\u4e9b\u7b80\u5355\u7684\u8ba1\u7b97\u3002\u60a8\u53ef\u4ee5\u4f7f\u7528 AS \u91cd\u547d\u540d\u8fd4\u56de\u7684\u5217\u3002 nebula> YIELD 1 + 1; ========= | (1+1) | ========= | 2 | --------- nebula> YIELD \"Hel\" + \"\\tlo\" AS HELLO_1, \", World!\" AS WORLD_2; ====================== | HELLO_1 | WORLD_2 | ====================== | Hel lo | , World! | ---------------------- nebula> YIELD hash(\"Tim\") % 100; ===================== | (hash(\"Tim\")%100) | ===================== | 42 | --------------------- \u6ce8\u610f\uff1a \u4e0d\u652f\u6301 YIELD DISTINCT \u5728\u5355\u53e5\u4e2d\u4f7f\u7528\u3002 nebula> YIELD DISTINCT 1; --- \u8bed\u6cd5\u9519\u8bef","title":"\u4f5c\u4e3a\u72ec\u7acb\u7684\u8bed\u53e5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/describe-syntax/","text":"DESCRIBE \u8bed\u6cd5 \u00b6 DESCRIBE SPACE <space_name> DESCRIBE TAG <tag_name> DESCRIBE EDGE <edge_name> DESCRIBE {TAG | EDGE} INDEX <index_name> DESCRIBE \u5173\u952e\u8bcd\u7684\u4f5c\u7528\u662f\u83b7\u53d6\u5173\u4e8e space, tag, edge \u7ed3\u6784\u7684\u4fe1\u606f\u3002 \u540c\u65f6\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cDESCRIBE \u548c SHOW \u4e5f\u662f\u4e0d\u540c\u7684\u3002 \u8be6\u7ec6\u53c2\u89c1 SHOW \u6587\u6863\u3002 \u793a\u4f8b \u00b6 \u83b7\u53d6\u6307\u5b9a space \u7684\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE SPACE \u3002 nebula> DESCRIBE SPACE nba; ======================================================== | ID | Name | Partition number | Replica Factor | ======================================================== | 1 | nba | 100 | 1 | -------------------------------------------------------- \u83b7\u53d6\u6307\u5b9a tag \u7684\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE TAG \u3002 nebula> DESCRIBE TAG player; ================================================== | Field | Type | Null | Key | Default | Extra | ================================================== | name | string | false | | | | -------------------------------------------------- | age | int | false | | | | -------------------------------------------------- \u83b7\u53d6\u6307\u5b9a EDGE \u7684\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE EDGE \u3002 nebula> DESCRIBE EDGE serve; ====================================================== | Field | Type | Null | Key | Default | Extra | ====================================================== | start_year | int | false | | | | ------------------------------------------------------ | end_year | int | false | | | | ------------------------------------------------------ \u8fd4\u56de\u6307\u5b9a\u7d22\u5f15\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE INDEX \u3002 nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------","title":"DESCRIBE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/describe-syntax/#describe","text":"DESCRIBE SPACE <space_name> DESCRIBE TAG <tag_name> DESCRIBE EDGE <edge_name> DESCRIBE {TAG | EDGE} INDEX <index_name> DESCRIBE \u5173\u952e\u8bcd\u7684\u4f5c\u7528\u662f\u83b7\u53d6\u5173\u4e8e space, tag, edge \u7ed3\u6784\u7684\u4fe1\u606f\u3002 \u540c\u65f6\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cDESCRIBE \u548c SHOW \u4e5f\u662f\u4e0d\u540c\u7684\u3002 \u8be6\u7ec6\u53c2\u89c1 SHOW \u6587\u6863\u3002","title":"DESCRIBE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/describe-syntax/#_1","text":"\u83b7\u53d6\u6307\u5b9a space \u7684\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE SPACE \u3002 nebula> DESCRIBE SPACE nba; ======================================================== | ID | Name | Partition number | Replica Factor | ======================================================== | 1 | nba | 100 | 1 | -------------------------------------------------------- \u83b7\u53d6\u6307\u5b9a tag \u7684\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE TAG \u3002 nebula> DESCRIBE TAG player; ================================================== | Field | Type | Null | Key | Default | Extra | ================================================== | name | string | false | | | | -------------------------------------------------- | age | int | false | | | | -------------------------------------------------- \u83b7\u53d6\u6307\u5b9a EDGE \u7684\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE EDGE \u3002 nebula> DESCRIBE EDGE serve; ====================================================== | Field | Type | Null | Key | Default | Extra | ====================================================== | start_year | int | false | | | | ------------------------------------------------------ | end_year | int | false | | | | ------------------------------------------------------ \u8fd4\u56de\u6307\u5b9a\u7d22\u5f15\u4fe1\u606f\uff0c\u5bf9\u5e94 DESCRIBE INDEX \u3002 nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------","title":"\u793a\u4f8b"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/use-syntax/","text":"USE \u8bed\u6cd5 \u00b6 USE <graph_space_name> \u5728 Nebula Graph \u4e2d USE \u8bed\u53e5\u7684\u4f5c\u7528\u662f\u9009\u62e9\u4e00\u4e2a\u56fe\u7a7a\u95f4\u6765\u4f5c\u4e3a\u5f53\u524d\u7684\u5de5\u4f5c\u56fe\u7a7a\u95f4\u3002 USE \u9700\u8981\u4e00\u4e9b\u7279\u5b9a\u7684\u6743\u9650\u6765\u6267\u884c\u3002 \u5f53\u524d\u7684\u56fe\u7a7a\u95f4\u4f1a\u4fdd\u6301\u9ed8\u8ba4\u76f4\u81f3\u5f53\u524d\u4f1a\u8bdd\u7ed3\u675f\u6216\u53e6\u4e00\u4e2a USE \u8bed\u53e5\u88ab\u6267\u884c\u3002 nebula> USE space1; -- \u904d\u5386 space1\u3002 nebula> GO FROM 1 OVER edge1; -- \u4f7f\u7528 space2\u3002space2 \u4e2d\u7684\u6570\u636e\u4e0e space1 \u7269\u7406\u9694\u79bb\u3002 nebula> USE space2; nebula> GO FROM 2 OVER edge2; -- \u56de\u5230 space1\u3002\u81f3\u6b64\u4f60\u4e0d\u80fd\u4ece space2 \u4e2d\u8bfb\u53d6\u6570\u636e\u3002 nebula> USE space1; \u548c SQL \u4e0d\u540c\u7684\u662f\uff0c\u9009\u53d6\u4e00\u4e2a\u5f53\u524d\u7684\u5de5\u4f5c\u56fe\u7a7a\u95f4\u4f1a\u963b\u6b62\u4f60\u8bbf\u95ee\u5176\u4ed6\u56fe\u7a7a\u95f4\u3002\u904d\u5386\u4e00\u4e2a\u65b0\u7684\u56fe\u7a7a\u95f4\u7684\u552f\u4e00\u65b9\u6848\u662f\u901a\u8fc7 USE \u8bed\u53e5\u6765\u5207\u6362\u5de5\u4f5c\u56fe\u7a7a\u95f4\u3002 SPACES \u4e4b\u95f4\u662f \u5b8c\u5168\u9694\u79bb\u7684 \u3002\u4e0d\u50cf SQL \u5141\u8bb8\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u9009\u62e9\u4e24\u4e2a\u6765\u81ea\u4e0d\u540c\u6570\u636e\u5e93\u7684\u8868\u5355\uff0c\u5728 Nebula Graph \u4e2d\u4e00\u6b21\u53ea\u80fd\u5bf9\u4e00\u4e2a\u56fe\u7a7a\u95f4\u8fdb\u884c\u64cd\u4f5c\u3002","title":"USE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/use-syntax/#use","text":"USE <graph_space_name> \u5728 Nebula Graph \u4e2d USE \u8bed\u53e5\u7684\u4f5c\u7528\u662f\u9009\u62e9\u4e00\u4e2a\u56fe\u7a7a\u95f4\u6765\u4f5c\u4e3a\u5f53\u524d\u7684\u5de5\u4f5c\u56fe\u7a7a\u95f4\u3002 USE \u9700\u8981\u4e00\u4e9b\u7279\u5b9a\u7684\u6743\u9650\u6765\u6267\u884c\u3002 \u5f53\u524d\u7684\u56fe\u7a7a\u95f4\u4f1a\u4fdd\u6301\u9ed8\u8ba4\u76f4\u81f3\u5f53\u524d\u4f1a\u8bdd\u7ed3\u675f\u6216\u53e6\u4e00\u4e2a USE \u8bed\u53e5\u88ab\u6267\u884c\u3002 nebula> USE space1; -- \u904d\u5386 space1\u3002 nebula> GO FROM 1 OVER edge1; -- \u4f7f\u7528 space2\u3002space2 \u4e2d\u7684\u6570\u636e\u4e0e space1 \u7269\u7406\u9694\u79bb\u3002 nebula> USE space2; nebula> GO FROM 2 OVER edge2; -- \u56de\u5230 space1\u3002\u81f3\u6b64\u4f60\u4e0d\u80fd\u4ece space2 \u4e2d\u8bfb\u53d6\u6570\u636e\u3002 nebula> USE space1; \u548c SQL \u4e0d\u540c\u7684\u662f\uff0c\u9009\u53d6\u4e00\u4e2a\u5f53\u524d\u7684\u5de5\u4f5c\u56fe\u7a7a\u95f4\u4f1a\u963b\u6b62\u4f60\u8bbf\u95ee\u5176\u4ed6\u56fe\u7a7a\u95f4\u3002\u904d\u5386\u4e00\u4e2a\u65b0\u7684\u56fe\u7a7a\u95f4\u7684\u552f\u4e00\u65b9\u6848\u662f\u901a\u8fc7 USE \u8bed\u53e5\u6765\u5207\u6362\u5de5\u4f5c\u56fe\u7a7a\u95f4\u3002 SPACES \u4e4b\u95f4\u662f \u5b8c\u5168\u9694\u79bb\u7684 \u3002\u4e0d\u50cf SQL \u5141\u8bb8\u5728\u4e00\u4e2a\u8bed\u53e5\u4e2d\u9009\u62e9\u4e24\u4e2a\u6765\u81ea\u4e0d\u540c\u6570\u636e\u5e93\u7684\u8868\u5355\uff0c\u5728 Nebula Graph \u4e2d\u4e00\u6b21\u53ea\u80fd\u5bf9\u4e00\u4e2a\u56fe\u7a7a\u95f4\u8fdb\u884c\u64cd\u4f5c\u3002","title":"USE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-charset-syntax/","text":"SHOW CHARSET \u8bed\u6cd5 \u00b6 SHOW CHARSET SHOW CHARSET \u8fd4\u56de\u6240\u6709\u53ef\u7528\u7684\u5b57\u7b26\u96c6\u3002\u76ee\u524d\u652f\u6301\u4e24\u79cd\u7c7b\u578b\uff1autf8\u3001utf8mb4\u3002\u5176\u4e2d\u9ed8\u8ba4\u5b57\u7b26\u96c6\u4e3a utf8\u3002 Nebula Graph \u5c06 utf8 \u8fdb\u884c\u4e86\u6269\u5c55\uff0cutf8 \u540c\u65f6\u652f\u6301 4 \u4e2a\u5b57\u8282\u7684\u5b57\u7b26\uff0c\u56e0\u6b64\uff0cutf8 \u548c utf8mb4 \u662f\u7b49\u4ef7\u7684\u3002 nebula> SHOW CHARSET; ======================================================== | Charset | Description | Default collation | Maxlen | ======================================================== | utf8 | UTF-8 Unicode | utf8_bin | 4 | -------------------------------------------------------- SHOW CHARSET \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a Charset \u5b57\u7b26\u96c6\u540d\u79f0\u3002 Description \u5b57\u7b26\u96c6\u7684\u63cf\u8ff0\u3002 Default collation \u5b57\u7b26\u96c6\u7684\u9ed8\u8ba4\u6392\u5e8f\u89c4\u5219\u3002 Maxlen \u5b58\u50a8\u4e00\u4e2a\u5b57\u7b26\u6240\u9700\u7684\u6700\u5927\u5b57\u8282\u6570\u3002","title":"SHOW CHARSET \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-charset-syntax/#show_charset","text":"SHOW CHARSET SHOW CHARSET \u8fd4\u56de\u6240\u6709\u53ef\u7528\u7684\u5b57\u7b26\u96c6\u3002\u76ee\u524d\u652f\u6301\u4e24\u79cd\u7c7b\u578b\uff1autf8\u3001utf8mb4\u3002\u5176\u4e2d\u9ed8\u8ba4\u5b57\u7b26\u96c6\u4e3a utf8\u3002 Nebula Graph \u5c06 utf8 \u8fdb\u884c\u4e86\u6269\u5c55\uff0cutf8 \u540c\u65f6\u652f\u6301 4 \u4e2a\u5b57\u8282\u7684\u5b57\u7b26\uff0c\u56e0\u6b64\uff0cutf8 \u548c utf8mb4 \u662f\u7b49\u4ef7\u7684\u3002 nebula> SHOW CHARSET; ======================================================== | Charset | Description | Default collation | Maxlen | ======================================================== | utf8 | UTF-8 Unicode | utf8_bin | 4 | -------------------------------------------------------- SHOW CHARSET \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a Charset \u5b57\u7b26\u96c6\u540d\u79f0\u3002 Description \u5b57\u7b26\u96c6\u7684\u63cf\u8ff0\u3002 Default collation \u5b57\u7b26\u96c6\u7684\u9ed8\u8ba4\u6392\u5e8f\u89c4\u5219\u3002 Maxlen \u5b58\u50a8\u4e00\u4e2a\u5b57\u7b26\u6240\u9700\u7684\u6700\u5927\u5b57\u8282\u6570\u3002","title":"SHOW CHARSET \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-collation-syntax/","text":"SHOW COLLATION \u8bed\u6cd5 \u00b6 SHOW COLLATION SHOW COLLATION \u8bed\u53e5\u5217\u51fa Nebula Graph \u76ee\u524d\u652f\u6301\u7684\u6240\u6709\u6392\u5e8f\u89c4\u5219\u3002\u76ee\u524d\u652f\u6301\u56db\u79cd\u6392\u5e8f\u89c4\u5219\uff1autf8_bin\u3001utf8_general_ci\u3001utf8mb4_bin\u3001utf8mb4_general_ci\u3002\u5b57\u7b26\u96c6\u4e3a utf8 \u65f6\uff0c\u9ed8\u8ba4 collate \u4e3a utf8_bin\uff1b\u5b57\u7b26\u96c6\u4e3a utf8mb4 \u65f6\uff0c\u9ed8\u8ba4 collate \u4e3a utf8mb4_bin\u3002utf8_general_ci \u548c utf8mb4_general_ci \u90fd\u662f\u5ffd\u7565\u5927\u5c0f\u5199\u7684\u6bd4\u8f83\uff0c\u884c\u4e3a\u540c MySQL \u4e00\u81f4\u3002 nebula> SHOW COLLATION; ======================= | Collation | Charset | ======================= | utf8_bin | utf8 | ----------------------- SHOW COLLATION \u8f93\u51fa\u6709\u4ee5\u4e0b\u5217\uff1a Collation \u6392\u5e8f\u89c4\u5219\u540d\u79f0\u3002 Charset \u4e0e\u6392\u5e8f\u89c4\u5219\u5173\u8054\u7684\u5b57\u7b26\u96c6\u7684\u540d\u79f0\u3002","title":"SHOW COLLATION \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-collation-syntax/#show_collation","text":"SHOW COLLATION SHOW COLLATION \u8bed\u53e5\u5217\u51fa Nebula Graph \u76ee\u524d\u652f\u6301\u7684\u6240\u6709\u6392\u5e8f\u89c4\u5219\u3002\u76ee\u524d\u652f\u6301\u56db\u79cd\u6392\u5e8f\u89c4\u5219\uff1autf8_bin\u3001utf8_general_ci\u3001utf8mb4_bin\u3001utf8mb4_general_ci\u3002\u5b57\u7b26\u96c6\u4e3a utf8 \u65f6\uff0c\u9ed8\u8ba4 collate \u4e3a utf8_bin\uff1b\u5b57\u7b26\u96c6\u4e3a utf8mb4 \u65f6\uff0c\u9ed8\u8ba4 collate \u4e3a utf8mb4_bin\u3002utf8_general_ci \u548c utf8mb4_general_ci \u90fd\u662f\u5ffd\u7565\u5927\u5c0f\u5199\u7684\u6bd4\u8f83\uff0c\u884c\u4e3a\u540c MySQL \u4e00\u81f4\u3002 nebula> SHOW COLLATION; ======================= | Collation | Charset | ======================= | utf8_bin | utf8 | ----------------------- SHOW COLLATION \u8f93\u51fa\u6709\u4ee5\u4e0b\u5217\uff1a Collation \u6392\u5e8f\u89c4\u5219\u540d\u79f0\u3002 Charset \u4e0e\u6392\u5e8f\u89c4\u5219\u5173\u8054\u7684\u5b57\u7b26\u96c6\u7684\u540d\u79f0\u3002","title":"SHOW COLLATION \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-configs-syntax/","text":"SHOW CONFIGS \u8bed\u6cd5 \u00b6 SHOW CONFIGS [graph|meta|storage] SHOW CONFIGS \u8bed\u53e5\u663e\u793a\u53c2\u6570\u4fe1\u606f\u3002 SHOW CONFIGS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1amodule\uff08\u6a21\u5757\u4fe1\u606f\uff09\u3001name\uff08\u53c2\u6570\u540d\u79f0\uff09\u3001type\uff08\u53c2\u6570\u7c7b\u578b\uff09\u3001mode\uff08\u53c2\u6570\u6a21\u5f0f\uff09\u548c value\uff08\u53c2\u6570\u503c\uff09\u3002 \u66f4\u591a\u5173\u4e8e SHOW CONFIGS [graph|meta|storage] \u7684\u4fe1\u606f\uff0c\u53c2\u89c1 configs syntax \u3002","title":"SHOW CONFIGS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-configs-syntax/#show_configs","text":"SHOW CONFIGS [graph|meta|storage] SHOW CONFIGS \u8bed\u53e5\u663e\u793a\u53c2\u6570\u4fe1\u606f\u3002 SHOW CONFIGS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1amodule\uff08\u6a21\u5757\u4fe1\u606f\uff09\u3001name\uff08\u53c2\u6570\u540d\u79f0\uff09\u3001type\uff08\u53c2\u6570\u7c7b\u578b\uff09\u3001mode\uff08\u53c2\u6570\u6a21\u5f0f\uff09\u548c value\uff08\u53c2\u6570\u503c\uff09\u3002 \u66f4\u591a\u5173\u4e8e SHOW CONFIGS [graph|meta|storage] \u7684\u4fe1\u606f\uff0c\u53c2\u89c1 configs syntax \u3002","title":"SHOW CONFIGS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-space-syntax/","text":"SHOW CREATE SPACE \u8bed\u6cd5 \u00b6 SHOW CREATE SPACE <space_name> SHOW CREATE SPACE \u8fd4\u56de\u6307\u5b9a space \u53ca\u5176\u521b\u5efa\u8bed\u6cd5\u3002\u5982\u679c space \u5305\u542b\u9ed8\u8ba4\u503c\uff0c\u5219\u540c\u65f6\u8fd4\u56de\u9ed8\u8ba4\u503c\u3002","title":"SHOW CREATE SPACE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-space-syntax/#show_create_space","text":"SHOW CREATE SPACE <space_name> SHOW CREATE SPACE \u8fd4\u56de\u6307\u5b9a space \u53ca\u5176\u521b\u5efa\u8bed\u6cd5\u3002\u5982\u679c space \u5305\u542b\u9ed8\u8ba4\u503c\uff0c\u5219\u540c\u65f6\u8fd4\u56de\u9ed8\u8ba4\u503c\u3002","title":"SHOW CREATE SPACE \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-tag-edge-syntax/","text":"SHOW CREATE TAGS/EDGES \u8bed\u6cd5 \u00b6 SHOW CREATE {TAG <tag_name> | EDGE <edge_name>} SHOW CREATE TAG \u548c SHOW CREATE EDGE \u8fd4\u56de\u5f53\u524d\u56fe\u7a7a\u95f4\u4e2d\u6307\u5b9a\u7684 tag\u3001edge type \u53ca\u5176\u521b\u5efa\u8bed\u6cd5\u3002\u5982\u679c tag \u6216 edge type \u5305\u542b\u9ed8\u8ba4\u503c\uff0c\u5219\u540c\u65f6\u8fd4\u56de\u9ed8\u8ba4\u503c\u3002","title":"SHOW CREATE TAGS/EDGES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-tag-edge-syntax/#show_create_tagsedges","text":"SHOW CREATE {TAG <tag_name> | EDGE <edge_name>} SHOW CREATE TAG \u548c SHOW CREATE EDGE \u8fd4\u56de\u5f53\u524d\u56fe\u7a7a\u95f4\u4e2d\u6307\u5b9a\u7684 tag\u3001edge type \u53ca\u5176\u521b\u5efa\u8bed\u6cd5\u3002\u5982\u679c tag \u6216 edge type \u5305\u542b\u9ed8\u8ba4\u503c\uff0c\u5219\u540c\u65f6\u8fd4\u56de\u9ed8\u8ba4\u503c\u3002","title":"SHOW CREATE TAGS/EDGES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-hosts-syntax/","text":"SHOW HOSTS \u8bed\u6cd5 \u00b6 SHOW HOSTS SHOW HOSTS \u5217\u51fa\u5143\u670d\u52a1\u5668\u6ce8\u518c\u7684\u6240\u6709\u5b58\u50a8\u4e3b\u673a\u3002 SHOW HOSTS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1aIP \u5730\u5740\u3001\u7aef\u53e3\u53f7\u3001\u72b6\u6001\uff08online/offline\uff09\u3001leader \u6570\u91cf\u3001leader \u5206\u5e03\u3001partition \u5206\u5e03\u3002 nebula> SHOW HOSTS; ============================================================================================= | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ============================================================================================= | 172.28.2.1 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | 172.28.2.2 | 44500 | online | 2 | NBA: 1, gods: 1 | NBA: 1, gods: 1 | --------------------------------------------------------------------------------------------- | 172.28.2.3 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | Total | | | 2 | gods: 1, NBA: 1 | gods: 1, NBA: 1 | ---------------------------------------------------------------------------------------------","title":"SHOW HOSTS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-hosts-syntax/#show_hosts","text":"SHOW HOSTS SHOW HOSTS \u5217\u51fa\u5143\u670d\u52a1\u5668\u6ce8\u518c\u7684\u6240\u6709\u5b58\u50a8\u4e3b\u673a\u3002 SHOW HOSTS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1aIP \u5730\u5740\u3001\u7aef\u53e3\u53f7\u3001\u72b6\u6001\uff08online/offline\uff09\u3001leader \u6570\u91cf\u3001leader \u5206\u5e03\u3001partition \u5206\u5e03\u3002 nebula> SHOW HOSTS; ============================================================================================= | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ============================================================================================= | 172.28.2.1 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | 172.28.2.2 | 44500 | online | 2 | NBA: 1, gods: 1 | NBA: 1, gods: 1 | --------------------------------------------------------------------------------------------- | 172.28.2.3 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | Total | | | 2 | gods: 1, NBA: 1 | gods: 1, NBA: 1 | ---------------------------------------------------------------------------------------------","title":"SHOW HOSTS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-index-status/","text":"SHOW INDEX STATUS \u8bed\u6cd5 \u00b6 SHOW {TAG | EDGE} INDEX STATUS SHOW INDEX STATUS \u7528\u4e8e\u5217\u51fa\u5df2\u521b\u5efa\u5b8c\u6210\u7684 Tag/Edge-type \u7684\u7d22\u5f15\u72b6\u6001\u4fe1\u606f\u3002\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5217\u51fa tag \u7d22\u5f15\u7684\u72b6\u6001\u4fe1\u606f\uff1a nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------ \u5982\u4f55\u521b\u5efa\u7d22\u5f15\u8bf7\u53c2\u8003 \u7d22\u5f15 \u6587\u6863\u3002","title":"SHOW INDEX STATUS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-index-status/#show_index_status","text":"SHOW {TAG | EDGE} INDEX STATUS SHOW INDEX STATUS \u7528\u4e8e\u5217\u51fa\u5df2\u521b\u5efa\u5b8c\u6210\u7684 Tag/Edge-type \u7684\u7d22\u5f15\u72b6\u6001\u4fe1\u606f\u3002\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5217\u51fa tag \u7d22\u5f15\u7684\u72b6\u6001\u4fe1\u606f\uff1a nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------ \u5982\u4f55\u521b\u5efa\u7d22\u5f15\u8bf7\u53c2\u8003 \u7d22\u5f15 \u6587\u6863\u3002","title":"SHOW INDEX STATUS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-indexes-syntax/","text":"SHOW INDEXES \u8bed\u6cd5 \u00b6 SHOW {TAG | EDGE} INDEXES SHOW INDEXES \u7528\u4e8e\u5217\u51fa\u5df2\u521b\u5efa\u5b8c\u6210\u7684\u6807\u7b7e\u6216\u8fb9\u7c7b\u578b\u7684\u7d22\u5f15\u4fe1\u606f\u3002 SHOW INDEXES \u8fd4\u56de\u4ee5\u4e0b\u5b57\u6bb5\uff1a\u7d22\u5f15 ID \u548c \u7d22\u5f15\u540d\u79f0\u3002","title":"SHOW INDEXES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-indexes-syntax/#show_indexes","text":"SHOW {TAG | EDGE} INDEXES SHOW INDEXES \u7528\u4e8e\u5217\u51fa\u5df2\u521b\u5efa\u5b8c\u6210\u7684\u6807\u7b7e\u6216\u8fb9\u7c7b\u578b\u7684\u7d22\u5f15\u4fe1\u606f\u3002 SHOW INDEXES \u8fd4\u56de\u4ee5\u4e0b\u5b57\u6bb5\uff1a\u7d22\u5f15 ID \u548c \u7d22\u5f15\u540d\u79f0\u3002","title":"SHOW INDEXES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-parts-syntax/","text":"SHOW PARTS \u8bed\u6cd5 \u00b6 SHOW PARTS <part_id> SHOW PARTS \u5217\u51fa\u6307\u5b9a partition \u7684\u4fe1\u606f\u3002 nebula> SHOW PARTS 1; ============================================================== | Partition ID | Leader | Peers | Losts | ============================================================== | 1 | 172.28.2.2:44500 | 172.28.2.2:44500 | | -------------------------------------------------------------- SHOW PARTS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a Partition ID Leader Peers Losts","title":"SHOW PARTS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-parts-syntax/#show_parts","text":"SHOW PARTS <part_id> SHOW PARTS \u5217\u51fa\u6307\u5b9a partition \u7684\u4fe1\u606f\u3002 nebula> SHOW PARTS 1; ============================================================== | Partition ID | Leader | Peers | Losts | ============================================================== | 1 | 172.28.2.2:44500 | 172.28.2.2:44500 | | -------------------------------------------------------------- SHOW PARTS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a Partition ID Leader Peers Losts","title":"SHOW PARTS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-roles-syntax/","text":"SHOW ROLES \u8bed\u6cd5 \u00b6 SHOW ROLES IN <space_name>> SHOW ROLES \u8bed\u53e5\u663e\u793a\u5206\u914d\u7ed9\u7528\u6237\u8d26\u6237\u7684\u89d2\u8272\u3002 SHOW ROLES \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a\u7528\u6237\u8d26\u6237\u548c\u89d2\u8272\u7c7b\u578b\u3002","title":"SHOW ROLES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-roles-syntax/#show_roles","text":"SHOW ROLES IN <space_name>> SHOW ROLES \u8bed\u53e5\u663e\u793a\u5206\u914d\u7ed9\u7528\u6237\u8d26\u6237\u7684\u89d2\u8272\u3002 SHOW ROLES \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a\u7528\u6237\u8d26\u6237\u548c\u89d2\u8272\u7c7b\u578b\u3002","title":"SHOW ROLES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-snapshots-syntax/","text":"SHOW SNAPSHOTS \u8bed\u6cd5 \u00b6 SHOW SNAPSHOTS SHOW SNAPSHOTS \u8bed\u53e5\u8fd4\u56de\u6240\u6709\u5feb\u7167\u3002","title":"SHOW SNAPSHOTS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-snapshots-syntax/#show_snapshots","text":"SHOW SNAPSHOTS SHOW SNAPSHOTS \u8bed\u53e5\u8fd4\u56de\u6240\u6709\u5feb\u7167\u3002","title":"SHOW SNAPSHOTS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-spaces-syntax/","text":"SHOW SPACES \u8bed\u6cd5 \u00b6 SHOW SPACES SHOW SPACES \u5217\u51fa Nebula Graph \u96c6\u7fa4\u4e2d\u7684\u6240\u6709\u56fe\u7a7a\u95f4\u3002","title":"SHOW SPACES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-spaces-syntax/#show_spaces","text":"SHOW SPACES SHOW SPACES \u5217\u51fa Nebula Graph \u96c6\u7fa4\u4e2d\u7684\u6240\u6709\u56fe\u7a7a\u95f4\u3002","title":"SHOW SPACES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-tags-edges-syntax/","text":"SHOW TAGS/EDGES \u8bed\u6cd5 \u00b6 SHOW {TAGS | EDGES} SHOW TAGS \u548c SHOW EDGES \u5219\u8fd4\u56de\u5f53\u524d\u56fe\u7a7a\u95f4\u4e2d\u88ab\u5b9a\u4e49\u7684 tag \u548c edge type\u3002","title":"SHOW TAGS/EDGES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-tags-edges-syntax/#show_tagsedges","text":"SHOW {TAGS | EDGES} SHOW TAGS \u548c SHOW EDGES \u5219\u8fd4\u56de\u5f53\u524d\u56fe\u7a7a\u95f4\u4e2d\u88ab\u5b9a\u4e49\u7684 tag \u548c edge type\u3002","title":"SHOW TAGS/EDGES \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-users-syntax/","text":"SHOW USERS \u8bed\u6cd5 \u00b6 SHOW USERS SHOW USERS \u8bed\u53e5\u663e\u793a\u7528\u6237\u4fe1\u606f\u3002 SHOW USERS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a\u8d26\u6237\u540d\u3002","title":"SHOW USERS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-users-syntax/#show_users","text":"SHOW USERS SHOW USERS \u8bed\u53e5\u663e\u793a\u7528\u6237\u4fe1\u606f\u3002 SHOW USERS \u8f93\u51fa\u4ee5\u4e0b\u5217\uff1a\u8d26\u6237\u540d\u3002","title":"SHOW USERS \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/","text":"FIND PATH \u8bed\u6cd5 \u00b6 FIND PATH \u8bed\u6cd5\u7528\u4e8e\u83b7\u53d6\u6700\u77ed\u8def\u5f84\u53ca\u5168\u8def\u5f84\u3002 FIND SHORTEST | ALL PATH FROM <vertex_id_list> TO <vertex_id_list> OVER <edge_type_list> [UPTO <N> STEPS] SHORTEST \u5bfb\u627e\u6700\u77ed\u8def\u5f84\u5173\u952e\u8bcd\u3002 ALL \u5bfb\u627e\u5168\u8def\u5f84\u5173\u952e\u8bcd\u3002 <vertex_id_list>::=[vertex_id [, vertex_id]] \u4e3a\u8282\u70b9\u5217\u8868\uff0c\u7528\u9017\u53f7\u9694\u5f00\u3002\u652f\u6301\u8f93\u5165 $- \u53ca\u53d8\u91cf $var \u3002 <edge_type_list> \u6307\u5b9a\u8fb9\u7684\u7c7b\u578b\uff0c\u591a\u79cd\u8fb9\u7c7b\u578b\u7528 , \u9694\u5f00\uff0c\u7528 * \u8868\u793a\u6240\u6709\u8fb9\u7c7b\u578b\u3002 <N> \u4e3a\u8df3\u6570\uff0c\u9ed8\u8ba4\u503c 5\u3002 \u6ce8\u610f\u4e8b\u9879 \u00b6 \u5f53\u8d77\u70b9\u53ca\u7ec8\u70b9\u662f ID \u5217\u8868\u65f6\uff0c\u8868\u793a\u5bfb\u627e\u4ece\u4efb\u610f\u8d77\u70b9\u5f00\u59cb\u5230\u7ec8\u70b9\u7684\u6700\u77ed\u8def\u5f84\u3002 \u5168\u8def\u5f84\u4f1a\u6709\u73af\u3002 \u793a\u4f8b \u00b6 \u5728 console \u4e2d\uff0c\u8def\u5f84\u663e\u793a\u65b9\u5f0f\u4e3a id <edge_name, ranking> id \u3002 nebula> FIND SHORTEST PATH FROM 100 to 200 OVER *; ============================= | _path_ | ============================= | 100 <serve,0> 200 ----------------------------- nebula> FIND ALL PATH FROM 100 to 200 OVER *; ============================================================================================================= | _path_ | ============================================================================================================= | 100 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 101 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 102 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 106 < serve,0> 200 -------------------------------------------------------------------------------------------------------------","title":"FIND PATH \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/#find_path","text":"FIND PATH \u8bed\u6cd5\u7528\u4e8e\u83b7\u53d6\u6700\u77ed\u8def\u5f84\u53ca\u5168\u8def\u5f84\u3002 FIND SHORTEST | ALL PATH FROM <vertex_id_list> TO <vertex_id_list> OVER <edge_type_list> [UPTO <N> STEPS] SHORTEST \u5bfb\u627e\u6700\u77ed\u8def\u5f84\u5173\u952e\u8bcd\u3002 ALL \u5bfb\u627e\u5168\u8def\u5f84\u5173\u952e\u8bcd\u3002 <vertex_id_list>::=[vertex_id [, vertex_id]] \u4e3a\u8282\u70b9\u5217\u8868\uff0c\u7528\u9017\u53f7\u9694\u5f00\u3002\u652f\u6301\u8f93\u5165 $- \u53ca\u53d8\u91cf $var \u3002 <edge_type_list> \u6307\u5b9a\u8fb9\u7684\u7c7b\u578b\uff0c\u591a\u79cd\u8fb9\u7c7b\u578b\u7528 , \u9694\u5f00\uff0c\u7528 * \u8868\u793a\u6240\u6709\u8fb9\u7c7b\u578b\u3002 <N> \u4e3a\u8df3\u6570\uff0c\u9ed8\u8ba4\u503c 5\u3002","title":"FIND PATH \u8bed\u6cd5"},{"location":"manual-CN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/#_1","text":"\u5f53\u8d77\u70b9\u53ca\u7ec8\u70b9\u662f ID \u5217\u8868\u65f6\uff0c\u8868\u793a\u5bfb\u627e\u4ece\u4efb\u610f\u8d77\u70b9\u5f00\u59cb\u5230\u7ec8\u70b9\u7684\u6700\u77ed\u8def\u5f84\u3002 \u5168\u8def\u5f84\u4f1a\u6709\u73af\u3002","title":"\u6ce8\u610f\u4e8b\u9879"},{"location":"manual-CN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/#_2","text":"\u5728 console \u4e2d\uff0c\u8def\u5f84\u663e\u793a\u65b9\u5f0f\u4e3a id <edge_name, ranking> id \u3002 nebula> FIND SHORTEST PATH FROM 100 to 200 OVER *; ============================= | _path_ | ============================= | 100 <serve,0> 200 ----------------------------- nebula> FIND ALL PATH FROM 100 to 200 OVER *; ============================================================================================================= | _path_ | ============================================================================================================= | 100 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 101 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 102 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 106 < serve,0> 200 -------------------------------------------------------------------------------------------------------------","title":"\u793a\u4f8b"},{"location":"manual-CN/3.build-develop-and-administration/0.README/","text":"\u9762\u5411\u7684\u8bfb\u8005 \u00b6 \u672c\u7ae0\u4ecb\u7ecd\u5982\u4f55\u7f16\u8bd1\u3001\u90e8\u7f72\u548c\u8fd0\u7ef4\uff0c\u9762\u5411\u7a0b\u5e8f\u5458\u548c DBA\u3002","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/3.build-develop-and-administration/0.README/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd\u5982\u4f55\u7f16\u8bd1\u3001\u90e8\u7f72\u548c\u8fd0\u7ef4\uff0c\u9762\u5411\u7a0b\u5e8f\u5458\u548c DBA\u3002","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/","text":"\u4f7f\u7528\u6e90\u7801\u7f16\u8bd1 \u00b6 \u524d\u8a00 \u00b6 \u6211\u4eec\u5df2\u7ecf\u9488\u5bf9\u591a\u79cd\u4e0d\u540c\u7684\u73af\u5883\u505a\u8fc7\u7f16\u8bd1\u6d4b\u8bd5\uff0c\u5305\u62ec CentOS 6/7/8\u3001Ubuntu 16.04/18.04/19.04\u3001Fedora 28/29/30\u3001GCC 7/8/9 \u4ee5\u53ca\u8f83\u65b0\u7248\u672c\u7684 LLVM/Clang\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7f16\u8bd1\u73af\u5883\u53ca\u4f9d\u8d56\u7684\u590d\u6742\u6027\uff0c\u5f88\u96be\u4fdd\u8bc1\u8986\u76d6\u5230\u6240\u6709\u573a\u666f\u3002\u5982\u679c\u5728\u7f16\u8bd1\u8fc7\u7a0b\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u6b22\u8fce\u901a\u8fc7 Issue \u6216\u8005 Pull Request \u8054\u7cfb\u6211\u4eec\u3002 \u7cfb\u7edf\u8981\u6c42 \u00b6 \u5904\u7406\u5668: x86_64 \u5185\u5b58: \u81f3\u5c11 4GB \u5b58\u50a8\u7a7a\u95f4: \u81f3\u5c11 10GB Linux \u5185\u6838: 2.3.32 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 uname -r \u67e5\u770b glibc: 2.12 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 ldd --version \u67e5\u770b GCC: 7.1.0 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 g++ --version \u67e5\u770b CMake: 3.5.0 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 cmake --version \u67e5\u770b \u80fd\u591f\u8bbf\u95ee\u4e92\u8054\u7f51 \u6ce8\u610f : Nebula Graph \u76ee\u524d\u4ec5\u652f\u6301 x86_64 \u67b6\u6784\u3002 \u5feb\u901f\u7f16\u8bd1\u6b65\u9aa4 \u00b6 \u5b89\u88c5\u7cfb\u7edf\u4f9d\u8d56 \u00b6 \u8bf7\u6ce8\u610f\uff0c\u5b89\u88c5\u7cfb\u7edf\u4f9d\u8d56\u9700\u8981 root \u6743\u9650\u3002 CentOS\uff0cRedHat \u548c Fedora \u7528\u6237\u53ef\u4ee5\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\uff1a $ yum update $ yum install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz \\ readline-devel \\ ncurses-devel \\ zlib-devel \\ gcc \\ gcc-c++ \\ cmake \\ gettext \\ curl \\ redhat-lsb-core # CentOS 8+\uff0cRedHat 8+ \u4ee5\u53ca Fedora \u7528\u6237\uff0c\u9700\u8981\u989d\u5916\u5b89\u88c5 libstdc++-static \u548c libasan $ yum install -y libstdc++-static libasan Debian \u53ca Ubuntu \u7528\u6237\uff0c\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\uff1a $ apt-get update $ apt-get install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz-utils \\ curl \\ lsb-core \\ build-essential \\ libreadline-dev \\ ncurses-dev \\ cmake \\ gettext ArchLinux\u3001Gentoo \u6216\u8005 LFS \u7528\u6237\u8bf7\u81ea\u884c\u5b89\u88c5\u3002 \u5728\u5f00\u59cb\u7f16\u8bd1\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u7f16\u8bd1\u5668\u548c CMake \u7248\u672c\u6ee1\u8db3\u8981\u6c42\uff1a $ g++ --version $ cmake --version \u5426\u5219\uff0c\u8bf7\u5206\u522b\u53c2\u8003 \u5b89\u88c5 GCC \u6216 \u5b89\u88c5 CMake \u8fdb\u884c\u64cd\u4f5c\u3002 \u514b\u9686\u6e90\u7801 \u00b6 $ git clone https://github.com/vesoft-inc/nebula.git \u5982\u679c\u4e0d\u5173\u5fc3\u4ee3\u7801\u4ed3\u5e93\u7684\u5386\u53f2\u63d0\u4ea4\u4fe1\u606f\uff0c\u60a8\u53ef\u8fdb\u884c_\u6d45\u514b\u9686_\uff08Shallow clone\uff09\u4ee5\u52a0\u5feb\u4e0b\u8f7d\u901f\u5ea6\uff1a $ git clone --depth = 1 https://github.com/vesoft-inc/nebula.git \u6267\u884c\u7f16\u8bd1 \u00b6 $ cd nebula $ mkdir build $ cd build $ cmake -DENABLE_TESTING = OFF -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = $PWD /install .. # \u5047\u8bbe cores \u4e3a\u6838\u6570\uff0cmem_gb \u4e3a\u5185\u5b58\u5927\u5c0f\uff08\u5355\u4f4d\u4e3a GB\uff09\uff0cN \u53d6\u503c\u5efa\u8bae\u4e3a cores \u548c mem_gb/2 \u4e2d\u7684\u8f83\u5c0f\u503c # Build type \u5efa\u8bae\u9009\u62e9 release \u4ee5\u52a0\u5feb\u7f16\u8bd1\u901f\u5ea6 $ make -jN $ make install $ ls install/ etc/ bin/ share/ scripts/ \u7531\u4e8e Nebula Graph \u4f7f\u7528\u4e86\u5927\u91cf\u7684 C++ \u6a21\u677f\uff0c\u5c24\u5176\u662f Folly\uff0cfbthrift \u548c boost\uff0c\u56e0\u6b64\u7f16\u8bd1\u4f1a\u975e\u5e38\u8017\u65f6\u3002\u6bd4\u5982\uff0c\u5982\u679c\u4f7f\u7528 Intel E5-2697 v3 \u5904\u7406\u5668\uff0c\u5728 16 \u4e2a\u4efb\u52a1\u5e76\u53d1\u8fd0\u884c\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u82b1\u8d39\u5927\u7ea6 4 \u5206\u949f\u5b8c\u6210\u7f16\u8bd1\uff0c\u603b\u7684 CPU \u65f6\u95f4\u5927\u7ea6 35 \u5206\u949f\u3002 \u542f\u52a8 Nebula Graph \u670d\u52a1 \u00b6 \u5728\u7f16\u8bd1\u5b89\u88c5 Nebula Graph \u540e\uff0c\u53ef\u4ee5\u542f\u52a8 Nebula Graph \u670d\u52a1\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c Nebula Graph \u5b89\u88c5\u5728 /home/username/nebula/build/install \u8def\u5f84\u4e0b\uff0c\u5176\u4e2d username \u9700\u8981\u66ff\u6362\u6210\u60a8\u81ea\u5df1\u7684\u7528\u6237\u540d\u3002 \u628a\u60a8\u5f53\u524d\u7684\u8def\u5f84\u5207\u6362\u5230 Nebula Graph \u7684\u5b89\u88c5\u8def\u5f84\u4e0b\u3002 $ cd /home/username/nebula/build/install \u91cd\u547d\u540d Nebula Graph \u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6\u3002 $ cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf $ cp etc/nebula-metad.conf.default etc/nebula-metad.conf $ cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf \u542f\u52a8 Nebula Graph \u670d\u52a1\u3002 $ ./scripts/nebula.service start all \u8fde\u63a5\u5230 Nebula Graph \u670d\u52a1\u3002 $ ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u6210\u529f\u8fde\u63a5\u5230 Nebula Graph \u670d\u52a1\uff0c\u5219\u53ef\u4ee5\u770b\u5230 Welcome to Nebula Graph \u4fe1\u606f\uff0c\u5e76\u81ea\u52a8\u8fdb\u5165\u5230 ngql \u547d\u4ee4\u884c\u754c\u9762\u3002 \u7f16\u8bd1\u9009\u9879 \u00b6 \u9664\u9ed8\u8ba4\u9009\u9879\u5916\uff0c Nebula Graph \u7684\u7f16\u8bd1\u7cfb\u7edf\u8fd8\u63d0\u4f9b\u8bf8\u591a\u9009\u9879\u6765\u8c03\u6574\u7f16\u8bd1\u884c\u4e3a\u3002 CMake \u53c2\u6570 \u00b6 \u53ef\u901a\u8fc7 cmake -DArgument=Value .. \u8c03\u6574 CMake \u53c2\u6570\u3002 ENABLE_WERROR \u00b6 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c Nebula Graph \u4f7f\u7528 -Werror \u9009\u9879\u5c06\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u7684\u544a\u8b66\u5f53\u6210\u9519\u8bef\u3002\u5982\u679c\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u9047\u5230\u4e86\u7c7b\u4f3c\u60c5\u51b5\uff0c\u53ef\u4ee5\u901a\u8fc7\u5c06 ENABLE_WERROR \u8bbe\u7f6e\u4e3a OFF \u6765\u6682\u65f6\u5ffd\u7565\u6b64\u7c7b\u9519\u8bef\u3002 ENABLE_TESTING \u00b6 \u8be5\u9009\u9879\u5141\u8bb8\u7528\u6237\u5f00\u542f\u6216\u5173\u95ed\u5355\u5143\u6d4b\u8bd5\u7684\u7f16\u8bd1\uff0c\u9ed8\u8ba4\u5f00\u542f\u3002\u5982\u679c\u60a8\u53ea\u9700\u8981\u7f16\u8bd1 Nebula Graph \u670d\u52a1\u6a21\u5757\uff0c\u53ef\u4ee5\u5c06\u8be5\u9009\u9879\u8bbe\u7f6e\u4e3a OFF \u3002 ENABLE_ASAN \u00b6 \u8be5\u9009\u9879\u5141\u8bb8\u7528\u6237\u5f00\u542f\u6216\u5173\u95ed AddressSanitizer\uff08\u5185\u5b58\u76f8\u5173\u9519\u8bef\u68c0\u6d4b\u5668\uff09\uff0c\u9ed8\u8ba4\u5173\u95ed\u3002 CMAKE_BUILD_TYPE \u00b6 Nebula Graph \u652f\u6301\u4ee5\u4e0b\u51e0\u79cd\u7f16\u8bd1\u7c7b\u578b\uff1a Debug \uff0c\u542f\u7528\u8c03\u8bd5\u4fe1\u606f\uff0c\u4e0d\u542f\u7528\u4f18\u5316\u9009\u9879\uff0c\u4e3a\u9ed8\u8ba4\u7f16\u8bd1\u7c7b\u578b Release \uff0c\u542f\u7528\u4f18\u5316\u9009\u9879\uff0c\u4e0d\u542f\u7528\u8c03\u8bd5\u4fe1\u606f RelWithDebInfo \uff0c\u542f\u7528\u4f18\u5316\u9009\u9879\uff0c\u4e14\u542f\u7528\u8c03\u8bd5\u4fe1\u606f MinSizeRel \uff0c\u542f\u7528\u5229\u4e8e\u51cf\u5c0f\u4ee3\u7801\u4f53\u79ef\u7684\u4f18\u5316\u9009\u9879\uff0c\u4e0d\u542f\u7528\u8c03\u8bd5\u4fe1\u606f CMAKE_INSTALL_PREFIX \u00b6 \u8be5\u9009\u9879\u7528\u4e8e\u6307\u5b9a\u6267\u884c make install \u547d\u4ee4\u65f6\uff0c Nebula Graph \u7684\u670d\u52a1\u6a21\u5757\u3001\u914d\u7f6e\u6587\u4ef6\u4ee5\u53ca\u5de5\u5177\u96c6\u7684\u5b89\u88c5\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a /usr/local/nebula \u3002 CMAKE_CXX_COMPILER \u00b6 \u901a\u5e38\u60c5\u51b5\u4e0b\uff0cCMake \u4f1a\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u7f16\u8bd1\u5668\u3002\u4f46\u662f\uff0c\u5982\u679c\u76ee\u6807\u7f16\u8bd1\u5668\u4e0d\u5728\u9ed8\u8ba4\u7684\u6807\u51c6\u8def\u5f84\u4e0b\uff0c\u6216\u8005\u4f60\u60f3\u4f7f\u7528\u5176\u4ed6\u79cd\u7c7b\u6216\u8def\u5f84\u4e0b\u7684\u7f16\u8bd1\u5668\uff0c\u8bf7\u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\u6307\u5b9a\uff1a $ cmake -DCMAKE_C_COMPILER = /path/to/gcc/bin/gcc -DCMAKE_CXX_COMPILER = /path/to/gcc/bin/g++ .. $ cmake -DCMAKE_C_COMPILER = /path/to/clang/bin/clang -DCMAKE_CXX_COMPILER = /path/to/clang/bin/clang++ .. ENABLE_CCACHE \u00b6 ccache \u53ef\u4ee5\u52a0\u5feb\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u4e3b\u8981\u7528\u4e8e\u5f00\u53d1\u8fc7\u7a0b\u3002\u5982\u679c\u7cfb\u7edf\u4e2d\u5b89\u88c5\u4e86 ccache \uff0c Nebula Graph \u9ed8\u8ba4\u4f1a\u81ea\u52a8\u542f\u7528\u8be5\u9009\u9879\u3002 \u4f46\u662f\uff0c\u5982\u679c\u4f60\u60f3\u7981\u7528 ccache \uff0c\u5c06\u8be5\u9009\u9879\u8bbe\u7f6e\u6210 OFF \u53ef\u80fd \u662f\u4e0d\u591f\u7684\u3002\u56e0\u4e3a\uff0c\u5728\u67d0\u4e9b\u7cfb\u7edf\u4e2d\uff0c ccache \u4f1a_\u4ee3\u7406_ \u5f53\u524d\u7f16\u8bd1\u5668\u3002\u6b64\u65f6\uff0c\u9700\u8981\u901a\u8fc7\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf export CCACHE_DISABLE=true \uff0c\u6216\u8005\u5728 ~/.ccache/ccache.conf \u6587\u4ef6\u4e2d\u6dfb\u52a0 disable=true \u3002\u540e\u7eed Nebula Graph \u5c06\u9690\u85cf\u8fd9\u4e9b\u7ec6\u8282\u3002 \u53e6\u5916\uff0c\u5173\u4e8e ccache \u7684\u66f4\u591a\u7ec6\u8282\uff0c\u8bf7\u53c2\u8003 \u5b98\u65b9\u6587\u6863 \u3002 NEBULA_USE_LINKER \u00b6 \u8be5\u9009\u9879\u5141\u8bb8\u6211\u4eec\u4f7f\u7528\u4e0d\u540c\u7684\u94fe\u63a5\u5668\u3002\u76ee\u524d\u53ef\u7528\u7684\u9009\u9879\u662f\uff1a bfd \uff0c gold \uff0c lld \u3002\u5176\u4e2d\uff0c bfd \u548c gold \u96b6\u5c5e\u4e8e GNU binutils\uff0c lld \u5219\u9700\u8981\u5b89\u88c5 LLVM/Clang\u3002\u6b64\u5916\uff0c\u5982\u679c\u9700\u8981\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528\u8be5\u53c2\u6570\u6307\u5b9a\u94fe\u63a5\u5668\u7684\u7edd\u5bf9\u8def\u5f84\u3002 NEBULA_THIRDPARTY_ROOT \u00b6 \u8be5\u9009\u9879\u7528\u4e8e\u663e\u5f0f\u6307\u5b9a third party \u6240\u5728\u8def\u5f84\u3002 \u624b\u52a8\u5b89\u88c5 Third Party \u00b6 \u5728 configure/cmake \u9636\u6bb5\uff0c Nebula Graph \u9ed8\u8ba4\u5c06\u9884\u5148\u7f16\u8bd1\u597d\u7684 third party \u4e0b\u8f7d\u5230\u5f53\u524d build \u76ee\u5f55\u3002\u4f46\u662f\u5982\u679c\u4f60\u60f3\u5c06\u5176\u5b89\u88c5\u5230\u5176\u4ed6\u8def\u5f84\uff08\u6bd4\u5982\uff0c\u5b89\u88c5\u5230\u67d0\u4e2a\u516c\u5171\u76ee\u5f55\uff09\uff0c\u4f60\u53ef\u4ee5\uff1a # \u5b89\u88c5 third party \u81f3 /opt \u9700\u8981 root \u6743\u9650\uff0c\u53ef\u4f7f\u7528 --prefix \u6539\u53d8\u5b89\u88c5\u8def\u5f84 $ ../third-party/install-third-party.sh --prefix = /opt/vesoft/third-party \u5982\u679c\u4e0d\u6307\u5b9a --prefix \uff0cthird party \u7684\u9ed8\u8ba4\u5b89\u88c5\u8def\u5f84\u4e3a /opt/vesoft/third-party \uff0c\u4e14\u53ef\u4e3a Nebula Graph \u7684\u7f16\u8bd1\u7cfb\u7edf\u81ea\u52a8\u627e\u5230\u3002\u5426\u5219\uff0c\u9700\u4f7f\u7528\u4e0a\u6587\u6240\u8ff0\u7684 NEBULA_THIRDPARTY_ROOT CMake \u53c2\u6570\u6307\u5b9a\u8def\u5f84\uff0c\u6216\u4e3a\u8be5\u8def\u5f84\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u5e76\u5bfc\u51fa\u3002 Nebula Graph \u67e5\u627e\u5e76\u9009\u62e9 third party \u7684\u4f18\u5148\u7ea7\u5982\u4e0b\uff1a CMake \u53d8\u91cf NEBULA_THIRDPARTY_ROOT build \u8def\u5f84\u4e0b\u7684 third-party/install NEBULA_THIRDPARTY_ROOT \u73af\u5883\u53d8\u91cf /opt/vesoft/third-party \u5b89\u88c5\u53ef\u7528\u7684 CMake \u00b6 \u5bf9\u4e8e\u6ca1\u6709\u53ef\u7528 CMake \u5b89\u88c5\u7684\u7528\u6237\uff0c \u6211\u4eec\u63d0\u4f9b\u4e86\u53ef\u81ea\u52a8\u4e0b\u8f7d\u5b89\u88c5\u7684\u811a\u672c\u3002\u5728 build \u76ee\u5f55\u4e0b\uff0c\u8fd0\u884c\uff1a $ ../third-party/install-cmake.sh cmake-install CMake has been installed to prefix = cmake-install Run 'source cmake-install/bin/enable-cmake.sh' to make it ready to use. Run 'source cmake-install/bin/disable-cmake.sh' to disable it. $ source cmake-install/bin/enable-cmake.sh $ cmake --version cmake version 3 .15.5 \u6b64\u65f6\u53ef\u7528\u7684 CMake \u5df2\u5b89\u88c5\u5b8c\u6210\u3002\u4f60\u53ef\u4ee5\u5728\u4efb\u4f55\u65f6\u5019\u4f7f\u7528 source cmake-install/bin/disable-cmake.sh \u547d\u4ee4\u5c06\u5176\u7981\u7528\u3002 \u5b89\u88c5\u53ef\u7528\u7684 GCC \u00b6 \u5bf9\u4e8e\u6ca1\u6709\u53ef\u7528 GCC \u5b89\u88c5\u7684\u7528\u6237\uff0c \u6211\u4eec\u63d0\u4f9b\u4e86 GCC \u548c\u53ef\u81ea\u52a8\u4e0b\u8f7d\u5b89\u88c5\u7684\u811a\u672c\u3002\u5728 build \u76ee\u5f55\u4e0b\uff0c\u8fd0\u884c\uff1a # \u5c06 GCC \u5b89\u88c5\u81f3 /opt \u9700\u8981 root \u6743\u9650\uff0c\u652f\u6301\u66f4\u6539\u5b89\u88c5\u8def\u5f84 $ ../third-party/install-gcc.sh --prefix = /opt GCC-7.5.0 has been installed to /opt/vesoft/toolset/gcc/7.5.0 Performing usability tests Performing regular C++14 tests...OK Performing LeakSanitizer tests...OK Run 'source /opt/vesoft/toolset/gcc/7.5.0/enable' to start using. Run 'source /opt/vesoft/toolset/gcc/7.5.0/disable' to stop using. # \u6ce8\u610f\u8def\u5f84\u548c\u6307\u5b9a\u7248\u672c\u53ef\u80fd\u4e0e\u4f60\u7684\u73af\u5883\u4e0d\u540c $ source /opt/vesoft/toolset/gcc/7.5.0/enable # \u6b64\u5904\u4ec5\u8bbe\u7f6e\u4e86 PATH\uff0c\u4ee5\u514d\u6c61\u67d3\u5e93\u8def\u5f84 # \u5982\u679c\u9700\u8981\u53ef\u8fd0\u884c 'export LD_LIBRARY_PATH=/opt/vesoft/toolset/gcc/7.5.0/lib64:$LD_LIBRARY_PATH' $ g++ --version g++ ( Nebula Graph Build ) 7 .5.0 Copyright ( C ) 2017 Free Software Foundation, Inc. \u6b64\u65f6\u53ef\u7528\u7684 GCC \u7f16\u8bd1\u5668\u5df2\u5b89\u88c5\u5b8c\u6210\u3002\u4f60\u53ef\u4ee5\u5728\u4efb\u4f55\u65f6\u5019\u4f7f\u7528 source /opt/vesoft/toolset/gcc/7.5.0/disable \u547d\u4ee4\u5c06\u5176\u7981\u7528\u3002 FAQ \u00b6 error: invalid argument type 'auto' to unary expression \u00b6 \u5f53\u4f7f\u7528 Clang 9.0 \u7f16\u8bd1 Nebula Graph \u65f6\uff0c\u4f1a\u53d1\u751f\u8be5\u9519\u8bef\uff1a [ 5 % ] Building CXX object src/common/fs/CMakeFiles/fs_obj.dir/FileUtils.cpp.o In file included from src/common/fs/FileUtils.cpp:8: In file included from src/common/fs/FileUtils.h:12: src/common/base/StatusOr.h:57:19: error: invalid argument type 'auto' to unary expression static_assert ( !is_status_v<T>, \"`T' must not be of type `Status'\" ) ; ^~~~~~~~~~~~~~~ src/common/fs/FileUtils.cpp:90:34: note: in instantiation of template class 'nebula::StatusOr<std::__cxx11::basic_string<char> >' requested here StatusOr<std::string> FileUtils::readLink ( const char *path ) { ... \u8fd9\u662f Clang 9.0 \u5f15\u5165\u7684\u4e00\u4e2a\u5df2\u77e5\u7684 Bug\uff0c\u76ee\u524d\uff082020-01-20\uff09\u5c1a\u672a\u4fee\u590d\u3002","title":"\u4f7f\u7528\u6e90\u7801\u7f16\u8bd1"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_1","text":"","title":"\u4f7f\u7528\u6e90\u7801\u7f16\u8bd1"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_2","text":"\u6211\u4eec\u5df2\u7ecf\u9488\u5bf9\u591a\u79cd\u4e0d\u540c\u7684\u73af\u5883\u505a\u8fc7\u7f16\u8bd1\u6d4b\u8bd5\uff0c\u5305\u62ec CentOS 6/7/8\u3001Ubuntu 16.04/18.04/19.04\u3001Fedora 28/29/30\u3001GCC 7/8/9 \u4ee5\u53ca\u8f83\u65b0\u7248\u672c\u7684 LLVM/Clang\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7f16\u8bd1\u73af\u5883\u53ca\u4f9d\u8d56\u7684\u590d\u6742\u6027\uff0c\u5f88\u96be\u4fdd\u8bc1\u8986\u76d6\u5230\u6240\u6709\u573a\u666f\u3002\u5982\u679c\u5728\u7f16\u8bd1\u8fc7\u7a0b\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u6b22\u8fce\u901a\u8fc7 Issue \u6216\u8005 Pull Request \u8054\u7cfb\u6211\u4eec\u3002","title":"\u524d\u8a00"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_3","text":"\u5904\u7406\u5668: x86_64 \u5185\u5b58: \u81f3\u5c11 4GB \u5b58\u50a8\u7a7a\u95f4: \u81f3\u5c11 10GB Linux \u5185\u6838: 2.3.32 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 uname -r \u67e5\u770b glibc: 2.12 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 ldd --version \u67e5\u770b GCC: 7.1.0 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 g++ --version \u67e5\u770b CMake: 3.5.0 \u6216\u66f4\u9ad8\u7248\u672c\uff0c\u901a\u8fc7\u547d\u4ee4 cmake --version \u67e5\u770b \u80fd\u591f\u8bbf\u95ee\u4e92\u8054\u7f51 \u6ce8\u610f : Nebula Graph \u76ee\u524d\u4ec5\u652f\u6301 x86_64 \u67b6\u6784\u3002","title":"\u7cfb\u7edf\u8981\u6c42"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_4","text":"","title":"\u5feb\u901f\u7f16\u8bd1\u6b65\u9aa4"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_5","text":"\u8bf7\u6ce8\u610f\uff0c\u5b89\u88c5\u7cfb\u7edf\u4f9d\u8d56\u9700\u8981 root \u6743\u9650\u3002 CentOS\uff0cRedHat \u548c Fedora \u7528\u6237\u53ef\u4ee5\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\uff1a $ yum update $ yum install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz \\ readline-devel \\ ncurses-devel \\ zlib-devel \\ gcc \\ gcc-c++ \\ cmake \\ gettext \\ curl \\ redhat-lsb-core # CentOS 8+\uff0cRedHat 8+ \u4ee5\u53ca Fedora \u7528\u6237\uff0c\u9700\u8981\u989d\u5916\u5b89\u88c5 libstdc++-static \u548c libasan $ yum install -y libstdc++-static libasan Debian \u53ca Ubuntu \u7528\u6237\uff0c\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\uff1a $ apt-get update $ apt-get install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz-utils \\ curl \\ lsb-core \\ build-essential \\ libreadline-dev \\ ncurses-dev \\ cmake \\ gettext ArchLinux\u3001Gentoo \u6216\u8005 LFS \u7528\u6237\u8bf7\u81ea\u884c\u5b89\u88c5\u3002 \u5728\u5f00\u59cb\u7f16\u8bd1\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u7f16\u8bd1\u5668\u548c CMake \u7248\u672c\u6ee1\u8db3\u8981\u6c42\uff1a $ g++ --version $ cmake --version \u5426\u5219\uff0c\u8bf7\u5206\u522b\u53c2\u8003 \u5b89\u88c5 GCC \u6216 \u5b89\u88c5 CMake \u8fdb\u884c\u64cd\u4f5c\u3002","title":"\u5b89\u88c5\u7cfb\u7edf\u4f9d\u8d56"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_6","text":"$ git clone https://github.com/vesoft-inc/nebula.git \u5982\u679c\u4e0d\u5173\u5fc3\u4ee3\u7801\u4ed3\u5e93\u7684\u5386\u53f2\u63d0\u4ea4\u4fe1\u606f\uff0c\u60a8\u53ef\u8fdb\u884c_\u6d45\u514b\u9686_\uff08Shallow clone\uff09\u4ee5\u52a0\u5feb\u4e0b\u8f7d\u901f\u5ea6\uff1a $ git clone --depth = 1 https://github.com/vesoft-inc/nebula.git","title":"\u514b\u9686\u6e90\u7801"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_7","text":"$ cd nebula $ mkdir build $ cd build $ cmake -DENABLE_TESTING = OFF -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = $PWD /install .. # \u5047\u8bbe cores \u4e3a\u6838\u6570\uff0cmem_gb \u4e3a\u5185\u5b58\u5927\u5c0f\uff08\u5355\u4f4d\u4e3a GB\uff09\uff0cN \u53d6\u503c\u5efa\u8bae\u4e3a cores \u548c mem_gb/2 \u4e2d\u7684\u8f83\u5c0f\u503c # Build type \u5efa\u8bae\u9009\u62e9 release \u4ee5\u52a0\u5feb\u7f16\u8bd1\u901f\u5ea6 $ make -jN $ make install $ ls install/ etc/ bin/ share/ scripts/ \u7531\u4e8e Nebula Graph \u4f7f\u7528\u4e86\u5927\u91cf\u7684 C++ \u6a21\u677f\uff0c\u5c24\u5176\u662f Folly\uff0cfbthrift \u548c boost\uff0c\u56e0\u6b64\u7f16\u8bd1\u4f1a\u975e\u5e38\u8017\u65f6\u3002\u6bd4\u5982\uff0c\u5982\u679c\u4f7f\u7528 Intel E5-2697 v3 \u5904\u7406\u5668\uff0c\u5728 16 \u4e2a\u4efb\u52a1\u5e76\u53d1\u8fd0\u884c\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u82b1\u8d39\u5927\u7ea6 4 \u5206\u949f\u5b8c\u6210\u7f16\u8bd1\uff0c\u603b\u7684 CPU \u65f6\u95f4\u5927\u7ea6 35 \u5206\u949f\u3002","title":"\u6267\u884c\u7f16\u8bd1"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#nebula_graph","text":"\u5728\u7f16\u8bd1\u5b89\u88c5 Nebula Graph \u540e\uff0c\u53ef\u4ee5\u542f\u52a8 Nebula Graph \u670d\u52a1\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c Nebula Graph \u5b89\u88c5\u5728 /home/username/nebula/build/install \u8def\u5f84\u4e0b\uff0c\u5176\u4e2d username \u9700\u8981\u66ff\u6362\u6210\u60a8\u81ea\u5df1\u7684\u7528\u6237\u540d\u3002 \u628a\u60a8\u5f53\u524d\u7684\u8def\u5f84\u5207\u6362\u5230 Nebula Graph \u7684\u5b89\u88c5\u8def\u5f84\u4e0b\u3002 $ cd /home/username/nebula/build/install \u91cd\u547d\u540d Nebula Graph \u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6\u3002 $ cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf $ cp etc/nebula-metad.conf.default etc/nebula-metad.conf $ cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf \u542f\u52a8 Nebula Graph \u670d\u52a1\u3002 $ ./scripts/nebula.service start all \u8fde\u63a5\u5230 Nebula Graph \u670d\u52a1\u3002 $ ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u6210\u529f\u8fde\u63a5\u5230 Nebula Graph \u670d\u52a1\uff0c\u5219\u53ef\u4ee5\u770b\u5230 Welcome to Nebula Graph \u4fe1\u606f\uff0c\u5e76\u81ea\u52a8\u8fdb\u5165\u5230 ngql \u547d\u4ee4\u884c\u754c\u9762\u3002","title":"\u542f\u52a8 Nebula Graph \u670d\u52a1"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#_8","text":"\u9664\u9ed8\u8ba4\u9009\u9879\u5916\uff0c Nebula Graph \u7684\u7f16\u8bd1\u7cfb\u7edf\u8fd8\u63d0\u4f9b\u8bf8\u591a\u9009\u9879\u6765\u8c03\u6574\u7f16\u8bd1\u884c\u4e3a\u3002","title":"\u7f16\u8bd1\u9009\u9879"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake","text":"\u53ef\u901a\u8fc7 cmake -DArgument=Value .. \u8c03\u6574 CMake \u53c2\u6570\u3002","title":"CMake \u53c2\u6570"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_werror","text":"\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c Nebula Graph \u4f7f\u7528 -Werror \u9009\u9879\u5c06\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u7684\u544a\u8b66\u5f53\u6210\u9519\u8bef\u3002\u5982\u679c\u5728\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u9047\u5230\u4e86\u7c7b\u4f3c\u60c5\u51b5\uff0c\u53ef\u4ee5\u901a\u8fc7\u5c06 ENABLE_WERROR \u8bbe\u7f6e\u4e3a OFF \u6765\u6682\u65f6\u5ffd\u7565\u6b64\u7c7b\u9519\u8bef\u3002","title":"ENABLE_WERROR"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_testing","text":"\u8be5\u9009\u9879\u5141\u8bb8\u7528\u6237\u5f00\u542f\u6216\u5173\u95ed\u5355\u5143\u6d4b\u8bd5\u7684\u7f16\u8bd1\uff0c\u9ed8\u8ba4\u5f00\u542f\u3002\u5982\u679c\u60a8\u53ea\u9700\u8981\u7f16\u8bd1 Nebula Graph \u670d\u52a1\u6a21\u5757\uff0c\u53ef\u4ee5\u5c06\u8be5\u9009\u9879\u8bbe\u7f6e\u4e3a OFF \u3002","title":"ENABLE_TESTING"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_asan","text":"\u8be5\u9009\u9879\u5141\u8bb8\u7528\u6237\u5f00\u542f\u6216\u5173\u95ed AddressSanitizer\uff08\u5185\u5b58\u76f8\u5173\u9519\u8bef\u68c0\u6d4b\u5668\uff09\uff0c\u9ed8\u8ba4\u5173\u95ed\u3002","title":"ENABLE_ASAN"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_build_type","text":"Nebula Graph \u652f\u6301\u4ee5\u4e0b\u51e0\u79cd\u7f16\u8bd1\u7c7b\u578b\uff1a Debug \uff0c\u542f\u7528\u8c03\u8bd5\u4fe1\u606f\uff0c\u4e0d\u542f\u7528\u4f18\u5316\u9009\u9879\uff0c\u4e3a\u9ed8\u8ba4\u7f16\u8bd1\u7c7b\u578b Release \uff0c\u542f\u7528\u4f18\u5316\u9009\u9879\uff0c\u4e0d\u542f\u7528\u8c03\u8bd5\u4fe1\u606f RelWithDebInfo \uff0c\u542f\u7528\u4f18\u5316\u9009\u9879\uff0c\u4e14\u542f\u7528\u8c03\u8bd5\u4fe1\u606f MinSizeRel \uff0c\u542f\u7528\u5229\u4e8e\u51cf\u5c0f\u4ee3\u7801\u4f53\u79ef\u7684\u4f18\u5316\u9009\u9879\uff0c\u4e0d\u542f\u7528\u8c03\u8bd5\u4fe1\u606f","title":"CMAKE_BUILD_TYPE"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_install_prefix","text":"\u8be5\u9009\u9879\u7528\u4e8e\u6307\u5b9a\u6267\u884c make install \u547d\u4ee4\u65f6\uff0c Nebula Graph \u7684\u670d\u52a1\u6a21\u5757\u3001\u914d\u7f6e\u6587\u4ef6\u4ee5\u53ca\u5de5\u5177\u96c6\u7684\u5b89\u88c5\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a /usr/local/nebula \u3002","title":"CMAKE_INSTALL_PREFIX"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_cxx_compiler","text":"\u901a\u5e38\u60c5\u51b5\u4e0b\uff0cCMake \u4f1a\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u7f16\u8bd1\u5668\u3002\u4f46\u662f\uff0c\u5982\u679c\u76ee\u6807\u7f16\u8bd1\u5668\u4e0d\u5728\u9ed8\u8ba4\u7684\u6807\u51c6\u8def\u5f84\u4e0b\uff0c\u6216\u8005\u4f60\u60f3\u4f7f\u7528\u5176\u4ed6\u79cd\u7c7b\u6216\u8def\u5f84\u4e0b\u7684\u7f16\u8bd1\u5668\uff0c\u8bf7\u4f7f\u7528\u5982\u4e0b\u65b9\u5f0f\u6307\u5b9a\uff1a $ cmake -DCMAKE_C_COMPILER = /path/to/gcc/bin/gcc -DCMAKE_CXX_COMPILER = /path/to/gcc/bin/g++ .. $ cmake -DCMAKE_C_COMPILER = /path/to/clang/bin/clang -DCMAKE_CXX_COMPILER = /path/to/clang/bin/clang++ ..","title":"CMAKE_CXX_COMPILER"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_ccache","text":"ccache \u53ef\u4ee5\u52a0\u5feb\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u4e3b\u8981\u7528\u4e8e\u5f00\u53d1\u8fc7\u7a0b\u3002\u5982\u679c\u7cfb\u7edf\u4e2d\u5b89\u88c5\u4e86 ccache \uff0c Nebula Graph \u9ed8\u8ba4\u4f1a\u81ea\u52a8\u542f\u7528\u8be5\u9009\u9879\u3002 \u4f46\u662f\uff0c\u5982\u679c\u4f60\u60f3\u7981\u7528 ccache \uff0c\u5c06\u8be5\u9009\u9879\u8bbe\u7f6e\u6210 OFF \u53ef\u80fd \u662f\u4e0d\u591f\u7684\u3002\u56e0\u4e3a\uff0c\u5728\u67d0\u4e9b\u7cfb\u7edf\u4e2d\uff0c ccache \u4f1a_\u4ee3\u7406_ \u5f53\u524d\u7f16\u8bd1\u5668\u3002\u6b64\u65f6\uff0c\u9700\u8981\u901a\u8fc7\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf export CCACHE_DISABLE=true \uff0c\u6216\u8005\u5728 ~/.ccache/ccache.conf \u6587\u4ef6\u4e2d\u6dfb\u52a0 disable=true \u3002\u540e\u7eed Nebula Graph \u5c06\u9690\u85cf\u8fd9\u4e9b\u7ec6\u8282\u3002 \u53e6\u5916\uff0c\u5173\u4e8e ccache \u7684\u66f4\u591a\u7ec6\u8282\uff0c\u8bf7\u53c2\u8003 \u5b98\u65b9\u6587\u6863 \u3002","title":"ENABLE_CCACHE"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#nebula_use_linker","text":"\u8be5\u9009\u9879\u5141\u8bb8\u6211\u4eec\u4f7f\u7528\u4e0d\u540c\u7684\u94fe\u63a5\u5668\u3002\u76ee\u524d\u53ef\u7528\u7684\u9009\u9879\u662f\uff1a bfd \uff0c gold \uff0c lld \u3002\u5176\u4e2d\uff0c bfd \u548c gold \u96b6\u5c5e\u4e8e GNU binutils\uff0c lld \u5219\u9700\u8981\u5b89\u88c5 LLVM/Clang\u3002\u6b64\u5916\uff0c\u5982\u679c\u9700\u8981\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528\u8be5\u53c2\u6570\u6307\u5b9a\u94fe\u63a5\u5668\u7684\u7edd\u5bf9\u8def\u5f84\u3002","title":"NEBULA_USE_LINKER"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#nebula_thirdparty_root","text":"\u8be5\u9009\u9879\u7528\u4e8e\u663e\u5f0f\u6307\u5b9a third party \u6240\u5728\u8def\u5f84\u3002","title":"NEBULA_THIRDPARTY_ROOT"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#third_party","text":"\u5728 configure/cmake \u9636\u6bb5\uff0c Nebula Graph \u9ed8\u8ba4\u5c06\u9884\u5148\u7f16\u8bd1\u597d\u7684 third party \u4e0b\u8f7d\u5230\u5f53\u524d build \u76ee\u5f55\u3002\u4f46\u662f\u5982\u679c\u4f60\u60f3\u5c06\u5176\u5b89\u88c5\u5230\u5176\u4ed6\u8def\u5f84\uff08\u6bd4\u5982\uff0c\u5b89\u88c5\u5230\u67d0\u4e2a\u516c\u5171\u76ee\u5f55\uff09\uff0c\u4f60\u53ef\u4ee5\uff1a # \u5b89\u88c5 third party \u81f3 /opt \u9700\u8981 root \u6743\u9650\uff0c\u53ef\u4f7f\u7528 --prefix \u6539\u53d8\u5b89\u88c5\u8def\u5f84 $ ../third-party/install-third-party.sh --prefix = /opt/vesoft/third-party \u5982\u679c\u4e0d\u6307\u5b9a --prefix \uff0cthird party \u7684\u9ed8\u8ba4\u5b89\u88c5\u8def\u5f84\u4e3a /opt/vesoft/third-party \uff0c\u4e14\u53ef\u4e3a Nebula Graph \u7684\u7f16\u8bd1\u7cfb\u7edf\u81ea\u52a8\u627e\u5230\u3002\u5426\u5219\uff0c\u9700\u4f7f\u7528\u4e0a\u6587\u6240\u8ff0\u7684 NEBULA_THIRDPARTY_ROOT CMake \u53c2\u6570\u6307\u5b9a\u8def\u5f84\uff0c\u6216\u4e3a\u8be5\u8def\u5f84\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u5e76\u5bfc\u51fa\u3002 Nebula Graph \u67e5\u627e\u5e76\u9009\u62e9 third party \u7684\u4f18\u5148\u7ea7\u5982\u4e0b\uff1a CMake \u53d8\u91cf NEBULA_THIRDPARTY_ROOT build \u8def\u5f84\u4e0b\u7684 third-party/install NEBULA_THIRDPARTY_ROOT \u73af\u5883\u53d8\u91cf /opt/vesoft/third-party","title":"\u624b\u52a8\u5b89\u88c5 Third Party"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_1","text":"\u5bf9\u4e8e\u6ca1\u6709\u53ef\u7528 CMake \u5b89\u88c5\u7684\u7528\u6237\uff0c \u6211\u4eec\u63d0\u4f9b\u4e86\u53ef\u81ea\u52a8\u4e0b\u8f7d\u5b89\u88c5\u7684\u811a\u672c\u3002\u5728 build \u76ee\u5f55\u4e0b\uff0c\u8fd0\u884c\uff1a $ ../third-party/install-cmake.sh cmake-install CMake has been installed to prefix = cmake-install Run 'source cmake-install/bin/enable-cmake.sh' to make it ready to use. Run 'source cmake-install/bin/disable-cmake.sh' to disable it. $ source cmake-install/bin/enable-cmake.sh $ cmake --version cmake version 3 .15.5 \u6b64\u65f6\u53ef\u7528\u7684 CMake \u5df2\u5b89\u88c5\u5b8c\u6210\u3002\u4f60\u53ef\u4ee5\u5728\u4efb\u4f55\u65f6\u5019\u4f7f\u7528 source cmake-install/bin/disable-cmake.sh \u547d\u4ee4\u5c06\u5176\u7981\u7528\u3002","title":"\u5b89\u88c5\u53ef\u7528\u7684 CMake"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#gcc","text":"\u5bf9\u4e8e\u6ca1\u6709\u53ef\u7528 GCC \u5b89\u88c5\u7684\u7528\u6237\uff0c \u6211\u4eec\u63d0\u4f9b\u4e86 GCC \u548c\u53ef\u81ea\u52a8\u4e0b\u8f7d\u5b89\u88c5\u7684\u811a\u672c\u3002\u5728 build \u76ee\u5f55\u4e0b\uff0c\u8fd0\u884c\uff1a # \u5c06 GCC \u5b89\u88c5\u81f3 /opt \u9700\u8981 root \u6743\u9650\uff0c\u652f\u6301\u66f4\u6539\u5b89\u88c5\u8def\u5f84 $ ../third-party/install-gcc.sh --prefix = /opt GCC-7.5.0 has been installed to /opt/vesoft/toolset/gcc/7.5.0 Performing usability tests Performing regular C++14 tests...OK Performing LeakSanitizer tests...OK Run 'source /opt/vesoft/toolset/gcc/7.5.0/enable' to start using. Run 'source /opt/vesoft/toolset/gcc/7.5.0/disable' to stop using. # \u6ce8\u610f\u8def\u5f84\u548c\u6307\u5b9a\u7248\u672c\u53ef\u80fd\u4e0e\u4f60\u7684\u73af\u5883\u4e0d\u540c $ source /opt/vesoft/toolset/gcc/7.5.0/enable # \u6b64\u5904\u4ec5\u8bbe\u7f6e\u4e86 PATH\uff0c\u4ee5\u514d\u6c61\u67d3\u5e93\u8def\u5f84 # \u5982\u679c\u9700\u8981\u53ef\u8fd0\u884c 'export LD_LIBRARY_PATH=/opt/vesoft/toolset/gcc/7.5.0/lib64:$LD_LIBRARY_PATH' $ g++ --version g++ ( Nebula Graph Build ) 7 .5.0 Copyright ( C ) 2017 Free Software Foundation, Inc. \u6b64\u65f6\u53ef\u7528\u7684 GCC \u7f16\u8bd1\u5668\u5df2\u5b89\u88c5\u5b8c\u6210\u3002\u4f60\u53ef\u4ee5\u5728\u4efb\u4f55\u65f6\u5019\u4f7f\u7528 source /opt/vesoft/toolset/gcc/7.5.0/disable \u547d\u4ee4\u5c06\u5176\u7981\u7528\u3002","title":"\u5b89\u88c5\u53ef\u7528\u7684 GCC"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#faq","text":"","title":"FAQ"},{"location":"manual-CN/3.build-develop-and-administration/1.build/1.build-source-code/#error_invalid_argument_type_auto_to_unary_expression","text":"\u5f53\u4f7f\u7528 Clang 9.0 \u7f16\u8bd1 Nebula Graph \u65f6\uff0c\u4f1a\u53d1\u751f\u8be5\u9519\u8bef\uff1a [ 5 % ] Building CXX object src/common/fs/CMakeFiles/fs_obj.dir/FileUtils.cpp.o In file included from src/common/fs/FileUtils.cpp:8: In file included from src/common/fs/FileUtils.h:12: src/common/base/StatusOr.h:57:19: error: invalid argument type 'auto' to unary expression static_assert ( !is_status_v<T>, \"`T' must not be of type `Status'\" ) ; ^~~~~~~~~~~~~~~ src/common/fs/FileUtils.cpp:90:34: note: in instantiation of template class 'nebula::StatusOr<std::__cxx11::basic_string<char> >' requested here StatusOr<std::string> FileUtils::readLink ( const char *path ) { ... \u8fd9\u662f Clang 9.0 \u5f15\u5165\u7684\u4e00\u4e2a\u5df2\u77e5\u7684 Bug\uff0c\u76ee\u524d\uff082020-01-20\uff09\u5c1a\u672a\u4fee\u590d\u3002","title":"error: invalid argument type 'auto' to unary expression"},{"location":"manual-CN/3.build-develop-and-administration/1.build/2.build-by-docker/","text":"\u901a\u8fc7 Docker \u6784\u5efa \u00b6 Nebula Graph \u63d0\u4f9b\u6574\u4e2a\u7f16\u8bd1\u73af\u5883\u7684 docker \u955c\u50cf vesoft/nebula-dev \uff0c\u652f\u6301\u5728\u672c\u5730\u66f4\u6539\u6e90\u4ee3\u7801\uff0c\u6784\u5efa\u5e76\u5728\u5bb9\u5668\u4e2d\u8c03\u8bd5\u3002\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\u4ee5\u5f00\u59cb\u5feb\u901f\u5f00\u53d1\uff1a \u4ece Docker Hub \u83b7\u53d6\u955c\u50cf \u00b6 bash> docker pull vesoft/nebula-dev \u8fd0\u884c docker \u5bb9\u5668\u5e76\u5c06\u672c\u5730\u6e90\u7801\u76ee\u5f55\u6302\u8f7d\u5230\u5bb9\u5668\u5de5\u4f5c\u76ee\u5f55 /home/nebula \u4e2d \u00b6 bash> docker run --rm -ti \\ --security-opt seccomp = unconfined \\ -v /path/to/nebula/directory:/home/nebula \\ -w /home/nebula \\ vesoft/nebula-dev \\ bash \u5c06 /path/to/nebula/directory \u66ff\u6362\u6210\u4f60\u4e2a\u4eba\u7684 \u6e90\u7801\u8def\u5f84 \u3002 \u5728\u5bb9\u5668\u5185\u7f16\u8bd1 \u00b6 docker> mkdir _build && cd _build docker> cmake .. docker> make docker> make install \u542f\u52a8 Nebula Graph \u670d\u52a1 \u00b6 \u4e0a\u8ff0\u6b65\u9aa4\u5b8c\u6210\u540e\u5373\u53ef\u5728\u5bb9\u5668\u5185\u542f\u52a8\u670d\u52a1\uff0c\u9ed8\u8ba4\u5b89\u88c5\u76ee\u5f55\u4e3a /usr/local/nebula \u3002 docker> cd /usr/local/nebula \u91cd\u547d\u540d Nebula Graph \u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6 docker> cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf docker> cp etc/nebula-metad.conf.default etc/nebula-metad.conf docker> cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf \u542f\u52a8\u670d\u52a1 docker> ./scripts/nebula.service start all docker> ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" nebula> SHOW HOSTS ;","title":"\u901a\u8fc7 Docker \u6784\u5efa"},{"location":"manual-CN/3.build-develop-and-administration/1.build/2.build-by-docker/#docker","text":"Nebula Graph \u63d0\u4f9b\u6574\u4e2a\u7f16\u8bd1\u73af\u5883\u7684 docker \u955c\u50cf vesoft/nebula-dev \uff0c\u652f\u6301\u5728\u672c\u5730\u66f4\u6539\u6e90\u4ee3\u7801\uff0c\u6784\u5efa\u5e76\u5728\u5bb9\u5668\u4e2d\u8c03\u8bd5\u3002\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\u4ee5\u5f00\u59cb\u5feb\u901f\u5f00\u53d1\uff1a","title":"\u901a\u8fc7 Docker \u6784\u5efa"},{"location":"manual-CN/3.build-develop-and-administration/1.build/2.build-by-docker/#docker_hub","text":"bash> docker pull vesoft/nebula-dev","title":"\u4ece Docker Hub \u83b7\u53d6\u955c\u50cf"},{"location":"manual-CN/3.build-develop-and-administration/1.build/2.build-by-docker/#docker_homenebula","text":"bash> docker run --rm -ti \\ --security-opt seccomp = unconfined \\ -v /path/to/nebula/directory:/home/nebula \\ -w /home/nebula \\ vesoft/nebula-dev \\ bash \u5c06 /path/to/nebula/directory \u66ff\u6362\u6210\u4f60\u4e2a\u4eba\u7684 \u6e90\u7801\u8def\u5f84 \u3002","title":"\u8fd0\u884c docker \u5bb9\u5668\u5e76\u5c06\u672c\u5730\u6e90\u7801\u76ee\u5f55\u6302\u8f7d\u5230\u5bb9\u5668\u5de5\u4f5c\u76ee\u5f55 /home/nebula \u4e2d"},{"location":"manual-CN/3.build-develop-and-administration/1.build/2.build-by-docker/#_1","text":"docker> mkdir _build && cd _build docker> cmake .. docker> make docker> make install","title":"\u5728\u5bb9\u5668\u5185\u7f16\u8bd1"},{"location":"manual-CN/3.build-develop-and-administration/1.build/2.build-by-docker/#nebula_graph","text":"\u4e0a\u8ff0\u6b65\u9aa4\u5b8c\u6210\u540e\u5373\u53ef\u5728\u5bb9\u5668\u5185\u542f\u52a8\u670d\u52a1\uff0c\u9ed8\u8ba4\u5b89\u88c5\u76ee\u5f55\u4e3a /usr/local/nebula \u3002 docker> cd /usr/local/nebula \u91cd\u547d\u540d Nebula Graph \u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6 docker> cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf docker> cp etc/nebula-metad.conf.default etc/nebula-metad.conf docker> cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf \u542f\u52a8\u670d\u52a1 docker> ./scripts/nebula.service start all docker> ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" nebula> SHOW HOSTS ;","title":"\u542f\u52a8 Nebula Graph \u670d\u52a1"},{"location":"manual-CN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/","text":"KV \u63a5\u53e3 \u00b6 \u63a5\u53e3\u793a\u4f8b \u00b6 Nebula Graph storage \u63d0\u4f9b key-value \u63a5\u53e3\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 StorageClient \u8fdb\u884c kv \u7684\u76f8\u5173\u64cd\u4f5c\uff0c\u8bf7\u6ce8\u610f\u7528\u6237\u4ecd\u7136\u9700\u8981\u901a\u8fc7 console \u6765\u521b\u5efa space\u3002\u76ee\u524d\u652f\u6301\u7684\u63a5\u53e3\u6709 Get \u548c Put\uff0c\u63a5\u53e3\u5982\u4e0b\u3002 folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: ExecResponse >> put ( GraphSpaceID space , std :: vector < nebula :: cpp2 :: Pair > values , folly :: EventBase * evb = nullptr ); folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: GeneralResponse >> get ( GraphSpaceID space , const std :: vector < std :: string >& keys , folly :: EventBase * evb = nullptr ); \u540e\u7eed\u5c06\u63d0\u4f9b remove\uff0cremoveRange \u4ee5\u53ca scan \u7684\u65b9\u6cd5\u3002 \u4e0b\u9762\u7ed3\u5408\u793a\u4f8b\u8bf4\u660e kv \u63a5\u53e3\u7684\u4f7f\u7528\u65b9\u6cd5\uff1a // Put \u63a5\u53e3 std :: vector < nebula :: cpp2 :: Pair > pairs ; for ( int32_t i = 0 ; i < 1000 ; i ++ ) { auto key = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); auto value = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); pairs . emplace_back ( apache :: thrift :: FragileConstructor :: FRAGILE , std :: move ( key ), std :: move ( value )); } // \u901a\u8fc7 StorageClient \u53d1\u9001\u8bf7\u6c42\uff0c\u76f8\u5e94\u7684\u53c2\u6570\u4e3a spaceId\uff0c\u4ee5\u53ca\u5199\u5165\u7684\u952e\u503c\u5bf9 auto future = storageClient -> put ( spaceId , std :: move ( pairs )); // \u83b7\u53d6\u7ed3\u679c auto resp = std :: move ( future ). get (); // Get \u63a5\u53e3 std :: vector < std :: string > keys ; for ( auto & pair : pairs ) { keys . emplace_back ( pair . first ); } // \u901a\u8fc7 StorageClient \u53d1\u9001\u8bf7\u6c42\uff0c\u76f8\u5e94\u7684\u53c2\u6570\u4e3a spaceId\uff0c\u4ee5\u53ca\u8981\u83b7\u53d6\u7684 keys auto future = storageClient -> get ( spaceId , std :: move ( keys )); // \u83b7\u53d6\u7ed3\u679c auto resp = std :: move ( future ). get () \u5904\u7406\u8fd4\u56de\u7ed3\u679c \u00b6 \u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u68c0\u67e5 rpc \u8fd4\u56de\u7ed3\u679c\u67e5\u770b\u76f8\u5e94\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002\u6b64\u5916\u7531\u4e8e\u6bcf\u4e2a Nebula Graph storage \u4e2d\u90fd\u5bf9\u6570\u636e\u8fdb\u884c\u4e86\u5206\u7247\uff0c\u56e0\u6b64\u5982\u679c\u5bf9\u5e94\u7684 Partition \u5931\u8d25\u4e86\uff0c\u4e5f\u4f1a\u8fd4\u56de\u6bcf\u4e2a\u5931\u8d25\u7684 Partition \u7684\u9519\u8bef\u7801\u3002\u82e5\u4efb\u610f\u4e00\u4e2a Partition \u5931\u8d25\uff0c\u5219\u6574\u4e2a\u8bf7\u6c42\u5931\u8d25(resp.succeeded()\u4e3a false)\uff0c\u4f46\u662f\u5176\u4ed6\u6210\u529f\u7684 Partition \u4ecd\u7136\u4f1a\u6210\u529f\u5199\u5165\u6216\u8bfb\u53d6\u3002 \u7528\u6237\u53ef\u4ee5\u8fdb\u884c\u91cd\u8bd5\uff0c\u76f4\u81f3\u6240\u6709\u8bf7\u6c42\u90fd\u6210\u529f\u3002\u76ee\u524d StorageClient \u4e0d\u652f\u6301\u81ea\u52a8\u91cd\u8bd5\uff0c\u7528\u6237\u53ef\u4ee5\u6839\u636e\u9519\u8bef\u7801\u51b3\u5b9a\u662f\u5426\u8fdb\u884c\u91cd\u8bd5\u3002 // \u5224\u65ad\u8c03\u7528\u662f\u5426\u6210\u529f if ( ! resp . succeeded ()) { LOG ( ERROR ) << \"Operation Failed\" ; return ; } // \u5931\u8d25\u7684 Partition \u4ee5\u53ca\u76f8\u5e94\u7684\u9519\u8bef\u7801 if ( ! resp . failedParts (). empty ()) { for ( const auto & partEntry : resp . failedParts ()) { LOG ( ERROR ) << \"Operation Failed in \" << partEntry . first << \", Code: \" << static_cast < int32_t > ( partEntry . second ); } return ; } \u8bfb\u53d6\u8fd4\u56de\u503c \u00b6 \u5bf9\u4e8e Get \u63a5\u53e3\uff0c\u7528\u6237\u9700\u8981\u4e00\u4e9b\u64cd\u4f5c\u6765\u83b7\u53d6\u76f8\u5e94\u7684\u8fd4\u56de\u503c\u3002Nebula storage \u662f\u57fa\u4e8e Raft \u7684\u591a\u526f\u672c\uff0c\u6240\u6709\u8bfb\u5199\u64cd\u4f5c\u53ea\u80fd\u53d1\u9001\u7ed9\u5bf9\u5e94 partition \u7684 leader\u3002\u5f53\u4e00\u4e2a rpc \u8bf7\u6c42\u5305\u542b\u4e86\u591a\u4e2a\u8de8 partition \u7684 get \u65f6\uff0cStorage Client \u4f1a\u7ed9\u8bbf\u95ee\u8fd9\u4e9b key \u6240\u5bf9\u5e94\u7684 Partition leader\u3002\u6bcf\u4e2a rpc \u8fd4\u56de\u90fd\u5355\u72ec\u4fdd\u5b58\u5728\u4e00\u4e2a unordered_map \u4e2d\uff0c\u76ee\u524d\u8fd8\u9700\u8981\u7528\u6237\u5728\u8fd9\u4e9b unordered_map \u4e2d\u904d\u5386\u67e5\u627e key \u662f\u5426\u5b58\u5728\u3002\u793a\u4f8b\u5982\u4e0b\uff1a // \u67e5\u627e key \u5bf9\u5e94\u7684 value \u662f\u5426\u5728\u8fd4\u56de\u7ed3\u679c\u4e2d\uff0c\u5982\u679c\u5b58\u5728\uff0c\u5219\u4fdd\u5b58\u5728 value \u4e2d bool found = false ; std :: string value ; // resp.responses()\u4e2d\u662f\u591a\u4e2a storage server \u8fd4\u56de\u7684\u7ed3\u679c for ( const auto & result : resp . responses ()) { // result.values \u5373\u4e3a\u67d0\u4e2a storage server \u8fd4\u56de\u7684 key-value paris auto iter = result . values . find ( key ); if ( iter != result . values . end ()) { value = iter -> second ; found = true ; break ; } }","title":"KV \u63a5\u53e3"},{"location":"manual-CN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#kv","text":"","title":"KV \u63a5\u53e3"},{"location":"manual-CN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#_1","text":"Nebula Graph storage \u63d0\u4f9b key-value \u63a5\u53e3\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7 StorageClient \u8fdb\u884c kv \u7684\u76f8\u5173\u64cd\u4f5c\uff0c\u8bf7\u6ce8\u610f\u7528\u6237\u4ecd\u7136\u9700\u8981\u901a\u8fc7 console \u6765\u521b\u5efa space\u3002\u76ee\u524d\u652f\u6301\u7684\u63a5\u53e3\u6709 Get \u548c Put\uff0c\u63a5\u53e3\u5982\u4e0b\u3002 folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: ExecResponse >> put ( GraphSpaceID space , std :: vector < nebula :: cpp2 :: Pair > values , folly :: EventBase * evb = nullptr ); folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: GeneralResponse >> get ( GraphSpaceID space , const std :: vector < std :: string >& keys , folly :: EventBase * evb = nullptr ); \u540e\u7eed\u5c06\u63d0\u4f9b remove\uff0cremoveRange \u4ee5\u53ca scan \u7684\u65b9\u6cd5\u3002 \u4e0b\u9762\u7ed3\u5408\u793a\u4f8b\u8bf4\u660e kv \u63a5\u53e3\u7684\u4f7f\u7528\u65b9\u6cd5\uff1a // Put \u63a5\u53e3 std :: vector < nebula :: cpp2 :: Pair > pairs ; for ( int32_t i = 0 ; i < 1000 ; i ++ ) { auto key = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); auto value = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); pairs . emplace_back ( apache :: thrift :: FragileConstructor :: FRAGILE , std :: move ( key ), std :: move ( value )); } // \u901a\u8fc7 StorageClient \u53d1\u9001\u8bf7\u6c42\uff0c\u76f8\u5e94\u7684\u53c2\u6570\u4e3a spaceId\uff0c\u4ee5\u53ca\u5199\u5165\u7684\u952e\u503c\u5bf9 auto future = storageClient -> put ( spaceId , std :: move ( pairs )); // \u83b7\u53d6\u7ed3\u679c auto resp = std :: move ( future ). get (); // Get \u63a5\u53e3 std :: vector < std :: string > keys ; for ( auto & pair : pairs ) { keys . emplace_back ( pair . first ); } // \u901a\u8fc7 StorageClient \u53d1\u9001\u8bf7\u6c42\uff0c\u76f8\u5e94\u7684\u53c2\u6570\u4e3a spaceId\uff0c\u4ee5\u53ca\u8981\u83b7\u53d6\u7684 keys auto future = storageClient -> get ( spaceId , std :: move ( keys )); // \u83b7\u53d6\u7ed3\u679c auto resp = std :: move ( future ). get ()","title":"\u63a5\u53e3\u793a\u4f8b"},{"location":"manual-CN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#_2","text":"\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u68c0\u67e5 rpc \u8fd4\u56de\u7ed3\u679c\u67e5\u770b\u76f8\u5e94\u64cd\u4f5c\u662f\u5426\u6210\u529f\u3002\u6b64\u5916\u7531\u4e8e\u6bcf\u4e2a Nebula Graph storage \u4e2d\u90fd\u5bf9\u6570\u636e\u8fdb\u884c\u4e86\u5206\u7247\uff0c\u56e0\u6b64\u5982\u679c\u5bf9\u5e94\u7684 Partition \u5931\u8d25\u4e86\uff0c\u4e5f\u4f1a\u8fd4\u56de\u6bcf\u4e2a\u5931\u8d25\u7684 Partition \u7684\u9519\u8bef\u7801\u3002\u82e5\u4efb\u610f\u4e00\u4e2a Partition \u5931\u8d25\uff0c\u5219\u6574\u4e2a\u8bf7\u6c42\u5931\u8d25(resp.succeeded()\u4e3a false)\uff0c\u4f46\u662f\u5176\u4ed6\u6210\u529f\u7684 Partition \u4ecd\u7136\u4f1a\u6210\u529f\u5199\u5165\u6216\u8bfb\u53d6\u3002 \u7528\u6237\u53ef\u4ee5\u8fdb\u884c\u91cd\u8bd5\uff0c\u76f4\u81f3\u6240\u6709\u8bf7\u6c42\u90fd\u6210\u529f\u3002\u76ee\u524d StorageClient \u4e0d\u652f\u6301\u81ea\u52a8\u91cd\u8bd5\uff0c\u7528\u6237\u53ef\u4ee5\u6839\u636e\u9519\u8bef\u7801\u51b3\u5b9a\u662f\u5426\u8fdb\u884c\u91cd\u8bd5\u3002 // \u5224\u65ad\u8c03\u7528\u662f\u5426\u6210\u529f if ( ! resp . succeeded ()) { LOG ( ERROR ) << \"Operation Failed\" ; return ; } // \u5931\u8d25\u7684 Partition \u4ee5\u53ca\u76f8\u5e94\u7684\u9519\u8bef\u7801 if ( ! resp . failedParts (). empty ()) { for ( const auto & partEntry : resp . failedParts ()) { LOG ( ERROR ) << \"Operation Failed in \" << partEntry . first << \", Code: \" << static_cast < int32_t > ( partEntry . second ); } return ; }","title":"\u5904\u7406\u8fd4\u56de\u7ed3\u679c"},{"location":"manual-CN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#_3","text":"\u5bf9\u4e8e Get \u63a5\u53e3\uff0c\u7528\u6237\u9700\u8981\u4e00\u4e9b\u64cd\u4f5c\u6765\u83b7\u53d6\u76f8\u5e94\u7684\u8fd4\u56de\u503c\u3002Nebula storage \u662f\u57fa\u4e8e Raft \u7684\u591a\u526f\u672c\uff0c\u6240\u6709\u8bfb\u5199\u64cd\u4f5c\u53ea\u80fd\u53d1\u9001\u7ed9\u5bf9\u5e94 partition \u7684 leader\u3002\u5f53\u4e00\u4e2a rpc \u8bf7\u6c42\u5305\u542b\u4e86\u591a\u4e2a\u8de8 partition \u7684 get \u65f6\uff0cStorage Client \u4f1a\u7ed9\u8bbf\u95ee\u8fd9\u4e9b key \u6240\u5bf9\u5e94\u7684 Partition leader\u3002\u6bcf\u4e2a rpc \u8fd4\u56de\u90fd\u5355\u72ec\u4fdd\u5b58\u5728\u4e00\u4e2a unordered_map \u4e2d\uff0c\u76ee\u524d\u8fd8\u9700\u8981\u7528\u6237\u5728\u8fd9\u4e9b unordered_map \u4e2d\u904d\u5386\u67e5\u627e key \u662f\u5426\u5b58\u5728\u3002\u793a\u4f8b\u5982\u4e0b\uff1a // \u67e5\u627e key \u5bf9\u5e94\u7684 value \u662f\u5426\u5728\u8fd4\u56de\u7ed3\u679c\u4e2d\uff0c\u5982\u679c\u5b58\u5728\uff0c\u5219\u4fdd\u5b58\u5728 value \u4e2d bool found = false ; std :: string value ; // resp.responses()\u4e2d\u662f\u591a\u4e2a storage server \u8fd4\u56de\u7684\u7ed3\u679c for ( const auto & result : resp . responses ()) { // result.values \u5373\u4e3a\u67d0\u4e2a storage server \u8fd4\u56de\u7684 key-value paris auto iter = result . values . find ( key ); if ( iter != result . values . end ()) { value = iter -> second ; found = true ; break ; } }","title":"\u8bfb\u53d6\u8fd4\u56de\u503c"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/","text":"Reader \u00b6 \u672c\u7ae0\u4e3b\u8981\u9762\u5bf9\u5f00\u53d1\u8005\u548c DBA","title":"Reader"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/#reader","text":"\u672c\u7ae0\u4e3b\u8981\u9762\u5bf9\u5f00\u53d1\u8005\u548c DBA","title":"Reader"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/","text":"\u914d\u7f6e\u6587\u4ef6\u8bf4\u660e \u00b6 \u672c\u6587\u4ecb\u7ecd etc/ \u76ee\u5f55\u4e0b\u914d\u7f6e\u6587\u4ef6\u6240\u5bf9\u5e94\u53c2\u6570\u3002 Meta Service \u00b6 \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 45500 Meta daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u8def\u5f84\uff0c\u4e0d\u652f\u6301\u591a\u6761\u8def\u5f84 meta_server_addrs \"\" \u4e00\u7cfb\u5217\u7531\u9017\u53f7\u5206\u9694\u7684 IP \u5730\u5740\uff0c\u7528\u4e8e\u96c6\u7fa4\u90e8\u7f72\uff0cIP \u6570\u4e0e\u526f\u672c\u6570\u76f8\u7b49\uff0c\u5982\u679c\u4e3a\u7a7a\uff0c\u5219\u8868\u660e\u662f\u5355\u673a local_ip \"\" \u4e3a NetworkUtils :: getLocalIP \u6307\u5b9a\u672c\u5730 IP num_io_threads 16 IO \u7ebf\u7a0b\u6570 meta_http_thread_num 3 meta daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 part_man_type memory memory\uff0cmeta pid_file \"pids/nebula-metad.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c cluster_id 0 \u96c6\u7fa4\u7684\u552f\u4e00 ID meta_ingest_thread_num 3 Meta daemon \u7684 ingest \u7ebf\u7a0b\u6570 ws_http_port 11000 Meta HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 11000 ws_h2_port 11002 Meta HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 11002 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570 Storage Service \u00b6 \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 44500 Storage daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u8def\u5f84\uff0c\u591a\u6761\u8def\u5f84\u7531\u9017\u53f7\u5206\u9694\uff0c\u5bf9\u4e8e RocksDB \u5f15\u64ce\uff0c\u4e00\u4e2a\u8def\u5f84\u4e3a\u4e00\u4e2a\u5b9e\u4f8b local_ip \"\" IP \u5730\u5740\u548c\u76d1\u542c\u7aef\u53e3\u5171\u540c\u7528\u4e8e\u6807\u8bc6\u6b64\u670d\u52a1\u5668 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c pid_file \"pids/nebula-storaged.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 store_type \"nebula\" storage daemon \u4f7f\u7528\u7684 KVStore \u7c7b\u578b\uff0c\u53ef\u9009\u7c7b\u578b\u4e3a nebula\u3001HBase \u7b49 num_io_threads 16 IO \u7ebf\u7a0b\u6570 storage_http_thread_num 3 storage daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 engine_type rocksdb RocksDB, memory ... custom_filter_interval_secs 24 * 3600 \u89e6\u53d1\u81ea\u5b9a\u4e49\u538b\u7f29\u95f4\u9694 num_workers 4 worker \u7ebf\u7a0b\u6570 rocksdb_disable_wal false \u7981\u7528 RocksDB \u7684 WAL rocksdb_db_options \"{}\" DBOptions \u7684 Json \u5b57\u7b26\u4e32\uff0c\u6240\u6709\u952e\u503c\u5747\u4e3a\u5b57\u7b26\u4e32 rocksdb_column_family_options \"{}\" ColumnFamilyOptions \u7684 Json \u5b57\u7b26\u4e32\uff0c\u6240\u6709\u952e\u503c\u5747\u4e3a\u5b57\u7b26\u4e32 rocksdb_block_based_table_options \"{}\" BlockBasedTableOptions \u7684 Json \u5b57\u7b26\u4e32\uff0c\u6240\u6709\u952e\u503c\u5747\u4e3a\u5b57\u7b26\u4e32 rocksdb_batch_size 4 * 1024 \u5355\u4e2a\u6279\u5904\u7406\u7684\u9ed8\u8ba4\u4fdd\u7559\u5b57\u8282 rocksdb_block_cache 4 BlockBasedTable \u4f7f\u7528\u7684\u9ed8\u8ba4\u5757\u7f13\u5b58\u5927\u5c0f\u3002\u5355\u4f4d\u662f MB\u3002 download_thread_num 3 \u4e0b\u8f7d\u7ebf\u7a0b\u6570 min_vertices_per_bucket 3 \u4e00\u4e2a bucket \u4e2d\u6700\u5c0f\u8282\u70b9\u6570 max_appendlog_batch_size 128 \u6bcf\u4e2a appendLog \u6279\u8bf7\u6c42\u7684\u6700\u5927 log \u6570 max_outstanding_requests 1024 outstanding appendLog \u8bf7\u6c42\u6700\u5927\u6570 raft_rpc_timeout_ms 500 raft \u5ba2\u6237\u7aef RPC \u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2 raft_heartbeat_interval_secs 5 \u6bcf\u6b21\u5fc3\u8df3\u95f4\u9694\u65f6\u957f\uff0c\u5355\u4f4d\u79d2 max_batch_size 256 \u4e00\u4e2a batch \u4e2d\u6700\u5927 log \u6570 ws_http_port 12000 Storage HTTP 12000 ws_h2_port 12002 Storage HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 12002 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570 Graph Service \u00b6 \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 3699 Nebula Graph daemon \u76d1\u542c\u7aef\u53e3 client_idle_timeout_secs 0 \u5173\u95ed idle \u8fde\u63a5\u524d\u7684\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c 0 \u4e3a\u65e0\u7a77\u5927 session_idle_timeout_secs 600 idle sessions \u8fc7\u671f\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c0 \u4e3a\u65e0\u7a77\u5927 session_reclaim_interval_secs 10 \u8d85\u51fa\u6307\u5b9a\u65f6\u95f4\u5219\u8ba4\u4e3a\u8d85\u65f6 num_netio_threads 0 networking \u7ebf\u7a0b\u6570\uff0c0\u4e3a\u7269\u7406 CPU \u6838\u6570 num_accept_threads 1 \u63a5\u53d7\u8fdb\u5165\u8fde\u63a5\u7684\u7ebf\u7a0b\u6570 num_worker_threads 0 \u6267\u884c\u7528\u6237\u8bf7\u6c42\u7684\u7ebf\u7a0b\u6570\uff0c\u7ebf\u7a0b\u6570\u4e3a\u7cfb\u7edf CPU \u6838\u6570 reuse_port false \u5f00\u542f SO_REUSEPORT \u9009\u9879 listen_backlog 1024 listen socket \u7684 backlog listen_netdev \"any\" \u76d1\u542c\u7684\u7f51\u7edc\u670d\u52a1 pid_file \"pids/nebula-graphd.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 redirect_stdout true \u5c06 stdout \u548c stderr \u91cd\u5b9a\u5411\u5230\u5355\u72ec\u7684\u6587\u4ef6 stdout_log_file \"graphd-stdout.log\" stdout \u76ee\u6807\u6587\u4ef6\u540d stderr_log_file \"graphd-stderr.log\" stderr \u76ee\u6807\u6587\u4ef6\u540d daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 ws_http_port 13000 Graph HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 13000 ws_h2_port 13002 Graph HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 13002 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570 Console \u00b6 \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e addr \"127.0.0.1\" Graph daemon IP \u5730\u5740 port 0 Graph daemon \u76d1\u542c\u7aef\u53e3 u \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u7528\u6237\u540d p \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u5bc6\u7801 enable_history false \u662f\u5426\u4fdd\u5b58\u5386\u53f2\u547d\u4ee4 server_conn_timeout_ms 1000 \u8fde\u63a5\u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2","title":"\u914d\u7f6e\u6587\u4ef6\u8bf4\u660e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#_1","text":"\u672c\u6587\u4ecb\u7ecd etc/ \u76ee\u5f55\u4e0b\u914d\u7f6e\u6587\u4ef6\u6240\u5bf9\u5e94\u53c2\u6570\u3002","title":"\u914d\u7f6e\u6587\u4ef6\u8bf4\u660e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#meta_service","text":"\u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 45500 Meta daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u8def\u5f84\uff0c\u4e0d\u652f\u6301\u591a\u6761\u8def\u5f84 meta_server_addrs \"\" \u4e00\u7cfb\u5217\u7531\u9017\u53f7\u5206\u9694\u7684 IP \u5730\u5740\uff0c\u7528\u4e8e\u96c6\u7fa4\u90e8\u7f72\uff0cIP \u6570\u4e0e\u526f\u672c\u6570\u76f8\u7b49\uff0c\u5982\u679c\u4e3a\u7a7a\uff0c\u5219\u8868\u660e\u662f\u5355\u673a local_ip \"\" \u4e3a NetworkUtils :: getLocalIP \u6307\u5b9a\u672c\u5730 IP num_io_threads 16 IO \u7ebf\u7a0b\u6570 meta_http_thread_num 3 meta daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 part_man_type memory memory\uff0cmeta pid_file \"pids/nebula-metad.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c cluster_id 0 \u96c6\u7fa4\u7684\u552f\u4e00 ID meta_ingest_thread_num 3 Meta daemon \u7684 ingest \u7ebf\u7a0b\u6570 ws_http_port 11000 Meta HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 11000 ws_h2_port 11002 Meta HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 11002 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570","title":"Meta Service"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#storage_service","text":"\u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 44500 Storage daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u8def\u5f84\uff0c\u591a\u6761\u8def\u5f84\u7531\u9017\u53f7\u5206\u9694\uff0c\u5bf9\u4e8e RocksDB \u5f15\u64ce\uff0c\u4e00\u4e2a\u8def\u5f84\u4e3a\u4e00\u4e2a\u5b9e\u4f8b local_ip \"\" IP \u5730\u5740\u548c\u76d1\u542c\u7aef\u53e3\u5171\u540c\u7528\u4e8e\u6807\u8bc6\u6b64\u670d\u52a1\u5668 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c pid_file \"pids/nebula-storaged.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 store_type \"nebula\" storage daemon \u4f7f\u7528\u7684 KVStore \u7c7b\u578b\uff0c\u53ef\u9009\u7c7b\u578b\u4e3a nebula\u3001HBase \u7b49 num_io_threads 16 IO \u7ebf\u7a0b\u6570 storage_http_thread_num 3 storage daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 engine_type rocksdb RocksDB, memory ... custom_filter_interval_secs 24 * 3600 \u89e6\u53d1\u81ea\u5b9a\u4e49\u538b\u7f29\u95f4\u9694 num_workers 4 worker \u7ebf\u7a0b\u6570 rocksdb_disable_wal false \u7981\u7528 RocksDB \u7684 WAL rocksdb_db_options \"{}\" DBOptions \u7684 Json \u5b57\u7b26\u4e32\uff0c\u6240\u6709\u952e\u503c\u5747\u4e3a\u5b57\u7b26\u4e32 rocksdb_column_family_options \"{}\" ColumnFamilyOptions \u7684 Json \u5b57\u7b26\u4e32\uff0c\u6240\u6709\u952e\u503c\u5747\u4e3a\u5b57\u7b26\u4e32 rocksdb_block_based_table_options \"{}\" BlockBasedTableOptions \u7684 Json \u5b57\u7b26\u4e32\uff0c\u6240\u6709\u952e\u503c\u5747\u4e3a\u5b57\u7b26\u4e32 rocksdb_batch_size 4 * 1024 \u5355\u4e2a\u6279\u5904\u7406\u7684\u9ed8\u8ba4\u4fdd\u7559\u5b57\u8282 rocksdb_block_cache 4 BlockBasedTable \u4f7f\u7528\u7684\u9ed8\u8ba4\u5757\u7f13\u5b58\u5927\u5c0f\u3002\u5355\u4f4d\u662f MB\u3002 download_thread_num 3 \u4e0b\u8f7d\u7ebf\u7a0b\u6570 min_vertices_per_bucket 3 \u4e00\u4e2a bucket \u4e2d\u6700\u5c0f\u8282\u70b9\u6570 max_appendlog_batch_size 128 \u6bcf\u4e2a appendLog \u6279\u8bf7\u6c42\u7684\u6700\u5927 log \u6570 max_outstanding_requests 1024 outstanding appendLog \u8bf7\u6c42\u6700\u5927\u6570 raft_rpc_timeout_ms 500 raft \u5ba2\u6237\u7aef RPC \u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2 raft_heartbeat_interval_secs 5 \u6bcf\u6b21\u5fc3\u8df3\u95f4\u9694\u65f6\u957f\uff0c\u5355\u4f4d\u79d2 max_batch_size 256 \u4e00\u4e2a batch \u4e2d\u6700\u5927 log \u6570 ws_http_port 12000 Storage HTTP 12000 ws_h2_port 12002 Storage HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 12002 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570","title":"Storage Service"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#graph_service","text":"\u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 3699 Nebula Graph daemon \u76d1\u542c\u7aef\u53e3 client_idle_timeout_secs 0 \u5173\u95ed idle \u8fde\u63a5\u524d\u7684\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c 0 \u4e3a\u65e0\u7a77\u5927 session_idle_timeout_secs 600 idle sessions \u8fc7\u671f\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c0 \u4e3a\u65e0\u7a77\u5927 session_reclaim_interval_secs 10 \u8d85\u51fa\u6307\u5b9a\u65f6\u95f4\u5219\u8ba4\u4e3a\u8d85\u65f6 num_netio_threads 0 networking \u7ebf\u7a0b\u6570\uff0c0\u4e3a\u7269\u7406 CPU \u6838\u6570 num_accept_threads 1 \u63a5\u53d7\u8fdb\u5165\u8fde\u63a5\u7684\u7ebf\u7a0b\u6570 num_worker_threads 0 \u6267\u884c\u7528\u6237\u8bf7\u6c42\u7684\u7ebf\u7a0b\u6570\uff0c\u7ebf\u7a0b\u6570\u4e3a\u7cfb\u7edf CPU \u6838\u6570 reuse_port false \u5f00\u542f SO_REUSEPORT \u9009\u9879 listen_backlog 1024 listen socket \u7684 backlog listen_netdev \"any\" \u76d1\u542c\u7684\u7f51\u7edc\u670d\u52a1 pid_file \"pids/nebula-graphd.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 redirect_stdout true \u5c06 stdout \u548c stderr \u91cd\u5b9a\u5411\u5230\u5355\u72ec\u7684\u6587\u4ef6 stdout_log_file \"graphd-stdout.log\" stdout \u76ee\u6807\u6587\u4ef6\u540d stderr_log_file \"graphd-stderr.log\" stderr \u76ee\u6807\u6587\u4ef6\u540d daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 ws_http_port 13000 Graph HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 13000 ws_h2_port 13002 Graph HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3\u9ed8\u8ba4\u503c\u4e3a 13002 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570","title":"Graph Service"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#console","text":"\u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e addr \"127.0.0.1\" Graph daemon IP \u5730\u5740 port 0 Graph daemon \u76d1\u542c\u7aef\u53e3 u \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u7528\u6237\u540d p \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u5bc6\u7801 enable_history false \u662f\u5426\u4fdd\u5b58\u5386\u53f2\u547d\u4ee4 server_conn_timeout_ms 1000 \u8fde\u63a5\u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2","title":"Console"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster-on-docker/","text":"\u4f7f\u7528 Docker \u90e8\u7f72\u96c6\u7fa4 \u00b6 \u53c2\u8003\u53e6\u5916\u4e00\u4e2a\u4ed3\u5e93: vesoft-inc/nebula-docker-compose","title":"\u4f7f\u7528 Docker \u90e8\u7f72\u96c6\u7fa4"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster-on-docker/#docker","text":"\u53c2\u8003\u53e6\u5916\u4e00\u4e2a\u4ed3\u5e93: vesoft-inc/nebula-docker-compose","title":"\u4f7f\u7528 Docker \u90e8\u7f72\u96c6\u7fa4"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/","text":"\u96c6\u7fa4\u90e8\u7f72 \u00b6 \u672c\u8282\u4ecb\u7ecd Nebula Graph \u7684\u90e8\u7f72 \u4e0b\u8f7d\u5e76\u5b89\u88c5\u5305 \u00b6 \u76ee\u524d\uff0c Nebula Graph \u5b98\u65b9\u63d0\u4f9b CentOS 7.5 \uff0c CentOS 6.5 \uff0c Ubuntu 1604 \u548c Ubuntu 1804 \u5305\uff0crpm \u6216 deb \u5305\u4e0b\u8f7d\u70b9\u51fb \u6b64\u5904 \u3002 CentOS \u7cfb\u7edf\uff1a rpm -ivh nebula- { VERSION } . { SYSTEM_VERSION } .x86_64.rpm Ubuntu \u7cfb\u7edf\uff1a dpkg -i nebula- { VERSION } . { SYSTEM_VERSION } .amd64.deb \u914d\u7f6e\u6587\u4ef6\u9ed8\u8ba4\u76ee\u5f55\u4e3a /usr/local/nebula/etc \uff0c\u8bf7\u66f4\u6539 meta_server_addrs \uff0c\u914d\u7f6e Meta Server \u7684\u5730\u5740\u3002 \u542f\u52a8\u591a\u526f\u672c Meta \u670d\u52a1\u9700\u5c06\u591a\u4e2a\u5730\u5740\u914d\u7f6e\u5230 meta_server_addrs \uff0c\u5730\u5740\u95f4\u9700\u4f7f\u7528\u9017\u53f7\u5206\u9694\u3002 \u4f7f\u7528 data_path \u8bbe\u7f6e Meta \u7684\u5e95\u5c42\u5b58\u50a8\u8def\u5f84\u3002 \u542f\u52a8 Nebula Graph \u96c6\u7fa4 \u00b6 \u76ee\u524d\uff0c Nebula Graph \u96c6\u7fa4\u7531 scripts/services.sh \u8fd0\u7ef4\uff0c\u53ef\u4f7f\u7528\u6b64\u811a\u672c start \uff0c stop \u6216 restart \u91cd\u542f\u96c6\u7fa4\u3002 \u793a\u4f8b\u547d\u4ee4\u5982\u4e0b\uff1a scripts/services.sh <start | stop | restart | status | kill> metas\uff0c storages \u548c graphs \u5305\u542b\u5176\u81ea\u8eab\u7684 hosts\u3002 \u8fde\u63a5 Nebula Graph \u00b6 > bin/nebula -u = user -p = password --addr ={ graphd IP address } --port ={ graphd listening port } -u \u7528\u6765\u8bbe\u7f6e\u7528\u6237\u540d\u79f0\uff0c\u9ed8\u8ba4\u503c\u4e3a user -p \u7528\u6765\u8bbe\u7f6e\u5bc6\u7801\uff0c\u7528\u6237 user \u7684\u5bc6\u7801\u4e3a password --addr \u4e3a graphd IP \u5730\u5740 --port \u4e3a graphd \u670d\u52a1\u7aef\u53e3\uff0c\u9ed8\u8ba4\u503c\u4e3a 3699 \u914d\u7f6e\u5f15\u7528 \u00b6 Meta Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 45500 Meta daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u76ee\u5f55\uff0c\u4e0d\u652f\u6301\u591a\u76ee\u5f55 meta_server_addrs \"\" \u4e00\u7cfb\u5217\u7531\u9017\u53f7\u5206\u9694\u7684 IP \u5730\u5740\uff0cIP \u6570\u4e0e\u526f\u672c\u6570\u76f8\u7b49\uff0c\u5982\u679c\u4e3a\u7a7a\uff0c\u5219\u8868\u660e\u526f\u672c\u6570\u4e3a 1 local_ip \"\" \u6307\u5b9a\u672c\u5730 IP NetworkUtils::getLocalIP. num_io_threads 16 IO \u7ebf\u7a0b\u6570 meta_http_thread_num 3 meta daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 part_man_type memory memory\uff0cmeta pid_file \"pids/nebula-metad.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c load_config_interval_secs 2 * 60 \u52a0\u8f7d\u914d\u7f6e\u95f4\u9694 meta_ingest_thread_num 3. Meta daemon\u7684 ingest \u7ebf\u7a0b\u6570 Storage Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 44500 Storage daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u76ee\u5f55\uff0c\u591a\u6761\u8def\u5f84\u7531\u9017\u53f7\u5206\u9694\uff0c\u5bf9 RocksDB \u5f15\u64ce\uff0c\u4e00\u4e2a\u8def\u5f84\u4e3a\u4e00\u4e2a\u5b9e\u4f8b local_ip \"\" IP \u5730\u5740\u548c\u76d1\u542c\u7aef\u53e3\u5171\u540c\u7528\u4e8e\u6807\u8bc6\u6b64\u670d\u52a1\u5668 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c pid_file \"pids/nebula-storaged.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 store_type \"nebula\" storage daemon \u4f7f\u7528\u7684 KVStore \u7c7b\u578b\uff0c\u53ef\u9009\u7c7b\u578b\u4e3a \\\"nebula\\\" \u548c \\\"hbase\\\" num_io_threads 16 IO \u7ebf\u7a0b\u6570 storage_http_thread_num 3 storage daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 engine_type rocksdb RocksDB, memory ... custom_filter_interval_secs 24 * 3600 \u89e6\u53d1\u81ea\u5b9a\u4e49\u538b\u7f29\u95f4\u9694 num_workers 4 worker \u7ebf\u7a0b\u6570 rocksdb_disable_wal false \u7981\u7528 RocksDB \u7684 WAL rocksdb_db_options \"\" DBOptions\uff0c\u6bcf\u4e2a\u9009\u9879\u4ee5 : \u683c\u5f0f\u7ed9\u51fa\uff0c\u4ee5.\u5206\u9694 rocksdb_column_family_options \"\" ColumnFamilyOptions\uff0c\u6bcf\u4e2a\u9009\u9879\u4ee5 : \u683c\u5f0f\u7ed9\u51fa\uff0c\u4ee5.\u5206\u9694 rocksdb_block_based_table_options \"\" BlockBasedTableOptions\uff0c\u6bcf\u4e2a\u9009\u9879\u4ee5 : \u683c\u5f0f\u7ed9\u51fa\uff0c\u4ee5.\u5206\u9694 batch_size 4 * 1024 \u5355\u4e2a\u6279\u5904\u7406\u7684\u9ed8\u8ba4\u4fdd\u7559\u5b57\u8282 block_cache 4 BlockBasedTable:block_cache : MB download_thread_num 3 \u4e0b\u8f7d\u7ebf\u7a0b\u6570 min_vertices_per_bucket 3 \u4e00\u4e2a bucket \u4e2d\u6700\u5c0f\u8282\u70b9\u6570 max_appendlog_batch_size 128 \u6bcf\u4e2a appendLog \u6279\u8bf7\u6c42\u7684\u6700\u5927 log \u6570 max_outstanding_requests 1024 outstanding appendLog \u8bf7\u6c42\u6700\u5927\u6570 raft_rpc_timeout_ms 500 raft \u5ba2\u6237\u7aef RPC \u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2 accept_log_append_during_pulling false pull snapshot \u8fc7\u7a0b\u4e2d\u4e0d\u63a5\u53d7\u65b0 log raft_heartbeat_interval_secs 5 \u6bcf\u6b21\u5fc3\u8df3\u95f4\u9694\u65f6\u957f\uff0c\u5355\u4f4d\u79d2 max_batch_size 256 \u4e00\u4e2a batch \u4e2d\u6700\u5927 log \u6570 Graph Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 3699 Nebula Graph daemon \u76d1\u542c\u7aef\u53e3 client_idle_timeout_secs 0 \u5173\u95ed idle \u8fde\u63a5\u524d\u7684\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c 0 \u4e3a\u65e0\u7a77\u5927 session_idle_timeout_secs 600 idle sessions \u8fc7\u671f\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c0 \u4e3a\u65e0\u7a77\u5927 session_reclaim_interval_secs 10 \u8d85\u51fa\u6307\u5b9a\u65f6\u95f4\u5219\u8ba4\u4e3a\u8d85\u65f6 num_netio_threads 0 networking \u7ebf\u7a0b\u6570\uff0c0\u4e3a\u7269\u7406 CPU \u6838\u6570 num_accept_threads 1 \u63a5\u53d7\u8fdb\u5165\u8fde\u63a5\u7684\u7ebf\u7a0b\u6570 num_worker_threads 1 \u6267\u884c\u7528\u6237\u67e5\u8be2\u7684\u7ebf\u7a0b\u6570 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 listen_backlog 1024 listen socket \u7684 backlog listen_netdev \"any\" \u76d1\u542c\u7684\u7f51\u7edc\u670d\u52a1 pid_file \"pids/nebula-graphd.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 redirect_stdout true \u5c06 stdout \u548c stderr \u91cd\u5b9a\u5411\u5230\u5355\u72ec\u7684\u6587\u4ef6 stdout_log_file \"graphd-stdout.log\" stdout \u76ee\u6807\u6587\u4ef6\u540d stderr_log_file \"graphd-stderr.log\" stderr \u76ee\u6807\u6587\u4ef6\u540d daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 Web Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e ws_http_port 11000 HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_h2_port 11002 HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570 ws_meta_http_port 11000 Meta HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_meta_h2_port 11002 Meta HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_storage_http_port 12000 Storage HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_storage_h2_port 12002 Storage HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3 Console \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e addr \"127.0.0.1\" Nebula daemon IP \u5730\u5740 port 0 Nebula daemon \u76d1\u542c\u7aef\u53e3 u \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u7528\u6237\u540d p \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u5bc6\u7801 enable_history false \u662f\u5426\u4fdd\u5b58\u5386\u53f2\u547d\u4ee4 server_conn_timeout_ms 1000 \u8fde\u63a5\u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2 \u6ce8\u610f\uff1a \u914d\u7f6e\u65f6\u8bf7\u786e\u4fdd\u7aef\u53e3\u672a\u88ab\u9632\u706b\u5899\u963b\u62e6","title":"\u96c6\u7fa4\u90e8\u7f72"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#_1","text":"\u672c\u8282\u4ecb\u7ecd Nebula Graph \u7684\u90e8\u7f72","title":"\u96c6\u7fa4\u90e8\u7f72"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#_2","text":"\u76ee\u524d\uff0c Nebula Graph \u5b98\u65b9\u63d0\u4f9b CentOS 7.5 \uff0c CentOS 6.5 \uff0c Ubuntu 1604 \u548c Ubuntu 1804 \u5305\uff0crpm \u6216 deb \u5305\u4e0b\u8f7d\u70b9\u51fb \u6b64\u5904 \u3002 CentOS \u7cfb\u7edf\uff1a rpm -ivh nebula- { VERSION } . { SYSTEM_VERSION } .x86_64.rpm Ubuntu \u7cfb\u7edf\uff1a dpkg -i nebula- { VERSION } . { SYSTEM_VERSION } .amd64.deb \u914d\u7f6e\u6587\u4ef6\u9ed8\u8ba4\u76ee\u5f55\u4e3a /usr/local/nebula/etc \uff0c\u8bf7\u66f4\u6539 meta_server_addrs \uff0c\u914d\u7f6e Meta Server \u7684\u5730\u5740\u3002 \u542f\u52a8\u591a\u526f\u672c Meta \u670d\u52a1\u9700\u5c06\u591a\u4e2a\u5730\u5740\u914d\u7f6e\u5230 meta_server_addrs \uff0c\u5730\u5740\u95f4\u9700\u4f7f\u7528\u9017\u53f7\u5206\u9694\u3002 \u4f7f\u7528 data_path \u8bbe\u7f6e Meta \u7684\u5e95\u5c42\u5b58\u50a8\u8def\u5f84\u3002","title":"\u4e0b\u8f7d\u5e76\u5b89\u88c5\u5305"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#nebula_graph","text":"\u76ee\u524d\uff0c Nebula Graph \u96c6\u7fa4\u7531 scripts/services.sh \u8fd0\u7ef4\uff0c\u53ef\u4f7f\u7528\u6b64\u811a\u672c start \uff0c stop \u6216 restart \u91cd\u542f\u96c6\u7fa4\u3002 \u793a\u4f8b\u547d\u4ee4\u5982\u4e0b\uff1a scripts/services.sh <start | stop | restart | status | kill> metas\uff0c storages \u548c graphs \u5305\u542b\u5176\u81ea\u8eab\u7684 hosts\u3002","title":"\u542f\u52a8 Nebula Graph \u96c6\u7fa4"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#nebula_graph_1","text":"> bin/nebula -u = user -p = password --addr ={ graphd IP address } --port ={ graphd listening port } -u \u7528\u6765\u8bbe\u7f6e\u7528\u6237\u540d\u79f0\uff0c\u9ed8\u8ba4\u503c\u4e3a user -p \u7528\u6765\u8bbe\u7f6e\u5bc6\u7801\uff0c\u7528\u6237 user \u7684\u5bc6\u7801\u4e3a password --addr \u4e3a graphd IP \u5730\u5740 --port \u4e3a graphd \u670d\u52a1\u7aef\u53e3\uff0c\u9ed8\u8ba4\u503c\u4e3a 3699","title":"\u8fde\u63a5 Nebula Graph"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#_3","text":"Meta Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 45500 Meta daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u76ee\u5f55\uff0c\u4e0d\u652f\u6301\u591a\u76ee\u5f55 meta_server_addrs \"\" \u4e00\u7cfb\u5217\u7531\u9017\u53f7\u5206\u9694\u7684 IP \u5730\u5740\uff0cIP \u6570\u4e0e\u526f\u672c\u6570\u76f8\u7b49\uff0c\u5982\u679c\u4e3a\u7a7a\uff0c\u5219\u8868\u660e\u526f\u672c\u6570\u4e3a 1 local_ip \"\" \u6307\u5b9a\u672c\u5730 IP NetworkUtils::getLocalIP. num_io_threads 16 IO \u7ebf\u7a0b\u6570 meta_http_thread_num 3 meta daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 part_man_type memory memory\uff0cmeta pid_file \"pids/nebula-metad.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c load_config_interval_secs 2 * 60 \u52a0\u8f7d\u914d\u7f6e\u95f4\u9694 meta_ingest_thread_num 3. Meta daemon\u7684 ingest \u7ebf\u7a0b\u6570 Storage Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 44500 Storage daemon \u76d1\u542c\u7aef\u53e3 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 data_path \"\" \u6839\u6570\u636e\u76ee\u5f55\uff0c\u591a\u6761\u8def\u5f84\u7531\u9017\u53f7\u5206\u9694\uff0c\u5bf9 RocksDB \u5f15\u64ce\uff0c\u4e00\u4e2a\u8def\u5f84\u4e3a\u4e00\u4e2a\u5b9e\u4f8b local_ip \"\" IP \u5730\u5740\u548c\u76d1\u542c\u7aef\u53e3\u5171\u540c\u7528\u4e8e\u6807\u8bc6\u6b64\u670d\u52a1\u5668 daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c pid_file \"pids/nebula-storaged.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 store_type \"nebula\" storage daemon \u4f7f\u7528\u7684 KVStore \u7c7b\u578b\uff0c\u53ef\u9009\u7c7b\u578b\u4e3a \\\"nebula\\\" \u548c \\\"hbase\\\" num_io_threads 16 IO \u7ebf\u7a0b\u6570 storage_http_thread_num 3 storage daemon \u7684 http \u7ebf\u7a0b\u6570 num_worker_threads 32 worker \u6570 engine_type rocksdb RocksDB, memory ... custom_filter_interval_secs 24 * 3600 \u89e6\u53d1\u81ea\u5b9a\u4e49\u538b\u7f29\u95f4\u9694 num_workers 4 worker \u7ebf\u7a0b\u6570 rocksdb_disable_wal false \u7981\u7528 RocksDB \u7684 WAL rocksdb_db_options \"\" DBOptions\uff0c\u6bcf\u4e2a\u9009\u9879\u4ee5 : \u683c\u5f0f\u7ed9\u51fa\uff0c\u4ee5.\u5206\u9694 rocksdb_column_family_options \"\" ColumnFamilyOptions\uff0c\u6bcf\u4e2a\u9009\u9879\u4ee5 : \u683c\u5f0f\u7ed9\u51fa\uff0c\u4ee5.\u5206\u9694 rocksdb_block_based_table_options \"\" BlockBasedTableOptions\uff0c\u6bcf\u4e2a\u9009\u9879\u4ee5 : \u683c\u5f0f\u7ed9\u51fa\uff0c\u4ee5.\u5206\u9694 batch_size 4 * 1024 \u5355\u4e2a\u6279\u5904\u7406\u7684\u9ed8\u8ba4\u4fdd\u7559\u5b57\u8282 block_cache 4 BlockBasedTable:block_cache : MB download_thread_num 3 \u4e0b\u8f7d\u7ebf\u7a0b\u6570 min_vertices_per_bucket 3 \u4e00\u4e2a bucket \u4e2d\u6700\u5c0f\u8282\u70b9\u6570 max_appendlog_batch_size 128 \u6bcf\u4e2a appendLog \u6279\u8bf7\u6c42\u7684\u6700\u5927 log \u6570 max_outstanding_requests 1024 outstanding appendLog \u8bf7\u6c42\u6700\u5927\u6570 raft_rpc_timeout_ms 500 raft \u5ba2\u6237\u7aef RPC \u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2 accept_log_append_during_pulling false pull snapshot \u8fc7\u7a0b\u4e2d\u4e0d\u63a5\u53d7\u65b0 log raft_heartbeat_interval_secs 5 \u6bcf\u6b21\u5fc3\u8df3\u95f4\u9694\u65f6\u957f\uff0c\u5355\u4f4d\u79d2 max_batch_size 256 \u4e00\u4e2a batch \u4e2d\u6700\u5927 log \u6570 Graph Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e port 3699 Nebula Graph daemon \u76d1\u542c\u7aef\u53e3 client_idle_timeout_secs 0 \u5173\u95ed idle \u8fde\u63a5\u524d\u7684\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c 0 \u4e3a\u65e0\u7a77\u5927 session_idle_timeout_secs 600 idle sessions \u8fc7\u671f\u65f6\u957f\uff08\u5355\u4f4d\u79d2\uff09\uff0c0 \u4e3a\u65e0\u7a77\u5927 session_reclaim_interval_secs 10 \u8d85\u51fa\u6307\u5b9a\u65f6\u95f4\u5219\u8ba4\u4e3a\u8d85\u65f6 num_netio_threads 0 networking \u7ebf\u7a0b\u6570\uff0c0\u4e3a\u7269\u7406 CPU \u6838\u6570 num_accept_threads 1 \u63a5\u53d7\u8fdb\u5165\u8fde\u63a5\u7684\u7ebf\u7a0b\u6570 num_worker_threads 1 \u6267\u884c\u7528\u6237\u67e5\u8be2\u7684\u7ebf\u7a0b\u6570 reuse_port true \u5f00\u542f SO_REUSEPORT \u9009\u9879 listen_backlog 1024 listen socket \u7684 backlog listen_netdev \"any\" \u76d1\u542c\u7684\u7f51\u7edc\u670d\u52a1 pid_file \"pids/nebula-graphd.pid\" \u5b58\u50a8\u8fdb\u7a0b ID \u7684\u6587\u4ef6 redirect_stdout true \u5c06 stdout \u548c stderr \u91cd\u5b9a\u5411\u5230\u5355\u72ec\u7684\u6587\u4ef6 stdout_log_file \"graphd-stdout.log\" stdout \u76ee\u6807\u6587\u4ef6\u540d stderr_log_file \"graphd-stderr.log\" stderr \u76ee\u6807\u6587\u4ef6\u540d daemonize true \u4f5c\u4e3a daemon \u8fdb\u7a0b\u8fd0\u884c meta_server_addrs \"\" meta server \u5730\u5740\u5217\u8868\uff0c\u683c\u5f0f\u4e3a ip1:port1, ip2:port2, ip3:port3 Web Service \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e ws_http_port 11000 HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_h2_port 11002 HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_ip \"127.0.0.1\" IP/Hostname \u7ed1\u5b9a\u5730\u5740 ws_threads 4 web service \u7ebf\u7a0b\u6570 ws_meta_http_port 11000 Meta HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_meta_h2_port 11002 Meta HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_storage_http_port 12000 Storage HTTP \u534f\u8bae\u76d1\u542c\u7aef\u53e3 ws_storage_h2_port 12002 Storage HTTP/2 \u534f\u8bae\u76d1\u542c\u7aef\u53e3 Console \u652f\u6301\u5982\u4e0b\u914d\u7f6e\u5c5e\u6027\uff1a \u5c5e\u6027\u540d \u9ed8\u8ba4\u503c \u8bf4\u660e addr \"127.0.0.1\" Nebula daemon IP \u5730\u5740 port 0 Nebula daemon \u76d1\u542c\u7aef\u53e3 u \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u7528\u6237\u540d p \"\" \u7528\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u7684\u5bc6\u7801 enable_history false \u662f\u5426\u4fdd\u5b58\u5386\u53f2\u547d\u4ee4 server_conn_timeout_ms 1000 \u8fde\u63a5\u8d85\u65f6\u65f6\u957f\uff0c\u5355\u4f4d\u6beb\u79d2 \u6ce8\u610f\uff1a \u914d\u7f6e\u65f6\u8bf7\u786e\u4fdd\u7aef\u53e3\u672a\u88ab\u9632\u706b\u5899\u963b\u62e6","title":"\u914d\u7f6e\u5f15\u7528"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/","text":"\u4f7f\u7528 rpm/deb \u5305\u5b89\u88c5 Nebula Graph \u00b6 \u6982\u89c8 \u00b6 \u672c\u6307\u5357\u5c06\u6307\u5bfc\u60a8\u4f7f\u7528 rpm/deb \u5305\u6765\u5b89\u88c5 Nebula Graph \u3002 \u524d\u63d0\u6761\u4ef6 \u00b6 \u5728\u5f00\u59cb\u524d\uff0c\u8bf7\u786e\u4fdd\u6ee1\u8db3\u4ee5\u4e0b\u6761\u4ef6\uff1a \u786c\u76d8\uff1a50 GB \u5185\u5b58\uff1a8 GB \u5b89\u88c5 Nebula Graph \u00b6 \u4f7f\u7528 rpm/deb \u5305\u6765\u5b89\u88c5 Nebula Graph \uff0c\u9700\u8981\u5b8c\u6210\u4ee5\u4e0b\u6b65\u9aa4\uff1a \u4e0b\u8f7d\u5b89\u88c5\u5305 \u65b9\u5f0f\u4e00\uff1a\u901a\u8fc7\u963f\u91cc\u4e91 OSS \u83b7\u53d6\u5b89\u88c5\u5305\u3002\uff08\u56fd\u5185\u7528\u6237\u53ef\u4f18\u5148\u8003\u8651\u4f7f\u7528 OSS \u4e0b\u8f7d\uff09 \u83b7\u53d6 release \u7248\u672c\uff0cURL \u683c\u5f0f\u5982\u4e0b\uff1a Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1604 \u94fe\u63a5\u4e2d ${release_version} \u4e3a\u5177\u4f53\u7684\u53d1\u5e03\u7248\u672c\u53f7\uff0c\u4f8b\u5982\u8981\u4e0b\u8f7d 1.0.0-rc2 Centos 7 \u7684\u5b89\u88c5\u5305\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u547d\u4ee4\u4e0b\u8f7d\u3002 bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/1.0.0-rc2/nebula-1.0.0-rc2.el7-5.x86_64.rpm b. \u83b7\u53d6 nightly \u7248\u672c\uff0cURL \u683c\u5f0f\u5982\u4e0b\uff1a Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1804 \u94fe\u63a5\u4e2d ${date} \u4e3a\u5177\u4f53\u7684\u65e5\u671f\uff0c\u4f8b\u5982\u8981\u4e0b\u8f7d 2020\u5e744\u67081\u65e5\u7684 Centos 7 \u7684\u5b89\u88c5\u5305\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u547d\u4ee4\u4e0b\u8f7d bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/nightly/2020.04.01/nebula-2020.04.01-nightly.el7-5.x86_64.rpm \u65b9\u5f0f\u4e8c\uff1a\u901a\u8fc7 GitHub \u83b7\u53d6\u5b89\u88c5\u5305 \u767b\u5f55\u5230 GitHub \u5e76\u5355\u51fb rpm/deb \u94fe\u63a5\u3002 \u5728 Actions \u9009\u9879\u5361\u4e0b\uff0c\u5355\u51fb\u5de6\u4fa7\u7684 package \uff0c\u663e\u793a\u6240\u6709\u53ef\u7528\u7684\u5305\u3002 \u5355\u51fb\u5217\u8868\u9876\u90e8\u6700\u65b0\u7684\u5305\u3002 \u5355\u51fb\u53f3\u4e0a\u89d2 Artifacts \uff0c \u9009\u62e9\u8981\u4e0b\u8f7d\u7684\u5b89\u88c5\u5305\u3002 \u5b89\u88c5 Nebula Graph \u3002 \u5982\u679c\u662f rpm \u6587\u4ef6\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5 Nebula Graph \uff1a $ sudo rpm -ivh nebula-2019.12.23-nightly.el6-5.x86_64.rpm \u5982\u679c\u662f deb \u6587\u4ef6\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5 Nebula Graph \uff1a $ sudo dpkg -i nebula-2019.12.23-nightly.ubuntu1604.amd64.deb \u5982\u9700\u5b89\u88c5\u81f3\u81ea\u5b9a\u4e49\u76ee\u5f55\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a rpm -ivh --prefix = ${ your_dir } nebula-graph- ${ version } .rpm \u5982\u9700\u5c06 Nebula Graph \u6253\u5305\u81f3\u4e00\u4e2a\u5305\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a cd nebula/package ./package.sh -v <version> \u5982\u9700\u5c06 Nebula Graph \u6253\u5305\u81f3\u591a\u4e2a\u5305\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a cd nebula/package ./package.sh -v <version> -n OFF \u6ce8\u610f \uff1a \u4f7f\u7528\u60a8\u81ea\u5df1\u7684\u6587\u4ef6\u540d\u66ff\u6362\u4ee5\u4e0a\u547d\u4ee4\u4e2d\u7684\u6587\u4ef6\u540d\uff0c\u5426\u5219\u4ee5\u4e0a\u547d\u4ee4\u53ef\u80fd\u6267\u884c\u5931\u8d25\u3002 Nebula Graph \u9ed8\u8ba4\u4f1a\u5b89\u88c5\u5728 /usr/local/nebula \u76ee\u5f55\u4e0b\u3002 \u542f\u52a8 Nebula Graph \u670d\u52a1 \u00b6 \u6210\u529f\u5b89\u88c5 Nebula Graph \u540e\uff0c\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u542f\u52a8 Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/scripts/nebula.service start all \u67e5\u770b Nebula Graph \u670d\u52a1 \u00b6 \u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/scripts/nebula.service status all \u8fde\u63a5 Nebula Graph \u670d\u52a1 \u00b6 \u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u8fde\u63a5 Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/bin/nebula -u user -p password \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u6210\u529f\u8fde\u63a5\u4e86 Nebula Graph \u670d\u52a1\uff0c\u5c06\u8fd4\u56de Welcome to Nebula Graph \u6d88\u606f\u3002 \u505c\u6b62 Nebula Graph \u670d\u52a1 \u00b6 \u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u505c\u6b62 Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/scripts/nebula.service stop all","title":"\u4f7f\u7528 rpm/deb \u5305\u5b89\u88c5 **Nebula Graph**"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#rpmdeb_nebula_graph","text":"","title":"\u4f7f\u7528 rpm/deb \u5305\u5b89\u88c5 Nebula Graph"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#_1","text":"\u672c\u6307\u5357\u5c06\u6307\u5bfc\u60a8\u4f7f\u7528 rpm/deb \u5305\u6765\u5b89\u88c5 Nebula Graph \u3002","title":"\u6982\u89c8"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#_2","text":"\u5728\u5f00\u59cb\u524d\uff0c\u8bf7\u786e\u4fdd\u6ee1\u8db3\u4ee5\u4e0b\u6761\u4ef6\uff1a \u786c\u76d8\uff1a50 GB \u5185\u5b58\uff1a8 GB","title":"\u524d\u63d0\u6761\u4ef6"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#nebula_graph","text":"\u4f7f\u7528 rpm/deb \u5305\u6765\u5b89\u88c5 Nebula Graph \uff0c\u9700\u8981\u5b8c\u6210\u4ee5\u4e0b\u6b65\u9aa4\uff1a \u4e0b\u8f7d\u5b89\u88c5\u5305 \u65b9\u5f0f\u4e00\uff1a\u901a\u8fc7\u963f\u91cc\u4e91 OSS \u83b7\u53d6\u5b89\u88c5\u5305\u3002\uff08\u56fd\u5185\u7528\u6237\u53ef\u4f18\u5148\u8003\u8651\u4f7f\u7528 OSS \u4e0b\u8f7d\uff09 \u83b7\u53d6 release \u7248\u672c\uff0cURL \u683c\u5f0f\u5982\u4e0b\uff1a Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1604 \u94fe\u63a5\u4e2d ${release_version} \u4e3a\u5177\u4f53\u7684\u53d1\u5e03\u7248\u672c\u53f7\uff0c\u4f8b\u5982\u8981\u4e0b\u8f7d 1.0.0-rc2 Centos 7 \u7684\u5b89\u88c5\u5305\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u547d\u4ee4\u4e0b\u8f7d\u3002 bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/1.0.0-rc2/nebula-1.0.0-rc2.el7-5.x86_64.rpm b. \u83b7\u53d6 nightly \u7248\u672c\uff0cURL \u683c\u5f0f\u5982\u4e0b\uff1a Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1804 \u94fe\u63a5\u4e2d ${date} \u4e3a\u5177\u4f53\u7684\u65e5\u671f\uff0c\u4f8b\u5982\u8981\u4e0b\u8f7d 2020\u5e744\u67081\u65e5\u7684 Centos 7 \u7684\u5b89\u88c5\u5305\uff0c\u90a3\u4e48\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7\u547d\u4ee4\u4e0b\u8f7d bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/nightly/2020.04.01/nebula-2020.04.01-nightly.el7-5.x86_64.rpm \u65b9\u5f0f\u4e8c\uff1a\u901a\u8fc7 GitHub \u83b7\u53d6\u5b89\u88c5\u5305 \u767b\u5f55\u5230 GitHub \u5e76\u5355\u51fb rpm/deb \u94fe\u63a5\u3002 \u5728 Actions \u9009\u9879\u5361\u4e0b\uff0c\u5355\u51fb\u5de6\u4fa7\u7684 package \uff0c\u663e\u793a\u6240\u6709\u53ef\u7528\u7684\u5305\u3002 \u5355\u51fb\u5217\u8868\u9876\u90e8\u6700\u65b0\u7684\u5305\u3002 \u5355\u51fb\u53f3\u4e0a\u89d2 Artifacts \uff0c \u9009\u62e9\u8981\u4e0b\u8f7d\u7684\u5b89\u88c5\u5305\u3002 \u5b89\u88c5 Nebula Graph \u3002 \u5982\u679c\u662f rpm \u6587\u4ef6\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5 Nebula Graph \uff1a $ sudo rpm -ivh nebula-2019.12.23-nightly.el6-5.x86_64.rpm \u5982\u679c\u662f deb \u6587\u4ef6\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5 Nebula Graph \uff1a $ sudo dpkg -i nebula-2019.12.23-nightly.ubuntu1604.amd64.deb \u5982\u9700\u5b89\u88c5\u81f3\u81ea\u5b9a\u4e49\u76ee\u5f55\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a rpm -ivh --prefix = ${ your_dir } nebula-graph- ${ version } .rpm \u5982\u9700\u5c06 Nebula Graph \u6253\u5305\u81f3\u4e00\u4e2a\u5305\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a cd nebula/package ./package.sh -v <version> \u5982\u9700\u5c06 Nebula Graph \u6253\u5305\u81f3\u591a\u4e2a\u5305\uff0c\u8bf7\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a cd nebula/package ./package.sh -v <version> -n OFF \u6ce8\u610f \uff1a \u4f7f\u7528\u60a8\u81ea\u5df1\u7684\u6587\u4ef6\u540d\u66ff\u6362\u4ee5\u4e0a\u547d\u4ee4\u4e2d\u7684\u6587\u4ef6\u540d\uff0c\u5426\u5219\u4ee5\u4e0a\u547d\u4ee4\u53ef\u80fd\u6267\u884c\u5931\u8d25\u3002 Nebula Graph \u9ed8\u8ba4\u4f1a\u5b89\u88c5\u5728 /usr/local/nebula \u76ee\u5f55\u4e0b\u3002","title":"\u5b89\u88c5 Nebula Graph"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#nebula_graph_1","text":"\u6210\u529f\u5b89\u88c5 Nebula Graph \u540e\uff0c\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u542f\u52a8 Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/scripts/nebula.service start all","title":"\u542f\u52a8 Nebula Graph \u670d\u52a1"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#nebula_graph_2","text":"\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u67e5\u770b Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/scripts/nebula.service status all","title":"\u67e5\u770b Nebula Graph \u670d\u52a1"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#nebula_graph_3","text":"\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u8fde\u63a5 Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/bin/nebula -u user -p password \u6ce8\u610f \uff1a\u5982\u679c\u60a8\u6210\u529f\u8fde\u63a5\u4e86 Nebula Graph \u670d\u52a1\uff0c\u5c06\u8fd4\u56de Welcome to Nebula Graph \u6d88\u606f\u3002","title":"\u8fde\u63a5 Nebula Graph \u670d\u52a1"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#nebula_graph_4","text":"\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4\u505c\u6b62 Nebula Graph \u670d\u52a1\uff1a $ sudo /usr/local/nebula/scripts/nebula.service stop all","title":"\u505c\u6b62 Nebula Graph \u670d\u52a1"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/alter-user-syntax/","text":"ALTER USER \u8bed\u6cd5 \u00b6 ALTER USER <user_name> WITH PASSWORD <password> \u4f7f\u7528 ALTER USER \u8bed\u53e5\u4fee\u6539 Nebula Graph \u5e10\u6237\u3002\u4f7f\u7528 ALTER USER \u5fc5\u987b\u62e5\u6709\u5168\u5c40\u7684 CREATE USER \u6743\u9650\u3002\u5c1d\u8bd5\u4fee\u6539\u4e00\u4e2a\u4e0d\u5b58\u5728\u7684\u7528\u6237\u4f1a\u53d1\u751f\u9519\u8bef\u3002 ALTER \u65e0\u9700\u5bc6\u7801\u6821\u9a8c\u3002","title":"ALTER USER \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/alter-user-syntax/#alter_user","text":"ALTER USER <user_name> WITH PASSWORD <password> \u4f7f\u7528 ALTER USER \u8bed\u53e5\u4fee\u6539 Nebula Graph \u5e10\u6237\u3002\u4f7f\u7528 ALTER USER \u5fc5\u987b\u62e5\u6709\u5168\u5c40\u7684 CREATE USER \u6743\u9650\u3002\u5c1d\u8bd5\u4fee\u6539\u4e00\u4e2a\u4e0d\u5b58\u5728\u7684\u7528\u6237\u4f1a\u53d1\u751f\u9519\u8bef\u3002 ALTER \u65e0\u9700\u5bc6\u7801\u6821\u9a8c\u3002","title":"ALTER USER \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/built-in-roles/","text":"Built-in Roles \u00b6 Nebula Graph \u89d2\u8272\u53ef\u5206\u4e3a\u4ee5\u4e0b\u51e0\u7c7b\uff1a God \u521d\u59cb Root \u7528\u6237\uff08\u7c7b\u4f3c\u4e8e Linux \u7cfb\u7edf\u4e2d\u7684 Root\uff0c\u548c Windows \u7cfb\u7edf\u4e2d\u7684 Administrator\uff09\u3002 \u62e5\u6709\u6240\u6709\u64cd\u4f5c\u6743\u9650\u3002 \u4e00\u4e2a\u96c6\u7fa4\u53ea\u80fd\u6709\u4e00\u4e2a God\u3002God \u53ef\u7ba1\u7406\u96c6\u7fa4\u5185\u6240\u6709 space\u3002 God \u89d2\u8272\u7531 meta \u81ea\u52a8\u521d\u59cb\u5316\uff0c\u4e14\u4e0d\u652f\u6301\u7528\u6237\u81ea\u884c\u6388\u6743\u6210\u4e3a God\u3002 Admin \u7ba1\u7406\u5458\u7528\u6237\u3002 \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u548c data \u7684\u8bfb/\u5199\u6743\u9650\u3002 \u53ef\u5bf9\u6743\u9650\u5185\u7684 space \u8fdb\u884c\u7528\u6237\u53d7\u6743\u3002 DBA \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u548c data \u7684\u8bfb/\u5199\u6743\u9650\u3002 \u6ca1\u6709\u5bf9\u7528\u6237\u53d7\u6743\u7684\u6743\u9650\u3002 User \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 data \u7684\u8bfb/\u5199\u6743\u9650\u3002 \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u53ea\u8bfb\u6743\u9650\u3002 Guest \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u548c data \u7684\u53ea\u8bfb\u6743\u9650\u3002 \u5982\u679c\u5f00\u542f\u7528\u6237\u6743\u9650\u5f00\u5173\uff0c\u5219\u9ed8\u8ba4\u7528\u6237\u540d\u4e3a root\uff0c\u9ed8\u8ba4\u5bc6\u7801\u4e3a nebula\uff0c\u4e14\u7528\u6237\u540d\u4e0d\u53ef\u66f4\u6539\u3002\u5c06 /usr/local/nebula/etc/nebula-graphd.conf \u6587\u4ef6\u4e2d\u7684 enable_authorize \u8bbe\u7f6e\u4e3a true \u5373\u53ef\u6253\u5f00\u6743\u9650\u5f00\u5173\u3002 \u672a\u88ab\u5206\u914d\u89d2\u8272\u7684\u7528\u6237\u5c06\u65e0\u6743\u8bbf\u95ee\u8be5 space\u3002\u4e00\u4e2a\u7528\u6237\u5728\u540c\u4e00\u4e2a space \u4e2d\u53ea\u80fd\u5206\u914d\u4e00\u4e2a\u89d2\u8272\u3002\u4e00\u4e2a\u7528\u6237\u5728\u4e0d\u540c space \u53ef\u62e5\u6709\u4e0d\u540c\u6743\u9650\u3002 \u5404\u89d2\u8272\u7684 Executor \u6743\u9650\u89c1\u4e0b\u8868\u3002 \u6309\u64cd\u4f5c\u6743\u9650\u5212\u5206\u3002 OPERATION STATEMENTS Read space Use, DescribeSpace Write space CreateSpace, DropSpace, CreateSnapshot, DropSnapshot, Balance, Admin, Config, Ingest, Download Read schema DescribeTag, DescribeEdge, DescribeTagIndex, DescribeEdgeIndex Write schema CreateTag, AlterTag, CreateEdge, AlterEdge, DropTag, DropEdge, CreateTagIndex, CreateEdgeIndex, DropTagIndex, DropEdgeIndex Write user CreateUser, DropUser, AlterUser Write role Grant, Revoke Read data Go, Set, Pipe, Match, Assignment, Lookup, Yield, OrderBy, FetchVertices, Find, FetchEdges, FindPath, Limit, GroupBy, Return Write data BuildTagIndex, BuildEdgeIndex, InsertVertex, UpdateVertex, InsertEdge, UpdateEdge, DeleteVertex, DeleteEdges Special operation Show, ChangePassword \u6309\u64cd\u4f5c\u5212\u5206\u3002 OPERATION GOD ADMIN DBA USER GUEST Read space Y Y Y Y Y Write space Y Read schema Y Y Y Y Y Write schema Y Y Y Write user Y Write role Y Y Read data Y Y Y Y Y Write data Y Y Y Y Special operation Y Y Y Y Y","title":"Built-in Roles"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/built-in-roles/#built-in_roles","text":"Nebula Graph \u89d2\u8272\u53ef\u5206\u4e3a\u4ee5\u4e0b\u51e0\u7c7b\uff1a God \u521d\u59cb Root \u7528\u6237\uff08\u7c7b\u4f3c\u4e8e Linux \u7cfb\u7edf\u4e2d\u7684 Root\uff0c\u548c Windows \u7cfb\u7edf\u4e2d\u7684 Administrator\uff09\u3002 \u62e5\u6709\u6240\u6709\u64cd\u4f5c\u6743\u9650\u3002 \u4e00\u4e2a\u96c6\u7fa4\u53ea\u80fd\u6709\u4e00\u4e2a God\u3002God \u53ef\u7ba1\u7406\u96c6\u7fa4\u5185\u6240\u6709 space\u3002 God \u89d2\u8272\u7531 meta \u81ea\u52a8\u521d\u59cb\u5316\uff0c\u4e14\u4e0d\u652f\u6301\u7528\u6237\u81ea\u884c\u6388\u6743\u6210\u4e3a God\u3002 Admin \u7ba1\u7406\u5458\u7528\u6237\u3002 \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u548c data \u7684\u8bfb/\u5199\u6743\u9650\u3002 \u53ef\u5bf9\u6743\u9650\u5185\u7684 space \u8fdb\u884c\u7528\u6237\u53d7\u6743\u3002 DBA \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u548c data \u7684\u8bfb/\u5199\u6743\u9650\u3002 \u6ca1\u6709\u5bf9\u7528\u6237\u53d7\u6743\u7684\u6743\u9650\u3002 User \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 data \u7684\u8bfb/\u5199\u6743\u9650\u3002 \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u53ea\u8bfb\u6743\u9650\u3002 Guest \u5bf9\u6743\u9650\u5185\u7684 space \u62e5\u6709 schema \u548c data \u7684\u53ea\u8bfb\u6743\u9650\u3002 \u5982\u679c\u5f00\u542f\u7528\u6237\u6743\u9650\u5f00\u5173\uff0c\u5219\u9ed8\u8ba4\u7528\u6237\u540d\u4e3a root\uff0c\u9ed8\u8ba4\u5bc6\u7801\u4e3a nebula\uff0c\u4e14\u7528\u6237\u540d\u4e0d\u53ef\u66f4\u6539\u3002\u5c06 /usr/local/nebula/etc/nebula-graphd.conf \u6587\u4ef6\u4e2d\u7684 enable_authorize \u8bbe\u7f6e\u4e3a true \u5373\u53ef\u6253\u5f00\u6743\u9650\u5f00\u5173\u3002 \u672a\u88ab\u5206\u914d\u89d2\u8272\u7684\u7528\u6237\u5c06\u65e0\u6743\u8bbf\u95ee\u8be5 space\u3002\u4e00\u4e2a\u7528\u6237\u5728\u540c\u4e00\u4e2a space \u4e2d\u53ea\u80fd\u5206\u914d\u4e00\u4e2a\u89d2\u8272\u3002\u4e00\u4e2a\u7528\u6237\u5728\u4e0d\u540c space \u53ef\u62e5\u6709\u4e0d\u540c\u6743\u9650\u3002 \u5404\u89d2\u8272\u7684 Executor \u6743\u9650\u89c1\u4e0b\u8868\u3002 \u6309\u64cd\u4f5c\u6743\u9650\u5212\u5206\u3002 OPERATION STATEMENTS Read space Use, DescribeSpace Write space CreateSpace, DropSpace, CreateSnapshot, DropSnapshot, Balance, Admin, Config, Ingest, Download Read schema DescribeTag, DescribeEdge, DescribeTagIndex, DescribeEdgeIndex Write schema CreateTag, AlterTag, CreateEdge, AlterEdge, DropTag, DropEdge, CreateTagIndex, CreateEdgeIndex, DropTagIndex, DropEdgeIndex Write user CreateUser, DropUser, AlterUser Write role Grant, Revoke Read data Go, Set, Pipe, Match, Assignment, Lookup, Yield, OrderBy, FetchVertices, Find, FetchEdges, FindPath, Limit, GroupBy, Return Write data BuildTagIndex, BuildEdgeIndex, InsertVertex, UpdateVertex, InsertEdge, UpdateEdge, DeleteVertex, DeleteEdges Special operation Show, ChangePassword \u6309\u64cd\u4f5c\u5212\u5206\u3002 OPERATION GOD ADMIN DBA USER GUEST Read space Y Y Y Y Y Write space Y Read schema Y Y Y Y Y Write schema Y Y Y Write user Y Write role Y Y Read data Y Y Y Y Y Write data Y Y Y Y Special operation Y Y Y Y Y","title":"Built-in Roles"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/change-password/","text":"CHANGE PASSWORD \u8bed\u6cd5 \u00b6 CHANGE PASSWORD <user_name> FROM <old_psw> TO <new-psw> CHANGE PASSWORD \u66f4\u6539 Nebula Graph \u7528\u6237\u8d26\u6237\u5bc6\u7801\u3002\u66f4\u6539\u5bc6\u7801\u9700\u540c\u65f6\u63d0\u4f9b\u65b0\u5bc6\u7801\u548c\u65e7\u5bc6\u7801\u3002","title":"CHANGE PASSWORD \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/change-password/#change_password","text":"CHANGE PASSWORD <user_name> FROM <old_psw> TO <new-psw> CHANGE PASSWORD \u66f4\u6539 Nebula Graph \u7528\u6237\u8d26\u6237\u5bc6\u7801\u3002\u66f4\u6539\u5bc6\u7801\u9700\u540c\u65f6\u63d0\u4f9b\u65b0\u5bc6\u7801\u548c\u65e7\u5bc6\u7801\u3002","title":"CHANGE PASSWORD \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/create-user-syntax/","text":"CREATE USER \u8bed\u6cd5 \u00b6 CREATE USER [IF NOT EXISTS] <user_name> [WITH PASSWORD <password>] \u4f7f\u7528 CREATE USER \u8bed\u53e5\u521b\u5efa\u65b0\u7684 Nebula Graph \u5e10\u6237\u3002\u4f7f\u7528 CREATE USER \u5fc5\u987b\u62e5\u6709\u5168\u5c40\u7684 CREATE USER \u6743\u9650\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5c1d\u8bd5\u521b\u5efa\u4e00\u4e2a\u5df2\u7ecf\u5b58\u5728\u7684\u7528\u6237\u4f1a\u53d1\u751f\u9519\u8bef\u3002\u5982\u679c\u4f7f\u7528 IF NOT EXISTS \u5b50\u53e5\uff0c\u5219\u4f1a\u63d0\u793a\u7528\u6237\u540d\u5df2\u5b58\u5728\u3002","title":"CREATE USER \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/create-user-syntax/#create_user","text":"CREATE USER [IF NOT EXISTS] <user_name> [WITH PASSWORD <password>] \u4f7f\u7528 CREATE USER \u8bed\u53e5\u521b\u5efa\u65b0\u7684 Nebula Graph \u5e10\u6237\u3002\u4f7f\u7528 CREATE USER \u5fc5\u987b\u62e5\u6709\u5168\u5c40\u7684 CREATE USER \u6743\u9650\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5c1d\u8bd5\u521b\u5efa\u4e00\u4e2a\u5df2\u7ecf\u5b58\u5728\u7684\u7528\u6237\u4f1a\u53d1\u751f\u9519\u8bef\u3002\u5982\u679c\u4f7f\u7528 IF NOT EXISTS \u5b50\u53e5\uff0c\u5219\u4f1a\u63d0\u793a\u7528\u6237\u540d\u5df2\u5b58\u5728\u3002","title":"CREATE USER \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/drop-user-syntax/","text":"DROP USER \u8bed\u6cd5 \u00b6 DROP USER [IF EXISTS] \u53ea\u6709 God \u548c Admin \u7528\u6237\u6709\u4f7f\u7528 DROP \u8bed\u53e5\u7684\u6743\u9650\u3002 DROP USER \u4e0d\u4f1a\u81ea\u52a8\u5173\u95ed\u4efb\u4f55\u5df2\u6253\u5f00\u7684\u5ba2\u6237\u7aef\u8fde\u63a5\u3002","title":"DROP USER \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/drop-user-syntax/#drop_user","text":"DROP USER [IF EXISTS] \u53ea\u6709 God \u548c Admin \u7528\u6237\u6709\u4f7f\u7528 DROP \u8bed\u53e5\u7684\u6743\u9650\u3002 DROP USER \u4e0d\u4f1a\u81ea\u52a8\u5173\u95ed\u4efb\u4f55\u5df2\u6253\u5f00\u7684\u5ba2\u6237\u7aef\u8fde\u63a5\u3002","title":"DROP USER \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/grant-role-syntax/","text":"GRANT ROLE \u8bed\u6cd5 \u00b6 GRANT ROLE <role_type> ON <space> TO <user> \u4f7f\u7528 GRANT \u8bed\u53e5\u4e3a Nebula Graph \u7528\u6237\u6388\u4e88\u6743\u9650\u3002\u4f7f\u7528 GRANT \u5fc5\u987b\u62e5\u6709 GRANT \u6743\u9650\u3002 \u76ee\u524d Nebula Graph \u5305\u542b\u4e94\u79cd\u89d2\u8272\u6743\u9650\uff1a GOD \u3001 ADMIN \u3001 DBA \u3001 USER \u548c GUEST \u3002 \u901a\u5e38\uff0c\u9700\u8981\u5148\u4f7f\u7528 CREATE USER \u521b\u5efa\u5e10\u6237\uff0c\u7136\u540e\u518d\u4f7f\u7528 GRANT \u4e3a\u5176\u6388\u4e88\u6743\u9650\uff08\u5047\u8bbe\u4f60\u62e5\u6709 CREATE \u548c GRANT \u6743\u9650\uff09\u3002\u5f85\u6388\u4e88\u7684\u89d2\u8272\u4ee5\u53ca\u7528\u6237\u5e10\u6237\u5fc5\u987b\u5b58\u5728\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002 <space> \u5fc5\u987b\u6307\u5b9a\u4e3a\u5b58\u5728\u7684\u56fe\u7a7a\u95f4\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002","title":"GRANT ROLE \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/grant-role-syntax/#grant_role","text":"GRANT ROLE <role_type> ON <space> TO <user> \u4f7f\u7528 GRANT \u8bed\u53e5\u4e3a Nebula Graph \u7528\u6237\u6388\u4e88\u6743\u9650\u3002\u4f7f\u7528 GRANT \u5fc5\u987b\u62e5\u6709 GRANT \u6743\u9650\u3002 \u76ee\u524d Nebula Graph \u5305\u542b\u4e94\u79cd\u89d2\u8272\u6743\u9650\uff1a GOD \u3001 ADMIN \u3001 DBA \u3001 USER \u548c GUEST \u3002 \u901a\u5e38\uff0c\u9700\u8981\u5148\u4f7f\u7528 CREATE USER \u521b\u5efa\u5e10\u6237\uff0c\u7136\u540e\u518d\u4f7f\u7528 GRANT \u4e3a\u5176\u6388\u4e88\u6743\u9650\uff08\u5047\u8bbe\u4f60\u62e5\u6709 CREATE \u548c GRANT \u6743\u9650\uff09\u3002\u5f85\u6388\u4e88\u7684\u89d2\u8272\u4ee5\u53ca\u7528\u6237\u5e10\u6237\u5fc5\u987b\u5b58\u5728\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002 <space> \u5fc5\u987b\u6307\u5b9a\u4e3a\u5b58\u5728\u7684\u56fe\u7a7a\u95f4\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002","title":"GRANT ROLE \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/revoke-syntax/","text":"REVOKE \u8bed\u6cd5 \u00b6 REVOKE ROLE <role_type> ON <space> FROM <user> \u4f7f\u7528 REVOKE \u8bed\u53e5\u4ece Nebula Graph \u7528\u6237\u5220\u9664\u6743\u9650\u3002\u4f7f\u7528 REVOKE \u5fc5\u987b\u62e5\u6709 REVOKE \u6743\u9650\u3002 \u76ee\u524d Nebula Graph \u5305\u542b\u4e94\u79cd\u89d2\u8272\u6743\u9650\uff1a GOD \u3001 ADMIN \u3001 DBA \u3001 USER \u548c GUEST \u3002 \u5f85\u5220\u9664\u7684\u89d2\u8272\u4ee5\u53ca\u7528\u6237\u5e10\u6237\u5fc5\u987b\u5b58\u5728\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002 <space> \u5fc5\u987b\u6307\u5b9a\u4e3a\u5b58\u5728\u7684\u56fe\u7a7a\u95f4\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002","title":"REVOKE \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/revoke-syntax/#revoke","text":"REVOKE ROLE <role_type> ON <space> FROM <user> \u4f7f\u7528 REVOKE \u8bed\u53e5\u4ece Nebula Graph \u7528\u6237\u5220\u9664\u6743\u9650\u3002\u4f7f\u7528 REVOKE \u5fc5\u987b\u62e5\u6709 REVOKE \u6743\u9650\u3002 \u76ee\u524d Nebula Graph \u5305\u542b\u4e94\u79cd\u89d2\u8272\u6743\u9650\uff1a GOD \u3001 ADMIN \u3001 DBA \u3001 USER \u548c GUEST \u3002 \u5f85\u5220\u9664\u7684\u89d2\u8272\u4ee5\u53ca\u7528\u6237\u5e10\u6237\u5fc5\u987b\u5b58\u5728\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002 <space> \u5fc5\u987b\u6307\u5b9a\u4e3a\u5b58\u5728\u7684\u56fe\u7a7a\u95f4\uff0c\u5426\u5219\u4f1a\u53d1\u751f\u9519\u8bef\u3002","title":"REVOKE \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/","text":"CONFIG \u8bed\u6cd5 \u00b6 \u914d\u7f6e\u8bf4\u660e \u00b6 Nebula Graph \u9ed8\u8ba4\u4ece meta \u83b7\u53d6\u914d\u7f6e\u3002\u5982\u9700\u4ece\u672c\u5730\u83b7\u53d6\u914d\u7f6e\uff0c\u8bf7\u5728\u914d\u7f6e\u6587\u4ef6 metad.conf \u3001 storaged.conf \u3001 graphd.conf \uff08\u8def\u5f84\u4e3a /home/user/nebula/build/install/etc \uff09\u4e2d\u5206\u522b\u6dfb\u52a0 --local_config=true \uff0c\u4ee5\u4ece\u672c\u5730\u914d\u7f6e\u6587\u4ef6\u83b7\u53d6\u3002 \u6ce8\u610f\uff1a \u914d\u7f6e\u4f18\u5148\u7ea7\u662f\uff1ameta > \u547d\u4ee4\u884c\u53c2\u6570 > \u73af\u5883\u53d8\u91cf > \u914d\u7f6e\u6587\u4ef6\u3002 \u5982\u679c\u5c06 --local_config \u8bbe\u7f6e\u4e3a true\uff0c\u5219\u914d\u7f6e\u6587\u4ef6\u4f18\u5148\u7ea7\u6700\u9ad8\u3002 \u66f4\u6539\u914d\u7f6e\u6587\u4ef6\u540e\u9700\u91cd\u542f\u670d\u52a1\u65b9\u53ef\u751f\u6548\u3002 \u4f7f\u7528\u547d\u4ee4\u884c\u66f4\u6539\u53ef\u5b9e\u65f6\u751f\u6548\u3002 gflags \u53c2\u6570 \u00b6 Nebula Graph \u4f7f\u7528 gflags \u8fdb\u884c\u8fd0\u884c\u65f6\u914d\u7f6e\u3002 gflags \u53c2\u6570\u89c1\u4e0b\u8868\u3002 Name Type Description max_edge_returned_per_vertex MUTABLE \u7528\u6765\u63a7\u5236\u4e00\u4e2a\u70b9\u6700\u591a\u53ef\u4ee5\u641c\u7d22\u8fd4\u56de\u7684\u8fb9\u6570 minloglevel MUTABLE \u6700\u5c0f\u65e5\u5fd7\u7ea7\u522b v MUTABLE debug \u65e5\u5fd7\u7ea7\u522b heartbeat_interval_secs MUTABLE \u5fc3\u8df3\u95f4\u9694 meta_client_retry_times MUTABLE meta \u5ba2\u6237\u7aef\u91cd\u8bd5\u6b21\u6570 slow_op_threshhold_ms MUTABLE \u6162\u901f\u8fd0\u884c\u7684\u9ed8\u8ba4\u9608\u503c\uff0c\u5355\u4f4d\u4e3a ms wal_ttl MUTABLE \u9ed8\u8ba4\u503c\u4e3a 14400 \u79d2 rocksdb_db_options NESTED \u53c2\u6570\u4e3a json \u683c\u5f0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u53c2\u6570 key \u548c value \u5747\u4e3a string \u683c\u5f0f rocksdb_column_family_options NESTED \u53c2\u6570\u4e3a json \u683c\u5f0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u53c2\u6570 key \u548c value \u5747\u4e3a string \u683c\u5f0f rocksdb_block_based_table_options NESTED \u53c2\u6570\u4e3a json \u683c\u5f0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u53c2\u6570 key \u548c value \u5747\u4e3a string \u683c\u5f0f \u4f8b\u5982\u53ef\u4ee5\u5728 storage \u7684 conf \u6587\u4ef6\u4e2d\u505a\u5982\u4e0b\u8bbe\u7f6e\uff1a rocksdb_db_options = {\"stats_dump_period_sec\":\"200\", \"enable_write_thread_adaptive_yield\":\"false\", \"write_thread_max_yield_usec\":\"600\", \"max_edge_returned_per_vertex\":\"INT_MAX\"} rocksdb_column_family_options = {\"max_write_buffer_number\":\"4\", \"min_write_buffer_number_to_merge\":\"2\", \"max_write_buffer_number_to_maintain\":\"1\"} rocksdb_block_based_table_options = {\"block_restart_interval\":\"2\"} \u53e6\u5916\u76ee\u524d\u652f\u6301\u52a8\u6001\u4fee\u6539 storage service \u7684\u90e8\u5206 rocksdb \u53c2\u6570, \u5982\u4e0b // rocksdb_column_family_options disable_auto_compactions write_buffer_size max_write_buffer_number level0_file_num_compaction_trigger level0_slowdown_writes_trigger level0_stop_writes_trigger target_file_size_base target_file_size_multiplier max_bytes_for_level_base max_bytes_for_level_multiplier // rocksdb_db_options max_total_wal_size delete_obsolete_files_period_micros max_background_jobs stats_dump_period_sec compaction_readahead_size writable_file_max_buffer_size bytes_per_sync wal_bytes_per_sync delayed_write_rate avoid_flush_during_shutdown max_open_files \u793a\u4f8b nebula> UPDATE CONFIGS storage:rocksdb_column_family_options = \\ { disable_auto_compactions = false , level0_file_num_compaction_trigger = 10 }; Reservoir Sampling \u53c2\u6570 \u00b6 \u5728\u914d\u7f6e\u6587\u4ef6 storaged-conf \u4e2d\u8bbe\u7f6e\u5982\u4e0b\u53c2\u6570\uff1a enable_reservoir_sampling = true/false # true \u65f6\u6253\u5f00\u84c4\u6c34\u6c60\u91c7\u6837 max_edge_returned_per_vertex = number # \u8bbe\u7f6e\u91c7\u6837\u6570\u91cf \u9488\u5bf9\u5927\u70b9\u7684\u573a\u666f\uff0c\u76ee\u524d\u6709\u4e24\u79cd\u622a\u65ad\u7b56\u7565\uff1a \u76f4\u63a5\u622a\u65ad\uff0c\u8bbe\u7f6e enable_reservoir_sampling = false \u3002\u9ed8\u8ba4\u622a\u53d6\u524d max_edge_returned_per_vertex \u4e2a\u8fb9\u3002 \u84c4\u6c34\u6c60\u91c7\u6837\u3002\u57fa\u4e8e\u84c4\u6c34\u6c60\u7b97\u6cd5\uff0c\u5bf9\u51fa\u8fb9\u8fdb\u884c\u7b49\u6982\u7387\u91c7\u6837\uff0c\u4ece\u672a\u77e5\u6570\u91cf\u7684 n \u4e2a\u51fa\u8fb9\u4e2d\u7b49\u6982\u7387\u91c7\u6837 max_edge_returned_per_vertex \u4e2a\u8fb9\u3002\u5f53\u51fa\u8fb9\u6570\u91cf\u8d85\u8fc7 max_edge_returned_per_vertex \u65f6\uff0c\u7531\u4e8e\u9700\u8981\u8ba1\u7b97\u6982\u7387\uff0c\u6027\u80fd\u76f8\u5bf9\u76f4\u63a5\u622a\u53d6\u8981\u5dee\uff0c\u4f46\u662f\u7b49\u6982\u7387\u91c7\u6837\u5bf9\u67d0\u4e9b\u4e1a\u52a1\u573a\u666f\u66f4\u6709\u5e94\u7528\u4ef7\u503c\u3002 \u663e\u793a\u53d8\u91cf \u00b6 SHOW CONFIGS [graph|meta|storage] \u4f8b\u5982 nebula> SHOW CONFIGS meta; ============================================================================================================================ | module | name | type | mode | value | ============================================================================================================================ | META | v | INT64 | IMMUTABLE | 4 | ---------------------------------------------------------------------------------------------------------------------------- | META | help | BOOL | IMMUTABLE | False | ---------------------------------------------------------------------------------------------------------------------------- | META | port | INT64 | IMMUTABLE | 45500 | ---------------------------------------------------------------------------------------------------------------------------- \u83b7\u53d6\u53d8\u91cf \u00b6 GET CONFIGS [graph|meta|storage :] var \u4f8b\u5982 nebula> GET CONFIGS storage:local_ip; ======================================================= | module | name | type | mode | value | ======================================================= | STORAGE | local_ip | STRING | IMMUTABLE | 127.0.0.1 | ------------------------------------------------------- nebula> GET CONFIGS heartbeat_interval_secs; ================================================================= | module | name | type | mode | value | ================================================================= | GRAPH | heartbeat_interval_secs | INT64 | MUTABLE | 10 | ----------------------------------------------------------------- | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 10 | ----------------------------------------------------------------- \u66f4\u65b0\u53d8\u91cf \u00b6 UPDATE CONFIGS [graph|meta|storage :] var = value \u66f4\u65b0\u7684\u53d8\u91cf\u5c06\u6c38\u4e45\u5b58\u50a8\u4e8e meta-service \u4e2d\u3002 \u5982\u679c\u53d8\u91cf\u6a21\u5f0f\u4e3a MUTABLE \uff0c\u66f4\u6539\u4f1a\u5373\u65f6\u751f\u6548\u3002\u5982\u679c\u6a21\u5f0f\u4e3a REBOOT \uff0c\u66f4\u6539\u5728\u670d\u52a1\u5668\u91cd\u542f\u540e\u751f\u6548\u3002 \u652f\u6301\u5728 UPDATE CONFIGS \u4e2d\u4f7f\u7528\u7b97\u5f0f\u3002 \u4f8b\u5982 nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1; nebula> GET CONFIGS storage:heartbeat_interval_secs; =============================================================== | module | name | type | mode | value | =============================================================== | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 1 | ---------------------------------------------------------------","title":"CONFIG \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#config","text":"","title":"CONFIG \u8bed\u6cd5"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#_1","text":"Nebula Graph \u9ed8\u8ba4\u4ece meta \u83b7\u53d6\u914d\u7f6e\u3002\u5982\u9700\u4ece\u672c\u5730\u83b7\u53d6\u914d\u7f6e\uff0c\u8bf7\u5728\u914d\u7f6e\u6587\u4ef6 metad.conf \u3001 storaged.conf \u3001 graphd.conf \uff08\u8def\u5f84\u4e3a /home/user/nebula/build/install/etc \uff09\u4e2d\u5206\u522b\u6dfb\u52a0 --local_config=true \uff0c\u4ee5\u4ece\u672c\u5730\u914d\u7f6e\u6587\u4ef6\u83b7\u53d6\u3002 \u6ce8\u610f\uff1a \u914d\u7f6e\u4f18\u5148\u7ea7\u662f\uff1ameta > \u547d\u4ee4\u884c\u53c2\u6570 > \u73af\u5883\u53d8\u91cf > \u914d\u7f6e\u6587\u4ef6\u3002 \u5982\u679c\u5c06 --local_config \u8bbe\u7f6e\u4e3a true\uff0c\u5219\u914d\u7f6e\u6587\u4ef6\u4f18\u5148\u7ea7\u6700\u9ad8\u3002 \u66f4\u6539\u914d\u7f6e\u6587\u4ef6\u540e\u9700\u91cd\u542f\u670d\u52a1\u65b9\u53ef\u751f\u6548\u3002 \u4f7f\u7528\u547d\u4ee4\u884c\u66f4\u6539\u53ef\u5b9e\u65f6\u751f\u6548\u3002","title":"\u914d\u7f6e\u8bf4\u660e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#gflags","text":"Nebula Graph \u4f7f\u7528 gflags \u8fdb\u884c\u8fd0\u884c\u65f6\u914d\u7f6e\u3002 gflags \u53c2\u6570\u89c1\u4e0b\u8868\u3002 Name Type Description max_edge_returned_per_vertex MUTABLE \u7528\u6765\u63a7\u5236\u4e00\u4e2a\u70b9\u6700\u591a\u53ef\u4ee5\u641c\u7d22\u8fd4\u56de\u7684\u8fb9\u6570 minloglevel MUTABLE \u6700\u5c0f\u65e5\u5fd7\u7ea7\u522b v MUTABLE debug \u65e5\u5fd7\u7ea7\u522b heartbeat_interval_secs MUTABLE \u5fc3\u8df3\u95f4\u9694 meta_client_retry_times MUTABLE meta \u5ba2\u6237\u7aef\u91cd\u8bd5\u6b21\u6570 slow_op_threshhold_ms MUTABLE \u6162\u901f\u8fd0\u884c\u7684\u9ed8\u8ba4\u9608\u503c\uff0c\u5355\u4f4d\u4e3a ms wal_ttl MUTABLE \u9ed8\u8ba4\u503c\u4e3a 14400 \u79d2 rocksdb_db_options NESTED \u53c2\u6570\u4e3a json \u683c\u5f0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u53c2\u6570 key \u548c value \u5747\u4e3a string \u683c\u5f0f rocksdb_column_family_options NESTED \u53c2\u6570\u4e3a json \u683c\u5f0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u53c2\u6570 key \u548c value \u5747\u4e3a string \u683c\u5f0f rocksdb_block_based_table_options NESTED \u53c2\u6570\u4e3a json \u683c\u5f0f\uff0c\u5176\u4e2d\u6bcf\u4e2a\u53c2\u6570 key \u548c value \u5747\u4e3a string \u683c\u5f0f \u4f8b\u5982\u53ef\u4ee5\u5728 storage \u7684 conf \u6587\u4ef6\u4e2d\u505a\u5982\u4e0b\u8bbe\u7f6e\uff1a rocksdb_db_options = {\"stats_dump_period_sec\":\"200\", \"enable_write_thread_adaptive_yield\":\"false\", \"write_thread_max_yield_usec\":\"600\", \"max_edge_returned_per_vertex\":\"INT_MAX\"} rocksdb_column_family_options = {\"max_write_buffer_number\":\"4\", \"min_write_buffer_number_to_merge\":\"2\", \"max_write_buffer_number_to_maintain\":\"1\"} rocksdb_block_based_table_options = {\"block_restart_interval\":\"2\"} \u53e6\u5916\u76ee\u524d\u652f\u6301\u52a8\u6001\u4fee\u6539 storage service \u7684\u90e8\u5206 rocksdb \u53c2\u6570, \u5982\u4e0b // rocksdb_column_family_options disable_auto_compactions write_buffer_size max_write_buffer_number level0_file_num_compaction_trigger level0_slowdown_writes_trigger level0_stop_writes_trigger target_file_size_base target_file_size_multiplier max_bytes_for_level_base max_bytes_for_level_multiplier // rocksdb_db_options max_total_wal_size delete_obsolete_files_period_micros max_background_jobs stats_dump_period_sec compaction_readahead_size writable_file_max_buffer_size bytes_per_sync wal_bytes_per_sync delayed_write_rate avoid_flush_during_shutdown max_open_files \u793a\u4f8b nebula> UPDATE CONFIGS storage:rocksdb_column_family_options = \\ { disable_auto_compactions = false , level0_file_num_compaction_trigger = 10 };","title":"gflags \u53c2\u6570"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#reservoir_sampling","text":"\u5728\u914d\u7f6e\u6587\u4ef6 storaged-conf \u4e2d\u8bbe\u7f6e\u5982\u4e0b\u53c2\u6570\uff1a enable_reservoir_sampling = true/false # true \u65f6\u6253\u5f00\u84c4\u6c34\u6c60\u91c7\u6837 max_edge_returned_per_vertex = number # \u8bbe\u7f6e\u91c7\u6837\u6570\u91cf \u9488\u5bf9\u5927\u70b9\u7684\u573a\u666f\uff0c\u76ee\u524d\u6709\u4e24\u79cd\u622a\u65ad\u7b56\u7565\uff1a \u76f4\u63a5\u622a\u65ad\uff0c\u8bbe\u7f6e enable_reservoir_sampling = false \u3002\u9ed8\u8ba4\u622a\u53d6\u524d max_edge_returned_per_vertex \u4e2a\u8fb9\u3002 \u84c4\u6c34\u6c60\u91c7\u6837\u3002\u57fa\u4e8e\u84c4\u6c34\u6c60\u7b97\u6cd5\uff0c\u5bf9\u51fa\u8fb9\u8fdb\u884c\u7b49\u6982\u7387\u91c7\u6837\uff0c\u4ece\u672a\u77e5\u6570\u91cf\u7684 n \u4e2a\u51fa\u8fb9\u4e2d\u7b49\u6982\u7387\u91c7\u6837 max_edge_returned_per_vertex \u4e2a\u8fb9\u3002\u5f53\u51fa\u8fb9\u6570\u91cf\u8d85\u8fc7 max_edge_returned_per_vertex \u65f6\uff0c\u7531\u4e8e\u9700\u8981\u8ba1\u7b97\u6982\u7387\uff0c\u6027\u80fd\u76f8\u5bf9\u76f4\u63a5\u622a\u53d6\u8981\u5dee\uff0c\u4f46\u662f\u7b49\u6982\u7387\u91c7\u6837\u5bf9\u67d0\u4e9b\u4e1a\u52a1\u573a\u666f\u66f4\u6709\u5e94\u7528\u4ef7\u503c\u3002","title":"Reservoir Sampling \u53c2\u6570"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#_2","text":"SHOW CONFIGS [graph|meta|storage] \u4f8b\u5982 nebula> SHOW CONFIGS meta; ============================================================================================================================ | module | name | type | mode | value | ============================================================================================================================ | META | v | INT64 | IMMUTABLE | 4 | ---------------------------------------------------------------------------------------------------------------------------- | META | help | BOOL | IMMUTABLE | False | ---------------------------------------------------------------------------------------------------------------------------- | META | port | INT64 | IMMUTABLE | 45500 | ----------------------------------------------------------------------------------------------------------------------------","title":"\u663e\u793a\u53d8\u91cf"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#_3","text":"GET CONFIGS [graph|meta|storage :] var \u4f8b\u5982 nebula> GET CONFIGS storage:local_ip; ======================================================= | module | name | type | mode | value | ======================================================= | STORAGE | local_ip | STRING | IMMUTABLE | 127.0.0.1 | ------------------------------------------------------- nebula> GET CONFIGS heartbeat_interval_secs; ================================================================= | module | name | type | mode | value | ================================================================= | GRAPH | heartbeat_interval_secs | INT64 | MUTABLE | 10 | ----------------------------------------------------------------- | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 10 | -----------------------------------------------------------------","title":"\u83b7\u53d6\u53d8\u91cf"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#_4","text":"UPDATE CONFIGS [graph|meta|storage :] var = value \u66f4\u65b0\u7684\u53d8\u91cf\u5c06\u6c38\u4e45\u5b58\u50a8\u4e8e meta-service \u4e2d\u3002 \u5982\u679c\u53d8\u91cf\u6a21\u5f0f\u4e3a MUTABLE \uff0c\u66f4\u6539\u4f1a\u5373\u65f6\u751f\u6548\u3002\u5982\u679c\u6a21\u5f0f\u4e3a REBOOT \uff0c\u66f4\u6539\u5728\u670d\u52a1\u5668\u91cd\u542f\u540e\u751f\u6548\u3002 \u652f\u6301\u5728 UPDATE CONFIGS \u4e2d\u4f7f\u7528\u7b97\u5f0f\u3002 \u4f8b\u5982 nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1; nebula> GET CONFIGS storage:heartbeat_interval_secs; =============================================================== | module | name | type | mode | value | =============================================================== | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 1 | ---------------------------------------------------------------","title":"\u66f4\u65b0\u53d8\u91cf"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/","text":"\u65e5\u5fd7 \u00b6 Nebula Graph \u4f7f\u7528 glog \u6253\u5370\u65e5\u5fd7\uff0c\u4f7f\u7528 gflag \u63a7\u5236\u65e5\u5fd7\u7ea7\u522b\uff0c\u5e76\u63d0\u4f9b HTTP \u63a5\u53e3\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u6539\u53d8\u65e5\u5fd7\u7ea7\u522b\uff0c\u4ee5\u65b9\u4fbf\u8ffd\u8e2a\u95ee\u9898\u3002 \u65e5\u5fd7\u4f4d\u7f6e \u00b6 \u65e5\u5fd7\u9ed8\u8ba4\u5b58\u653e\u5728 /usr/local/nebula/logs/ \u4e0b\u3002 \u5982\u679c\u5728\u8fd0\u884c\u65f6\u5220\u9664\u4e86\u65e5\u5fd7\u76ee\u5f55\uff0c\u4f1a\u5bfc\u81f4\u8fd0\u884c\u65f6\u7684\u65e5\u5fd7\u4e0d\u7ee7\u7eed\u8f93\u51fa\uff0c\u4f46\u4e0d\u4f1a\u5f71\u54cd\u670d\u52a1\u3002\u7a0b\u5e8f\u91cd\u542f\u540e\u53ef\u6062\u590d\u6b63\u5e38\u3002 \u53c2\u6570\u8bf4\u660e \u00b6 glog \u4e2d\u7684\u4e24\u4e2a\u4e3b\u8981\u53c2\u6570 \u00b6 minloglevel 0-3\uff1a\u5bf9\u5e94\u7684\u65e5\u5fd7\u7ea7\u522b\u5206\u522b\u4e3a INFO(DEBUG)\uff0cWARNING\uff0cERROR\uff0cFATAL\u3002\u901a\u5e38\u5728\u8c03\u8bd5\u73af\u5883\u8bbe\u7f6e\u4e3a 0\uff0c\u751f\u4ea7\u73af\u5883\u8bbe\u7f6e\u4e3a 1\uff0c\u8bbe\u7f6e\u4e3a 4 \u4e0d\u6253\u5370\u4efb\u4f55\u65e5\u5fd7\u3002 v 0-4: \u5f53 minloglevel \u8bbe\u7f6e\u4e3a 0 \u65f6\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8bbe\u7f6e\u8c03\u8bd5\u65e5\u5fd7\u7684\u8be6\u7ec6\u7a0b\u5ea6\uff0c\u503c\u8d8a\u5927\u8d8a\u8be6\u7ec6\u3002 \u914d\u7f6e\u6587\u4ef6 \u00b6 \u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\uff08\u901a\u5e38\u5728 /usr/local/nebula/etc/ \u4e0b\uff09\u53ef\u4ee5\u627e\u5230 metad\uff0cgraphd\uff0cstoraged \u7684\u65e5\u5fd7\u9ed8\u8ba4\u914d\u7f6e\u7ea7\u522b\u3002 \u52a8\u6001\u67e5\u770b\u548c\u4fee\u6539\u65e5\u5fd7\u7ea7\u522b \u00b6 \u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u6765\u67e5\u770b\u5f53\u524d\u7684\u6240\u6709\u7684 gflags \u53c2\u6570\uff08\u5305\u62ec\u65e5\u5fd7\u53c2\u6570\uff09 > curl ${ ws_ip } : ${ ws_port } /get_flags \u5176\u4e2d\uff0c ws_ip \u4e3a HTTP \u670d\u52a1\u7684 IP\uff0c\u53ef\u4ee5\u5728\u4e0a\u8ff0\u914d\u7f6e\u6587\u4ef6\u4e2d\u627e\u5230\uff08\u9ed8\u8ba4\u4e3a 127.0.0.1\uff09\u3002 ws_port \u4e3a HTTP \u670d\u52a1\u7684\u7aef\u53e3\u53f7\u3002 metad \u9ed8\u8ba4\u4e3a 11000\uff0c storaged \u9ed8\u8ba4\u4e3a 12000\uff0c graphd \u9ed8\u8ba4\u4e3a 13000\u3002 \u4f8b\u5982\uff0c\u67e5\u770b storaged \u7684 minloglevel \u7ea7\u522b\uff1a > curl 127 .0.0.1:12000/get_flags | grep minloglevel # storage > curl 127 .0.0.1:13000/get_flags # metad \u4e5f\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u5c06\u65e5\u5fd7\u7ea7\u522b\u66f4\u6539\u4e3a \u6700\u8be6\u7ec6 \u3002 > curl \"http://127.0.0.1:12000/set_flags?flag=v&value=3\" > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=0\" \u5728 console \u4e2d\uff0c\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u83b7\u53d6\u5f53\u524d\u65e5\u5fd7\u7ea7\u522b\u5e76\u5c06\u65e5\u5fd7\u7ea7\u522b\u8bbe\u7f6e\u4e3a \u6700\u8be6\u7ec6 \u3002 nebula> GET CONFIGS graph:minloglevel; nebula> UPDATE CONFIGS graph:minloglevel=0; \u5982\u9700\u66f4\u6539 storage \u65e5\u5fd7\u7ea7\u522b\uff0c\u5c06\u4e0a\u8ff0\u547d\u4ee4\u4e2d\u7684 graph \u66f4\u6362\u4e3a storage \u5373\u53ef\uff0c\u6ce8\u610f\uff0c Nebula Graph \u4ec5\u652f\u6301\u901a\u8fc7 console \u4fee\u6539 graph \u548c storage \u65e5\u5fd7\u7ea7\u522b\uff0cmeta \u65e5\u5fd7\u4e0d\u80fd\u66f4\u6539\u3002 \u6216\u8005 \u5173\u95ed \u6240\u6709\u7684\u65e5\u5fd7\u6253\u5370(\u4ec5\u4fdd\u7559 FATAL)\u3002 > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=3\"","title":"\u65e5\u5fd7"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#_1","text":"Nebula Graph \u4f7f\u7528 glog \u6253\u5370\u65e5\u5fd7\uff0c\u4f7f\u7528 gflag \u63a7\u5236\u65e5\u5fd7\u7ea7\u522b\uff0c\u5e76\u63d0\u4f9b HTTP \u63a5\u53e3\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u6539\u53d8\u65e5\u5fd7\u7ea7\u522b\uff0c\u4ee5\u65b9\u4fbf\u8ffd\u8e2a\u95ee\u9898\u3002","title":"\u65e5\u5fd7"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#_2","text":"\u65e5\u5fd7\u9ed8\u8ba4\u5b58\u653e\u5728 /usr/local/nebula/logs/ \u4e0b\u3002 \u5982\u679c\u5728\u8fd0\u884c\u65f6\u5220\u9664\u4e86\u65e5\u5fd7\u76ee\u5f55\uff0c\u4f1a\u5bfc\u81f4\u8fd0\u884c\u65f6\u7684\u65e5\u5fd7\u4e0d\u7ee7\u7eed\u8f93\u51fa\uff0c\u4f46\u4e0d\u4f1a\u5f71\u54cd\u670d\u52a1\u3002\u7a0b\u5e8f\u91cd\u542f\u540e\u53ef\u6062\u590d\u6b63\u5e38\u3002","title":"\u65e5\u5fd7\u4f4d\u7f6e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#_3","text":"","title":"\u53c2\u6570\u8bf4\u660e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#glog","text":"minloglevel 0-3\uff1a\u5bf9\u5e94\u7684\u65e5\u5fd7\u7ea7\u522b\u5206\u522b\u4e3a INFO(DEBUG)\uff0cWARNING\uff0cERROR\uff0cFATAL\u3002\u901a\u5e38\u5728\u8c03\u8bd5\u73af\u5883\u8bbe\u7f6e\u4e3a 0\uff0c\u751f\u4ea7\u73af\u5883\u8bbe\u7f6e\u4e3a 1\uff0c\u8bbe\u7f6e\u4e3a 4 \u4e0d\u6253\u5370\u4efb\u4f55\u65e5\u5fd7\u3002 v 0-4: \u5f53 minloglevel \u8bbe\u7f6e\u4e3a 0 \u65f6\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8bbe\u7f6e\u8c03\u8bd5\u65e5\u5fd7\u7684\u8be6\u7ec6\u7a0b\u5ea6\uff0c\u503c\u8d8a\u5927\u8d8a\u8be6\u7ec6\u3002","title":"glog \u4e2d\u7684\u4e24\u4e2a\u4e3b\u8981\u53c2\u6570"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#_4","text":"\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\uff08\u901a\u5e38\u5728 /usr/local/nebula/etc/ \u4e0b\uff09\u53ef\u4ee5\u627e\u5230 metad\uff0cgraphd\uff0cstoraged \u7684\u65e5\u5fd7\u9ed8\u8ba4\u914d\u7f6e\u7ea7\u522b\u3002","title":"\u914d\u7f6e\u6587\u4ef6"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#_5","text":"\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u6765\u67e5\u770b\u5f53\u524d\u7684\u6240\u6709\u7684 gflags \u53c2\u6570\uff08\u5305\u62ec\u65e5\u5fd7\u53c2\u6570\uff09 > curl ${ ws_ip } : ${ ws_port } /get_flags \u5176\u4e2d\uff0c ws_ip \u4e3a HTTP \u670d\u52a1\u7684 IP\uff0c\u53ef\u4ee5\u5728\u4e0a\u8ff0\u914d\u7f6e\u6587\u4ef6\u4e2d\u627e\u5230\uff08\u9ed8\u8ba4\u4e3a 127.0.0.1\uff09\u3002 ws_port \u4e3a HTTP \u670d\u52a1\u7684\u7aef\u53e3\u53f7\u3002 metad \u9ed8\u8ba4\u4e3a 11000\uff0c storaged \u9ed8\u8ba4\u4e3a 12000\uff0c graphd \u9ed8\u8ba4\u4e3a 13000\u3002 \u4f8b\u5982\uff0c\u67e5\u770b storaged \u7684 minloglevel \u7ea7\u522b\uff1a > curl 127 .0.0.1:12000/get_flags | grep minloglevel # storage > curl 127 .0.0.1:13000/get_flags # metad \u4e5f\u53ef\u4ee5\u901a\u8fc7\u5982\u4e0b\u547d\u4ee4\u5c06\u65e5\u5fd7\u7ea7\u522b\u66f4\u6539\u4e3a \u6700\u8be6\u7ec6 \u3002 > curl \"http://127.0.0.1:12000/set_flags?flag=v&value=3\" > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=0\" \u5728 console \u4e2d\uff0c\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u83b7\u53d6\u5f53\u524d\u65e5\u5fd7\u7ea7\u522b\u5e76\u5c06\u65e5\u5fd7\u7ea7\u522b\u8bbe\u7f6e\u4e3a \u6700\u8be6\u7ec6 \u3002 nebula> GET CONFIGS graph:minloglevel; nebula> UPDATE CONFIGS graph:minloglevel=0; \u5982\u9700\u66f4\u6539 storage \u65e5\u5fd7\u7ea7\u522b\uff0c\u5c06\u4e0a\u8ff0\u547d\u4ee4\u4e2d\u7684 graph \u66f4\u6362\u4e3a storage \u5373\u53ef\uff0c\u6ce8\u610f\uff0c Nebula Graph \u4ec5\u652f\u6301\u901a\u8fc7 console \u4fee\u6539 graph \u548c storage \u65e5\u5fd7\u7ea7\u522b\uff0cmeta \u65e5\u5fd7\u4e0d\u80fd\u66f4\u6539\u3002 \u6216\u8005 \u5173\u95ed \u6240\u6709\u7684\u65e5\u5fd7\u6253\u5370(\u4ec5\u4fdd\u7559 FATAL)\u3002 > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=3\"","title":"\u52a8\u6001\u67e5\u770b\u548c\u4fee\u6539\u65e5\u5fd7\u7ea7\u522b"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/","text":"Graph Metrics \u00b6 \u4ecb\u7ecd \u00b6 \u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u901a\u8fc7 HTTP \u65b9\u5f0f\u6765\u83b7\u53d6 Graph Service \u5c42\u7684\u57fa\u672c\u6027\u80fd\u6307\u6807\u3002 \u6bcf\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u90fd\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6307\u6807\u540d\u3001\u7edf\u8ba1\u7c7b\u578b\u3001\u65f6\u95f4\u8303\u56f4\u3002 counter_name statistic_type time_range \u6307\u6807\u540d \u00b6 \u6bcf\u4e2a\u6307\u6807\u540d\u90fd\u7531\u670d\u52a1\u540d\u52a0\u6a21\u5757\u540d\u6784\u6210\uff0c\u76ee\u524d\u652f\u6301\u83b7\u53d6\u5982\u4e0b\u63a5\u53e3\uff1a \u901a\u8fc7 storageClient \u53d1\u9001\u7684\u8bf7\u6c42\uff0c\u9700\u8981\u540c\u65f6\u5411\u591a\u4e2a storage \u5e76\u53d1\u591a\u6761\u6d88\u606f\u65f6\uff0c\u6309\u4e00\u6b21\u7edf\u8ba1 graph_storageClient \u901a\u8fc7 metaClient \u53d1\u9001\u7684\u8bf7\u6c42 graph_graph_all \u5ba2\u6237\u7aef\u5411 graph \u53d1\u9001\u7684\u8bf7\u6c42\uff0c\u5f53\u4e00\u6761\u8bf7\u6c42\u5305\u542b\u591a\u6761\u8bed\u53e5\u65f6\uff0c\u6309\u4e00\u6761\u8ba1\u7b97 graph_metaClient \u63d2\u5165\u70b9 graph_insertVertex \u63d2\u5165\u8fb9 graph_insertEdge \u5220\u9664\u70b9 graph_deleteVertex \u5220\u9664\u8fb9 graph_deleteEdge //\u672a\u652f\u6301 \u66f4\u65b0\u70b9\u7684\u5c5e\u6027 graph_updateVertex \u66f4\u65b0\u8fb9\u7684\u5c5e\u6027 graph_updateEdge \u6267\u884c go \u547d\u4ee4 graph_go \u67e5\u627e\u6700\u5c0f\u8def\u5f84\u6216\u8005\u5168\u8def\u5f84 graph_findPath \u83b7\u53d6\u70b9\u5c5e\u6027\uff0c\u4e0d\u7edf\u8ba1\u83b7\u53d6\u70b9\u7684\u603b\u6570\uff0c\u53ea\u7edf\u8ba1\u6267\u884c\u547d\u4ee4\u7684\u6570\u91cf graph_fetchVertex \u83b7\u53d6\u8fb9\u5c5e\u6027\uff0c\u4e0d\u7edf\u8ba1\u8fb9\u7684\u603b\u6570\uff0c\u53ea\u7edf\u8ba1\u6267\u884c\u547d\u4ee4\u7684\u6570\u91cf graph_fetchEdge \u6bcf\u4e00\u4e2a\u63a5\u53e3\u90fd\u6709\u4e09\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u522b\u4e3a\u5ef6\u8fdf(\u5355\u4f4d\u4e3a us)\u3001\u6210\u529f\u7684 QPS\u3001\u53d1\u751f\u9519\u8bef\u7684 QPS\uff0c\u540e\u7f00\u540d\u5982\u4e0b\uff1a _latency _qps _error_qps \u5c06\u63a5\u53e3\u540d\u548c\u76f8\u5e94\u6307\u6807\u8fde\u63a5\u5728\u4e00\u8d77\u5373\u53ef\u83b7\u5f97\u5b8c\u6574\u7684\u6307\u6807\u540d\uff0c\u4f8b\u5982 graph_insertVertex_latency \u3001 graph_insertVertex_qps \u3001 graph_insertVertex_error_qps \u3001\u5206\u522b\u4ee3\u8868\u63d2\u5165\u4e00\u4e2a\u70b9\u7684\u5ef6\u8fdf\u3001QPS \u548c\u53d1\u751f\u9519\u8bef\u7684 QPS\u3002 \u7edf\u8ba1\u7c7b\u578b \u00b6 \u76ee\u524d\u652f\u6301\u7684\u7edf\u8ba1\u7c7b\u578b\u6709 SUM\u3001COUNT\u3001AVG\u3001RATE \u548c P \u5206\u4f4d\u6570 (P99\uff0cP999\uff0c ... \uff0cP999999)\u3002\u5176\u4e2d\uff1a _qps \u3001 _error_qps \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4f46\u4e0d\u652f\u6301 P \u5206\u4f4d\uff1b _latency \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4e5f\u652f\u6301 P \u5206\u4f4d\u3002 \u65f6\u95f4\u8303\u56f4 \u00b6 \u65f6\u95f4\u8303\u56f4\u76ee\u524d\u53ea\u652f\u6301\u4e09\u79cd\uff0c\u5206\u522b\u4e3a 60\u3001600\u30013600\uff0c\u5206\u522b\u8868\u793a\u6700\u8fd1\u4e00\u5206\u949f\uff0c\u6700\u8fd1\u5341\u5206\u949f\u548c\u6700\u8fd1\u4e00\u5c0f\u65f6\u3002 \u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u76f8\u5e94\u7684\u6027\u80fd\u6307\u6807 \u00b6 \u6839\u636e\u4e0a\u9762\u7684\u4ecb\u7ecd\uff0c\u5c31\u53ef\u4ee5\u5199\u51fa\u4e00\u4e2a\u5b8c\u6574\u7684\u6307\u6807\u540d\u79f0\u4e86\uff0c\u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a graph_insertVertex_latency . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u63d2\u5165\u70b9\u547d\u4ee4\u6267\u884c\u6210\u529f\u7684\u5e73\u5747\u5ef6\u65f6 graph_updateEdge_error_qps . count .3600 // \u6700\u8fd1\u4e00\u5c0f\u65f6\u66f4\u65b0\u8fb9\u547d\u4ee4\u5931\u8d25\u7684\u603b\u8ba1\u6570\u91cf \u5047\u8bbe\u672c\u5730\u542f\u52a8\u4e86\u4e00\u4e2a nebula graph service\uff0c\u540c\u65f6\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684 ws_http_port \u7aef\u53e3\u53f7\u4e3a 13000\u3002\u901a\u8fc7 HTTP \u7684 GET \u63a5\u53e3\u53d1\u9001\uff0c\u65b9\u6cd5\u540d\u4e3a get_stats \uff0c\u53c2\u6570\u4e3a stats \u52a0\u5bf9\u5e94\u7684\u6307\u6807\u540d\u5b57\u3002\u4e0b\u9762\u662f\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u6307\u6807\u7684\u793a\u4f8b\uff1a # \u83b7\u53d6\u4e00\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60\" # graph_insertVertex_qps.rate.60=3069 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60\" # graph_insertVertex_qps.rate.60=3069 # graph_deleteVertex_latency.avg.60=837 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807\u5e76\u4ee5 json \u683c\u5f0f\u8fd4\u56de curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60&returnjson\" # [{\"value\":2373,\"name\":\"graph_insertVertex_qps.rate.60\"},{\"value\":760,\"name\":\"graph_deleteVertex_latency.avg.60\"}] # \u83b7\u53d6\u6240\u6709\u6307\u6807 curl -G \"http://127.0.0.1:13000/get_stats?stats\" # \u6216 curl -G \"http://127.0.0.1:13000/get_stats\"","title":"Graph Metrics"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#graph_metrics","text":"","title":"Graph Metrics"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#_1","text":"\u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u901a\u8fc7 HTTP \u65b9\u5f0f\u6765\u83b7\u53d6 Graph Service \u5c42\u7684\u57fa\u672c\u6027\u80fd\u6307\u6807\u3002 \u6bcf\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u90fd\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6307\u6807\u540d\u3001\u7edf\u8ba1\u7c7b\u578b\u3001\u65f6\u95f4\u8303\u56f4\u3002 counter_name statistic_type time_range","title":"\u4ecb\u7ecd"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#_2","text":"\u6bcf\u4e2a\u6307\u6807\u540d\u90fd\u7531\u670d\u52a1\u540d\u52a0\u6a21\u5757\u540d\u6784\u6210\uff0c\u76ee\u524d\u652f\u6301\u83b7\u53d6\u5982\u4e0b\u63a5\u53e3\uff1a \u901a\u8fc7 storageClient \u53d1\u9001\u7684\u8bf7\u6c42\uff0c\u9700\u8981\u540c\u65f6\u5411\u591a\u4e2a storage \u5e76\u53d1\u591a\u6761\u6d88\u606f\u65f6\uff0c\u6309\u4e00\u6b21\u7edf\u8ba1 graph_storageClient \u901a\u8fc7 metaClient \u53d1\u9001\u7684\u8bf7\u6c42 graph_graph_all \u5ba2\u6237\u7aef\u5411 graph \u53d1\u9001\u7684\u8bf7\u6c42\uff0c\u5f53\u4e00\u6761\u8bf7\u6c42\u5305\u542b\u591a\u6761\u8bed\u53e5\u65f6\uff0c\u6309\u4e00\u6761\u8ba1\u7b97 graph_metaClient \u63d2\u5165\u70b9 graph_insertVertex \u63d2\u5165\u8fb9 graph_insertEdge \u5220\u9664\u70b9 graph_deleteVertex \u5220\u9664\u8fb9 graph_deleteEdge //\u672a\u652f\u6301 \u66f4\u65b0\u70b9\u7684\u5c5e\u6027 graph_updateVertex \u66f4\u65b0\u8fb9\u7684\u5c5e\u6027 graph_updateEdge \u6267\u884c go \u547d\u4ee4 graph_go \u67e5\u627e\u6700\u5c0f\u8def\u5f84\u6216\u8005\u5168\u8def\u5f84 graph_findPath \u83b7\u53d6\u70b9\u5c5e\u6027\uff0c\u4e0d\u7edf\u8ba1\u83b7\u53d6\u70b9\u7684\u603b\u6570\uff0c\u53ea\u7edf\u8ba1\u6267\u884c\u547d\u4ee4\u7684\u6570\u91cf graph_fetchVertex \u83b7\u53d6\u8fb9\u5c5e\u6027\uff0c\u4e0d\u7edf\u8ba1\u8fb9\u7684\u603b\u6570\uff0c\u53ea\u7edf\u8ba1\u6267\u884c\u547d\u4ee4\u7684\u6570\u91cf graph_fetchEdge \u6bcf\u4e00\u4e2a\u63a5\u53e3\u90fd\u6709\u4e09\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u522b\u4e3a\u5ef6\u8fdf(\u5355\u4f4d\u4e3a us)\u3001\u6210\u529f\u7684 QPS\u3001\u53d1\u751f\u9519\u8bef\u7684 QPS\uff0c\u540e\u7f00\u540d\u5982\u4e0b\uff1a _latency _qps _error_qps \u5c06\u63a5\u53e3\u540d\u548c\u76f8\u5e94\u6307\u6807\u8fde\u63a5\u5728\u4e00\u8d77\u5373\u53ef\u83b7\u5f97\u5b8c\u6574\u7684\u6307\u6807\u540d\uff0c\u4f8b\u5982 graph_insertVertex_latency \u3001 graph_insertVertex_qps \u3001 graph_insertVertex_error_qps \u3001\u5206\u522b\u4ee3\u8868\u63d2\u5165\u4e00\u4e2a\u70b9\u7684\u5ef6\u8fdf\u3001QPS \u548c\u53d1\u751f\u9519\u8bef\u7684 QPS\u3002","title":"\u6307\u6807\u540d"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#_3","text":"\u76ee\u524d\u652f\u6301\u7684\u7edf\u8ba1\u7c7b\u578b\u6709 SUM\u3001COUNT\u3001AVG\u3001RATE \u548c P \u5206\u4f4d\u6570 (P99\uff0cP999\uff0c ... \uff0cP999999)\u3002\u5176\u4e2d\uff1a _qps \u3001 _error_qps \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4f46\u4e0d\u652f\u6301 P \u5206\u4f4d\uff1b _latency \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4e5f\u652f\u6301 P \u5206\u4f4d\u3002","title":"\u7edf\u8ba1\u7c7b\u578b"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#_4","text":"\u65f6\u95f4\u8303\u56f4\u76ee\u524d\u53ea\u652f\u6301\u4e09\u79cd\uff0c\u5206\u522b\u4e3a 60\u3001600\u30013600\uff0c\u5206\u522b\u8868\u793a\u6700\u8fd1\u4e00\u5206\u949f\uff0c\u6700\u8fd1\u5341\u5206\u949f\u548c\u6700\u8fd1\u4e00\u5c0f\u65f6\u3002","title":"\u65f6\u95f4\u8303\u56f4"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#http","text":"\u6839\u636e\u4e0a\u9762\u7684\u4ecb\u7ecd\uff0c\u5c31\u53ef\u4ee5\u5199\u51fa\u4e00\u4e2a\u5b8c\u6574\u7684\u6307\u6807\u540d\u79f0\u4e86\uff0c\u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a graph_insertVertex_latency . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u63d2\u5165\u70b9\u547d\u4ee4\u6267\u884c\u6210\u529f\u7684\u5e73\u5747\u5ef6\u65f6 graph_updateEdge_error_qps . count .3600 // \u6700\u8fd1\u4e00\u5c0f\u65f6\u66f4\u65b0\u8fb9\u547d\u4ee4\u5931\u8d25\u7684\u603b\u8ba1\u6570\u91cf \u5047\u8bbe\u672c\u5730\u542f\u52a8\u4e86\u4e00\u4e2a nebula graph service\uff0c\u540c\u65f6\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684 ws_http_port \u7aef\u53e3\u53f7\u4e3a 13000\u3002\u901a\u8fc7 HTTP \u7684 GET \u63a5\u53e3\u53d1\u9001\uff0c\u65b9\u6cd5\u540d\u4e3a get_stats \uff0c\u53c2\u6570\u4e3a stats \u52a0\u5bf9\u5e94\u7684\u6307\u6807\u540d\u5b57\u3002\u4e0b\u9762\u662f\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u6307\u6807\u7684\u793a\u4f8b\uff1a # \u83b7\u53d6\u4e00\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60\" # graph_insertVertex_qps.rate.60=3069 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60\" # graph_insertVertex_qps.rate.60=3069 # graph_deleteVertex_latency.avg.60=837 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807\u5e76\u4ee5 json \u683c\u5f0f\u8fd4\u56de curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60&returnjson\" # [{\"value\":2373,\"name\":\"graph_insertVertex_qps.rate.60\"},{\"value\":760,\"name\":\"graph_deleteVertex_latency.avg.60\"}] # \u83b7\u53d6\u6240\u6709\u6307\u6807 curl -G \"http://127.0.0.1:13000/get_stats?stats\" # \u6216 curl -G \"http://127.0.0.1:13000/get_stats\"","title":"\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u76f8\u5e94\u7684\u6027\u80fd\u6307\u6807"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/","text":"Meta Metrics \u00b6 \u4ecb\u7ecd \u00b6 \u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u901a\u8fc7 HTTP \u65b9\u5f0f\u6765\u83b7\u53d6 Meta Service \u5c42\u7684\u57fa\u672c\u6027\u80fd\u6307\u6807\u3002 \u6bcf\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u90fd\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6307\u6807\u540d\u3001\u7edf\u8ba1\u7c7b\u578b\u3001\u65f6\u95f4\u8303\u56f4\u3002 counter_name statistic_type time_range \u6307\u6807\u540d \u00b6 \u6bcf\u4e2a\u6307\u6807\u540d\u90fd\u7531\u670d\u52a1\u540d\u52a0\u6a21\u5757\u540d\u6784\u6210\uff0cmeta \u53ea\u7edf\u8ba1\u5fc3\u8df3\u4fe1\u606f\uff0c\u76ee\u524d\u652f\u6301\u83b7\u53d6\u5982\u4e0b\u63a5\u53e3\uff1a meta_heartbeat_qps meta_heartbeat_error_qps meta_heartbeat_latency \u7edf\u8ba1\u7c7b\u578b \u00b6 \u76ee\u524d\u652f\u6301\u7684\u7edf\u8ba1\u7c7b\u578b\u6709 SUM\u3001COUNT\u3001AVG\u3001RATE \u548c P \u5206\u4f4d\u6570 (P99\uff0cP999\uff0c ... \uff0cP999999)\u3002\u5176\u4e2d\uff1a _qps \u3001 _error_qps \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4f46\u4e0d\u652f\u6301 P \u5206\u4f4d\uff1b _latency \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4e5f\u652f\u6301 P \u5206\u4f4d\u3002 \u65f6\u95f4\u8303\u56f4 \u00b6 \u65f6\u95f4\u8303\u56f4\u76ee\u524d\u53ea\u652f\u6301\u4e09\u79cd\uff0c\u5206\u522b\u4e3a 60\u3001600\u30013600\uff0c\u5206\u522b\u8868\u793a\u6700\u8fd1\u4e00\u5206\u949f\uff0c\u6700\u8fd1\u5341\u5206\u949f\u548c\u6700\u8fd1\u4e00\u5c0f\u65f6\u3002 \u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u76f8\u5e94\u7684\u6027\u80fd\u6307\u6807 \u00b6 \u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a meta_heartbeat_qps . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u5fc3\u8df3\u7684\u5e73\u5747 QPS meta_heartbeat_error_qps . count .60 // \u6700\u8fd1\u4e00\u5206\u949f\u5fc3\u8df3\u7684\u5e73\u5747\u9519\u8bef\u603b\u8ba1\u6570\u91cf meta_heartbeat_latency . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u5fc3\u4e2d\u7684\u5e73\u5747\u5ef6\u65f6 \u5047\u8bbe\u672c\u5730\u542f\u52a8\u4e86\u4e00\u4e2a nebula meta service\uff0c\u540c\u65f6\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684 ws_http_port \u7aef\u53e3\u53f7\u4e3a 11000\u3002\u901a\u8fc7 HTTP \u7684 GET \u63a5\u53e3\u53d1\u9001\uff0c\u65b9\u6cd5\u540d\u4e3a get_stats \uff0c\u53c2\u6570\u4e3a stats \u52a0\u5bf9\u5e94\u7684\u6307\u6807\u540d\u5b57\u3002\u4e0b\u9762\u662f\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u6307\u6807\u7684\u793a\u4f8b\uff1a # \u83b7\u53d6\u4e00\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60\" # meta_heartbeat_qps.avg.60=580 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60\" # meta_heartbeat_qps.avg.60=537 # meta_heartbeat_error_qps.avg.60=579 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807\u5e76\u4ee5 json \u683c\u5f0f\u8fd4\u56de curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60&returnjson\" # [{\"value\":533,\"name\":\"meta_heartbeat_qps.avg.60\"},{\"value\":574,\"name\":\"meta_heartbeat_error_qps.avg.60\"}] # \u83b7\u53d6\u6240\u6709\u6307\u6807 curl -G \"http://127.0.0.1:11000/get_stats?stats\" # \u6216 curl -G \"http://127.0.0.1:11000/get_stats\"","title":"Meta Metrics"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#meta_metrics","text":"","title":"Meta Metrics"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#_1","text":"\u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u901a\u8fc7 HTTP \u65b9\u5f0f\u6765\u83b7\u53d6 Meta Service \u5c42\u7684\u57fa\u672c\u6027\u80fd\u6307\u6807\u3002 \u6bcf\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u90fd\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6307\u6807\u540d\u3001\u7edf\u8ba1\u7c7b\u578b\u3001\u65f6\u95f4\u8303\u56f4\u3002 counter_name statistic_type time_range","title":"\u4ecb\u7ecd"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#_2","text":"\u6bcf\u4e2a\u6307\u6807\u540d\u90fd\u7531\u670d\u52a1\u540d\u52a0\u6a21\u5757\u540d\u6784\u6210\uff0cmeta \u53ea\u7edf\u8ba1\u5fc3\u8df3\u4fe1\u606f\uff0c\u76ee\u524d\u652f\u6301\u83b7\u53d6\u5982\u4e0b\u63a5\u53e3\uff1a meta_heartbeat_qps meta_heartbeat_error_qps meta_heartbeat_latency","title":"\u6307\u6807\u540d"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#_3","text":"\u76ee\u524d\u652f\u6301\u7684\u7edf\u8ba1\u7c7b\u578b\u6709 SUM\u3001COUNT\u3001AVG\u3001RATE \u548c P \u5206\u4f4d\u6570 (P99\uff0cP999\uff0c ... \uff0cP999999)\u3002\u5176\u4e2d\uff1a _qps \u3001 _error_qps \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4f46\u4e0d\u652f\u6301 P \u5206\u4f4d\uff1b _latency \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4e5f\u652f\u6301 P \u5206\u4f4d\u3002","title":"\u7edf\u8ba1\u7c7b\u578b"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#_4","text":"\u65f6\u95f4\u8303\u56f4\u76ee\u524d\u53ea\u652f\u6301\u4e09\u79cd\uff0c\u5206\u522b\u4e3a 60\u3001600\u30013600\uff0c\u5206\u522b\u8868\u793a\u6700\u8fd1\u4e00\u5206\u949f\uff0c\u6700\u8fd1\u5341\u5206\u949f\u548c\u6700\u8fd1\u4e00\u5c0f\u65f6\u3002","title":"\u65f6\u95f4\u8303\u56f4"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#http","text":"\u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a meta_heartbeat_qps . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u5fc3\u8df3\u7684\u5e73\u5747 QPS meta_heartbeat_error_qps . count .60 // \u6700\u8fd1\u4e00\u5206\u949f\u5fc3\u8df3\u7684\u5e73\u5747\u9519\u8bef\u603b\u8ba1\u6570\u91cf meta_heartbeat_latency . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u5fc3\u4e2d\u7684\u5e73\u5747\u5ef6\u65f6 \u5047\u8bbe\u672c\u5730\u542f\u52a8\u4e86\u4e00\u4e2a nebula meta service\uff0c\u540c\u65f6\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684 ws_http_port \u7aef\u53e3\u53f7\u4e3a 11000\u3002\u901a\u8fc7 HTTP \u7684 GET \u63a5\u53e3\u53d1\u9001\uff0c\u65b9\u6cd5\u540d\u4e3a get_stats \uff0c\u53c2\u6570\u4e3a stats \u52a0\u5bf9\u5e94\u7684\u6307\u6807\u540d\u5b57\u3002\u4e0b\u9762\u662f\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u6307\u6807\u7684\u793a\u4f8b\uff1a # \u83b7\u53d6\u4e00\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60\" # meta_heartbeat_qps.avg.60=580 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60\" # meta_heartbeat_qps.avg.60=537 # meta_heartbeat_error_qps.avg.60=579 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807\u5e76\u4ee5 json \u683c\u5f0f\u8fd4\u56de curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60&returnjson\" # [{\"value\":533,\"name\":\"meta_heartbeat_qps.avg.60\"},{\"value\":574,\"name\":\"meta_heartbeat_error_qps.avg.60\"}] # \u83b7\u53d6\u6240\u6709\u6307\u6807 curl -G \"http://127.0.0.1:11000/get_stats?stats\" # \u6216 curl -G \"http://127.0.0.1:11000/get_stats\"","title":"\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u76f8\u5e94\u7684\u6027\u80fd\u6307\u6807"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/","text":"\u96c6\u7fa4\u5feb\u7167 \u00b6 \u521b\u5efa\u5feb\u7167 \u00b6 CREATE SNAPSHOT \u547d\u4ee4\u53ef\u5bf9\u6574\u4e2a\u96c6\u7fa4\u521b\u5efa\u5f53\u524d\u65f6\u95f4\u70b9\u7684\u5feb\u7167\uff0c\u5feb\u7167\u540d\u79f0\u7531 meta server \u7684\u65f6\u95f4\u6233\u7ec4\u6210\u3002\u5f53\u524d\u7248\u672c\u5982\u679c\u5feb\u7167\u521b\u5efa\u5931\u8d25\uff0c\u5fc5\u987b\u901a\u8fc7 DROP SNAPSHOT \u547d\u4ee4\u6e05\u9664\u65e0\u6548\u7684\u5feb\u7167\u3002 \u5f53\u524d\u7248\u672c\u4e0d\u652f\u6301\u5bf9\u6307\u5b9a\u7684\u56fe\u7a7a\u95f4\u521b\u5efa\u5feb\u7167\uff0c\u5f53\u6267\u884c CREATE SNAPSHOT \u540e\uff0c\u5c06\u5bf9\u96c6\u7fa4\u4e2d\u7684\u6240\u6709\u56fe\u7a7a\u95f4\u521b\u5efa\u5feb\u7167\u3002\u4f8b\u5982\uff1a nebula> CREATE SNAPSHOT; Execution succeeded (Time spent: 22892/23923 us) \u67e5\u770b\u5feb\u7167 \u00b6 SHOW SNAPSHOT \u547d\u4ee4\u53ef\u67e5\u770b\u96c6\u7fa4\u4e2d\u6240\u6709\u5feb\u7167\u72b6\u6001\uff08VALID \u6216 INVALID\uff09\u3001\u540d\u79f0\u548c\u521b\u5efa\u5feb\u7167\u65f6\u6240\u6709 storage server \u7684 IP \u5730\u5740\u3002\u4f8b\u5982\uff1a nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_36 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- \u5220\u9664\u5feb\u7167 \u00b6 DROP SNAPSHOT \u547d\u4ee4\u53ef\u5220\u9664\u6307\u5b9a\u540d\u79f0\u7684\u5feb\u7167\uff0c\u8bed\u6cd5\u4e3a\uff1a DROP SNAPSHOT <snapshot-name> \u53ef\u4ee5\u901a\u8fc7 SHOW SNAPSHOTS \u547d\u4ee4\u83b7\u53d6\u5feb\u7167\u540d\u79f0\uff0c DROP SNAPSHOT \u65e2\u53ef\u4ee5\u5220\u9664\u6709\u6548\u7684\u5feb\u7167\uff0c\u4e5f\u53ef\u4ee5\u5220\u9664\u521b\u5efa\u5931\u8d25\u7684\u5feb\u7167\u3002 nebula> DROP SNAPSHOT SNAPSHOT_2019_12_04_10_54_36; nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- \u6b64\u65f6\u5220\u9664\u7684\u5feb\u7167\u5df2\u4e0d\u5728\u5feb\u7167\u5217\u8868\u4e2d\u3002 \u6ce8\u610f\u4e8b\u9879 \u00b6 \u5f53\u7cfb\u7edf\u7ed3\u6784\u53d1\u751f\u53d8\u5316\u540e\uff0c\u6700\u597d\u7acb\u523b\u521b\u5efa\u5feb\u7167\uff0c\u4f8b\u5982\u5728 add host\u3001drop host\u3001create space\u3001drop space\u3001balance \u7b49\u64cd\u4f5c\u4e4b\u540e\u3002 \u5f53\u524d\u7248\u672c\u4e0d\u652f\u6301\u5bf9\u521b\u5efa\u5931\u8d25\u7684\u5feb\u7167\u8fdb\u884c\u81ea\u52a8\u5783\u573e\u56de\u6536\uff0c\u540e\u7eed\u5c06\u5728 meta server \u4e2d\u5f00\u53d1 cluster checker \u529f\u80fd\uff0c\u901a\u8fc7\u5f02\u6b65\u7ebf\u7a0b\u68c0\u67e5\u96c6\u7fa4\u72b6\u6001\uff0c\u5e76\u81ea\u52a8\u56de\u6536\u521b\u5efa\u5931\u8d25\u7684\u5feb\u7167\u5783\u573e\u6587\u4ef6 \u5f53\u524d\u7248\u672c\u6682\u672a\u63d0\u4f9b\u7528\u6237\u6307\u5b9a\u5feb\u7167\u8def\u5f84\u7684\u529f\u80fd\uff0c\u5feb\u7167\u5c06\u9ed8\u8ba4\u521b\u5efa\u5728 data_path/nebula \u76ee\u5f55\u4e0b\u3002 \u5f53\u524d\u7248\u672c\u6682\u672a\u63d0\u4f9b\u5feb\u7167\u6062\u590d\u529f\u80fd\uff0c\u9700\u8981\u7528\u6237\u6839\u636e\u5b9e\u9645\u7684\u751f\u4ea7\u73af\u5883\u7f16\u5199 shell \u811a\u672c\u5b9e\u73b0\u3002\u5b9e\u73b0\u903b\u8f91\u4e5f\u6bd4\u8f83\u7b80\u5355\uff0c\u62f7\u8d1d\u5404 engine server \u7684\u5feb\u7167\u5230\u6307\u5b9a\u7684\u6587\u4ef6\u5939\u4e0b\uff0c\u5e76\u5c06\u6b64\u6587\u4ef6\u5939\u8bbe\u7f6e\u4e3a data_path \uff0c\u7136\u540e\u542f\u52a8\u96c6\u7fa4\u5373\u53ef\u3002","title":"\u96c6\u7fa4\u5feb\u7167"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#_1","text":"","title":"\u96c6\u7fa4\u5feb\u7167"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#_2","text":"CREATE SNAPSHOT \u547d\u4ee4\u53ef\u5bf9\u6574\u4e2a\u96c6\u7fa4\u521b\u5efa\u5f53\u524d\u65f6\u95f4\u70b9\u7684\u5feb\u7167\uff0c\u5feb\u7167\u540d\u79f0\u7531 meta server \u7684\u65f6\u95f4\u6233\u7ec4\u6210\u3002\u5f53\u524d\u7248\u672c\u5982\u679c\u5feb\u7167\u521b\u5efa\u5931\u8d25\uff0c\u5fc5\u987b\u901a\u8fc7 DROP SNAPSHOT \u547d\u4ee4\u6e05\u9664\u65e0\u6548\u7684\u5feb\u7167\u3002 \u5f53\u524d\u7248\u672c\u4e0d\u652f\u6301\u5bf9\u6307\u5b9a\u7684\u56fe\u7a7a\u95f4\u521b\u5efa\u5feb\u7167\uff0c\u5f53\u6267\u884c CREATE SNAPSHOT \u540e\uff0c\u5c06\u5bf9\u96c6\u7fa4\u4e2d\u7684\u6240\u6709\u56fe\u7a7a\u95f4\u521b\u5efa\u5feb\u7167\u3002\u4f8b\u5982\uff1a nebula> CREATE SNAPSHOT; Execution succeeded (Time spent: 22892/23923 us)","title":"\u521b\u5efa\u5feb\u7167"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#_3","text":"SHOW SNAPSHOT \u547d\u4ee4\u53ef\u67e5\u770b\u96c6\u7fa4\u4e2d\u6240\u6709\u5feb\u7167\u72b6\u6001\uff08VALID \u6216 INVALID\uff09\u3001\u540d\u79f0\u548c\u521b\u5efa\u5feb\u7167\u65f6\u6240\u6709 storage server \u7684 IP \u5730\u5740\u3002\u4f8b\u5982\uff1a nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_36 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | -----------------------------------------------------------","title":"\u67e5\u770b\u5feb\u7167"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#_4","text":"DROP SNAPSHOT \u547d\u4ee4\u53ef\u5220\u9664\u6307\u5b9a\u540d\u79f0\u7684\u5feb\u7167\uff0c\u8bed\u6cd5\u4e3a\uff1a DROP SNAPSHOT <snapshot-name> \u53ef\u4ee5\u901a\u8fc7 SHOW SNAPSHOTS \u547d\u4ee4\u83b7\u53d6\u5feb\u7167\u540d\u79f0\uff0c DROP SNAPSHOT \u65e2\u53ef\u4ee5\u5220\u9664\u6709\u6548\u7684\u5feb\u7167\uff0c\u4e5f\u53ef\u4ee5\u5220\u9664\u521b\u5efa\u5931\u8d25\u7684\u5feb\u7167\u3002 nebula> DROP SNAPSHOT SNAPSHOT_2019_12_04_10_54_36; nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- \u6b64\u65f6\u5220\u9664\u7684\u5feb\u7167\u5df2\u4e0d\u5728\u5feb\u7167\u5217\u8868\u4e2d\u3002","title":"\u5220\u9664\u5feb\u7167"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#_5","text":"\u5f53\u7cfb\u7edf\u7ed3\u6784\u53d1\u751f\u53d8\u5316\u540e\uff0c\u6700\u597d\u7acb\u523b\u521b\u5efa\u5feb\u7167\uff0c\u4f8b\u5982\u5728 add host\u3001drop host\u3001create space\u3001drop space\u3001balance \u7b49\u64cd\u4f5c\u4e4b\u540e\u3002 \u5f53\u524d\u7248\u672c\u4e0d\u652f\u6301\u5bf9\u521b\u5efa\u5931\u8d25\u7684\u5feb\u7167\u8fdb\u884c\u81ea\u52a8\u5783\u573e\u56de\u6536\uff0c\u540e\u7eed\u5c06\u5728 meta server \u4e2d\u5f00\u53d1 cluster checker \u529f\u80fd\uff0c\u901a\u8fc7\u5f02\u6b65\u7ebf\u7a0b\u68c0\u67e5\u96c6\u7fa4\u72b6\u6001\uff0c\u5e76\u81ea\u52a8\u56de\u6536\u521b\u5efa\u5931\u8d25\u7684\u5feb\u7167\u5783\u573e\u6587\u4ef6 \u5f53\u524d\u7248\u672c\u6682\u672a\u63d0\u4f9b\u7528\u6237\u6307\u5b9a\u5feb\u7167\u8def\u5f84\u7684\u529f\u80fd\uff0c\u5feb\u7167\u5c06\u9ed8\u8ba4\u521b\u5efa\u5728 data_path/nebula \u76ee\u5f55\u4e0b\u3002 \u5f53\u524d\u7248\u672c\u6682\u672a\u63d0\u4f9b\u5feb\u7167\u6062\u590d\u529f\u80fd\uff0c\u9700\u8981\u7528\u6237\u6839\u636e\u5b9e\u9645\u7684\u751f\u4ea7\u73af\u5883\u7f16\u5199 shell \u811a\u672c\u5b9e\u73b0\u3002\u5b9e\u73b0\u903b\u8f91\u4e5f\u6bd4\u8f83\u7b80\u5355\uff0c\u62f7\u8d1d\u5404 engine server \u7684\u5feb\u7167\u5230\u6307\u5b9a\u7684\u6587\u4ef6\u5939\u4e0b\uff0c\u5e76\u5c06\u6b64\u6587\u4ef6\u5939\u8bbe\u7f6e\u4e3a data_path \uff0c\u7136\u540e\u542f\u52a8\u96c6\u7fa4\u5373\u53ef\u3002","title":"\u6ce8\u610f\u4e8b\u9879"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/","text":"\u4f5c\u4e1a\u7ba1\u7406\uff08Job Manager\uff09 \u00b6 \u4f5c\u4e1a\u7279\u6307\u5728\u5b58\u50a8\u5c42\u8fd0\u884c\u7684\u4e00\u4e9b\u957f\u4efb\u52a1\u3002\u6bd4\u5982 compact \u548c flush \u3002\u7ba1\u7406\u6307\u5bf9\u4f5c\u4e1a\u8fdb\u884c\u7ba1\u7406\u3002\u6bd4\u5982\u8ba9\u4f5c\u4e1a\u6392\u961f\u6267\u884c\u3001\u67e5\u770b\u4f5c\u4e1a\u72b6\u6001\u3001\u505c\u6b62\u4f5c\u4e1a\u3001\u6062\u590d\u4f5c\u4e1a\u7b49\u3002 \u547d\u4ee4\u5217\u8868 \u00b6 submit job compact / flush \u00b6 submit job compact/flush \u547d\u4ee4\u5728\u4f5c\u4e1a\u7ba1\u7406\u4e2d\u65b0\u5efa\u4f5c\u4e1a\u5e76\u8fd4\u56de\u4f5c\u4e1a ID\uff0c\u5728\u5b58\u50a8\u5c42\u4e2d\u6267\u884c compact/flush \u547d\u4ee4\u3002\u793a\u4f8b\u8fd4\u56de\u7ed3\u679c\u5982\u4e0b\uff1a nebula> SUBMIT JOB COMPACT; ============== | New Job Id | ============== | 40 | -------------- nebula> SUBMIT JOB FLUSH; ============== | New Job Id | ============== | 2 | -------------- SHOW JOB \u00b6 \u8fd4\u56de\u5355\u4e2a\u4f5c\u4e1a\u4fe1\u606f \u00b6 \u547d\u4ee4 SHOW JOB <job_id> \u7528\u4e8e\u8fd4\u56de\u5bf9\u5e94 ID \u4f5c\u4e1a\u53ca\u5176\u6240\u6709\u4efb\u52a1\u3002\u4f5c\u4e1a\u5230\u8fbe Meta \u5c42\u540e\uff0cMeta \u4f1a\u5c06\u4f5c\u4e1a\u5206\u6210\u591a\u4e2a\u4efb\u52a1\u5e76\u53d1\u9001\u81f3 storage \u5c42\u3002 nebula> SHOW JOB 40; ===================================================================================== | Job Id(TaskId) | Command(Dest) | Status | Start Time | Stop Time | ===================================================================================== | 40 | flush nba | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- | 40-0 | 192.168.8.5 | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- \u6267\u884c\u4e0a\u8ff0\u547d\u4ee4\u5c06\u8fd4\u56de 1 \u5230\u591a\u884c\u7ed3\u679c\uff0c\u53d6\u51b3\u4e8e space \u6240\u5728\u7684 storage \u4e2a\u6570\u3002 \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\uff1a 40 \u4e3a\u5f53\u524d\u4f5c\u4e1a ID flush nba \u8868\u793a\u5728 nba \u56fe\u7a7a\u95f4\u4e0a\u6267\u884c\u4e86 flush \u64cd\u4f5c finished \u8868\u793a\u8fd0\u884c\u5df2\u7ed3\u675f\uff0c\u4e14\u6210\u529f\u3002\u5176\u4ed6\u53ef\u80fd\u7684\u72b6\u6001\u6709 Queue\u3001running\u3001failed\u3001stopped 12/17/19 17:21:30 \u8868\u793a\u5f00\u59cb\u65f6\u95f4\uff0c\u521d\u59cb\u4e3a\u7a7a(Queue)\uff0c\u5f53\u4e14\u4ec5\u5f53\u72b6\u6001\u53d8\u4e3a running \u65f6\uff0c\u624d\u4f1a\u8bbe\u8fd9\u4e2a\u503c 12/17/19 17:21:30 \u8868\u793a\u7ed3\u675f\u65f6\u95f4\uff0c\u5982\u679c\u4e3a Queue \u6216\u8005 running \u72b6\u6001\uff0c\u8fd9\u91cc\u4f1a\u4e3a\u7a7a\uff0c\u5f53\u72b6\u6001\u53d8\u4e3a finished\u3001failed\u3001stopped \u65f6\u4f1a\u8bbe\u7f6e\u6b64\u503c 40-0 \u8868\u793a\u5f53\u524d\u4f5c\u4e1a ID \u662f 40\uff0c\u4efb\u52a1 ID \u662f 0 192.168.8.5 \u8868\u793a\u8fd0\u884c\u5728 192.168.8.5 \u8fd9\u53f0\u673a\u5668\u4e0a finished \u8868\u793a\u8fd0\u884c\u5df2\u7ed3\u675f\uff0c\u4e14\u6210\u529f\u3002\u5176\u4ed6\u53ef\u80fd\u7684\u72b6\u6001\u6709 Queue\u3001running\u3001failed\u3001stopped 12/17/19 17:21:30 \u8868\u793a\u5f00\u59cb\u65f6\u95f4\uff0c\u56e0\u4e3a\u4efb\u52a1\u521d\u59cb\u5373\u4e3a running \u72b6\u6001\uff0c\u6240\u4ee5\u8fd9\u91cc\u6c38\u4e0d\u4e3a\u7a7a 12/17/19 17:21:30 \u8868\u793a\u7ed3\u675f\u65f6\u95f4\uff0c\u5982\u679c\u4e3a running \u72b6\u6001\uff0c\u8fd9\u91cc\u4f1a\u4e3a\u7a7a\uff0c\u5f53\u72b6\u6001\u53d8\u4e3a finished\u3001failed\u3001stopped \u65f6\u4f1a\u8bbe\u7f6e\u6b64\u503c \u6ce8\u610f\uff1a \u4f5c\u4e1a\u72b6\u6001\u6709\u4e94\u79cd\uff0c\u5206\u4e3a\u662f QUEUE\u3001RUNNING\u3001FINISHED\u3001FAILED\u3001STOPPED\u3002\u72b6\u6001\u673a\u8f6c\u6362\u89c1\u4ee5\u4e0b\u8bf4\u660e\uff1a Queue -- running -- finished -- removed \\ \\ / \\ \\ -- failed -- / \\ \\ / \\ ---------- stopped -/ \u8fd4\u56de\u6240\u6709\u4f5c\u4e1a\u4fe1\u606f \u00b6 \u547d\u4ee4 SHOW JOBS \u7528\u4e8e\u5217\u51fa\u6240\u6709\u672a\u8fc7\u671f\u7684\u4f5c\u4e1a\u4fe1\u606f\u3002\u9ed8\u8ba4\u4f5c\u4e1a\u8fc7\u671f\u65f6\u957f\u4e3a\u4e00\u5468\u3002\u7528\u6237\u53ef\u901a\u8fc7 job_expired_secs \u53c2\u6570\u66f4\u6539\u8fc7\u671f\u65f6\u957f\u3002 nebula> SHOW JOBS; ============================================================================= | Job Id | Command | Status | Start Time | Stop Time | ============================================================================= | 22 | flush test2 | failed | 12/06/19 14:46:22 | 12/06/19 14:46:22 | ----------------------------------------------------------------------------- | 23 | compact test2 | stopped | 12/06/19 15:07:09 | 12/06/19 15:07:33 | ----------------------------------------------------------------------------- | 24 | compact test2 | stopped | 12/06/19 15:07:11 | 12/06/19 15:07:20 | ----------------------------------------------------------------------------- | 25 | compact test2 | stopped | 12/06/19 15:07:13 | 12/06/19 15:07:24 | ----------------------------------------------------------------------------- \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\u89c1\u4e0a\u8282 \u8fd4\u56de\u5355\u4e2a\u4f5c\u4e1a\u4fe1\u606f \u3002 STOP JOB \u00b6 \u547d\u4ee4 STOP JOB \u7528\u4e8e\u5728\u505c\u6b62\u672a\u5b8c\u6210\u7684\u4f5c\u4e1a\u3002 nebula> STOP JOB 22; ========================= | STOP Result | ========================= | stop 1 jobs 2 tasks | ------------------------- RECOVER JOB \u00b6 \u547d\u4ee4 RECOVER JOB \u7528\u4e8e\u91cd\u65b0\u5931\u8d25\u6267\u884c\u4f5c\u4e1a\uff0c\u5e76\u8fd4\u56de recover \u7684\u4f5c\u4e1a\u6570\u76ee\u3002 nebula> RECOVER JOB; ===================== | Recovered job num | ===================== | 5 job recovered | ---------------------","title":"\u4f5c\u4e1a\u7ba1\u7406\uff08Job Manager\uff09"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#job_manager","text":"\u4f5c\u4e1a\u7279\u6307\u5728\u5b58\u50a8\u5c42\u8fd0\u884c\u7684\u4e00\u4e9b\u957f\u4efb\u52a1\u3002\u6bd4\u5982 compact \u548c flush \u3002\u7ba1\u7406\u6307\u5bf9\u4f5c\u4e1a\u8fdb\u884c\u7ba1\u7406\u3002\u6bd4\u5982\u8ba9\u4f5c\u4e1a\u6392\u961f\u6267\u884c\u3001\u67e5\u770b\u4f5c\u4e1a\u72b6\u6001\u3001\u505c\u6b62\u4f5c\u4e1a\u3001\u6062\u590d\u4f5c\u4e1a\u7b49\u3002","title":"\u4f5c\u4e1a\u7ba1\u7406\uff08Job Manager\uff09"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#_1","text":"","title":"\u547d\u4ee4\u5217\u8868"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#submit_job_compact_flush","text":"submit job compact/flush \u547d\u4ee4\u5728\u4f5c\u4e1a\u7ba1\u7406\u4e2d\u65b0\u5efa\u4f5c\u4e1a\u5e76\u8fd4\u56de\u4f5c\u4e1a ID\uff0c\u5728\u5b58\u50a8\u5c42\u4e2d\u6267\u884c compact/flush \u547d\u4ee4\u3002\u793a\u4f8b\u8fd4\u56de\u7ed3\u679c\u5982\u4e0b\uff1a nebula> SUBMIT JOB COMPACT; ============== | New Job Id | ============== | 40 | -------------- nebula> SUBMIT JOB FLUSH; ============== | New Job Id | ============== | 2 | --------------","title":"submit job compact / flush"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#show_job","text":"","title":"SHOW JOB"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#_2","text":"\u547d\u4ee4 SHOW JOB <job_id> \u7528\u4e8e\u8fd4\u56de\u5bf9\u5e94 ID \u4f5c\u4e1a\u53ca\u5176\u6240\u6709\u4efb\u52a1\u3002\u4f5c\u4e1a\u5230\u8fbe Meta \u5c42\u540e\uff0cMeta \u4f1a\u5c06\u4f5c\u4e1a\u5206\u6210\u591a\u4e2a\u4efb\u52a1\u5e76\u53d1\u9001\u81f3 storage \u5c42\u3002 nebula> SHOW JOB 40; ===================================================================================== | Job Id(TaskId) | Command(Dest) | Status | Start Time | Stop Time | ===================================================================================== | 40 | flush nba | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- | 40-0 | 192.168.8.5 | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- \u6267\u884c\u4e0a\u8ff0\u547d\u4ee4\u5c06\u8fd4\u56de 1 \u5230\u591a\u884c\u7ed3\u679c\uff0c\u53d6\u51b3\u4e8e space \u6240\u5728\u7684 storage \u4e2a\u6570\u3002 \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\uff1a 40 \u4e3a\u5f53\u524d\u4f5c\u4e1a ID flush nba \u8868\u793a\u5728 nba \u56fe\u7a7a\u95f4\u4e0a\u6267\u884c\u4e86 flush \u64cd\u4f5c finished \u8868\u793a\u8fd0\u884c\u5df2\u7ed3\u675f\uff0c\u4e14\u6210\u529f\u3002\u5176\u4ed6\u53ef\u80fd\u7684\u72b6\u6001\u6709 Queue\u3001running\u3001failed\u3001stopped 12/17/19 17:21:30 \u8868\u793a\u5f00\u59cb\u65f6\u95f4\uff0c\u521d\u59cb\u4e3a\u7a7a(Queue)\uff0c\u5f53\u4e14\u4ec5\u5f53\u72b6\u6001\u53d8\u4e3a running \u65f6\uff0c\u624d\u4f1a\u8bbe\u8fd9\u4e2a\u503c 12/17/19 17:21:30 \u8868\u793a\u7ed3\u675f\u65f6\u95f4\uff0c\u5982\u679c\u4e3a Queue \u6216\u8005 running \u72b6\u6001\uff0c\u8fd9\u91cc\u4f1a\u4e3a\u7a7a\uff0c\u5f53\u72b6\u6001\u53d8\u4e3a finished\u3001failed\u3001stopped \u65f6\u4f1a\u8bbe\u7f6e\u6b64\u503c 40-0 \u8868\u793a\u5f53\u524d\u4f5c\u4e1a ID \u662f 40\uff0c\u4efb\u52a1 ID \u662f 0 192.168.8.5 \u8868\u793a\u8fd0\u884c\u5728 192.168.8.5 \u8fd9\u53f0\u673a\u5668\u4e0a finished \u8868\u793a\u8fd0\u884c\u5df2\u7ed3\u675f\uff0c\u4e14\u6210\u529f\u3002\u5176\u4ed6\u53ef\u80fd\u7684\u72b6\u6001\u6709 Queue\u3001running\u3001failed\u3001stopped 12/17/19 17:21:30 \u8868\u793a\u5f00\u59cb\u65f6\u95f4\uff0c\u56e0\u4e3a\u4efb\u52a1\u521d\u59cb\u5373\u4e3a running \u72b6\u6001\uff0c\u6240\u4ee5\u8fd9\u91cc\u6c38\u4e0d\u4e3a\u7a7a 12/17/19 17:21:30 \u8868\u793a\u7ed3\u675f\u65f6\u95f4\uff0c\u5982\u679c\u4e3a running \u72b6\u6001\uff0c\u8fd9\u91cc\u4f1a\u4e3a\u7a7a\uff0c\u5f53\u72b6\u6001\u53d8\u4e3a finished\u3001failed\u3001stopped \u65f6\u4f1a\u8bbe\u7f6e\u6b64\u503c \u6ce8\u610f\uff1a \u4f5c\u4e1a\u72b6\u6001\u6709\u4e94\u79cd\uff0c\u5206\u4e3a\u662f QUEUE\u3001RUNNING\u3001FINISHED\u3001FAILED\u3001STOPPED\u3002\u72b6\u6001\u673a\u8f6c\u6362\u89c1\u4ee5\u4e0b\u8bf4\u660e\uff1a Queue -- running -- finished -- removed \\ \\ / \\ \\ -- failed -- / \\ \\ / \\ ---------- stopped -/","title":"\u8fd4\u56de\u5355\u4e2a\u4f5c\u4e1a\u4fe1\u606f"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#_3","text":"\u547d\u4ee4 SHOW JOBS \u7528\u4e8e\u5217\u51fa\u6240\u6709\u672a\u8fc7\u671f\u7684\u4f5c\u4e1a\u4fe1\u606f\u3002\u9ed8\u8ba4\u4f5c\u4e1a\u8fc7\u671f\u65f6\u957f\u4e3a\u4e00\u5468\u3002\u7528\u6237\u53ef\u901a\u8fc7 job_expired_secs \u53c2\u6570\u66f4\u6539\u8fc7\u671f\u65f6\u957f\u3002 nebula> SHOW JOBS; ============================================================================= | Job Id | Command | Status | Start Time | Stop Time | ============================================================================= | 22 | flush test2 | failed | 12/06/19 14:46:22 | 12/06/19 14:46:22 | ----------------------------------------------------------------------------- | 23 | compact test2 | stopped | 12/06/19 15:07:09 | 12/06/19 15:07:33 | ----------------------------------------------------------------------------- | 24 | compact test2 | stopped | 12/06/19 15:07:11 | 12/06/19 15:07:20 | ----------------------------------------------------------------------------- | 25 | compact test2 | stopped | 12/06/19 15:07:13 | 12/06/19 15:07:24 | ----------------------------------------------------------------------------- \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\u89c1\u4e0a\u8282 \u8fd4\u56de\u5355\u4e2a\u4f5c\u4e1a\u4fe1\u606f \u3002","title":"\u8fd4\u56de\u6240\u6709\u4f5c\u4e1a\u4fe1\u606f"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#stop_job","text":"\u547d\u4ee4 STOP JOB \u7528\u4e8e\u5728\u505c\u6b62\u672a\u5b8c\u6210\u7684\u4f5c\u4e1a\u3002 nebula> STOP JOB 22; ========================= | STOP Result | ========================= | stop 1 jobs 2 tasks | -------------------------","title":"STOP JOB"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#recover_job","text":"\u547d\u4ee4 RECOVER JOB \u7528\u4e8e\u91cd\u65b0\u5931\u8d25\u6267\u884c\u4f5c\u4e1a\uff0c\u5e76\u8fd4\u56de recover \u7684\u4f5c\u4e1a\u6570\u76ee\u3002 nebula> RECOVER JOB; ===================== | Recovered job num | ===================== | 5 job recovered | ---------------------","title":"RECOVER JOB"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/","text":"\u5b58\u50a8\u670d\u52a1\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u6570\u636e\u8fc1\u79fb \u00b6 Nebula Graph \u7684\u670d\u52a1\u53ef\u5206\u4e3a graphd\uff0cstoraged\uff0cmetad\u3002\u6b64\u6587\u6863\u4e2d\u7684 balance \u4ec5\u9488\u5bf9 storaged \u8fdb\u884c\u64cd\u4f5c\u3002\u76ee\u524d\uff0cstoraged \u7684\u6269\u7f29\u5bb9\u662f\u901a\u8fc7 balance \u547d\u4ee4\u6765\u5b9e\u73b0\u7684\u3002balance \u547d\u4ee4\u6709\u4e24\u79cd\uff0c\u4e00\u79cd\u9700\u8981\u8fc1\u79fb\u6570\u636e\uff0c\u547d\u4ee4\u4e3a BALANCE DATA \uff1b\u53e6\u4e00\u79cd\u4e0d\u9700\u8981\u8fc1\u79fb\u6570\u636e\uff0c\u53ea\u6539\u53d8 partition \u7684 leader \u5206\u5e03\uff0c\u6765\u8fbe\u5230\u8d1f\u8f7d\u5747\u8861\u7684\u76ee\u7684\uff0c\u547d\u4ee4\u4e3a BALANCE LEADER \u3002 Balance data \u00b6 \u4ee5\u4e0b\u4e3e\u4f8b\u8bf4\u660e BALANCE DATA \u7684\u4f7f\u7528\u65b9\u5f0f\u3002\u672c\u4f8b\u5c06\u96c6\u7fa4\u4ece 3 \u4e2a\u5b9e\u4f8b\uff08\u8fdb\u7a0b\uff09\u6269\u5c55\u5230 8 \u4e2a\u5b9e\u4f8b\uff08\u8fdb\u7a0b\uff09\uff1a Step 1 \u51c6\u5907 \u00b6 \u90e8\u7f72\u4e00\u4e2a\u4e09\u526f\u672c\u7684\u96c6\u7fa4\uff0c1\u4e2a graphd\uff0c1\u4e2a metad\uff0c3\u4e2a storaged\uff08\u5177\u4f53\u90e8\u7f72\u65b9\u5f0f\u8bf7\u53c2\u8003\u96c6\u7fa4\u90e8\u7f72\u6587\u6863\uff09\uff0c\u901a\u8fc7 SHOW HOSTS \u547d\u4ee4\u53ef\u4ee5\u770b\u5230\u96c6\u7fa4\u7684\u72b6\u6001\u4fe1\u606f\uff1a Step 1.1 \u00b6 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ Got 3 rows (Time spent: 5886/6835 us) SHOW HOSTS \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\uff1a IP, Port \u8868\u793a\u5f53\u524d\u7684 storage \u5b9e\u4f8b. \u8fd9\u4e2a\u96c6\u7fa4\u542f\u52a8\u4e86 3 \u4e2a storaged \u670d\u52a1\uff0c\u5e76\u4e14\u6ca1\u6709\u4efb\u4f55\u6570\u636e\u3002(192.168.8.210:34600\uff0c192.168.8.210:34700\uff0c192.168.8.210:34500) Status \u8868\u793a\u5f53\u524d\u5b9e\u4f8b\u7684\u72b6\u6001\uff0c\u76ee\u524d\u6709 online/offline \u4e24\u79cd\u3002\u5f53\u673a\u5668\u4e0b\u7ebf\u4ee5\u540e\uff08metad \u5728\u4e00\u6bb5\u95f4\u9694\u5185\u6536\u4e0d\u5230\u5176\u5fc3\u8df3\uff09\uff0c\u5c06\u628a\u5176\u66f4\u6539\u4e3a offline\u3002 \u8fd9\u4e2a\u65f6\u95f4\u95f4\u9694\u53ef\u4ee5\u5728\u542f\u52a8 metad \u7684\u65f6\u5019\u901a\u8fc7\u8bbe\u7f6e expired_threshold_sec \u6765\u4fee\u6539\uff0c\u5f53\u524d\u9ed8\u8ba4\u503c\u662f 10 \u5206\u949f\u3002 Leader count\uff1a\u8868\u793a\u5f53\u524d\u5b9e\u4f8b Raft leader \u6570\u76ee\u3002 Leader distribution\uff1a\u8868\u793a\u5f53\u524d leader \u5728\u6bcf\u4e2a\u56fe\u7a7a\u95f4\u4e0a\u7684\u5206\u5e03\uff0c\u76ee\u524d\u5c1a\u672a\u521b\u5efa\u4efb\u4f55\u56fe\u7a7a\u95f4\u3002 Partition distribution\uff1a\u4e0d\u540c space \u4e2d partition \u7684\u6570\u76ee\u3002 Step 1.2 \u00b6 \u521b\u5efa\u4e00\u4e2a\u540d\u4e3a test \u7684\u56fe\u7a7a\u95f4\uff0c\u5305\u542b 100 \u4e2a partition \u548c 3 \u4e2a replica\u3002 nebula> CREATE SPACE test(PARTITION_NUM=100, REPLICA_FACTOR=3); \u7247\u523b\u540e\uff0c\u4f7f\u7528 SHOW HOSTS \u547d\u4ee4\u663e\u793a\u96c6\u7fa4\u7684\u5206\u5e03\u3002 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------ Step 2 \u4e0a\u7ebf\u65b0\u673a\u5668 \u00b6 \u542f\u52a8 5 \u4e2a\u65b0 storaged \u8fdb\u7a0b\u8fdb\u884c\u6269\u5bb9\u3002\u542f\u52a8\u5b8c\u6bd5\u540e\uff0c\u4f7f\u7528 SHOW HOSTS \u547d\u4ee4\u67e5\u770b\u65b0\u7684\u72b6\u6001\uff1a nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ \u65b0\u542f\u52a8\u7684 storage instance \u6b64\u65f6\u8fd8\u6ca1\u6709\u4efb\u4f55 partition\u3002 Step 3 \u8fc1\u79fb\u6570\u636e \u00b6 \u8fd0\u884c BALANCE DATA \u547d\u4ee4\uff0c \u67e5\u770b\u5f53\u524d\u7684 balance \u8ba1\u5212 id\u3002\u5982\u679c\u5f53\u524d\u96c6\u7fa4\u6709\u65b0\u673a\u5668\u52a0\u5165\uff0c\u5219\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u8ba1\u5212 id\u3002\u5bf9\u4e8e\u5df2\u7ecf\u5e73\u8861\u7684\u96c6\u7fa4\uff0c\u91cd\u590d\u8fd0\u884c BALANCE DATA \u4e0d\u4f1a\u6709\u4efb\u4f55\u65b0\u64cd\u4f5c\u3002 nebula> BALANCE DATA; ============== | ID | ============== | 1570761786 | -------------- \u4e5f\u53ef\u901a\u8fc7 BALANCE DATA $id \u67e5\u770b\u5177 balance \u7684\u5177\u4f53\u6267\u884c\u8fdb\u5ea6\u3002 nebula> BALANCE DATA 1570761786; =============================================================================== | balanceId, spaceId:partId, src->dst | status | =============================================================================== | [1570761786, 1:1, 192.168.8.210:34600->192.168.8.210:44920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34700->192.168.8.210:34920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34500->192.168.8.210:34800] | succeeded | ------------------------------------------------------------------------------- ... | Total:189, Succeeded:170, Failed:0, In Progress:19, Invalid:0 | 89.947090% | ------------------------------------------------------------------------------- BALANCE DATA $id \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\uff1a \u7b2c\u4e00\u5217 balanceId, spaceId:partId, src->dst \u8868\u793a\u4e00\u4e2a\u5177\u4f53\u7684 balance task\u3002 \u4ee5 1570761786, 1:88, 192.168.8.210:34700->192.168.8.210:35940 \u4e3a\u4f8b\uff1a 1570761786 \u4e3a balance ID 1:88\uff0c1 \u8868\u793a\u5f53\u524d\u7684 spaceId\uff0c88 \u8868\u793a\u8fc1\u79fb\u7684 partId 192.168.8.210:34700->192.168.8.210:3594\uff0c\u8868\u793a\u6570\u636e\u4ece192.168.8.210:34700 \u642c\u8fc1\u81f3 192.168.8.210:35940 \u7b2c\u4e8c\u5217\u8868\u793a\u5f53\u524d task \u7684\u8fd0\u884c\u72b6\u6001\uff0c\u76ee\u524d\u6709 4 \u79cd\u72b6\u6001 Succeeded\uff1a\u8fd0\u884c\u6210\u529f Failed\uff1a\u8fd0\u884c\u5931\u8d25 In progress\uff1a\u8fd0\u884c\u4e2d Invalid\uff1a\u65e0\u6548\u7684 task \u6700\u540e\u4e00\u884c\u4e3a\u5bf9\u6240\u6709 task \u8fd0\u884c\u72b6\u6001\u7684\u7edf\u8ba1\uff0c\u90e8\u5206 partition \u5c1a\u672a\u5b8c\u6210\u8fc1\u79fb\u3002 Step 4 \u67e5\u770b\u7ed3\u679c \u00b6 \u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u642c\u8fc1\u6570\u636e\u662f\u4e2a\u6bd4\u8f83\u6f2b\u957f\u7684\u8fc7\u7a0b\u3002\u4f46\u662f\u642c\u8fc1\u8fc7\u7a0b\u4e0d\u4f1a\u5f71\u54cd\u5df2\u6709\u670d\u52a1\u3002\u8fd0\u884c\u7ed3\u675f\u540e\uff0c\u8fdb\u5ea6\u4f1a\u63d0\u793a 100%\u3002\u5982\u679c\u6709\u8fd0\u884c\u5931\u8d25\u7684 task\uff0c\u53ef\u518d\u6b21\u8fd0\u884c BALANCE DATA \u547d\u4ee4\u8fdb\u884c\u4fee\u590d\u3002\u5982\u679c\u591a\u6b21\u8fd0\u884c\u4ecd\u65e0\u6cd5\u4fee\u590d\uff0c\u8bf7\u4e0e\u793e\u533a\u8054\u7cfb GitHub \u3002\u6700\u540e\uff0c\u901a\u8fc7 SHOW HOSTS \u67e5\u770b\u8fd0\u884c\u540e\u7684 partition \u5206\u5e03\u3002 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 3 | test: 3 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | test: 0 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 35 | test: 35 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 24 | test: 24 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 38 | test: 38 | test: 38 | ------------------------------------------------------------------------------------------------ Got 8 rows (Time spent: 5074/6488 us) \u53ef\u4ee5\u770b\u5230 partition \u548c\u5bf9\u5e94\u7684\u6570\u636e\u5df2\u5747\u8861\u7684\u5206\u5e03\u81f3\u5404\u4e2a\u673a\u5668\u3002 Balance stop \u00b6 BALANCE DATA STOP \u547d\u4ee4\u7528\u4e8e\u505c\u6b62\u5df2\u7ecf\u5f00\u59cb\u6267\u884c\u7684 balance data \u8ba1\u5212\u3002\u5982\u679c\u6ca1\u6709\u6b63\u5728\u8fd0\u884c\u7684 balance \u8ba1\u5212\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\u3002\u5982\u679c\u6709\u6b63\u5728\u8fd0\u884c\u7684 balance \u8ba1\u5212\uff0c\u5219\u4f1a\u8fd4\u56de\u8ba1\u5212\u5bf9\u5e94\u7684 ID\u3002 \u7531\u4e8e\u6bcf\u4e2a balance \u8ba1\u5212\u5bf9\u5e94\u82e5\u5e72\u4e2a balance task\uff0c BALANCE DATA STOP \u4e0d\u4f1a\u505c\u6b62\u5df2\u7ecf\u5f00\u59cb\u6267\u884c\u7684 balance task\uff0c\u53ea\u4f1a\u53d6\u6d88\u540e\u7eed\u7684 task\uff0c\u5df2\u7ecf\u5f00\u59cb\u7684 task \u5c06\u7ee7\u7eed\u6267\u884c\u76f4\u81f3\u5b8c\u6210\u3002 \u7528\u6237\u53ef\u4ee5\u5728 BALANCE DATA STOP \u4e4b\u540e\u8f93\u5165 BALANCE DATA $id \u6765\u67e5\u770b\u5df2\u7ecf\u505c\u6b62\u7684 balance \u8ba1\u5212\u72b6\u6001\u3002 \u6240\u6709\u5df2\u7ecf\u5f00\u59cb\u6267\u884c\u7684 task \u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u518d\u6b21\u6267\u884c BALANCE DATA \uff0c\u91cd\u65b0\u5f00\u59cb balance\u3002 \u5982\u679c\u4e4b\u524d\u505c\u6b62\u7684\u8ba1\u5212\u4e2d\u6709\u5931\u8d25\u7684 task\uff0c\u5219\u4f1a\u7ee7\u7eed\u6267\u884c\u4e4b\u524d\u7684\u8ba1\u5212\uff0c\u5982\u679c\u4e4b\u524d\u505c\u6b62\u7684\u8ba1\u5212\u4e2d\u6240\u6709 task \u90fd\u6210\u529f\u4e86\uff0c\u5219\u4f1a\u65b0\u5efa\u4e00\u4e2a balance \u8ba1\u5212\u5e76\u5f00\u59cb\u6267\u884c\u3002 \u6279\u91cf\u7f29\u5bb9 \u00b6 Nebula Graph \u652f\u6301\u6307\u5b9a\u9700\u8981\u4e0b\u7ebf\u7684\u673a\u5668\u8fdb\u884c\u6279\u91cf\u7f29\u5bb9\u3002\u8bed\u6cd5\u4e3a BALANCE DATA REMOVE $host_list \uff0c\u4f8b\u5982 BALANCE DATA REMOVE 192.168.0.1:50000,192.168.0.2:50000 \uff0c\u5c06\u5728\u672c\u6b21 balance \u8fc7\u7a0b\u4e2d\u79fb\u9664 192.168.0.1:50000\uff0c192.168.0.2:50000 \u4e24\u53f0\u673a\u5668\u3002 \u5982\u679c\u79fb\u9664\u6307\u5b9a\u673a\u5668\u540e\uff0c\u4e0d\u6ee1\u8db3\u526f\u672c\u6570\u8981\u6c42\uff08\u4f8b\u5982\u5269\u4f59\u673a\u5668\u6570\u5c0f\u4e8e\u526f\u672c\u6570\uff0c\u6216\u8005\u4e09\u526f\u672c\u4e2d\u6709\u4e00\u53f0\u5df2\u7ecf\u79bb\u7ebf\uff0c\u6b64\u65f6\u8981\u6c42\u79fb\u9664\u5269\u4f59\u4e24\u526f\u672c\u4e2d\u7684\u4e00\u4e2a\uff09\uff0cNebula Graph \u5c06\u62d2\u7edd\u672c\u6b21 balance \u8bf7\u6c42\uff0c\u5e76\u8fd4\u56de\u76f8\u5173\u9519\u8bef\u7801\u3002 Balance leader \u00b6 BALANCE DATA \u4ec5\u80fd balance partition\uff0c\u4f46\u662f leader \u5206\u5e03\u4ecd\u7136\u4e0d\u5747\u8861\uff0c\u8fd9\u610f\u5473\u7740\u65e7\u670d\u52a1\u8fc7\u8f7d\uff0c\u800c\u65b0\u670d\u52a1\u672a\u5f97\u5230\u5145\u5206\u4f7f\u7528\u3002\u8fd0\u884c BALANCE LEADER \u91cd\u65b0\u5206\u5e03 Raft leader\uff1a nebula> BALANCE LEADER \u7247\u523b\u540e\uff0c\u4f7f\u7528 SHOW HOSTS \u547d\u4ee4\u67e5\u770b\uff0c\u6b64\u65f6 Raft leader \u5df2\u5747\u5300\u5206\u5e03\u81f3\u6240\u6709\u7684\u5b9e\u4f8b\u3002 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------ Got 8 rows (Time spent: 5039/6346 us)","title":"\u5b58\u50a8\u670d\u52a1\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u6570\u636e\u8fc1\u79fb"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#_1","text":"Nebula Graph \u7684\u670d\u52a1\u53ef\u5206\u4e3a graphd\uff0cstoraged\uff0cmetad\u3002\u6b64\u6587\u6863\u4e2d\u7684 balance \u4ec5\u9488\u5bf9 storaged \u8fdb\u884c\u64cd\u4f5c\u3002\u76ee\u524d\uff0cstoraged \u7684\u6269\u7f29\u5bb9\u662f\u901a\u8fc7 balance \u547d\u4ee4\u6765\u5b9e\u73b0\u7684\u3002balance \u547d\u4ee4\u6709\u4e24\u79cd\uff0c\u4e00\u79cd\u9700\u8981\u8fc1\u79fb\u6570\u636e\uff0c\u547d\u4ee4\u4e3a BALANCE DATA \uff1b\u53e6\u4e00\u79cd\u4e0d\u9700\u8981\u8fc1\u79fb\u6570\u636e\uff0c\u53ea\u6539\u53d8 partition \u7684 leader \u5206\u5e03\uff0c\u6765\u8fbe\u5230\u8d1f\u8f7d\u5747\u8861\u7684\u76ee\u7684\uff0c\u547d\u4ee4\u4e3a BALANCE LEADER \u3002","title":"\u5b58\u50a8\u670d\u52a1\u7684\u8d1f\u8f7d\u5747\u8861\u548c\u6570\u636e\u8fc1\u79fb"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#balance_data","text":"\u4ee5\u4e0b\u4e3e\u4f8b\u8bf4\u660e BALANCE DATA \u7684\u4f7f\u7528\u65b9\u5f0f\u3002\u672c\u4f8b\u5c06\u96c6\u7fa4\u4ece 3 \u4e2a\u5b9e\u4f8b\uff08\u8fdb\u7a0b\uff09\u6269\u5c55\u5230 8 \u4e2a\u5b9e\u4f8b\uff08\u8fdb\u7a0b\uff09\uff1a","title":"Balance data"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_1","text":"\u90e8\u7f72\u4e00\u4e2a\u4e09\u526f\u672c\u7684\u96c6\u7fa4\uff0c1\u4e2a graphd\uff0c1\u4e2a metad\uff0c3\u4e2a storaged\uff08\u5177\u4f53\u90e8\u7f72\u65b9\u5f0f\u8bf7\u53c2\u8003\u96c6\u7fa4\u90e8\u7f72\u6587\u6863\uff09\uff0c\u901a\u8fc7 SHOW HOSTS \u547d\u4ee4\u53ef\u4ee5\u770b\u5230\u96c6\u7fa4\u7684\u72b6\u6001\u4fe1\u606f\uff1a","title":"Step 1 \u51c6\u5907"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_11","text":"nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ Got 3 rows (Time spent: 5886/6835 us) SHOW HOSTS \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\uff1a IP, Port \u8868\u793a\u5f53\u524d\u7684 storage \u5b9e\u4f8b. \u8fd9\u4e2a\u96c6\u7fa4\u542f\u52a8\u4e86 3 \u4e2a storaged \u670d\u52a1\uff0c\u5e76\u4e14\u6ca1\u6709\u4efb\u4f55\u6570\u636e\u3002(192.168.8.210:34600\uff0c192.168.8.210:34700\uff0c192.168.8.210:34500) Status \u8868\u793a\u5f53\u524d\u5b9e\u4f8b\u7684\u72b6\u6001\uff0c\u76ee\u524d\u6709 online/offline \u4e24\u79cd\u3002\u5f53\u673a\u5668\u4e0b\u7ebf\u4ee5\u540e\uff08metad \u5728\u4e00\u6bb5\u95f4\u9694\u5185\u6536\u4e0d\u5230\u5176\u5fc3\u8df3\uff09\uff0c\u5c06\u628a\u5176\u66f4\u6539\u4e3a offline\u3002 \u8fd9\u4e2a\u65f6\u95f4\u95f4\u9694\u53ef\u4ee5\u5728\u542f\u52a8 metad \u7684\u65f6\u5019\u901a\u8fc7\u8bbe\u7f6e expired_threshold_sec \u6765\u4fee\u6539\uff0c\u5f53\u524d\u9ed8\u8ba4\u503c\u662f 10 \u5206\u949f\u3002 Leader count\uff1a\u8868\u793a\u5f53\u524d\u5b9e\u4f8b Raft leader \u6570\u76ee\u3002 Leader distribution\uff1a\u8868\u793a\u5f53\u524d leader \u5728\u6bcf\u4e2a\u56fe\u7a7a\u95f4\u4e0a\u7684\u5206\u5e03\uff0c\u76ee\u524d\u5c1a\u672a\u521b\u5efa\u4efb\u4f55\u56fe\u7a7a\u95f4\u3002 Partition distribution\uff1a\u4e0d\u540c space \u4e2d partition \u7684\u6570\u76ee\u3002","title":"Step 1.1"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_12","text":"\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a test \u7684\u56fe\u7a7a\u95f4\uff0c\u5305\u542b 100 \u4e2a partition \u548c 3 \u4e2a replica\u3002 nebula> CREATE SPACE test(PARTITION_NUM=100, REPLICA_FACTOR=3); \u7247\u523b\u540e\uff0c\u4f7f\u7528 SHOW HOSTS \u547d\u4ee4\u663e\u793a\u96c6\u7fa4\u7684\u5206\u5e03\u3002 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------","title":"Step 1.2"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_2","text":"\u542f\u52a8 5 \u4e2a\u65b0 storaged \u8fdb\u7a0b\u8fdb\u884c\u6269\u5bb9\u3002\u542f\u52a8\u5b8c\u6bd5\u540e\uff0c\u4f7f\u7528 SHOW HOSTS \u547d\u4ee4\u67e5\u770b\u65b0\u7684\u72b6\u6001\uff1a nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ \u65b0\u542f\u52a8\u7684 storage instance \u6b64\u65f6\u8fd8\u6ca1\u6709\u4efb\u4f55 partition\u3002","title":"Step 2 \u4e0a\u7ebf\u65b0\u673a\u5668"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_3","text":"\u8fd0\u884c BALANCE DATA \u547d\u4ee4\uff0c \u67e5\u770b\u5f53\u524d\u7684 balance \u8ba1\u5212 id\u3002\u5982\u679c\u5f53\u524d\u96c6\u7fa4\u6709\u65b0\u673a\u5668\u52a0\u5165\uff0c\u5219\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u8ba1\u5212 id\u3002\u5bf9\u4e8e\u5df2\u7ecf\u5e73\u8861\u7684\u96c6\u7fa4\uff0c\u91cd\u590d\u8fd0\u884c BALANCE DATA \u4e0d\u4f1a\u6709\u4efb\u4f55\u65b0\u64cd\u4f5c\u3002 nebula> BALANCE DATA; ============== | ID | ============== | 1570761786 | -------------- \u4e5f\u53ef\u901a\u8fc7 BALANCE DATA $id \u67e5\u770b\u5177 balance \u7684\u5177\u4f53\u6267\u884c\u8fdb\u5ea6\u3002 nebula> BALANCE DATA 1570761786; =============================================================================== | balanceId, spaceId:partId, src->dst | status | =============================================================================== | [1570761786, 1:1, 192.168.8.210:34600->192.168.8.210:44920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34700->192.168.8.210:34920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34500->192.168.8.210:34800] | succeeded | ------------------------------------------------------------------------------- ... | Total:189, Succeeded:170, Failed:0, In Progress:19, Invalid:0 | 89.947090% | ------------------------------------------------------------------------------- BALANCE DATA $id \u8fd4\u56de\u7ed3\u679c\u8bf4\u660e\uff1a \u7b2c\u4e00\u5217 balanceId, spaceId:partId, src->dst \u8868\u793a\u4e00\u4e2a\u5177\u4f53\u7684 balance task\u3002 \u4ee5 1570761786, 1:88, 192.168.8.210:34700->192.168.8.210:35940 \u4e3a\u4f8b\uff1a 1570761786 \u4e3a balance ID 1:88\uff0c1 \u8868\u793a\u5f53\u524d\u7684 spaceId\uff0c88 \u8868\u793a\u8fc1\u79fb\u7684 partId 192.168.8.210:34700->192.168.8.210:3594\uff0c\u8868\u793a\u6570\u636e\u4ece192.168.8.210:34700 \u642c\u8fc1\u81f3 192.168.8.210:35940 \u7b2c\u4e8c\u5217\u8868\u793a\u5f53\u524d task \u7684\u8fd0\u884c\u72b6\u6001\uff0c\u76ee\u524d\u6709 4 \u79cd\u72b6\u6001 Succeeded\uff1a\u8fd0\u884c\u6210\u529f Failed\uff1a\u8fd0\u884c\u5931\u8d25 In progress\uff1a\u8fd0\u884c\u4e2d Invalid\uff1a\u65e0\u6548\u7684 task \u6700\u540e\u4e00\u884c\u4e3a\u5bf9\u6240\u6709 task \u8fd0\u884c\u72b6\u6001\u7684\u7edf\u8ba1\uff0c\u90e8\u5206 partition \u5c1a\u672a\u5b8c\u6210\u8fc1\u79fb\u3002","title":"Step 3 \u8fc1\u79fb\u6570\u636e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_4","text":"\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u642c\u8fc1\u6570\u636e\u662f\u4e2a\u6bd4\u8f83\u6f2b\u957f\u7684\u8fc7\u7a0b\u3002\u4f46\u662f\u642c\u8fc1\u8fc7\u7a0b\u4e0d\u4f1a\u5f71\u54cd\u5df2\u6709\u670d\u52a1\u3002\u8fd0\u884c\u7ed3\u675f\u540e\uff0c\u8fdb\u5ea6\u4f1a\u63d0\u793a 100%\u3002\u5982\u679c\u6709\u8fd0\u884c\u5931\u8d25\u7684 task\uff0c\u53ef\u518d\u6b21\u8fd0\u884c BALANCE DATA \u547d\u4ee4\u8fdb\u884c\u4fee\u590d\u3002\u5982\u679c\u591a\u6b21\u8fd0\u884c\u4ecd\u65e0\u6cd5\u4fee\u590d\uff0c\u8bf7\u4e0e\u793e\u533a\u8054\u7cfb GitHub \u3002\u6700\u540e\uff0c\u901a\u8fc7 SHOW HOSTS \u67e5\u770b\u8fd0\u884c\u540e\u7684 partition \u5206\u5e03\u3002 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 3 | test: 3 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | test: 0 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 35 | test: 35 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 24 | test: 24 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 38 | test: 38 | test: 38 | ------------------------------------------------------------------------------------------------ Got 8 rows (Time spent: 5074/6488 us) \u53ef\u4ee5\u770b\u5230 partition \u548c\u5bf9\u5e94\u7684\u6570\u636e\u5df2\u5747\u8861\u7684\u5206\u5e03\u81f3\u5404\u4e2a\u673a\u5668\u3002","title":"Step 4 \u67e5\u770b\u7ed3\u679c"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#balance_stop","text":"BALANCE DATA STOP \u547d\u4ee4\u7528\u4e8e\u505c\u6b62\u5df2\u7ecf\u5f00\u59cb\u6267\u884c\u7684 balance data \u8ba1\u5212\u3002\u5982\u679c\u6ca1\u6709\u6b63\u5728\u8fd0\u884c\u7684 balance \u8ba1\u5212\uff0c\u5219\u4f1a\u8fd4\u56de\u9519\u8bef\u4fe1\u606f\u3002\u5982\u679c\u6709\u6b63\u5728\u8fd0\u884c\u7684 balance \u8ba1\u5212\uff0c\u5219\u4f1a\u8fd4\u56de\u8ba1\u5212\u5bf9\u5e94\u7684 ID\u3002 \u7531\u4e8e\u6bcf\u4e2a balance \u8ba1\u5212\u5bf9\u5e94\u82e5\u5e72\u4e2a balance task\uff0c BALANCE DATA STOP \u4e0d\u4f1a\u505c\u6b62\u5df2\u7ecf\u5f00\u59cb\u6267\u884c\u7684 balance task\uff0c\u53ea\u4f1a\u53d6\u6d88\u540e\u7eed\u7684 task\uff0c\u5df2\u7ecf\u5f00\u59cb\u7684 task \u5c06\u7ee7\u7eed\u6267\u884c\u76f4\u81f3\u5b8c\u6210\u3002 \u7528\u6237\u53ef\u4ee5\u5728 BALANCE DATA STOP \u4e4b\u540e\u8f93\u5165 BALANCE DATA $id \u6765\u67e5\u770b\u5df2\u7ecf\u505c\u6b62\u7684 balance \u8ba1\u5212\u72b6\u6001\u3002 \u6240\u6709\u5df2\u7ecf\u5f00\u59cb\u6267\u884c\u7684 task \u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u518d\u6b21\u6267\u884c BALANCE DATA \uff0c\u91cd\u65b0\u5f00\u59cb balance\u3002 \u5982\u679c\u4e4b\u524d\u505c\u6b62\u7684\u8ba1\u5212\u4e2d\u6709\u5931\u8d25\u7684 task\uff0c\u5219\u4f1a\u7ee7\u7eed\u6267\u884c\u4e4b\u524d\u7684\u8ba1\u5212\uff0c\u5982\u679c\u4e4b\u524d\u505c\u6b62\u7684\u8ba1\u5212\u4e2d\u6240\u6709 task \u90fd\u6210\u529f\u4e86\uff0c\u5219\u4f1a\u65b0\u5efa\u4e00\u4e2a balance \u8ba1\u5212\u5e76\u5f00\u59cb\u6267\u884c\u3002","title":"Balance stop"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#_2","text":"Nebula Graph \u652f\u6301\u6307\u5b9a\u9700\u8981\u4e0b\u7ebf\u7684\u673a\u5668\u8fdb\u884c\u6279\u91cf\u7f29\u5bb9\u3002\u8bed\u6cd5\u4e3a BALANCE DATA REMOVE $host_list \uff0c\u4f8b\u5982 BALANCE DATA REMOVE 192.168.0.1:50000,192.168.0.2:50000 \uff0c\u5c06\u5728\u672c\u6b21 balance \u8fc7\u7a0b\u4e2d\u79fb\u9664 192.168.0.1:50000\uff0c192.168.0.2:50000 \u4e24\u53f0\u673a\u5668\u3002 \u5982\u679c\u79fb\u9664\u6307\u5b9a\u673a\u5668\u540e\uff0c\u4e0d\u6ee1\u8db3\u526f\u672c\u6570\u8981\u6c42\uff08\u4f8b\u5982\u5269\u4f59\u673a\u5668\u6570\u5c0f\u4e8e\u526f\u672c\u6570\uff0c\u6216\u8005\u4e09\u526f\u672c\u4e2d\u6709\u4e00\u53f0\u5df2\u7ecf\u79bb\u7ebf\uff0c\u6b64\u65f6\u8981\u6c42\u79fb\u9664\u5269\u4f59\u4e24\u526f\u672c\u4e2d\u7684\u4e00\u4e2a\uff09\uff0cNebula Graph \u5c06\u62d2\u7edd\u672c\u6b21 balance \u8bf7\u6c42\uff0c\u5e76\u8fd4\u56de\u76f8\u5173\u9519\u8bef\u7801\u3002","title":"\u6279\u91cf\u7f29\u5bb9"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#balance_leader","text":"BALANCE DATA \u4ec5\u80fd balance partition\uff0c\u4f46\u662f leader \u5206\u5e03\u4ecd\u7136\u4e0d\u5747\u8861\uff0c\u8fd9\u610f\u5473\u7740\u65e7\u670d\u52a1\u8fc7\u8f7d\uff0c\u800c\u65b0\u670d\u52a1\u672a\u5f97\u5230\u5145\u5206\u4f7f\u7528\u3002\u8fd0\u884c BALANCE LEADER \u91cd\u65b0\u5206\u5e03 Raft leader\uff1a nebula> BALANCE LEADER \u7247\u523b\u540e\uff0c\u4f7f\u7528 SHOW HOSTS \u547d\u4ee4\u67e5\u770b\uff0c\u6b64\u65f6 Raft leader \u5df2\u5747\u5300\u5206\u5e03\u81f3\u6240\u6709\u7684\u5b9e\u4f8b\u3002 nebula> SHOW HOSTS; ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------ Got 8 rows (Time spent: 5039/6346 us)","title":"Balance leader"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/","text":"Storage Metrics \u00b6 \u4ecb\u7ecd \u00b6 \u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u901a\u8fc7 HTTP \u65b9\u5f0f\u6765\u83b7\u53d6 Storage Service \u5c42\u7684\u57fa\u672c\u6027\u80fd\u6307\u6807\u3002 \u6bcf\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u90fd\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6307\u6807\u540d\u3001\u7edf\u8ba1\u7c7b\u578b\u3001\u65f6\u95f4\u8303\u56f4\u3002 counter_name statistic_type time_range \u4e0b\u9762\u5c06\u5206\u522b\u4ecb\u7ecd\u8fd9\u4e09\u90e8\u5206\u3002 \u6307\u6807\u540d \u00b6 \u6bcf\u4e2a\u6307\u6807\u540d\u90fd\u7531\u670d\u52a1\u540d\u52a0\u6a21\u5757\u540d\u6784\u6210\uff0c\u76ee\u524d\u652f\u6301\u83b7\u53d6\u5982\u4e0b\u63a5\u53e3\uff1a \u83b7\u53d6\u70b9\u7684\u5c5e\u6027 storage_vertex_props \u83b7\u53d6\u8fb9\u7684\u5c5e\u6027 storage_edge_props \u63d2\u5165\u4e00\u4e2a\u70b9 storage_add_vertex \u63d2\u5165\u4e00\u6761\u8fb9 storage_add_edge \u5220\u9664\u4e00\u4e2a\u70b9 storage_del_vertex \u66f4\u65b0\u4e00\u4e2a\u70b9\u7684\u5c5e\u6027 storage_update_vertex \u66f4\u65b0\u4e00\u6761\u8fb9\u7684\u5c5e\u6027 storage_update_edge \u8bfb\u53d6\u4e00\u4e2a\u952e\u503c\u5bf9 storage_get_kv \u5199\u5165\u4e00\u4e2a\u952e\u503c\u5bf9 storage_put_kv \u4ec5\u9650\u5185\u90e8\u4f7f\u7528 storage_get_bound \u6bcf\u4e00\u4e2a\u63a5\u53e3\u90fd\u6709\u4e09\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u522b\u4e3a\u5ef6\u8fdf(\u5355\u4f4d\u4e3a us)\u3001\u6210\u529f\u7684 QPS\u3001\u53d1\u751f\u9519\u8bef\u7684 QPS\uff0c\u540e\u7f00\u540d\u5982\u4e0b\uff1a _latency _qps _error_qps \u5c06\u63a5\u53e3\u540d\u548c\u76f8\u5e94\u6307\u6807\u8fde\u63a5\u5728\u4e00\u8d77\u5373\u53ef\u83b7\u5f97\u5b8c\u6574\u7684\u6307\u6807\u540d\uff0c\u4f8b\u5982 storage_add_vertex_latency \u3001 storage_add_vertex_qps \u3001 storage_add_vertex_error_qps \u5206\u522b\u4ee3\u8868\u63d2\u5165\u4e00\u4e2a\u70b9\u7684\u5ef6\u8fdf\u3001QPS \u548c\u53d1\u751f\u9519\u8bef\u7684 QPS\u3002 \u7edf\u8ba1\u7c7b\u578b \u00b6 \u76ee\u524d\u652f\u6301\u7684\u7edf\u8ba1\u7c7b\u578b\u6709 SUM\u3001COUNT\u3001AVG\u3001RATE \u548c P \u5206\u4f4d\u6570 (P99\uff0cP999\uff0c ... \uff0cP999999)\u3002\u5176\u4e2d\uff1a _qps \u3001 _error_qps \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4f46\u4e0d\u652f\u6301 P \u5206\u4f4d\uff1b _latency \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4e5f\u652f\u6301 P \u5206\u4f4d\u3002 \u65f6\u95f4\u8303\u56f4 \u00b6 \u65f6\u95f4\u8303\u56f4\u76ee\u524d\u53ea\u652f\u6301\u4e09\u79cd\uff0c\u5206\u522b\u4e3a 60\u3001600\u30013600\uff0c\u5206\u522b\u8868\u793a\u6700\u8fd1\u4e00\u5206\u949f\u3001\u6700\u8fd1\u5341\u5206\u949f\u548c\u6700\u8fd1\u4e00\u5c0f\u65f6\u3002 \u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u76f8\u5e94\u7684\u6027\u80fd\u6307\u6807 \u00b6 \u6839\u636e\u4e0a\u9762\u7684\u4ecb\u7ecd\uff0c\u5c31\u53ef\u4ee5\u5199\u51fa\u4e00\u4e2a\u5b8c\u6574\u7684\u6307\u6807\u540d\u79f0\u4e86\uff0c\u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a storage_add_vertex_latency . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u63d2\u5165\u4e00\u4e2a\u70b9\u7684\u5e73\u5747\u5ef6\u65f6 storage_get_bound_qps . rate .600 // \u6700\u8fd1\u5341\u5206\u949f\u83b7\u53d6\u90bb\u70b9\u7684 QPS storage_update_edge_error_qps . count .3600 // \u6700\u8fd1\u4e00\u5c0f\u65f6\u66f4\u65b0\u4e00\u6761\u8fb9\u53d1\u751f\u9519\u8bef\u7684\u603b\u8ba1\u6570\u91cf \u5047\u8bbe\u672c\u5730\u542f\u52a8\u4e86\u4e00\u4e2a nebula storage service\uff0c\u540c\u65f6\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684 ws_http_port \u7aef\u53e3\u53f7\u4e3a 12000\u3002\u901a\u8fc7 HTTP \u7684 GET \u63a5\u53e3\u53d1\u9001\uff0c\u65b9\u6cd5\u540d\u4e3a get_stats \uff0c\u53c2\u6570\u4e3a stats \u52a0\u5bf9\u5e94\u7684\u6307\u6807\u540d\u5b57\u3002\u4e0b\u9762\u662f\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u6307\u6807\u7684\u793a\u4f8b\uff1a # \u83b7\u53d6\u4e00\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60\" # storage_vertex_props_qps.rate.60=2674 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60\" # storage_vertex_props_qps.rate.60=2638 # storage_vertex_props_latency.avg.60=812 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807\u5e76\u4ee5 json \u683c\u5f0f\u8fd4\u56de curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60&returnjson\" # [{\"value\":2723,\"name\":\"storage_vertex_props_qps.rate.60\"},{\"value\":804,\"name\":\"storage_vertex_props_latency.avg.60\"}] # \u83b7\u53d6\u6240\u6709\u6307\u6807 curl -G \"http://127.0.0.1:12000/get_stats?stats\" # \u6216 curl -G \"http://127.0.0.1:12000/get_stats\"","title":"Storage Metrics"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#storage_metrics","text":"","title":"Storage Metrics"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#_1","text":"\u76ee\u524d\uff0c Nebula Graph \u652f\u6301\u901a\u8fc7 HTTP \u65b9\u5f0f\u6765\u83b7\u53d6 Storage Service \u5c42\u7684\u57fa\u672c\u6027\u80fd\u6307\u6807\u3002 \u6bcf\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u90fd\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff0c\u5206\u522b\u4e3a\u6307\u6807\u540d\u3001\u7edf\u8ba1\u7c7b\u578b\u3001\u65f6\u95f4\u8303\u56f4\u3002 counter_name statistic_type time_range \u4e0b\u9762\u5c06\u5206\u522b\u4ecb\u7ecd\u8fd9\u4e09\u90e8\u5206\u3002","title":"\u4ecb\u7ecd"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#_2","text":"\u6bcf\u4e2a\u6307\u6807\u540d\u90fd\u7531\u670d\u52a1\u540d\u52a0\u6a21\u5757\u540d\u6784\u6210\uff0c\u76ee\u524d\u652f\u6301\u83b7\u53d6\u5982\u4e0b\u63a5\u53e3\uff1a \u83b7\u53d6\u70b9\u7684\u5c5e\u6027 storage_vertex_props \u83b7\u53d6\u8fb9\u7684\u5c5e\u6027 storage_edge_props \u63d2\u5165\u4e00\u4e2a\u70b9 storage_add_vertex \u63d2\u5165\u4e00\u6761\u8fb9 storage_add_edge \u5220\u9664\u4e00\u4e2a\u70b9 storage_del_vertex \u66f4\u65b0\u4e00\u4e2a\u70b9\u7684\u5c5e\u6027 storage_update_vertex \u66f4\u65b0\u4e00\u6761\u8fb9\u7684\u5c5e\u6027 storage_update_edge \u8bfb\u53d6\u4e00\u4e2a\u952e\u503c\u5bf9 storage_get_kv \u5199\u5165\u4e00\u4e2a\u952e\u503c\u5bf9 storage_put_kv \u4ec5\u9650\u5185\u90e8\u4f7f\u7528 storage_get_bound \u6bcf\u4e00\u4e2a\u63a5\u53e3\u90fd\u6709\u4e09\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u522b\u4e3a\u5ef6\u8fdf(\u5355\u4f4d\u4e3a us)\u3001\u6210\u529f\u7684 QPS\u3001\u53d1\u751f\u9519\u8bef\u7684 QPS\uff0c\u540e\u7f00\u540d\u5982\u4e0b\uff1a _latency _qps _error_qps \u5c06\u63a5\u53e3\u540d\u548c\u76f8\u5e94\u6307\u6807\u8fde\u63a5\u5728\u4e00\u8d77\u5373\u53ef\u83b7\u5f97\u5b8c\u6574\u7684\u6307\u6807\u540d\uff0c\u4f8b\u5982 storage_add_vertex_latency \u3001 storage_add_vertex_qps \u3001 storage_add_vertex_error_qps \u5206\u522b\u4ee3\u8868\u63d2\u5165\u4e00\u4e2a\u70b9\u7684\u5ef6\u8fdf\u3001QPS \u548c\u53d1\u751f\u9519\u8bef\u7684 QPS\u3002","title":"\u6307\u6807\u540d"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#_3","text":"\u76ee\u524d\u652f\u6301\u7684\u7edf\u8ba1\u7c7b\u578b\u6709 SUM\u3001COUNT\u3001AVG\u3001RATE \u548c P \u5206\u4f4d\u6570 (P99\uff0cP999\uff0c ... \uff0cP999999)\u3002\u5176\u4e2d\uff1a _qps \u3001 _error_qps \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4f46\u4e0d\u652f\u6301 P \u5206\u4f4d\uff1b _latency \u540e\u7f00\u7684\u6307\u6807\uff0c\u652f\u6301 SUM\u3001COUNT\u3001AVG\u3001RATE\uff0c\u4e5f\u652f\u6301 P \u5206\u4f4d\u3002","title":"\u7edf\u8ba1\u7c7b\u578b"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#_4","text":"\u65f6\u95f4\u8303\u56f4\u76ee\u524d\u53ea\u652f\u6301\u4e09\u79cd\uff0c\u5206\u522b\u4e3a 60\u3001600\u30013600\uff0c\u5206\u522b\u8868\u793a\u6700\u8fd1\u4e00\u5206\u949f\u3001\u6700\u8fd1\u5341\u5206\u949f\u548c\u6700\u8fd1\u4e00\u5c0f\u65f6\u3002","title":"\u65f6\u95f4\u8303\u56f4"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#http","text":"\u6839\u636e\u4e0a\u9762\u7684\u4ecb\u7ecd\uff0c\u5c31\u53ef\u4ee5\u5199\u51fa\u4e00\u4e2a\u5b8c\u6574\u7684\u6307\u6807\u540d\u79f0\u4e86\uff0c\u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a storage_add_vertex_latency . avg .60 // \u6700\u8fd1\u4e00\u5206\u949f\u63d2\u5165\u4e00\u4e2a\u70b9\u7684\u5e73\u5747\u5ef6\u65f6 storage_get_bound_qps . rate .600 // \u6700\u8fd1\u5341\u5206\u949f\u83b7\u53d6\u90bb\u70b9\u7684 QPS storage_update_edge_error_qps . count .3600 // \u6700\u8fd1\u4e00\u5c0f\u65f6\u66f4\u65b0\u4e00\u6761\u8fb9\u53d1\u751f\u9519\u8bef\u7684\u603b\u8ba1\u6570\u91cf \u5047\u8bbe\u672c\u5730\u542f\u52a8\u4e86\u4e00\u4e2a nebula storage service\uff0c\u540c\u65f6\u542f\u52a8\u65f6\u8bbe\u7f6e\u7684 ws_http_port \u7aef\u53e3\u53f7\u4e3a 12000\u3002\u901a\u8fc7 HTTP \u7684 GET \u63a5\u53e3\u53d1\u9001\uff0c\u65b9\u6cd5\u540d\u4e3a get_stats \uff0c\u53c2\u6570\u4e3a stats \u52a0\u5bf9\u5e94\u7684\u6307\u6807\u540d\u5b57\u3002\u4e0b\u9762\u662f\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u6307\u6807\u7684\u793a\u4f8b\uff1a # \u83b7\u53d6\u4e00\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60\" # storage_vertex_props_qps.rate.60=2674 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807 curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60\" # storage_vertex_props_qps.rate.60=2638 # storage_vertex_props_latency.avg.60=812 # \u540c\u65f6\u83b7\u53d6\u591a\u4e2a\u6307\u6807\u5e76\u4ee5 json \u683c\u5f0f\u8fd4\u56de curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60&returnjson\" # [{\"value\":2723,\"name\":\"storage_vertex_props_qps.rate.60\"},{\"value\":804,\"name\":\"storage_vertex_props_latency.avg.60\"}] # \u83b7\u53d6\u6240\u6709\u6307\u6807 curl -G \"http://127.0.0.1:12000/get_stats?stats\" # \u6216 curl -G \"http://127.0.0.1:12000/get_stats\"","title":"\u901a\u8fc7 HTTP \u63a5\u53e3\u83b7\u53d6\u76f8\u5e94\u7684\u6027\u80fd\u6307\u6807"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/","text":"Dump Tool \u00b6 Dump Tool \u662f\u4e00\u4e2a\u5355\u673a\u79bb\u7ebf\u6570\u636e\u5bfc\u51fa\u5de5\u5177\uff0c\u53ef\u4ee5\u7528\u4e8e\u5bfc\u51fa\u6216\u7edf\u8ba1\u6307\u5b9a\u6761\u4ef6\u7684\u6570\u636e\u3002 \u5982\u4f55\u83b7\u5f97 \u00b6 Dump Tool \u6e90\u7801\u4f4d\u4e8e nebula/src/tools/db_dump \u4e0b\uff0c\u7528\u6237\u53ef\u4ee5\u6267\u884c make db_dump \u547d\u4ee4\u6765\u7f16\u8bd1\u751f\u6210\u8be5\u5de5\u5177\u3002\u5728\u4f7f\u7528\u672c\u5de5\u5177\u524d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 Nebula Graph CLI \u7684 SHOW HOSTS \u547d\u4ee4\u67e5\u770b\u5206\u533a\u7684\u5206\u5e03\u3002\u4f7f\u7528 vertex_id % partition_num \u6765\u8ba1\u7b97\u70b9\u5bf9\u5e94\u7684 key \u4f4d\u4e8e\u54ea\u4e2a\u5206\u533a\u3002 \u6ce8\u610f\uff1a Dump Tool \u4f4d\u4e8e rpm \u5305\u4e2d\uff0c\u76ee\u5f55\u662f nebula/bin/ \u3002\u8be5\u5de5\u5177\u901a\u8fc7\u76f4\u63a5\u6253\u5f00 RocksDB \u8f6c\u50a8\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u79bb\u7ebf\u4f7f\u7528\uff0c\u5173\u95ed\u8be5 storaged \u8fdb\u7a0b\uff0c\u5e76\u540c\u65f6\u4fdd\u6301 meta_server \u5df2\u542f\u52a8\u3002\u5177\u4f53\u7528\u6cd5\u8bf7\u53c2\u8003\u4e0b\u65b9\u8bf4\u660e\u3002 \u5982\u4f55\u4f7f\u7528 \u00b6 \u5177\u4f53\u7528\u6cd5\u5982\u4e0b\u6240\u793a\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u6267\u884c\u4e0d\u5e26\u53c2\u6570\u7684 db_dump \u547d\u4ee4\u83b7\u5f97\u5e2e\u52a9\u3002\u5176\u4e2d space \u53c2\u6570\u662f\u5fc5\u987b\u7684\uff0c\u800c db_path \u4ee5\u53ca meta_server \u5177\u6709\u9ed8\u8ba4\u503c\uff0c\u7528\u6237\u53ef\u4ee5\u6309\u7167\u5b9e\u9645\u914d\u7f6e\u3002 vids \u3001 parts \u3001 tags \u3001 edges \u53ef\u4ee5\u4efb\u610f\u7ec4\u5408\uff0c\u5bfc\u51fa\u4f60\u9700\u8981\u7684\u6570\u636e\u3002 ./db_dump --space = <space name> required: --space = <space name> # A space name must be given. optional: --db_path = <path to rocksdb> # Path to the RocksDB data directory. If nebula was installed in `/usr/local/nebula`, # the db_path would be /usr/local/nebula/data/storage/nebula/ # Default: ./ --meta_server = <ip:port,...> # A list of meta severs' ip:port separated by comma. # Default: 127.0.0.1:45500 --mode = scan | stat # scan: print to screen when records meet the condition, and also print statistics to screen in final. # stat: print statistics to screen. # Default: scan --vids = <list of vid> # A list of vids separated by comma. This parameter means vertex_id/edge_src_id # Would scan the whole space's records if it is not given. --parts = <list of partition id> # A list of partition ids separated by comma. # Would output all partitions if it is not given. --tags = <list of tag name> # A list of tag name separated by comma. --edges = <list of edge name> # A list of edge name separated by comma. --limit = <N> # A positive number that limits the output. # Would output all if set to 0 or negative. # Default: 1000 \u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a // \u6307\u5b9a space \u5bfc\u51fa\u6570\u636e ./db_dump --space = space_name // \u6307\u5b9aspace, db_path, meta_server ./db_dump --space = space_name --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // \u6307\u5b9a mode = stat ( \u7edf\u8ba1\u6a21\u5f0f ) \uff0c\u6b64\u65f6\u53ea\u8fd4\u56de\u7edf\u8ba1\u4fe1\u606f\uff0c\u4e0d\u6253\u5370\u6570\u636e ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // \u6307\u5b9a vid \u5bfc\u51fa\u8be5\u70b9\u4ee5\u53ca\u4ee5\u8be5\u70b9\u4e3a\u8d77\u59cb\u70b9\u7684\u8fb9 ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --vids = 123 ,456 // \u6307\u5b9a tag \u7c7b\u578b\uff0c\u5bfc\u51fa\u5177\u6709\u8be5 tag \u7684\u70b9 ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --tags = tag1,tag2 \u8fd4\u56de\u7684\u6570\u636e\u683c\u5f0f\uff1a // \u70b9\uff0ckey: part_id, vertex_id, tag_name, value: <prop_list> [ vertex ] key: 1 , 0 , poi value:mid:0,8191765721868409651,8025713627522363385,1993089399535188613,3926276052777355165,5123607763506443893,2990089379644866415,poi_name_0,\u4e0a\u6d77,\u534e\u4e1c,30.2824,120.016,poi_stat_0,poi_fc_0,poi_sc_0,0,poi_star_0, // \u8fb9, key: part_id, src_id, edge_name, ranking, dst_id, value: <prop_list> [ edge ] key: 1 , 0 , consume_poi_reverse, 0 , 656384 value:mid:656384,mid:0,7.19312,mid:656384,3897457441682646732,mun:656384,4038264117233984707,dun:656384,empe:656384,mobile:656384,gender:656384,age:656384,rs:656384,fpd:656384,0.75313,1.34433,fpd:656384,0.03567,7.56212, // \u7edf\u8ba1 ======================================================= COUNT: 10 #\u672c\u6b21\u5bfc\u51fa\u8bb0\u5f55\u6570\u91cf VERTEX COUNT: 1 #\u672c\u6b21\u5bfc\u51fa\u70b9\u6570\u91cf EDGE COUNT: 9 #\u672c\u6b21\u5bfc\u51fa\u8fb9\u6570\u91cf TAG STATISTICS: #\u672c\u6b21\u5bfc\u51fatag\u7edf\u8ba1 poi : 1 EDGE STATISTICS: #\u672c\u6b21\u5bfc\u51faedge\u7edf\u8ba1 consume_poi_reverse : 9 =======================================================","title":"Dump Tool"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/#dump_tool","text":"Dump Tool \u662f\u4e00\u4e2a\u5355\u673a\u79bb\u7ebf\u6570\u636e\u5bfc\u51fa\u5de5\u5177\uff0c\u53ef\u4ee5\u7528\u4e8e\u5bfc\u51fa\u6216\u7edf\u8ba1\u6307\u5b9a\u6761\u4ef6\u7684\u6570\u636e\u3002","title":"Dump Tool"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/#_1","text":"Dump Tool \u6e90\u7801\u4f4d\u4e8e nebula/src/tools/db_dump \u4e0b\uff0c\u7528\u6237\u53ef\u4ee5\u6267\u884c make db_dump \u547d\u4ee4\u6765\u7f16\u8bd1\u751f\u6210\u8be5\u5de5\u5177\u3002\u5728\u4f7f\u7528\u672c\u5de5\u5177\u524d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 Nebula Graph CLI \u7684 SHOW HOSTS \u547d\u4ee4\u67e5\u770b\u5206\u533a\u7684\u5206\u5e03\u3002\u4f7f\u7528 vertex_id % partition_num \u6765\u8ba1\u7b97\u70b9\u5bf9\u5e94\u7684 key \u4f4d\u4e8e\u54ea\u4e2a\u5206\u533a\u3002 \u6ce8\u610f\uff1a Dump Tool \u4f4d\u4e8e rpm \u5305\u4e2d\uff0c\u76ee\u5f55\u662f nebula/bin/ \u3002\u8be5\u5de5\u5177\u901a\u8fc7\u76f4\u63a5\u6253\u5f00 RocksDB \u8f6c\u50a8\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u79bb\u7ebf\u4f7f\u7528\uff0c\u5173\u95ed\u8be5 storaged \u8fdb\u7a0b\uff0c\u5e76\u540c\u65f6\u4fdd\u6301 meta_server \u5df2\u542f\u52a8\u3002\u5177\u4f53\u7528\u6cd5\u8bf7\u53c2\u8003\u4e0b\u65b9\u8bf4\u660e\u3002","title":"\u5982\u4f55\u83b7\u5f97"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/#_2","text":"\u5177\u4f53\u7528\u6cd5\u5982\u4e0b\u6240\u793a\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u6267\u884c\u4e0d\u5e26\u53c2\u6570\u7684 db_dump \u547d\u4ee4\u83b7\u5f97\u5e2e\u52a9\u3002\u5176\u4e2d space \u53c2\u6570\u662f\u5fc5\u987b\u7684\uff0c\u800c db_path \u4ee5\u53ca meta_server \u5177\u6709\u9ed8\u8ba4\u503c\uff0c\u7528\u6237\u53ef\u4ee5\u6309\u7167\u5b9e\u9645\u914d\u7f6e\u3002 vids \u3001 parts \u3001 tags \u3001 edges \u53ef\u4ee5\u4efb\u610f\u7ec4\u5408\uff0c\u5bfc\u51fa\u4f60\u9700\u8981\u7684\u6570\u636e\u3002 ./db_dump --space = <space name> required: --space = <space name> # A space name must be given. optional: --db_path = <path to rocksdb> # Path to the RocksDB data directory. If nebula was installed in `/usr/local/nebula`, # the db_path would be /usr/local/nebula/data/storage/nebula/ # Default: ./ --meta_server = <ip:port,...> # A list of meta severs' ip:port separated by comma. # Default: 127.0.0.1:45500 --mode = scan | stat # scan: print to screen when records meet the condition, and also print statistics to screen in final. # stat: print statistics to screen. # Default: scan --vids = <list of vid> # A list of vids separated by comma. This parameter means vertex_id/edge_src_id # Would scan the whole space's records if it is not given. --parts = <list of partition id> # A list of partition ids separated by comma. # Would output all partitions if it is not given. --tags = <list of tag name> # A list of tag name separated by comma. --edges = <list of edge name> # A list of edge name separated by comma. --limit = <N> # A positive number that limits the output. # Would output all if set to 0 or negative. # Default: 1000 \u4e0b\u9762\u662f\u4e00\u4e9b\u793a\u4f8b\uff1a // \u6307\u5b9a space \u5bfc\u51fa\u6570\u636e ./db_dump --space = space_name // \u6307\u5b9aspace, db_path, meta_server ./db_dump --space = space_name --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // \u6307\u5b9a mode = stat ( \u7edf\u8ba1\u6a21\u5f0f ) \uff0c\u6b64\u65f6\u53ea\u8fd4\u56de\u7edf\u8ba1\u4fe1\u606f\uff0c\u4e0d\u6253\u5370\u6570\u636e ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // \u6307\u5b9a vid \u5bfc\u51fa\u8be5\u70b9\u4ee5\u53ca\u4ee5\u8be5\u70b9\u4e3a\u8d77\u59cb\u70b9\u7684\u8fb9 ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --vids = 123 ,456 // \u6307\u5b9a tag \u7c7b\u578b\uff0c\u5bfc\u51fa\u5177\u6709\u8be5 tag \u7684\u70b9 ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --tags = tag1,tag2 \u8fd4\u56de\u7684\u6570\u636e\u683c\u5f0f\uff1a // \u70b9\uff0ckey: part_id, vertex_id, tag_name, value: <prop_list> [ vertex ] key: 1 , 0 , poi value:mid:0,8191765721868409651,8025713627522363385,1993089399535188613,3926276052777355165,5123607763506443893,2990089379644866415,poi_name_0,\u4e0a\u6d77,\u534e\u4e1c,30.2824,120.016,poi_stat_0,poi_fc_0,poi_sc_0,0,poi_star_0, // \u8fb9, key: part_id, src_id, edge_name, ranking, dst_id, value: <prop_list> [ edge ] key: 1 , 0 , consume_poi_reverse, 0 , 656384 value:mid:656384,mid:0,7.19312,mid:656384,3897457441682646732,mun:656384,4038264117233984707,dun:656384,empe:656384,mobile:656384,gender:656384,age:656384,rs:656384,fpd:656384,0.75313,1.34433,fpd:656384,0.03567,7.56212, // \u7edf\u8ba1 ======================================================= COUNT: 10 #\u672c\u6b21\u5bfc\u51fa\u8bb0\u5f55\u6570\u91cf VERTEX COUNT: 1 #\u672c\u6b21\u5bfc\u51fa\u70b9\u6570\u91cf EDGE COUNT: 9 #\u672c\u6b21\u5bfc\u51fa\u8fb9\u6570\u91cf TAG STATISTICS: #\u672c\u6b21\u5bfc\u51fatag\u7edf\u8ba1 poi : 1 EDGE STATISTICS: #\u672c\u6b21\u5bfc\u51faedge\u7edf\u8ba1 consume_poi_reverse : 9 =======================================================","title":"\u5982\u4f55\u4f7f\u7528"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/download-and-ingest-sst-file/","text":"Download and Ingest \u00b6 Nebula Graph \u5b58\u50a8\u8bbf\u95ee\u9ed8\u8ba4\u4f7f\u7528 RocksDB \u4f5c\u4e3a key-value \u5b58\u50a8\u5f15\u64ce\u3002\u56e0\u6b64\u5728\u5927\u91cf\u6570\u636e\u52a0\u8f7d\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u8fd0\u884c\u4e00\u4e2a map-reduce job \u79bb\u7ebf\u751f\u6210 RocksDB \u7684 SST \u6587\u4ef6\uff0c\u518d\u76f4\u63a5\u5206\u53d1\u5230\u670d\u52a1\u5668\u4e0a\u3002 Nebula Graph \u63d0\u4f9b\u4e86 Spark-SSTFile-Generator \u5de5\u5177\u3002 Spark-SSTFile-Generator \u901a\u8fc7\u6620\u5c04\u6587\u4ef6\uff0c\u4ece hive \u8868\u751f\u6210 SST \u6587\u4ef6\u3002 \u5177\u4f53\u7528\u6cd5\u8be6\u89c1 Spark application command line reference \u3002 \u6267\u884c\u540e\u4f1a\u5728 HDFS \u4e0a\u751f\u6210 SST \u6587\u4ef6\uff0c\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\uff1a |---1 (this is partition number) | | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst |---2 | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst .... \u5176\u4e2d\u5404\u4e2a\u76ee\u5f55\u4e3a partition \u7f16\u53f7\u3002 SST \u6587\u4ef6\u540d\u683c\u5f0f\u4e3a {TYPE}-${FIRST_KEY_IN_THIS_FILE}.sst \uff0c\u5176\u4e2d TYPE \u8868\u793a\u6570\u636e\u7c7b\u578b\uff0c FIRST_KEY_IN_THIS_FILE \u4e3a\u6587\u4ef6\u4e2d\u7684\u8d77\u59cb key\u3002\uff08\u5982\u679c\u4f60\u60f3\u81ea\u5df1\u5199\u5de5\u5177\u751f\u6210 SST \u6587\u4ef6\uff0c\u9700\u8981\u4fdd\u8bc1\u6bcf\u4e2a SST \u6587\u4ef6\u4e2d\u7684 key \u662f\u6709\u5e8f\u7684\u3002) \u8bf7\u786e\u8ba4\u6240\u6709 server \u5df2\u5b89\u88c5 Hadoop \uff0c\u5e76\u4e14 HADOOP_HOME \u5df2\u8bbe\u7f6e\u3002 \u8fd0\u884c Nebula Graph console\uff0c\u6267\u884c Download \u547d\u4ee4\uff1a nebula > DOWNLOAD HDFS \"hdfs://${HADOOP_HOST}:${HADOOP_PORT}/${HADOOP_PATH}\" \u901a\u8fc7 download \u547d\u4ee4\u4ee5\u53ca\u5404\u4e2a Storage Server \u7684 meta \u4fe1\u606f\uff0c\u5206\u522b\u4e0b\u8f7d\u5404\u81ea\u7684 SST \u6587\u4ef6\u5230 data/download \u76ee\u5f55\u4e2d\u3002\u5176\u4e2d\uff1a HADOOP_HOST \u6307\u5b9a Hadoop NameNode \u5730\u5740 HADOOP_PORT \u6307\u5b9a Hadoop NameNode \u7aef\u53e3\u53f7 HADOOP_PATH \u6307\u5b9a Hadoop \u6570\u636e\u5b58\u653e\u76ee\u5f55 \u5982\u679c download \u8fc7\u7a0b\u51fa\u73b0\u9519\u8bef\uff0c\u8bf7\u5220\u9664 data/download \u76ee\u5f55\u4e0b\u76f8\u5e94\u7684\u6570\u636e\u6587\u4ef6\uff0c\u5e76\u5c1d\u8bd5\u91cd\u65b0\u4e0b\u8f7d\u3002\u5982\u679c\u9047\u5230\u591a\u6b21\u5931\u8d25\uff0c\u8bf7\u5728 GitHub \u63d0 issue\u3002 \u6570\u636e\u4e0b\u8f7d\u5b8c\u6bd5\u540e\uff0c\u91cd\u65b0\u6267\u884c\u8be5\u547d\u4ee4\u4e0d\u4f1a\u53d1\u751f\u4efb\u4f55\u64cd\u4f5c\u3002 SST \u6570\u636e\u79bb\u7ebf\u4e0b\u8f7d\u5b8c\u6210\u540e\uff0c\u901a\u8fc7 INGEST \u547d\u4ee4\u5728\u7ebf \u52a0\u8f7d \u5230\u5b58\u50a8\u670d\u52a1\u4e2d\u3002 Ingest \u547d\u4ee4\u5982\u4e0b\uff1a nebula > INGEST; \u8be5\u547d\u4ee4\u5c06\u52a0\u8f7d download \u76ee\u5f55\u4e2d\u7684 SST \u6587\u4ef6\u3002 \u6ce8\u610f\uff1a \u6570\u636e\u91cf\u8f83\u5927\u65f6 ingest \u4f1a\u963b\u585e RocksDB \uff0c\u8bf7\u907f\u514d\u5728\u8bf7\u6c42\u9ad8\u5cf0\u6267\u884c\u8be5\u547d\u4ee4\u3002","title":"Download and Ingest"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/download-and-ingest-sst-file/#download_and_ingest","text":"Nebula Graph \u5b58\u50a8\u8bbf\u95ee\u9ed8\u8ba4\u4f7f\u7528 RocksDB \u4f5c\u4e3a key-value \u5b58\u50a8\u5f15\u64ce\u3002\u56e0\u6b64\u5728\u5927\u91cf\u6570\u636e\u52a0\u8f7d\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u8fd0\u884c\u4e00\u4e2a map-reduce job \u79bb\u7ebf\u751f\u6210 RocksDB \u7684 SST \u6587\u4ef6\uff0c\u518d\u76f4\u63a5\u5206\u53d1\u5230\u670d\u52a1\u5668\u4e0a\u3002 Nebula Graph \u63d0\u4f9b\u4e86 Spark-SSTFile-Generator \u5de5\u5177\u3002 Spark-SSTFile-Generator \u901a\u8fc7\u6620\u5c04\u6587\u4ef6\uff0c\u4ece hive \u8868\u751f\u6210 SST \u6587\u4ef6\u3002 \u5177\u4f53\u7528\u6cd5\u8be6\u89c1 Spark application command line reference \u3002 \u6267\u884c\u540e\u4f1a\u5728 HDFS \u4e0a\u751f\u6210 SST \u6587\u4ef6\uff0c\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\uff1a |---1 (this is partition number) | | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst |---2 | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst .... \u5176\u4e2d\u5404\u4e2a\u76ee\u5f55\u4e3a partition \u7f16\u53f7\u3002 SST \u6587\u4ef6\u540d\u683c\u5f0f\u4e3a {TYPE}-${FIRST_KEY_IN_THIS_FILE}.sst \uff0c\u5176\u4e2d TYPE \u8868\u793a\u6570\u636e\u7c7b\u578b\uff0c FIRST_KEY_IN_THIS_FILE \u4e3a\u6587\u4ef6\u4e2d\u7684\u8d77\u59cb key\u3002\uff08\u5982\u679c\u4f60\u60f3\u81ea\u5df1\u5199\u5de5\u5177\u751f\u6210 SST \u6587\u4ef6\uff0c\u9700\u8981\u4fdd\u8bc1\u6bcf\u4e2a SST \u6587\u4ef6\u4e2d\u7684 key \u662f\u6709\u5e8f\u7684\u3002) \u8bf7\u786e\u8ba4\u6240\u6709 server \u5df2\u5b89\u88c5 Hadoop \uff0c\u5e76\u4e14 HADOOP_HOME \u5df2\u8bbe\u7f6e\u3002 \u8fd0\u884c Nebula Graph console\uff0c\u6267\u884c Download \u547d\u4ee4\uff1a nebula > DOWNLOAD HDFS \"hdfs://${HADOOP_HOST}:${HADOOP_PORT}/${HADOOP_PATH}\" \u901a\u8fc7 download \u547d\u4ee4\u4ee5\u53ca\u5404\u4e2a Storage Server \u7684 meta \u4fe1\u606f\uff0c\u5206\u522b\u4e0b\u8f7d\u5404\u81ea\u7684 SST \u6587\u4ef6\u5230 data/download \u76ee\u5f55\u4e2d\u3002\u5176\u4e2d\uff1a HADOOP_HOST \u6307\u5b9a Hadoop NameNode \u5730\u5740 HADOOP_PORT \u6307\u5b9a Hadoop NameNode \u7aef\u53e3\u53f7 HADOOP_PATH \u6307\u5b9a Hadoop \u6570\u636e\u5b58\u653e\u76ee\u5f55 \u5982\u679c download \u8fc7\u7a0b\u51fa\u73b0\u9519\u8bef\uff0c\u8bf7\u5220\u9664 data/download \u76ee\u5f55\u4e0b\u76f8\u5e94\u7684\u6570\u636e\u6587\u4ef6\uff0c\u5e76\u5c1d\u8bd5\u91cd\u65b0\u4e0b\u8f7d\u3002\u5982\u679c\u9047\u5230\u591a\u6b21\u5931\u8d25\uff0c\u8bf7\u5728 GitHub \u63d0 issue\u3002 \u6570\u636e\u4e0b\u8f7d\u5b8c\u6bd5\u540e\uff0c\u91cd\u65b0\u6267\u884c\u8be5\u547d\u4ee4\u4e0d\u4f1a\u53d1\u751f\u4efb\u4f55\u64cd\u4f5c\u3002 SST \u6570\u636e\u79bb\u7ebf\u4e0b\u8f7d\u5b8c\u6210\u540e\uff0c\u901a\u8fc7 INGEST \u547d\u4ee4\u5728\u7ebf \u52a0\u8f7d \u5230\u5b58\u50a8\u670d\u52a1\u4e2d\u3002 Ingest \u547d\u4ee4\u5982\u4e0b\uff1a nebula > INGEST; \u8be5\u547d\u4ee4\u5c06\u52a0\u8f7d download \u76ee\u5f55\u4e2d\u7684 SST \u6587\u4ef6\u3002 \u6ce8\u610f\uff1a \u6570\u636e\u91cf\u8f83\u5927\u65f6 ingest \u4f1a\u963b\u585e RocksDB \uff0c\u8bf7\u907f\u514d\u5728\u8bf7\u6c42\u9ad8\u5cf0\u6267\u884c\u8be5\u547d\u4ee4\u3002","title":"Download and Ingest"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/import-csv-file/","text":"csv \u5bfc\u5165\u5de5\u5177 \u00b6 \u89c1 vesoft-inc/nebula-importer \u3002","title":"csv \u5bfc\u5165\u5de5\u5177"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/import-csv-file/#csv","text":"\u89c1 vesoft-inc/nebula-importer \u3002","title":"csv \u5bfc\u5165\u5de5\u5177"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/","text":"Spark Writer \u00b6 \u6982\u8ff0 \u00b6 Spark Writer \u662f Nebula Graph \u57fa\u4e8e Spark \u7684\u5206\u5e03\u5f0f\u6570\u636e\u5bfc\u5165\u5de5\u5177\uff0c\u80fd\u591f\u5c06\u591a\u79cd\u6570\u636e\u4ed3\u5e93\u4e2d\u7684\u6570\u636e\u8f6c\u5316\u4e3a\u56fe\u7684\u70b9\u548c\u8fb9\uff0c\u5e76\u6279\u91cf\u5bfc\u5165\u5230\u56fe\u6570\u636e\u5e93\u4e2d\u3002\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u4ed3\u5e93\u6709\uff1a HDFS\uff0c\u5305\u62ec Parquet\u3001JSON\u3001ORC \u548c CSV \u683c\u5f0f\u7684\u6587\u4ef6 HIVE Spark Writer \u652f\u6301\u5e76\u53d1\u5bfc\u5165\u591a\u4e2a tag\u3001edge\uff0c\u652f\u6301\u4e0d\u540c tag/edge \u914d\u7f6e\u4e0d\u540c\u7684\u6570\u636e\u4ed3\u5e93\u3002 \u8f6f\u4ef6\u8981\u6c42 \u00b6 \u6ce8\u610f\uff1a \u4e3a\u786e\u4fdd Nebula Graph Spark Writer \u6b63\u5e38\u4f7f\u7528\uff0c\u8bf7\u786e\u4fdd\u4f60\u7684\u673a\u5668\u5df2\u5b89\u88c5\uff1a Spark 2.0 \u53ca\u4ee5\u4e0a\u7248\u672c Hive 2.3 \u53ca\u4ee5\u4e0a\u7248\u672c Hadoop 2.0 \u53ca\u4ee5\u4e0a\u7248\u672c \u83b7\u53d6 Spark Writer \u00b6 \u7f16\u8bd1\u6e90\u7801 \u00b6 git clone https://github.com/vesoft-inc/nebula.git cd nebula/src/tools/spark-sstfile-generator mvn compile package \u6216\u8005\u76f4\u63a5\u4e0b\u8f7d \u4ece\u4e91\u5b58\u50a8 OSS \u4e0b\u8f7d \u00b6 wget https://nebula-graph.oss-accelerate.aliyuncs.com/jar-packages/sst.generator-1.0.0-beta.jar \u4f7f\u7528\u6d41\u7a0b \u00b6 \u57fa\u672c\u6d41\u7a0b\u5206\u4e3a\u4ee5\u4e0b\u51e0\u6b65\uff1a \u5728 Nebula Graph \u4e2d\u521b\u5efa\u56fe\u6a21\u578b\uff0c\u6784\u56fe \u7f16\u5199\u6570\u636e\u6587\u4ef6 \u7f16\u5199\u8f93\u5165\u6e90\u6620\u5c04\u6587\u4ef6 \u5bfc\u5165\u6570\u636e \u6784\u56fe \u00b6 \u6784\u56fe\u8bf7\u53c2\u8003 \u5feb\u901f\u8bd5\u7528 \u4e2d\u7684\u793a\u4f8b\u6784\u56fe\u3002 \u6ce8\u610f\uff1a\u8bf7\u5148\u5728 Nebula Graph \u4e2d\u5b8c\u6210\u6784\u56fe\uff08\u521b\u5efa\u56fe\u7a7a\u95f4\u548c\u5b9a\u4e49\u56fe\u6570\u636e Schema\uff09\uff0c\u518d\u901a\u8fc7\u672c\u5de5\u5177\u5411 Nebula Graph \u4e2d\u5199\u5165\u6570\u636e\u3002 \u6570\u636e\u793a\u4f8b \u00b6 \u70b9 \u00b6 \u9876\u70b9\u6570\u636e\u6587\u4ef6\u7531\u4e00\u884c\u4e00\u884c\u7684\u6570\u636e\u7ec4\u6210\uff0c\u6587\u4ef6\u4e2d\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u4e2a\u70b9\u548c\u5b83\u7684\u5c5e\u6027\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u7b2c\u4e00\u5217\u4e3a\u70b9\u7684 ID \u2014\u2014\u6b64\u5217\u7684\u540d\u79f0\u5c06\u5728\u540e\u6587\u7684\u6620\u5c04\u6587\u4ef6\u4e2d\u6307\u5b9a\uff0c\u5176\u4ed6\u5217\u4e3a\u70b9\u7684\u5c5e\u6027\u3002 player \u9876\u70b9\u6570\u636e {\"id\":100,\"name\":\"Tim Duncan\",\"age\":42} {\"id\":101,\"name\":\"Tony Parker\",\"age\":36} {\"id\":102,\"name\":\"LaMarcus Aldridge\",\"age\":33} \u8fb9 \u00b6 \u8fb9\u6570\u636e\u6587\u4ef6\u7531\u4e00\u884c\u4e00\u884c\u7684\u6570\u636e\u7ec4\u6210\uff0c\u6587\u4ef6\u4e2d\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u6761\u8fb9\u548c\u5b83\u7684\u5c5e\u6027\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u7b2c\u4e00\u5217\u4e3a\u8d77\u70b9 ID\uff0c\u7b2c\u4e8c\u5217\u4e3a\u7ec8\u70b9 ID\uff0c\u8d77\u70b9 ID \u5217\u53ca\u7ec8\u70b9 ID \u5217\u4f1a\u5728\u6620\u5c04\u6587\u4ef6\u4e2d\u6307\u5b9a\u3002\u5176\u4ed6\u5217\u4e3a\u8fb9\u5c5e\u6027\u3002\u4e0b\u9762\u4ee5 JSON \u683c\u5f0f\u4e3a\u4f8b\u8fdb\u884c\u8bf4\u660e\u3002 \u4ee5\u8fb9 \u8fb9 follow \u7684\u6570\u636e\u4e3a\u4f8b\uff1a \u65e0 rank \u7684\u8fb9 {\"source\":100,\"target\":101,\"likeness\":95} {\"source\":101,\"target\":100,\"likeness\":95} {\"source\":101,\"target\":102,\"likeness\":90} \u6709 rank \u7684\u8fb9 {\"source\":100,\"target\":101,\"likeness\":95,\"ranking\":2} {\"source\":101,\"target\":100,\"likeness\":95,\"ranking\":1} {\"source\":101,\"target\":102,\"likeness\":90,\"ranking\":3} \u542b\u6709\u5730\u7406\u4f4d\u7f6e Geo \u7684\u6570\u636e \u00b6 Spark Writer \u652f\u6301 Geo \u6570\u636e\u5bfc\u5165\uff0cGeo \u6570\u636e\u7528 latitude \u4e0e longitude \u5b57\u6bb5\u63cf\u8ff0\u7ecf\u7eac\u5ea6\uff0c\u6570\u636e\u7c7b\u578b\u4e3a double\u3002 {\"latitude\":30.2822095,\"longitude\":120.0298785,\"target\":0,\"dp_poi_name\":\"0\"} {\"latitude\":30.2813834,\"longitude\":120.0208692,\"target\":1,\"dp_poi_name\":\"1\"} {\"latitude\":30.2807347,\"longitude\":120.0181162,\"target\":2,\"dp_poi_name\":\"2\"} {\"latitude\":30.2812694,\"longitude\":120.0164896,\"target\":3,\"dp_poi_name\":\"3\"} \u6570\u636e\u6e90\u6587\u4ef6 \u00b6 \u76ee\u524d Spark Writer \u652f\u6301\u7684\u6570\u636e\u6e90\u6709\uff1a HDFS HIVE HDFS \u6587\u4ef6 \u00b6 \u652f\u6301\u7684\u6587\u4ef6\u683c\u5f0f\u5305\u62ec\uff1a Parquet JSON CSV ORC Player \u7684 Parquet \u793a\u4f8b\u5982\u4e0b\uff1a +---+---+------------+ |age| id| name| +---+---+------------+ | 42|100| Tim Duncan | | 36|101| Tony Parker| +---+---+------------+ JSON \u793a\u4f8b\u5982\u4e0b\uff1a { \"id\" : 100 , \"name\" : \"Tim Duncan\" , \"age\" : 42 } { \"id\" : 101 , \"name\" : \"Tony Parker\" , \"age\" : 36 } CSV \u793a\u4f8b\u5982\u4e0b\uff1a age,id,name 42,100,Tim Duncan 36,101,Tony Parker \u6570\u636e\u5e93 \u00b6 Spark Writer \u652f\u6301\u4ee5\u6570\u636e\u5e93\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u76ee\u524d\u652f\u6301 HIVE\u3002 Player \u8868\u7ed3\u6784\u5982\u4e0b\uff1a col_name data_type comment id int name string age int \u7f16\u5199\u914d\u7f6e\u6587\u4ef6 \u00b6 \u914d\u7f6e\u6587\u4ef6\u7531 Spark \u76f8\u5173\u4fe1\u606f\uff0cNebula \u76f8\u5173\u4fe1\u606f\uff0c\u4ee5\u53ca tags \u6620\u5c04 \u548c edges \u6620\u5c04\u5757\u7ec4\u6210\u3002Spark \u4fe1\u606f\u914d\u7f6e\u4e86 Spark \u8fd0\u884c\u7684\u76f8\u5173\u53c2\u6570\uff0cNebula \u76f8\u5173\u4fe1\u606f\u914d\u7f6e\u4e86\u8fde\u63a5 Nebula Graph \u7684\u7528\u6237\u540d\u548c\u5bc6\u7801\u7b49\u4fe1\u606f\u3002 tags \u6620\u5c04\u548c edges \u6620\u5c04\u5206\u522b\u5bf9\u5e94\u591a\u4e2a tag/edge \u7684\u8f93\u5165\u6e90\u6620\u5c04\uff0c\u63cf\u8ff0\u6bcf\u4e2a tag/edge \u7684\u6570\u636e\u6e90\u7b49\u57fa\u672c\u4fe1\u606f\uff0c\u4e0d\u540c tag/edge \u53ef\u4ee5\u6765\u81ea\u4e0d\u540c\u6570\u636e\u6e90\u3002 \u8f93\u5165\u6e90\u7684\u6620\u5c04\u6587\u4ef6\u793a\u4f8b\uff1a { # Spark \u76f8\u5173\u4fe1\u606f\u914d\u7f6e # \u53c2\u89c1\uff1a http://spark.apache.org/docs/latest/configuration.html spark: { app: { name: Spark Writer } driver: { cores: 1 maxResultSize: 1G } cores { max: 16 } } # Nebula Graph \u76f8\u5173\u4fe1\u606f\u914d\u7f6e nebula: { # \u67e5\u8be2\u5f15\u64ce IP \u5217\u8868 addresses: [\"127.0.0.1:3699\"] # \u8fde\u63a5 Nebula Graph \u670d\u52a1\u7684\u7528\u6237\u540d\u548c\u5bc6\u7801 user: user pswd: password # Nebula Graph \u56fe\u7a7a\u95f4\u540d\u79f0 space: test # thrift \u8d85\u65f6\u65f6\u957f\u53ca\u91cd\u8bd5\u6b21\u6570 # \u5982\u672a\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u503c\u5206\u522b\u4e3a 3000 \u548c 3 connection { timeout: 3000 retry: 3 } # nGQL \u67e5\u8be2\u91cd\u8bd5\u6b21\u6570 # \u5982\u672a\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u503c\u4e3a 3 execution { retry: 3 } } # \u5904\u7406\u6807\u7b7e tags: [ # \u4ece HDFS \u6587\u4ef6\u52a0\u8f7d\u6570\u636e\uff0c \u6b64\u5904\u6570\u636e\u7c7b\u578b\u4e3a Parquet # tag \u540d\u79f0\u4e3a tag name 0 # HDFS Parquet \u6587\u4ef6\u7684\u4e2d\u7684 field_0\u3001field_1\u3001field_2 \u5c06\u5199\u5165 tag_name_0 # \u8282\u70b9\u5217\u4e3a vertex_key_field { name: tag_name_0 type: parquet path: hdfs path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } vertex: vertex_key_field batch : 16 } # \u4e0e\u4e0a\u8ff0\u7c7b\u4f3c # \u4ece Hive \u52a0\u8f7d\u5c06\u6267\u884c\u547d\u4ee4 $ {exec} \u4f5c\u4e3a\u6570\u636e\u96c6 { name: tag_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } vertex: vertex_id_field } ] # \u5904\u7406\u8fb9 edges: [ # \u4ece HDFS \u52a0\u8f7d\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u4e3a JSON # \u8fb9\u540d\u79f0\u4e3a edge_name_0 # HDFS JSON \u6587\u4ef6\u4e2d\u7684 field_0\u3001field_1\u3001field 2 \u5c06\u88ab\u5199\u5165 edge_name_0 # \u8d77\u59cb\u5b57\u6bb5\u4e3a source_field\uff0c\u7ec8\u6b62\u5b57\u6bb5\u4e3a target_field \uff0c\u8fb9\u6743\u91cd\u5b57\u6bb5\u4e3a ranking_field\u3002 { name: edge_name_0 type: json path: hdfs_path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } source: source_field target: target_field ranking: ranking_field } # \u4ece Hive \u52a0\u8f7d\u5c06\u6267\u884c\u547d\u4ee4 $ {exec} \u4f5c\u4e3a\u6570\u636e\u96c6 # \u8fb9\u6743\u91cd\u4e3a\u53ef\u9009 { name: edge_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } source: source_id_field target: target_id_field } ] } Spark \u914d\u7f6e\u4fe1\u606f \u00b6 \u4e0b\u8868\u7ed9\u51fa\u4e86\u4e00\u4e9b\u793a\u4f8b\uff0c\u6240\u6709\u53ef\u914d\u7f6e\u9879\u8bf7\u89c1 Spark Available Properties \u3002 \u5b57\u6bb5 \u9ed8\u8ba4\u503c \u662f\u5426\u5fc5\u987b \u8bf4\u660e spark.app.name Spark Writer \u5426 app \u540d\u79f0 spark.driver.cores 1 \u5426 \u9a71\u52a8\u7a0b\u5e8f\u8fdb\u7a0b\u7684\u6838\u6570\uff0c\u4ec5\u9002\u7528\u4e8e\u7fa4\u96c6\u6a21\u5f0f spark.driver.maxResultSize 1G \u5426 \u6bcf\u4e2a Spark \u64cd\u4f5c\uff08\u4f8b\u5982\u6536\u96c6\uff09\u4e2d\u6240\u6709\u5206\u533a\u7684\u5e8f\u5217\u5316\u7ed3\u679c\u7684\u4e0a\u9650\uff08\u4ee5\u5b57\u8282\u4e3a\u5355\u4f4d\uff09\u3002\u81f3\u5c11\u5e94\u4e3a 1M\uff0c\u5426\u5219\u5e94\u4e3a 0\uff08\u65e0\u9650\u5236\uff09 spark.cores.max (not set) \u5426 \u5f53\u4ee5\u201c\u7c97\u7c92\u5ea6\u201d\u5171\u4eab\u6a21\u5f0f\u5728\u72ec\u7acb\u90e8\u7f72\u7fa4\u96c6\u6216 Mesos \u7fa4\u96c6\u4e0a\u8fd0\u884c\u65f6\uff0c\u8de8\u7fa4\u96c6\uff08\u800c\u975e\u4ece\u6bcf\u53f0\u8ba1\u7b97\u673a\uff09\u8bf7\u6c42\u5e94\u7528\u7a0b\u5e8f\u7684\u6700\u5927 CPU \u6838\u6570\u3002\u5982\u679c\u672a\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u503c\u4e3a Spark \u7684\u72ec\u7acb\u96c6\u7fa4\u7ba1\u7406\u5668\u4e0a\u7684 spark.deploy.defaultCores \u6216 Mesos \u4e0a\u7684 infinite\uff08\u6240\u6709\u53ef\u7528\u7684\u5185\u6838\uff09 Nebula Graph \u914d\u7f6e\u4fe1\u606f \u00b6 \u5b57\u6bb5 \u9ed8\u8ba4\u503c \u662f\u5426\u5fc5\u987b \u8bf4\u660e nebula.addresses \u65e0 \u662f \u67e5\u8be2\u5f15\u64ce\u7684\u5730\u5740\u5217\u8868\uff0c\u9017\u53f7\u5206\u9694 nebula.user \u65e0 \u662f \u6570\u636e\u5e93\u7528\u6237\u540d\uff0c\u9ed8\u8ba4\u4e3a user nebula.pswd \u65e0 \u662f \u6570\u636e\u5e93\u7528\u6237\u540d\u5bf9\u5e94\u5bc6\u7801\uff0c\u9ed8\u8ba4 user \u5bc6\u7801\u4e3a password nebula.space \u65e0 \u662f \u5bfc\u5165\u6570\u636e\u5bf9\u5e94\u7684 space\uff0c\u672c\u4f8b\u4e2d\u4e3a test nebula.connection.timeout 3000 \u5426 Thrift \u8fde\u63a5\u8d85\u65f6\u65f6\u95f4 nebula.connection.retry 3 \u5426 Thrift \u8fde\u63a5\u91cd\u8bd5\u6b21\u6570 nebula.execution.retry 3 \u5426 nGQL \u8bed\u53e5\u6267\u884c\u91cd\u8bd5\u6b21\u6570 tags \u548c edges \u6620\u5c04\u4fe1\u606f \u00b6 tag \u548c edge \u6620\u5c04\u7684\u9009\u9879\u6bd4\u8f83\u7c7b\u4f3c\u3002\u4e0b\u9762\u5148\u4ecb\u7ecd\u76f8\u540c\u7684\u9009\u9879\uff0c\u518d\u5206\u522b\u4ecb\u7ecd tag \u6620\u5c04 \u548c edge \u6620\u5c04 \u7684\u7279\u6709\u9009\u9879\u3002 \u76f8\u540c\u7684\u9009\u9879 type \u6307\u5b9a\u4e0a\u6587\u4e2d\u63d0\u5230\u7684\u6570\u636e\u7c7b\u578b\uff0c\u76ee\u524d\u652f\u6301 \u201cParquet\u201d\u3001\"JSON\"\u3001\"ORC\" \u548c \u201cCSV\u201d\uff0c\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u9002\u7528\u4e8e HDFS \u6570\u636e\u6e90\uff0c\u6307\u5b9aHDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u7edd\u5bf9\u8def\u5f84\uff0ctype \u4e3a HDFS \u65f6\uff0c\u5fc5\u586b exec \u9002\u7528\u4e8e Hive \u6570\u636e\u6e90\uff0c \u5f53\u6267\u884c\u67e5\u8be2\u8bed\u53e5 type \u4e3a HIVE \u65f6\uff0c\u5fc5\u586b fields \u5c06\u8f93\u5165\u6e90\u5217\u7684\u5217\u540d\u6620\u5c04\u4e3a tag / edge \u7684\u5c5e\u6027\u540d\uff0c\u5fc5\u586b tag \u6620\u5c04\u7684\u7279\u6709\u9009\u9879 vertex \u6307\u5b9a\u67d0\u4e00\u5217\u4f5c\u4e3a\u70b9\u7684 ID \u5217\uff0c\u5fc5\u586b edge \u6620\u5c04\u7684\u7279\u6709\u9009\u9879 source \u6307\u5b9a\u8f93\u5165\u6e90\u67d0\u4e00\u5217\u4f5c\u4e3a \u6e90\u70b9 \u7684 ID \u5217\uff0c\u5fc5\u586b target \u6307\u5b9a\u67d0\u4e00\u5217\u4f5c\u4e3a \u76ee\u6807\u70b9 \u7684 ID \u5217\uff0c\u5fc5\u586b \u5f53\u63d2\u5165\u8fb9\u6709 ranking \u503c\uff0c ranking \u6307\u5b9a\u67d0\u4e00\u5217\u4f5c\u4e3a\u8fb9 ranking \u5217\uff0c\u9009\u586b \u6570\u636e\u6e90\u6620\u5c04 \u00b6 HDFS Parquet \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a parquet \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HDFS JSON \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a JSON \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HIVE ORC \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a ORC\u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HIVE CSV \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a CSV \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HIVE type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a HIVE \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b exec \u6307\u5b9a HIVE \u6267\u884c\u67e5\u8be2\u7684\u8bed\u53e5\uff0c\u5fc5\u586b \u6267\u884c\u547d\u4ee4\u5bfc\u5165\u6570\u636e \u00b6 \u5bfc\u5165\u6570\u636e\u547d\u4ee4\uff1a bin/spark-submit \\ --class com.vesoft.nebula.tools.generator.v2.SparkClientGenerator \\ --master ${ MASTER -URL } \\ ${ SPARK_WRITER_JAR_PACKAGE } -c conf/test.conf -h -d \u53c2\u6570\u8bf4\u660e\uff1a Abbreviation Required Default Description \u793a\u4f8b --class yes \u6307\u5b9a\u7a0b\u5e8f\u4e3b\u7c7b --master yes \u6307\u5b9aspark cluster master url\uff0c\u8bf7\u53c2\u89c1 master-urls e.g. spark://23.195.26.187:7077 -c / --config yes \u4e0a\u6587\u6240\u7f16\u5199\u7684\u914d\u7f6e\u6587\u4ef6\u8def\u5f84 -h / --hive no false \u7528\u4e8e\u6307\u5b9a\u662f\u5426\u652f\u6301 Hive -d / --directly no false true \u4e3a\u5ba2\u6237\u7aef\u65b9\u5f0f\u63d2\u5165\uff1b false \u4e3a sst \u65b9\u5f0f\u5bfc\u5165 (TODO) -D / --dry no false \u68c0\u67e5\u914d\u7f6e\u6587\u4ef6\u662f\u5426\u6b63\u786e \u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c \u00b6 \u4e09\u53f0\u7269\u7406\u673a (56 \u6838\uff0c250G \u5185\u5b58\uff0c\u4e07\u5146\u7f51\uff0cSSD\uff09\uff0c\u5199 1 \u4ebf\u6761\u6570\u636e\uff08\u6bcf\u6761\u6570\u636e\u4e09\u4e2a\u5b57\u6bb5\uff0c\u6bcf\u4e2a batch 64 \u6761\u8bb0\u5f55\uff09\uff0c\u7528\u65f6 4 \u5206\u949f\uff0840\u4e07\u6761/\u79d2\uff09\u3002","title":"Spark Writer"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#spark_writer","text":"","title":"Spark Writer"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_1","text":"Spark Writer \u662f Nebula Graph \u57fa\u4e8e Spark \u7684\u5206\u5e03\u5f0f\u6570\u636e\u5bfc\u5165\u5de5\u5177\uff0c\u80fd\u591f\u5c06\u591a\u79cd\u6570\u636e\u4ed3\u5e93\u4e2d\u7684\u6570\u636e\u8f6c\u5316\u4e3a\u56fe\u7684\u70b9\u548c\u8fb9\uff0c\u5e76\u6279\u91cf\u5bfc\u5165\u5230\u56fe\u6570\u636e\u5e93\u4e2d\u3002\u76ee\u524d\u652f\u6301\u7684\u6570\u636e\u4ed3\u5e93\u6709\uff1a HDFS\uff0c\u5305\u62ec Parquet\u3001JSON\u3001ORC \u548c CSV \u683c\u5f0f\u7684\u6587\u4ef6 HIVE Spark Writer \u652f\u6301\u5e76\u53d1\u5bfc\u5165\u591a\u4e2a tag\u3001edge\uff0c\u652f\u6301\u4e0d\u540c tag/edge \u914d\u7f6e\u4e0d\u540c\u7684\u6570\u636e\u4ed3\u5e93\u3002","title":"\u6982\u8ff0"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_2","text":"\u6ce8\u610f\uff1a \u4e3a\u786e\u4fdd Nebula Graph Spark Writer \u6b63\u5e38\u4f7f\u7528\uff0c\u8bf7\u786e\u4fdd\u4f60\u7684\u673a\u5668\u5df2\u5b89\u88c5\uff1a Spark 2.0 \u53ca\u4ee5\u4e0a\u7248\u672c Hive 2.3 \u53ca\u4ee5\u4e0a\u7248\u672c Hadoop 2.0 \u53ca\u4ee5\u4e0a\u7248\u672c","title":"\u8f6f\u4ef6\u8981\u6c42"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#spark_writer_1","text":"","title":"\u83b7\u53d6 Spark Writer"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_3","text":"git clone https://github.com/vesoft-inc/nebula.git cd nebula/src/tools/spark-sstfile-generator mvn compile package \u6216\u8005\u76f4\u63a5\u4e0b\u8f7d","title":"\u7f16\u8bd1\u6e90\u7801"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#oss","text":"wget https://nebula-graph.oss-accelerate.aliyuncs.com/jar-packages/sst.generator-1.0.0-beta.jar","title":"\u4ece\u4e91\u5b58\u50a8 OSS \u4e0b\u8f7d"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_4","text":"\u57fa\u672c\u6d41\u7a0b\u5206\u4e3a\u4ee5\u4e0b\u51e0\u6b65\uff1a \u5728 Nebula Graph \u4e2d\u521b\u5efa\u56fe\u6a21\u578b\uff0c\u6784\u56fe \u7f16\u5199\u6570\u636e\u6587\u4ef6 \u7f16\u5199\u8f93\u5165\u6e90\u6620\u5c04\u6587\u4ef6 \u5bfc\u5165\u6570\u636e","title":"\u4f7f\u7528\u6d41\u7a0b"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_5","text":"\u6784\u56fe\u8bf7\u53c2\u8003 \u5feb\u901f\u8bd5\u7528 \u4e2d\u7684\u793a\u4f8b\u6784\u56fe\u3002 \u6ce8\u610f\uff1a\u8bf7\u5148\u5728 Nebula Graph \u4e2d\u5b8c\u6210\u6784\u56fe\uff08\u521b\u5efa\u56fe\u7a7a\u95f4\u548c\u5b9a\u4e49\u56fe\u6570\u636e Schema\uff09\uff0c\u518d\u901a\u8fc7\u672c\u5de5\u5177\u5411 Nebula Graph \u4e2d\u5199\u5165\u6570\u636e\u3002","title":"\u6784\u56fe"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_6","text":"","title":"\u6570\u636e\u793a\u4f8b"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_7","text":"\u9876\u70b9\u6570\u636e\u6587\u4ef6\u7531\u4e00\u884c\u4e00\u884c\u7684\u6570\u636e\u7ec4\u6210\uff0c\u6587\u4ef6\u4e2d\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u4e2a\u70b9\u548c\u5b83\u7684\u5c5e\u6027\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u7b2c\u4e00\u5217\u4e3a\u70b9\u7684 ID \u2014\u2014\u6b64\u5217\u7684\u540d\u79f0\u5c06\u5728\u540e\u6587\u7684\u6620\u5c04\u6587\u4ef6\u4e2d\u6307\u5b9a\uff0c\u5176\u4ed6\u5217\u4e3a\u70b9\u7684\u5c5e\u6027\u3002 player \u9876\u70b9\u6570\u636e {\"id\":100,\"name\":\"Tim Duncan\",\"age\":42} {\"id\":101,\"name\":\"Tony Parker\",\"age\":36} {\"id\":102,\"name\":\"LaMarcus Aldridge\",\"age\":33}","title":"\u70b9"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_8","text":"\u8fb9\u6570\u636e\u6587\u4ef6\u7531\u4e00\u884c\u4e00\u884c\u7684\u6570\u636e\u7ec4\u6210\uff0c\u6587\u4ef6\u4e2d\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u6761\u8fb9\u548c\u5b83\u7684\u5c5e\u6027\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u7b2c\u4e00\u5217\u4e3a\u8d77\u70b9 ID\uff0c\u7b2c\u4e8c\u5217\u4e3a\u7ec8\u70b9 ID\uff0c\u8d77\u70b9 ID \u5217\u53ca\u7ec8\u70b9 ID \u5217\u4f1a\u5728\u6620\u5c04\u6587\u4ef6\u4e2d\u6307\u5b9a\u3002\u5176\u4ed6\u5217\u4e3a\u8fb9\u5c5e\u6027\u3002\u4e0b\u9762\u4ee5 JSON \u683c\u5f0f\u4e3a\u4f8b\u8fdb\u884c\u8bf4\u660e\u3002 \u4ee5\u8fb9 \u8fb9 follow \u7684\u6570\u636e\u4e3a\u4f8b\uff1a \u65e0 rank \u7684\u8fb9 {\"source\":100,\"target\":101,\"likeness\":95} {\"source\":101,\"target\":100,\"likeness\":95} {\"source\":101,\"target\":102,\"likeness\":90} \u6709 rank \u7684\u8fb9 {\"source\":100,\"target\":101,\"likeness\":95,\"ranking\":2} {\"source\":101,\"target\":100,\"likeness\":95,\"ranking\":1} {\"source\":101,\"target\":102,\"likeness\":90,\"ranking\":3}","title":"\u8fb9"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#geo","text":"Spark Writer \u652f\u6301 Geo \u6570\u636e\u5bfc\u5165\uff0cGeo \u6570\u636e\u7528 latitude \u4e0e longitude \u5b57\u6bb5\u63cf\u8ff0\u7ecf\u7eac\u5ea6\uff0c\u6570\u636e\u7c7b\u578b\u4e3a double\u3002 {\"latitude\":30.2822095,\"longitude\":120.0298785,\"target\":0,\"dp_poi_name\":\"0\"} {\"latitude\":30.2813834,\"longitude\":120.0208692,\"target\":1,\"dp_poi_name\":\"1\"} {\"latitude\":30.2807347,\"longitude\":120.0181162,\"target\":2,\"dp_poi_name\":\"2\"} {\"latitude\":30.2812694,\"longitude\":120.0164896,\"target\":3,\"dp_poi_name\":\"3\"}","title":"\u542b\u6709\u5730\u7406\u4f4d\u7f6e Geo \u7684\u6570\u636e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_9","text":"\u76ee\u524d Spark Writer \u652f\u6301\u7684\u6570\u636e\u6e90\u6709\uff1a HDFS HIVE","title":"\u6570\u636e\u6e90\u6587\u4ef6"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#hdfs","text":"\u652f\u6301\u7684\u6587\u4ef6\u683c\u5f0f\u5305\u62ec\uff1a Parquet JSON CSV ORC Player \u7684 Parquet \u793a\u4f8b\u5982\u4e0b\uff1a +---+---+------------+ |age| id| name| +---+---+------------+ | 42|100| Tim Duncan | | 36|101| Tony Parker| +---+---+------------+ JSON \u793a\u4f8b\u5982\u4e0b\uff1a { \"id\" : 100 , \"name\" : \"Tim Duncan\" , \"age\" : 42 } { \"id\" : 101 , \"name\" : \"Tony Parker\" , \"age\" : 36 } CSV \u793a\u4f8b\u5982\u4e0b\uff1a age,id,name 42,100,Tim Duncan 36,101,Tony Parker","title":"HDFS \u6587\u4ef6"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_10","text":"Spark Writer \u652f\u6301\u4ee5\u6570\u636e\u5e93\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u76ee\u524d\u652f\u6301 HIVE\u3002 Player \u8868\u7ed3\u6784\u5982\u4e0b\uff1a col_name data_type comment id int name string age int","title":"\u6570\u636e\u5e93"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_11","text":"\u914d\u7f6e\u6587\u4ef6\u7531 Spark \u76f8\u5173\u4fe1\u606f\uff0cNebula \u76f8\u5173\u4fe1\u606f\uff0c\u4ee5\u53ca tags \u6620\u5c04 \u548c edges \u6620\u5c04\u5757\u7ec4\u6210\u3002Spark \u4fe1\u606f\u914d\u7f6e\u4e86 Spark \u8fd0\u884c\u7684\u76f8\u5173\u53c2\u6570\uff0cNebula \u76f8\u5173\u4fe1\u606f\u914d\u7f6e\u4e86\u8fde\u63a5 Nebula Graph \u7684\u7528\u6237\u540d\u548c\u5bc6\u7801\u7b49\u4fe1\u606f\u3002 tags \u6620\u5c04\u548c edges \u6620\u5c04\u5206\u522b\u5bf9\u5e94\u591a\u4e2a tag/edge \u7684\u8f93\u5165\u6e90\u6620\u5c04\uff0c\u63cf\u8ff0\u6bcf\u4e2a tag/edge \u7684\u6570\u636e\u6e90\u7b49\u57fa\u672c\u4fe1\u606f\uff0c\u4e0d\u540c tag/edge \u53ef\u4ee5\u6765\u81ea\u4e0d\u540c\u6570\u636e\u6e90\u3002 \u8f93\u5165\u6e90\u7684\u6620\u5c04\u6587\u4ef6\u793a\u4f8b\uff1a { # Spark \u76f8\u5173\u4fe1\u606f\u914d\u7f6e # \u53c2\u89c1\uff1a http://spark.apache.org/docs/latest/configuration.html spark: { app: { name: Spark Writer } driver: { cores: 1 maxResultSize: 1G } cores { max: 16 } } # Nebula Graph \u76f8\u5173\u4fe1\u606f\u914d\u7f6e nebula: { # \u67e5\u8be2\u5f15\u64ce IP \u5217\u8868 addresses: [\"127.0.0.1:3699\"] # \u8fde\u63a5 Nebula Graph \u670d\u52a1\u7684\u7528\u6237\u540d\u548c\u5bc6\u7801 user: user pswd: password # Nebula Graph \u56fe\u7a7a\u95f4\u540d\u79f0 space: test # thrift \u8d85\u65f6\u65f6\u957f\u53ca\u91cd\u8bd5\u6b21\u6570 # \u5982\u672a\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u503c\u5206\u522b\u4e3a 3000 \u548c 3 connection { timeout: 3000 retry: 3 } # nGQL \u67e5\u8be2\u91cd\u8bd5\u6b21\u6570 # \u5982\u672a\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u503c\u4e3a 3 execution { retry: 3 } } # \u5904\u7406\u6807\u7b7e tags: [ # \u4ece HDFS \u6587\u4ef6\u52a0\u8f7d\u6570\u636e\uff0c \u6b64\u5904\u6570\u636e\u7c7b\u578b\u4e3a Parquet # tag \u540d\u79f0\u4e3a tag name 0 # HDFS Parquet \u6587\u4ef6\u7684\u4e2d\u7684 field_0\u3001field_1\u3001field_2 \u5c06\u5199\u5165 tag_name_0 # \u8282\u70b9\u5217\u4e3a vertex_key_field { name: tag_name_0 type: parquet path: hdfs path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } vertex: vertex_key_field batch : 16 } # \u4e0e\u4e0a\u8ff0\u7c7b\u4f3c # \u4ece Hive \u52a0\u8f7d\u5c06\u6267\u884c\u547d\u4ee4 $ {exec} \u4f5c\u4e3a\u6570\u636e\u96c6 { name: tag_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } vertex: vertex_id_field } ] # \u5904\u7406\u8fb9 edges: [ # \u4ece HDFS \u52a0\u8f7d\u6570\u636e\uff0c\u6570\u636e\u7c7b\u578b\u4e3a JSON # \u8fb9\u540d\u79f0\u4e3a edge_name_0 # HDFS JSON \u6587\u4ef6\u4e2d\u7684 field_0\u3001field_1\u3001field 2 \u5c06\u88ab\u5199\u5165 edge_name_0 # \u8d77\u59cb\u5b57\u6bb5\u4e3a source_field\uff0c\u7ec8\u6b62\u5b57\u6bb5\u4e3a target_field \uff0c\u8fb9\u6743\u91cd\u5b57\u6bb5\u4e3a ranking_field\u3002 { name: edge_name_0 type: json path: hdfs_path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } source: source_field target: target_field ranking: ranking_field } # \u4ece Hive \u52a0\u8f7d\u5c06\u6267\u884c\u547d\u4ee4 $ {exec} \u4f5c\u4e3a\u6570\u636e\u96c6 # \u8fb9\u6743\u91cd\u4e3a\u53ef\u9009 { name: edge_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } source: source_id_field target: target_id_field } ] }","title":"\u7f16\u5199\u914d\u7f6e\u6587\u4ef6"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#spark","text":"\u4e0b\u8868\u7ed9\u51fa\u4e86\u4e00\u4e9b\u793a\u4f8b\uff0c\u6240\u6709\u53ef\u914d\u7f6e\u9879\u8bf7\u89c1 Spark Available Properties \u3002 \u5b57\u6bb5 \u9ed8\u8ba4\u503c \u662f\u5426\u5fc5\u987b \u8bf4\u660e spark.app.name Spark Writer \u5426 app \u540d\u79f0 spark.driver.cores 1 \u5426 \u9a71\u52a8\u7a0b\u5e8f\u8fdb\u7a0b\u7684\u6838\u6570\uff0c\u4ec5\u9002\u7528\u4e8e\u7fa4\u96c6\u6a21\u5f0f spark.driver.maxResultSize 1G \u5426 \u6bcf\u4e2a Spark \u64cd\u4f5c\uff08\u4f8b\u5982\u6536\u96c6\uff09\u4e2d\u6240\u6709\u5206\u533a\u7684\u5e8f\u5217\u5316\u7ed3\u679c\u7684\u4e0a\u9650\uff08\u4ee5\u5b57\u8282\u4e3a\u5355\u4f4d\uff09\u3002\u81f3\u5c11\u5e94\u4e3a 1M\uff0c\u5426\u5219\u5e94\u4e3a 0\uff08\u65e0\u9650\u5236\uff09 spark.cores.max (not set) \u5426 \u5f53\u4ee5\u201c\u7c97\u7c92\u5ea6\u201d\u5171\u4eab\u6a21\u5f0f\u5728\u72ec\u7acb\u90e8\u7f72\u7fa4\u96c6\u6216 Mesos \u7fa4\u96c6\u4e0a\u8fd0\u884c\u65f6\uff0c\u8de8\u7fa4\u96c6\uff08\u800c\u975e\u4ece\u6bcf\u53f0\u8ba1\u7b97\u673a\uff09\u8bf7\u6c42\u5e94\u7528\u7a0b\u5e8f\u7684\u6700\u5927 CPU \u6838\u6570\u3002\u5982\u679c\u672a\u8bbe\u7f6e\uff0c\u5219\u9ed8\u8ba4\u503c\u4e3a Spark \u7684\u72ec\u7acb\u96c6\u7fa4\u7ba1\u7406\u5668\u4e0a\u7684 spark.deploy.defaultCores \u6216 Mesos \u4e0a\u7684 infinite\uff08\u6240\u6709\u53ef\u7528\u7684\u5185\u6838\uff09","title":"Spark \u914d\u7f6e\u4fe1\u606f"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#nebula_graph","text":"\u5b57\u6bb5 \u9ed8\u8ba4\u503c \u662f\u5426\u5fc5\u987b \u8bf4\u660e nebula.addresses \u65e0 \u662f \u67e5\u8be2\u5f15\u64ce\u7684\u5730\u5740\u5217\u8868\uff0c\u9017\u53f7\u5206\u9694 nebula.user \u65e0 \u662f \u6570\u636e\u5e93\u7528\u6237\u540d\uff0c\u9ed8\u8ba4\u4e3a user nebula.pswd \u65e0 \u662f \u6570\u636e\u5e93\u7528\u6237\u540d\u5bf9\u5e94\u5bc6\u7801\uff0c\u9ed8\u8ba4 user \u5bc6\u7801\u4e3a password nebula.space \u65e0 \u662f \u5bfc\u5165\u6570\u636e\u5bf9\u5e94\u7684 space\uff0c\u672c\u4f8b\u4e2d\u4e3a test nebula.connection.timeout 3000 \u5426 Thrift \u8fde\u63a5\u8d85\u65f6\u65f6\u95f4 nebula.connection.retry 3 \u5426 Thrift \u8fde\u63a5\u91cd\u8bd5\u6b21\u6570 nebula.execution.retry 3 \u5426 nGQL \u8bed\u53e5\u6267\u884c\u91cd\u8bd5\u6b21\u6570","title":"Nebula Graph \u914d\u7f6e\u4fe1\u606f"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#tags_edges","text":"tag \u548c edge \u6620\u5c04\u7684\u9009\u9879\u6bd4\u8f83\u7c7b\u4f3c\u3002\u4e0b\u9762\u5148\u4ecb\u7ecd\u76f8\u540c\u7684\u9009\u9879\uff0c\u518d\u5206\u522b\u4ecb\u7ecd tag \u6620\u5c04 \u548c edge \u6620\u5c04 \u7684\u7279\u6709\u9009\u9879\u3002 \u76f8\u540c\u7684\u9009\u9879 type \u6307\u5b9a\u4e0a\u6587\u4e2d\u63d0\u5230\u7684\u6570\u636e\u7c7b\u578b\uff0c\u76ee\u524d\u652f\u6301 \u201cParquet\u201d\u3001\"JSON\"\u3001\"ORC\" \u548c \u201cCSV\u201d\uff0c\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u9002\u7528\u4e8e HDFS \u6570\u636e\u6e90\uff0c\u6307\u5b9aHDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u7edd\u5bf9\u8def\u5f84\uff0ctype \u4e3a HDFS \u65f6\uff0c\u5fc5\u586b exec \u9002\u7528\u4e8e Hive \u6570\u636e\u6e90\uff0c \u5f53\u6267\u884c\u67e5\u8be2\u8bed\u53e5 type \u4e3a HIVE \u65f6\uff0c\u5fc5\u586b fields \u5c06\u8f93\u5165\u6e90\u5217\u7684\u5217\u540d\u6620\u5c04\u4e3a tag / edge \u7684\u5c5e\u6027\u540d\uff0c\u5fc5\u586b tag \u6620\u5c04\u7684\u7279\u6709\u9009\u9879 vertex \u6307\u5b9a\u67d0\u4e00\u5217\u4f5c\u4e3a\u70b9\u7684 ID \u5217\uff0c\u5fc5\u586b edge \u6620\u5c04\u7684\u7279\u6709\u9009\u9879 source \u6307\u5b9a\u8f93\u5165\u6e90\u67d0\u4e00\u5217\u4f5c\u4e3a \u6e90\u70b9 \u7684 ID \u5217\uff0c\u5fc5\u586b target \u6307\u5b9a\u67d0\u4e00\u5217\u4f5c\u4e3a \u76ee\u6807\u70b9 \u7684 ID \u5217\uff0c\u5fc5\u586b \u5f53\u63d2\u5165\u8fb9\u6709 ranking \u503c\uff0c ranking \u6307\u5b9a\u67d0\u4e00\u5217\u4f5c\u4e3a\u8fb9 ranking \u5217\uff0c\u9009\u586b","title":"tags \u548c edges \u6620\u5c04\u4fe1\u606f"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_12","text":"HDFS Parquet \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a parquet \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HDFS JSON \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a JSON \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HIVE ORC \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a ORC\u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HIVE CSV \u6587\u4ef6 type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a CSV \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b path \u6307\u5b9a HDFS \u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\uff0c\u5fc5\u987b\u662f HDFS \u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u5fc5\u586b HIVE type \u6307\u5b9a\u8f93\u5165\u6e90\u7c7b\u578b\uff0c\u5f53\u4e3a HIVE \u65f6\u5927\u5c0f\u5199\u4e0d\u654f\u611f\uff0c\u5fc5\u586b exec \u6307\u5b9a HIVE \u6267\u884c\u67e5\u8be2\u7684\u8bed\u53e5\uff0c\u5fc5\u586b","title":"\u6570\u636e\u6e90\u6620\u5c04"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_13","text":"\u5bfc\u5165\u6570\u636e\u547d\u4ee4\uff1a bin/spark-submit \\ --class com.vesoft.nebula.tools.generator.v2.SparkClientGenerator \\ --master ${ MASTER -URL } \\ ${ SPARK_WRITER_JAR_PACKAGE } -c conf/test.conf -h -d \u53c2\u6570\u8bf4\u660e\uff1a Abbreviation Required Default Description \u793a\u4f8b --class yes \u6307\u5b9a\u7a0b\u5e8f\u4e3b\u7c7b --master yes \u6307\u5b9aspark cluster master url\uff0c\u8bf7\u53c2\u89c1 master-urls e.g. spark://23.195.26.187:7077 -c / --config yes \u4e0a\u6587\u6240\u7f16\u5199\u7684\u914d\u7f6e\u6587\u4ef6\u8def\u5f84 -h / --hive no false \u7528\u4e8e\u6307\u5b9a\u662f\u5426\u652f\u6301 Hive -d / --directly no false true \u4e3a\u5ba2\u6237\u7aef\u65b9\u5f0f\u63d2\u5165\uff1b false \u4e3a sst \u65b9\u5f0f\u5bfc\u5165 (TODO) -D / --dry no false \u68c0\u67e5\u914d\u7f6e\u6587\u4ef6\u662f\u5426\u6b63\u786e","title":"\u6267\u884c\u547d\u4ee4\u5bfc\u5165\u6570\u636e"},{"location":"manual-CN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#_14","text":"\u4e09\u53f0\u7269\u7406\u673a (56 \u6838\uff0c250G \u5185\u5b58\uff0c\u4e07\u5146\u7f51\uff0cSSD\uff09\uff0c\u5199 1 \u4ebf\u6761\u6570\u636e\uff08\u6bcf\u6761\u6570\u636e\u4e09\u4e2a\u5b57\u6bb5\uff0c\u6bcf\u4e2a batch 64 \u6761\u8bb0\u5f55\uff09\uff0c\u7528\u65f6 4 \u5206\u949f\uff0840\u4e07\u6761/\u79d2\uff09\u3002","title":"\u6027\u80fd\u6d4b\u8bd5\u7ed3\u679c"},{"location":"manual-CN/4.contributions/","text":"\u9762\u5411\u7684\u8bfb\u8005 \u00b6 \u672c\u7ae0\u4ecb\u7ecd\u5982\u4f55\u5411 Nebula Graph \u63d0\u4ea4\u6587\u6863\u548c\u4ee3\u7801\uff0c\u4e3b\u8981\u9762\u5bf9 Nebula Graph \u7684\u5f00\u53d1\u8005","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/4.contributions/#_1","text":"\u672c\u7ae0\u4ecb\u7ecd\u5982\u4f55\u5411 Nebula Graph \u63d0\u4ea4\u6587\u6863\u548c\u4ee3\u7801\uff0c\u4e3b\u8981\u9762\u5bf9 Nebula Graph \u7684\u5f00\u53d1\u8005","title":"\u9762\u5411\u7684\u8bfb\u8005"},{"location":"manual-CN/4.contributions/contribute-to-documentation/","text":"\u8d21\u732e\u6587\u6863 \u00b6 Nebula Graph \u6587\u6863\u5b8c\u5168\u5f00\u6e90\uff0c\u6b22\u8fce\u66f4\u591a\u8d21\u732e\u8005\u5e2e\u52a9\u6539\u8fdb\u6587\u6863\u3002 Nebula Graph \u6587\u6863\u4f7f\u7528 Markdown \u8bed\u8a00\uff0c\u5e76\u53c2\u8003\u4e86 Google \u5f00\u53d1\u8005\u6587\u6863\u98ce\u683c\u6307\u5357 \u8fdb\u884c\u7f16\u5199\u3002 \u5982\u4f55\u8d21\u732e \u00b6 \u8d21\u732e\u6587\u6863\u6709\u591a\u79cd\u65b9\u5f0f\uff1a \u5728 GitHub \u4e0a\u63d0 issue \u3002 Fork \u4ed3\u5e93\uff0c\u5728\u672c\u5730\u5206\u652f\u4e0a\u505a\u66f4\u6539\uff0c\u7136\u540e\u63d0\u4ea4 PR\u3002","title":"\u8d21\u732e\u6587\u6863"},{"location":"manual-CN/4.contributions/contribute-to-documentation/#_1","text":"Nebula Graph \u6587\u6863\u5b8c\u5168\u5f00\u6e90\uff0c\u6b22\u8fce\u66f4\u591a\u8d21\u732e\u8005\u5e2e\u52a9\u6539\u8fdb\u6587\u6863\u3002 Nebula Graph \u6587\u6863\u4f7f\u7528 Markdown \u8bed\u8a00\uff0c\u5e76\u53c2\u8003\u4e86 Google \u5f00\u53d1\u8005\u6587\u6863\u98ce\u683c\u6307\u5357 \u8fdb\u884c\u7f16\u5199\u3002","title":"\u8d21\u732e\u6587\u6863"},{"location":"manual-CN/4.contributions/contribute-to-documentation/#_2","text":"\u8d21\u732e\u6587\u6863\u6709\u591a\u79cd\u65b9\u5f0f\uff1a \u5728 GitHub \u4e0a\u63d0 issue \u3002 Fork \u4ed3\u5e93\uff0c\u5728\u672c\u5730\u5206\u652f\u4e0a\u505a\u66f4\u6539\uff0c\u7136\u540e\u63d0\u4ea4 PR\u3002","title":"\u5982\u4f55\u8d21\u732e"},{"location":"manual-CN/4.contributions/cpp-coding-style/","text":"C++ \u7f16\u7801\u98ce\u683c \u00b6 \u8bf7\u53c2\u8003 Google C++ Style Guide \u3002","title":"C++ \u7f16\u7801\u98ce\u683c"},{"location":"manual-CN/4.contributions/cpp-coding-style/#c","text":"\u8bf7\u53c2\u8003 Google C++ Style Guide \u3002","title":"C++ \u7f16\u7801\u98ce\u683c"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/","text":"\u6587\u6863\u98ce\u683c\u6307\u5357 \u00b6 \u76ee\u7684 \u672c\u6307\u5357\u65e8\u5728\u6307\u5bfc\u5f00\u53d1\u4eba\u5458\u7f16\u5199\u6587\u6863\u3002 \u76ee\u6807 \u00b6 \u672c\u6307\u5357\u53ef\u5e2e\u52a9\u5f00\u53d1\u4eba\u5458\u7edf\u4e00\u6587\u6863\u98ce\u683c\uff0c\u5e76\u63d0\u4f9b\u6587\u6863\u7f16\u5199\u5e2e\u52a9\u3002 \u975e\u76ee\u6807 \u00b6 \u672c\u6307\u5357\u4e0d\u662f\u884c\u4e1a\u6807\u51c6\uff0c\u53ea\u4e3a\u65b9\u4fbf\u6587\u6863\u683c\u5f0f\u7edf\u4e00\u800c\u7528\uff0c\u6ca1\u6709\u7edd\u5bf9\u7684\u5bf9\u9519\u3002 \u672c\u6307\u5357\u4e5f\u5c06\u6301\u7eed\u66f4\u65b0\uff0c\u66f4\u65b0\u540e\u4e4b\u524d\u7684\u6587\u6863\u4e0d\u4f1a\u968f\u4e4b\u66f4\u65b0\u3002\u6211\u4eec\u4f1a\u52aa\u529b\u7ef4\u62a4\u6587\u6863\u98ce\u683c\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u662f\u90e8\u5206\u6587\u6863\u53ef\u80fd\u4e0e\u672c\u6307\u5357\u98ce\u683c\u4e0d\u7b26\u3002\u5982\u6709\u7591\u95ee\uff0c\u8bf7\u4ee5\u672c\u6307\u5357\u4e3a\u51c6\u3002 \u6253\u7834\u5e38\u89c4 \u00b6 Nebula Graph \u4e0d\u4f1a\u5728\u4efb\u4f55\u65f6\u5019\u5f3a\u52a0\u4e0d\u9002\u7528\u884c\u6587\u8bed\u5883\u7684\u6587\u6863\u683c\u5f0f\u3002\u4f46\u662f\u6211\u4eec\u5e0c\u671b\u4fdd\u8bc1\u6587\u6863\u7684\u9ad8\u8d28\u91cf\u3002\u672c\u6307\u5357\u65e8\u5728\u63d0\u9ad8\u6587\u6863\u8d28\u91cf\uff0c\u4fdd\u8bc1\u884c\u6587\u98ce\u683c\u4e00\u81f4\uff0c\u56e0\u6b64\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6709\u5fc5\u8981\u4e0e\u6211\u4eec\u7684\u6307\u5bfc\u539f\u5219\u6709\u6240\u4e0d\u540c\uff0c\u4ee5\u4f7f\u60a8\u7684\u6587\u6863\u66f4\u597d\u3002 \u884c\u6587\u98ce\u683c\u53ca\u8bed\u6c14 \u00b6 \u5728\u6587\u6863\u4e2d\uff0c\u529b\u6c42\u5bf9\u8bdd\u6027\uff0c\u53cb\u597d\u548c\u53d7\u4eba\u5c0a\u656c\u7684\u8bed\u6c14\uff0c\u800c\u4e0d\u8981\u8fc7\u4e8e\u53e3\u8bed\u5316\u6216\u8f7b\u6d6e\uff1b\u5e94\u968f\u610f\uff0c\u81ea\u7136\uff0c\u5e73\u6613\u8fd1\u4eba\uff0c\u800c\u4e0d\u662f\u547d\u4ee4\u6216\u6025\u8e81\u3002\u5e94\u4f7f\u6587\u6863\u8bfb\u8d77\u6765\u50cf\u4e0e\u4e00\u4e2a\u535a\u5b66\u591a\u624d\u7684\u670b\u53cb\u8c08\u8bdd\uff0c\u786e\u4fdd\u6587\u6863\u5145\u5206\u7406\u89e3\u5f00\u53d1\u4eba\u5458\u7684\u60f3\u6cd5\u3002 \u9700\u8981\u8003\u8651\u7684\u8981\u70b9 \u00b6 \u5982\u679c\u60a8\u5728\u8868\u8fbe\u67d0\u4e9b\u5185\u5bb9\u65f6\u9047\u5230\u9ebb\u70e6\uff0c\u8bf7\u9000\u540e\u4e00\u6b65\u95ee\u81ea\u5df1\uff1a\u201c\u6211\u60f3\u8bf4\u4ec0\u4e48\uff1f\u201d\u901a\u5e38\uff0c\u60a8\u7ed9\u81ea\u5df1\u7684\u7b54\u6848\u63ed\u793a\u4e86\u60a8\u5728\u6587\u6863\u4e2d\u60f3\u8868\u8fbe\u7684\u610f\u601d\u3002 \u5982\u679c\u4e0d\u786e\u5b9a\u8868\u8ff0\u7528\u8bcd\uff0c\u8bf7\u627e\u540c\u4e8b\u5bfb\u6c42\u5e2e\u52a9\u3002 \u5927\u58f0\u6717\u8bfb\u6216\u4ed4\u7ec6\u9605\u8bfb\u6587\u6863\u7684\u67d0\u4e9b\u90e8\u5206\uff0c\u786e\u8ba4\u53e5\u5b50\u662f\u5426\u81ea\u7136\u3002\u6bcf\u4e2a\u53e5\u5b50\u7684\u53d1\u97f3\u90fd\u542c\u8d77\u6765\u5f88\u81ea\u7136\u3002\u5e76\u4e0d\u662f\u6240\u6709\u53e5\u5b50\u90fd\u8981\u81ea\u7136\uff0c\u6bd5\u7adf\u8fd9\u4e9b\u662f\u4e66\u9762\u6587\u4ef6\u3002\u4f46\u662f\uff0c\u5982\u679c\u53e5\u5b50\u5f88\u5c34\u5c2c\u6216\u4ee4\u4eba\u56f0\u60d1\uff0c\u8bf7\u91cd\u65b0\u7ec4\u7ec7\u8bed\u8a00\u3002 \u5728\u53e5\u5b50\u4e4b\u95f4\u4f7f\u7528\u8fc7\u6e21\u3002 \u5373\u4f7f\u5728\u6587\u6863\u884c\u6587\u98ce\u683c\u4e0a\u9047\u5230\u95ee\u9898\uff0c\u4e5f\u8bf7\u786e\u4fdd\u6587\u6863\u660e\u786e\u6e05\u6670\u5730\u4f20\u8fbe\u4e86\u6709\u6548\u4fe1\u606f\uff0c\u8fd9\u662f\u91cd\u4e2d\u4e4b\u91cd\u3002 \u65f6\u6001 \u00b6 \u901a\u5e38\uff0c\u4f7f\u7528\u73b0\u5728\u65f6\u800c\u4e0d\u662f\u5c06\u6765\u65f6\u3002 \u8bfb\u8005\u5c06\u6765\u4f1a\u7f16\u5199\u548c\u8fd0\u884c\u4ee3\u7801\u5e76\u4e0d\u662f\u4f7f\u7528\u5c06\u6765\u65f6\u6001\u7684\u5145\u5206\u7406\u7531\u3002\u8bf7\u575a\u6301\u73b0\u5728\u65f6\u3002 \u94fe\u63a5 \u00b6 \u5728\u7f16\u5199\u94fe\u63a5\u6587\u672c\u65f6\uff0c\u8bf7\u4f7f\u7528\u4e00\u4e2a\u77ed\u8bed\u63cf\u8ff0\u8bfb\u8005\u5728\u70b9\u94fe\u63a5\u540e\u5c06\u770b\u5230\u7684\u5185\u5bb9\u3002\u53ef\u4ee5\u91c7\u7528\u4ee5\u4e0b\u4e24\u79cd\u5f62\u5f0f\u4e4b\u4e00\uff1a \u94fe\u63a5\u9875\u9762\u7684\u51c6\u786e\u6807\u9898\uff0c\u5927\u5199\u4e0e\u6807\u9898\u5927\u5199\u76f8\u540c\u3002 \u94fe\u63a5\u9875\u9762\u7684\u63cf\u8ff0\u3002 \u4e0d\u8981\u5728\u94fe\u63a5\u5185\u5305\u542b\uff1a \u201c\u70b9\u51fb\u6b64\u5904\u201d \u201c\u672c\u6587\u201d \u6587\u6863\u4e2d\u4e0d\u8981\u51fa\u73b0 URL \u94fe\u63a5\u6807\u70b9 \u00b6 \u5982\u679c\u5728\u94fe\u63a5\u4e4b\u524d\u6216\u4e4b\u540e\u6709\u6807\u70b9\u7b26\u53f7\uff0c\u8bf7\u5c3d\u53ef\u80fd\u5c06\u6807\u70b9\u7b26\u53f7\u653e\u5728\u94fe\u63a5\u6807\u7b7e\u4e4b\u5916\u3002\u7279\u522b\u662f\u5c06\u5f15\u53f7\u653e\u5728\u94fe\u63a5\u6807\u7b7e\u4e4b\u5916\u3002 \u6587\u6863\u5185\u5bb9 \u00b6 \u6ce8\u610f\u4e8b\u9879 \u00b6 \u786e\u4fdd\u8bfb\u8005\u4ec5\u4f7f\u7528\u952e\u76d8\u5373\u53ef\u4f7f\u7528\u6587\u6863\uff0c\u800c\u65e0\u9700\u4f7f\u7528\u9f20\u6807\u6216\u89e6\u63a7\u677f\uff0c\u5373\u53ef\u9605\u8bfb\u6587\u6863\u7684\u6240\u6709\u90e8\u5206\uff08\u5305\u62ec\u9009\u9879\u5361\uff0c\u63d0\u4ea4\u8868\u5355\u7684\u6309\u94ae\u548c\u4ea4\u4e92\u5f0f\u5143\u7d20\uff09\u3002 \u4e0d\u8981\u5c06\u989c\u8272\uff0c\u5927\u5c0f\uff0c\u4f4d\u7f6e\u6216\u5176\u4ed6\u89c6\u89c9\u63d0\u793a\u7528\u4f5c\u4f20\u8fbe\u4fe1\u606f\u7684\u4e3b\u8981\u65b9\u5f0f\u3002 \u5982\u679c\u4e00\u5b9a\u8981\u4f7f\u7528\u989c\u8272\uff0c\u56fe\u6807\u6216\u8f6e\u5ed3\u7ebf\u7c97\u7ec6\u6765\u4f20\u8fbe\u72b6\u6001\uff0c\u8fd8\u5e94\u63d0\u4f9b\u8f85\u52a9\u63d0\u793a\uff0c\u4f8b\u5982\u66f4\u6539\u6587\u672c\u6807\u7b7e\u3002 \u8bf7\u4f7f\u7528\u6807\u7b7e\u5173\u8054\u6309\u94ae\u548c\u5176\u4ed6\u5143\u7d20\u7684\u6807\u7b7e\u800c\u975e\u4f4d\u7f6e\u6216\u5f62\u72b6\u3002 \u907f\u514d\u4f7f\u7528\u4e0d\u5fc5\u8981\u7684\u5b57\u4f53\u683c\u5f0f\u3002 \u5982\u679c\u662f\u4e3a\u5305\u542b\u7279\u6b8a\u529f\u80fd\u7684\u4ea7\u54c1\u5199\u6587\u6863\uff0c\u8bf7\u660e\u786e\u8bb0\u5f55\u8fd9\u4e9b\u529f\u80fd\u3002\u4f8b\u5982\uff0c\u201c gcloud\u201d \u547d\u4ee4\u884c\u5de5\u5177\u5305\u62ec\u53ef\u5207\u6362\u7684\u8f85\u52a9\u529f\u80fd\uff0c\u4f8b\u5982\u8fdb\u5ea6\u6761\u767e\u5206\u6bd4\u548c ASCII \u6846\u6e32\u67d3\u3002 \u56fe\u7247 \u00b6 \u8bf7\u4e3a\u56fe\u7247\u63d0\u4f9b\u6587\u5b57\u8bf4\u660e\u3002 \u4e0d\u8981\u5728\u56fe\u50cf\u4e2d\u663e\u793a\u65b0\u4fe1\u606f\uff1b\u59cb\u7ec8\u5728\u56fe\u50cf\u4e0a\u63d0\u4f9b\u7b49\u6548\u7684\u6587\u5b57\u8bf4\u660e\u3002 Use SVG files \u6216 PNG \u56fe\u7247\u3002 \u8bf7\u63d0\u4f9b\u9ad8\u50cf\u7d20\u56fe\u7247 Provide high-resolution images \u3002 \u8868\u683c \u00b6 \u5982\u679c\u8868\u683c\u540c\u65f6\u5305\u542b\u884c\u548c\u5217\u6807\u9898\uff0c\u4f7f\u7528\u4ee5\u4e0b\u6807\u51c6\u6807\u6ce8 scope \u3002 headers \u5c5e\u6027\u3002 \u5f62\u5f0f \u00b6 \u4f7f\u7528 <label> \u5143\u7d20\u6807\u8bb0\u6bcf\u4e2a\u8f93\u5165\u5b57\u6bb5\u3002 \u5c06\u6807\u8bb0\u653e\u5728\u5b57\u6bb5\u4e4b\u5916\u3002 \u5f53\u521b\u5efa\u7528\u4e8e\u8868\u5355\u9a8c\u8bc1\u7684\u9519\u8bef\u6d88\u606f\u65f6\uff0c\u8bf7\u660e\u786e\u8bf4\u660e\u51fa\u4e86\u4ec0\u4e48\u95ee\u9898\u4ee5\u53ca\u5982\u4f55\u89e3\u51b3\u3002\u4f8b\u5982\uff1a\u201c\u540d\u79f0\u662f\u5fc5\u586b\u5b57\u6bb5\u3002\u201d \u89c6\u9891 \u00b6 \u89c6\u9891\u9700\u6dfb\u52a0\u6587\u5b57\u8bf4\u660e\u3002 \u8bf7\u786e\u4fdd\u6587\u5b57\u8bf4\u660e\u53ef\u7ffb\u8bd1\u6210\u5176\u4ed6\u8bed\u8a00\u3002 \u8bed\u8a00\u53ca\u8bed\u6cd5 \u00b6 \u63a8\u8350\u4f7f\u7528\u7b2c\u4e8c\u4eba\u79f0 \u8bf7\u4f7f\u7528\u4e3b\u52a8\u8bed\u6001\u6e05\u6670\u8868\u8ff0\u52a8\u4f5c\u7684\u53d1\u8d77\u4eba\u3002\u8bf7\u4f7f\u7528\u6807\u51c6\u7684\u6807\u70b9\u7b26\u53f7\u3002 \u683c\u5f0f\u3001\u6807\u70b9\u7b26\u53f7\u53ca\u7ec4\u7ec7\u65b9\u5f0f \u00b6 \u6587\u6863\u53ca\u7ae0\u8282\u547d\u540d\u89c1 Use sentence case \u3002 \u6709\u5e8f\u5217\u8868\u89c1 Use numbered lists \u3002 \u5176\u4ed6\u5217\u8868\u89c1 Use bulleted lists \u3002 \u6570\u636e\u76f8\u5173\u89c1 Use description lists \u3002 \u6807\u70b9\u7b26\u53f7\u89c1 Use serial commas \u3002 Put code-related text in code font . Put UI elements in bold . Use unambiguous date formatting .","title":"\u6587\u6863\u98ce\u683c\u6307\u5357"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_1","text":"\u76ee\u7684 \u672c\u6307\u5357\u65e8\u5728\u6307\u5bfc\u5f00\u53d1\u4eba\u5458\u7f16\u5199\u6587\u6863\u3002","title":"\u6587\u6863\u98ce\u683c\u6307\u5357"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_2","text":"\u672c\u6307\u5357\u53ef\u5e2e\u52a9\u5f00\u53d1\u4eba\u5458\u7edf\u4e00\u6587\u6863\u98ce\u683c\uff0c\u5e76\u63d0\u4f9b\u6587\u6863\u7f16\u5199\u5e2e\u52a9\u3002","title":"\u76ee\u6807"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_3","text":"\u672c\u6307\u5357\u4e0d\u662f\u884c\u4e1a\u6807\u51c6\uff0c\u53ea\u4e3a\u65b9\u4fbf\u6587\u6863\u683c\u5f0f\u7edf\u4e00\u800c\u7528\uff0c\u6ca1\u6709\u7edd\u5bf9\u7684\u5bf9\u9519\u3002 \u672c\u6307\u5357\u4e5f\u5c06\u6301\u7eed\u66f4\u65b0\uff0c\u66f4\u65b0\u540e\u4e4b\u524d\u7684\u6587\u6863\u4e0d\u4f1a\u968f\u4e4b\u66f4\u65b0\u3002\u6211\u4eec\u4f1a\u52aa\u529b\u7ef4\u62a4\u6587\u6863\u98ce\u683c\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u662f\u90e8\u5206\u6587\u6863\u53ef\u80fd\u4e0e\u672c\u6307\u5357\u98ce\u683c\u4e0d\u7b26\u3002\u5982\u6709\u7591\u95ee\uff0c\u8bf7\u4ee5\u672c\u6307\u5357\u4e3a\u51c6\u3002","title":"\u975e\u76ee\u6807"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_4","text":"Nebula Graph \u4e0d\u4f1a\u5728\u4efb\u4f55\u65f6\u5019\u5f3a\u52a0\u4e0d\u9002\u7528\u884c\u6587\u8bed\u5883\u7684\u6587\u6863\u683c\u5f0f\u3002\u4f46\u662f\u6211\u4eec\u5e0c\u671b\u4fdd\u8bc1\u6587\u6863\u7684\u9ad8\u8d28\u91cf\u3002\u672c\u6307\u5357\u65e8\u5728\u63d0\u9ad8\u6587\u6863\u8d28\u91cf\uff0c\u4fdd\u8bc1\u884c\u6587\u98ce\u683c\u4e00\u81f4\uff0c\u56e0\u6b64\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6709\u5fc5\u8981\u4e0e\u6211\u4eec\u7684\u6307\u5bfc\u539f\u5219\u6709\u6240\u4e0d\u540c\uff0c\u4ee5\u4f7f\u60a8\u7684\u6587\u6863\u66f4\u597d\u3002","title":"\u6253\u7834\u5e38\u89c4"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_5","text":"\u5728\u6587\u6863\u4e2d\uff0c\u529b\u6c42\u5bf9\u8bdd\u6027\uff0c\u53cb\u597d\u548c\u53d7\u4eba\u5c0a\u656c\u7684\u8bed\u6c14\uff0c\u800c\u4e0d\u8981\u8fc7\u4e8e\u53e3\u8bed\u5316\u6216\u8f7b\u6d6e\uff1b\u5e94\u968f\u610f\uff0c\u81ea\u7136\uff0c\u5e73\u6613\u8fd1\u4eba\uff0c\u800c\u4e0d\u662f\u547d\u4ee4\u6216\u6025\u8e81\u3002\u5e94\u4f7f\u6587\u6863\u8bfb\u8d77\u6765\u50cf\u4e0e\u4e00\u4e2a\u535a\u5b66\u591a\u624d\u7684\u670b\u53cb\u8c08\u8bdd\uff0c\u786e\u4fdd\u6587\u6863\u5145\u5206\u7406\u89e3\u5f00\u53d1\u4eba\u5458\u7684\u60f3\u6cd5\u3002","title":"\u884c\u6587\u98ce\u683c\u53ca\u8bed\u6c14"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_6","text":"\u5982\u679c\u60a8\u5728\u8868\u8fbe\u67d0\u4e9b\u5185\u5bb9\u65f6\u9047\u5230\u9ebb\u70e6\uff0c\u8bf7\u9000\u540e\u4e00\u6b65\u95ee\u81ea\u5df1\uff1a\u201c\u6211\u60f3\u8bf4\u4ec0\u4e48\uff1f\u201d\u901a\u5e38\uff0c\u60a8\u7ed9\u81ea\u5df1\u7684\u7b54\u6848\u63ed\u793a\u4e86\u60a8\u5728\u6587\u6863\u4e2d\u60f3\u8868\u8fbe\u7684\u610f\u601d\u3002 \u5982\u679c\u4e0d\u786e\u5b9a\u8868\u8ff0\u7528\u8bcd\uff0c\u8bf7\u627e\u540c\u4e8b\u5bfb\u6c42\u5e2e\u52a9\u3002 \u5927\u58f0\u6717\u8bfb\u6216\u4ed4\u7ec6\u9605\u8bfb\u6587\u6863\u7684\u67d0\u4e9b\u90e8\u5206\uff0c\u786e\u8ba4\u53e5\u5b50\u662f\u5426\u81ea\u7136\u3002\u6bcf\u4e2a\u53e5\u5b50\u7684\u53d1\u97f3\u90fd\u542c\u8d77\u6765\u5f88\u81ea\u7136\u3002\u5e76\u4e0d\u662f\u6240\u6709\u53e5\u5b50\u90fd\u8981\u81ea\u7136\uff0c\u6bd5\u7adf\u8fd9\u4e9b\u662f\u4e66\u9762\u6587\u4ef6\u3002\u4f46\u662f\uff0c\u5982\u679c\u53e5\u5b50\u5f88\u5c34\u5c2c\u6216\u4ee4\u4eba\u56f0\u60d1\uff0c\u8bf7\u91cd\u65b0\u7ec4\u7ec7\u8bed\u8a00\u3002 \u5728\u53e5\u5b50\u4e4b\u95f4\u4f7f\u7528\u8fc7\u6e21\u3002 \u5373\u4f7f\u5728\u6587\u6863\u884c\u6587\u98ce\u683c\u4e0a\u9047\u5230\u95ee\u9898\uff0c\u4e5f\u8bf7\u786e\u4fdd\u6587\u6863\u660e\u786e\u6e05\u6670\u5730\u4f20\u8fbe\u4e86\u6709\u6548\u4fe1\u606f\uff0c\u8fd9\u662f\u91cd\u4e2d\u4e4b\u91cd\u3002","title":"\u9700\u8981\u8003\u8651\u7684\u8981\u70b9"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_7","text":"\u901a\u5e38\uff0c\u4f7f\u7528\u73b0\u5728\u65f6\u800c\u4e0d\u662f\u5c06\u6765\u65f6\u3002 \u8bfb\u8005\u5c06\u6765\u4f1a\u7f16\u5199\u548c\u8fd0\u884c\u4ee3\u7801\u5e76\u4e0d\u662f\u4f7f\u7528\u5c06\u6765\u65f6\u6001\u7684\u5145\u5206\u7406\u7531\u3002\u8bf7\u575a\u6301\u73b0\u5728\u65f6\u3002","title":"\u65f6\u6001"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_8","text":"\u5728\u7f16\u5199\u94fe\u63a5\u6587\u672c\u65f6\uff0c\u8bf7\u4f7f\u7528\u4e00\u4e2a\u77ed\u8bed\u63cf\u8ff0\u8bfb\u8005\u5728\u70b9\u94fe\u63a5\u540e\u5c06\u770b\u5230\u7684\u5185\u5bb9\u3002\u53ef\u4ee5\u91c7\u7528\u4ee5\u4e0b\u4e24\u79cd\u5f62\u5f0f\u4e4b\u4e00\uff1a \u94fe\u63a5\u9875\u9762\u7684\u51c6\u786e\u6807\u9898\uff0c\u5927\u5199\u4e0e\u6807\u9898\u5927\u5199\u76f8\u540c\u3002 \u94fe\u63a5\u9875\u9762\u7684\u63cf\u8ff0\u3002 \u4e0d\u8981\u5728\u94fe\u63a5\u5185\u5305\u542b\uff1a \u201c\u70b9\u51fb\u6b64\u5904\u201d \u201c\u672c\u6587\u201d \u6587\u6863\u4e2d\u4e0d\u8981\u51fa\u73b0 URL","title":"\u94fe\u63a5"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_9","text":"\u5982\u679c\u5728\u94fe\u63a5\u4e4b\u524d\u6216\u4e4b\u540e\u6709\u6807\u70b9\u7b26\u53f7\uff0c\u8bf7\u5c3d\u53ef\u80fd\u5c06\u6807\u70b9\u7b26\u53f7\u653e\u5728\u94fe\u63a5\u6807\u7b7e\u4e4b\u5916\u3002\u7279\u522b\u662f\u5c06\u5f15\u53f7\u653e\u5728\u94fe\u63a5\u6807\u7b7e\u4e4b\u5916\u3002","title":"\u94fe\u63a5\u6807\u70b9"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_10","text":"","title":"\u6587\u6863\u5185\u5bb9"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_11","text":"\u786e\u4fdd\u8bfb\u8005\u4ec5\u4f7f\u7528\u952e\u76d8\u5373\u53ef\u4f7f\u7528\u6587\u6863\uff0c\u800c\u65e0\u9700\u4f7f\u7528\u9f20\u6807\u6216\u89e6\u63a7\u677f\uff0c\u5373\u53ef\u9605\u8bfb\u6587\u6863\u7684\u6240\u6709\u90e8\u5206\uff08\u5305\u62ec\u9009\u9879\u5361\uff0c\u63d0\u4ea4\u8868\u5355\u7684\u6309\u94ae\u548c\u4ea4\u4e92\u5f0f\u5143\u7d20\uff09\u3002 \u4e0d\u8981\u5c06\u989c\u8272\uff0c\u5927\u5c0f\uff0c\u4f4d\u7f6e\u6216\u5176\u4ed6\u89c6\u89c9\u63d0\u793a\u7528\u4f5c\u4f20\u8fbe\u4fe1\u606f\u7684\u4e3b\u8981\u65b9\u5f0f\u3002 \u5982\u679c\u4e00\u5b9a\u8981\u4f7f\u7528\u989c\u8272\uff0c\u56fe\u6807\u6216\u8f6e\u5ed3\u7ebf\u7c97\u7ec6\u6765\u4f20\u8fbe\u72b6\u6001\uff0c\u8fd8\u5e94\u63d0\u4f9b\u8f85\u52a9\u63d0\u793a\uff0c\u4f8b\u5982\u66f4\u6539\u6587\u672c\u6807\u7b7e\u3002 \u8bf7\u4f7f\u7528\u6807\u7b7e\u5173\u8054\u6309\u94ae\u548c\u5176\u4ed6\u5143\u7d20\u7684\u6807\u7b7e\u800c\u975e\u4f4d\u7f6e\u6216\u5f62\u72b6\u3002 \u907f\u514d\u4f7f\u7528\u4e0d\u5fc5\u8981\u7684\u5b57\u4f53\u683c\u5f0f\u3002 \u5982\u679c\u662f\u4e3a\u5305\u542b\u7279\u6b8a\u529f\u80fd\u7684\u4ea7\u54c1\u5199\u6587\u6863\uff0c\u8bf7\u660e\u786e\u8bb0\u5f55\u8fd9\u4e9b\u529f\u80fd\u3002\u4f8b\u5982\uff0c\u201c gcloud\u201d \u547d\u4ee4\u884c\u5de5\u5177\u5305\u62ec\u53ef\u5207\u6362\u7684\u8f85\u52a9\u529f\u80fd\uff0c\u4f8b\u5982\u8fdb\u5ea6\u6761\u767e\u5206\u6bd4\u548c ASCII \u6846\u6e32\u67d3\u3002","title":"\u6ce8\u610f\u4e8b\u9879"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_12","text":"\u8bf7\u4e3a\u56fe\u7247\u63d0\u4f9b\u6587\u5b57\u8bf4\u660e\u3002 \u4e0d\u8981\u5728\u56fe\u50cf\u4e2d\u663e\u793a\u65b0\u4fe1\u606f\uff1b\u59cb\u7ec8\u5728\u56fe\u50cf\u4e0a\u63d0\u4f9b\u7b49\u6548\u7684\u6587\u5b57\u8bf4\u660e\u3002 Use SVG files \u6216 PNG \u56fe\u7247\u3002 \u8bf7\u63d0\u4f9b\u9ad8\u50cf\u7d20\u56fe\u7247 Provide high-resolution images \u3002","title":"\u56fe\u7247"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_13","text":"\u5982\u679c\u8868\u683c\u540c\u65f6\u5305\u542b\u884c\u548c\u5217\u6807\u9898\uff0c\u4f7f\u7528\u4ee5\u4e0b\u6807\u51c6\u6807\u6ce8 scope \u3002 headers \u5c5e\u6027\u3002","title":"\u8868\u683c"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_14","text":"\u4f7f\u7528 <label> \u5143\u7d20\u6807\u8bb0\u6bcf\u4e2a\u8f93\u5165\u5b57\u6bb5\u3002 \u5c06\u6807\u8bb0\u653e\u5728\u5b57\u6bb5\u4e4b\u5916\u3002 \u5f53\u521b\u5efa\u7528\u4e8e\u8868\u5355\u9a8c\u8bc1\u7684\u9519\u8bef\u6d88\u606f\u65f6\uff0c\u8bf7\u660e\u786e\u8bf4\u660e\u51fa\u4e86\u4ec0\u4e48\u95ee\u9898\u4ee5\u53ca\u5982\u4f55\u89e3\u51b3\u3002\u4f8b\u5982\uff1a\u201c\u540d\u79f0\u662f\u5fc5\u586b\u5b57\u6bb5\u3002\u201d","title":"\u5f62\u5f0f"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_15","text":"\u89c6\u9891\u9700\u6dfb\u52a0\u6587\u5b57\u8bf4\u660e\u3002 \u8bf7\u786e\u4fdd\u6587\u5b57\u8bf4\u660e\u53ef\u7ffb\u8bd1\u6210\u5176\u4ed6\u8bed\u8a00\u3002","title":"\u89c6\u9891"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_16","text":"\u63a8\u8350\u4f7f\u7528\u7b2c\u4e8c\u4eba\u79f0 \u8bf7\u4f7f\u7528\u4e3b\u52a8\u8bed\u6001\u6e05\u6670\u8868\u8ff0\u52a8\u4f5c\u7684\u53d1\u8d77\u4eba\u3002\u8bf7\u4f7f\u7528\u6807\u51c6\u7684\u6807\u70b9\u7b26\u53f7\u3002","title":"\u8bed\u8a00\u53ca\u8bed\u6cd5"},{"location":"manual-CN/4.contributions/developer-documentation-style-guide/#_17","text":"\u6587\u6863\u53ca\u7ae0\u8282\u547d\u540d\u89c1 Use sentence case \u3002 \u6709\u5e8f\u5217\u8868\u89c1 Use numbered lists \u3002 \u5176\u4ed6\u5217\u8868\u89c1 Use bulleted lists \u3002 \u6570\u636e\u76f8\u5173\u89c1 Use description lists \u3002 \u6807\u70b9\u7b26\u53f7\u89c1 Use serial commas \u3002 Put code-related text in code font . Put UI elements in bold . Use unambiguous date formatting .","title":"\u683c\u5f0f\u3001\u6807\u70b9\u7b26\u53f7\u53ca\u7ec4\u7ec7\u65b9\u5f0f"},{"location":"manual-CN/4.contributions/how-to-contribute/","text":"\u5982\u4f55\u63d0\u4ea4\u4ee3\u7801\u548c\u6587\u6863 \u00b6 Step 1: \u901a\u8fc7 GitHub Fork \u00b6 \u8bbf\u95ee https://github.com/vesoft-inc/nebula \u70b9\u51fb\u53f3\u4e0a\u89d2 Fork \u6309\u94ae\u521b\u5efa\u8fdc\u7a0b\u5206\u652f Step 2: \u5c06\u5206\u652f\u514b\u9686\u5230\u672c\u5730 \u00b6 \u5b9a\u4e49\u672c\u5730\u5de5\u4f5c\u76ee\u5f55\uff1a # \u5b9a\u4e49\u5de5\u4f5c\u76ee\u5f55 working_dir = $HOME /Workspace \u5c06 user \u8bbe\u7f6e\u4e3a GitHub \u8d26\u6237\u540d\uff1a user ={ GitHub\u8d26\u6237\u540d } clone \u4ee3\u7801\uff1a mkdir -p $working_dir cd $working_dir git clone https://github.com/ $user /nebula.git # \u63a8\u8350\u5982\u4e0b\u65b9\u5f0f # \u6216: git clone git@github.com:$user/nebula.git cd $working_dir /nebula git remote add upstream https://github.com/vesoft-inc/nebula.git # \u6216: git remote add upstream git@github.com:vesoft-inc/nebula.git # \u7531\u4e8e\u6ca1\u6709\u5199\u8bbf\u95ee\u6743\u9650\uff0c\u8bf7\u52ff\u63a8\u9001\u81f3\u4e0a\u6e38\u4e3b\u5206\u652f git remote set-url --push upstream no_push # \u786e\u8ba4\u8fdc\u7a0b\u5206\u652f\u6709\u6548\uff1a # \u6b63\u786e\u7684\u683c\u5f0f\u4e3a\uff1a # origin git@github.com:$(user)/nebula.git (fetch) # origin git@github.com:$(user)/nebula.git (push) # upstream https://github.com/vesoft-inc/nebula (fetch) # upstream no_push (push) git remote -v \u5b9a\u4e49\u9884\u63d0\u4ea4 hook \u00b6 \u8bf7\u5c06 Nebula Graph \u9884\u63d0\u4ea4\u6302\u94a9\u94fe\u63a5\u5230 .git \u76ee\u5f55\u3002 \u6b64\u6302\u94a9\u68c0\u67e5\u63d0\u4ea4\u683c\u5f0f\uff0c\u6784\u5efa\uff0c\u6587\u6863\u751f\u6210\u7b49\u3002 cd $working_dir /nebula/.git/hooks ln -s ../../cpplint/bin/pre-commit.sh . \u6709\u65f6\uff0c\u9884\u63d0\u4ea4\u6302\u94a9\u4e0d\u80fd\u6267\u884c\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u624b\u52a8\u6267\u884c\u3002 cd $working_dir /nebula/.git/hooks chmod +x pre-commit Step 3: \u5206\u652f \u00b6 \u66f4\u65b0\u672c\u5730\u4e3b\u5206\u652f\uff1a cd $working_dir /nebula git fetch upstream git checkout master git rebase upstream/master \u4ece\u4e3b\u5206\u652f\u521b\u5efa\u5e76\u5207\u6362\u5206\u652f\uff1a git checkout -b myfeature \u6ce8\u610f \u7531\u4e8e\u4e00\u4e2a PR \u901a\u5e38\u5305\u542b\u591a\u4e2a commit\uff0c\u5728\u5408\u5e76\u81f3 master \u65f6\u5bb9\u6613\u88ab\u6324\u538b ( squash )\uff0c\u56e0\u6b64\u5efa\u8bae\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684\u5206\u652f\u8fdb\u884c\u66f4\u6539\u3002\u5408\u5e76\u540e\uff0c\u8fd9\u4e2a\u5206\u652f\u5df2\u65e0\u7528\u5904\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u4e0a\u8ff0 rebase \u547d\u4ee4\u5c06\u672c\u5730 master \u4e0e upstream \u540c\u6b65\u3002\u6b64\u5916\uff0c\u5982\u679c\u76f4\u63a5\u5c06 commit \u63d0\u4ea4\u81f3 master\uff0c\u5219\u9700\u8981 hard reset \u4e3b\u5206\u652f\uff0c\u4f8b\u5982\uff1a git fetch upstream git checkout master git reset --hard upstream/master git push --force origin master Step 4: \u5f00\u53d1 \u00b6 \u7f16\u8f91\u4ee3\u7801 \u00b6 \u6b64\u65f6\u53ef\u5728 myfeature \u5206\u652f\u7f16\u8f91\u4ee3\u7801\uff0c \u7f16\u8f91\u65f6\u8bf7\u9075\u5faa Google C++ Style Guide \u3002 \u5bf9\u4fee\u6539\u7684\u4ee3\u7801\u8fdb\u884c\u9a8c\u8bc1 \u00b6 \u7f16\u8bd1\u6e90\u7801 \u00b6 \u8bf7\u53c2\u8003\u6587\u6863 build-source-code \u9a8c\u8bc1 \u00b6 \u66ff\u6362\u4e8c\u8fdb\u5236\u6587\u4ef6 \u7f16\u8bd1\u597d\u7684\u4e09\u4e2a\u670d\u52a1\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u5728 nebula/build/src/daemon/_build/ \u76ee\u5f55\u4e0b\u9762\uff0c\u7f16\u8bd1\u597d\u7684 console \u5728 nebula/build/src/console/_build \u76ee\u5f55\u4e0b\u9762\u3002\u53ef\u4ee5\u628a\u4e8c\u8fdb\u5236\u66ff\u6362\u5230\u5b89\u88c5\u76ee\u5f55 bin \u4e0b\u9762\uff0c\u91cd\u542f\u670d\u52a1\u5e76\u505a\u9a8c\u8bc1\u3002 \u6dfb\u52a0\u5355\u5143\u6d4b\u8bd5 \u5728\u4fee\u6539\u7684\u6a21\u5757\u4ee3\u7801\u76ee\u5f55\u4e0b\u9762\u4f1a\u6709\u4e2atest\u76ee\u5f55\uff0c\u53ef\u4ee5\u5728\u91cc\u9762\u6dfb\u52a0\u5355\u5143\u6d4b\u8bd5\uff0c\u7136\u540e\u7f16\u8bd1\u8fd0\u884c\u5355\u5143\u6d4b\u8bd5\uff0c\u63d0\u4ea4\u7684\u4ee3\u7801\u5fc5\u987b\u786e\u4fdd\u6240\u6709\u5355\u5143\u6d4b\u8bd5\u987a\u5229\u901a\u8fc7\u3002 \u8fd0\u884c\u6240\u6709\u5355\u5143\u6d4b\u8bd5 cd nebula/build ctest -j $( nproc ) Step 5: \u4fdd\u6301\u5206\u652f\u540c\u6b65 \u00b6 # \u5f53\u5904\u4e8e myfeature \u5206\u652f\u65f6\uff1a git fetch upstream git rebase upstream/master Step 6: Commit \u00b6 \u63d0\u4ea4\u4ee3\u7801\u66f4\u6539 git commit Step 7: Push \u00b6 \u4ee3\u7801\u66f4\u6539\u5b8c\u6210\u6216\u9700\u8981\u5907\u4efd\u4ee3\u7801\u65f6\uff0c\u5c06\u672c\u5730\u4ed3\u5e93\u521b\u5efa\u7684\u5206\u652f push \u5230 GitHub \u7aef\u7684\u8fdc\u7a0b\u4ed3\u5e93\uff1a git push -f origin myfeature Step 8: \u521b\u5efa pull request \u00b6 \u70b9\u51fb\u6b64\u5904\u8bbf\u95ee fork \u4ed3\u5e93https://github.com/$user/nebula (\u66ff\u6362\u6b64\u5904\u7684 $user \u7528\u6237\u540d)\u3002 \u70b9\u51fb myfeature \u5206\u652f\u65c1\u7684 Compare & pull request \u6309\u94ae\u3002 Step 9: \u4ee3\u7801\u5ba1\u67e5 \u00b6 \u516c\u5f00\u7684 pull request \u81f3\u5c11\u9700\u8981\u4e24\u4eba\u5ba1\u67e5\uff0c\u4ee3\u7801\u5ba1\u67e5\u5305\u62ec\u67e5\u627e bug\uff0c\u5ba1\u67e5\u4ee3\u7801\u98ce\u683c\u7b49\u3002","title":"\u5982\u4f55\u63d0\u4ea4\u4ee3\u7801\u548c\u6587\u6863"},{"location":"manual-CN/4.contributions/how-to-contribute/#_1","text":"","title":"\u5982\u4f55\u63d0\u4ea4\u4ee3\u7801\u548c\u6587\u6863"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_1_github_fork","text":"\u8bbf\u95ee https://github.com/vesoft-inc/nebula \u70b9\u51fb\u53f3\u4e0a\u89d2 Fork \u6309\u94ae\u521b\u5efa\u8fdc\u7a0b\u5206\u652f","title":"Step 1: \u901a\u8fc7 GitHub Fork"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_2","text":"\u5b9a\u4e49\u672c\u5730\u5de5\u4f5c\u76ee\u5f55\uff1a # \u5b9a\u4e49\u5de5\u4f5c\u76ee\u5f55 working_dir = $HOME /Workspace \u5c06 user \u8bbe\u7f6e\u4e3a GitHub \u8d26\u6237\u540d\uff1a user ={ GitHub\u8d26\u6237\u540d } clone \u4ee3\u7801\uff1a mkdir -p $working_dir cd $working_dir git clone https://github.com/ $user /nebula.git # \u63a8\u8350\u5982\u4e0b\u65b9\u5f0f # \u6216: git clone git@github.com:$user/nebula.git cd $working_dir /nebula git remote add upstream https://github.com/vesoft-inc/nebula.git # \u6216: git remote add upstream git@github.com:vesoft-inc/nebula.git # \u7531\u4e8e\u6ca1\u6709\u5199\u8bbf\u95ee\u6743\u9650\uff0c\u8bf7\u52ff\u63a8\u9001\u81f3\u4e0a\u6e38\u4e3b\u5206\u652f git remote set-url --push upstream no_push # \u786e\u8ba4\u8fdc\u7a0b\u5206\u652f\u6709\u6548\uff1a # \u6b63\u786e\u7684\u683c\u5f0f\u4e3a\uff1a # origin git@github.com:$(user)/nebula.git (fetch) # origin git@github.com:$(user)/nebula.git (push) # upstream https://github.com/vesoft-inc/nebula (fetch) # upstream no_push (push) git remote -v","title":"Step 2: \u5c06\u5206\u652f\u514b\u9686\u5230\u672c\u5730"},{"location":"manual-CN/4.contributions/how-to-contribute/#hook","text":"\u8bf7\u5c06 Nebula Graph \u9884\u63d0\u4ea4\u6302\u94a9\u94fe\u63a5\u5230 .git \u76ee\u5f55\u3002 \u6b64\u6302\u94a9\u68c0\u67e5\u63d0\u4ea4\u683c\u5f0f\uff0c\u6784\u5efa\uff0c\u6587\u6863\u751f\u6210\u7b49\u3002 cd $working_dir /nebula/.git/hooks ln -s ../../cpplint/bin/pre-commit.sh . \u6709\u65f6\uff0c\u9884\u63d0\u4ea4\u6302\u94a9\u4e0d\u80fd\u6267\u884c\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u624b\u52a8\u6267\u884c\u3002 cd $working_dir /nebula/.git/hooks chmod +x pre-commit","title":"\u5b9a\u4e49\u9884\u63d0\u4ea4 hook"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_3","text":"\u66f4\u65b0\u672c\u5730\u4e3b\u5206\u652f\uff1a cd $working_dir /nebula git fetch upstream git checkout master git rebase upstream/master \u4ece\u4e3b\u5206\u652f\u521b\u5efa\u5e76\u5207\u6362\u5206\u652f\uff1a git checkout -b myfeature \u6ce8\u610f \u7531\u4e8e\u4e00\u4e2a PR \u901a\u5e38\u5305\u542b\u591a\u4e2a commit\uff0c\u5728\u5408\u5e76\u81f3 master \u65f6\u5bb9\u6613\u88ab\u6324\u538b ( squash )\uff0c\u56e0\u6b64\u5efa\u8bae\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684\u5206\u652f\u8fdb\u884c\u66f4\u6539\u3002\u5408\u5e76\u540e\uff0c\u8fd9\u4e2a\u5206\u652f\u5df2\u65e0\u7528\u5904\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528\u4e0a\u8ff0 rebase \u547d\u4ee4\u5c06\u672c\u5730 master \u4e0e upstream \u540c\u6b65\u3002\u6b64\u5916\uff0c\u5982\u679c\u76f4\u63a5\u5c06 commit \u63d0\u4ea4\u81f3 master\uff0c\u5219\u9700\u8981 hard reset \u4e3b\u5206\u652f\uff0c\u4f8b\u5982\uff1a git fetch upstream git checkout master git reset --hard upstream/master git push --force origin master","title":"Step 3: \u5206\u652f"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_4","text":"","title":"Step 4: \u5f00\u53d1"},{"location":"manual-CN/4.contributions/how-to-contribute/#_2","text":"\u6b64\u65f6\u53ef\u5728 myfeature \u5206\u652f\u7f16\u8f91\u4ee3\u7801\uff0c \u7f16\u8f91\u65f6\u8bf7\u9075\u5faa Google C++ Style Guide \u3002","title":"\u7f16\u8f91\u4ee3\u7801"},{"location":"manual-CN/4.contributions/how-to-contribute/#_3","text":"","title":"\u5bf9\u4fee\u6539\u7684\u4ee3\u7801\u8fdb\u884c\u9a8c\u8bc1"},{"location":"manual-CN/4.contributions/how-to-contribute/#_4","text":"\u8bf7\u53c2\u8003\u6587\u6863 build-source-code","title":"\u7f16\u8bd1\u6e90\u7801"},{"location":"manual-CN/4.contributions/how-to-contribute/#_5","text":"\u66ff\u6362\u4e8c\u8fdb\u5236\u6587\u4ef6 \u7f16\u8bd1\u597d\u7684\u4e09\u4e2a\u670d\u52a1\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u5728 nebula/build/src/daemon/_build/ \u76ee\u5f55\u4e0b\u9762\uff0c\u7f16\u8bd1\u597d\u7684 console \u5728 nebula/build/src/console/_build \u76ee\u5f55\u4e0b\u9762\u3002\u53ef\u4ee5\u628a\u4e8c\u8fdb\u5236\u66ff\u6362\u5230\u5b89\u88c5\u76ee\u5f55 bin \u4e0b\u9762\uff0c\u91cd\u542f\u670d\u52a1\u5e76\u505a\u9a8c\u8bc1\u3002 \u6dfb\u52a0\u5355\u5143\u6d4b\u8bd5 \u5728\u4fee\u6539\u7684\u6a21\u5757\u4ee3\u7801\u76ee\u5f55\u4e0b\u9762\u4f1a\u6709\u4e2atest\u76ee\u5f55\uff0c\u53ef\u4ee5\u5728\u91cc\u9762\u6dfb\u52a0\u5355\u5143\u6d4b\u8bd5\uff0c\u7136\u540e\u7f16\u8bd1\u8fd0\u884c\u5355\u5143\u6d4b\u8bd5\uff0c\u63d0\u4ea4\u7684\u4ee3\u7801\u5fc5\u987b\u786e\u4fdd\u6240\u6709\u5355\u5143\u6d4b\u8bd5\u987a\u5229\u901a\u8fc7\u3002 \u8fd0\u884c\u6240\u6709\u5355\u5143\u6d4b\u8bd5 cd nebula/build ctest -j $( nproc )","title":"\u9a8c\u8bc1"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_5","text":"# \u5f53\u5904\u4e8e myfeature \u5206\u652f\u65f6\uff1a git fetch upstream git rebase upstream/master","title":"Step 5: \u4fdd\u6301\u5206\u652f\u540c\u6b65"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_6_commit","text":"\u63d0\u4ea4\u4ee3\u7801\u66f4\u6539 git commit","title":"Step 6: Commit"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_7_push","text":"\u4ee3\u7801\u66f4\u6539\u5b8c\u6210\u6216\u9700\u8981\u5907\u4efd\u4ee3\u7801\u65f6\uff0c\u5c06\u672c\u5730\u4ed3\u5e93\u521b\u5efa\u7684\u5206\u652f push \u5230 GitHub \u7aef\u7684\u8fdc\u7a0b\u4ed3\u5e93\uff1a git push -f origin myfeature","title":"Step 7: Push"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_8_pull_request","text":"\u70b9\u51fb\u6b64\u5904\u8bbf\u95ee fork \u4ed3\u5e93https://github.com/$user/nebula (\u66ff\u6362\u6b64\u5904\u7684 $user \u7528\u6237\u540d)\u3002 \u70b9\u51fb myfeature \u5206\u652f\u65c1\u7684 Compare & pull request \u6309\u94ae\u3002","title":"Step 8: \u521b\u5efa pull request"},{"location":"manual-CN/4.contributions/how-to-contribute/#step_9","text":"\u516c\u5f00\u7684 pull request \u81f3\u5c11\u9700\u8981\u4e24\u4eba\u5ba1\u67e5\uff0c\u4ee3\u7801\u5ba1\u67e5\u5305\u62ec\u67e5\u627e bug\uff0c\u5ba1\u67e5\u4ee3\u7801\u98ce\u683c\u7b49\u3002","title":"Step 9: \u4ee3\u7801\u5ba1\u67e5"},{"location":"manual-CN/4.contributions/pull-request-commit-message-guidelines/","text":"PR \u548c Commit Message \u6307\u5357 \u00b6 \u672c\u6587\u6863\u4ecb\u7ecd\u7684 PR \u548c Commit Message \u6307\u5357\u9002\u7528\u4e8e\u6240\u6709 Nebula Graph \u4ed3\u5e93\u3002 \u6240\u6709\u63d0\u4ea4\u81f3 master \u5206\u652f\u7684 commit \u5747\u5fc5\u987b\u9075\u5faa\u4ee5\u4e0b\u51c6\u5219\u3002 Commit Message \u00b6 <type> ( <scope> ) : <subject> // scope is optional, subject is must <body> // optional <footer> // optional \u672c\u6307\u5357\u53c2\u7167 AngularJS commit \u89c4\u5219 \u3002 <Type> \u63cf\u8ff0 commit \u7c7b\u578b\u3002 <subject> \u662f commit \u7684\u7b80\u77ed\u63cf\u8ff0\u3002 \u5982\u9700\u6dfb\u52a0\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u6dfb\u52a0\u7a7a\u767d\u884c\uff0c\u7136\u540e\u4ee5\u6bb5\u843d\u683c\u5f0f\u8fdb\u884c\u6dfb\u52a0\u3002 Commit \u7c7b\u578b \u00b6 Type Description Feature \u65b0\u529f\u80fd Fix \u4fee\u590d bug Doc \u6587\u6863 Style \u4ee3\u7801\u683c\u5f0f Refactor \u4ee3\u7801\u91cd\u6784 Test \u589e\u52a0\u6d4b\u8bd5 Chore \u6784\u5efa\u8fc7\u7a0b\u6216\u8f85\u52a9\u5de5\u5177\u7684\u53d8\u52a8 Pull Request \u00b6 \u63d0\u4ea4 PR \u65f6\uff0c\u8bf7\u5728\u6807\u9898\u4e2d\u5305\u542b\u6240\u6709\u66f4\u6539\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u5e76\u786e\u4fdd\u6807\u9898\u7b80\u6d01\u3002 PR \u6807\u9898\u5fc5\u9700\u7b80\u660e\u6982\u62ec\u66f4\u6539\u4fe1\u606f\u3002 \u5bf9\u4e8e\u663e\u800c\u6613\u89c1\u7684\u7b80\u5355\u66f4\u6539\uff0c\u53ef\u4e0d\u5fc5\u6dfb\u52a0\u63cf\u8ff0\u3002\u5982\u679c PR \u6d89\u53ca\u590d\u6742\u66f4\u6539\uff0c\u8bf7\u5bf9\u66f4\u6539\u8fdb\u884c\u6982\u8ff0\u3002\u5982\u679c PR \u4fee\u590d\u4e86\u76f8\u5173 issue\uff0c\u8bf7\u5173\u8054\u3002 Pull Request \u6a21\u677f \u00b6 What changes were proposed in this pull request? Why are the changes needed? Does this PR introduce any user-facing change? How was this patch tested?","title":"PR \u548c Commit Message \u6307\u5357"},{"location":"manual-CN/4.contributions/pull-request-commit-message-guidelines/#pr_commit_message","text":"\u672c\u6587\u6863\u4ecb\u7ecd\u7684 PR \u548c Commit Message \u6307\u5357\u9002\u7528\u4e8e\u6240\u6709 Nebula Graph \u4ed3\u5e93\u3002 \u6240\u6709\u63d0\u4ea4\u81f3 master \u5206\u652f\u7684 commit \u5747\u5fc5\u987b\u9075\u5faa\u4ee5\u4e0b\u51c6\u5219\u3002","title":"PR \u548c Commit Message \u6307\u5357"},{"location":"manual-CN/4.contributions/pull-request-commit-message-guidelines/#commit_message","text":"<type> ( <scope> ) : <subject> // scope is optional, subject is must <body> // optional <footer> // optional \u672c\u6307\u5357\u53c2\u7167 AngularJS commit \u89c4\u5219 \u3002 <Type> \u63cf\u8ff0 commit \u7c7b\u578b\u3002 <subject> \u662f commit \u7684\u7b80\u77ed\u63cf\u8ff0\u3002 \u5982\u9700\u6dfb\u52a0\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u6dfb\u52a0\u7a7a\u767d\u884c\uff0c\u7136\u540e\u4ee5\u6bb5\u843d\u683c\u5f0f\u8fdb\u884c\u6dfb\u52a0\u3002","title":"Commit Message"},{"location":"manual-CN/4.contributions/pull-request-commit-message-guidelines/#commit","text":"Type Description Feature \u65b0\u529f\u80fd Fix \u4fee\u590d bug Doc \u6587\u6863 Style \u4ee3\u7801\u683c\u5f0f Refactor \u4ee3\u7801\u91cd\u6784 Test \u589e\u52a0\u6d4b\u8bd5 Chore \u6784\u5efa\u8fc7\u7a0b\u6216\u8f85\u52a9\u5de5\u5177\u7684\u53d8\u52a8","title":"Commit \u7c7b\u578b"},{"location":"manual-CN/4.contributions/pull-request-commit-message-guidelines/#pull_request","text":"\u63d0\u4ea4 PR \u65f6\uff0c\u8bf7\u5728\u6807\u9898\u4e2d\u5305\u542b\u6240\u6709\u66f4\u6539\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u5e76\u786e\u4fdd\u6807\u9898\u7b80\u6d01\u3002 PR \u6807\u9898\u5fc5\u9700\u7b80\u660e\u6982\u62ec\u66f4\u6539\u4fe1\u606f\u3002 \u5bf9\u4e8e\u663e\u800c\u6613\u89c1\u7684\u7b80\u5355\u66f4\u6539\uff0c\u53ef\u4e0d\u5fc5\u6dfb\u52a0\u63cf\u8ff0\u3002\u5982\u679c PR \u6d89\u53ca\u590d\u6742\u66f4\u6539\uff0c\u8bf7\u5bf9\u66f4\u6539\u8fdb\u884c\u6982\u8ff0\u3002\u5982\u679c PR \u4fee\u590d\u4e86\u76f8\u5173 issue\uff0c\u8bf7\u5173\u8054\u3002","title":"Pull Request"},{"location":"manual-CN/4.contributions/pull-request-commit-message-guidelines/#pull_request_1","text":"What changes were proposed in this pull request? Why are the changes needed? Does this PR introduce any user-facing change? How was this patch tested?","title":"Pull Request \u6a21\u677f"},{"location":"manual-CN/5.appendix/cypher-ngql/","text":"Cypher \u548c nGQL \u00b6 \u57fa\u672c\u6982\u5ff5\u5bf9\u6bd4 \u00b6 \u6982\u5ff5\u540d\u79f0 Cypher nGQL vertex, node node vertex edge, relationship relationship edge vertex type label tag edge type relationship type edge type vertex identifier node id generated by default vid edge identifier edge id generated by default \u56fe\u57fa\u672c\u64cd\u4f5c \u00b6 \u64cd\u4f5c Cypher nGQL \u5217\u51fa\u6240\u6709 labels/tags * MATCH (n) RETURN distinct labels(n); * call db.labels(); SHOW TAGS \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u7684\u70b9 CREATE (:Person {age: 16}) INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u7684\u8fb9 CREATE (src)-[:LIKES]->(dst) SET rel.prop = V INSERT EDGE ( ) VALUES -> [@ ]: ( ) \u5220\u9664\u70b9 MATCH (n) WHERE ID(n) = vid DETACH DELETE n DELETE VERTEX \\ \u5220\u9664\u8fb9 MATCH ()-[r]->() WHERE ID(r)=edgeID DELETE r DELETE EDGE \\ -> \\ [@ ] \u66f4\u65b0\u70b9\u5c5e\u6027 SET n.name = V UPDATE VERTEX \\ SET \u67e5\u8be2\u6307\u5b9a\u70b9\u7684\u5c5e\u6027 MATCH (n) WHERE ID(n) = vid RETURN properties(n) FETCH PROP ON \\ \u67e5\u8be2\u6307\u5b9a\u8fb9\u7684\u5c5e\u6027 MATCH (n)-[r]->() WHERE ID(r)=edgeID return properties(r) FETCH PROP ON -> [@ ] \u67e5\u8be2\u6307\u5b9a\u70b9\u7684\u67d0\u4e00\u7c7b\u5173\u7cfb MATCH (n)-[r:edge_type]->() WHERE ID(n) = vid GO FROM \\ OVER \\ \u6307\u5b9a\u70b9\u7684\u67d0\u4e00\u7c7b\u53cd\u5411\u5173\u7cfb MATCH (n)<-[r:edge_type]-() WHERE ID(n) = vid GO FROM \\ OVER \\ REVERSELY \u6307\u5b9a\u70b9\u67d0\u4e00\u7c7b\u5173\u7cfb\u7b2c N-Hop \u67e5\u8be2 MATCH (n)-[r:edge_type*N]->() WHERE ID(n) = vid return r GO N STEPS FROM \\ OVER \\ \u4e24\u70b9\u8def\u5f84 MATCH p =(a)-[]->(b) WHERE ID(a) = a_vid AND ID(b) = b_vid RETURN p FIND ALL PATH FROM \\ TO \\ OVER * \u793a\u4f8b\u67e5\u8be2 \u00b6 \u793a\u4f8b\u4f7f\u7528\u4ee5\u4e0b\u6570\u636e: \u63d2\u5165\u6570\u636e # \u63d2\u5165\u70b9 nebula> INSERT VERTEX character(name, age, type) VALUES hash(\"saturn\"):(\"saturn\", 10000, \"titan\"), hash(\"jupiter\"):(\"jupiter\", 5000, \"god\"); # \u63d2\u5165\u8fb9 nebula> INSERT EDGE father() VALUES hash(\"jupiter\")->hash(\"saturn\"):(); // cypher cypher> CREATE (src:character {name:\"saturn\", age: 10000, type:\"titan\"}) > CREATE (dst:character {name:\"jupiter\", age: 5000, type:\"god\"}) > CREATE (src)-[rel:father]->(dst) ``` - \u5220\u9664\u70b9 ```ngql nebula> DELETE VERTEX hash(\"prometheus\"); cypher> MATCH (n:character {name:\"prometheus\"}) > DETACH DELETE n \u66f4\u65b0\u70b9\u7684\u5c5e\u6027 nebula> UPDATE VERTEX hash(\"jesus\") SET character.type = 'titan'; cypher> MATCH (n:character {name:\"jesus\"}) > SET n.type = 'titan' \u67e5\u770b\u70b9\u7684\u5c5e\u6027 nebula> FETCH PROP ON character hash(\"saturn\"); =================================================== | character.name | character.age | character.type | =================================================== | saturn | 10000 | titan | --------------------------------------------------- cypher> MATCH (n:character {name:\"saturn\"}) > RETURN properties(n) \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"properties(n)\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502{\"name\":\"saturn\",\"type\":\"titan\",\"age\":10000}\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2 hercules \u7956\u7236\u7684\u59d3\u540d nebula> GO 2 STEPS FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | saturn | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father*2]->(dst:character) > RETURN dst.name; \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"satun\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2 hercules \u7236\u4eb2\u7684\u59d3\u540d nebula> GO FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | jupiter | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father]->(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"jupiter\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2\u767e\u5c81\u8001\u4eba\u7684\u59d3\u540d nebula> # coming soon cypher> MATCH (src:character) > WHERE src.age > 100 > RETURN src.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"src.name\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"saturn\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"jupiter\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 \u2502 \"pluto\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u627e\u51fa pluto \u548c\u8c01\u4f4f nebula> GO FROM hash(\"pluto\") OVER lives YIELD lives._dst AS place | GO FROM $-.place OVER lives REVERSELY WHERE \\ > $$.character.name != \"pluto\" YIELD $$.character.name AS cohabitants; =============== | cohabitants | =============== | cerberus | --------------- cypher> MATCH (src:character{name:\"pluto\"})-[r1:lives]->()<-[r2:lives]-(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"cerberus\"\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2 Pluto \u7684\u5144\u5f1f\u4eec\u4ee5\u53ca\u4ed6\u4eec\u7684\u5c45\u4f4f\u5730 nebula> GO FROM hash(\"pluto\") OVER brother YIELD brother._dst AS god | \\ > GO FROM $-.god OVER lives YIELD $^.character.name AS Brother, $$.location.name AS Habitations; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- cypher> MATCH (src:Character{name:\"pluto\"})-[r1:brother]->(bro:Character)-[r2:lives]->(dst) > RETURN bro.name, dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"bro.name\" \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"jupiter\" \u2502 \"sky\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \"sea\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Cypher \u548c nGQL"},{"location":"manual-CN/5.appendix/cypher-ngql/#cypher_ngql","text":"","title":"Cypher \u548c nGQL"},{"location":"manual-CN/5.appendix/cypher-ngql/#_1","text":"\u6982\u5ff5\u540d\u79f0 Cypher nGQL vertex, node node vertex edge, relationship relationship edge vertex type label tag edge type relationship type edge type vertex identifier node id generated by default vid edge identifier edge id generated by default","title":"\u57fa\u672c\u6982\u5ff5\u5bf9\u6bd4"},{"location":"manual-CN/5.appendix/cypher-ngql/#_2","text":"\u64cd\u4f5c Cypher nGQL \u5217\u51fa\u6240\u6709 labels/tags * MATCH (n) RETURN distinct labels(n); * call db.labels(); SHOW TAGS \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u7684\u70b9 CREATE (:Person {age: 16}) INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u7684\u8fb9 CREATE (src)-[:LIKES]->(dst) SET rel.prop = V INSERT EDGE ( ) VALUES -> [@ ]: ( ) \u5220\u9664\u70b9 MATCH (n) WHERE ID(n) = vid DETACH DELETE n DELETE VERTEX \\ \u5220\u9664\u8fb9 MATCH ()-[r]->() WHERE ID(r)=edgeID DELETE r DELETE EDGE \\ -> \\ [@ ] \u66f4\u65b0\u70b9\u5c5e\u6027 SET n.name = V UPDATE VERTEX \\ SET \u67e5\u8be2\u6307\u5b9a\u70b9\u7684\u5c5e\u6027 MATCH (n) WHERE ID(n) = vid RETURN properties(n) FETCH PROP ON \\ \u67e5\u8be2\u6307\u5b9a\u8fb9\u7684\u5c5e\u6027 MATCH (n)-[r]->() WHERE ID(r)=edgeID return properties(r) FETCH PROP ON -> [@ ] \u67e5\u8be2\u6307\u5b9a\u70b9\u7684\u67d0\u4e00\u7c7b\u5173\u7cfb MATCH (n)-[r:edge_type]->() WHERE ID(n) = vid GO FROM \\ OVER \\ \u6307\u5b9a\u70b9\u7684\u67d0\u4e00\u7c7b\u53cd\u5411\u5173\u7cfb MATCH (n)<-[r:edge_type]-() WHERE ID(n) = vid GO FROM \\ OVER \\ REVERSELY \u6307\u5b9a\u70b9\u67d0\u4e00\u7c7b\u5173\u7cfb\u7b2c N-Hop \u67e5\u8be2 MATCH (n)-[r:edge_type*N]->() WHERE ID(n) = vid return r GO N STEPS FROM \\ OVER \\ \u4e24\u70b9\u8def\u5f84 MATCH p =(a)-[]->(b) WHERE ID(a) = a_vid AND ID(b) = b_vid RETURN p FIND ALL PATH FROM \\ TO \\ OVER *","title":"\u56fe\u57fa\u672c\u64cd\u4f5c"},{"location":"manual-CN/5.appendix/cypher-ngql/#_3","text":"\u793a\u4f8b\u4f7f\u7528\u4ee5\u4e0b\u6570\u636e: \u63d2\u5165\u6570\u636e # \u63d2\u5165\u70b9 nebula> INSERT VERTEX character(name, age, type) VALUES hash(\"saturn\"):(\"saturn\", 10000, \"titan\"), hash(\"jupiter\"):(\"jupiter\", 5000, \"god\"); # \u63d2\u5165\u8fb9 nebula> INSERT EDGE father() VALUES hash(\"jupiter\")->hash(\"saturn\"):(); // cypher cypher> CREATE (src:character {name:\"saturn\", age: 10000, type:\"titan\"}) > CREATE (dst:character {name:\"jupiter\", age: 5000, type:\"god\"}) > CREATE (src)-[rel:father]->(dst) ``` - \u5220\u9664\u70b9 ```ngql nebula> DELETE VERTEX hash(\"prometheus\"); cypher> MATCH (n:character {name:\"prometheus\"}) > DETACH DELETE n \u66f4\u65b0\u70b9\u7684\u5c5e\u6027 nebula> UPDATE VERTEX hash(\"jesus\") SET character.type = 'titan'; cypher> MATCH (n:character {name:\"jesus\"}) > SET n.type = 'titan' \u67e5\u770b\u70b9\u7684\u5c5e\u6027 nebula> FETCH PROP ON character hash(\"saturn\"); =================================================== | character.name | character.age | character.type | =================================================== | saturn | 10000 | titan | --------------------------------------------------- cypher> MATCH (n:character {name:\"saturn\"}) > RETURN properties(n) \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"properties(n)\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502{\"name\":\"saturn\",\"type\":\"titan\",\"age\":10000}\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2 hercules \u7956\u7236\u7684\u59d3\u540d nebula> GO 2 STEPS FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | saturn | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father*2]->(dst:character) > RETURN dst.name; \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"satun\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2 hercules \u7236\u4eb2\u7684\u59d3\u540d nebula> GO FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | jupiter | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father]->(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"jupiter\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2\u767e\u5c81\u8001\u4eba\u7684\u59d3\u540d nebula> # coming soon cypher> MATCH (src:character) > WHERE src.age > 100 > RETURN src.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"src.name\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"saturn\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"jupiter\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 \u2502 \"pluto\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u627e\u51fa pluto \u548c\u8c01\u4f4f nebula> GO FROM hash(\"pluto\") OVER lives YIELD lives._dst AS place | GO FROM $-.place OVER lives REVERSELY WHERE \\ > $$.character.name != \"pluto\" YIELD $$.character.name AS cohabitants; =============== | cohabitants | =============== | cerberus | --------------- cypher> MATCH (src:character{name:\"pluto\"})-[r1:lives]->()<-[r2:lives]-(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"cerberus\"\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u67e5\u8be2 Pluto \u7684\u5144\u5f1f\u4eec\u4ee5\u53ca\u4ed6\u4eec\u7684\u5c45\u4f4f\u5730 nebula> GO FROM hash(\"pluto\") OVER brother YIELD brother._dst AS god | \\ > GO FROM $-.god OVER lives YIELD $^.character.name AS Brother, $$.location.name AS Habitations; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- cypher> MATCH (src:Character{name:\"pluto\"})-[r1:brother]->(bro:Character)-[r2:lives]->(dst) > RETURN bro.name, dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"bro.name\" \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"jupiter\" \u2502 \"sky\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \"sea\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"\u793a\u4f8b\u67e5\u8be2"},{"location":"manual-CN/5.appendix/gremlin-ngql/","text":"Gremlin \u548c nGQL \u5bf9\u6bd4 \u00b6 Gremlin \u4ecb\u7ecd \u00b6 Gremlin \u662f Apache ThinkerPop \u6846\u67b6\u4e0b\u7684\u56fe\u904d\u5386\u8bed\u8a00\u3002Gremlin \u53ef\u4ee5\u662f\u58f0\u660e\u6027\u7684\u4e5f\u53ef\u4ee5\u662f\u547d\u4ee4\u6027\u7684\u3002\u867d\u7136 Gremlin \u662f\u57fa\u4e8e Groovy \u7684\uff0c\u4f46\u5177\u6709\u8bb8\u591a\u8bed\u8a00\u53d8\u4f53\uff0c\u5141\u8bb8\u5f00\u53d1\u4eba\u5458\u4ee5 Java\u3001JavaScript\u3001Python\u3001Scala\u3001Clojure \u548c Groovy \u7b49\u8bb8\u591a\u73b0\u4ee3\u7f16\u7a0b\u8bed\u8a00\u539f\u751f\u7f16\u5199 Gremlin \u67e5\u8be2\u3002 nGQL \u4ecb\u7ecd \u00b6 Nebula Graph \u7684\u67e5\u8be2\u8bed\u8a00\u4e3a nGQL \uff0c \u662f\u4e00\u79cd\u7c7b SQL \u7684\u58f0\u660e\u578b\u7684\u6587\u672c\u67e5\u8be2\u8bed\u8a00\u3002\u76f8\u6bd4 SQL\uff0c nGQL \u5177\u6709\u5982\u4e0b\u7279\u70b9\uff1a \u7c7b SQL\uff0c\u6613\u5b66\u6613\u7528 \u53ef\u6269\u5c55 \u5173\u952e\u8bcd\u5927\u5c0f\u5199\u4e0d\u654f\u611f \u652f\u6301\u56fe\u904d\u5386 \u652f\u6301\u6a21\u5f0f\u5339\u914d \u652f\u6301\u805a\u5408\u8fd0\u7b97 \u652f\u6301\u56fe\u8ba1\u7b97 \u652f\u6301\u5206\u5e03\u5f0f\u4e8b\u52a1\uff08\u5f00\u53d1\u4e2d\uff09 \u65e0\u5d4c\u5165\u652f\u6301\u7ec4\u5408\u8bed\u53e5\uff0c\u6613\u4e8e\u9605\u8bfb \u57fa\u672c\u6982\u5ff5\u5bf9\u6bd4 \u00b6 \u540d\u79f0 Gremlin nGQL vertex, node vertex vertex edge, relationship edge edge vertex type label tag edge type label edge type vertex id vid vid edge id eid \u65e0 Gremlin \u548c nGQL \u5747\u4f7f\u7528\u552f\u4e00\u6807\u8bc6\u7b26\u6807\u8bb0\u9876\u70b9\u548c\u8fb9\u3002\u5728 Nebula Graph \u4e2d\uff0c\u7528\u6237\u53ef\u4ee5\u4f7f\u7528\u6307\u5b9a\u6807\u8bc6\u7b26\u3001\u54c8\u5e0c\u6216 uuid \u51fd\u6570\u81ea\u52a8\u751f\u6210\u6807\u8bc6\u7b26\u3002 \u56fe\u57fa\u672c\u64cd\u4f5c \u00b6 \u540d\u79f0 Gremlin nGQL \u65b0\u5efa\u56fe\u7a7a\u95f4 g = TinkerGraph.open().traversal() CREATE SPACE gods \u67e5\u770b\u70b9\u7c7b\u578b g.V().label() SHOW TAGS \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u70b9 g.addV(String vertexLabel).property() INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u8fb9 g.addE(String edgeLabel).from(v1).to(v2).property() INSERT EDGE ( ) VALUES -> : ( ) \u5220\u9664\u70b9 g.V(\\ ).drop() DELETE VERTEX \\ \u5220\u9664\u8fb9 g.E(\\ ).outE(\\ ).where(otherV().is(\\ ))drop() DELETE EDGE \\ -> \\ \u66f4\u65b0\u70b9\u5c5e\u6027 g.V(\\ ).property() UPDATE VERTEX \\ SET \u67e5\u770b\u6307\u5b9a\u70b9 g.V(\\ ) FETCH PROP ON \\ \u67e5\u770b\u6307\u5b9a\u8fb9 g.E( >> ) FETCH PROP ON -> \u6cbf\u6307\u5b9a\u70b9\u67e5\u8be2\u6307\u5b9a\u8fb9 g.V(\\ ).outE( \\ ) GO FROM \\ OVER \\ \u6cbf\u6307\u5b9a\u70b9\u53cd\u5411\u67e5\u8be2\u6307\u5b9a\u8fb9 g.V(\\ ).in( \\ ) GO FROM \\ OVER \\ REVERSELY \u6cbf\u6307\u5b9a\u70b9\u67e5\u8be2\u6307\u5b9a\u8fb9 N \u8df3 g.V(\\ ).repeat(out(\\ )).times(N) GO N STEPS FROM \\ OVER \\ \u8fd4\u56de\u6307\u5b9a\u4e24\u70b9\u8def\u5f84 g.V(\\ ).repeat(out()).until(\\ ).path() FIND ALL PATH FROM \\ TO \\ OVER * \u793a\u4f8b\u67e5\u8be2 \u00b6 \u672c\u8282\u4e2d\u7684\u793a\u4f8b\u4f7f\u7528\u4e86 Janus Graph \u7684\u793a\u4f8b\u56fe The Graphs of Gods \u3002\u8be5\u56fe\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u6b64\u5904\u4f7f\u7528 \u5c5e\u6027\u56fe\u6a21\u578b \u63cf\u8ff0\u7f57\u9a6c\u4e07\u795e\u8bdd\u4e2d\u8bf8\u795e\u5173\u7cfb\u3002 \u63d2\u5165\u6570\u636e # \u63d2\u5165\u70b9 nebula> INSERT VERTEX character ( name, age, type ) VALUES hash ( \"saturn\" ) : ( \"saturn\" , 10000 , \"titan\" ) , hash ( \"jupiter\" ) : ( \"jupiter\" , 5000 , \"god\" ) ; gremlin> saturn = g.addV ( \"character\" ) .property ( T.id, 1 ) .property ( 'name' , 'saturn' ) .property ( 'age' , 10000 ) .property ( 'type' , 'titan' ) .next () ; == >v [ 1 ] gremlin> jupiter = g.addV ( \"character\" ) .property ( T.id, 2 ) .property ( 'name' , 'jupiter' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 2 ] gremlin> prometheus = g.addV ( \"character\" ) .property ( T.id, 31 ) .property ( 'name' , 'prometheus' ) .property ( 'age' , 1000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 31 ] gremlin> jesus = g.addV ( \"character\" ) .property ( T.id, 32 ) .property ( 'name' , 'jesus' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 32 ] # \u63d2\u5165\u8fb9 nebula> INSERT EDGE father () VALUES hash ( \"jupiter\" ) ->hash ( \"saturn\" ) : () ; gremlin> g.addE ( \"father\" ) .from ( jupiter ) .to ( saturn ) .property ( T.id, 13 ) ; == >e [ 13 ][ 2 -father->1 ] \u5220\u9664\u6570\u636e nebula> DELETE VERTEX hash ( \"prometheus\" ) ; gremlin> g.V ( prometheus ) .drop () ; \u66f4\u65b0\u6570\u636e nebula> UPDATE VERTEX hash ( \"jesus\" ) SET character.type = 'titan' ; gremlin> g.V ( jesus ) .property ( 'age' , 6000 ) ; \u67e5\u770b\u6570\u636e nebula> FETCH PROP ON character hash ( \"saturn\" ) ; =================================================== | character.name | character.age | character.type | =================================================== | saturn | 10000 | titan | --------------------------------------------------- gremlin> g.V ( saturn ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] \u67e5\u8be2 hercules \u7684\u7956\u7236 nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO 2 STEPS FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | saturn | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .out ( 'father' ) .values ( 'name' ) ; == >saturn \u67e5\u8be2 hercules \u7684\u7236\u4eb2 nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .values ( 'name' ) ; == >jupiter \u67e5\u8be2\u5e74\u9f84\u5927\u4e8e 100 \u7684\u4eba\u7269 nebula> LOOKUP ON character WHERE character.age > 100 YIELD character.name, character.age ; ========================================================= | VertexID | character.name | character.age | ========================================================= | 6761447489613431910 | pluto | 4000 | --------------------------------------------------------- | -5860788569139907963 | neptune | 4500 | --------------------------------------------------------- | 4863977009196259577 | jupiter | 5000 | --------------------------------------------------------- | -4316810810681305233 | saturn | 10000 | --------------------------------------------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'age' ,gt ( 100 )) .values ( 'name' ) ; == >saturn == >jupiter == >neptune == >pluto \u67e5\u8be2\u548c pluto \u4e00\u8d77\u5c45\u4f4f\u7684\u4eba\u7269 nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | \\ GO FROM $- .place OVER lives REVERSELY YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | pluto | --------------- | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .values ( 'name' ) ; == >pluto == >cerberus \u4ece\u4e00\u8d77\u5c45\u4f4f\u7684\u4eba\u7269\u4e2d\u6392\u9664 pluto \u672c\u4eba nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus Pluto \u7684\u5144\u5f1f\u4eec # where do pluto's brothers live? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS brother | \\ GO FROM $- .brother OVER lives YIELD $$ .location.name ; ==================== | $$ .location.name | ==================== | sky | -------------------- | sea | -------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .out ( 'lives' ) .values ( 'name' ) ; == >sky == >sea # which brother lives in which place? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS god | \\ GO FROM $- .god OVER lives YIELD $^.character.name AS Brother, $$ .location.name AS Habitations ; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .as ( 'god' ) .out ( 'lives' ) .as ( 'place' ) .select ( 'god' , 'place' ) .by ( 'name' ) ; == > [ god:jupiter, place:sky ] == > [ god:neptune, place:sea ] \u9ad8\u7ea7\u67e5\u8be2 \u00b6 \u56fe\u63a2\u7d22 \u00b6 # gremlin \u7248\u672c gremlin> Gremlin.version () ; == >3.3.5 # \u8fd4\u56de\u6240\u6709\u70b9 gremlin> g.V () ; == >v [ 1 ] == >v [ 2 ] ... nebula> # Coming soon # \u7edf\u8ba1\u70b9\u6570 gremlin> g.V () .count () ; == >12 nebula> # Coming soon # \u6309\u7167\u70b9\u8fb9\u7c7b\u578b\u7edf\u8ba1\u70b9\u8fb9\u4e2a\u6570 gremlin> g.V () .groupCount () .by ( label ) ; == > [ character:9,location:3 ] gremlin> g.E () .groupCount () .by ( label ) ; == > [ mother:1,lives:5,father:2,brother:6,battled:3,pet:1 ] nebula> # Coming soon # \u8fd4\u56de\u6240\u6709\u8fb9 gremlin> g.E () ; == >e [ 13 ][ 2 -father->1 ] == >e [ 14 ][ 2 -lives->3 ] ... nebula> # Coming soon # \u67e5\u8be2\u6240\u6709\u70b9\u7c7b\u578b gremlin> g.V () .label () .dedup () ; == >character == >location nebula> SHOW TAGS ; ================== | ID | Name | ================== | 15 | character | ------------------ | 16 | location | ------------------ # \u67e5\u8be2\u6240\u6709\u8fb9\u7c7b\u578b gremlin> g.E () .label () .dedup () ; == >father == >lives ... nebula> SHOW EDGES ; ================ | ID | Name | ================ | 17 | father | ---------------- | 18 | brother | ---------------- ... # \u67e5\u8be2\u6240\u6709\u9876\u70b9\u7684\u5c5e\u6027 gremlin> g.V () .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ... nebula> # Coming soon # \u67e5\u8be2 character \u9876\u70b9\u5c5e\u6027 gremlin> g.V () .hasLabel ( 'character' ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ... \u8fb9\u7684\u904d\u5386 \u00b6 \u540d\u79f0 Gremlin nGQL \u6307\u5b9a\u70b9\u6cbf\u6307\u5b9a\u8fb9\u7684\u51fa\u9876\u70b9 out(\\ ) GO FROM \\ OVER \\ \u6307\u5b9a\u70b9\u6cbf\u6307\u5b9a\u8fb9\u7684\u5165\u9876\u70b9 in(\\ ) GO FROM \\ OVER \\ REVERSELY \u6307\u5b9a\u70b9\u6cbf\u6307\u5b9a\u8fb9\u7684\u53cc\u5411\u9876\u70b9 both(\\ ) GO FROM \\ OVER \\ BIDIRECT # \u8bbf\u95ee\u67d0\u4e2a\u9876\u70b9\u6cbf\u67d0\u6761\u8fb9\u7684 OUT \u65b9\u5411\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .out ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother ; ======================== | brother._dst | ======================== | 6761447489613431910 | ------------------------ | -5860788569139907963 | ------------------------ # \u8bbf\u95ee\u67d0\u4e2a\u9876\u70b9\u6cbf\u67d0\u6761\u8fb9\u7684 IN \u65b9\u5411\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .in ( 'brother' ) ; == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother REVERSELY ; ======================= | brother._dst | ======================= | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # \u8bbf\u95ee\u67d0\u4e2a\u9876\u70b9\u6cbf\u67d0\u6761\u8fb9\u7684\u53cc\u5411\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .both ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother BIDIRECT ; ======================= | brother._dst | ======================= | 6761447489613431910 | ------------------------ | -5860788569139907963 | | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # 2\u5ea6 out \u67e5\u8be2 gremlin> g.V ( hercules ) .out ( 'father' ) .out ( 'lives' ) ; == >v [ 3 ] nebula> GO FROM hash ( \"hercules\" ) OVER father YIELD father._dst AS id | \\ GO FROM $- .id OVER lives ; ======================== | lives._dst | ======================== | -1121386748834253737 | ------------------------ has \u6761\u4ef6\u8fc7\u6ee4 \u00b6 \u540d\u79f0 Gremlin nGQL \u901a\u8fc7 ID \u6765\u8fc7\u6ee4\u9876\u70b9 hasId(\\ ) FETCH PROP ON \\ \u901a\u8fc7 label \u548c\u5c5e\u6027\u7684\u540d\u5b57\u548c\u503c\u8fc7\u6ee4\u9876\u70b9\u548c\u8fb9 has(\\ , \\ , \\ ) LOOKUP \\ | \\ WHERE \\ # \u67e5\u8be2 ID \u4e3a saturn \u7684\u9876\u70b9 gremlin> g.V () .hasId ( saturn ) ; == >v [ 1 ] nebula> FETCH PROP ON * hash ( \"saturn\" ) ; ========================================================================== | VertexID | character.name | character.age | character.type | ========================================================================== | -4316810810681305233 | saturn | 10000 | titan | -------------------------------------------------------------------------- # \u67e5\u8be2 tag \u4e3a character \u4e14 name \u5c5e\u6027\u503c\u4e3a hercules \u7684\u9876\u70b9 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .valueMap () ; == > [ name: [ hercules ] ,type: [ demigod ] ,age: [ 30 ]] nebula> LOOKUP ON character WHERE character.name == 'hercules' YIELD character.name, character.age, character.type ; ========================================================================= | VertexID | character.name | character.age | character.type | ========================================================================= | 5976696804486077889 | hercules | 30 | demigod | ------------------------------------------------------------------------- \u8fd4\u56de\u7ed3\u679c\u9650\u5236 \u00b6 \u540d\u79f0 Gremlin nGQL \u6307\u5b9a\u8fd4\u56de\u7ed3\u679c\u884c\u6570 limit() LIMIT \u83b7\u53d6\u540e n \u4e2a\u5143\u7d20 tail() ORDER BY \\ DESC LIMIT \u8df3\u8fc7\u524d n \u4e2a\u5143\u7d20 skip() LIMIT \\ # \u67e5\u8be2\u524d\u4e24\u4e2a\u9876\u70b9 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .limit ( 2 ) ; == >v [ 9 ] == >v [ 10 ] nebula> GO FROM hash ( 'hercules' ) OVER battled | LIMIT 2 ; ======================= | battled._dst | ======================= | 530133512982221454 | ----------------------- | -695163537569412701 | ----------------------- # \u67e5\u8be2\u6700\u540e\u4e00\u4e2a\u9876\u70b9 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .tail ( 1 ) ; == >cerberus nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ; ============ | name | ============ | cerberus | ------------ # \u8df3\u8fc7\u7b2c 1 \u4e2a\u5143\u7d20\u5e76\u8fd4\u56de\u4e00\u4e2a\u5143\u7d20 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .skip ( 1 ) .limit ( 1 ) ; == >hydra nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ,1 ; ========= | name | ========= | hydra | --------- \u8def\u5f84\u67e5\u8be2 \u00b6 \u540d\u79f0 Gremlin nGQL \u6240\u6709\u8def\u5f84 path() FIND ALL PATH \u4e0d\u5305\u542b\u73af\u8def simplePath() \\ \u53ea\u5305\u542b\u73af\u8def cyclicPath() \\ \u6700\u77ed\u8def\u5f84 \\ FIND SHORTEST PATH \u6ce8\u610f\uff1a Nebula Graph \u9700\u8981\u8d77\u59cb\u70b9\u548c\u7ec8\u70b9\u65b9\u53ef\u8fd4\u56de\u8def\u5f84\uff0c Gremlin \u4ec5\u9700\u8981\u8d77\u59cb\u70b9\u3002 # pluto \u9876\u70b9\u5230\u4e0e\u5176\u6709\u76f4\u63a5\u5173\u8054\u7684\u51fa\u8fb9\u9876\u70b9\u7684\u8def\u5f84 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .out () .path () ; == > [ v [ 8 ] ,v [ 12 ]] == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] == > [ v [ 8 ] ,v [ 11 ]] # \u67e5\u8be2\u70b9 pluto \u5230\u70b9 jupiter \u7684\u6700\u77ed\u8def\u5f84 nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ FIND SHORTEST PATH FROM $- .VertexID TO hash ( \"jupiter\" ) OVER * ; ============================================================ | _path_ | ============================================================ | 6761447489613431910 <brother,0> 4863977009196259577 ------------------------------------------------------------ \u591a\u5ea6\u67e5\u8be2 \u00b6 \u540d\u79f0 Gremlin nGQL \u6307\u5b9a\u91cd\u590d\u6267\u884c\u7684\u8bed\u53e5 repeat() N STEPS \u6307\u5b9a\u91cd\u590d\u6267\u884c\u7684\u6b21\u6570 times() N STEPS \u6307\u5b9a\u5faa\u73af\u7ec8\u6b62\u7684\u6761\u4ef6 until() \\ \u6307\u5b9a\u6536\u96c6\u6570\u636e\u7684\u6761\u4ef6 emit() \\ # \u67e5\u8be2\u70b9 pluto \u51fa\u8fb9\u90bb\u70b9 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .repeat ( out ()) .times ( 1 ) ; == >v [ 12 ] == >v [ 2 ] == >v [ 5 ] == >v [ 11 ] nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ GO FROM $- .VertexID OVER * ; ================================================================================================================ | father._dst | brother._dst | lives._dst | mother._dst | pet._dst | battled._dst | ================================================================================================================ | 0 | -5860788569139907963 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 4863977009196259577 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | -4331657707562925133 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | 0 | 0 | 4594048193862126013 | 0 | ---------------------------------------------------------------------------------------------------------------- # \u67e5\u8be2\u9876\u70b9 hercules \u5230\u9876\u70b9 cerberus \u4e4b\u95f4\u7684\u8def\u5f84 # \u5faa\u73af\u7684\u7ec8\u6b62\u6761\u4ef6\u662f\u9047\u5230\u540d\u79f0\u662f cerberus \u7684\u9876\u70b9 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .until ( has ( 'name' , 'cerberus' )) .path () ; == > [ v [ 6 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 8 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 5 ] ,v [ 8 ] ,v [ 11 ]] ... nebula> # Coming soon # \u67e5\u8be2\u70b9 hercules \u7684\u6240\u6709\u51fa\u8fb9\u53ef\u5230\u8fbe\u70b9\u7684\u8def\u5f84 # \u4e14\u7ec8\u70b9\u5fc5\u987b\u662f character \u7c7b\u578b\u7684\u70b9 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .emit ( hasLabel ( 'character' )) .path () ; == > [ v [ 6 ] ,v [ 7 ]] == > [ v [ 6 ] ,v [ 2 ]] == > [ v [ 6 ] ,v [ 9 ]] == > [ v [ 6 ] ,v [ 10 ]] ... nebula> # Coming soon # \u67e5\u8be2\u4e24\u9876\u70b9 pluto \u548c saturn \u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84 # \u4e14\u6700\u5927\u6df1\u5ea6\u4e3a 3 gremlin> g.V ( 'pluto' ) .repeat ( out () .simplePath ()) .until ( hasId ( 'saturn' ) .and () .loops () .is ( lte ( 3 ))) .hasId ( 'saturn' ) .path () ; nebula> FIND SHORTEST PATH FROM hash ( 'pluto' ) TO hash ( 'saturn' ) OVER * UPTO 3 STEPS ; ================================================================================================= | _path_ | ================================================================================================= | 6761447489613431910 <brother,0> 4863977009196259577 <father,0> -4316810810681305233 ------------------------------------------------------------------------------------------------- \u67e5\u8be2\u7ed3\u679c\u6392\u5e8f \u00b6 \u540d\u79f0 Gremlin nGQL \u5347\u5e8f\u6392\u5217 order().by() ORDER BY \u964d\u5e8f\u6392\u5217 order().by(decr) ORDER BY DESC \u968f\u673a\u6392\u5217 order().by(shuffle) \\ # \u67e5\u8be2 pluto \u7684\u5144\u5f1f\u5e76\u6309\u7167\u5e74\u9f84\u964d\u5e8f\u6392\u5217 gremlin> g.V ( pluto ) .out ( 'brother' ) .order () .by ( 'age' , decr ) .valueMap () ; == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] == > [ name: [ neptune ] ,type: [ god ] ,age: [ 4500 ]] nebula> GO FROM hash ( 'pluto' ) OVER brother YIELD $$ .character.name AS Name, $$ .character.age as Age | ORDER BY Age DESC ; ================== | Name | Age | ================== | jupiter | 5000 | ------------------ | neptune | 4500 | ------------------ Group By \u00b6 \u540d\u79f0 Gremlin nGQL \u5bf9\u7ed3\u679c\u96c6\u8fdb\u884c\u5206\u7ec4 group().by() GROUP BY \u53bb\u9664\u76f8\u540c\u5143\u7d20 dedup() DISTINCT \u5bf9\u7ed3\u679c\u96c6\u8fdb\u884c\u5206\u7ec4\u5e76\u7edf\u8ba1 groupCount() GROUP BY COUNT \u6ce8\u610f\uff1a GROUP BY \u51fd\u6570\u53ea\u80fd\u4e0e YIELD \u8bed\u53e5\u4e00\u8d77\u4f7f\u7528\u3002 # \u6839\u636e\u9876\u70b9\u7c7b\u522b\u8fdb\u884c\u5206\u7ec4\u5e76\u7edf\u8ba1\u5404\u4e2a\u7c7b\u522b\u7684\u6570\u91cf gremlin> g.V () .group () .by ( label ) .by ( count ()) ; == > [ character:9,location:3 ] nebula> # Coming soon # \u67e5\u8be2\u70b9 jupiter \u51fa\u8fb9\u90bb\u70b9\uff0c\u4f7f\u7528 name \u5206\u7ec4\u5e76\u7edf\u8ba1 gremlin> g.V ( jupiter ) .out () .group () .by ( 'name' ) .by ( count ()) ; == > [ sky:1,saturn:1,neptune:1,pluto:1 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD $$ .character.name AS Name, $$ .character.age as Age, $$ .location.name | \\ GROUP BY $- .Name YIELD $- .Name, COUNT ( * ) ; ====================== | $- .Name | COUNT ( * ) | ====================== | | 1 | ---------------------- | pluto | 1 | ---------------------- | saturn | 1 | ---------------------- | neptune | 1 | ---------------------- # \u67e5\u627e\u70b9 jupiter \u51fa\u8fb9\u5230\u8fbe\u7684\u70b9\u5e76\u53bb\u91cd gremlin> g.V ( jupiter ) .out () .hasLabel ( 'character' ) .dedup () ; == >v [ 1 ] == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD DISTINCT $$ .character.name, $$ .character.age, $$ .location.name ; =========================================================== | $$ .character.name | $$ .character.age | $$ .location.name | =========================================================== | pluto | 4000 | | ----------------------------------------------------------- | neptune | 4500 | | ----------------------------------------------------------- | saturn | 10000 | | ----------------------------------------------------------- | | 0 | sky | ----------------------------------------------------------- where \u6761\u4ef6\u8fc7\u6ee4 \u00b6 \u540d\u79f0 Gremlin nGQL where \u6761\u4ef6\u8fc7\u6ee4 where() WHERE \u8fc7\u6ee4\u6761\u4ef6\u5bf9\u6bd4\uff1a \u540d\u79f0 Gremlin nGQL \u7b49\u4e8e eq(object) == \u4e0d\u7b49\u4e8e neq(object) != \u5c0f\u4e8e lt(number) < \u5c0f\u4e8e\u7b49\u4e8e lte(number) <= \u5927\u4e8e gt(number) > \u5927\u4e8e\u7b49\u4e8e gte(number) >= \u5224\u65ad\u503c\u662f\u5426\u5728\u6307\u5b9a\u7684\u5217\u8868\u4e2d within(objects\u2026\u200b) udf_is_in() gremlin> eq ( 2 ) .test ( 3 ) ; == >false nebula> YIELD 3 == 2 ; ========== | ( 3 == 2 ) | ========== | false | ---------- gremlin> within ( 'a' , 'b' , 'c' ) .test ( 'd' ) ; == >false nebula> YIELD udf_is_in ( 'd' , 'a' , 'b' , 'c' ) ; ====================== | udf_is_in ( d,a,b,c ) | ====================== | false | ---------------------- # \u627e\u51fa pluto \u548c\u8c01\u4f4f\u5e76\u6392\u961f\u4ed6\u672c\u4eba gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | --------------- \u903b\u8f91\u8fd0\u7b97 \u00b6 \u540d\u79f0 Gremlin nGQL Is is() == Not not() != And and() AND Or or() OR # \u67e5\u8be2\u5e74\u9f84\u5927\u4e8e 30 \u7684\u4eba\u7269 gremlin> g.V () .values ( 'age' ) .is ( gte ( 30 )) ; == >10000 == >5000 == >4500 == >30 == >45 == >4000 nebula> LOOKUP ON character WHERE character.age > = 30 YIELD character.age ; ======================================== | VertexID | character.age | ======================================== | -4316810810681305233 | 10000 | ---------------------------------------\u2013 | 4863977009196259577 | 5000 | ---------------------------------------\u2013 | -5860788569139907963 | 4500 | ---------------------------------------\u2013 | 5976696804486077889 | 30 | ---------------------------------------\u2013 | -6780323075177699500 | 45 | ---------------------------------------\u2013 | 6761447489613431910 | 4000 | ---------------------------------------\u2013 # \u67e5\u8be2\u540d\u79f0\u4e3a pluto \u4e14\u5e74\u9f84\u4e3a 4000 \u7684\u4eba\u7269 gremlin> g.V () .has ( 'name' , 'pluto' ) .and () .has ( 'age' ,4000 ) ; == >v [ 8 ] nebula> LOOKUP ON character WHERE character.name == 'pluto' AND character.age == 4000 ; ======================= | VertexID | ======================= | 6761447489613431910 | ----------------------- # \u903b\u8f91\u975e\u7684\u7528\u6cd5 gremlin> g.V () .has ( 'name' , 'pluto' ) .out ( 'brother' ) .not ( values ( 'name' ) .is ( 'neptune' )) .values ( 'name' ) ; == >jupiter nebula> LOOKUP ON character WHERE character.name == 'pluto' YIELD character.name AS name | \\ GO FROM $- .VertexID OVER brother WHERE $$ .character.name ! = 'neptune' YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | --------------------- \u7edf\u8ba1\u8fd0\u7b97 \u00b6 \u540d\u79f0 Gremlin nGQL \u6c42\u548c sum() SUM() \u6700\u5927\u503c max() MAX() \u6700\u5c0f\u503c min() MIN() \u5e73\u5747\u503c mean() AVG() Nebula Graph \u7edf\u8ba1\u8fd0\u7b97\u5fc5\u987b\u540c GROUP BY \u4e00\u8d77\u4f7f\u7528\u3002 # \u8ba1\u7b97\u6240\u6709 character \u7684\u5e74\u9f84\u7684\u603b\u548c gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .sum () ; == >23595 nebula> # Coming soon # \u8ba1\u7b97\u6240\u6709 character \u7684 brother \u51fa\u8fb9\u6570\u7684\u603b\u548c gremlin> g.V () .hasLabel ( 'character' ) .map ( outE ( 'brother' ) .count ()) .sum () ; == >6 nebula> # Coming soon # \u8fd4\u56de\u6240\u6709 character \u7684\u5e74\u9f84\u4e2d\u7684\u6700\u5927\u503c gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .max () ; == >10000 nebula> # Coming soon \u8def\u5f84\u9009\u53d6\u4e0e\u8fc7\u6ee4 \u00b6 # \u4ece\u8def\u5f84\u4e2d\u9009\u53d6\u7b2c 1 \u6b65\u548c\u7b2c 3 \u6b65\u7684\u7ed3\u679c\u4f5c\u4e3a\u6700\u7ec8\u7ed3\u679c gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) ; == > [ a:v [ 8 ] ,c:v [ 3 ]] == > [ a:v [ 8 ] ,c:v [ 1 ]] ... nebula> # Coming soon # \u901a\u8fc7 by() \u6307\u5b9a\u9009\u53d6\u7684\u7ef4\u5ea6 gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:pluto,c:sky ] == > [ a:pluto,c:saturn ] ... nebula> # Coming soon # \u4ece map \u4e2d\u9009\u62e9\u6307\u5b9a key \u7684\u503c gremlin> g.V () .valueMap () .select ( 'name' ) .dedup () ; == > [ saturn ] == > [ jupiter ] ... nebula> # Coming soon \u5206\u652f \u00b6 # \u67e5\u627e\u6240\u6709\u7c7b\u578b\u4e3a 'character' \u7684\u9876\u70b9 # name \u5c5e\u6027\u4e3a 'jupiter' \u7684\u9876\u70b9\u8f93\u51fa\u5176 age \u5c5e\u6027 # \u5426\u5219\u8f93\u51fa\u9876\u70b9\u7684 name \u5c5e\u6027 gremlin> g.V () .hasLabel ( 'character' ) .choose ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 == >neptune ... # Lambda gremlin> g.V () .branch { it.get () .value ( 'name' )} .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 ... # Traversal gremlin> g.V () .branch ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 # Branch gremlin> g.V () .choose ( has ( 'name' , 'jupiter' ) ,values ( 'age' ) ,values ( 'name' )) ; == >saturn == >5000 # \u57fa\u4e8e if then \u8fdb\u884c\u5206\u7ec4 gremlin> g.V () .hasLabel ( \"character\" ) .groupCount () .by ( values ( \"age\" ) .choose ( is ( lt ( 40 )) ,constant ( \"young\" ) , choose ( is ( lt ( 4500 )) , constant ( \"old\" ) , constant ( \"very old\" )))) ; == > [ young:4,old:2,very old:3 ] Nebula Graph \u5c1a\u65e0\u7c7b\u4f3c\u529f\u80fd\u3002 \u5408\u5e76 \u00b6 coalesce() \u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u6570\u91cf\u7684\u904d\u5386\u5668\uff08traversal\uff09\uff0c\u6309\u987a\u5e8f\u6267\u884c\uff0c\u5e76\u8fd4\u56de\u7b2c\u4e00\u4e2a\u80fd\u4ea7\u751f\u8f93\u51fa\u7684\u904d\u5386\u5668\u7684\u7ed3\u679c\u3002 optional() \u53ea\u80fd\u63a5\u53d7\u4e00\u4e2a\u904d\u5386\u5668\uff08traversal\uff09\uff0c\u5982\u679c\u8be5\u904d\u5386\u5668\u80fd\u4ea7\u751f\u4e00\u4e2a\u7ed3\u679c\uff0c\u5219\u8fd4\u56de\u8be5\u7ed3\u679c\uff0c\u5426\u5219\u8fd4\u56de\u8c03\u7528 optionalStep \u7684\u5143\u7d20\u672c\u8eab\u3002 union() \u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u6570\u91cf\u7684\u904d\u5386\u5668\uff0c\u5e76\u80fd\u591f\u5c06\u5404\u4e2a\u904d\u5386\u5668\u7684\u8f93\u51fa\u5408\u5e76\u5230\u4e00\u8d77\u3002 # \u5982\u679c\u7c7b\u578b\u4e3a monster \u5219\u8fd4\u56de\u7c7b\u578b\u5426\u5219\u8fd4\u56de 'Not a monster' gremlin> g.V ( pluto ) .coalesce ( has ( 'type' , 'monster' ) .values ( 'type' ) ,constant ( \"Not a monster\" )) ; == >Not a monster # \u6309\u4f18\u5148\u7ea7\u5bfb\u627e\u5230\u9876\u70b9 jupiter \u7684\u4ee5\u4e0b\u8fb9\u548c\u90bb\u63a5\u70b9\uff0c\u627e\u5230\u4e00\u4e2a\u5c31\u505c\u6b62 # 1\u3001brother \u51fa\u8fb9\u548c\u90bb\u63a5\u70b9 # 2\u3001father \u51fa\u8fb9\u548c\u90bb\u63a5\u70b9 # 3\u3001father \u5165\u8fb9\u548c\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .coalesce ( outE ( 'brother' ) , outE ( 'father' ) , inE ( 'father' )) .inV () .path () .by ( 'name' ) .by ( label ) ; == > [ jupiter,brother,pluto ] == > [ jupiter,brother,neptune ] # \u67e5\u627e\u9876\u70b9 pluto \u7684 father \u51fa\u9876\u70b9\uff0c\u5982\u679c\u6ca1\u6709\u5c31\u8fd4\u56de pluto \u81ea\u5df1 gremlin> g.V ( pluto ) .optional ( out ( 'father' )) .valueMap () ; == > [ name: [ pluto ] ,type: [ god ] ,age: [ 4000 ]] # \u5bfb\u627e\u9876\u70b9 pluto \u7684\u51fa father \u9876\u70b9\uff0c\u90bb\u63a5 brother \u9876\u70b9\uff0c\u5e76\u5c06\u7ed3\u679c\u5408\u5e76\uff0c\u6700\u540e\u6253\u5370\u51fa\u8def\u5f84 gremlin> g.V ( pluto ) .union ( out ( 'father' ) ,both ( 'brother' )) .path () ; == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] Nebula Graph \u5c1a\u65e0\u7c7b\u4f3c\u529f\u80fd\u3002 \u7ed3\u679c\u805a\u96c6\u4e0e\u5c55\u5f00 \u00b6 # \u6536\u96c6\u7b2c 1 \u6b65\u7684\u7ed3\u679c\u5230\u96c6\u5408 x \u4e2d # \u6ce8\u610f\uff1a\u4e0d\u5f71\u54cd\u540e\u7eed\u7ed3\u679c gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) ; == >v [ 12 ] == >v [ 2 ] ... # \u901a\u8fc7 by() \u6307\u5b9a\u805a\u96c6\u7684\u7ef4\u5ea6 gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .by ( 'name' ) .cap ( 'x' ) ; == > [ tartarus,jupiter,neptune,cerberus ] # \u67e5\u8be2\u4e0e pluto \u7684\u4e24\u5ea6 OUT \u90bb\u5c45 # \u5e76\u6536\u96c6\u8fd9\u4e9b\u5230 x \u96c6\u5408\u91cc\u9762 # \u6700\u7ec8\u4ee5 name \u5c5e\u6027\u5c55\u793a\u5176\u90bb\u5c45 gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .out () .aggregate ( 'x' ) .cap ( 'x' ) .unfold () .values ( 'name' ) ; == >tartarus == >tartarus ... Nebula Graph \u5c1a\u65e0\u7c7b\u4f3c\u529f\u80fd\u3002 \u6a21\u5f0f\u5339\u914d \u00b6 match() \u8bed\u53e5\u4e3a\u56fe\u67e5\u8be2\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u65b9\u5f0f\uff0c\u4ee5\u4fbf\u7528\u66f4\u5177\u63cf\u8ff0\u6027\u7684\u65b9\u5f0f\u8fdb\u884c\u56fe\u67e5\u8be2\u3002match()\u8bed\u53e5\u901a\u8fc7\u591a\u4e2a\u6a21\u5f0f\u7247\u6bb5 traversal fragments \u6765\u8fdb\u884c\u6a21\u5f0f\u5339\u914d\u3002\u8fd9\u4e9b traversal fragments \u4e2d\u4f1a\u5b9a\u4e49\u4e00\u4e9b\u53d8\u91cf\uff0c\u53ea\u6709\u6ee1\u8db3\u6240\u6709\u7528\u53d8\u91cf\u8868\u793a\u7684\u7ea6\u675f\u7684\u5bf9\u8c61\u624d\u80fd\u591f\u901a\u8fc7\u3002 # \u5bf9\u6bcf\u4e00\u4e2a\u9876\u70b9\uff0c\u7528\u4ee5\u4e0b\u6a21\u5f0f\u53bb\u5339\u914d\uff0c\u6ee1\u8db3\u5219\u751f\u6210\u4e00\u4e2a map<String, Object>\uff0c\u4e0d\u6ee1\u8db3\u5219\u8fc7\u6ee4\u6389 # \u6a21\u5f0f1\uff1aa \u4e3a\u6cbf father \u51fa\u8fb9\u6307\u5411 jupiter \u7684\u9876\u70b9 # \u6a21\u5f0f2\uff1ab \u5bf9\u5e94\u5f53\u524d\u9876\u70b9 jupiter # \u6a21\u5f0f3\uff1ac \u5bf9\u5e94\u521b\u5efa jupiter \u7684 brother \u5e74\u9f84\u4e3a 4000 \u7684 \u9876\u70b9 gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) ; == > [ a:v [ 6 ] ,b:v [ 2 ] ,c:v [ 8 ]] # match() \u8bed\u53e5\u53ef\u4ee5\u4e0e select() \u8bed\u53e5\u914d\u5408\u4f7f\u7528\uff0c\u4ece Map<String, Object> \u4e2d\u9009\u53d6\u90e8\u5206\u7ed3\u679c gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ] # match() \u8bed\u53e5\u53ef\u4ee5\u4e0e where() \u8bed\u53e5\u914d\u5408\u4f7f\u7528\uff0c\u8fc7\u6ee4\u7ed3\u679c gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .where ( 'a' , neq ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ] \u968f\u673a\u8fc7\u6ee4 \u00b6 sample() \u63a5\u53d7\u4e00\u4e2a\u6574\u6570\u503c\uff0c\u4ece\u524d\u4e00\u6b65\u7684\u904d\u5386\u5668\u4e2d\u91c7\u6837\uff08\u968f\u673a\uff09\u51fa\u6700\u591a\u6307\u5b9a\u6570\u76ee\u7684\u7ed3\u679c\u3002 coin() \u5b57\u9762\u610f\u601d\u662f\u629b\u786c\u5e01\u8fc7\u6ee4\uff0c\u63a5\u53d7\u4e00\u4e2a\u6d6e\u70b9\u503c\uff0c\u8be5\u6d6e\u70b9\u503c\u8868\u793a\u786c\u5e01\u51fa\u73b0\u6b63\u9762\u7684\u6982\u7387\u3002 # \u4ece\u6240\u6709\u9876\u70b9\u7684\u51fa\u8fb9\u4e2d\u968f\u673a\u9009\u62e9 2 \u6761 gremlin> g.V () .outE () .sample ( 2 ) ; == >e [ 15 ][ 2 -brother->5 ] == >e [ 18 ][ 5 -brother->2 ] # \u4ece\u6240\u9876\u70b9\u7684 name \u5c5e\u6027\u4e2d\u968f\u673a\u9009\u53d6 3 \u4e2a gremlin> g.V () .values ( 'name' ) .sample ( 3 ) ; == >hercules == >sea == >jupiter # \u4ece\u6240\u6709\u7684 character \u4e2d\u6839\u636e age \u968f\u673a\u9009\u62e9 3 \u4e2a gremlin> g.V () .hasLabel ( 'character' ) .sample ( 3 ) .by ( 'age' ) ; == >v [ 1 ] == >v [ 2 ] == >v [ 6 ] # \u4e0e local \u8054\u5408\u4f7f\u7528\u505a\u968f\u673a\u6f2b\u6e38 # \u4ece\u9876\u70b9 pluto \u51fa\u53d1\u505a 3 \u6b21\u968f\u673a\u6f2b\u6e38 gremlin> g.V ( pluto ) .repeat ( local ( bothE () .sample ( 1 ) .otherV ())) .times ( 3 ) .path () ; == > [ v [ 8 ] ,e [ 26 ][ 8 -brother->5 ] ,v [ 5 ] ,e [ 18 ][ 5 -brother->2 ] ,v [ 2 ] ,e [ 13 ][ 2 -father->1 ] ,v [ 1 ]] # \u6bcf\u4e2a\u9876\u70b9\u6309 0.5 \u7684\u6982\u7387\u8fc7\u6ee4 gremlin> g.V () .coin ( 0 .5 ) ; == >v [ 1 ] == >v [ 2 ] ... # \u8f93\u51fa\u6240\u6709 location \u7c7b\u9876\u70b9\u7684 name \u5c5e\u6027\uff0c\u5426\u5219\u8f93\u51fa not a location gremlin> g.V () .choose ( hasLabel ( 'location' ) , values ( 'name' ) , constant ( 'not a location' )) ; == >not a location == >not a location == >sky ... \u7ed3\u679c\u5b58\u53d6\u53e3\u888b Sack \u00b6 \u5305\u542b\u672c\u5730\u6570\u636e\u7ed3\u6784\u7684\u904d\u5386\u5668\u79f0\u4e3a\u53e3\u888b\u3002 sack() \u5c06\u6570\u636e\u653e\u5165\u53e3\u888b\uff0c\u6216\u8005\u4ece\u53e3\u888b\u53d6\u51fa\u6570\u636e\u3002\u6bcf\u4e2a\u904d\u5386\u5668\u7684\u6bcf\u4e2a\u53e3\u888b\u90fd\u662f\u901a\u8fc7 withSack\uff08\uff09 \u521b\u5efa\u7684\u3002 # \u521b\u5efa\u4e00\u4e2a\u5305\u542b\u5e38\u6570 1 \u7684\u53e3\u888b\uff0c\u5e76\u4e14\u5728\u6700\u7ec8\u53d6\u51fa\u53e3\u888b\u4e2d\u7684\u503c gremlin> g.withSack ( 1 ) .V () .sack () ; == >1 == >1 ... \u904d\u5386\u6805\u680f barrier \u00b6 barrier() \u5728\u67d0\u4e2a\u4f4d\u7f6e\u63d2\u5165\u4e00\u4e2a\u6805\u680f\uff0c\u4ee5\u5f3a\u5236\u8be5\u4f4d\u7f6e\u4e4b\u524d\u7684\u6b65\u9aa4\u5fc5\u987b\u90fd\u6267\u884c\u5b8c\u6210\u624d\u53ef\u4ee5\u7ee7\u7eed\u5f80\u540e\u6267\u884c\u3002 # \u5229\u7528\u9690\u5f0f barrier \u8ba1\u7b97\u7279\u5f81\u5411\u91cf\u4e2d\u5fc3\u6027 # \u5305\u62ec groupCount\u3001cap\uff0c\u6309\u7167\u964d\u5e8f\u6392\u5e8f gremlin> g.V () .repeat ( both () .groupCount ( 'm' )) .times ( 5 ) .cap ( 'm' ) .order ( local ) .by ( values, decr ) ; \u5c40\u90e8\u64cd\u4f5c local \u00b6 \u901a\u8fc7 Gremlin \u8fdb\u884c\u56fe\u904d\u5386\u901a\u5e38\u662f\u5f53\u524d step \u5904\u7406\u524d\u4e00 step \u4f20\u9012\u8fc7\u6765\u7684\u5bf9\u8c61\u6d41\u3002\u5f88\u591a\u64cd\u4f5c\u662f\u9488\u5bf9\u4f20\u9012\u8fc7\u6765\u7684\u5bf9\u8c61\u6d41\u4e2d\u7684\u5168\u90e8\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\uff0c\u4f46\u4e5f\u6709\u5f88\u591a\u65f6\u5019\u9700\u8981\u9488\u5bf9\u5bf9\u8c61\u6d41\u4e2d\u7684\u5355\u4e2a\u5bf9\u8c61\u800c\u975e\u5bf9\u8c61\u6d41\u4e2d\u7684\u5168\u90e8\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\u3002\u8fd9\u79cd\u5bf9\u5355\u4e2a\u5bf9\u8c61\u7684\u5c40\u90e8\u64cd\u4f5c\uff0c\u53ef\u4ee5\u4f7f\u7528 local() \u8bed\u53e5\u5b9e\u73b0\u3002 # \u4e0d\u4f7f\u7528 local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .properties ( 'age' ) .order () .by ( value,decr ) .limit ( 2 ) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () ; == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] # \u4f7f\u7528 local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .local ( properties ( 'age' ) .order () .by ( value ) .limit ( 2 )) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] == > [ character:neptune,age:4500 ] == > [ character:hercules,age:30 ] ... # \u67e5\u8be2 monster \u7684\u5c5e\u6027 map gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'type' ) .propertyMap () ; == > [ name: [ vp [ name->nemean ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->20 ]]] == > [ name: [ vp [ name->hydra ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] == > [ name: [ vp [ name->cerberus ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] # \u67e5\u8be2 monster \u7684\u5c5e\u6027\u4e2a\u6570 gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'monster' ) .propertyMap () .count ( local ) ; == >3 == >3 == >3 # \u6570\u76ee\u6700\u591a\u7684\u9876\u70b9\u7c7b\u578b\u7684\u9876\u70b9\u6570\u76ee gremlin> g.V () .groupCount () .by ( label ) .select ( values ) .max ( local ) ; == >9 # \u6240\u6709\u9876\u70b9\u7684\u5c5e\u6027\u5217\u8868\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5c5e\u6027 gremlin> g.V () .valueMap () .limit ( local, 1 ) ; == > [ name: [ saturn ]] == > [ name: [ jupiter ]] == > [ name: [ sky ]] ... # \u4e0d\u52a0 local gremlin> g.V () .valueMap () .limit ( 1 ) ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] # \u6240\u6709\u9876\u70b9\u4f5c\u4e3a\u4e00\u4e2a\u96c6\u5408\uff0c\u4ece\u4e2d\u91c7\u6837 2 \u4e2a gremlin> g.V () .fold () .sample ( local,2 ) ; == > [ v [ 8 ] ,v [ 1 ]] \u6267\u884c\u7edf\u8ba1\u548c\u5206\u6790 \u00b6 Gremlin \u63d0\u4f9b\u4e24\u79cd\u8bed\u53e5\u5bf9\u6267\u884c\u7684\u67e5\u8be2\u8bed\u53e5\u8fdb\u884c\u7edf\u8ba1\u548c\u5206\u6790\uff1a explain() \uff0c\u8be6\u7ec6\u63cf\u8ff0\u539f\u59cb\u7684 Gremlin \u8bed\u53e5\u5728\u7f16\u8bd1\u671f\u662f\u5982\u4f55\u8f6c\u53d8\u4e3a\u6700\u7ec8\u8981\u6267\u884c\u7684 step \u96c6\u5408\u7684 profile() \uff0c\u7edf\u8ba1 Gremlin \u8bed\u53e5\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u6bcf\u4e2a step \u6d88\u8017\u7684\u65f6\u95f4\u548c\u901a\u8fc7\u7684\u5bf9\u8c61\u7b49\u7edf\u8ba1\u4fe1\u606f # explain() gremlin> g.V () .hasLabel ( 'character' ) .explain () ; == >Traversal Explanation ========================================================================================== Original Traversal [ GraphStep ( vertex, []) , HasStep ([ ~label.eq ( character )])] ConnectiveStrategy [ D ] [ GraphStep ( vertex, []) , HasStep ([ ~label.eq ( character )])] MatchPredicateStrategy [ O ] [ GraphStep ( vertex, []) , HasStep ([ ~label.eq ( character )])] ... StandardVerificationStrategy [ V ] [ TinkerGraphStep ( vertex, [ ~label.eq ( character )])] Final Traversal [ TinkerGraphStep ( vertex, [ ~label.eq ( character )])] # profile() gremlin> g.V () .out ( 'father' ) .profile () == >Traversal Metrics Step Count Traversers Time ( ms ) % Dur ============================================================================================================= TinkerGraphStep ( vertex, []) 12 12 0 .644 45 .66 VertexStep ( OUT, [ father ] ,vertex ) 2 2 0 .534 37 .83 NoOpBarrierStep ( 2500 ) 2 2 0 .233 16 .51 >TOTAL - - 1 .411 -","title":"Gremlin \u548c nGQL \u5bf9\u6bd4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#gremlin_ngql","text":"","title":"Gremlin \u548c nGQL \u5bf9\u6bd4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#gremlin","text":"Gremlin \u662f Apache ThinkerPop \u6846\u67b6\u4e0b\u7684\u56fe\u904d\u5386\u8bed\u8a00\u3002Gremlin \u53ef\u4ee5\u662f\u58f0\u660e\u6027\u7684\u4e5f\u53ef\u4ee5\u662f\u547d\u4ee4\u6027\u7684\u3002\u867d\u7136 Gremlin \u662f\u57fa\u4e8e Groovy \u7684\uff0c\u4f46\u5177\u6709\u8bb8\u591a\u8bed\u8a00\u53d8\u4f53\uff0c\u5141\u8bb8\u5f00\u53d1\u4eba\u5458\u4ee5 Java\u3001JavaScript\u3001Python\u3001Scala\u3001Clojure \u548c Groovy \u7b49\u8bb8\u591a\u73b0\u4ee3\u7f16\u7a0b\u8bed\u8a00\u539f\u751f\u7f16\u5199 Gremlin \u67e5\u8be2\u3002","title":"Gremlin \u4ecb\u7ecd"},{"location":"manual-CN/5.appendix/gremlin-ngql/#ngql","text":"Nebula Graph \u7684\u67e5\u8be2\u8bed\u8a00\u4e3a nGQL \uff0c \u662f\u4e00\u79cd\u7c7b SQL \u7684\u58f0\u660e\u578b\u7684\u6587\u672c\u67e5\u8be2\u8bed\u8a00\u3002\u76f8\u6bd4 SQL\uff0c nGQL \u5177\u6709\u5982\u4e0b\u7279\u70b9\uff1a \u7c7b SQL\uff0c\u6613\u5b66\u6613\u7528 \u53ef\u6269\u5c55 \u5173\u952e\u8bcd\u5927\u5c0f\u5199\u4e0d\u654f\u611f \u652f\u6301\u56fe\u904d\u5386 \u652f\u6301\u6a21\u5f0f\u5339\u914d \u652f\u6301\u805a\u5408\u8fd0\u7b97 \u652f\u6301\u56fe\u8ba1\u7b97 \u652f\u6301\u5206\u5e03\u5f0f\u4e8b\u52a1\uff08\u5f00\u53d1\u4e2d\uff09 \u65e0\u5d4c\u5165\u652f\u6301\u7ec4\u5408\u8bed\u53e5\uff0c\u6613\u4e8e\u9605\u8bfb","title":"nGQL \u4ecb\u7ecd"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_1","text":"\u540d\u79f0 Gremlin nGQL vertex, node vertex vertex edge, relationship edge edge vertex type label tag edge type label edge type vertex id vid vid edge id eid \u65e0 Gremlin \u548c nGQL \u5747\u4f7f\u7528\u552f\u4e00\u6807\u8bc6\u7b26\u6807\u8bb0\u9876\u70b9\u548c\u8fb9\u3002\u5728 Nebula Graph \u4e2d\uff0c\u7528\u6237\u53ef\u4ee5\u4f7f\u7528\u6307\u5b9a\u6807\u8bc6\u7b26\u3001\u54c8\u5e0c\u6216 uuid \u51fd\u6570\u81ea\u52a8\u751f\u6210\u6807\u8bc6\u7b26\u3002","title":"\u57fa\u672c\u6982\u5ff5\u5bf9\u6bd4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_2","text":"\u540d\u79f0 Gremlin nGQL \u65b0\u5efa\u56fe\u7a7a\u95f4 g = TinkerGraph.open().traversal() CREATE SPACE gods \u67e5\u770b\u70b9\u7c7b\u578b g.V().label() SHOW TAGS \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u70b9 g.addV(String vertexLabel).property() INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) \u63d2\u5165\u6307\u5b9a\u7c7b\u578b\u8fb9 g.addE(String edgeLabel).from(v1).to(v2).property() INSERT EDGE ( ) VALUES -> : ( ) \u5220\u9664\u70b9 g.V(\\ ).drop() DELETE VERTEX \\ \u5220\u9664\u8fb9 g.E(\\ ).outE(\\ ).where(otherV().is(\\ ))drop() DELETE EDGE \\ -> \\ \u66f4\u65b0\u70b9\u5c5e\u6027 g.V(\\ ).property() UPDATE VERTEX \\ SET \u67e5\u770b\u6307\u5b9a\u70b9 g.V(\\ ) FETCH PROP ON \\ \u67e5\u770b\u6307\u5b9a\u8fb9 g.E( >> ) FETCH PROP ON -> \u6cbf\u6307\u5b9a\u70b9\u67e5\u8be2\u6307\u5b9a\u8fb9 g.V(\\ ).outE( \\ ) GO FROM \\ OVER \\ \u6cbf\u6307\u5b9a\u70b9\u53cd\u5411\u67e5\u8be2\u6307\u5b9a\u8fb9 g.V(\\ ).in( \\ ) GO FROM \\ OVER \\ REVERSELY \u6cbf\u6307\u5b9a\u70b9\u67e5\u8be2\u6307\u5b9a\u8fb9 N \u8df3 g.V(\\ ).repeat(out(\\ )).times(N) GO N STEPS FROM \\ OVER \\ \u8fd4\u56de\u6307\u5b9a\u4e24\u70b9\u8def\u5f84 g.V(\\ ).repeat(out()).until(\\ ).path() FIND ALL PATH FROM \\ TO \\ OVER *","title":"\u56fe\u57fa\u672c\u64cd\u4f5c"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_3","text":"\u672c\u8282\u4e2d\u7684\u793a\u4f8b\u4f7f\u7528\u4e86 Janus Graph \u7684\u793a\u4f8b\u56fe The Graphs of Gods \u3002\u8be5\u56fe\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u6b64\u5904\u4f7f\u7528 \u5c5e\u6027\u56fe\u6a21\u578b \u63cf\u8ff0\u7f57\u9a6c\u4e07\u795e\u8bdd\u4e2d\u8bf8\u795e\u5173\u7cfb\u3002 \u63d2\u5165\u6570\u636e # \u63d2\u5165\u70b9 nebula> INSERT VERTEX character ( name, age, type ) VALUES hash ( \"saturn\" ) : ( \"saturn\" , 10000 , \"titan\" ) , hash ( \"jupiter\" ) : ( \"jupiter\" , 5000 , \"god\" ) ; gremlin> saturn = g.addV ( \"character\" ) .property ( T.id, 1 ) .property ( 'name' , 'saturn' ) .property ( 'age' , 10000 ) .property ( 'type' , 'titan' ) .next () ; == >v [ 1 ] gremlin> jupiter = g.addV ( \"character\" ) .property ( T.id, 2 ) .property ( 'name' , 'jupiter' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 2 ] gremlin> prometheus = g.addV ( \"character\" ) .property ( T.id, 31 ) .property ( 'name' , 'prometheus' ) .property ( 'age' , 1000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 31 ] gremlin> jesus = g.addV ( \"character\" ) .property ( T.id, 32 ) .property ( 'name' , 'jesus' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 32 ] # \u63d2\u5165\u8fb9 nebula> INSERT EDGE father () VALUES hash ( \"jupiter\" ) ->hash ( \"saturn\" ) : () ; gremlin> g.addE ( \"father\" ) .from ( jupiter ) .to ( saturn ) .property ( T.id, 13 ) ; == >e [ 13 ][ 2 -father->1 ] \u5220\u9664\u6570\u636e nebula> DELETE VERTEX hash ( \"prometheus\" ) ; gremlin> g.V ( prometheus ) .drop () ; \u66f4\u65b0\u6570\u636e nebula> UPDATE VERTEX hash ( \"jesus\" ) SET character.type = 'titan' ; gremlin> g.V ( jesus ) .property ( 'age' , 6000 ) ; \u67e5\u770b\u6570\u636e nebula> FETCH PROP ON character hash ( \"saturn\" ) ; =================================================== | character.name | character.age | character.type | =================================================== | saturn | 10000 | titan | --------------------------------------------------- gremlin> g.V ( saturn ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] \u67e5\u8be2 hercules \u7684\u7956\u7236 nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO 2 STEPS FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | saturn | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .out ( 'father' ) .values ( 'name' ) ; == >saturn \u67e5\u8be2 hercules \u7684\u7236\u4eb2 nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .values ( 'name' ) ; == >jupiter \u67e5\u8be2\u5e74\u9f84\u5927\u4e8e 100 \u7684\u4eba\u7269 nebula> LOOKUP ON character WHERE character.age > 100 YIELD character.name, character.age ; ========================================================= | VertexID | character.name | character.age | ========================================================= | 6761447489613431910 | pluto | 4000 | --------------------------------------------------------- | -5860788569139907963 | neptune | 4500 | --------------------------------------------------------- | 4863977009196259577 | jupiter | 5000 | --------------------------------------------------------- | -4316810810681305233 | saturn | 10000 | --------------------------------------------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'age' ,gt ( 100 )) .values ( 'name' ) ; == >saturn == >jupiter == >neptune == >pluto \u67e5\u8be2\u548c pluto \u4e00\u8d77\u5c45\u4f4f\u7684\u4eba\u7269 nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | \\ GO FROM $- .place OVER lives REVERSELY YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | pluto | --------------- | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .values ( 'name' ) ; == >pluto == >cerberus \u4ece\u4e00\u8d77\u5c45\u4f4f\u7684\u4eba\u7269\u4e2d\u6392\u9664 pluto \u672c\u4eba nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus Pluto \u7684\u5144\u5f1f\u4eec # where do pluto's brothers live? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS brother | \\ GO FROM $- .brother OVER lives YIELD $$ .location.name ; ==================== | $$ .location.name | ==================== | sky | -------------------- | sea | -------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .out ( 'lives' ) .values ( 'name' ) ; == >sky == >sea # which brother lives in which place? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS god | \\ GO FROM $- .god OVER lives YIELD $^.character.name AS Brother, $$ .location.name AS Habitations ; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .as ( 'god' ) .out ( 'lives' ) .as ( 'place' ) .select ( 'god' , 'place' ) .by ( 'name' ) ; == > [ god:jupiter, place:sky ] == > [ god:neptune, place:sea ]","title":"\u793a\u4f8b\u67e5\u8be2"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_4","text":"","title":"\u9ad8\u7ea7\u67e5\u8be2"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_5","text":"# gremlin \u7248\u672c gremlin> Gremlin.version () ; == >3.3.5 # \u8fd4\u56de\u6240\u6709\u70b9 gremlin> g.V () ; == >v [ 1 ] == >v [ 2 ] ... nebula> # Coming soon # \u7edf\u8ba1\u70b9\u6570 gremlin> g.V () .count () ; == >12 nebula> # Coming soon # \u6309\u7167\u70b9\u8fb9\u7c7b\u578b\u7edf\u8ba1\u70b9\u8fb9\u4e2a\u6570 gremlin> g.V () .groupCount () .by ( label ) ; == > [ character:9,location:3 ] gremlin> g.E () .groupCount () .by ( label ) ; == > [ mother:1,lives:5,father:2,brother:6,battled:3,pet:1 ] nebula> # Coming soon # \u8fd4\u56de\u6240\u6709\u8fb9 gremlin> g.E () ; == >e [ 13 ][ 2 -father->1 ] == >e [ 14 ][ 2 -lives->3 ] ... nebula> # Coming soon # \u67e5\u8be2\u6240\u6709\u70b9\u7c7b\u578b gremlin> g.V () .label () .dedup () ; == >character == >location nebula> SHOW TAGS ; ================== | ID | Name | ================== | 15 | character | ------------------ | 16 | location | ------------------ # \u67e5\u8be2\u6240\u6709\u8fb9\u7c7b\u578b gremlin> g.E () .label () .dedup () ; == >father == >lives ... nebula> SHOW EDGES ; ================ | ID | Name | ================ | 17 | father | ---------------- | 18 | brother | ---------------- ... # \u67e5\u8be2\u6240\u6709\u9876\u70b9\u7684\u5c5e\u6027 gremlin> g.V () .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ... nebula> # Coming soon # \u67e5\u8be2 character \u9876\u70b9\u5c5e\u6027 gremlin> g.V () .hasLabel ( 'character' ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ...","title":"\u56fe\u63a2\u7d22"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_6","text":"\u540d\u79f0 Gremlin nGQL \u6307\u5b9a\u70b9\u6cbf\u6307\u5b9a\u8fb9\u7684\u51fa\u9876\u70b9 out(\\ ) GO FROM \\ OVER \\ \u6307\u5b9a\u70b9\u6cbf\u6307\u5b9a\u8fb9\u7684\u5165\u9876\u70b9 in(\\ ) GO FROM \\ OVER \\ REVERSELY \u6307\u5b9a\u70b9\u6cbf\u6307\u5b9a\u8fb9\u7684\u53cc\u5411\u9876\u70b9 both(\\ ) GO FROM \\ OVER \\ BIDIRECT # \u8bbf\u95ee\u67d0\u4e2a\u9876\u70b9\u6cbf\u67d0\u6761\u8fb9\u7684 OUT \u65b9\u5411\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .out ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother ; ======================== | brother._dst | ======================== | 6761447489613431910 | ------------------------ | -5860788569139907963 | ------------------------ # \u8bbf\u95ee\u67d0\u4e2a\u9876\u70b9\u6cbf\u67d0\u6761\u8fb9\u7684 IN \u65b9\u5411\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .in ( 'brother' ) ; == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother REVERSELY ; ======================= | brother._dst | ======================= | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # \u8bbf\u95ee\u67d0\u4e2a\u9876\u70b9\u6cbf\u67d0\u6761\u8fb9\u7684\u53cc\u5411\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .both ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother BIDIRECT ; ======================= | brother._dst | ======================= | 6761447489613431910 | ------------------------ | -5860788569139907963 | | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # 2\u5ea6 out \u67e5\u8be2 gremlin> g.V ( hercules ) .out ( 'father' ) .out ( 'lives' ) ; == >v [ 3 ] nebula> GO FROM hash ( \"hercules\" ) OVER father YIELD father._dst AS id | \\ GO FROM $- .id OVER lives ; ======================== | lives._dst | ======================== | -1121386748834253737 | ------------------------","title":"\u8fb9\u7684\u904d\u5386"},{"location":"manual-CN/5.appendix/gremlin-ngql/#has","text":"\u540d\u79f0 Gremlin nGQL \u901a\u8fc7 ID \u6765\u8fc7\u6ee4\u9876\u70b9 hasId(\\ ) FETCH PROP ON \\ \u901a\u8fc7 label \u548c\u5c5e\u6027\u7684\u540d\u5b57\u548c\u503c\u8fc7\u6ee4\u9876\u70b9\u548c\u8fb9 has(\\ , \\ , \\ ) LOOKUP \\ | \\ WHERE \\ # \u67e5\u8be2 ID \u4e3a saturn \u7684\u9876\u70b9 gremlin> g.V () .hasId ( saturn ) ; == >v [ 1 ] nebula> FETCH PROP ON * hash ( \"saturn\" ) ; ========================================================================== | VertexID | character.name | character.age | character.type | ========================================================================== | -4316810810681305233 | saturn | 10000 | titan | -------------------------------------------------------------------------- # \u67e5\u8be2 tag \u4e3a character \u4e14 name \u5c5e\u6027\u503c\u4e3a hercules \u7684\u9876\u70b9 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .valueMap () ; == > [ name: [ hercules ] ,type: [ demigod ] ,age: [ 30 ]] nebula> LOOKUP ON character WHERE character.name == 'hercules' YIELD character.name, character.age, character.type ; ========================================================================= | VertexID | character.name | character.age | character.type | ========================================================================= | 5976696804486077889 | hercules | 30 | demigod | -------------------------------------------------------------------------","title":"has \u6761\u4ef6\u8fc7\u6ee4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_7","text":"\u540d\u79f0 Gremlin nGQL \u6307\u5b9a\u8fd4\u56de\u7ed3\u679c\u884c\u6570 limit() LIMIT \u83b7\u53d6\u540e n \u4e2a\u5143\u7d20 tail() ORDER BY \\ DESC LIMIT \u8df3\u8fc7\u524d n \u4e2a\u5143\u7d20 skip() LIMIT \\ # \u67e5\u8be2\u524d\u4e24\u4e2a\u9876\u70b9 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .limit ( 2 ) ; == >v [ 9 ] == >v [ 10 ] nebula> GO FROM hash ( 'hercules' ) OVER battled | LIMIT 2 ; ======================= | battled._dst | ======================= | 530133512982221454 | ----------------------- | -695163537569412701 | ----------------------- # \u67e5\u8be2\u6700\u540e\u4e00\u4e2a\u9876\u70b9 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .tail ( 1 ) ; == >cerberus nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ; ============ | name | ============ | cerberus | ------------ # \u8df3\u8fc7\u7b2c 1 \u4e2a\u5143\u7d20\u5e76\u8fd4\u56de\u4e00\u4e2a\u5143\u7d20 gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .skip ( 1 ) .limit ( 1 ) ; == >hydra nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ,1 ; ========= | name | ========= | hydra | ---------","title":"\u8fd4\u56de\u7ed3\u679c\u9650\u5236"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_8","text":"\u540d\u79f0 Gremlin nGQL \u6240\u6709\u8def\u5f84 path() FIND ALL PATH \u4e0d\u5305\u542b\u73af\u8def simplePath() \\ \u53ea\u5305\u542b\u73af\u8def cyclicPath() \\ \u6700\u77ed\u8def\u5f84 \\ FIND SHORTEST PATH \u6ce8\u610f\uff1a Nebula Graph \u9700\u8981\u8d77\u59cb\u70b9\u548c\u7ec8\u70b9\u65b9\u53ef\u8fd4\u56de\u8def\u5f84\uff0c Gremlin \u4ec5\u9700\u8981\u8d77\u59cb\u70b9\u3002 # pluto \u9876\u70b9\u5230\u4e0e\u5176\u6709\u76f4\u63a5\u5173\u8054\u7684\u51fa\u8fb9\u9876\u70b9\u7684\u8def\u5f84 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .out () .path () ; == > [ v [ 8 ] ,v [ 12 ]] == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] == > [ v [ 8 ] ,v [ 11 ]] # \u67e5\u8be2\u70b9 pluto \u5230\u70b9 jupiter \u7684\u6700\u77ed\u8def\u5f84 nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ FIND SHORTEST PATH FROM $- .VertexID TO hash ( \"jupiter\" ) OVER * ; ============================================================ | _path_ | ============================================================ | 6761447489613431910 <brother,0> 4863977009196259577 ------------------------------------------------------------","title":"\u8def\u5f84\u67e5\u8be2"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_9","text":"\u540d\u79f0 Gremlin nGQL \u6307\u5b9a\u91cd\u590d\u6267\u884c\u7684\u8bed\u53e5 repeat() N STEPS \u6307\u5b9a\u91cd\u590d\u6267\u884c\u7684\u6b21\u6570 times() N STEPS \u6307\u5b9a\u5faa\u73af\u7ec8\u6b62\u7684\u6761\u4ef6 until() \\ \u6307\u5b9a\u6536\u96c6\u6570\u636e\u7684\u6761\u4ef6 emit() \\ # \u67e5\u8be2\u70b9 pluto \u51fa\u8fb9\u90bb\u70b9 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .repeat ( out ()) .times ( 1 ) ; == >v [ 12 ] == >v [ 2 ] == >v [ 5 ] == >v [ 11 ] nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ GO FROM $- .VertexID OVER * ; ================================================================================================================ | father._dst | brother._dst | lives._dst | mother._dst | pet._dst | battled._dst | ================================================================================================================ | 0 | -5860788569139907963 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 4863977009196259577 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | -4331657707562925133 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | 0 | 0 | 4594048193862126013 | 0 | ---------------------------------------------------------------------------------------------------------------- # \u67e5\u8be2\u9876\u70b9 hercules \u5230\u9876\u70b9 cerberus \u4e4b\u95f4\u7684\u8def\u5f84 # \u5faa\u73af\u7684\u7ec8\u6b62\u6761\u4ef6\u662f\u9047\u5230\u540d\u79f0\u662f cerberus \u7684\u9876\u70b9 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .until ( has ( 'name' , 'cerberus' )) .path () ; == > [ v [ 6 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 8 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 5 ] ,v [ 8 ] ,v [ 11 ]] ... nebula> # Coming soon # \u67e5\u8be2\u70b9 hercules \u7684\u6240\u6709\u51fa\u8fb9\u53ef\u5230\u8fbe\u70b9\u7684\u8def\u5f84 # \u4e14\u7ec8\u70b9\u5fc5\u987b\u662f character \u7c7b\u578b\u7684\u70b9 gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .emit ( hasLabel ( 'character' )) .path () ; == > [ v [ 6 ] ,v [ 7 ]] == > [ v [ 6 ] ,v [ 2 ]] == > [ v [ 6 ] ,v [ 9 ]] == > [ v [ 6 ] ,v [ 10 ]] ... nebula> # Coming soon # \u67e5\u8be2\u4e24\u9876\u70b9 pluto \u548c saturn \u4e4b\u95f4\u7684\u6700\u77ed\u8def\u5f84 # \u4e14\u6700\u5927\u6df1\u5ea6\u4e3a 3 gremlin> g.V ( 'pluto' ) .repeat ( out () .simplePath ()) .until ( hasId ( 'saturn' ) .and () .loops () .is ( lte ( 3 ))) .hasId ( 'saturn' ) .path () ; nebula> FIND SHORTEST PATH FROM hash ( 'pluto' ) TO hash ( 'saturn' ) OVER * UPTO 3 STEPS ; ================================================================================================= | _path_ | ================================================================================================= | 6761447489613431910 <brother,0> 4863977009196259577 <father,0> -4316810810681305233 -------------------------------------------------------------------------------------------------","title":"\u591a\u5ea6\u67e5\u8be2"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_10","text":"\u540d\u79f0 Gremlin nGQL \u5347\u5e8f\u6392\u5217 order().by() ORDER BY \u964d\u5e8f\u6392\u5217 order().by(decr) ORDER BY DESC \u968f\u673a\u6392\u5217 order().by(shuffle) \\ # \u67e5\u8be2 pluto \u7684\u5144\u5f1f\u5e76\u6309\u7167\u5e74\u9f84\u964d\u5e8f\u6392\u5217 gremlin> g.V ( pluto ) .out ( 'brother' ) .order () .by ( 'age' , decr ) .valueMap () ; == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] == > [ name: [ neptune ] ,type: [ god ] ,age: [ 4500 ]] nebula> GO FROM hash ( 'pluto' ) OVER brother YIELD $$ .character.name AS Name, $$ .character.age as Age | ORDER BY Age DESC ; ================== | Name | Age | ================== | jupiter | 5000 | ------------------ | neptune | 4500 | ------------------","title":"\u67e5\u8be2\u7ed3\u679c\u6392\u5e8f"},{"location":"manual-CN/5.appendix/gremlin-ngql/#group_by","text":"\u540d\u79f0 Gremlin nGQL \u5bf9\u7ed3\u679c\u96c6\u8fdb\u884c\u5206\u7ec4 group().by() GROUP BY \u53bb\u9664\u76f8\u540c\u5143\u7d20 dedup() DISTINCT \u5bf9\u7ed3\u679c\u96c6\u8fdb\u884c\u5206\u7ec4\u5e76\u7edf\u8ba1 groupCount() GROUP BY COUNT \u6ce8\u610f\uff1a GROUP BY \u51fd\u6570\u53ea\u80fd\u4e0e YIELD \u8bed\u53e5\u4e00\u8d77\u4f7f\u7528\u3002 # \u6839\u636e\u9876\u70b9\u7c7b\u522b\u8fdb\u884c\u5206\u7ec4\u5e76\u7edf\u8ba1\u5404\u4e2a\u7c7b\u522b\u7684\u6570\u91cf gremlin> g.V () .group () .by ( label ) .by ( count ()) ; == > [ character:9,location:3 ] nebula> # Coming soon # \u67e5\u8be2\u70b9 jupiter \u51fa\u8fb9\u90bb\u70b9\uff0c\u4f7f\u7528 name \u5206\u7ec4\u5e76\u7edf\u8ba1 gremlin> g.V ( jupiter ) .out () .group () .by ( 'name' ) .by ( count ()) ; == > [ sky:1,saturn:1,neptune:1,pluto:1 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD $$ .character.name AS Name, $$ .character.age as Age, $$ .location.name | \\ GROUP BY $- .Name YIELD $- .Name, COUNT ( * ) ; ====================== | $- .Name | COUNT ( * ) | ====================== | | 1 | ---------------------- | pluto | 1 | ---------------------- | saturn | 1 | ---------------------- | neptune | 1 | ---------------------- # \u67e5\u627e\u70b9 jupiter \u51fa\u8fb9\u5230\u8fbe\u7684\u70b9\u5e76\u53bb\u91cd gremlin> g.V ( jupiter ) .out () .hasLabel ( 'character' ) .dedup () ; == >v [ 1 ] == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD DISTINCT $$ .character.name, $$ .character.age, $$ .location.name ; =========================================================== | $$ .character.name | $$ .character.age | $$ .location.name | =========================================================== | pluto | 4000 | | ----------------------------------------------------------- | neptune | 4500 | | ----------------------------------------------------------- | saturn | 10000 | | ----------------------------------------------------------- | | 0 | sky | -----------------------------------------------------------","title":"Group By"},{"location":"manual-CN/5.appendix/gremlin-ngql/#where","text":"\u540d\u79f0 Gremlin nGQL where \u6761\u4ef6\u8fc7\u6ee4 where() WHERE \u8fc7\u6ee4\u6761\u4ef6\u5bf9\u6bd4\uff1a \u540d\u79f0 Gremlin nGQL \u7b49\u4e8e eq(object) == \u4e0d\u7b49\u4e8e neq(object) != \u5c0f\u4e8e lt(number) < \u5c0f\u4e8e\u7b49\u4e8e lte(number) <= \u5927\u4e8e gt(number) > \u5927\u4e8e\u7b49\u4e8e gte(number) >= \u5224\u65ad\u503c\u662f\u5426\u5728\u6307\u5b9a\u7684\u5217\u8868\u4e2d within(objects\u2026\u200b) udf_is_in() gremlin> eq ( 2 ) .test ( 3 ) ; == >false nebula> YIELD 3 == 2 ; ========== | ( 3 == 2 ) | ========== | false | ---------- gremlin> within ( 'a' , 'b' , 'c' ) .test ( 'd' ) ; == >false nebula> YIELD udf_is_in ( 'd' , 'a' , 'b' , 'c' ) ; ====================== | udf_is_in ( d,a,b,c ) | ====================== | false | ---------------------- # \u627e\u51fa pluto \u548c\u8c01\u4f4f\u5e76\u6392\u961f\u4ed6\u672c\u4eba gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | ---------------","title":"where \u6761\u4ef6\u8fc7\u6ee4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_11","text":"\u540d\u79f0 Gremlin nGQL Is is() == Not not() != And and() AND Or or() OR # \u67e5\u8be2\u5e74\u9f84\u5927\u4e8e 30 \u7684\u4eba\u7269 gremlin> g.V () .values ( 'age' ) .is ( gte ( 30 )) ; == >10000 == >5000 == >4500 == >30 == >45 == >4000 nebula> LOOKUP ON character WHERE character.age > = 30 YIELD character.age ; ======================================== | VertexID | character.age | ======================================== | -4316810810681305233 | 10000 | ---------------------------------------\u2013 | 4863977009196259577 | 5000 | ---------------------------------------\u2013 | -5860788569139907963 | 4500 | ---------------------------------------\u2013 | 5976696804486077889 | 30 | ---------------------------------------\u2013 | -6780323075177699500 | 45 | ---------------------------------------\u2013 | 6761447489613431910 | 4000 | ---------------------------------------\u2013 # \u67e5\u8be2\u540d\u79f0\u4e3a pluto \u4e14\u5e74\u9f84\u4e3a 4000 \u7684\u4eba\u7269 gremlin> g.V () .has ( 'name' , 'pluto' ) .and () .has ( 'age' ,4000 ) ; == >v [ 8 ] nebula> LOOKUP ON character WHERE character.name == 'pluto' AND character.age == 4000 ; ======================= | VertexID | ======================= | 6761447489613431910 | ----------------------- # \u903b\u8f91\u975e\u7684\u7528\u6cd5 gremlin> g.V () .has ( 'name' , 'pluto' ) .out ( 'brother' ) .not ( values ( 'name' ) .is ( 'neptune' )) .values ( 'name' ) ; == >jupiter nebula> LOOKUP ON character WHERE character.name == 'pluto' YIELD character.name AS name | \\ GO FROM $- .VertexID OVER brother WHERE $$ .character.name ! = 'neptune' YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | ---------------------","title":"\u903b\u8f91\u8fd0\u7b97"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_12","text":"\u540d\u79f0 Gremlin nGQL \u6c42\u548c sum() SUM() \u6700\u5927\u503c max() MAX() \u6700\u5c0f\u503c min() MIN() \u5e73\u5747\u503c mean() AVG() Nebula Graph \u7edf\u8ba1\u8fd0\u7b97\u5fc5\u987b\u540c GROUP BY \u4e00\u8d77\u4f7f\u7528\u3002 # \u8ba1\u7b97\u6240\u6709 character \u7684\u5e74\u9f84\u7684\u603b\u548c gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .sum () ; == >23595 nebula> # Coming soon # \u8ba1\u7b97\u6240\u6709 character \u7684 brother \u51fa\u8fb9\u6570\u7684\u603b\u548c gremlin> g.V () .hasLabel ( 'character' ) .map ( outE ( 'brother' ) .count ()) .sum () ; == >6 nebula> # Coming soon # \u8fd4\u56de\u6240\u6709 character \u7684\u5e74\u9f84\u4e2d\u7684\u6700\u5927\u503c gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .max () ; == >10000 nebula> # Coming soon","title":"\u7edf\u8ba1\u8fd0\u7b97"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_13","text":"# \u4ece\u8def\u5f84\u4e2d\u9009\u53d6\u7b2c 1 \u6b65\u548c\u7b2c 3 \u6b65\u7684\u7ed3\u679c\u4f5c\u4e3a\u6700\u7ec8\u7ed3\u679c gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) ; == > [ a:v [ 8 ] ,c:v [ 3 ]] == > [ a:v [ 8 ] ,c:v [ 1 ]] ... nebula> # Coming soon # \u901a\u8fc7 by() \u6307\u5b9a\u9009\u53d6\u7684\u7ef4\u5ea6 gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:pluto,c:sky ] == > [ a:pluto,c:saturn ] ... nebula> # Coming soon # \u4ece map \u4e2d\u9009\u62e9\u6307\u5b9a key \u7684\u503c gremlin> g.V () .valueMap () .select ( 'name' ) .dedup () ; == > [ saturn ] == > [ jupiter ] ... nebula> # Coming soon","title":"\u8def\u5f84\u9009\u53d6\u4e0e\u8fc7\u6ee4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_14","text":"# \u67e5\u627e\u6240\u6709\u7c7b\u578b\u4e3a 'character' \u7684\u9876\u70b9 # name \u5c5e\u6027\u4e3a 'jupiter' \u7684\u9876\u70b9\u8f93\u51fa\u5176 age \u5c5e\u6027 # \u5426\u5219\u8f93\u51fa\u9876\u70b9\u7684 name \u5c5e\u6027 gremlin> g.V () .hasLabel ( 'character' ) .choose ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 == >neptune ... # Lambda gremlin> g.V () .branch { it.get () .value ( 'name' )} .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 ... # Traversal gremlin> g.V () .branch ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 # Branch gremlin> g.V () .choose ( has ( 'name' , 'jupiter' ) ,values ( 'age' ) ,values ( 'name' )) ; == >saturn == >5000 # \u57fa\u4e8e if then \u8fdb\u884c\u5206\u7ec4 gremlin> g.V () .hasLabel ( \"character\" ) .groupCount () .by ( values ( \"age\" ) .choose ( is ( lt ( 40 )) ,constant ( \"young\" ) , choose ( is ( lt ( 4500 )) , constant ( \"old\" ) , constant ( \"very old\" )))) ; == > [ young:4,old:2,very old:3 ] Nebula Graph \u5c1a\u65e0\u7c7b\u4f3c\u529f\u80fd\u3002","title":"\u5206\u652f"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_15","text":"coalesce() \u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u6570\u91cf\u7684\u904d\u5386\u5668\uff08traversal\uff09\uff0c\u6309\u987a\u5e8f\u6267\u884c\uff0c\u5e76\u8fd4\u56de\u7b2c\u4e00\u4e2a\u80fd\u4ea7\u751f\u8f93\u51fa\u7684\u904d\u5386\u5668\u7684\u7ed3\u679c\u3002 optional() \u53ea\u80fd\u63a5\u53d7\u4e00\u4e2a\u904d\u5386\u5668\uff08traversal\uff09\uff0c\u5982\u679c\u8be5\u904d\u5386\u5668\u80fd\u4ea7\u751f\u4e00\u4e2a\u7ed3\u679c\uff0c\u5219\u8fd4\u56de\u8be5\u7ed3\u679c\uff0c\u5426\u5219\u8fd4\u56de\u8c03\u7528 optionalStep \u7684\u5143\u7d20\u672c\u8eab\u3002 union() \u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u6570\u91cf\u7684\u904d\u5386\u5668\uff0c\u5e76\u80fd\u591f\u5c06\u5404\u4e2a\u904d\u5386\u5668\u7684\u8f93\u51fa\u5408\u5e76\u5230\u4e00\u8d77\u3002 # \u5982\u679c\u7c7b\u578b\u4e3a monster \u5219\u8fd4\u56de\u7c7b\u578b\u5426\u5219\u8fd4\u56de 'Not a monster' gremlin> g.V ( pluto ) .coalesce ( has ( 'type' , 'monster' ) .values ( 'type' ) ,constant ( \"Not a monster\" )) ; == >Not a monster # \u6309\u4f18\u5148\u7ea7\u5bfb\u627e\u5230\u9876\u70b9 jupiter \u7684\u4ee5\u4e0b\u8fb9\u548c\u90bb\u63a5\u70b9\uff0c\u627e\u5230\u4e00\u4e2a\u5c31\u505c\u6b62 # 1\u3001brother \u51fa\u8fb9\u548c\u90bb\u63a5\u70b9 # 2\u3001father \u51fa\u8fb9\u548c\u90bb\u63a5\u70b9 # 3\u3001father \u5165\u8fb9\u548c\u90bb\u63a5\u70b9 gremlin> g.V ( jupiter ) .coalesce ( outE ( 'brother' ) , outE ( 'father' ) , inE ( 'father' )) .inV () .path () .by ( 'name' ) .by ( label ) ; == > [ jupiter,brother,pluto ] == > [ jupiter,brother,neptune ] # \u67e5\u627e\u9876\u70b9 pluto \u7684 father \u51fa\u9876\u70b9\uff0c\u5982\u679c\u6ca1\u6709\u5c31\u8fd4\u56de pluto \u81ea\u5df1 gremlin> g.V ( pluto ) .optional ( out ( 'father' )) .valueMap () ; == > [ name: [ pluto ] ,type: [ god ] ,age: [ 4000 ]] # \u5bfb\u627e\u9876\u70b9 pluto \u7684\u51fa father \u9876\u70b9\uff0c\u90bb\u63a5 brother \u9876\u70b9\uff0c\u5e76\u5c06\u7ed3\u679c\u5408\u5e76\uff0c\u6700\u540e\u6253\u5370\u51fa\u8def\u5f84 gremlin> g.V ( pluto ) .union ( out ( 'father' ) ,both ( 'brother' )) .path () ; == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] Nebula Graph \u5c1a\u65e0\u7c7b\u4f3c\u529f\u80fd\u3002","title":"\u5408\u5e76"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_16","text":"# \u6536\u96c6\u7b2c 1 \u6b65\u7684\u7ed3\u679c\u5230\u96c6\u5408 x \u4e2d # \u6ce8\u610f\uff1a\u4e0d\u5f71\u54cd\u540e\u7eed\u7ed3\u679c gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) ; == >v [ 12 ] == >v [ 2 ] ... # \u901a\u8fc7 by() \u6307\u5b9a\u805a\u96c6\u7684\u7ef4\u5ea6 gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .by ( 'name' ) .cap ( 'x' ) ; == > [ tartarus,jupiter,neptune,cerberus ] # \u67e5\u8be2\u4e0e pluto \u7684\u4e24\u5ea6 OUT \u90bb\u5c45 # \u5e76\u6536\u96c6\u8fd9\u4e9b\u5230 x \u96c6\u5408\u91cc\u9762 # \u6700\u7ec8\u4ee5 name \u5c5e\u6027\u5c55\u793a\u5176\u90bb\u5c45 gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .out () .aggregate ( 'x' ) .cap ( 'x' ) .unfold () .values ( 'name' ) ; == >tartarus == >tartarus ... Nebula Graph \u5c1a\u65e0\u7c7b\u4f3c\u529f\u80fd\u3002","title":"\u7ed3\u679c\u805a\u96c6\u4e0e\u5c55\u5f00"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_17","text":"match() \u8bed\u53e5\u4e3a\u56fe\u67e5\u8be2\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u5f0f\u5339\u914d\u7684\u65b9\u5f0f\uff0c\u4ee5\u4fbf\u7528\u66f4\u5177\u63cf\u8ff0\u6027\u7684\u65b9\u5f0f\u8fdb\u884c\u56fe\u67e5\u8be2\u3002match()\u8bed\u53e5\u901a\u8fc7\u591a\u4e2a\u6a21\u5f0f\u7247\u6bb5 traversal fragments \u6765\u8fdb\u884c\u6a21\u5f0f\u5339\u914d\u3002\u8fd9\u4e9b traversal fragments \u4e2d\u4f1a\u5b9a\u4e49\u4e00\u4e9b\u53d8\u91cf\uff0c\u53ea\u6709\u6ee1\u8db3\u6240\u6709\u7528\u53d8\u91cf\u8868\u793a\u7684\u7ea6\u675f\u7684\u5bf9\u8c61\u624d\u80fd\u591f\u901a\u8fc7\u3002 # \u5bf9\u6bcf\u4e00\u4e2a\u9876\u70b9\uff0c\u7528\u4ee5\u4e0b\u6a21\u5f0f\u53bb\u5339\u914d\uff0c\u6ee1\u8db3\u5219\u751f\u6210\u4e00\u4e2a map<String, Object>\uff0c\u4e0d\u6ee1\u8db3\u5219\u8fc7\u6ee4\u6389 # \u6a21\u5f0f1\uff1aa \u4e3a\u6cbf father \u51fa\u8fb9\u6307\u5411 jupiter \u7684\u9876\u70b9 # \u6a21\u5f0f2\uff1ab \u5bf9\u5e94\u5f53\u524d\u9876\u70b9 jupiter # \u6a21\u5f0f3\uff1ac \u5bf9\u5e94\u521b\u5efa jupiter \u7684 brother \u5e74\u9f84\u4e3a 4000 \u7684 \u9876\u70b9 gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) ; == > [ a:v [ 6 ] ,b:v [ 2 ] ,c:v [ 8 ]] # match() \u8bed\u53e5\u53ef\u4ee5\u4e0e select() \u8bed\u53e5\u914d\u5408\u4f7f\u7528\uff0c\u4ece Map<String, Object> \u4e2d\u9009\u53d6\u90e8\u5206\u7ed3\u679c gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ] # match() \u8bed\u53e5\u53ef\u4ee5\u4e0e where() \u8bed\u53e5\u914d\u5408\u4f7f\u7528\uff0c\u8fc7\u6ee4\u7ed3\u679c gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .where ( 'a' , neq ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ]","title":"\u6a21\u5f0f\u5339\u914d"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_18","text":"sample() \u63a5\u53d7\u4e00\u4e2a\u6574\u6570\u503c\uff0c\u4ece\u524d\u4e00\u6b65\u7684\u904d\u5386\u5668\u4e2d\u91c7\u6837\uff08\u968f\u673a\uff09\u51fa\u6700\u591a\u6307\u5b9a\u6570\u76ee\u7684\u7ed3\u679c\u3002 coin() \u5b57\u9762\u610f\u601d\u662f\u629b\u786c\u5e01\u8fc7\u6ee4\uff0c\u63a5\u53d7\u4e00\u4e2a\u6d6e\u70b9\u503c\uff0c\u8be5\u6d6e\u70b9\u503c\u8868\u793a\u786c\u5e01\u51fa\u73b0\u6b63\u9762\u7684\u6982\u7387\u3002 # \u4ece\u6240\u6709\u9876\u70b9\u7684\u51fa\u8fb9\u4e2d\u968f\u673a\u9009\u62e9 2 \u6761 gremlin> g.V () .outE () .sample ( 2 ) ; == >e [ 15 ][ 2 -brother->5 ] == >e [ 18 ][ 5 -brother->2 ] # \u4ece\u6240\u9876\u70b9\u7684 name \u5c5e\u6027\u4e2d\u968f\u673a\u9009\u53d6 3 \u4e2a gremlin> g.V () .values ( 'name' ) .sample ( 3 ) ; == >hercules == >sea == >jupiter # \u4ece\u6240\u6709\u7684 character \u4e2d\u6839\u636e age \u968f\u673a\u9009\u62e9 3 \u4e2a gremlin> g.V () .hasLabel ( 'character' ) .sample ( 3 ) .by ( 'age' ) ; == >v [ 1 ] == >v [ 2 ] == >v [ 6 ] # \u4e0e local \u8054\u5408\u4f7f\u7528\u505a\u968f\u673a\u6f2b\u6e38 # \u4ece\u9876\u70b9 pluto \u51fa\u53d1\u505a 3 \u6b21\u968f\u673a\u6f2b\u6e38 gremlin> g.V ( pluto ) .repeat ( local ( bothE () .sample ( 1 ) .otherV ())) .times ( 3 ) .path () ; == > [ v [ 8 ] ,e [ 26 ][ 8 -brother->5 ] ,v [ 5 ] ,e [ 18 ][ 5 -brother->2 ] ,v [ 2 ] ,e [ 13 ][ 2 -father->1 ] ,v [ 1 ]] # \u6bcf\u4e2a\u9876\u70b9\u6309 0.5 \u7684\u6982\u7387\u8fc7\u6ee4 gremlin> g.V () .coin ( 0 .5 ) ; == >v [ 1 ] == >v [ 2 ] ... # \u8f93\u51fa\u6240\u6709 location \u7c7b\u9876\u70b9\u7684 name \u5c5e\u6027\uff0c\u5426\u5219\u8f93\u51fa not a location gremlin> g.V () .choose ( hasLabel ( 'location' ) , values ( 'name' ) , constant ( 'not a location' )) ; == >not a location == >not a location == >sky ...","title":"\u968f\u673a\u8fc7\u6ee4"},{"location":"manual-CN/5.appendix/gremlin-ngql/#sack","text":"\u5305\u542b\u672c\u5730\u6570\u636e\u7ed3\u6784\u7684\u904d\u5386\u5668\u79f0\u4e3a\u53e3\u888b\u3002 sack() \u5c06\u6570\u636e\u653e\u5165\u53e3\u888b\uff0c\u6216\u8005\u4ece\u53e3\u888b\u53d6\u51fa\u6570\u636e\u3002\u6bcf\u4e2a\u904d\u5386\u5668\u7684\u6bcf\u4e2a\u53e3\u888b\u90fd\u662f\u901a\u8fc7 withSack\uff08\uff09 \u521b\u5efa\u7684\u3002 # \u521b\u5efa\u4e00\u4e2a\u5305\u542b\u5e38\u6570 1 \u7684\u53e3\u888b\uff0c\u5e76\u4e14\u5728\u6700\u7ec8\u53d6\u51fa\u53e3\u888b\u4e2d\u7684\u503c gremlin> g.withSack ( 1 ) .V () .sack () ; == >1 == >1 ...","title":"\u7ed3\u679c\u5b58\u53d6\u53e3\u888b Sack"},{"location":"manual-CN/5.appendix/gremlin-ngql/#barrier","text":"barrier() \u5728\u67d0\u4e2a\u4f4d\u7f6e\u63d2\u5165\u4e00\u4e2a\u6805\u680f\uff0c\u4ee5\u5f3a\u5236\u8be5\u4f4d\u7f6e\u4e4b\u524d\u7684\u6b65\u9aa4\u5fc5\u987b\u90fd\u6267\u884c\u5b8c\u6210\u624d\u53ef\u4ee5\u7ee7\u7eed\u5f80\u540e\u6267\u884c\u3002 # \u5229\u7528\u9690\u5f0f barrier \u8ba1\u7b97\u7279\u5f81\u5411\u91cf\u4e2d\u5fc3\u6027 # \u5305\u62ec groupCount\u3001cap\uff0c\u6309\u7167\u964d\u5e8f\u6392\u5e8f gremlin> g.V () .repeat ( both () .groupCount ( 'm' )) .times ( 5 ) .cap ( 'm' ) .order ( local ) .by ( values, decr ) ;","title":"\u904d\u5386\u6805\u680f barrier"},{"location":"manual-CN/5.appendix/gremlin-ngql/#local","text":"\u901a\u8fc7 Gremlin \u8fdb\u884c\u56fe\u904d\u5386\u901a\u5e38\u662f\u5f53\u524d step \u5904\u7406\u524d\u4e00 step \u4f20\u9012\u8fc7\u6765\u7684\u5bf9\u8c61\u6d41\u3002\u5f88\u591a\u64cd\u4f5c\u662f\u9488\u5bf9\u4f20\u9012\u8fc7\u6765\u7684\u5bf9\u8c61\u6d41\u4e2d\u7684\u5168\u90e8\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\uff0c\u4f46\u4e5f\u6709\u5f88\u591a\u65f6\u5019\u9700\u8981\u9488\u5bf9\u5bf9\u8c61\u6d41\u4e2d\u7684\u5355\u4e2a\u5bf9\u8c61\u800c\u975e\u5bf9\u8c61\u6d41\u4e2d\u7684\u5168\u90e8\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\u3002\u8fd9\u79cd\u5bf9\u5355\u4e2a\u5bf9\u8c61\u7684\u5c40\u90e8\u64cd\u4f5c\uff0c\u53ef\u4ee5\u4f7f\u7528 local() \u8bed\u53e5\u5b9e\u73b0\u3002 # \u4e0d\u4f7f\u7528 local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .properties ( 'age' ) .order () .by ( value,decr ) .limit ( 2 ) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () ; == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] # \u4f7f\u7528 local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .local ( properties ( 'age' ) .order () .by ( value ) .limit ( 2 )) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] == > [ character:neptune,age:4500 ] == > [ character:hercules,age:30 ] ... # \u67e5\u8be2 monster \u7684\u5c5e\u6027 map gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'type' ) .propertyMap () ; == > [ name: [ vp [ name->nemean ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->20 ]]] == > [ name: [ vp [ name->hydra ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] == > [ name: [ vp [ name->cerberus ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] # \u67e5\u8be2 monster \u7684\u5c5e\u6027\u4e2a\u6570 gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'monster' ) .propertyMap () .count ( local ) ; == >3 == >3 == >3 # \u6570\u76ee\u6700\u591a\u7684\u9876\u70b9\u7c7b\u578b\u7684\u9876\u70b9\u6570\u76ee gremlin> g.V () .groupCount () .by ( label ) .select ( values ) .max ( local ) ; == >9 # \u6240\u6709\u9876\u70b9\u7684\u5c5e\u6027\u5217\u8868\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5c5e\u6027 gremlin> g.V () .valueMap () .limit ( local, 1 ) ; == > [ name: [ saturn ]] == > [ name: [ jupiter ]] == > [ name: [ sky ]] ... # \u4e0d\u52a0 local gremlin> g.V () .valueMap () .limit ( 1 ) ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] # \u6240\u6709\u9876\u70b9\u4f5c\u4e3a\u4e00\u4e2a\u96c6\u5408\uff0c\u4ece\u4e2d\u91c7\u6837 2 \u4e2a gremlin> g.V () .fold () .sample ( local,2 ) ; == > [ v [ 8 ] ,v [ 1 ]]","title":"\u5c40\u90e8\u64cd\u4f5c local"},{"location":"manual-CN/5.appendix/gremlin-ngql/#_19","text":"Gremlin \u63d0\u4f9b\u4e24\u79cd\u8bed\u53e5\u5bf9\u6267\u884c\u7684\u67e5\u8be2\u8bed\u53e5\u8fdb\u884c\u7edf\u8ba1\u548c\u5206\u6790\uff1a explain() \uff0c\u8be6\u7ec6\u63cf\u8ff0\u539f\u59cb\u7684 Gremlin \u8bed\u53e5\u5728\u7f16\u8bd1\u671f\u662f\u5982\u4f55\u8f6c\u53d8\u4e3a\u6700\u7ec8\u8981\u6267\u884c\u7684 step \u96c6\u5408\u7684 profile() \uff0c\u7edf\u8ba1 Gremlin \u8bed\u53e5\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u6bcf\u4e2a step \u6d88\u8017\u7684\u65f6\u95f4\u548c\u901a\u8fc7\u7684\u5bf9\u8c61\u7b49\u7edf\u8ba1\u4fe1\u606f # explain() gremlin> g.V () .hasLabel ( 'character' ) .explain () ; == >Traversal Explanation ========================================================================================== Original Traversal [ GraphStep ( vertex, []) , HasStep ([ ~label.eq ( character )])] ConnectiveStrategy [ D ] [ GraphStep ( vertex, []) , HasStep ([ ~label.eq ( character )])] MatchPredicateStrategy [ O ] [ GraphStep ( vertex, []) , HasStep ([ ~label.eq ( character )])] ... StandardVerificationStrategy [ V ] [ TinkerGraphStep ( vertex, [ ~label.eq ( character )])] Final Traversal [ TinkerGraphStep ( vertex, [ ~label.eq ( character )])] # profile() gremlin> g.V () .out ( 'father' ) .profile () == >Traversal Metrics Step Count Traversers Time ( ms ) % Dur ============================================================================================================= TinkerGraphStep ( vertex, []) 12 12 0 .644 45 .66 VertexStep ( OUT, [ father ] ,vertex ) 2 2 0 .534 37 .83 NoOpBarrierStep ( 2500 ) 2 2 0 .233 16 .51 >TOTAL - - 1 .411 -","title":"\u6267\u884c\u7edf\u8ba1\u548c\u5206\u6790"},{"location":"manual-CN/5.appendix/upgrade-guide/","text":"Nebula Graph \u5347\u7ea7\u6307\u5357 \u00b6 \u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u5347\u7ea7 Nebula Graph\u3002\u5bf9\u5e94\u7248\u672c\u5347\u7ea7\u6307\u5357\u89c1\u4e0b\u6587\u3002 \u4ece Nebula Graph RC3 \u5347\u7ea7\u81f3 RC4 \u00b6 \u9996\u5148\u505c\u6b62\u6240\u6709\u673a\u5668\u7684 Nebula \u670d\u52a1 \u5728\u6bcf\u4e00\u53f0\u673a\u5668\u6267\u884c scripts/nebula.service stop all \u547d\u4ee4 \u7136\u540e\u6267\u884c scripts/nebula.service status all \u547d\u4ee4\u786e\u8ba4\u8fdb\u7a0b\u5df2\u7ecf\u9000\u51fa \u5728\u6bcf\u4e00\u53f0\u673a\u5668(\u6839\u636e\u7cfb\u7edf\u73af\u5883)\u5b89\u88c5\u65b0\u7684 rpm \u5305 \u4e0b\u8f7d\u5b89\u88c5\u5305\uff1a https://github.com/vesoft-inc/nebula/releases/tag/v1.0.0-rc4 \u5b89\u88c5 Nebula\uff1a rpm -Uvh nebula-1.0.0-rc4.el7-5.x86_64.rpm \u5982\u679c\u4e0b\u8f7d\u901f\u5ea6\u8fc7\u6162\uff0c\u56fd\u5185\u7528\u6237\u53ef\u5728 OSS \u4e0b\u8f7d\u5bf9\u5e94\u5b89\u88c5\u5305\u3002 CentOS 6.5 CentOS 7.5 Ubuntu 16.04 Ubuntu 18.04 \u542f\u52a8 Nebula \u670d\u52a1 \u5728\u6240\u6709\u673a\u5668\u6267\u884c scripts/nebula.service start all \u547d\u4ee4 \u7136\u540e\u6267\u884c scripts/nebula.service status all \u786e\u8ba4\u8fdb\u7a0b\u6b63\u5e38\u542f\u52a8 \u91cd\u65b0\u5bfc\u5165\u6570\u636e","title":"Nebula Graph \u5347\u7ea7\u6307\u5357"},{"location":"manual-CN/5.appendix/upgrade-guide/#nebula_graph","text":"\u672c\u6587\u6863\u4ecb\u7ecd\u5982\u4f55\u5347\u7ea7 Nebula Graph\u3002\u5bf9\u5e94\u7248\u672c\u5347\u7ea7\u6307\u5357\u89c1\u4e0b\u6587\u3002","title":"Nebula Graph \u5347\u7ea7\u6307\u5357"},{"location":"manual-CN/5.appendix/upgrade-guide/#nebula_graph_rc3_rc4","text":"\u9996\u5148\u505c\u6b62\u6240\u6709\u673a\u5668\u7684 Nebula \u670d\u52a1 \u5728\u6bcf\u4e00\u53f0\u673a\u5668\u6267\u884c scripts/nebula.service stop all \u547d\u4ee4 \u7136\u540e\u6267\u884c scripts/nebula.service status all \u547d\u4ee4\u786e\u8ba4\u8fdb\u7a0b\u5df2\u7ecf\u9000\u51fa \u5728\u6bcf\u4e00\u53f0\u673a\u5668(\u6839\u636e\u7cfb\u7edf\u73af\u5883)\u5b89\u88c5\u65b0\u7684 rpm \u5305 \u4e0b\u8f7d\u5b89\u88c5\u5305\uff1a https://github.com/vesoft-inc/nebula/releases/tag/v1.0.0-rc4 \u5b89\u88c5 Nebula\uff1a rpm -Uvh nebula-1.0.0-rc4.el7-5.x86_64.rpm \u5982\u679c\u4e0b\u8f7d\u901f\u5ea6\u8fc7\u6162\uff0c\u56fd\u5185\u7528\u6237\u53ef\u5728 OSS \u4e0b\u8f7d\u5bf9\u5e94\u5b89\u88c5\u5305\u3002 CentOS 6.5 CentOS 7.5 Ubuntu 16.04 Ubuntu 18.04 \u542f\u52a8 Nebula \u670d\u52a1 \u5728\u6240\u6709\u673a\u5668\u6267\u884c scripts/nebula.service start all \u547d\u4ee4 \u7136\u540e\u6267\u884c scripts/nebula.service status all \u786e\u8ba4\u8fdb\u7a0b\u6b63\u5e38\u542f\u52a8 \u91cd\u65b0\u5bfc\u5165\u6570\u636e","title":"\u4ece Nebula Graph RC3 \u5347\u7ea7\u81f3 RC4"},{"location":"manual-EN/","text":"Welcome to the Official Nebula Graph Documentation \u00b6 Nebula Graph is a distributed, scalable, and lightning-fast graph database. It is the optimal solution in the world capable of hosting graphs with dozens of billions of vertices (nodes) and trillions of edges with millisecond latency. Preface \u00b6 About This Manual Manual Change Log Overview (for Beginners) \u00b6 Introduction Concepts Data Model Query Language Overview Quick Start and Useful Links Get Started FAQ Build Source Code Deploy Cluster Import .csv File Ingest .sst File Nebula Graph Clients Design and Architecture Design Overview Storage Architecture Query Engine Query Language (for All Users) \u00b6 Data Types Data Types Type Conversion Functions and Operators Bitwise Operators Built-In Functions Comparison Functions And Operators Group By Function Limit Syntax Logical Operators Order By Function Set Operations uuid Function Language Structure Literal Values Boolean Literals Numeric Literals String Literals Comment Syntax Identifier Case Sensitivity Keywords and Reserved Words Pipe Syntax Property Reference Schema Object Names Statement Composition User-Defined Variables Statement Syntax Data Definition Statements Alter Tag/Edge Syntax Create Space Syntax Create Tag/Edge Syntax Drop Edge Syntax Drop Space Syntax Drop Tag Syntax Index TTL (time-to-live) Data Query and Manipulation Statements Delete Edge Syntax Delete Vertex Syntax Fetch Syntax Go Syntax Insert Edge Syntax Insert Vertex Syntax Lookup Syntax Return Syntax Update Vertex/Edge Syntax Upsert Syntax Where Syntax Yield Syntax Utility Statements Show Statements Show Charset Syntax Show Collation Syntax Show Configs Syntax Show Create Spaces Syntax Show Create Tag/Edge Syntax Show Hosts Syntax Show Indexes Syntax Show Parts Syntax Show Roles Syntax Show Snapshots Syntax Show Spaces Syntax Show Tag/Edge Syntax Show Users Syntax Describe Syntax Use Syntax Graph Algorithms Find Path Syntax Build Develop and Administration (for Developers and DBA) \u00b6 Build Build Source Code Build By Docker Develop and Interface Key Value API Nebula Graph Clients Deploy and Administrations Deployment Configuration Description Deploy Cluster On Docker Deploy Cluster Installation With rpm Server Administration Account Management Statements Alter User Syntax Built-in Roles Change Password Create User Syntax Drop User Syntax Grant Role Syntax Revoke Syntax Configuration Statements Configs Syntax Logs Graph Service Administration Graph Metrics Meta Service Administration Meta Metrics Storage Service Administration Data Import Download And Ingest .sst File Import .csv File Spark Writer Data Export Dump Tool Storage Balance Storage Metrics Cluster Snapshot Job Manager Contributions (for Contributors) \u00b6 Contribute to Documentation Cpp Coding Style Developer Documentation Style Guide How to Contribute Appendix \u00b6 Gremlin V.S. nGQL Cypher V.S. nGQL Upgrading Nebula Graph Misc \u00b6 Video \u00b6 YouTube bilibili","title":"Welcome to the Official Nebula Graph Documentation"},{"location":"manual-EN/#welcome_to_the_official_nebula_graph_documentation","text":"Nebula Graph is a distributed, scalable, and lightning-fast graph database. It is the optimal solution in the world capable of hosting graphs with dozens of billions of vertices (nodes) and trillions of edges with millisecond latency.","title":"Welcome to the Official Nebula Graph Documentation"},{"location":"manual-EN/#preface","text":"About This Manual Manual Change Log","title":"Preface"},{"location":"manual-EN/#overview_for_beginners","text":"Introduction Concepts Data Model Query Language Overview Quick Start and Useful Links Get Started FAQ Build Source Code Deploy Cluster Import .csv File Ingest .sst File Nebula Graph Clients Design and Architecture Design Overview Storage Architecture Query Engine","title":"Overview (for Beginners)"},{"location":"manual-EN/#query_language_for_all_users","text":"Data Types Data Types Type Conversion Functions and Operators Bitwise Operators Built-In Functions Comparison Functions And Operators Group By Function Limit Syntax Logical Operators Order By Function Set Operations uuid Function Language Structure Literal Values Boolean Literals Numeric Literals String Literals Comment Syntax Identifier Case Sensitivity Keywords and Reserved Words Pipe Syntax Property Reference Schema Object Names Statement Composition User-Defined Variables Statement Syntax Data Definition Statements Alter Tag/Edge Syntax Create Space Syntax Create Tag/Edge Syntax Drop Edge Syntax Drop Space Syntax Drop Tag Syntax Index TTL (time-to-live) Data Query and Manipulation Statements Delete Edge Syntax Delete Vertex Syntax Fetch Syntax Go Syntax Insert Edge Syntax Insert Vertex Syntax Lookup Syntax Return Syntax Update Vertex/Edge Syntax Upsert Syntax Where Syntax Yield Syntax Utility Statements Show Statements Show Charset Syntax Show Collation Syntax Show Configs Syntax Show Create Spaces Syntax Show Create Tag/Edge Syntax Show Hosts Syntax Show Indexes Syntax Show Parts Syntax Show Roles Syntax Show Snapshots Syntax Show Spaces Syntax Show Tag/Edge Syntax Show Users Syntax Describe Syntax Use Syntax Graph Algorithms Find Path Syntax","title":"Query Language (for All Users)"},{"location":"manual-EN/#build_develop_and_administration_for_developers_and_dba","text":"Build Build Source Code Build By Docker Develop and Interface Key Value API Nebula Graph Clients Deploy and Administrations Deployment Configuration Description Deploy Cluster On Docker Deploy Cluster Installation With rpm Server Administration Account Management Statements Alter User Syntax Built-in Roles Change Password Create User Syntax Drop User Syntax Grant Role Syntax Revoke Syntax Configuration Statements Configs Syntax Logs Graph Service Administration Graph Metrics Meta Service Administration Meta Metrics Storage Service Administration Data Import Download And Ingest .sst File Import .csv File Spark Writer Data Export Dump Tool Storage Balance Storage Metrics Cluster Snapshot Job Manager","title":"Build Develop and Administration (for Developers and DBA)"},{"location":"manual-EN/#contributions_for_contributors","text":"Contribute to Documentation Cpp Coding Style Developer Documentation Style Guide How to Contribute","title":"Contributions (for Contributors)"},{"location":"manual-EN/#appendix","text":"Gremlin V.S. nGQL Cypher V.S. nGQL Upgrading Nebula Graph","title":"Appendix"},{"location":"manual-EN/#misc","text":"","title":"Misc"},{"location":"manual-EN/#video","text":"YouTube bilibili","title":"Video"},{"location":"manual-EN/0.about-this-manual/","text":"About This Manual \u00b6 This is the Nebula Graph User Manual. It documents Nebula Graph R202004_RC4. For information about which versions have been released, see Release Notes . Who Shall Read This Manual \u00b6 This manual is written for algorithms engineers , data scientists , software developers , database administrators , and all the people who are interested in the Graph Database areas. If you have questions about using Nebula Graph , join the Nebula Graph Community Slack . If you have suggestions concerning additions or corrections to the manual itself, please do not hesitate to open an issue on GitHub . Syntax Conventions \u00b6 Nebula Graph is under constant development, and this User Manual is updated frequently as well. This manual uses certain typographical conventions: Fixed width A fixed-width font is used for ngql statements , code examples , system output , and file names . Bold Bold typeface indicates commands , user types , or interface . UPPERCASE REVERSED KEYWORDS and NON REVERSED KEYWORDS in query-language and code examples are almost always shown in upper case. File Formats \u00b6 The manual source files are written in Markdown format. The HTML version is produced by mkdocs .","title":"Introduction"},{"location":"manual-EN/0.about-this-manual/#about_this_manual","text":"This is the Nebula Graph User Manual. It documents Nebula Graph R202004_RC4. For information about which versions have been released, see Release Notes .","title":"About This Manual"},{"location":"manual-EN/0.about-this-manual/#who_shall_read_this_manual","text":"This manual is written for algorithms engineers , data scientists , software developers , database administrators , and all the people who are interested in the Graph Database areas. If you have questions about using Nebula Graph , join the Nebula Graph Community Slack . If you have suggestions concerning additions or corrections to the manual itself, please do not hesitate to open an issue on GitHub .","title":"Who Shall Read This Manual"},{"location":"manual-EN/0.about-this-manual/#syntax_conventions","text":"Nebula Graph is under constant development, and this User Manual is updated frequently as well. This manual uses certain typographical conventions: Fixed width A fixed-width font is used for ngql statements , code examples , system output , and file names . Bold Bold typeface indicates commands , user types , or interface . UPPERCASE REVERSED KEYWORDS and NON REVERSED KEYWORDS in query-language and code examples are almost always shown in upper case.","title":"Syntax Conventions"},{"location":"manual-EN/0.about-this-manual/#file_formats","text":"The manual source files are written in Markdown format. The HTML version is produced by mkdocs .","title":"File Formats"},{"location":"manual-EN/CHANGELOG/","text":"Manual Changes \u00b6 0.1.5 - 1.0 RC1 0.1.4 - 1.0 beta release 0.1.3 - Add files in manual-CN 0.1.2 - Add files in manual-EN 0.1.1 - Initial release","title":"Manual Changes"},{"location":"manual-EN/CHANGELOG/#manual_changes","text":"0.1.5 - 1.0 RC1 0.1.4 - 1.0 beta release 0.1.3 - Add files in manual-CN 0.1.2 - Add files in manual-EN 0.1.1 - Initial release","title":"Manual Changes"},{"location":"manual-EN/1.overview/","text":"Reader \u00b6 This chapter is for Nebula Graph beginners.","title":"Reader"},{"location":"manual-EN/1.overview/#reader","text":"This chapter is for Nebula Graph beginners.","title":"Reader"},{"location":"manual-EN/1.overview/0.introduction/","text":"Overview of Nebula Graph \u00b6 What is Nebula Graph \u00b6 Nebula Graph is an open source (Apache 2.0 licensed), distributed, scalable, lightning-fast graph database. It is the only solution in the world capable to host graphs with dozens of billions of vertices (nodes) and trillions of edges, while still provides millisecond latency. Nebula Graph's goal is to provide reading, writing, and computing with high concurrency, low latency for super large scale graphs. Nebula Graph is an open source project and we are looking forward to working with the community to popularize and promote the graph database. Main Features of Nebula Graph \u00b6 This section describes some of the important characteristics of Nebula Graph . High performance Nebula Graph provides low latency read and write, while still maintaining high throughput. SQL-like Nebula Graph 's SQL-like query language is easy to understand and powerful enough to meet complex business needs. Secure With role-based access control, Nebula Graph only allows authenticated access. Scalable With shared-nothing distributed architecture, Nebula Graph offers linear scalability. Extensible Nebula Graph supports multiple storage engine types. The query language can be extended to support new algorithms. Transactional With distributed ACID transaction support, Nebula Graph ensures data integrity. Highly available Nebula Graph guarantees high availability even in case of failures.","title":"Overview of Nebula Graph"},{"location":"manual-EN/1.overview/0.introduction/#overview_of_nebula_graph","text":"","title":"Overview of Nebula Graph"},{"location":"manual-EN/1.overview/0.introduction/#what_is_nebula_graph","text":"Nebula Graph is an open source (Apache 2.0 licensed), distributed, scalable, lightning-fast graph database. It is the only solution in the world capable to host graphs with dozens of billions of vertices (nodes) and trillions of edges, while still provides millisecond latency. Nebula Graph's goal is to provide reading, writing, and computing with high concurrency, low latency for super large scale graphs. Nebula Graph is an open source project and we are looking forward to working with the community to popularize and promote the graph database.","title":"What is Nebula Graph"},{"location":"manual-EN/1.overview/0.introduction/#main_features_of_nebula_graph","text":"This section describes some of the important characteristics of Nebula Graph . High performance Nebula Graph provides low latency read and write, while still maintaining high throughput. SQL-like Nebula Graph 's SQL-like query language is easy to understand and powerful enough to meet complex business needs. Secure With role-based access control, Nebula Graph only allows authenticated access. Scalable With shared-nothing distributed architecture, Nebula Graph offers linear scalability. Extensible Nebula Graph supports multiple storage engine types. The query language can be extended to support new algorithms. Transactional With distributed ACID transaction support, Nebula Graph ensures data integrity. Highly available Nebula Graph guarantees high availability even in case of failures.","title":"Main Features of Nebula Graph"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/","text":"Graph Data Modeling \u00b6 This guide is designed to walk you through the graph data modeling of Nebula Graph . Basic concepts of designing a graph data model will be introduced. Graph Space \u00b6 Graph Space is a physically isolated space for different graph. It is similar to database in MySQL. Directed Property Graph \u00b6 The data model handled by the Nebula Graph is a directed property graph , whose edges are directional and there could be properties on both edges and vertices. It can be represented as: G = < V, E, P V , P E >, where V is a set of nodes aka vertices, E is a set of directional edges, P V represents properties on vertices, and P E is the properties on edges. We will use the example graph below to introduce the basic concepts of property graph: In the preceding picture, we have a data set about the players and teams information of NBA. We can see the eleven vertices are classified to two kinds, i.e. player and name while the fifteen edges are classified to serve and like . To better understand the elements of a graph data model, let us walk through each concept of the example graph. Vertices \u00b6 Vertices are typically used to represent entities in the real world. In the preceding example, the graph contains eleven vertices. Tags \u00b6 In Nebula Graph , vertex properties are clustered by tags . In the example above, the vertices have tags player and team . Edge \u00b6 Edges are used to connect vertices. Each edge usually represents a relationship or a behavior between two vertices. In the preceding example, edges are serve and like . Edge Type \u00b6 Each edge is an instance of an edge type. Our example uses serve and like as edge types. Take edge serve for example, in the preceding picture, vertex 101 (represents a player ) is the source vertex and vertex 215 (represents a team ) is the target vertex. We see that vertex 101 has an outgoing edge while vertex 215 has an incoming edge. Properties \u00b6 Properties are named-value pairs within vertices and edges. In our example graph, we have used the properties id , name and age on player , id and name on team , and likeness on like edge. Schema \u00b6 In Nebula Graph , schema refers to the definition of properties (name, type, etc.). Like MySQL , Nebula Graph is a strong typed database. The name and data type of the properties should be determined before the data is written.","title":"Data Model"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#graph_data_modeling","text":"This guide is designed to walk you through the graph data modeling of Nebula Graph . Basic concepts of designing a graph data model will be introduced.","title":"Graph Data Modeling"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#graph_space","text":"Graph Space is a physically isolated space for different graph. It is similar to database in MySQL.","title":"Graph Space"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#directed_property_graph","text":"The data model handled by the Nebula Graph is a directed property graph , whose edges are directional and there could be properties on both edges and vertices. It can be represented as: G = < V, E, P V , P E >, where V is a set of nodes aka vertices, E is a set of directional edges, P V represents properties on vertices, and P E is the properties on edges. We will use the example graph below to introduce the basic concepts of property graph: In the preceding picture, we have a data set about the players and teams information of NBA. We can see the eleven vertices are classified to two kinds, i.e. player and name while the fifteen edges are classified to serve and like . To better understand the elements of a graph data model, let us walk through each concept of the example graph.","title":"Directed Property Graph"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#vertices","text":"Vertices are typically used to represent entities in the real world. In the preceding example, the graph contains eleven vertices.","title":"Vertices"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#tags","text":"In Nebula Graph , vertex properties are clustered by tags . In the example above, the vertices have tags player and team .","title":"Tags"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#edge","text":"Edges are used to connect vertices. Each edge usually represents a relationship or a behavior between two vertices. In the preceding example, edges are serve and like .","title":"Edge"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#edge_type","text":"Each edge is an instance of an edge type. Our example uses serve and like as edge types. Take edge serve for example, in the preceding picture, vertex 101 (represents a player ) is the source vertex and vertex 215 (represents a team ) is the target vertex. We see that vertex 101 has an outgoing edge while vertex 215 has an incoming edge.","title":"Edge Type"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#properties","text":"Properties are named-value pairs within vertices and edges. In our example graph, we have used the properties id , name and age on player , id and name on team , and likeness on like edge.","title":"Properties"},{"location":"manual-EN/1.overview/1.concepts/1.data-model/#schema","text":"In Nebula Graph , schema refers to the definition of properties (name, type, etc.). Like MySQL , Nebula Graph is a strong typed database. The name and data type of the properties should be determined before the data is written.","title":"Schema"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/","text":"Nebula Graph Query Language (nGQL) \u00b6 About nGQL \u00b6 nGQL is a declarative, textual query language like SQL, but for graphs. Unlike SQL, nGQL is all about expressing graph patterns. nGQL is a work in progress. We will add more features and further simplify the existing ones. There might be inconsistency between the syntax specs and implementation for the time being. Goals \u00b6 Easy to learn Easy to understand To focus on the online queries, also to provide the foundation for the offline computation Features \u00b6 Syntax is close to SQL, but not exactly the same (Easy to learn) Expandable Case insensitive Support basic graph traverse Support pattern match Support aggregation Support graph mutation Support distributed transaction (future release) Statement composition, but NO statement embedding (Easy to read) Terminology \u00b6 Graph Space : A physically isolated space for different graph Tag : A label associated with a list of properties Each tag has a name (human readable string), and internally each tag will be assigned a 32-bit integer Each tag associates with a list of properties, each property has a name and a type There could be dependencies between tags. The dependency is a constrain, for instance, if tag S depends on tag T, then tag S cannot exist unless tag T exists Vertex : A Node in the graph Each vertex has a unique 64-bit (signed integer) ID ( VID ) Each vertex can associate with multiple tags Edge : A Link between two vertices Each edge can be uniquely identified by a tuple Edge type (ET) is a human readable string, internally it will be assigned a 32-bit integer. The edge type decides the property list (schema) on the edge Edge rank is an immutable user-assigned 64-bit signed integer. It affects the edge order between two vertices. The edge with a higher rank value comes first. When not specified, the default rank value is zero. Each edge can only be of one type Path : A non-forked connection with multiple vertices and edges between them The length of a path is the number of the edges on the path, which is one less than the number of vertices A path can be represented by a list of vertices, edge types, and rank. An edge is a special path with length==1 <vid, <edge_type, rank>, vid, ...> Language Specification at a Glance \u00b6 For most readers, You can skip this section if you are not familiar with BNF. General \u00b6 The entire set of statements can be categorized into three classes: query , mutation , and administration Every statement can yield a data set as the result. Each data set contains a schema (column name and type) and multiple data rows Composition \u00b6 Statements could be composed in two ways: Statements could be piped together using operator \" | \", much like the pipe in the shell scripts. The result yielded from the previous statement could be redirected to the next statement as input More than one statements can be batched together, separated by \" ; \". The result of the last statement (or a RETURN statement is executed) will be returned as the result of the batch Data Types \u00b6 Simple type: vid , double , int , bool , string , timestamp vid : 64-bit signed integer, representing a vertex ID List of simple types, such as integer[] , double[] , string[] Map : A list of KV pairs. The key must be a string , the value must be the same type for the given map Object (future release??): A list of KV pairs. The key mush be a string , the value can be any simple type Tuple List : This is only used for return values . It's composed by both meta data and data (multiple rows). The meta data includes the column names and their types. Type Conversion \u00b6 A simple typed value can be implicitly converted into a list A list can be implicitly converted into a one-column tuple list \"<type>_list\" can be used as the column name Common BNF \u00b6 ::= vid | integer | double | float | bool | string | path | timestamp | year | month | date | datetime ::= <type> ::= | ::= vid (, vid )* | \"{\" vid (, vid )* \"}\" <label> ::= [:alpha] ([:alnum:] | \"_\")* ::= (\"_\")* <label> ::= <label> ::= (, )* ::= :<type> ::= \":\" ::= ::= <tuple> (, <tuple>)* | \"{\" <tuple> (, <tuple>)* \"}\" <tuple> ::= \"(\" VALUE (, VALUE )* \")\" <var> ::= \"$\" <label> Statements \u00b6 Choose a Graph Space \u00b6 Nebula supports multiple graph spaces. Data in different graph spaces are physically isolated. Before executing a query, a graph space needs to be selected using the following statement USE Return a Data Set \u00b6 Simply return a single value or a data set RETURN ::= vid | | | <var> Create a Tag \u00b6 The following statement defines a new tag CREATE TAG ( ) ::= <label> ::= + ::= ,<type> ::= <label> Create an Edge Type \u00b6 The following statement defines a new edge type CREATE EDGE ( ) := <label> Insert Vertices \u00b6 The following statement inserts one or more vertices INSERT VERTEX [ NO OVERWRITE ] VALUES ::= ( ) (, ( ))* ::= :( ) (, :( ))* ::= vid ::= (, )* ::= VALUE (, VALUE )* Insert Edges \u00b6 The following statement inserts one or more edges INSERT EDGE [ NO OVERWRITE ] [( )] VALUES ( )+ edge_value ::= -> [@ <weight>] : Update a Vertex \u00b6 The following statement updates a vertex UPDATE VERTEX SET \\<update_decl> [ WHERE <conditions>] [ YIELD ] ::= | ::= = <expression> {, = <expression>}+ ::= ( ) = ( ) | ( ) = <var> Update an Edge \u00b6 The following statement updates an edge UPDATE EDGE -> [@<weight>] OF SET [ WHERE <conditions>] [ YIELD ] Traverse the Graph \u00b6 Navigate from given vertices to their neighbors according to the given conditions. It returns either a list of vertex IDs, or a list of tuples GO [ STEPS ] FROM [ OVER [ REVERSELY ] ] [ WHERE ] [ YIELD ] ::= [data_set] [[ AS ] <label>] ::= vid | | | <var> ::= [ AS <label>] ::= {, }* ::= <label> ::= <filter> { AND | OR <filter>}* ::= \\ \\ **>**\\ | \\ **>= | < | <= | == | != <expression> | <expression> IN <value_list> ::= {, }* ::= <expression> [ AS** <label>] WHERE clause only applies to the results that are going to be returned. It will not be applied to the intermediate results (See the detail description of the STEP[S] clause) When STEP[S] clause is skipped, it implies one step When going out for one step from the given vertex, all neighbors will be checked against the WHERE clause, only results satisfied the WHERE clause will be returned When going out for more than one step, WHERE clause will only be applied to the final results. It will not be applied to the intermediate results. Here is an example GO 2 STEPS FROM me OVER friend WHERE birthday > \"1988/1/1\" Obviously, you will probably guess the meaning of the query is to get all my fof (friend of friend) whose birthday is after 1988/1/1. You are absolutely right. We will not apply the filter to my friends (in the first step). Search \u00b6 Following statements looks for vertices or edges that match certain conditions FIND VERTEX WHERE [ YIELD ] FIND EDGE WHERE [ YIELD ] Property Reference \u00b6 It's common to refer a property in the statement, such as in WHERE clause and YIELD clause. In nGQL, the reference to a property is defined as ::= <object> \".\" <object> ::= | | <var> ::= <label> ::= '[' \"]\" <var> always starts with \"$\". There are two special variables: $- and $$. $- refers to the input stream, while $$ refers to the destination objects All property names start with a letter. There are a few system property names starting with \"_\". All properties names starting with \"_\" are reserved. Built-in Properties \u00b6 _id : Vertex id _type : Edge type _src : Source ID of the edge _dst : Destination ID of the edge _rank : Edge rank number","title":"nGQL Overview"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#nebula_graph_query_language_ngql","text":"","title":"Nebula Graph Query Language (nGQL)"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#about_ngql","text":"nGQL is a declarative, textual query language like SQL, but for graphs. Unlike SQL, nGQL is all about expressing graph patterns. nGQL is a work in progress. We will add more features and further simplify the existing ones. There might be inconsistency between the syntax specs and implementation for the time being.","title":"About nGQL"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#goals","text":"Easy to learn Easy to understand To focus on the online queries, also to provide the foundation for the offline computation","title":"Goals"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#features","text":"Syntax is close to SQL, but not exactly the same (Easy to learn) Expandable Case insensitive Support basic graph traverse Support pattern match Support aggregation Support graph mutation Support distributed transaction (future release) Statement composition, but NO statement embedding (Easy to read)","title":"Features"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#terminology","text":"Graph Space : A physically isolated space for different graph Tag : A label associated with a list of properties Each tag has a name (human readable string), and internally each tag will be assigned a 32-bit integer Each tag associates with a list of properties, each property has a name and a type There could be dependencies between tags. The dependency is a constrain, for instance, if tag S depends on tag T, then tag S cannot exist unless tag T exists Vertex : A Node in the graph Each vertex has a unique 64-bit (signed integer) ID ( VID ) Each vertex can associate with multiple tags Edge : A Link between two vertices Each edge can be uniquely identified by a tuple Edge type (ET) is a human readable string, internally it will be assigned a 32-bit integer. The edge type decides the property list (schema) on the edge Edge rank is an immutable user-assigned 64-bit signed integer. It affects the edge order between two vertices. The edge with a higher rank value comes first. When not specified, the default rank value is zero. Each edge can only be of one type Path : A non-forked connection with multiple vertices and edges between them The length of a path is the number of the edges on the path, which is one less than the number of vertices A path can be represented by a list of vertices, edge types, and rank. An edge is a special path with length==1 <vid, <edge_type, rank>, vid, ...>","title":"Terminology"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#language_specification_at_a_glance","text":"For most readers, You can skip this section if you are not familiar with BNF.","title":"Language Specification at a Glance"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#general","text":"The entire set of statements can be categorized into three classes: query , mutation , and administration Every statement can yield a data set as the result. Each data set contains a schema (column name and type) and multiple data rows","title":"General"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#composition","text":"Statements could be composed in two ways: Statements could be piped together using operator \" | \", much like the pipe in the shell scripts. The result yielded from the previous statement could be redirected to the next statement as input More than one statements can be batched together, separated by \" ; \". The result of the last statement (or a RETURN statement is executed) will be returned as the result of the batch","title":"Composition"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#data_types","text":"Simple type: vid , double , int , bool , string , timestamp vid : 64-bit signed integer, representing a vertex ID List of simple types, such as integer[] , double[] , string[] Map : A list of KV pairs. The key must be a string , the value must be the same type for the given map Object (future release??): A list of KV pairs. The key mush be a string , the value can be any simple type Tuple List : This is only used for return values . It's composed by both meta data and data (multiple rows). The meta data includes the column names and their types.","title":"Data Types"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#type_conversion","text":"A simple typed value can be implicitly converted into a list A list can be implicitly converted into a one-column tuple list \"<type>_list\" can be used as the column name","title":"Type Conversion"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#common_bnf","text":"::= vid | integer | double | float | bool | string | path | timestamp | year | month | date | datetime ::= <type> ::= | ::= vid (, vid )* | \"{\" vid (, vid )* \"}\" <label> ::= [:alpha] ([:alnum:] | \"_\")* ::= (\"_\")* <label> ::= <label> ::= (, )* ::= :<type> ::= \":\" ::= ::= <tuple> (, <tuple>)* | \"{\" <tuple> (, <tuple>)* \"}\" <tuple> ::= \"(\" VALUE (, VALUE )* \")\" <var> ::= \"$\" <label>","title":"Common BNF"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#statements","text":"","title":"Statements"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#choose_a_graph_space","text":"Nebula supports multiple graph spaces. Data in different graph spaces are physically isolated. Before executing a query, a graph space needs to be selected using the following statement USE","title":"Choose a Graph Space"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#return_a_data_set","text":"Simply return a single value or a data set RETURN ::= vid | | | <var>","title":"Return a Data Set"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#create_a_tag","text":"The following statement defines a new tag CREATE TAG ( ) ::= <label> ::= + ::= ,<type> ::= <label>","title":"Create a Tag"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#create_an_edge_type","text":"The following statement defines a new edge type CREATE EDGE ( ) := <label>","title":"Create an Edge Type"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#insert_vertices","text":"The following statement inserts one or more vertices INSERT VERTEX [ NO OVERWRITE ] VALUES ::= ( ) (, ( ))* ::= :( ) (, :( ))* ::= vid ::= (, )* ::= VALUE (, VALUE )*","title":"Insert Vertices"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#insert_edges","text":"The following statement inserts one or more edges INSERT EDGE [ NO OVERWRITE ] [( )] VALUES ( )+ edge_value ::= -> [@ <weight>] :","title":"Insert Edges"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#update_a_vertex","text":"The following statement updates a vertex UPDATE VERTEX SET \\<update_decl> [ WHERE <conditions>] [ YIELD ] ::= | ::= = <expression> {, = <expression>}+ ::= ( ) = ( ) | ( ) = <var>","title":"Update a Vertex"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#update_an_edge","text":"The following statement updates an edge UPDATE EDGE -> [@<weight>] OF SET [ WHERE <conditions>] [ YIELD ]","title":"Update an Edge"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#traverse_the_graph","text":"Navigate from given vertices to their neighbors according to the given conditions. It returns either a list of vertex IDs, or a list of tuples GO [ STEPS ] FROM [ OVER [ REVERSELY ] ] [ WHERE ] [ YIELD ] ::= [data_set] [[ AS ] <label>] ::= vid | | | <var> ::= [ AS <label>] ::= {, }* ::= <label> ::= <filter> { AND | OR <filter>}* ::= \\ \\ **>**\\ | \\ **>= | < | <= | == | != <expression> | <expression> IN <value_list> ::= {, }* ::= <expression> [ AS** <label>] WHERE clause only applies to the results that are going to be returned. It will not be applied to the intermediate results (See the detail description of the STEP[S] clause) When STEP[S] clause is skipped, it implies one step When going out for one step from the given vertex, all neighbors will be checked against the WHERE clause, only results satisfied the WHERE clause will be returned When going out for more than one step, WHERE clause will only be applied to the final results. It will not be applied to the intermediate results. Here is an example GO 2 STEPS FROM me OVER friend WHERE birthday > \"1988/1/1\" Obviously, you will probably guess the meaning of the query is to get all my fof (friend of friend) whose birthday is after 1988/1/1. You are absolutely right. We will not apply the filter to my friends (in the first step).","title":"Traverse the Graph"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#search","text":"Following statements looks for vertices or edges that match certain conditions FIND VERTEX WHERE [ YIELD ] FIND EDGE WHERE [ YIELD ]","title":"Search"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#property_reference","text":"It's common to refer a property in the statement, such as in WHERE clause and YIELD clause. In nGQL, the reference to a property is defined as ::= <object> \".\" <object> ::= | | <var> ::= <label> ::= '[' \"]\" <var> always starts with \"$\". There are two special variables: $- and $$. $- refers to the input stream, while $$ refers to the destination objects All property names start with a letter. There are a few system property names starting with \"_\". All properties names starting with \"_\" are reserved.","title":"Property Reference"},{"location":"manual-EN/1.overview/1.concepts/2.nGQL-overview/#built-in_properties","text":"_id : Vertex id _type : Edge type _src : Source ID of the edge _dst : Destination ID of the edge _rank : Edge rank number","title":"Built-in Properties"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/","text":"Quick Start \u00b6 This guide helps you walk through the process of using Nebula Graph . We will show you how to create and use a graph space , define the schema for your data , insert data , fetch data , update data and delete data . At the end we will show you how to insert multiple data with a .ngql file. Prerequisite \u00b6 Before using Nebula Graph , you must install Nebula Graph by installing source code , rpm/deb packages or docker compose . It is recommended to install Nebula Graph by docker compose . Overview \u00b6 We will show you how to use the Nebula Graph database based on the relations between different vertices in the following figure: In the above figure, there are two tags ( player , team ) and two edge types ( serve and follow ). Creating and Using a Graph Space \u00b6 A graph space in Nebula Graph is similar to an individual database that you create in traditional databases such as MySQL. First, you need to create a space and use it before can do any other operations. You can create and use a graph space by the following steps: Enter the following statement to create a graph space: nebula> CREATE SPACE nba(partition_num=10, replica_factor=1); Note : partition_num specifies the number of partitions in one replica. replica_factor specifies the number of replicas in the cluster. Enter the following statement to use the graph space: nebula> USE nba; Now you can check the space you just created by the following statement: nebula> SHOW SPACES; The following information is returned: ======== | Name | ======== | nba | -------- Defining the Schema for Your Data \u00b6 In Nebula Graph , we classify different vertices with similar properties into one group which is named a tag. The CREATE TAG statement defines a tag with a tag name followed by properties and the property types enclosed in parentheses. The CREATE EDGE statement defines an edge type with a type name, followed by properties and the property types enclosed in parentheses. You can create tags and edge types by the following steps: Enter the following statement to create the player tag: nebula> CREATE TAG player(name string, age int); Enter the following statement to create the team tag: nebula> CREATE TAG team(name string); Enter the following statement to create the follow edge type: nebula> CREATE EDGE follow(degree int); Enter the following statement to create the serve edge type: nebula> CREATE EDGE serve(start_year int, end_year int); Now you can check the tags and edge types you just created. To show the tags you just created, enter the following statement: nebula> SHOW TAGS; The following information is returned: ============ | Name | ============ | player | ------------ | team | ------------ To show the edge types you just created, enter the following statement: nebula> SHOW EDGES; The following information is returned: ========== | Name | ========== | serve | ---------- | follow | ---------- To show the properties of the player tag, enter the following statement: nebula> DESCRIBE TAG player; The following information is returned: =================== | Field | Type | =================== | name | string | ------------------- | age | int | ------------------- To show the properties of the follow edge type, enter the following statement: nebula> DESCRIBE EDGE follow; The following information is returned: ===================== | Field | Type | ===================== | degree | int | --------------------- Inserting Data \u00b6 You can insert vertices and edges based on relations in the illustration figure . Inserting Vertices \u00b6 The INSERT VERTEX statement inserts a vertex by specifying the vertex tag, properties, vertex ID and property values. You can insert some vertices by the following statements: nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); nebula> INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); nebula> INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); nebula> INSERT VERTEX team(name) VALUES 200:(\"Warriors\"); nebula> INSERT VERTEX team(name) VALUES 201:(\"Nuggets\"); nebula> INSERT VERTEX player(name, age) VALUES 121:(\"Useless\", 60); Note : In the above vertices inserted, the number after the keyword VALUES is the vertex ID (abbreviated for VID ). The VID must be unique in the space. The last vertex inserted will be deleted in the deleting data section. If you want to insert multiple vertices for the same tag by a single INSERT VERTEX operation, you can enter the following statement: nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42), \\ 101:(\"Tony Parker\", 36), 102:(\"LaMarcus Aldridge\", 33); Inserting Edges \u00b6 The INSERT EDGE statement inserts an edge by specifying the edge type name, properties, source vertex ID and target vertex ID, and property values. You can insert some edges by the following statements: nebula> INSERT EDGE follow(degree) VALUES 100 -> 101:(95); nebula> INSERT EDGE follow(degree) VALUES 100 -> 102:(90); nebula> INSERT EDGE follow(degree) VALUES 102 -> 101:(75); nebula> INSERT EDGE serve(start_year, end_year) VALUES 100 -> 200:(1997, 2016); nebula> INSERT EDGE serve(start_year, end_year) VALUES 101 -> 201:(1999, 2018); Note : If you want to insert multiple edges for the same edge type by a single INSERT EDGES operation, you can enter the following statement: INSERT EDGE follow(degree) VALUES 100 -> 101:(95),100 -> 102:(90),102 -> 101:(75); Fetching Data \u00b6 After you insert some data in Nebula Graph , you can retrieve any data from your graph space. The FETCH PROP ON statement retrieve data from your graph space. If you want to fetch vertex data, you must specify the vertex tag and vertex ID; if you want to fetch edge data, you must specify the edge type name, source vertex ID and target vertex ID. To fetch the data of the player whose VID is 100 , enter the following statement: nebula> FETCH PROP ON player 100; The following information is returned: ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim Duncan | 42 | --------------------------------------- To fetch the data of the serve edge between VID 100 and VID 200 , enter the following statement: nebula> FETCH PROP ON serve 100 -> 200; The following information is returned: ============================================================================= | serve._src | serve._dst | serve._rank | serve.start_year | serve.end_year | ============================================================================= | 100 | 200 | 0 | 1997 | 2016 | ----------------------------------------------------------------------------- Updating Data \u00b6 You can update the vertices and edges you just inserted. Updating Vertices \u00b6 The UPDATE VERTEX statement updates data for your vertex by selecting the vertex that you want to update and then setting the property value with an equal sign to assign it a new value. The following example shows you how to change the name value of VID 100 from Tim Duncan to Tim . Enter the following statement to update the name value: nebula> UPDATE VERTEX 100 SET player.name = \"Tim\"; To check whether the name value is updated, enter the following statement: nebula> FETCH PROP ON player 100; The following information is displayed: ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim | 42 | --------------------------------------- Updating Edges \u00b6 The UPDATE EDGE statement updates data for your edge by specifying the source vertex ID and the target vertex ID of the edge and then setting the property value with an equal sign to assign it a new value. The following example shows you how to change the value of the degree property in the follow edge between VID 100 and VID 101 . Now we change the degree property from 95 to 96 . Enter the following statement to update the degree value: nebula> UPDATE EDGE 100 -> 101 OF follow SET degree = 96; To check whether the degree value is updated, enter the following statement: nebula> FETCH PROP ON follow 100 -> 101; The following information is returned: ============================================================ | follow._src | follow._dst | follow._rank | follow.degree | ============================================================ | 100 | 101 | 0 | 96 | ------------------------------------------------------------ Deleting Data \u00b6 If you have some data that you do not need, you can delete it from your graph space. Deleting Vertices \u00b6 You can delete any vertex from your graph space. The DELETE VERTEX statement deletes a vertex by specifying the vertex ID. To delete a vertex whose VID is 121 , enter the following statement: nebula> DELETE VERTEX 121; To check whether the vertex is deleted, enter the following statement; nebula> FETCH PROP ON player 121; The following information is returned: Execution succeeded (Time spent: 1571/1910 us) Note : The above information with an empty return result indicates the query operation is successful but no data is queried from your graph space because the data is deleted. Deleting Edges \u00b6 You can delete any edge from your graph space. The DELETE EDGE statement deletes an edge by specifying the edge type name and the source vertex ID and target vertex ID. To delete a follow edge between VID 100 and VID 200 , enter the following statement: nebula> DELETE EDGE follow 100 -> 200; Note : If you delete a vertex, all the out-going and in-coming edges of this vertex are deleted. Sample Queries \u00b6 This section gives more query examples for your reference. Example 1 . Find the vertices that VID 100 follows. Enter the following statement: nebula> GO FROM 100 OVER follow; The following information is returned: =============== | follow._dst | =============== | 101 | --------------- | 102 | --------------- Example 2 . Find the vertex that VID 100 follows, whose age is greater than 35 . Return his name and age, and set the column names to Teammate and Age respectively. Enter the following statement: nebula> GO FROM 100 OVER follow WHERE $$.player.age >= 35 \\ YIELD $$.player.name AS Teammate, $$.player.age AS Age; The following information is returned: ===================== | Teammate | Age | ===================== | Tony Parker | 36 | --------------------- Note : YIELD specifies what values or results you want to return from the query. $$ represents the target vertex. \\ represents a line break. Example 3 . Find the team which is served by the player who is followed by 100 . There are two ways to get the same result. First, we can use a pipe to retrieve the team. Then we use a temporary variable to retrieve the same team. Enter the following statement with a pipe : GO FROM 100 OVER follow YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; The following information is returned. =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- Enter the following statement with a temporary variable : $var=GO FROM 100 OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; The following information is returned. =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- Note : $^ represents the source vertex. | denotes a pipe. The output of the previous query acts as an input to the next query. $- refers to the input stream. The second approach adopts a user-defined variable $var . The scope of this variable is within the compound statement. Batch Inserting \u00b6 To insert multiple data, you can put all the DDL (Data Definition Language) statements in a .ngql file as follows. CREATE SPACE nba(partition_num=10, replica_factor=1); USE nba; CREATE TAG player(name string, age int); CREATE TAG team(name string); CREATE EDGE follow(degree int); CREATE EDGE serve(start_year int, end_year int); If you install Nebula Graph by compiling the source code, you can batch write to console by the following command: $ cat schema.ngql | ./bin/nebula -u user -p password If you are using Nebula Graph by docker-compose, you can batch write to console by the following command: $ cat nba.ngql | sudo docker run --rm -i --network = host \\ vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 Note : You must change the IP address and the port number to yours. You can download the nba.ngql file here . Likewise, you can put hundreds or thousands DML (Data Manipulation Language) statements in a data.ngql file to insert data. If you have millions of records to insert, it is recommended to use the csv importer (or sst ingest tool ). Need Help \u00b6 Please use our official forum for questions, feature requests and discussions. Please use Github Issues if you encounter bugs or have feature requests. You can also raise your question on our Stack Overflow .","title":"Get Started"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#quick_start","text":"This guide helps you walk through the process of using Nebula Graph . We will show you how to create and use a graph space , define the schema for your data , insert data , fetch data , update data and delete data . At the end we will show you how to insert multiple data with a .ngql file.","title":"Quick Start"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#prerequisite","text":"Before using Nebula Graph , you must install Nebula Graph by installing source code , rpm/deb packages or docker compose . It is recommended to install Nebula Graph by docker compose .","title":"Prerequisite"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#overview","text":"We will show you how to use the Nebula Graph database based on the relations between different vertices in the following figure: In the above figure, there are two tags ( player , team ) and two edge types ( serve and follow ).","title":"Overview"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#creating_and_using_a_graph_space","text":"A graph space in Nebula Graph is similar to an individual database that you create in traditional databases such as MySQL. First, you need to create a space and use it before can do any other operations. You can create and use a graph space by the following steps: Enter the following statement to create a graph space: nebula> CREATE SPACE nba(partition_num=10, replica_factor=1); Note : partition_num specifies the number of partitions in one replica. replica_factor specifies the number of replicas in the cluster. Enter the following statement to use the graph space: nebula> USE nba; Now you can check the space you just created by the following statement: nebula> SHOW SPACES; The following information is returned: ======== | Name | ======== | nba | --------","title":"Creating and Using a Graph Space"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#defining_the_schema_for_your_data","text":"In Nebula Graph , we classify different vertices with similar properties into one group which is named a tag. The CREATE TAG statement defines a tag with a tag name followed by properties and the property types enclosed in parentheses. The CREATE EDGE statement defines an edge type with a type name, followed by properties and the property types enclosed in parentheses. You can create tags and edge types by the following steps: Enter the following statement to create the player tag: nebula> CREATE TAG player(name string, age int); Enter the following statement to create the team tag: nebula> CREATE TAG team(name string); Enter the following statement to create the follow edge type: nebula> CREATE EDGE follow(degree int); Enter the following statement to create the serve edge type: nebula> CREATE EDGE serve(start_year int, end_year int); Now you can check the tags and edge types you just created. To show the tags you just created, enter the following statement: nebula> SHOW TAGS; The following information is returned: ============ | Name | ============ | player | ------------ | team | ------------ To show the edge types you just created, enter the following statement: nebula> SHOW EDGES; The following information is returned: ========== | Name | ========== | serve | ---------- | follow | ---------- To show the properties of the player tag, enter the following statement: nebula> DESCRIBE TAG player; The following information is returned: =================== | Field | Type | =================== | name | string | ------------------- | age | int | ------------------- To show the properties of the follow edge type, enter the following statement: nebula> DESCRIBE EDGE follow; The following information is returned: ===================== | Field | Type | ===================== | degree | int | ---------------------","title":"Defining the Schema for Your Data"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#inserting_data","text":"You can insert vertices and edges based on relations in the illustration figure .","title":"Inserting Data"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#inserting_vertices","text":"The INSERT VERTEX statement inserts a vertex by specifying the vertex tag, properties, vertex ID and property values. You can insert some vertices by the following statements: nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); nebula> INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); nebula> INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); nebula> INSERT VERTEX team(name) VALUES 200:(\"Warriors\"); nebula> INSERT VERTEX team(name) VALUES 201:(\"Nuggets\"); nebula> INSERT VERTEX player(name, age) VALUES 121:(\"Useless\", 60); Note : In the above vertices inserted, the number after the keyword VALUES is the vertex ID (abbreviated for VID ). The VID must be unique in the space. The last vertex inserted will be deleted in the deleting data section. If you want to insert multiple vertices for the same tag by a single INSERT VERTEX operation, you can enter the following statement: nebula> INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42), \\ 101:(\"Tony Parker\", 36), 102:(\"LaMarcus Aldridge\", 33);","title":"Inserting Vertices"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#inserting_edges","text":"The INSERT EDGE statement inserts an edge by specifying the edge type name, properties, source vertex ID and target vertex ID, and property values. You can insert some edges by the following statements: nebula> INSERT EDGE follow(degree) VALUES 100 -> 101:(95); nebula> INSERT EDGE follow(degree) VALUES 100 -> 102:(90); nebula> INSERT EDGE follow(degree) VALUES 102 -> 101:(75); nebula> INSERT EDGE serve(start_year, end_year) VALUES 100 -> 200:(1997, 2016); nebula> INSERT EDGE serve(start_year, end_year) VALUES 101 -> 201:(1999, 2018); Note : If you want to insert multiple edges for the same edge type by a single INSERT EDGES operation, you can enter the following statement: INSERT EDGE follow(degree) VALUES 100 -> 101:(95),100 -> 102:(90),102 -> 101:(75);","title":"Inserting Edges"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#fetching_data","text":"After you insert some data in Nebula Graph , you can retrieve any data from your graph space. The FETCH PROP ON statement retrieve data from your graph space. If you want to fetch vertex data, you must specify the vertex tag and vertex ID; if you want to fetch edge data, you must specify the edge type name, source vertex ID and target vertex ID. To fetch the data of the player whose VID is 100 , enter the following statement: nebula> FETCH PROP ON player 100; The following information is returned: ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim Duncan | 42 | --------------------------------------- To fetch the data of the serve edge between VID 100 and VID 200 , enter the following statement: nebula> FETCH PROP ON serve 100 -> 200; The following information is returned: ============================================================================= | serve._src | serve._dst | serve._rank | serve.start_year | serve.end_year | ============================================================================= | 100 | 200 | 0 | 1997 | 2016 | -----------------------------------------------------------------------------","title":"Fetching Data"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#updating_data","text":"You can update the vertices and edges you just inserted.","title":"Updating Data"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#updating_vertices","text":"The UPDATE VERTEX statement updates data for your vertex by selecting the vertex that you want to update and then setting the property value with an equal sign to assign it a new value. The following example shows you how to change the name value of VID 100 from Tim Duncan to Tim . Enter the following statement to update the name value: nebula> UPDATE VERTEX 100 SET player.name = \"Tim\"; To check whether the name value is updated, enter the following statement: nebula> FETCH PROP ON player 100; The following information is displayed: ======================================= | VertexID | player.name | player.age | ======================================= | 100 | Tim | 42 | ---------------------------------------","title":"Updating Vertices"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#updating_edges","text":"The UPDATE EDGE statement updates data for your edge by specifying the source vertex ID and the target vertex ID of the edge and then setting the property value with an equal sign to assign it a new value. The following example shows you how to change the value of the degree property in the follow edge between VID 100 and VID 101 . Now we change the degree property from 95 to 96 . Enter the following statement to update the degree value: nebula> UPDATE EDGE 100 -> 101 OF follow SET degree = 96; To check whether the degree value is updated, enter the following statement: nebula> FETCH PROP ON follow 100 -> 101; The following information is returned: ============================================================ | follow._src | follow._dst | follow._rank | follow.degree | ============================================================ | 100 | 101 | 0 | 96 | ------------------------------------------------------------","title":"Updating Edges"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#deleting_data","text":"If you have some data that you do not need, you can delete it from your graph space.","title":"Deleting Data"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#deleting_vertices","text":"You can delete any vertex from your graph space. The DELETE VERTEX statement deletes a vertex by specifying the vertex ID. To delete a vertex whose VID is 121 , enter the following statement: nebula> DELETE VERTEX 121; To check whether the vertex is deleted, enter the following statement; nebula> FETCH PROP ON player 121; The following information is returned: Execution succeeded (Time spent: 1571/1910 us) Note : The above information with an empty return result indicates the query operation is successful but no data is queried from your graph space because the data is deleted.","title":"Deleting Vertices"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#deleting_edges","text":"You can delete any edge from your graph space. The DELETE EDGE statement deletes an edge by specifying the edge type name and the source vertex ID and target vertex ID. To delete a follow edge between VID 100 and VID 200 , enter the following statement: nebula> DELETE EDGE follow 100 -> 200; Note : If you delete a vertex, all the out-going and in-coming edges of this vertex are deleted.","title":"Deleting Edges"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#sample_queries","text":"This section gives more query examples for your reference. Example 1 . Find the vertices that VID 100 follows. Enter the following statement: nebula> GO FROM 100 OVER follow; The following information is returned: =============== | follow._dst | =============== | 101 | --------------- | 102 | --------------- Example 2 . Find the vertex that VID 100 follows, whose age is greater than 35 . Return his name and age, and set the column names to Teammate and Age respectively. Enter the following statement: nebula> GO FROM 100 OVER follow WHERE $$.player.age >= 35 \\ YIELD $$.player.name AS Teammate, $$.player.age AS Age; The following information is returned: ===================== | Teammate | Age | ===================== | Tony Parker | 36 | --------------------- Note : YIELD specifies what values or results you want to return from the query. $$ represents the target vertex. \\ represents a line break. Example 3 . Find the team which is served by the player who is followed by 100 . There are two ways to get the same result. First, we can use a pipe to retrieve the team. Then we use a temporary variable to retrieve the same team. Enter the following statement with a pipe : GO FROM 100 OVER follow YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; The following information is returned. =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- Enter the following statement with a temporary variable : $var=GO FROM 100 OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve YIELD $$.team.name \\ AS Team, $^.player.name AS Player; The following information is returned. =============================== | Team | Player | =============================== | Nuggets | Tony Parker | ------------------------------- Note : $^ represents the source vertex. | denotes a pipe. The output of the previous query acts as an input to the next query. $- refers to the input stream. The second approach adopts a user-defined variable $var . The scope of this variable is within the compound statement.","title":"Sample Queries"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#batch_inserting","text":"To insert multiple data, you can put all the DDL (Data Definition Language) statements in a .ngql file as follows. CREATE SPACE nba(partition_num=10, replica_factor=1); USE nba; CREATE TAG player(name string, age int); CREATE TAG team(name string); CREATE EDGE follow(degree int); CREATE EDGE serve(start_year int, end_year int); If you install Nebula Graph by compiling the source code, you can batch write to console by the following command: $ cat schema.ngql | ./bin/nebula -u user -p password If you are using Nebula Graph by docker-compose, you can batch write to console by the following command: $ cat nba.ngql | sudo docker run --rm -i --network = host \\ vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 Note : You must change the IP address and the port number to yours. You can download the nba.ngql file here . Likewise, you can put hundreds or thousands DML (Data Manipulation Language) statements in a data.ngql file to insert data. If you have millions of records to insert, it is recommended to use the csv importer (or sst ingest tool ).","title":"Batch Inserting"},{"location":"manual-EN/1.overview/2.quick-start/1.get-started/#need_help","text":"Please use our official forum for questions, feature requests and discussions. Please use Github Issues if you encounter bugs or have feature requests. You can also raise your question on our Stack Overflow .","title":"Need Help"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/","text":"Frequently Asked Questions \u00b6 Common questions about Nebula Graph and more. Frequently Asked Questions Trouble Shooting graphd Config File Doesn't Register to Meta Server Errors Thrown When Inserting Data After Tag or Edge is Created Errors Thrown When Executing Command in Docker How to Check Logs How to Check Configs How to Check Runtime Configs Connection Refused Process Crash Could not create logging file:... Too many open files Storaged Service Cannot Start Normally How to Check Nebula Graph Version Modifying the Configuration File Does not Take Effect Modify RocksDB block cache General Information Explanations on the Time Return in Queries Trouble Shooting \u00b6 Trouble Shooting session lists the common operation errors in Nebula Graph . graphd Config File Doesn't Register to Meta Server \u00b6 When starting Nebula Graph services with the nebula.service script, graphd , metad and storaged processes start too fast to make the graphd config file registered into the meta server. The same problem may also occur when restarting. If you are using the beta version, start the metad service first, then the storaged and graphd to avoid such problem. We will resolve this problem in the next release. Start metad first: nebula> scripts/nebula.service start metad [ INFO ] Starting nebula-metad... [ INFO ] Done Then start storaged and graphd nebula> scripts/nebula.service start storaged [ INFO ] Starting nebula-storaged... [ INFO ] Done nebula> scripts/nebula.service start graphd [ INFO ] Starting nebula-graphd... [ INFO ] Done [\u2191] Back to top Errors Thrown When Inserting Data After Tag or Edge is Created \u00b6 This is likely caused by setting the heartbeat_interval_secs value to fetch data from the meta server. Conduct the following steps to resolve: If meta has registered, check heartbeat_interval_secs value in console with the following command. nebula> GET CONFIGS storage:heartbeat_interval_secs nebula> GET CONFIGS graph:heartbeat_interval_secs If the value is large, change it to 1s with the following command. nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1 nebula> UPDATE CONFIGS graph:heartbeat_interval_secs=1 Note the changes take effect in the next period. [\u2191] Back to top Errors Thrown When Executing Command in Docker \u00b6 This is likely caused by the inconsistency between the docker IP and the default listening address (172.17.0.2). Thus we need to change the the latter. First run ifconfig in container to check your container IP, here we assume your IP is 172.17.0.3. In directory /usr/local/nebula/etc , check the config locations of all the IP addresses with the command grep \"172.17.0.2\" . -r . Change all the IPs you find in step 2 to your container IP 172.17.0.3. Restart all the services. [\u2191] Back to top How to Check Logs \u00b6 Logs are stored under /usr/local/nebula/logs/ by default. For details of logs, please refer to logs . [\u2191] Back to top How to Check Configs \u00b6 Configuration files are stored under /usr/local/nebula/etc/ by default. [\u2191] Back to top How to Check Runtime Configs \u00b6 In Nebula console, run nebula> SHOW CONFIGS; For configuration details, please see here . [\u2191] Back to top Connection Refused \u00b6 E1121 04:49:34.563858 256 GraphClient.cpp:54] Thrift rpc call failed: AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused): Connection refused Check service status by $ /usr/local/nebula/scripts/nebula.service status all [\u2191] Back to top Process Crash \u00b6 Check disk space df -h . Check memory usage free -h . [\u2191] Back to top Could not create logging file:... Too many open files \u00b6 Check your disk space df -h Check log directory /usr/local/nebula/logs/ reset your max open files by ulimit -n 65536 [\u2191] Back to top Storaged Service Cannot Start Normally \u00b6 When the same host is used for single host or cluster test, the storaged service cannot start normally. The listening port of the storaged service is red in the console. Check the logs of the storaged service. If you find the \"wrong cluster\" error message, the possible cause is that the cluster id generated by Nebula Graph during the single host test and the cluster test are inconsistent. You need to delete the cluster.id file and the data directory and restart the service. [\u2191] Back to top How to Check Nebula Graph Version \u00b6 Use the command curl http://ip:port/status to obtain the git_info_sha, the commitID of the binary package. Modifying the Configuration File Does not Take Effect \u00b6 Nebula Graph uses the following two methods obtaining configurations: From the configuration files (You need to modify the files then restart the services); From the Meta. Set via CLI and persists in Meta service. Please refer to the Configs Syntax for details. Modifying the configuration file does not take effect because Nebula Graph gets configuration in the second method (from meta) by default. If you want to use the first way, please add the --local_config=true option in flag files metad.conf , storaged.conf , graphd.conf (flag files directory is /home/user/nebula/build/install/etc ) respectively. [\u2191] Back to top Modify RocksDB block cache \u00b6 Modify the storage layer's configuration file storaged.conf (the default directory is /usr/local/nebula/etc/ , yours maybe different) and restart the service. For example: # Change rocksdb_block_cache to 1024 MB --rocksdb_block_cache = 1024 # Stop storaged and restart /usr/local/nebula/scripts/nebula.service stop storaged /usr/local/nebula/scripts/nebula.service start storaged Run command curl 127.0.0.1:12000/get_flags | grep rocksdb_block_cache in your command line to confirm your modification. $ curl 127 .0.0.1:12000/get_flags | grep rocksdb_block_cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3041 100 3041 0 0 989k 0 --:--:-- --:--:-- --:--:-- 989k rocksdb_block_cache = 1024 [\u2191] Back to top General Information \u00b6 General Information lists the conceptual questions about Nebula Graph . Explanations on the Time Return in Queries \u00b6 nebula> GO FROM 101 OVER follow =============== | follow._dst | =============== | 100 | --------------- | 102 | --------------- | 125 | --------------- Got 3 rows (Time spent: 7431/10406 us) Taking the above query as an example, the number 7431 in Time spent is the time spent by the database itself, that is, the time it takes for the query engine to receive a query from the console, fetch the data from the storage and perform a series of calculation ; the number 10406 is the time spent from the client's perspective, that is, the time it takes for the console from sending a request and receiving a response to displaying the result on the screen. [\u2191] Back to top","title":"FAQ"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#frequently_asked_questions","text":"Common questions about Nebula Graph and more. Frequently Asked Questions Trouble Shooting graphd Config File Doesn't Register to Meta Server Errors Thrown When Inserting Data After Tag or Edge is Created Errors Thrown When Executing Command in Docker How to Check Logs How to Check Configs How to Check Runtime Configs Connection Refused Process Crash Could not create logging file:... Too many open files Storaged Service Cannot Start Normally How to Check Nebula Graph Version Modifying the Configuration File Does not Take Effect Modify RocksDB block cache General Information Explanations on the Time Return in Queries","title":"Frequently Asked Questions"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#trouble_shooting","text":"Trouble Shooting session lists the common operation errors in Nebula Graph .","title":"Trouble Shooting"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#graphd_config_file_doesnt_register_to_meta_server","text":"When starting Nebula Graph services with the nebula.service script, graphd , metad and storaged processes start too fast to make the graphd config file registered into the meta server. The same problem may also occur when restarting. If you are using the beta version, start the metad service first, then the storaged and graphd to avoid such problem. We will resolve this problem in the next release. Start metad first: nebula> scripts/nebula.service start metad [ INFO ] Starting nebula-metad... [ INFO ] Done Then start storaged and graphd nebula> scripts/nebula.service start storaged [ INFO ] Starting nebula-storaged... [ INFO ] Done nebula> scripts/nebula.service start graphd [ INFO ] Starting nebula-graphd... [ INFO ] Done [\u2191] Back to top","title":"graphd Config File Doesn't Register to Meta Server"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#errors_thrown_when_inserting_data_after_tag_or_edge_is_created","text":"This is likely caused by setting the heartbeat_interval_secs value to fetch data from the meta server. Conduct the following steps to resolve: If meta has registered, check heartbeat_interval_secs value in console with the following command. nebula> GET CONFIGS storage:heartbeat_interval_secs nebula> GET CONFIGS graph:heartbeat_interval_secs If the value is large, change it to 1s with the following command. nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1 nebula> UPDATE CONFIGS graph:heartbeat_interval_secs=1 Note the changes take effect in the next period. [\u2191] Back to top","title":"Errors Thrown When Inserting Data After Tag or Edge is Created"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#errors_thrown_when_executing_command_in_docker","text":"This is likely caused by the inconsistency between the docker IP and the default listening address (172.17.0.2). Thus we need to change the the latter. First run ifconfig in container to check your container IP, here we assume your IP is 172.17.0.3. In directory /usr/local/nebula/etc , check the config locations of all the IP addresses with the command grep \"172.17.0.2\" . -r . Change all the IPs you find in step 2 to your container IP 172.17.0.3. Restart all the services. [\u2191] Back to top","title":"Errors Thrown When Executing Command in Docker"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#how_to_check_logs","text":"Logs are stored under /usr/local/nebula/logs/ by default. For details of logs, please refer to logs . [\u2191] Back to top","title":"How to Check Logs"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#how_to_check_configs","text":"Configuration files are stored under /usr/local/nebula/etc/ by default. [\u2191] Back to top","title":"How to Check Configs"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#how_to_check_runtime_configs","text":"In Nebula console, run nebula> SHOW CONFIGS; For configuration details, please see here . [\u2191] Back to top","title":"How to Check Runtime Configs"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#connection_refused","text":"E1121 04:49:34.563858 256 GraphClient.cpp:54] Thrift rpc call failed: AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused): Connection refused Check service status by $ /usr/local/nebula/scripts/nebula.service status all [\u2191] Back to top","title":"Connection Refused"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#process_crash","text":"Check disk space df -h . Check memory usage free -h . [\u2191] Back to top","title":"Process Crash"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#could_not_create_logging_file_too_many_open_files","text":"Check your disk space df -h Check log directory /usr/local/nebula/logs/ reset your max open files by ulimit -n 65536 [\u2191] Back to top","title":"Could not create logging file:... Too many open files"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#storaged_service_cannot_start_normally","text":"When the same host is used for single host or cluster test, the storaged service cannot start normally. The listening port of the storaged service is red in the console. Check the logs of the storaged service. If you find the \"wrong cluster\" error message, the possible cause is that the cluster id generated by Nebula Graph during the single host test and the cluster test are inconsistent. You need to delete the cluster.id file and the data directory and restart the service. [\u2191] Back to top","title":"Storaged Service Cannot Start Normally"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#how_to_check_nebula_graph_version","text":"Use the command curl http://ip:port/status to obtain the git_info_sha, the commitID of the binary package.","title":"How to Check Nebula Graph Version"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#modifying_the_configuration_file_does_not_take_effect","text":"Nebula Graph uses the following two methods obtaining configurations: From the configuration files (You need to modify the files then restart the services); From the Meta. Set via CLI and persists in Meta service. Please refer to the Configs Syntax for details. Modifying the configuration file does not take effect because Nebula Graph gets configuration in the second method (from meta) by default. If you want to use the first way, please add the --local_config=true option in flag files metad.conf , storaged.conf , graphd.conf (flag files directory is /home/user/nebula/build/install/etc ) respectively. [\u2191] Back to top","title":"Modifying the Configuration File Does not Take Effect"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#modify_rocksdb_block_cache","text":"Modify the storage layer's configuration file storaged.conf (the default directory is /usr/local/nebula/etc/ , yours maybe different) and restart the service. For example: # Change rocksdb_block_cache to 1024 MB --rocksdb_block_cache = 1024 # Stop storaged and restart /usr/local/nebula/scripts/nebula.service stop storaged /usr/local/nebula/scripts/nebula.service start storaged Run command curl 127.0.0.1:12000/get_flags | grep rocksdb_block_cache in your command line to confirm your modification. $ curl 127 .0.0.1:12000/get_flags | grep rocksdb_block_cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3041 100 3041 0 0 989k 0 --:--:-- --:--:-- --:--:-- 989k rocksdb_block_cache = 1024 [\u2191] Back to top","title":"Modify RocksDB block cache"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#general_information","text":"General Information lists the conceptual questions about Nebula Graph .","title":"General Information"},{"location":"manual-EN/1.overview/2.quick-start/2.FAQ/#explanations_on_the_time_return_in_queries","text":"nebula> GO FROM 101 OVER follow =============== | follow._dst | =============== | 100 | --------------- | 102 | --------------- | 125 | --------------- Got 3 rows (Time spent: 7431/10406 us) Taking the above query as an example, the number 7431 in Time spent is the time spent by the database itself, that is, the time it takes for the query engine to receive a query from the console, fetch the data from the storage and perform a series of calculation ; the number 10406 is the time spent from the client's perspective, that is, the time it takes for the console from sending a request and receiving a response to displaying the result on the screen. [\u2191] Back to top","title":"Explanations on the Time Return in Queries"},{"location":"manual-EN/1.overview/2.quick-start/3.supported-clients/","text":"Supported Clients by Nebula Graph \u00b6 Currently, Nebula Graph supports the following clients: Go Client Python Client Java Client","title":"Supported Clients"},{"location":"manual-EN/1.overview/2.quick-start/3.supported-clients/#supported_clients_by_nebula_graph","text":"Currently, Nebula Graph supports the following clients: Go Client Python Client Java Client","title":"Supported Clients by Nebula Graph"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/","text":"Example of Importing CSV Files \u00b6 The following example shows you how to import CSV data to Nebula Graph with Nebula Importer . In this example, Nebula Graph is installed with Docker and Docker Compose . We will walk you through the example by the following steps: Start your Nebula Graph services Create the schema for vertices and edges Prepare the configuration file Prepare the CSV data Import the CSV data Starting Nebula Graph Services \u00b6 You can start your Nebula Graph services by the following steps: On a command line interface, go to the nebula-docker-compose directory. Execute the following command to start Nebula Graph services: $ sudo docker-compose up -d Execute the following command to pull the Nebula Graph image: $ sudo docker pull vesoft/nebula-console:nightly Execute the following command to connect to your Nebula Graph server: $ sudo docker run --rm -ti --network = host vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 Note : You must ensure your IP address and port number are configured correctly. Creating the Schema for Vertices and Edges \u00b6 Before you can input your schema, you must create a space and use it. In this example we create a nba space and use it. We create two tags and two edge types with the following commands: nebula> CREATE TAG player (name string, age int); nebula> CREATE TAG team (name string); nebula> CREATE EDGE serve (start_year int, end_year int); nebula> CREATE EDGE follow (degree, int); Preparing Your Configuration File \u00b6 You must configure the .yaml configuration file, which regulates how data is organized in the CSV files. In this example, we create a config.yaml file. In this example, we configure the config.yaml configuration file as follows: version: v1rc1 description: example clientSettings: concurrency: 2 # number of graph clients channelBufferSize: 1 space: nba connection: user: user password: password address: 127.0.0.1:3699 logPath: ./err/test.log files: - path: /home/nebula/serve.csv failDataPath: ./err/serve.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: serve withRanking: false props: - name: start_year type: int - name: end_year type: int - path: /home/nebula/follow.csv failDataPath: ./err/follow.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: follow withRanking: false props: - name: degree type: int - path: /home/nebula/player.csv failDataPath: ./err/player.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: player props: - name: name type: string - name: age type: int - path: /home/nebula/team.csv failDataPath: ./err/team.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: team props: - name: name type: string Note : In the above configuration file, you must change the IP address and the port number to yours. You must change the directory of the CSV files to yours, otherwise, Nebula Importer cannot find the CSV files. Preparing the CSV Data \u00b6 In this example, we prepare four CSV data files: player.csv , team.csv , serve.csv , and follow.csv . The data in the serve.csv file is as follows: 100,200,1997,2016 101,201,1999,2018 102,203,2006,2015 102,204,2015,2019 103,204,2017,2019 104,200,2007,2009 The data in the follow.csv file is as follows: 100,101,95 100,102,90 101,100,95 102,101,75 102,100,75 103,102,70 104,101,50 104,105,60 105,104,83 The data in the player.csv file is as follows: 100,Tim Duncan,42 101,Tony Parker,36 102,LaMarcus Aldridge,33 103,Rudy Gay,32 104,Marco Belinelli,32 105,Danny Green,31 106,Kyle Anderson,25 107,Aron Baynes,32 108,Boris Diaw,36 The data in the team.csv file is as follows: 200,Warriors 201,Nuggets 202,Rockets 203,Trail 204,Spurs 205,Thunders 206,Jazz 207,Clippers 208,Kings Note : In the serve and follow CSV files, the first column is the source vertex ID, the second column is the destination vertex ID, and the other columns are consistent with the config.yaml file. In the player and team CSV files, the first column is the vertex ID and the other columns are consistent with the config.yaml file. Importing the CSV Data \u00b6 After all the previous four steps are complete, you can import the CSV data with Docker or Go . Importing the CSV Data With Go \u00b6 Before you import CSV data with Go , you must ensure Go is installed and the environment variable for Go is configured. You can import the CSV data by the following steps: Change your current directory to the directory where the import.go file is located by the following command: $ cd /home/nebula/nebula-importer/cmd Execute the following command to import the CSV data: $ go run importer.go --config /home/nebula/config.yaml Note : You must change the directory for the import.go file and the directory for the config.yaml file to yours, otherwise, the importing operation might fail. Importing the CSV Data With Docker \u00b6 Before you import the CSV data with Docker , you must ensure that Docker is up and running. You can import the CSV data with Docker by the following command: $ sudo docker run --rm -ti --network = host \\ -v /home/nebula/config.yaml:/home/nebula/config.yaml \\ -v /home/nebula/:/home/nebula/ vesoft/nebula-importer \\ --config /home/nebula/config.yaml Note : You must change the directory for the config.yaml file to yours, otherwise the importing operation might fail.","title":"Example of Importing CSV Files"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#example_of_importing_csv_files","text":"The following example shows you how to import CSV data to Nebula Graph with Nebula Importer . In this example, Nebula Graph is installed with Docker and Docker Compose . We will walk you through the example by the following steps: Start your Nebula Graph services Create the schema for vertices and edges Prepare the configuration file Prepare the CSV data Import the CSV data","title":"Example of Importing CSV Files"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#starting_nebula_graph_services","text":"You can start your Nebula Graph services by the following steps: On a command line interface, go to the nebula-docker-compose directory. Execute the following command to start Nebula Graph services: $ sudo docker-compose up -d Execute the following command to pull the Nebula Graph image: $ sudo docker pull vesoft/nebula-console:nightly Execute the following command to connect to your Nebula Graph server: $ sudo docker run --rm -ti --network = host vesoft/nebula-console:nightly --addr = 127 .0.0.1 --port = 3699 Note : You must ensure your IP address and port number are configured correctly.","title":"Starting Nebula Graph Services"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#creating_the_schema_for_vertices_and_edges","text":"Before you can input your schema, you must create a space and use it. In this example we create a nba space and use it. We create two tags and two edge types with the following commands: nebula> CREATE TAG player (name string, age int); nebula> CREATE TAG team (name string); nebula> CREATE EDGE serve (start_year int, end_year int); nebula> CREATE EDGE follow (degree, int);","title":"Creating the Schema for Vertices and Edges"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#preparing_your_configuration_file","text":"You must configure the .yaml configuration file, which regulates how data is organized in the CSV files. In this example, we create a config.yaml file. In this example, we configure the config.yaml configuration file as follows: version: v1rc1 description: example clientSettings: concurrency: 2 # number of graph clients channelBufferSize: 1 space: nba connection: user: user password: password address: 127.0.0.1:3699 logPath: ./err/test.log files: - path: /home/nebula/serve.csv failDataPath: ./err/serve.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: serve withRanking: false props: - name: start_year type: int - name: end_year type: int - path: /home/nebula/follow.csv failDataPath: ./err/follow.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: edge edge: name: follow withRanking: false props: - name: degree type: int - path: /home/nebula/player.csv failDataPath: ./err/player.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: player props: - name: name type: string - name: age type: int - path: /home/nebula/team.csv failDataPath: ./err/team.csv batchSize: 2 type: csv csv: withHeader: false withLabel: false schema: type: vertex vertex: tags: - name: team props: - name: name type: string Note : In the above configuration file, you must change the IP address and the port number to yours. You must change the directory of the CSV files to yours, otherwise, Nebula Importer cannot find the CSV files.","title":"Preparing Your Configuration File"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#preparing_the_csv_data","text":"In this example, we prepare four CSV data files: player.csv , team.csv , serve.csv , and follow.csv . The data in the serve.csv file is as follows: 100,200,1997,2016 101,201,1999,2018 102,203,2006,2015 102,204,2015,2019 103,204,2017,2019 104,200,2007,2009 The data in the follow.csv file is as follows: 100,101,95 100,102,90 101,100,95 102,101,75 102,100,75 103,102,70 104,101,50 104,105,60 105,104,83 The data in the player.csv file is as follows: 100,Tim Duncan,42 101,Tony Parker,36 102,LaMarcus Aldridge,33 103,Rudy Gay,32 104,Marco Belinelli,32 105,Danny Green,31 106,Kyle Anderson,25 107,Aron Baynes,32 108,Boris Diaw,36 The data in the team.csv file is as follows: 200,Warriors 201,Nuggets 202,Rockets 203,Trail 204,Spurs 205,Thunders 206,Jazz 207,Clippers 208,Kings Note : In the serve and follow CSV files, the first column is the source vertex ID, the second column is the destination vertex ID, and the other columns are consistent with the config.yaml file. In the player and team CSV files, the first column is the vertex ID and the other columns are consistent with the config.yaml file.","title":"Preparing the CSV Data"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#importing_the_csv_data","text":"After all the previous four steps are complete, you can import the CSV data with Docker or Go .","title":"Importing the CSV Data"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#importing_the_csv_data_with_go","text":"Before you import CSV data with Go , you must ensure Go is installed and the environment variable for Go is configured. You can import the CSV data by the following steps: Change your current directory to the directory where the import.go file is located by the following command: $ cd /home/nebula/nebula-importer/cmd Execute the following command to import the CSV data: $ go run importer.go --config /home/nebula/config.yaml Note : You must change the directory for the import.go file and the directory for the config.yaml file to yours, otherwise, the importing operation might fail.","title":"Importing the CSV Data With Go"},{"location":"manual-EN/1.overview/2.quick-start/4.import-csv-file/#importing_the_csv_data_with_docker","text":"Before you import the CSV data with Docker , you must ensure that Docker is up and running. You can import the CSV data with Docker by the following command: $ sudo docker run --rm -ti --network = host \\ -v /home/nebula/config.yaml:/home/nebula/config.yaml \\ -v /home/nebula/:/home/nebula/ vesoft/nebula-importer \\ --config /home/nebula/config.yaml Note : You must change the directory for the config.yaml file to yours, otherwise the importing operation might fail.","title":"Importing the CSV Data With Docker"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/","text":"Design and Architecture of Nebula Graph \u00b6 This document is to walk you through on how Nebula Graph is designed and why, and it will be separated into two parts: Industry Overview and Nebula Graph Architecture. Industry Overview \u00b6 OLAP & OLTP in Graph \u00b6 The axis in the above picture shows the different requirements for query latency. Like a traditional database, graph database can be divided into two parts: OLAP and OLTP. OLAP cares more about offline analysis while OLTP prefers online processing. Graph computing framework in OLAP is used to analyse data based on graph structure. And it's similar to OLAP in traditional database. But it has features which are not available in traditional database, one is iterative algorithm based on graph. A typical example is the PageRank algorithm from Google, which obtains the relevance of web pages through constant iterative computing. Another example is the commonly-used LPA algorithm. Along the axis to right, there comes the graph streaming field, which is the combination of basic computing and streaming computing. A relational network is not a static structure, rather, it constantly changes in the business: be it graph structure or graph properties. Computing in this filed is often triggered by events and its latency is in second. Right beside the graph streaming is the online response system, whose requirement for latency is extremely high, which should be in millisecond. The rightmost field is graph database and its use cases are completely different from the one on the left. The Nebula Graph we're working on can find its usage here in OLTP. Native Vs Multi-Model \u00b6 Graph databases can be classified into two kinds: native graph database and multi-model graph database. Using a graph first design, native graph databases are specifically optimized in storage and processing, thus they tend to perform queries faster, scale bigger and run more efficiently, calling for much less hardware at the same time. As for multi-model products, their storage comes from an outside source, such as a relational, columnar, or other NoSQL database. These databases use other algorithms to store data about vertices and edges and can lead to latent results as their storage layer is not optimized for graphs. Data Stored in Graph Database \u00b6 In graph database, data is stored as graph. Modelling data as graph is natural, and has the nice benefit of staying legible even by non-technical people. The data model handled by Nebula Graph is directed property graph , whose edges are directional and there could be properties on both edges and vertices. It can be represented as: G = < V, E, P V , P E > Here V is a set of nodes, aka vertices, E is a set of directional edges, P V represents properties on vertices, and P E is the properties on edges. Nebula Graph Architecture \u00b6 Designed based on the above features, Nebula Graph is an open source, distributed, lightning-fast graph database, it is composed of four components: storage service, meta service, query engine and client. The dashed line in the above picture divided computing and storage as two independent parts, the upper is the computing service, each machine or virtual machine is stateless and never talks to other so it's easy to scale in or out; the lower is the storage service, it's stateful since data is stored there. Storage service can turn graph semantics into key-values and pass them to the KV-store below it. Between the two is the Raft protocol. The right side is the meta service, similar to the NameNode in HDFS, it stores all metadata like schema and controls scaling. Design Thinking: Storage Service \u00b6 Nebula Graph adopted the shared-nothing distributed architecture in storage so nodes do not share memory or storage, which means there are no central nodes in the whole system. Benefits of such design are: Easy to scale The overall system continues operating despite individual crash Another design is the separation of computing and storage , and the benefits are as follows: Scalability. Separating storage from computing makes storage service flexible, thus it's easy to scale out or in. Availability. Recovery from vertex failure can be performed quickly. The binary of storage service is nebula-storaged , which provides a key-value store. Multiple storage engines like RocksDB and HBase are supported, with RocksDB set as the default engine. To build a resilient distributed system, Raft is implemented as the consensus algorithm. Raft achieves data consensus via an elected leader. Based on that, nebula-storaged makes the following optimizations: Parallel Raft Partitions of the same ID from multiple machines form a raft group. And the parallel operations are implemented with multiple sets of Raft groups. Write Path & batch In Raft protocol, the master replicates log entries to all the followers and commits the entries in order. To improve the write throughput, Nebula Graph not only employs the parallel raft, but also implements the dynamic batch replication. Load-balance Migrating the partitions on an overworked server to other relatively idle servers to increases availability and capacity of the system. Design-Thinking: Meta Service \u00b6 The binary of the meta service is nebula-metad . Here is the list of its main functionalities: User management In Nebula Graph different roles are assigned diverse privileges. We provide the following native roles: Global Admin, Graph Space Admin, User and Guest. - Cluster configuration management Meta service manages the servers and partitions in the cluster, e.g. records location of the partitions, receives heartbeat from servers, etc. It balances the partitions and manages the communication traffic in case of server failure. - Graph space management Nebula Graph supports multiple graph spaces. Data in different graph spaces are physically isolated. Meta service stores the metadata of all spaces in the cluster and tracks changes that take place in these spaces, like adding, dropping space, modifying graph space configuration (Raft copies). - Schema management Nebula Graph is a strong typed database. Types of tag and edge properties are recorded by meta service. Supported data types are: int, double, timestamp, list, etc. Multi-version management, supporting adding, modifying and deleting schema, and recording its version. TTL (time-to-live) management, supporting automatic data deletion and space reclamation. The meta service is stateful, and just like the storage service, it persists data to a key-value store. Design-Thinking: Query Engine \u00b6 Nebula Graph 's query language nGQL is a SQL-like descriptive language rather than an imperative one. It's compossible but not embeddable, it uses Shell pipe as an alternative, aka output in the former query acts as the input in the latter one. Key features of nGQL are as follows: Main algorithms are built in the query engine Duplicate queries can be avoided by supporting user-defined function (UDF) Programmable The binary of the query engine is nebula-graphd . Each nebula-graphd instance is stateless and never talks to other nebula-graphd. nebula-graphd only talks to the storage service and the meta service. That makes it trivial to expand or shrink the query engine cluster. The query engine accepts the message from the client and generates the execution plan after the lexical parsing (Lexer), semantic analysis (Parser) and the query optimization. Then the execution plan will be passed to the execution engine. The query execution engine takes the query plans and interacts with meta server and the storage engine to retrieve the schema and data. The main optimizations of the query engine are: Asynchronous and parallel execution I/O operations and network transmission are time-consuming. Thus asynchronous and parallel operations are widely adopted in the query engine to reduce the latency and to improve the overall throughput. Also, a separate resource pool is set for each query to avoid the long-tail effect of those time-consuming queries. Pushing down computation In a distributed system, transferring a large amount of data on the network really extends the overall latency. In Nebula Graph , the query engine will make decisions to push some filter and aggregation down to the storage service. The purpose is to reduce the amount of data passing back from the storage. Design-Thinking: API and SDK \u00b6 Nebula Graph provides SDKs in C++, Java, and Golang. Nebula Graph uses fbthrift as the RPC framework to communicate among servers. Nebula Graph 's web console is in progress and will be released soon.","title":"Design and Architecture"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#design_and_architecture_of_nebula_graph","text":"This document is to walk you through on how Nebula Graph is designed and why, and it will be separated into two parts: Industry Overview and Nebula Graph Architecture.","title":"Design and Architecture of Nebula Graph"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#industry_overview","text":"","title":"Industry Overview"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#olap_oltp_in_graph","text":"The axis in the above picture shows the different requirements for query latency. Like a traditional database, graph database can be divided into two parts: OLAP and OLTP. OLAP cares more about offline analysis while OLTP prefers online processing. Graph computing framework in OLAP is used to analyse data based on graph structure. And it's similar to OLAP in traditional database. But it has features which are not available in traditional database, one is iterative algorithm based on graph. A typical example is the PageRank algorithm from Google, which obtains the relevance of web pages through constant iterative computing. Another example is the commonly-used LPA algorithm. Along the axis to right, there comes the graph streaming field, which is the combination of basic computing and streaming computing. A relational network is not a static structure, rather, it constantly changes in the business: be it graph structure or graph properties. Computing in this filed is often triggered by events and its latency is in second. Right beside the graph streaming is the online response system, whose requirement for latency is extremely high, which should be in millisecond. The rightmost field is graph database and its use cases are completely different from the one on the left. The Nebula Graph we're working on can find its usage here in OLTP.","title":"OLAP &amp; OLTP in Graph"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#native_vs_multi-model","text":"Graph databases can be classified into two kinds: native graph database and multi-model graph database. Using a graph first design, native graph databases are specifically optimized in storage and processing, thus they tend to perform queries faster, scale bigger and run more efficiently, calling for much less hardware at the same time. As for multi-model products, their storage comes from an outside source, such as a relational, columnar, or other NoSQL database. These databases use other algorithms to store data about vertices and edges and can lead to latent results as their storage layer is not optimized for graphs.","title":"Native Vs Multi-Model"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#data_stored_in_graph_database","text":"In graph database, data is stored as graph. Modelling data as graph is natural, and has the nice benefit of staying legible even by non-technical people. The data model handled by Nebula Graph is directed property graph , whose edges are directional and there could be properties on both edges and vertices. It can be represented as: G = < V, E, P V , P E > Here V is a set of nodes, aka vertices, E is a set of directional edges, P V represents properties on vertices, and P E is the properties on edges.","title":"Data Stored in Graph Database"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#nebula_graph_architecture","text":"Designed based on the above features, Nebula Graph is an open source, distributed, lightning-fast graph database, it is composed of four components: storage service, meta service, query engine and client. The dashed line in the above picture divided computing and storage as two independent parts, the upper is the computing service, each machine or virtual machine is stateless and never talks to other so it's easy to scale in or out; the lower is the storage service, it's stateful since data is stored there. Storage service can turn graph semantics into key-values and pass them to the KV-store below it. Between the two is the Raft protocol. The right side is the meta service, similar to the NameNode in HDFS, it stores all metadata like schema and controls scaling.","title":"Nebula Graph Architecture"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#design_thinking_storage_service","text":"Nebula Graph adopted the shared-nothing distributed architecture in storage so nodes do not share memory or storage, which means there are no central nodes in the whole system. Benefits of such design are: Easy to scale The overall system continues operating despite individual crash Another design is the separation of computing and storage , and the benefits are as follows: Scalability. Separating storage from computing makes storage service flexible, thus it's easy to scale out or in. Availability. Recovery from vertex failure can be performed quickly. The binary of storage service is nebula-storaged , which provides a key-value store. Multiple storage engines like RocksDB and HBase are supported, with RocksDB set as the default engine. To build a resilient distributed system, Raft is implemented as the consensus algorithm. Raft achieves data consensus via an elected leader. Based on that, nebula-storaged makes the following optimizations: Parallel Raft Partitions of the same ID from multiple machines form a raft group. And the parallel operations are implemented with multiple sets of Raft groups. Write Path & batch In Raft protocol, the master replicates log entries to all the followers and commits the entries in order. To improve the write throughput, Nebula Graph not only employs the parallel raft, but also implements the dynamic batch replication. Load-balance Migrating the partitions on an overworked server to other relatively idle servers to increases availability and capacity of the system.","title":"Design Thinking: Storage Service"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#design-thinking_meta_service","text":"The binary of the meta service is nebula-metad . Here is the list of its main functionalities: User management In Nebula Graph different roles are assigned diverse privileges. We provide the following native roles: Global Admin, Graph Space Admin, User and Guest. - Cluster configuration management Meta service manages the servers and partitions in the cluster, e.g. records location of the partitions, receives heartbeat from servers, etc. It balances the partitions and manages the communication traffic in case of server failure. - Graph space management Nebula Graph supports multiple graph spaces. Data in different graph spaces are physically isolated. Meta service stores the metadata of all spaces in the cluster and tracks changes that take place in these spaces, like adding, dropping space, modifying graph space configuration (Raft copies). - Schema management Nebula Graph is a strong typed database. Types of tag and edge properties are recorded by meta service. Supported data types are: int, double, timestamp, list, etc. Multi-version management, supporting adding, modifying and deleting schema, and recording its version. TTL (time-to-live) management, supporting automatic data deletion and space reclamation. The meta service is stateful, and just like the storage service, it persists data to a key-value store.","title":"Design-Thinking: Meta Service"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#design-thinking_query_engine","text":"Nebula Graph 's query language nGQL is a SQL-like descriptive language rather than an imperative one. It's compossible but not embeddable, it uses Shell pipe as an alternative, aka output in the former query acts as the input in the latter one. Key features of nGQL are as follows: Main algorithms are built in the query engine Duplicate queries can be avoided by supporting user-defined function (UDF) Programmable The binary of the query engine is nebula-graphd . Each nebula-graphd instance is stateless and never talks to other nebula-graphd. nebula-graphd only talks to the storage service and the meta service. That makes it trivial to expand or shrink the query engine cluster. The query engine accepts the message from the client and generates the execution plan after the lexical parsing (Lexer), semantic analysis (Parser) and the query optimization. Then the execution plan will be passed to the execution engine. The query execution engine takes the query plans and interacts with meta server and the storage engine to retrieve the schema and data. The main optimizations of the query engine are: Asynchronous and parallel execution I/O operations and network transmission are time-consuming. Thus asynchronous and parallel operations are widely adopted in the query engine to reduce the latency and to improve the overall throughput. Also, a separate resource pool is set for each query to avoid the long-tail effect of those time-consuming queries. Pushing down computation In a distributed system, transferring a large amount of data on the network really extends the overall latency. In Nebula Graph , the query engine will make decisions to push some filter and aggregation down to the storage service. The purpose is to reduce the amount of data passing back from the storage.","title":"Design-Thinking: Query Engine"},{"location":"manual-EN/1.overview/3.design-and-architecture/1.design-and-architecture/#design-thinking_api_and_sdk","text":"Nebula Graph provides SDKs in C++, Java, and Golang. Nebula Graph uses fbthrift as the RPC framework to communicate among servers. Nebula Graph 's web console is in progress and will be released soon.","title":"Design-Thinking: API and SDK"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/","text":"Storage Design \u00b6 Abstract \u00b6 This document gives an introduction to the storage design of the graph database Nebula Graph . The Storage Service of Nebula Graph is composed of two parts. One is Meta Service that stores the meta data, the other is Storage Service that stores the data. The two services are in two independent processes. The data directory and deployment are separated but their architectures are almost the same. Architecture \u00b6 Fig. 1 The Architecture of Storage Service As shown in Fig. 1, there are three layers in Storage Service. The bottom layer is the local storage engine, providing get , put , scan and delete operations on local data. The related interfaces are in KVStore/KVEngine.h and users can develop their own local store plugins based on their needs. Currently, Nebula Graph provides store engine based on RocksDB. Above the local storage engine is the consensus layer that implements multi group raft. Each partition corresponding to a Raft group, is for the data sharding. Currently, Nebula Graph uses hash to shard data. When creating a space, users need to specify the partition number. Once set, partition number cannot be changed. Generally, the partition number must meet the need to scale-out in the future. Above the consensus layer is the storage interface that defines a set of APIs that are related to graph. These API requests are translated into a set of kv operations to the corresponding partition. It is this layer that makes the storage service a real graph storage, otherwise it's just a kv storage. Nebula Graph doesn't use kv-store as an independent service as a graph query involves a lot of calculation that involves schema, which is not existed in the kv layer. Such architecture makes computation operation pushing down more easily. Schema & Partition \u00b6 As a graph database, Nebula Graph stores the vertices, edges and their properties. How to efficiently filtering or projecting is critical for a graph exploration. Nebula Graph uses tags to indicate a vertex type. One vertex can have multiple types (and therefore multiple tags), and each tag defines its own properties. In the kv store, we use vertex_ID + Tag_ID together as a key, and the corresponding value are the encoded property. The format is shown in Fig. 2: Fig. 2 Vertex Key Format Type : one byte, to indicate the key type. e.g. data, index, system, etc. Part ID : three bytes, used to indicate the (sharding) partition id. It's designed for the data migration/balance operation by prefix-scanning all the data in a partition. Vertex ID : eight bytes, used to indicate vertex ID. Two vertices with an identity vertexID are considered as the same one. Tag ID : four bytes, used to indicate its tag's (encoded) ID. Timestamp : eight bytes, not visible to users. Reserved for Multiversion concurrency control (MVCC) . Each edge in Nebula Graph is modeled and stored as two independent key-values. One, namely the out-edge , is stored in the same partition as the source vertex . The other one, namely in-edge , is stored in the same partition as the destination vertex . So generally, out-key and in-key are in different partitions. Between two vertices, edges with the same type are acceptable, and different types are legal as well. For example, by defining an edge type ' money-transfer-to ', user A can transfer money to user B at two timestamps. Thus a field, namely rank , is added to (the key part of the timestamp to) distinguish which transfer records is referring. Edge key format is shown in Fig. 3: Fig. 3 Edge Key Format Type : one byte, used to indicate key type. E.g., data, index, system, etc. Part ID : three bytes. The same as in Fig. 2. Vertex ID : eight bytes, used to indicate source vertex ID of an out-edge (Fig. 4), and destination vertex ID of an in-edge (Fig. 5). See below. Edge Type : four bytes, used to indicate (encoded) edge type id. A positive number means that this key is an out-edge , and a negative number indicates that this is an in-edge . Rank : eight bytes, used in multiple edges with the same type. E.g., It can store transaction time , transaction amount , or edge weight . Timestamp : eight bytes. The same as in Fig. 2. If Edge Type is positive, the corresponding edge key format is shown in Fig. 4; otherwise, the corresponding edge key format is shown in Fig. 5. Fig. 4 Out-key format Fig. 5 In-key format Besides the key part above, the value part is the encoded properties (of a vertex or an edge). As a strong typed database, Nebula Graph gets the schema information from the Meta Service before encoding/decoding. And multi-version schema are also considered when altering schema. Nebula Graph shards data through modulo operation on vertex ID . All the out-keys , in-keys and tag id are placed in the same partition. This improves query efficiency as a local/non-remote file access. Breadth-First-Search (BFS) expansion starting from a given vertex is a very common ad-hoc graph exploration. And during BFS, the performance of filtering out edge/vertex properties are time-consuming. Nebula Graph guarantees the operation efficiency by putting properties of a vertex and its edges locating near each other. It is worth noting that most graph databases vendors run their benchmarks with Graph 500 or Twitter data set, which are of no eloquence because the properties are not taken into consideration in this kind of graph exploration. While most production cases are not that simple. KVStore \u00b6 Nebula Graph writes its own kv store to meet the performance needs: High performance , a pure high performance key value store. Provided as a library , as a strong typed database, the performance of storage layer is key to Nebula Graph . Strong data consistency , since Nebula Graph is a distribution system. Written in C++ , as most of our developers are C++ programers. For users who are not sensitive to performance or unwilling to migrate data from other storage systems, such as HBase or MySQL, Nebula Graph also provides a plugin over the kv store to replace its default RocksDB. Currently, HBase plugin has been released yet. As RocksDB is the local storage engine, Nebula Graph can manage multiple hard disks to take full use of the parallel IO access. What a user needs to do is to configure multiple data directories. Nebula Graph manages the distributed kv store in with meta service. All the partition distribution and cluster machine status can be found in the meta service. Users can input commands in the console to add or remove machines to generate and execute a balance plan in meta service. Nebula Graph writes its own (Write-Ahead-Log, WAL) module to replace the default one in RocksDB. Since the WAL is used for (distributed system's) Raft consensus. Each partition has a WAL, so after a (crash and) reboot, the partition can catch up its own data, and there is no need to split WAL between several partitions. Besides, Nebula Graph defines a special category, namely Command Operation Log , to conduct some command operations. These logs are very short, with no real data, and are only used to inform all replicas to execute certain command operations with raft protocol. What's more, since the logs are serialized in the Raft protocol, Nebula Graph also provides another class, namely Atomic Operation Log , to conduct the atomic operation between the replicas of a partitions. E.g., the compare-and-set (CAS) or read-modify-write operations are atomic in Nebula Graph per partition. A Nebula Graph cluster can have multiple individual graph spaces. Each space has its own partition number and replica copies. Different spaces are isolated physically from each other in the same cluster. Besides, the spaces can also have very different storage engines and sharding strategies. E.g., One space can use HBase as its storage backend with alphabet ranging sharding, and the other space uses the default RocksDB with hashing sharding. And these two spaces are running in the same Nebula Graph cluster. Raft Implementation \u00b6 This part gives some details on how the raft protocol is implemented in Nebula Graph . Multi Raft Group \u00b6 According to Raft requirement, the log ID must be in a sequential order. Therefore, almost all the raft implementations will use Multi Raft Group to increase the concurrency. Therefore, the number of partition will determine how many operations can be executed simultaneously. But you can not simply add too much partitions in the system, which can have some side affects. Each raft group stores many state information and (as mentioned earlier) it has a WAL file. Thus, the more partitions, the more footprint costs. Also, if the work load is low, the batch operation can not gain from the parallel. E.g., consider a system with ten thousand partitions. For every second, there are about ten thousands write-in requests. You can calculate that in average, for every partition, there is only one write-in request. So from the client side, it's a 100k batch write. But from the partition side, it's a single write. There are two key challenges to implement the Multi Raft Group. First one is how to share the transport layer . Because each Raft Group sends messages to its corresponding peers, if the transport layer cannot be shared, the connection costs will be very high. Second one is how to design the multi-threading model . Raft Groups share the same thread pool to prevent starting too many threads and a high context switch cost. Batch \u00b6 For each Partition, it is necessary to do batch multiple operations together to improve throughput when writing WAL serially. In general, there is nothing special about batch, but Nebula Graph designs some special types of WAL based on each part serialization, which brings some challenges. For example, Nebula Graph uses WAL to implement lock-free CAS operations. And every CAS operation will be executed until the previous WAL has been committed. So for a batch, if there are some logs contain CAS operation, we need to divide this batch into several smaller (sub)groups. And make sure these (sub)groups are executed in sequential order. Learner \u00b6 When a new machine is added to a cluster, it has to catch up data for quite a long time. And there may be accidents during this process. If this one directly joins the raft group as a follower role, it will dramatically reduce the availability of the entire cluster. Nebula Graph introduces the learner role, and it is implemented by the command WAL mentioned above. When a leader is writing WAL and meets an add learner command , it will add the new coming-in learner to its peers list and mark it as a learner. The logs will send to all the peers, both the followers and the learner. But the learner can not vote for the leader's election. Transfer Leadership \u00b6 Transfer leadership is extremely important during a data balance operation. When migrating a partition from one machine to another, Nebula Graph will first check if it is a leader. If so, another follower should be elected as a leader before the migration. Otherwise, the cluster service is affected since the leader is on migration. After the migration is done, a BALANCE LEADER command is invoked, so that the work load on each machine can be balanced. When transferring leadership, it is worth noting the timing when a leader abandons the leadership and when all the followers start a leader election. When a transfer leadership command is committed, from the leader's view, it loses the leadership. From other followers' view, when receiving this command, it starts a new leader election. These two operations must be executed in the same process with a normal raft leader election. Otherwise, some corner cases can occur and they are very hard to test. Membership Change \u00b6 To avoid the brain-split, when Raft Group members changed, an intermediate state is required. In such state, the majority of the old group and new group always have an overlap. This majority overlap will prevent neither group from making decisions unilaterally. This is the joint consensus as mentioned in the famous Raft thesis. To make it even simpler, Diego Ongaro suggests to add or remove only one peer at a time to ensure the overlap between the majority in his doctoral thesis. Nebula Graph 's implementation also uses this approach, except that the implementation to add or remove member is different. For details, please refer to addPeer/removePeer in Raft Part source code. Snapshot \u00b6 Take snapshot is a common command during daily DBA operations. But snapshot operation will introduce extra challenges when considering together with the raft protocol. It's very error-prone. E.g., what if the leader loses its leadership in an election when sending a snapshot command. What should we do. In this situation, the follower may only receive half log of the snapshot command, should we cleanup and rollback? Because multiple partitions share a single storage, how to clean up the data is a cumbersome work. In addition, the snapshot process will start a heavy write to disks. To avoid slow down the frontend reads and writes, we do not want snapshot process to share the same IO threadPool with the normal Raft logs. Besides, snapshot also requires large footprint, which is critical for online service performance. Storage Service \u00b6 The Interfaces of Storage Service layer are: Insert vertex/edge : insert a vertex or edge and its properties. getNeighbors : get the in-edge or out-edge from a set of vertices. And return the edges and properties. Condition filtering are also considered. getProps : get the properties of a vertex or an edge. Graph semantics interfaces are translated into kv operations in this layer as well. In order to improve the performance, concurrent operations are also implemented in this layer. Meta Service \u00b6 Nebula Graph wrap up a set of meta-related interfaces from the kv store interface (as mentioned earlier). Meta service can support CRUD operation on schema, cluster administration and user privileges. Meta service can be deployed on a single host, but it is recommended to deploy on multiple hosts with at least three or five replicas to get a better availability and fault tolerance.","title":"Storage Design"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#storage_design","text":"","title":"Storage Design"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#abstract","text":"This document gives an introduction to the storage design of the graph database Nebula Graph . The Storage Service of Nebula Graph is composed of two parts. One is Meta Service that stores the meta data, the other is Storage Service that stores the data. The two services are in two independent processes. The data directory and deployment are separated but their architectures are almost the same.","title":"Abstract"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#architecture","text":"Fig. 1 The Architecture of Storage Service As shown in Fig. 1, there are three layers in Storage Service. The bottom layer is the local storage engine, providing get , put , scan and delete operations on local data. The related interfaces are in KVStore/KVEngine.h and users can develop their own local store plugins based on their needs. Currently, Nebula Graph provides store engine based on RocksDB. Above the local storage engine is the consensus layer that implements multi group raft. Each partition corresponding to a Raft group, is for the data sharding. Currently, Nebula Graph uses hash to shard data. When creating a space, users need to specify the partition number. Once set, partition number cannot be changed. Generally, the partition number must meet the need to scale-out in the future. Above the consensus layer is the storage interface that defines a set of APIs that are related to graph. These API requests are translated into a set of kv operations to the corresponding partition. It is this layer that makes the storage service a real graph storage, otherwise it's just a kv storage. Nebula Graph doesn't use kv-store as an independent service as a graph query involves a lot of calculation that involves schema, which is not existed in the kv layer. Such architecture makes computation operation pushing down more easily.","title":"Architecture"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#schema_partition","text":"As a graph database, Nebula Graph stores the vertices, edges and their properties. How to efficiently filtering or projecting is critical for a graph exploration. Nebula Graph uses tags to indicate a vertex type. One vertex can have multiple types (and therefore multiple tags), and each tag defines its own properties. In the kv store, we use vertex_ID + Tag_ID together as a key, and the corresponding value are the encoded property. The format is shown in Fig. 2: Fig. 2 Vertex Key Format Type : one byte, to indicate the key type. e.g. data, index, system, etc. Part ID : three bytes, used to indicate the (sharding) partition id. It's designed for the data migration/balance operation by prefix-scanning all the data in a partition. Vertex ID : eight bytes, used to indicate vertex ID. Two vertices with an identity vertexID are considered as the same one. Tag ID : four bytes, used to indicate its tag's (encoded) ID. Timestamp : eight bytes, not visible to users. Reserved for Multiversion concurrency control (MVCC) . Each edge in Nebula Graph is modeled and stored as two independent key-values. One, namely the out-edge , is stored in the same partition as the source vertex . The other one, namely in-edge , is stored in the same partition as the destination vertex . So generally, out-key and in-key are in different partitions. Between two vertices, edges with the same type are acceptable, and different types are legal as well. For example, by defining an edge type ' money-transfer-to ', user A can transfer money to user B at two timestamps. Thus a field, namely rank , is added to (the key part of the timestamp to) distinguish which transfer records is referring. Edge key format is shown in Fig. 3: Fig. 3 Edge Key Format Type : one byte, used to indicate key type. E.g., data, index, system, etc. Part ID : three bytes. The same as in Fig. 2. Vertex ID : eight bytes, used to indicate source vertex ID of an out-edge (Fig. 4), and destination vertex ID of an in-edge (Fig. 5). See below. Edge Type : four bytes, used to indicate (encoded) edge type id. A positive number means that this key is an out-edge , and a negative number indicates that this is an in-edge . Rank : eight bytes, used in multiple edges with the same type. E.g., It can store transaction time , transaction amount , or edge weight . Timestamp : eight bytes. The same as in Fig. 2. If Edge Type is positive, the corresponding edge key format is shown in Fig. 4; otherwise, the corresponding edge key format is shown in Fig. 5. Fig. 4 Out-key format Fig. 5 In-key format Besides the key part above, the value part is the encoded properties (of a vertex or an edge). As a strong typed database, Nebula Graph gets the schema information from the Meta Service before encoding/decoding. And multi-version schema are also considered when altering schema. Nebula Graph shards data through modulo operation on vertex ID . All the out-keys , in-keys and tag id are placed in the same partition. This improves query efficiency as a local/non-remote file access. Breadth-First-Search (BFS) expansion starting from a given vertex is a very common ad-hoc graph exploration. And during BFS, the performance of filtering out edge/vertex properties are time-consuming. Nebula Graph guarantees the operation efficiency by putting properties of a vertex and its edges locating near each other. It is worth noting that most graph databases vendors run their benchmarks with Graph 500 or Twitter data set, which are of no eloquence because the properties are not taken into consideration in this kind of graph exploration. While most production cases are not that simple.","title":"Schema &amp; Partition"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#kvstore","text":"Nebula Graph writes its own kv store to meet the performance needs: High performance , a pure high performance key value store. Provided as a library , as a strong typed database, the performance of storage layer is key to Nebula Graph . Strong data consistency , since Nebula Graph is a distribution system. Written in C++ , as most of our developers are C++ programers. For users who are not sensitive to performance or unwilling to migrate data from other storage systems, such as HBase or MySQL, Nebula Graph also provides a plugin over the kv store to replace its default RocksDB. Currently, HBase plugin has been released yet. As RocksDB is the local storage engine, Nebula Graph can manage multiple hard disks to take full use of the parallel IO access. What a user needs to do is to configure multiple data directories. Nebula Graph manages the distributed kv store in with meta service. All the partition distribution and cluster machine status can be found in the meta service. Users can input commands in the console to add or remove machines to generate and execute a balance plan in meta service. Nebula Graph writes its own (Write-Ahead-Log, WAL) module to replace the default one in RocksDB. Since the WAL is used for (distributed system's) Raft consensus. Each partition has a WAL, so after a (crash and) reboot, the partition can catch up its own data, and there is no need to split WAL between several partitions. Besides, Nebula Graph defines a special category, namely Command Operation Log , to conduct some command operations. These logs are very short, with no real data, and are only used to inform all replicas to execute certain command operations with raft protocol. What's more, since the logs are serialized in the Raft protocol, Nebula Graph also provides another class, namely Atomic Operation Log , to conduct the atomic operation between the replicas of a partitions. E.g., the compare-and-set (CAS) or read-modify-write operations are atomic in Nebula Graph per partition. A Nebula Graph cluster can have multiple individual graph spaces. Each space has its own partition number and replica copies. Different spaces are isolated physically from each other in the same cluster. Besides, the spaces can also have very different storage engines and sharding strategies. E.g., One space can use HBase as its storage backend with alphabet ranging sharding, and the other space uses the default RocksDB with hashing sharding. And these two spaces are running in the same Nebula Graph cluster.","title":"KVStore"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#raft_implementation","text":"This part gives some details on how the raft protocol is implemented in Nebula Graph .","title":"Raft Implementation"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#multi_raft_group","text":"According to Raft requirement, the log ID must be in a sequential order. Therefore, almost all the raft implementations will use Multi Raft Group to increase the concurrency. Therefore, the number of partition will determine how many operations can be executed simultaneously. But you can not simply add too much partitions in the system, which can have some side affects. Each raft group stores many state information and (as mentioned earlier) it has a WAL file. Thus, the more partitions, the more footprint costs. Also, if the work load is low, the batch operation can not gain from the parallel. E.g., consider a system with ten thousand partitions. For every second, there are about ten thousands write-in requests. You can calculate that in average, for every partition, there is only one write-in request. So from the client side, it's a 100k batch write. But from the partition side, it's a single write. There are two key challenges to implement the Multi Raft Group. First one is how to share the transport layer . Because each Raft Group sends messages to its corresponding peers, if the transport layer cannot be shared, the connection costs will be very high. Second one is how to design the multi-threading model . Raft Groups share the same thread pool to prevent starting too many threads and a high context switch cost.","title":"Multi Raft Group"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#batch","text":"For each Partition, it is necessary to do batch multiple operations together to improve throughput when writing WAL serially. In general, there is nothing special about batch, but Nebula Graph designs some special types of WAL based on each part serialization, which brings some challenges. For example, Nebula Graph uses WAL to implement lock-free CAS operations. And every CAS operation will be executed until the previous WAL has been committed. So for a batch, if there are some logs contain CAS operation, we need to divide this batch into several smaller (sub)groups. And make sure these (sub)groups are executed in sequential order.","title":"Batch"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#learner","text":"When a new machine is added to a cluster, it has to catch up data for quite a long time. And there may be accidents during this process. If this one directly joins the raft group as a follower role, it will dramatically reduce the availability of the entire cluster. Nebula Graph introduces the learner role, and it is implemented by the command WAL mentioned above. When a leader is writing WAL and meets an add learner command , it will add the new coming-in learner to its peers list and mark it as a learner. The logs will send to all the peers, both the followers and the learner. But the learner can not vote for the leader's election.","title":"Learner"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#transfer_leadership","text":"Transfer leadership is extremely important during a data balance operation. When migrating a partition from one machine to another, Nebula Graph will first check if it is a leader. If so, another follower should be elected as a leader before the migration. Otherwise, the cluster service is affected since the leader is on migration. After the migration is done, a BALANCE LEADER command is invoked, so that the work load on each machine can be balanced. When transferring leadership, it is worth noting the timing when a leader abandons the leadership and when all the followers start a leader election. When a transfer leadership command is committed, from the leader's view, it loses the leadership. From other followers' view, when receiving this command, it starts a new leader election. These two operations must be executed in the same process with a normal raft leader election. Otherwise, some corner cases can occur and they are very hard to test.","title":"Transfer Leadership"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#membership_change","text":"To avoid the brain-split, when Raft Group members changed, an intermediate state is required. In such state, the majority of the old group and new group always have an overlap. This majority overlap will prevent neither group from making decisions unilaterally. This is the joint consensus as mentioned in the famous Raft thesis. To make it even simpler, Diego Ongaro suggests to add or remove only one peer at a time to ensure the overlap between the majority in his doctoral thesis. Nebula Graph 's implementation also uses this approach, except that the implementation to add or remove member is different. For details, please refer to addPeer/removePeer in Raft Part source code.","title":"Membership Change"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#snapshot","text":"Take snapshot is a common command during daily DBA operations. But snapshot operation will introduce extra challenges when considering together with the raft protocol. It's very error-prone. E.g., what if the leader loses its leadership in an election when sending a snapshot command. What should we do. In this situation, the follower may only receive half log of the snapshot command, should we cleanup and rollback? Because multiple partitions share a single storage, how to clean up the data is a cumbersome work. In addition, the snapshot process will start a heavy write to disks. To avoid slow down the frontend reads and writes, we do not want snapshot process to share the same IO threadPool with the normal Raft logs. Besides, snapshot also requires large footprint, which is critical for online service performance.","title":"Snapshot"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#storage_service","text":"The Interfaces of Storage Service layer are: Insert vertex/edge : insert a vertex or edge and its properties. getNeighbors : get the in-edge or out-edge from a set of vertices. And return the edges and properties. Condition filtering are also considered. getProps : get the properties of a vertex or an edge. Graph semantics interfaces are translated into kv operations in this layer as well. In order to improve the performance, concurrent operations are also implemented in this layer.","title":"Storage Service"},{"location":"manual-EN/1.overview/3.design-and-architecture/2.storage-design/#meta_service","text":"Nebula Graph wrap up a set of meta-related interfaces from the kv store interface (as mentioned earlier). Meta service can support CRUD operation on schema, cluster administration and user privileges. Meta service can be deployed on a single host, but it is recommended to deploy on multiple hosts with at least three or five replicas to get a better availability and fault tolerance.","title":"Meta Service"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/","text":"Query Engine Overview \u00b6 The query engine is used to process the Nebula Graph Query Language (nGQL) statements. This article gives an architectural overview of the Nebula Graph query engine. Above is the overview chart of the query engine. If you are familiar with the SQL execution engine, this should be no stranger to you. In fact, the Nebula Graph query engine is very similar to the modern SQL execution engine except the query language parser and the real actions in the execution plan. Session Manager \u00b6 Nebula Graph employs the Role Based Access Control. So when the client first connects to the Query Engine, it needs to authenticate itself. When it succeeds, the query engine creates a new session and returns the session ID to the client. All sessions are managed by the Session Manager. The session will remember the current graph space and the access rights to the space. The session will keep some session-wide configurations and be used as an temporary storage to store information across multiple requests in the same session as well. The session will be dropped when the client connection is closed, or being idle for a period of time. The length of the idle time is configurable. When the client sends a request to the query engine, it needs to attach the current session ID, otherwise, the query engine will reject the request. When the query engine accesses the storage engines, it will attach the session object to every request, so that the storage engine does not have to manage sessions. Parser \u00b6 The first thing that the query engine will do when receiving a request is to parse the statements in the request. This is done by the parser. The majority of the parser code is generated by the famous flex/bison tool set. The lexicon and syntax files for the nGQL can be found in the src/parser folder in the source code tree. The nGQL is designed in a way that is close enough to SQL. The idea is to smoothen the learning curve as much as possible. Graph databases currently do not have a unified international query language standard. As soon as the ISO's GQL committee releases their first draft, we will make nGQL compatible with the proposed GQL. The output of the parser is an Abstract Syntax Tree (AST), which will be passed on to the next module: Execution Planner. Execution Planner \u00b6 The Execution Planner will convert the AST from the parser into a list of actions (execution plan). An action is the smallest unit that can be executed. A typical action could be fetching all neighbors for a given vertex, getting properties for an edge, or filtering vertices or edges based on the given condition. When converting AST to the execution plan, all IDs will be extracted, so that the execution plan can be reused. The extracted IDs will be placed in the context for the current request. The context will be used to store the variables and intermediate results as well. Optimization \u00b6 The newly generated execution plan will then be passed to the Optimization Framework. There are multiple optimizers registered in the framework. The execution plan will be passed through all optimizers sequentially. Each optimizer has the opportunity to modify (optimize) the plan. At the end, the final plan can look dramatically different from the original plan, but the execution result should be exactly same as the original plan. Execution \u00b6 The last step in the query engine is to execute the optimized execution plan. It's done by the Execution Framework. Each executor will process one execution plan at a time. Actions in the plan will be executed one by one. The executor will do limited local optimization as well, such as deciding whether to run in parallel. Depending on the action, the executor will communicate with the Meta Service or the Storage Engine via their clients.","title":"Query Engine"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/#query_engine_overview","text":"The query engine is used to process the Nebula Graph Query Language (nGQL) statements. This article gives an architectural overview of the Nebula Graph query engine. Above is the overview chart of the query engine. If you are familiar with the SQL execution engine, this should be no stranger to you. In fact, the Nebula Graph query engine is very similar to the modern SQL execution engine except the query language parser and the real actions in the execution plan.","title":"Query Engine Overview"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/#session_manager","text":"Nebula Graph employs the Role Based Access Control. So when the client first connects to the Query Engine, it needs to authenticate itself. When it succeeds, the query engine creates a new session and returns the session ID to the client. All sessions are managed by the Session Manager. The session will remember the current graph space and the access rights to the space. The session will keep some session-wide configurations and be used as an temporary storage to store information across multiple requests in the same session as well. The session will be dropped when the client connection is closed, or being idle for a period of time. The length of the idle time is configurable. When the client sends a request to the query engine, it needs to attach the current session ID, otherwise, the query engine will reject the request. When the query engine accesses the storage engines, it will attach the session object to every request, so that the storage engine does not have to manage sessions.","title":"Session Manager"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/#parser","text":"The first thing that the query engine will do when receiving a request is to parse the statements in the request. This is done by the parser. The majority of the parser code is generated by the famous flex/bison tool set. The lexicon and syntax files for the nGQL can be found in the src/parser folder in the source code tree. The nGQL is designed in a way that is close enough to SQL. The idea is to smoothen the learning curve as much as possible. Graph databases currently do not have a unified international query language standard. As soon as the ISO's GQL committee releases their first draft, we will make nGQL compatible with the proposed GQL. The output of the parser is an Abstract Syntax Tree (AST), which will be passed on to the next module: Execution Planner.","title":"Parser"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/#execution_planner","text":"The Execution Planner will convert the AST from the parser into a list of actions (execution plan). An action is the smallest unit that can be executed. A typical action could be fetching all neighbors for a given vertex, getting properties for an edge, or filtering vertices or edges based on the given condition. When converting AST to the execution plan, all IDs will be extracted, so that the execution plan can be reused. The extracted IDs will be placed in the context for the current request. The context will be used to store the variables and intermediate results as well.","title":"Execution Planner"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/#optimization","text":"The newly generated execution plan will then be passed to the Optimization Framework. There are multiple optimizers registered in the framework. The execution plan will be passed through all optimizers sequentially. Each optimizer has the opportunity to modify (optimize) the plan. At the end, the final plan can look dramatically different from the original plan, but the execution result should be exactly same as the original plan.","title":"Optimization"},{"location":"manual-EN/1.overview/3.design-and-architecture/3.query-engine/#execution","text":"The last step in the query engine is to execute the optimized execution plan. It's done by the Execution Framework. Each executor will process one execution plan at a time. Actions in the plan will be executed one by one. The executor will do limited local optimization as well, such as deciding whether to run in parallel. Depending on the action, the executor will communicate with the Meta Service or the Storage Engine via their clients.","title":"Execution"},{"location":"manual-EN/2.query-language/0.README/","text":"Reader \u00b6 This chapter is for those who want to use Nebula Graph query language. Example Data \u00b6 The example data used in Nebula Graph query statements can be downloaded here . After downloading the example data, you can import it to your Nebula Graph database with Nebula Graph Studio . Placeholder Identifiers and Values \u00b6 The query language of Nebula Graph is nGQL. Refer to the following standards in nGQL: ISO/IEC 10646 ISO/IEC 39075 ISO/IEC NP 39075 (Draft) In template code, any token that is not a keyword, a literal value, or punctuation is a placeholder identifier or a placeholder value. For details of the symbols in nGQL, refer to the following table: Token Meaning < > name of a syntactic element ::= formula that defines an element [ ] optional elements { } explicitly specified elements | complete alternative elements ... may be repeated any number of times","title":"Reader"},{"location":"manual-EN/2.query-language/0.README/#reader","text":"This chapter is for those who want to use Nebula Graph query language.","title":"Reader"},{"location":"manual-EN/2.query-language/0.README/#example_data","text":"The example data used in Nebula Graph query statements can be downloaded here . After downloading the example data, you can import it to your Nebula Graph database with Nebula Graph Studio .","title":"Example Data"},{"location":"manual-EN/2.query-language/0.README/#placeholder_identifiers_and_values","text":"The query language of Nebula Graph is nGQL. Refer to the following standards in nGQL: ISO/IEC 10646 ISO/IEC 39075 ISO/IEC NP 39075 (Draft) In template code, any token that is not a keyword, a literal value, or punctuation is a placeholder identifier or a placeholder value. For details of the symbols in nGQL, refer to the following table: Token Meaning < > name of a syntactic element ::= formula that defines an element [ ] optional elements { } explicitly specified elements | complete alternative elements ... may be repeated any number of times","title":"Placeholder Identifiers and Values"},{"location":"manual-EN/2.query-language/1.data-types/data-types/","text":"Data Types \u00b6 The built-in data types supported by Nebula Graph are as follows: Numeric Types \u00b6 Integer \u00b6 An integer is declared with keyword int , which is 64-bit signed , the range is [-9223372036854775808, 9223372036854775807], and there is no overflow in int64-based calculation. Integer constants support multiple formats: Decimal, for example 123456 Hexadecimal, for example 0xdeadbeaf Octal, for example 01234567 Boolean \u00b6 A boolean data type is declared with the bool keyword and can only take the values true or false . String \u00b6 The string type is used to store a sequence of characters (text). The literal constant is a sequence of characters of any length surrounded by double or single quotes. Line breaks are not allowed in a string. For example \"Shaquile O'Neal\" , '\"This is a double-quoted literal string\"' . Embedding escape sequences are supported within strings, for example: 1. \"\\n\\t\\r\\b\\f\" 1. \"\\110ello world\" Timestamp \u00b6 The supported range of timestamp type is '1970-01-01 00:00:01' UTC to '2262-04-11 23:47:16' UTC Timestamp is measured in units of seconds Supported data inserting methods call function now() Time string, for example: \"2019-10-01 10:00:00\" Input the timestamp directly, namely the number of seconds from 1970-01-01 00:00:00 Nebula Graph converts TIMESTAMP values from the current time zone to UTC for storage, and back from UTC to the current time zone for retrieval The underlying storage data type is: int64 Examples Create a tag named school nebula> CREATE TAG school(name string , create_time timestamp); Insert a vertex named \"stanford\" with the foundation date \"1885-10-01 08:00:00\" nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"new\"):(\"new\", \"1985-10-01 08:00:00\") Insert a vertex named \"dut\" with the foundation date now nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"dut\"):(\"dut\", now())","title":"Data Types"},{"location":"manual-EN/2.query-language/1.data-types/data-types/#data_types","text":"The built-in data types supported by Nebula Graph are as follows:","title":"Data Types"},{"location":"manual-EN/2.query-language/1.data-types/data-types/#numeric_types","text":"","title":"Numeric Types"},{"location":"manual-EN/2.query-language/1.data-types/data-types/#integer","text":"An integer is declared with keyword int , which is 64-bit signed , the range is [-9223372036854775808, 9223372036854775807], and there is no overflow in int64-based calculation. Integer constants support multiple formats: Decimal, for example 123456 Hexadecimal, for example 0xdeadbeaf Octal, for example 01234567","title":"Integer"},{"location":"manual-EN/2.query-language/1.data-types/data-types/#boolean","text":"A boolean data type is declared with the bool keyword and can only take the values true or false .","title":"Boolean"},{"location":"manual-EN/2.query-language/1.data-types/data-types/#string","text":"The string type is used to store a sequence of characters (text). The literal constant is a sequence of characters of any length surrounded by double or single quotes. Line breaks are not allowed in a string. For example \"Shaquile O'Neal\" , '\"This is a double-quoted literal string\"' . Embedding escape sequences are supported within strings, for example: 1. \"\\n\\t\\r\\b\\f\" 1. \"\\110ello world\"","title":"String"},{"location":"manual-EN/2.query-language/1.data-types/data-types/#timestamp","text":"The supported range of timestamp type is '1970-01-01 00:00:01' UTC to '2262-04-11 23:47:16' UTC Timestamp is measured in units of seconds Supported data inserting methods call function now() Time string, for example: \"2019-10-01 10:00:00\" Input the timestamp directly, namely the number of seconds from 1970-01-01 00:00:00 Nebula Graph converts TIMESTAMP values from the current time zone to UTC for storage, and back from UTC to the current time zone for retrieval The underlying storage data type is: int64 Examples Create a tag named school nebula> CREATE TAG school(name string , create_time timestamp); Insert a vertex named \"stanford\" with the foundation date \"1885-10-01 08:00:00\" nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"new\"):(\"new\", \"1985-10-01 08:00:00\") Insert a vertex named \"dut\" with the foundation date now nebula> INSERT VERTEX school(name, create_time) VALUES hash(\"dut\"):(\"dut\", now())","title":"Timestamp"},{"location":"manual-EN/2.query-language/1.data-types/type-conversion/","text":"Type Conversion \u00b6 Converting an expression of a given type to another type is known as type-conversion. In nGQL, type conversion is divided into implicit conversion and explicit conversion. Implicit Type Conversion \u00b6 Implicit conversions are automatically performed when a value is copied to a compatible type. Following types can implicitly converted to bool : The conversions from/to bool consider false equivalent to 0 for empty string types, true is equivalent to all other values. The conversions from/to bool consider false equivalent to 0 for int types, true is equivalent to all other values. The conversions from/to bool consider false equivalent to 0.0 for float types, true is equivalent to all other values. int can implicitly converted to double . Explicit Type Conversion \u00b6 In addition to implicit type conversion, explicit type conversion is also supported in case of semantics compliance. The syntax is similar to the C language: (type_name)expression . For example, the results of YIELD length((string)(123)), (int)\"123\" + 1 are 3, 124 respectively. And YIELD (int)(\"12ab3\") fails in conversion.","title":"Type Conversion"},{"location":"manual-EN/2.query-language/1.data-types/type-conversion/#type_conversion","text":"Converting an expression of a given type to another type is known as type-conversion. In nGQL, type conversion is divided into implicit conversion and explicit conversion.","title":"Type Conversion"},{"location":"manual-EN/2.query-language/1.data-types/type-conversion/#implicit_type_conversion","text":"Implicit conversions are automatically performed when a value is copied to a compatible type. Following types can implicitly converted to bool : The conversions from/to bool consider false equivalent to 0 for empty string types, true is equivalent to all other values. The conversions from/to bool consider false equivalent to 0 for int types, true is equivalent to all other values. The conversions from/to bool consider false equivalent to 0.0 for float types, true is equivalent to all other values. int can implicitly converted to double .","title":"Implicit Type Conversion"},{"location":"manual-EN/2.query-language/1.data-types/type-conversion/#explicit_type_conversion","text":"In addition to implicit type conversion, explicit type conversion is also supported in case of semantics compliance. The syntax is similar to the C language: (type_name)expression . For example, the results of YIELD length((string)(123)), (int)\"123\" + 1 are 3, 124 respectively. And YIELD (int)(\"12ab3\") fails in conversion.","title":"Explicit Type Conversion"},{"location":"manual-EN/2.query-language/2.functions-and-operators/bitwise-operators/","text":"Bitwise Operators \u00b6 Name Description & Bitwise AND | Bitwise OR ^ Bitwise exclusive OR (XOR)","title":"Bitwise Operators"},{"location":"manual-EN/2.query-language/2.functions-and-operators/bitwise-operators/#bitwise_operators","text":"Name Description & Bitwise AND | Bitwise OR ^ Bitwise exclusive OR (XOR)","title":"Bitwise Operators"},{"location":"manual-EN/2.query-language/2.functions-and-operators/built-in-functions/","text":"Built-in Functions \u00b6 Nebula Graph supports calling built-in functions of the following types: Math \u00b6 Function Description double abs(double x) Return absolute value of the argument double floor(double x) Return the largest integer value smaller than or equal to the argument. (Rounds down) double ceil(double x) Return the smallest integer greater than or equal to the argument. (Rounds up) double round(double x) Return integral value nearest to the argument, returns a number farther away from 0 if the parameter is in the middle double sqrt(double x) Return the square root of the argument double cbrt(double x) Return the cubic root of the argument double hypot(double x, double x) Return the hypotenuse of a right-angled triangle double pow(double x, double y) Compute the power of the argument double exp(double x) Return the value of e raised to the x power double exp2(double x) Return 2 raised to the argument double log(double x) Return natural logarithm of the argument double log2(double x) Return the base-2 logarithm of the argument double log10(double x) Return the base-10 logarithm of the argument double sin(double x) Return sine of the argument double asin(double x) Return inverse sine of the argument double cos(double x) Return cosine of the argument double acos(double x) Return inverse cosine of the argument double tan(double x) Return tangent of the argument double atan(double x) Return inverse tangent the argument int rand32() Return a random 32 bit integer int rand32(int max) Return a random 32 bit integer in [0, max) int rand32(int min, int max) Return a random 32 bit integer in [min, max) int rand64() Return a random 64 bit integer int rand64(int max) Return a random 64 bit integer in [0, max) int rand64(int min, int max) Return a random 64 bit integer in [min, max) String \u00b6 NOTE: Like SQL, nGQL's character index (location) starts at 1 , not like C language from 0 . Function Description int strcasecmp(string a, string b) Compare strings without case sensitivity, when a = b, return 0, when a > b returned value is greater than 0, otherwise less than 0 string lower(string a) Return the argument in lowercase string upper(string a) Return the argument in uppercase int length(string a) Return length (int) of given string in bytes string trim(string a) Remove leading and trailing spaces string ltrim(string a) Remove leading spaces string rtrim(string a) Remove trailing spaces string left(string a, int count) Return the substring in [1, count], if length a is less than count, return a string right(string a, int count) Return the substring in [size - count + 1, size], if length a is less than count, return a string lpad(string a, int size, string letters) Left-pads a string with another string to a certain length string rpad(string a, int size, string letters) Reft-pads a string with another string to a certain length string substr(string a, int pos, int count) Extract a substring from a string, starting at the specified position, extract the specified length characters int hash(string a) Encode the data into integer value Explanations on the returns of function substr : If pos is 0, return empty string If the absolute value of pos is greater than the string, return empty string If pos is greater than 0, return substring in [pos, pos + count) If pos is less than 0, and set position N as length(a) + pos + 1, return substring in [N, N + count) If count is greater than length(a), return the whole string Timestamp \u00b6 Function Description int now() Return the current date and time","title":"Built in Functions"},{"location":"manual-EN/2.query-language/2.functions-and-operators/built-in-functions/#built-in_functions","text":"Nebula Graph supports calling built-in functions of the following types:","title":"Built-in Functions"},{"location":"manual-EN/2.query-language/2.functions-and-operators/built-in-functions/#math","text":"Function Description double abs(double x) Return absolute value of the argument double floor(double x) Return the largest integer value smaller than or equal to the argument. (Rounds down) double ceil(double x) Return the smallest integer greater than or equal to the argument. (Rounds up) double round(double x) Return integral value nearest to the argument, returns a number farther away from 0 if the parameter is in the middle double sqrt(double x) Return the square root of the argument double cbrt(double x) Return the cubic root of the argument double hypot(double x, double x) Return the hypotenuse of a right-angled triangle double pow(double x, double y) Compute the power of the argument double exp(double x) Return the value of e raised to the x power double exp2(double x) Return 2 raised to the argument double log(double x) Return natural logarithm of the argument double log2(double x) Return the base-2 logarithm of the argument double log10(double x) Return the base-10 logarithm of the argument double sin(double x) Return sine of the argument double asin(double x) Return inverse sine of the argument double cos(double x) Return cosine of the argument double acos(double x) Return inverse cosine of the argument double tan(double x) Return tangent of the argument double atan(double x) Return inverse tangent the argument int rand32() Return a random 32 bit integer int rand32(int max) Return a random 32 bit integer in [0, max) int rand32(int min, int max) Return a random 32 bit integer in [min, max) int rand64() Return a random 64 bit integer int rand64(int max) Return a random 64 bit integer in [0, max) int rand64(int min, int max) Return a random 64 bit integer in [min, max)","title":"Math"},{"location":"manual-EN/2.query-language/2.functions-and-operators/built-in-functions/#string","text":"NOTE: Like SQL, nGQL's character index (location) starts at 1 , not like C language from 0 . Function Description int strcasecmp(string a, string b) Compare strings without case sensitivity, when a = b, return 0, when a > b returned value is greater than 0, otherwise less than 0 string lower(string a) Return the argument in lowercase string upper(string a) Return the argument in uppercase int length(string a) Return length (int) of given string in bytes string trim(string a) Remove leading and trailing spaces string ltrim(string a) Remove leading spaces string rtrim(string a) Remove trailing spaces string left(string a, int count) Return the substring in [1, count], if length a is less than count, return a string right(string a, int count) Return the substring in [size - count + 1, size], if length a is less than count, return a string lpad(string a, int size, string letters) Left-pads a string with another string to a certain length string rpad(string a, int size, string letters) Reft-pads a string with another string to a certain length string substr(string a, int pos, int count) Extract a substring from a string, starting at the specified position, extract the specified length characters int hash(string a) Encode the data into integer value Explanations on the returns of function substr : If pos is 0, return empty string If the absolute value of pos is greater than the string, return empty string If pos is greater than 0, return substring in [pos, pos + count) If pos is less than 0, and set position N as length(a) + pos + 1, return substring in [N, N + count) If count is greater than length(a), return the whole string","title":"String"},{"location":"manual-EN/2.query-language/2.functions-and-operators/built-in-functions/#timestamp","text":"Function Description int now() Return the current date and time","title":"Timestamp"},{"location":"manual-EN/2.query-language/2.functions-and-operators/comparison-functions-and-operators/","text":"Comparison Functions and Operators \u00b6 Name Description = Assign a value / Division operator == Equal operator != Not equal operator < Less than operator <= Less than or equal operator - Minus operator % Modulo operator + Addition operator * Multiplication operator - Change the sign of the argument udf_is_in() Whether a value is within a set of values Comparison operations result in a value of true and false . == Equal. String comparisons are case-sensitive. Values of different types are not equal. nebula> YIELD 'A' == 'a'; ============== | (\"A\"==\"a\") | ============== | false | -------------- nebula> YIELD '2' == 2; [ERROR (-8)]: A string type can not be compared with a non-string type. > Greater than\uff1a nebula> YIELD 3 > 2; ========= | (3>2) | ========= | true | --------- \u2265 Greater than or equal to: nebula> YIELD 2 >= 2; [ERROR (-8)]: A string type can not be compared with a non-string type. < Less than: nebula> YIELD 2.0 < 1.9; ======================= | (2.000000<1.900000) | ======================= |false | ----------------------- \u2264 Less than or equal to: nebula> YIELD 0.11 <= 0.11; ======================== | (0.110000<=0.110000) | ======================== |true | ------------------------ != Not equal: nebula> YIELD 1 != '1'; A string type can not be compared with a non-string type. udf_is_in() Returns true if the first value is equal to any of the values in the list, otherwise, returns false. nebula> YIELD udf_is_in(1,0,1,2); ====================== | udf_is_in(1,0,1,2) | ====================== | true | ---------------------- nebula> GO FROM 100 OVER follow WHERE udf_is_in($$.player.name, \"Tony Parker\"); /* This example might not work because udf_is_in might be changed in the future.*/ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | GO FROM $-.id OVER follow WHERE udf_is_in($-.id, 102, 102 + 1); =============== | follow._dst | =============== | 100 | --------------- | 101 | ---------------","title":"Comparison Functions and Operators"},{"location":"manual-EN/2.query-language/2.functions-and-operators/comparison-functions-and-operators/#comparison_functions_and_operators","text":"Name Description = Assign a value / Division operator == Equal operator != Not equal operator < Less than operator <= Less than or equal operator - Minus operator % Modulo operator + Addition operator * Multiplication operator - Change the sign of the argument udf_is_in() Whether a value is within a set of values Comparison operations result in a value of true and false . == Equal. String comparisons are case-sensitive. Values of different types are not equal. nebula> YIELD 'A' == 'a'; ============== | (\"A\"==\"a\") | ============== | false | -------------- nebula> YIELD '2' == 2; [ERROR (-8)]: A string type can not be compared with a non-string type. > Greater than\uff1a nebula> YIELD 3 > 2; ========= | (3>2) | ========= | true | --------- \u2265 Greater than or equal to: nebula> YIELD 2 >= 2; [ERROR (-8)]: A string type can not be compared with a non-string type. < Less than: nebula> YIELD 2.0 < 1.9; ======================= | (2.000000<1.900000) | ======================= |false | ----------------------- \u2264 Less than or equal to: nebula> YIELD 0.11 <= 0.11; ======================== | (0.110000<=0.110000) | ======================== |true | ------------------------ != Not equal: nebula> YIELD 1 != '1'; A string type can not be compared with a non-string type. udf_is_in() Returns true if the first value is equal to any of the values in the list, otherwise, returns false. nebula> YIELD udf_is_in(1,0,1,2); ====================== | udf_is_in(1,0,1,2) | ====================== | true | ---------------------- nebula> GO FROM 100 OVER follow WHERE udf_is_in($$.player.name, \"Tony Parker\"); /* This example might not work because udf_is_in might be changed in the future.*/ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | GO FROM $-.id OVER follow WHERE udf_is_in($-.id, 102, 102 + 1); =============== | follow._dst | =============== | 100 | --------------- | 101 | ---------------","title":"Comparison Functions and Operators"},{"location":"manual-EN/2.query-language/2.functions-and-operators/group-by-function/","text":"Aggregate (Group By) Function \u00b6 The GROUP BY functions are similar with SQL. It can only be applied in the YIELD syntax. Name Description AVG() Return the average value of the argument COUNT() Return the number of records COUNT_DISTINCT()) Return the number of different values MAX() Return the maximum value MIN() Return the minimum value STD() Return the population standard deviation SUM() Return the sum BIT_AND() Bitwise AND BIT_OR() Bitwise OR BIT_XOR() Bitwise exclusive OR (XOR) All the functions above only work with int64 and double. Example \u00b6 nebula> GO FROM 100 OVER follow YIELD $$.player.name as Name | GROUP BY $-.Name YIELD $-.Name, COUNT(*); -- Find all the players followed by vertex 100 and return their names as Name. These players are grouped by Name and the number in each group is counted. -- The following result is returned: ================================ | $-.Name | COUNT(*) | ================================ | Kyle Anderson | 1 | -------------------------------- | Tony Parker | 1 | -------------------------------- | LaMarcus Aldridge | 1 | -------------------------------- nebula> GO FROM 101 OVER follow YIELD follow._src AS player, follow.degree AS degree | GROUP BY $-.player YIELD SUM($-.degree); -- Find all the players followed by vertex 101, return these players as player and the property of the follow edge as degree. These players are grouped and the sum of their degree values is returned. -- The following result is returned: ================== | SUM($-.degree) | ================== | 186 | ------------------","title":"Aggregate GROUP BY Functions"},{"location":"manual-EN/2.query-language/2.functions-and-operators/group-by-function/#aggregate_group_by_function","text":"The GROUP BY functions are similar with SQL. It can only be applied in the YIELD syntax. Name Description AVG() Return the average value of the argument COUNT() Return the number of records COUNT_DISTINCT()) Return the number of different values MAX() Return the maximum value MIN() Return the minimum value STD() Return the population standard deviation SUM() Return the sum BIT_AND() Bitwise AND BIT_OR() Bitwise OR BIT_XOR() Bitwise exclusive OR (XOR) All the functions above only work with int64 and double.","title":"Aggregate (Group By) Function"},{"location":"manual-EN/2.query-language/2.functions-and-operators/group-by-function/#example","text":"nebula> GO FROM 100 OVER follow YIELD $$.player.name as Name | GROUP BY $-.Name YIELD $-.Name, COUNT(*); -- Find all the players followed by vertex 100 and return their names as Name. These players are grouped by Name and the number in each group is counted. -- The following result is returned: ================================ | $-.Name | COUNT(*) | ================================ | Kyle Anderson | 1 | -------------------------------- | Tony Parker | 1 | -------------------------------- | LaMarcus Aldridge | 1 | -------------------------------- nebula> GO FROM 101 OVER follow YIELD follow._src AS player, follow.degree AS degree | GROUP BY $-.player YIELD SUM($-.degree); -- Find all the players followed by vertex 101, return these players as player and the property of the follow edge as degree. These players are grouped and the sum of their degree values is returned. -- The following result is returned: ================== | SUM($-.degree) | ================== | 186 | ------------------","title":"Example"},{"location":"manual-EN/2.query-language/2.functions-and-operators/limit-syntax/","text":"Limit Syntax \u00b6 LIMIT works the same as in SQL , and must be used with pipe | . The LIMIT clause accepts one or two arguments. The values of both arguments must be zero or positive integers. ORDER BY <expressions> [ASC | DESC] LIMIT [<offset_value>,] <number_rows> expressions The columns or calculations that you wish to sort. number_rows It constrains the number of rows to return. For example, LIMIT 10 would return the first 10 rows. This is where sorting order matters so be sure to use an ORDER BY clause appropriately. offset_value Optional. It defines from which row to start including the rows in the output. The offset starts from zero. When using LIMIT , it is important to use an ORDER BY clause that constrains the output into a unique order. Otherwise, you will get an unpredictable subset of the output. For example: nebula> GO FROM 200 OVER serve REVERSELY YIELD $$.player.name AS Friend, $$.player.age AS Age | ORDER BY Age, Friend | LIMIT 3; ========================= | Friend | Age | ========================= | Kyle Anderson | 25 | ------------------------- | Aron Baynes | 32 | ------------------------- | Marco Belinelli | 32 |","title":"LIMIT Syntax"},{"location":"manual-EN/2.query-language/2.functions-and-operators/limit-syntax/#limit_syntax","text":"LIMIT works the same as in SQL , and must be used with pipe | . The LIMIT clause accepts one or two arguments. The values of both arguments must be zero or positive integers. ORDER BY <expressions> [ASC | DESC] LIMIT [<offset_value>,] <number_rows> expressions The columns or calculations that you wish to sort. number_rows It constrains the number of rows to return. For example, LIMIT 10 would return the first 10 rows. This is where sorting order matters so be sure to use an ORDER BY clause appropriately. offset_value Optional. It defines from which row to start including the rows in the output. The offset starts from zero. When using LIMIT , it is important to use an ORDER BY clause that constrains the output into a unique order. Otherwise, you will get an unpredictable subset of the output. For example: nebula> GO FROM 200 OVER serve REVERSELY YIELD $$.player.name AS Friend, $$.player.age AS Age | ORDER BY Age, Friend | LIMIT 3; ========================= | Friend | Age | ========================= | Kyle Anderson | 25 | ------------------------- | Aron Baynes | 32 | ------------------------- | Marco Belinelli | 32 |","title":"Limit Syntax"},{"location":"manual-EN/2.query-language/2.functions-and-operators/logical-operators/","text":"Logical Operators \u00b6 Name Description && Logical AND ! Logical NOT || Logical OR XOR Logical XOR In nGQL, non-zero numbers are evaluated to true . For the precedence of the operators, refer to Operator Precedence . && Logical AND: nebula> YIELD -1 && true; ============== | (-1&&true) | ============== | true | -------------- ! Logical NOT: nebula> YIELD !(-1); ========= | !(-1) | ========= | false | --------- || Logical OR: nebula> YIELD 1 || !1; ============= | (1||!(1)) | ============= | true | ------------- ^ Logical XOR: nebula> YIELD (NOT 0 || 0) AND 0 XOR 1 AS ret; ========= | ret | ========= | true | ---------","title":"Logical Operators"},{"location":"manual-EN/2.query-language/2.functions-and-operators/logical-operators/#logical_operators","text":"Name Description && Logical AND ! Logical NOT || Logical OR XOR Logical XOR In nGQL, non-zero numbers are evaluated to true . For the precedence of the operators, refer to Operator Precedence . && Logical AND: nebula> YIELD -1 && true; ============== | (-1&&true) | ============== | true | -------------- ! Logical NOT: nebula> YIELD !(-1); ========= | !(-1) | ========= | false | --------- || Logical OR: nebula> YIELD 1 || !1; ============= | (1||!(1)) | ============= | true | ------------- ^ Logical XOR: nebula> YIELD (NOT 0 || 0) AND 0 XOR 1 AS ret; ========= | ret | ========= | true | ---------","title":"Logical Operators"},{"location":"manual-EN/2.query-language/2.functions-and-operators/operator-precedence/","text":"Operator Precedence \u00b6 The following list shows the precedence of nGQL operators in descending order. Operators that are shown together on a line have the same precedence. ! - (unary minus) *, /, % -, + == , >=, >, <=, <, <>, != && || = (assignment) For operators that occur at the same precedence level within an expression, evaluation proceeds left to right, with the exception that assignments evaluate right to left. The precedence of operators determines the order of evaluation of terms in an expression. To override this order and group terms explicitly, use parentheses. Examples: nebula> YIELD 2+3*5; nebula> YIELD (2+3)*5;","title":"Operator Precedence"},{"location":"manual-EN/2.query-language/2.functions-and-operators/operator-precedence/#operator_precedence","text":"The following list shows the precedence of nGQL operators in descending order. Operators that are shown together on a line have the same precedence. ! - (unary minus) *, /, % -, + == , >=, >, <=, <, <>, != && || = (assignment) For operators that occur at the same precedence level within an expression, evaluation proceeds left to right, with the exception that assignments evaluate right to left. The precedence of operators determines the order of evaluation of terms in an expression. To override this order and group terms explicitly, use parentheses. Examples: nebula> YIELD 2+3*5; nebula> YIELD (2+3)*5;","title":"Operator Precedence"},{"location":"manual-EN/2.query-language/2.functions-and-operators/order-by-function/","text":"Order by Function \u00b6 Similar with SQL, ORDER BY can be used to sort in ascending ( ASC ) or descending ( DESC ) order for returned results. ORDER BY can only be used in the PIPE -syntax ( | ). ORDER BY <expression> [ASC | DESC] [, <expression> [ASC | DESC] ...] By default, ORDER BY sorts the records in ascending order if no ASC or DESC is given. Example \u00b6 nebula> FETCH PROP ON player 100,101,102,103 YIELD player.age AS age, player.name AS name | ORDER BY age, name DESC; -- Fetch four vertices and sort them by their ages in ascending order, and for those in the same age, sort them by name in descending order. -- The following result is returned: ====================================== | VertexID | age | name | ====================================== | 103 | 32 | Rudy Gay | -------------------------------------- | 102 | 33 | LaMarcus Aldridge | -------------------------------------- | 101 | 36 | Tony Parker | -------------------------------------- | 100 | 42 | Tim Duncan | -------------------------------------- (see FETCH for the usage) nebula> GO FROM 100 OVER follow YIELD $$.player.age AS age, $$.player.name AS name | ORDER BY age DESC, name ASC; -- Search all the players followed by vertex 100 and return their ages and names. The age is in descending order; the name is in ascending order if they have the same name. -- The following result is returned: =========================== | age | name | =========================== | 36 | Tony Parker | --------------------------- | 33 | LaMarcus Aldridge | --------------------------- | 25 | Kyle Anderson | ---------------------------","title":"ORDER BY Function"},{"location":"manual-EN/2.query-language/2.functions-and-operators/order-by-function/#order_by_function","text":"Similar with SQL, ORDER BY can be used to sort in ascending ( ASC ) or descending ( DESC ) order for returned results. ORDER BY can only be used in the PIPE -syntax ( | ). ORDER BY <expression> [ASC | DESC] [, <expression> [ASC | DESC] ...] By default, ORDER BY sorts the records in ascending order if no ASC or DESC is given.","title":"Order by Function"},{"location":"manual-EN/2.query-language/2.functions-and-operators/order-by-function/#example","text":"nebula> FETCH PROP ON player 100,101,102,103 YIELD player.age AS age, player.name AS name | ORDER BY age, name DESC; -- Fetch four vertices and sort them by their ages in ascending order, and for those in the same age, sort them by name in descending order. -- The following result is returned: ====================================== | VertexID | age | name | ====================================== | 103 | 32 | Rudy Gay | -------------------------------------- | 102 | 33 | LaMarcus Aldridge | -------------------------------------- | 101 | 36 | Tony Parker | -------------------------------------- | 100 | 42 | Tim Duncan | -------------------------------------- (see FETCH for the usage) nebula> GO FROM 100 OVER follow YIELD $$.player.age AS age, $$.player.name AS name | ORDER BY age DESC, name ASC; -- Search all the players followed by vertex 100 and return their ages and names. The age is in descending order; the name is in ascending order if they have the same name. -- The following result is returned: =========================== | age | name | =========================== | 36 | Tony Parker | --------------------------- | 33 | LaMarcus Aldridge | --------------------------- | 25 | Kyle Anderson | ---------------------------","title":"Example"},{"location":"manual-EN/2.query-language/2.functions-and-operators/set-operations/","text":"Set Operations ( UNION , INTERSECT , and MINUS ) \u00b6 UNION, UNION DISTINCT, and UNION ALL \u00b6 Operator UNION DISTINCT (or by short UNION ) returns the union of two sets A and B (denoted by A \u22c3 B in mathematics), with the distinct element belongs to set A or set B, or both. Meanwhile, operation UNION ALL returns the union set with duplicated elements. The UNION syntax is <left> UNION [DISTINCT | ALL] <right> [ UNION [DISTINCT | ALL] <right> ...] where <left> and <right> must have the same number of columns and pair-wise data types. If the data types are different, Nebula Graph will convert according to Type Conversion . Example \u00b6 The following statement nebula> GO FROM 1 OVER e1 \\ UNION \\ GO FROM 2 OVER e1 returns the neighbors' id of vertex 1 and 2 (along with edge e1 ) without duplication. While nebula> GO FROM 1 OVER e1 \\ UNION ALL\\ GO FROM 2 OVER e1 returns all the neighbors of vertex 1 and 2 , with all possible duplications. UNION can also work with the YIELD statement. For example, let's suppose the results of the following two queries. nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 -- query 1 ========================== | id | left_1 | left_2 | ========================== | 104 | 1 | 2 | -- line 1 -------------------------- | 215 | 4 | 3 | -- line 3 -------------------------- nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 -- query 2 =========================== | id | right_1 | right_2 | =========================== | 104 | 1 | 2 | -- line 1 --------------------------- | 104 | 2 | 2 | -- line 2 --------------------------- And the following statement nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION /* DISTINCT */ \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 will return as follows: ========================= | id | left_1 | left_2 | -- UNION or UNION DISTINCT. The column names come from query 1 ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 ------------------------- Notice that line 1 and line 2 return the same id (104) with different column values. The DISTINCT check duplication by all the columns for every line. So line 1 and line 2 are different. You can expect the UNION ALL result nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION ALL \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 ========================= | id | left_1 | left_2 | -- UNION ALL ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 ------------------------- INTERSECT \u00b6 Operator INTERSECT returns the intersection of two sets A and B (denoted by A \u22c2 B), if the elements belong both to set A and set B. <left> INTERSECT <right> Alike UNION , <left> and <right> must have the same number of columns and data types. Besides, only the same line of <left> and <right> will be returned. For example, the following query nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 INTERSECT GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 returns ========================= | id | left_1 | left_2 | ========================= | 104 | 1 | 2 | -- line 1 ------------------------- MINUS \u00b6 The set subtraction (or difference), A - B, consists of elements that are in A but not in B. So the operation order matters. For example, the following query nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 MINUS GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 comes out ========================== | id | left_1 | left_2 | ========================== | 215 | 4 | 3 | -- line 3 -------------------------- And if we reverse the MINUS order, the query nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 MINUS GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 returns =========================== | id | right_1 | right_2 | -- column named from query 2 =========================== | 104 | 2 | 2 | -- line 2 ---------------------------","title":"Set Operations"},{"location":"manual-EN/2.query-language/2.functions-and-operators/set-operations/#set_operations_union_intersect_and_minus","text":"","title":"Set Operations (UNION, INTERSECT, and MINUS)"},{"location":"manual-EN/2.query-language/2.functions-and-operators/set-operations/#union_union_distinct_and_union_all","text":"Operator UNION DISTINCT (or by short UNION ) returns the union of two sets A and B (denoted by A \u22c3 B in mathematics), with the distinct element belongs to set A or set B, or both. Meanwhile, operation UNION ALL returns the union set with duplicated elements. The UNION syntax is <left> UNION [DISTINCT | ALL] <right> [ UNION [DISTINCT | ALL] <right> ...] where <left> and <right> must have the same number of columns and pair-wise data types. If the data types are different, Nebula Graph will convert according to Type Conversion .","title":"UNION, UNION DISTINCT, and UNION ALL"},{"location":"manual-EN/2.query-language/2.functions-and-operators/set-operations/#example","text":"The following statement nebula> GO FROM 1 OVER e1 \\ UNION \\ GO FROM 2 OVER e1 returns the neighbors' id of vertex 1 and 2 (along with edge e1 ) without duplication. While nebula> GO FROM 1 OVER e1 \\ UNION ALL\\ GO FROM 2 OVER e1 returns all the neighbors of vertex 1 and 2 , with all possible duplications. UNION can also work with the YIELD statement. For example, let's suppose the results of the following two queries. nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 -- query 1 ========================== | id | left_1 | left_2 | ========================== | 104 | 1 | 2 | -- line 1 -------------------------- | 215 | 4 | 3 | -- line 3 -------------------------- nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 -- query 2 =========================== | id | right_1 | right_2 | =========================== | 104 | 1 | 2 | -- line 1 --------------------------- | 104 | 2 | 2 | -- line 2 --------------------------- And the following statement nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION /* DISTINCT */ \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 will return as follows: ========================= | id | left_1 | left_2 | -- UNION or UNION DISTINCT. The column names come from query 1 ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 ------------------------- Notice that line 1 and line 2 return the same id (104) with different column values. The DISTINCT check duplication by all the columns for every line. So line 1 and line 2 are different. You can expect the UNION ALL result nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 \\ UNION ALL \\ GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 ========================= | id | left_1 | left_2 | -- UNION ALL ========================= | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 1 | 2 | -- line 1 ------------------------- | 104 | 2 | 2 | -- line 2 ------------------------- | 215 | 4 | 3 | -- line 3 -------------------------","title":"Example"},{"location":"manual-EN/2.query-language/2.functions-and-operators/set-operations/#intersect","text":"Operator INTERSECT returns the intersection of two sets A and B (denoted by A \u22c2 B), if the elements belong both to set A and set B. <left> INTERSECT <right> Alike UNION , <left> and <right> must have the same number of columns and data types. Besides, only the same line of <left> and <right> will be returned. For example, the following query nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 INTERSECT GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 returns ========================= | id | left_1 | left_2 | ========================= | 104 | 1 | 2 | -- line 1 -------------------------","title":"INTERSECT"},{"location":"manual-EN/2.query-language/2.functions-and-operators/set-operations/#minus","text":"The set subtraction (or difference), A - B, consists of elements that are in A but not in B. So the operation order matters. For example, the following query nebula> GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 MINUS GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 comes out ========================== | id | left_1 | left_2 | ========================== | 215 | 4 | 3 | -- line 3 -------------------------- And if we reverse the MINUS order, the query nebula> GO FROM 2,3 OVER e1 YIELD e1._dst AS id, e1.prop1 AS right_1, $$.tag.prop2 AS right_2 MINUS GO FROM 1 OVER e1 YIELD e1._dst AS id, e1.prop1 AS left_1, $$.tag.prop2 AS left_2 returns =========================== | id | right_1 | right_2 | -- column named from query 2 =========================== | 104 | 2 | 2 | -- line 2 ---------------------------","title":"MINUS"},{"location":"manual-EN/2.query-language/2.functions-and-operators/uuid/","text":"UUID \u00b6 UUID is used to generate the global unique identifiers. When the number of vertices reaches billions, using Hash Function to generate vids has a certain conflict probability. Therefore, Nebula Graph provides UUID Function to avoid vid conflicts in a large number of vertices. UUID Function is composed of the Murmur hash function and the current timestamp (in seconds). Values generated with the UUID are stored in the Nebula Graph Storage service in key-value mode. When called, it checks whether this key exists or conflicts. So the performance may be slower than hash. Insert with UUID : -- Insert a vertex with the UUID function. nebula> INSERT VERTEX player (name, age) VALUES uuid(\"n0\"):(\"n0\", 21); -- Insert an edge with the UUID function. nebula> INSERT EDGE follow(degree) VALUES uuid(\"n0\") -> uuid(\"n1\"): (90); Fetch with UUID : nebula> FETCH PROP ON player uuid(\"n0\") YIELD player.name, player.age; -- The following result is returned: =================================================== | VertexID | player.name | player.age | =================================================== | -5057115778034027261 | n0 | 21 | --------------------------------------------------- nebula> FETCH PROP ON follow uuid(\"n0\") -> uuid(\"n1\"); -- The following result is returned: ============================================================================= | follow._src | follow._dst | follow._rank | follow.degree | ============================================================================= | -5057115778034027261 | 4039977434270020867 | 0 | 90 | ----------------------------------------------------------------------------- Go with UUID : nebula> GO FROM uuid(\"n0\") OVER follow; --The following result is returned: ======================= | follow._dst | ======================= | 4039977434270020867 | -----------------------","title":"UUID Function"},{"location":"manual-EN/2.query-language/2.functions-and-operators/uuid/#uuid","text":"UUID is used to generate the global unique identifiers. When the number of vertices reaches billions, using Hash Function to generate vids has a certain conflict probability. Therefore, Nebula Graph provides UUID Function to avoid vid conflicts in a large number of vertices. UUID Function is composed of the Murmur hash function and the current timestamp (in seconds). Values generated with the UUID are stored in the Nebula Graph Storage service in key-value mode. When called, it checks whether this key exists or conflicts. So the performance may be slower than hash. Insert with UUID : -- Insert a vertex with the UUID function. nebula> INSERT VERTEX player (name, age) VALUES uuid(\"n0\"):(\"n0\", 21); -- Insert an edge with the UUID function. nebula> INSERT EDGE follow(degree) VALUES uuid(\"n0\") -> uuid(\"n1\"): (90); Fetch with UUID : nebula> FETCH PROP ON player uuid(\"n0\") YIELD player.name, player.age; -- The following result is returned: =================================================== | VertexID | player.name | player.age | =================================================== | -5057115778034027261 | n0 | 21 | --------------------------------------------------- nebula> FETCH PROP ON follow uuid(\"n0\") -> uuid(\"n1\"); -- The following result is returned: ============================================================================= | follow._src | follow._dst | follow._rank | follow.degree | ============================================================================= | -5057115778034027261 | 4039977434270020867 | 0 | 90 | ----------------------------------------------------------------------------- Go with UUID : nebula> GO FROM uuid(\"n0\") OVER follow; --The following result is returned: ======================= | follow._dst | ======================= | 4039977434270020867 | -----------------------","title":"UUID"},{"location":"manual-EN/2.query-language/3.language-structure/comment-syntax/","text":"Comment Syntax \u00b6 Nebula Graph supports four comment styles: From a # character to the end of the line. From a -- sequence to the end of the line. From a // sequence to the end of the line, as in the C programming language. From a / sequence to the following / sequence. This syntax enables a comment to extend over multiple lines because the beginning and closing sequences need not be on the same line. Nested comments are not supported. The following example demonstrates all these comment styles: nebula> -- Do nothing this line nebula> YIELD 1+1 # This comment continues to the end of line nebula> YIELD 1+1 -- This comment continues to the end of line nebula> YIELD 1+1 // This comment continues to the end of line nebula> YIELD 1 /* This is an in-line comment */ + 1 nebula> YIELD 11 + \\ /* Multiple-line comment \\ Use backslash as line break. \\ */ 12 The backslash \\ in a line indicates a line break.","title":"Comment Syntax"},{"location":"manual-EN/2.query-language/3.language-structure/comment-syntax/#comment_syntax","text":"Nebula Graph supports four comment styles: From a # character to the end of the line. From a -- sequence to the end of the line. From a // sequence to the end of the line, as in the C programming language. From a / sequence to the following / sequence. This syntax enables a comment to extend over multiple lines because the beginning and closing sequences need not be on the same line. Nested comments are not supported. The following example demonstrates all these comment styles: nebula> -- Do nothing this line nebula> YIELD 1+1 # This comment continues to the end of line nebula> YIELD 1+1 -- This comment continues to the end of line nebula> YIELD 1+1 // This comment continues to the end of line nebula> YIELD 1 /* This is an in-line comment */ + 1 nebula> YIELD 11 + \\ /* Multiple-line comment \\ Use backslash as line break. \\ */ 12 The backslash \\ in a line indicates a line break.","title":"Comment Syntax"},{"location":"manual-EN/2.query-language/3.language-structure/identifier-case-sensitivity/","text":"Identifer Case Sensitivity \u00b6 Identifiers are Case-Sensitive \u00b6 The following statements would not work because they refer to two different spaces, i.e. my_space and MY_SPACE : nebula> CREATE SPACE my_space; nebula> use MY_SPACE; -- my_space and MY_SPACE are two different spaces Keywords and Reserved Words are Case-Insensitive \u00b6 The following statements are equivalent: nebula> show spaces; -- show and spaces are keywords. nebula> SHOW SPACES; nebula> SHOW spaces; nebula> show SPACES;","title":"Identifer Case Sensitivity"},{"location":"manual-EN/2.query-language/3.language-structure/identifier-case-sensitivity/#identifer_case_sensitivity","text":"","title":"Identifer Case Sensitivity"},{"location":"manual-EN/2.query-language/3.language-structure/identifier-case-sensitivity/#identifiers_are_case-sensitive","text":"The following statements would not work because they refer to two different spaces, i.e. my_space and MY_SPACE : nebula> CREATE SPACE my_space; nebula> use MY_SPACE; -- my_space and MY_SPACE are two different spaces","title":"Identifiers are Case-Sensitive"},{"location":"manual-EN/2.query-language/3.language-structure/identifier-case-sensitivity/#keywords_and_reserved_words_are_case-insensitive","text":"The following statements are equivalent: nebula> show spaces; -- show and spaces are keywords. nebula> SHOW SPACES; nebula> SHOW spaces; nebula> show SPACES;","title":"Keywords and Reserved Words are Case-Insensitive"},{"location":"manual-EN/2.query-language/3.language-structure/keywords-and-reserved-words/","text":"Keywords and Reserved Words \u00b6 Keywords are words that have significance in nGQL. Certain keywords are reserved and require special treatment for use as identifiers. Non-reserved keywords are permitted as identifiers without quoting. All the non-reserved keywords are automatically converted to lower case. Non-reserved keywords are case-insensitive. Reserved words are permitted as identifiers if you quote them with back quotes such as `AND`. nebula> CREATE TAG TAG(name string); [ERROR (-7)]: SyntaxError: syntax error near `TAG' nebula> CREATE TAG SPACE(name string); -- SPACE is an unreserved KEY WORD Execution succeeded nebula> SHOW TAGS; -- All the non-reserved keywords are automatically converted to lower case. ============= | ID | Name | ============= | 25 | space| ------------- TAG is a reserved keyword and must be quoted with backtick to be used as an identifier. SPACE is keyword but not reserved, so its use as identifiers does not require quoting. nebula> CREATE TAG `TAG` (name string); -- TAG is a reserved word here Execution succeeded Reserved Words \u00b6 The following list shows reserved words in nGQL. ADD ALTER AND AS ASC BALANCE BIGINT BOOL BY CHANGE COMPACT CREATE DELETE DESC DESCRIBE DISTINCT DOUBLE DOWNLOAD DROP EDGE EDGES EXISTS FETCH FIND FLUSH FROM GET GO GRANT IF IN INDEX INDEXES INGEST INSERT INT INTERSECT IS LIMIT LOOKUP MATCH MINUS NO NOT NULL OF OFFSET ON OR ORDER OVER OVERWRITE PROP REBUILD RECOVER REMOVE RETURN REVERSELY REVOKE SET SHOW STEPS STOP STRING SUBMIT TAG TAGS TIMESTAMP TO UNION UPDATE UPSERT UPTO USE VERTEX WHEN WHERE WITH XOR YIELD Non-Reserved Keywords \u00b6 ACCOUNT ADMIN ALL AVG BIDIRECT BIT_AND BIT_OR BIT_XOR CHARSET COLLATE COLLATION CONFIGS COUNT COUNT_DISTINCT DATA DBA DEFAULT FORCE GOD GRAPH GROUP GUEST HDFS HOSTS JOB JOBS LEADER MAX META MIN OFFLINE PART PARTITION_NUM PARTS PASSWORD PATH REPLICA_FACTOR ROLE ROLES SHORTEST SNAPSHOT SNAPSHOTS SPACE SPACES STATUS STD STORAGE SUM TTL_COL TTL_DURATION USER USERS UUID VALUES","title":"Keywords and Reserved Words"},{"location":"manual-EN/2.query-language/3.language-structure/keywords-and-reserved-words/#keywords_and_reserved_words","text":"Keywords are words that have significance in nGQL. Certain keywords are reserved and require special treatment for use as identifiers. Non-reserved keywords are permitted as identifiers without quoting. All the non-reserved keywords are automatically converted to lower case. Non-reserved keywords are case-insensitive. Reserved words are permitted as identifiers if you quote them with back quotes such as `AND`. nebula> CREATE TAG TAG(name string); [ERROR (-7)]: SyntaxError: syntax error near `TAG' nebula> CREATE TAG SPACE(name string); -- SPACE is an unreserved KEY WORD Execution succeeded nebula> SHOW TAGS; -- All the non-reserved keywords are automatically converted to lower case. ============= | ID | Name | ============= | 25 | space| ------------- TAG is a reserved keyword and must be quoted with backtick to be used as an identifier. SPACE is keyword but not reserved, so its use as identifiers does not require quoting. nebula> CREATE TAG `TAG` (name string); -- TAG is a reserved word here Execution succeeded","title":"Keywords and Reserved Words"},{"location":"manual-EN/2.query-language/3.language-structure/keywords-and-reserved-words/#reserved_words","text":"The following list shows reserved words in nGQL. ADD ALTER AND AS ASC BALANCE BIGINT BOOL BY CHANGE COMPACT CREATE DELETE DESC DESCRIBE DISTINCT DOUBLE DOWNLOAD DROP EDGE EDGES EXISTS FETCH FIND FLUSH FROM GET GO GRANT IF IN INDEX INDEXES INGEST INSERT INT INTERSECT IS LIMIT LOOKUP MATCH MINUS NO NOT NULL OF OFFSET ON OR ORDER OVER OVERWRITE PROP REBUILD RECOVER REMOVE RETURN REVERSELY REVOKE SET SHOW STEPS STOP STRING SUBMIT TAG TAGS TIMESTAMP TO UNION UPDATE UPSERT UPTO USE VERTEX WHEN WHERE WITH XOR YIELD","title":"Reserved Words"},{"location":"manual-EN/2.query-language/3.language-structure/keywords-and-reserved-words/#non-reserved_keywords","text":"ACCOUNT ADMIN ALL AVG BIDIRECT BIT_AND BIT_OR BIT_XOR CHARSET COLLATE COLLATION CONFIGS COUNT COUNT_DISTINCT DATA DBA DEFAULT FORCE GOD GRAPH GROUP GUEST HDFS HOSTS JOB JOBS LEADER MAX META MIN OFFLINE PART PARTITION_NUM PARTS PASSWORD PATH REPLICA_FACTOR ROLE ROLES SHORTEST SNAPSHOT SNAPSHOTS SPACE SPACES STATUS STD STORAGE SUM TTL_COL TTL_DURATION USER USERS UUID VALUES","title":"Non-Reserved Keywords"},{"location":"manual-EN/2.query-language/3.language-structure/pipe-syntax/","text":"PIPE Syntax \u00b6 One major difference between nGQL and SQL is how sub-queries are composed. In SQL, sub-queries are nested (embedded) to form a statement. Meanwhile, nGQL uses shell style PIPE (|) . Examples \u00b6 nebula> GO FROM 100 OVER follow YIELD follow._dst AS dstid, $$.player.name AS Name | \\ GO FROM $-.dstid OVER follow YIELD follow._dst, follow.degree, $-.Name The dest (vertex) id will be given as the default value if no YIELD is used. But if YIELD is declared explicitly, (the default value) id will not be given. The alias name mentioned right after placeholder $-. must be defined in the previews YIELD statement, such as dstid or Name as shown in the above example.","title":"Pipe Syntax"},{"location":"manual-EN/2.query-language/3.language-structure/pipe-syntax/#pipe_syntax","text":"One major difference between nGQL and SQL is how sub-queries are composed. In SQL, sub-queries are nested (embedded) to form a statement. Meanwhile, nGQL uses shell style PIPE (|) .","title":"PIPE Syntax"},{"location":"manual-EN/2.query-language/3.language-structure/pipe-syntax/#examples","text":"nebula> GO FROM 100 OVER follow YIELD follow._dst AS dstid, $$.player.name AS Name | \\ GO FROM $-.dstid OVER follow YIELD follow._dst, follow.degree, $-.Name The dest (vertex) id will be given as the default value if no YIELD is used. But if YIELD is declared explicitly, (the default value) id will not be given. The alias name mentioned right after placeholder $-. must be defined in the previews YIELD statement, such as dstid or Name as shown in the above example.","title":"Examples"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/","text":"Property Reference \u00b6 You can refer a vertex or edge's property in WHERE or YIELD syntax. Reference From Vertex \u00b6 For Source Vertex \u00b6 $^.tag_name.prop_name where symbol $^ is used to get a source vertex's property, tag_name indicates the source vertex's tag , and prop_name specifies the property name. For Destination Vertex \u00b6 $$.tag_name.prop_name Symbol $$ indicates the ending vertex, tag_name and prop_name are the vertex's tag and property respectively. Example \u00b6 nebula> GO FROM 100 OVER follow YIELD $^.player.name AS startName, $$.player.age AS endAge; Use the above query to get the source vertex's property name and ending vertex's property age. Reference From Edge \u00b6 For Property \u00b6 You can use the following syntax to get an edge's property. edge_type.edge_prop edge_type is the edge's type, meanwhile edge_prop is the property. For example, nebula> GO FROM 100 OVER follow YIELD follow.degree; For Built-in Properties \u00b6 There are four built-in properties in the edge: _src: source vertex ID of the edge _dst: destination ID of the edge _type: edge type _ranking: the edge's ranking You can use _src and _dst to get the starting and ending vertices' ID, and they are very commonly used to show a graph path. For example, nebula> GO FROM 100 OVER follow YIELD follow._src AS startVID /* starting vertex is 100 */, follow._dst AS endVID; This statement returns all the neighbors of vertex 100 over edge type follow , by referencing follow._src as the starting vertex ID (which, of course, is 100 ) and follow._dst as the ending vertex ID.","title":"Property Reference"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#property_reference","text":"You can refer a vertex or edge's property in WHERE or YIELD syntax.","title":"Property Reference"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#reference_from_vertex","text":"","title":"Reference From Vertex"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#for_source_vertex","text":"$^.tag_name.prop_name where symbol $^ is used to get a source vertex's property, tag_name indicates the source vertex's tag , and prop_name specifies the property name.","title":"For Source Vertex"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#for_destination_vertex","text":"$$.tag_name.prop_name Symbol $$ indicates the ending vertex, tag_name and prop_name are the vertex's tag and property respectively.","title":"For Destination Vertex"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#example","text":"nebula> GO FROM 100 OVER follow YIELD $^.player.name AS startName, $$.player.age AS endAge; Use the above query to get the source vertex's property name and ending vertex's property age.","title":"Example"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#reference_from_edge","text":"","title":"Reference From Edge"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#for_property","text":"You can use the following syntax to get an edge's property. edge_type.edge_prop edge_type is the edge's type, meanwhile edge_prop is the property. For example, nebula> GO FROM 100 OVER follow YIELD follow.degree;","title":"For Property"},{"location":"manual-EN/2.query-language/3.language-structure/property-reference/#for_built-in_properties","text":"There are four built-in properties in the edge: _src: source vertex ID of the edge _dst: destination ID of the edge _type: edge type _ranking: the edge's ranking You can use _src and _dst to get the starting and ending vertices' ID, and they are very commonly used to show a graph path. For example, nebula> GO FROM 100 OVER follow YIELD follow._src AS startVID /* starting vertex is 100 */, follow._dst AS endVID; This statement returns all the neighbors of vertex 100 over edge type follow , by referencing follow._src as the starting vertex ID (which, of course, is 100 ) and follow._dst as the ending vertex ID.","title":"For Built-in Properties"},{"location":"manual-EN/2.query-language/3.language-structure/schema-object-names/","text":"Schema Object Names \u00b6 Certain objects within Nebula graph , including space, tag, edge, alias, customer variables and other object names are referred as identifiers. This section describes the rules for identifiers in Nebula Graph : Permitted characters in identifiers: ASCII: [0-9,a-z,A-Z,_] (basic Latin letters, digits 0-9, underscore), other punctuation characters are not supported. All identifiers must begin with a letter of the alphabet. Identifiers are case sensitive. You cannot use a keyword (a reserved word) as an identifier.","title":"Schema Object Names"},{"location":"manual-EN/2.query-language/3.language-structure/schema-object-names/#schema_object_names","text":"Certain objects within Nebula graph , including space, tag, edge, alias, customer variables and other object names are referred as identifiers. This section describes the rules for identifiers in Nebula Graph : Permitted characters in identifiers: ASCII: [0-9,a-z,A-Z,_] (basic Latin letters, digits 0-9, underscore), other punctuation characters are not supported. All identifiers must begin with a letter of the alphabet. Identifiers are case sensitive. You cannot use a keyword (a reserved word) as an identifier.","title":"Schema Object Names"},{"location":"manual-EN/2.query-language/3.language-structure/statement-composition/","text":"Statement Composition \u00b6 There are only two ways to compose statements (or sub-queries): More than one statements can be batched together, separated by semicolon (;). The result of the last statement will be returned as the result of the batch. Statements could be piped together using operator (|), much like the pipe in the shell scripts. The result yielded from the previous statement could be redirected to the next statement as input. Notice that compose statements are not Transactional queries. For example, a statement composed of three sub-queries: A | B | C, where A is a read operation, B is a computation, and C is a write operation. If any part fails in the execution, the whole result could be undefined -- currently, there is no so called roll back -- what was written depends on the query executor. Examples \u00b6 semicolon statements SHOW TAGS; SHOW EDGES; -- only edges are shown INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); \\ INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); \\ INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); /* multiple vertices are added in a compose statement. */ PIPE statements GO FROM 201 OVER edge_serve | GO FROM $-.id OVER edge_fans | GO FROM $-.id ... Placeholder $-.id takes the result from the first statement GO FROM 201 OVER edge_serve YIELD edge_serve._dst AS id .","title":"Statement Composition"},{"location":"manual-EN/2.query-language/3.language-structure/statement-composition/#statement_composition","text":"There are only two ways to compose statements (or sub-queries): More than one statements can be batched together, separated by semicolon (;). The result of the last statement will be returned as the result of the batch. Statements could be piped together using operator (|), much like the pipe in the shell scripts. The result yielded from the previous statement could be redirected to the next statement as input. Notice that compose statements are not Transactional queries. For example, a statement composed of three sub-queries: A | B | C, where A is a read operation, B is a computation, and C is a write operation. If any part fails in the execution, the whole result could be undefined -- currently, there is no so called roll back -- what was written depends on the query executor.","title":"Statement Composition"},{"location":"manual-EN/2.query-language/3.language-structure/statement-composition/#examples","text":"semicolon statements SHOW TAGS; SHOW EDGES; -- only edges are shown INSERT VERTEX player(name, age) VALUES 100:(\"Tim Duncan\", 42); \\ INSERT VERTEX player(name, age) VALUES 101:(\"Tony Parker\", 36); \\ INSERT VERTEX player(name, age) VALUES 102:(\"LaMarcus Aldridge\", 33); /* multiple vertices are added in a compose statement. */ PIPE statements GO FROM 201 OVER edge_serve | GO FROM $-.id OVER edge_fans | GO FROM $-.id ... Placeholder $-.id takes the result from the first statement GO FROM 201 OVER edge_serve YIELD edge_serve._dst AS id .","title":"Examples"},{"location":"manual-EN/2.query-language/3.language-structure/user-defined-variables/","text":"User-Defined Variables \u00b6 Nebula Graph supports user-defined variables, which allows passing the result of one statement to another. A user-defined variable is written as $var_name , where var_name is a user-defined name/variable that consists of alphanumeric characters, any other characters are not recommended currently. User-defined variables can only be used in one execution (compound statements separated by semicolon ; or pipe | and are submitted to the server to execute together). Be noted that a user-defined variable is valid only at the current session and execution. A user-defined variable in one statement can NOT be used in neither other clients nor other executions, which means that the definition statement and the statements that use it must be submitted together. And when the session ends these variables are automatically expired. User-defined variables are case-sensitive. Example: nebula> $var = GO FROM hash('curry') OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve;","title":"User Defined Variables"},{"location":"manual-EN/2.query-language/3.language-structure/user-defined-variables/#user-defined_variables","text":"Nebula Graph supports user-defined variables, which allows passing the result of one statement to another. A user-defined variable is written as $var_name , where var_name is a user-defined name/variable that consists of alphanumeric characters, any other characters are not recommended currently. User-defined variables can only be used in one execution (compound statements separated by semicolon ; or pipe | and are submitted to the server to execute together). Be noted that a user-defined variable is valid only at the current session and execution. A user-defined variable in one statement can NOT be used in neither other clients nor other executions, which means that the definition statement and the statements that use it must be submitted together. And when the session ends these variables are automatically expired. User-defined variables are case-sensitive. Example: nebula> $var = GO FROM hash('curry') OVER follow YIELD follow._dst AS id; \\ GO FROM $var.id OVER serve;","title":"User-Defined Variables"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/boolean-literals/","text":"Boolean Literals \u00b6 The boolean literals TRUE and FALSE can be written in any letter case. nebula> yield TRUE, true, FALSE, false, FalsE ========================================= | true | true | false | false | false | ========================================= | true | true | false | false | false | -----------------------------------------","title":"Boolean Literals"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/boolean-literals/#boolean_literals","text":"The boolean literals TRUE and FALSE can be written in any letter case. nebula> yield TRUE, true, FALSE, false, FalsE ========================================= | true | true | false | false | false | ========================================= | true | true | false | false | false | -----------------------------------------","title":"Boolean Literals"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/numeric-literals/","text":"Numeric Literals \u00b6 Numeric literals include integers literals and floating-point literals (doubles). Integers Literals \u00b6 Integers are 64 bit digitals, and can be preceded by + or - to indicate a positive or negative value, respectively. They're the same as int64_t in the C language. Notice that the maximum value for the positive integers is 9223372036854775807 . It's syntax-error if you try to input any value greater than the maximum. So as the minimum value -9223372036854775808 for the negative integers. Floating-Point Literals (Doubles) \u00b6 Floating-points are the same as double in the C language. The range for double is about -1.79769e+308 to 1.79769e+308 . Scientific notations is not supported yet. Examples \u00b6 Here are some examples: 1, -5, +10000100000 -2.3, +1.00000000000","title":"Numeric Literals"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/numeric-literals/#numeric_literals","text":"Numeric literals include integers literals and floating-point literals (doubles).","title":"Numeric Literals"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/numeric-literals/#integers_literals","text":"Integers are 64 bit digitals, and can be preceded by + or - to indicate a positive or negative value, respectively. They're the same as int64_t in the C language. Notice that the maximum value for the positive integers is 9223372036854775807 . It's syntax-error if you try to input any value greater than the maximum. So as the minimum value -9223372036854775808 for the negative integers.","title":"Integers Literals"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/numeric-literals/#floating-point_literals_doubles","text":"Floating-points are the same as double in the C language. The range for double is about -1.79769e+308 to 1.79769e+308 . Scientific notations is not supported yet.","title":"Floating-Point Literals (Doubles)"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/numeric-literals/#examples","text":"Here are some examples: 1, -5, +10000100000 -2.3, +1.00000000000","title":"Examples"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/string-literals/","text":"String Literals \u00b6 A string is a sequence of bytes or characters, enclosed within either single quote (') or double quote (\") characters. Examples: nebula> YIELD 'a string' nebula> YIELD \"another string\" Certain backslash escapes (\\) are supported (also known as the escape characters ). They are shown in the following table: Escape Sequence Character Represented by Sequence \\' A single quote (') character \\\" A double quote (\") character \\t A tab character \\n A newline character \\b A backspace character \\ A backslash (\\) character Here are some examples: nebula> YIELD 'This\\nIs\\nFour\\nLines' ======================== | \"This Is Four Lines\" | ======================== | This Is Four Lines | ------------------------ nebula> YIELD 'disappearing\\ backslash' ============================ | \"disappearing backslash\" | ============================ | disappearing backslash | ----------------------------","title":"String Literals"},{"location":"manual-EN/2.query-language/3.language-structure/literal-values/string-literals/#string_literals","text":"A string is a sequence of bytes or characters, enclosed within either single quote (') or double quote (\") characters. Examples: nebula> YIELD 'a string' nebula> YIELD \"another string\" Certain backslash escapes (\\) are supported (also known as the escape characters ). They are shown in the following table: Escape Sequence Character Represented by Sequence \\' A single quote (') character \\\" A double quote (\") character \\t A tab character \\n A newline character \\b A backspace character \\ A backslash (\\) character Here are some examples: nebula> YIELD 'This\\nIs\\nFour\\nLines' ======================== | \"This Is Four Lines\" | ======================== | This Is Four Lines | ------------------------ nebula> YIELD 'disappearing\\ backslash' ============================ | \"disappearing backslash\" | ============================ | disappearing backslash | ----------------------------","title":"String Literals"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/","text":"Schema Index \u00b6 CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] <index_name> ON {<tag_name> | <edge_name>} (prop_name_list) Schema indexes are built to fast process graph queries. Nebula Graph supports two different kinds of indexing to speed up query processing: tag indexes and edge type indexes . Most graph queries start the traversal from a list of vertices or edges that are identified by their properties. Schema indexes make these global retrieval operations efficient on large graphs. Normally, you create indexes on a tag/edge-type at the time the tag/edge-type itself is created with CREATE TAG/EDGE statement. Create Index \u00b6 CREATE INDEX enables you to add indexes to existing tag/edge-type. Create Single-Property Index \u00b6 nebula> CREATE TAG INDEX player_index_0 on player(name); The above statement creates an index for the name property on all vertices carrying the player tag. nebula> CREATE EDGE INDEX follow_index_0 on follow(degree); The above statement creates an index for the degree property on all edges carrying the follow edge type. Create Composite Index \u00b6 The schema indexes also support spawning over multiple properties. An index on multiple properties is called a composite index. Note: Index across multiple tags is not yet supported. Consider the following example: nebula> CREATE TAG INDEX player_index_1 on player(name,age); This statement creates a composite index for the name and age property on all vertices carrying the player tag. Show Index \u00b6 SHOW {TAG | EDGE} INDEXES SHOW INDEXES returns the defined tag/edg-type index information. For example, list the indexes with the following command: nebula> SHOW TAG INDEXES; ============================= | Index ID | Index Name | ============================= | 22 | player_index_0 | ----------------------------- | 23 | player_index_1 | ----------------------------- nebula> SHOW EDGE INDEXES; ============================= | Index ID | Index Name | ============================= | 24 | follow_index_0 | ----------------------------- DESCRIBE INDEX \u00b6 DESCRIBE {TAG | EDGE} INDEX <index_name> DESCRIBE INDEX is used to obtain information about the index. For example, list the index information with the following command: nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------ nebula> DESCRIBE TAG INDEX player_index_1; ================== | Field | Type | ================== | name | string | ------------------ | age | int | ------------------ DROP INDEX \u00b6 DROP {TAG | EDGE} INDEX [IF EXISTS] <index_name> DROP INDEX drops the index named index_name from the tag/edge-type. For example, drop the index player_index_0 with the following command: nebula> DROP TAG INDEX player_index_0; REBUILD INDEX \u00b6 REBUILD {TAG | EDGE} INDEX <index_name> [OFFLINE] Create Index section describes how to build indexes to improve query performance. If the index is created before inserting the data, there is no need to rebuild index and this section can be skipped; if data is updated or newly inserted after the index creation, it is necessary to rebuild the indexes in order to ensure that the indexes contain the previously added data. If the current database does not provide any services, use the OFFLINE keyword to speed up the rebuilding. After rebuilding is complete, you can use the SHOW {TAG | EDGE} INDEX STATUS command to check if the index is successfully rebuilt. For example: nebula> CREATE TAG person(name string, age int, gender string, email string); Execution succeeded (Time spent: 10.051/11.397 ms) nebula> CREATE TAG INDEX single_person_index ON person(name); Execution succeeded (Time spent: 2.168/3.379 ms) nebula> REBUILD TAG INDEX single_person_index OFFLINE; Execution succeeded (Time spent: 2.352/3.568 ms) nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------ Using Index \u00b6 After the index is created and data is inserted, you can use the LOOKUP statement to query the data. There is usually no need to specify which indexes to use in a query, Nebula Graph will figure that out by itself.","title":"INDEX Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#schema_index","text":"CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] <index_name> ON {<tag_name> | <edge_name>} (prop_name_list) Schema indexes are built to fast process graph queries. Nebula Graph supports two different kinds of indexing to speed up query processing: tag indexes and edge type indexes . Most graph queries start the traversal from a list of vertices or edges that are identified by their properties. Schema indexes make these global retrieval operations efficient on large graphs. Normally, you create indexes on a tag/edge-type at the time the tag/edge-type itself is created with CREATE TAG/EDGE statement.","title":"Schema Index"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#create_index","text":"CREATE INDEX enables you to add indexes to existing tag/edge-type.","title":"Create Index"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#create_single-property_index","text":"nebula> CREATE TAG INDEX player_index_0 on player(name); The above statement creates an index for the name property on all vertices carrying the player tag. nebula> CREATE EDGE INDEX follow_index_0 on follow(degree); The above statement creates an index for the degree property on all edges carrying the follow edge type.","title":"Create Single-Property Index"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#create_composite_index","text":"The schema indexes also support spawning over multiple properties. An index on multiple properties is called a composite index. Note: Index across multiple tags is not yet supported. Consider the following example: nebula> CREATE TAG INDEX player_index_1 on player(name,age); This statement creates a composite index for the name and age property on all vertices carrying the player tag.","title":"Create Composite Index"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#show_index","text":"SHOW {TAG | EDGE} INDEXES SHOW INDEXES returns the defined tag/edg-type index information. For example, list the indexes with the following command: nebula> SHOW TAG INDEXES; ============================= | Index ID | Index Name | ============================= | 22 | player_index_0 | ----------------------------- | 23 | player_index_1 | ----------------------------- nebula> SHOW EDGE INDEXES; ============================= | Index ID | Index Name | ============================= | 24 | follow_index_0 | -----------------------------","title":"Show Index"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#describe_index","text":"DESCRIBE {TAG | EDGE} INDEX <index_name> DESCRIBE INDEX is used to obtain information about the index. For example, list the index information with the following command: nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------ nebula> DESCRIBE TAG INDEX player_index_1; ================== | Field | Type | ================== | name | string | ------------------ | age | int | ------------------","title":"DESCRIBE INDEX"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#drop_index","text":"DROP {TAG | EDGE} INDEX [IF EXISTS] <index_name> DROP INDEX drops the index named index_name from the tag/edge-type. For example, drop the index player_index_0 with the following command: nebula> DROP TAG INDEX player_index_0;","title":"DROP INDEX"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#rebuild_index","text":"REBUILD {TAG | EDGE} INDEX <index_name> [OFFLINE] Create Index section describes how to build indexes to improve query performance. If the index is created before inserting the data, there is no need to rebuild index and this section can be skipped; if data is updated or newly inserted after the index creation, it is necessary to rebuild the indexes in order to ensure that the indexes contain the previously added data. If the current database does not provide any services, use the OFFLINE keyword to speed up the rebuilding. After rebuilding is complete, you can use the SHOW {TAG | EDGE} INDEX STATUS command to check if the index is successfully rebuilt. For example: nebula> CREATE TAG person(name string, age int, gender string, email string); Execution succeeded (Time spent: 10.051/11.397 ms) nebula> CREATE TAG INDEX single_person_index ON person(name); Execution succeeded (Time spent: 2.168/3.379 ms) nebula> REBUILD TAG INDEX single_person_index OFFLINE; Execution succeeded (Time spent: 2.352/3.568 ms) nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------","title":"REBUILD INDEX"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/#using_index","text":"After the index is created and data is inserted, you can use the LOOKUP statement to query the data. There is usually no need to specify which indexes to use in a query, Nebula Graph will figure that out by itself.","title":"Using Index"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/","text":"TTL (time-to-live) \u00b6 With TTL , Nebula Graph provides the ability to delete the expired vertices or edges automatically. The system will automatically delete the expired data during the compaction phase. Before compaction, query will filter the expired data. TTl requires ttl_col and ttl_duration together. ttl_col indicates the TTL column, while ttl_duration indicates the duration of the TTL. When the sum of the TTL column and the ttl_duration is less than the current time, we consider the data as expired. The ttl_col type is integer or timestamp, and is set in seconds. ttl_duration is also set in seconds. TTL configuration \u00b6 The ttl_duration is set in seconds and ranges from 0 to max(int64). If it is set to 0, the vertex properties of this tag does not expire. If TTL is set, when the sum of the ttl_col and the ttl_duration is less than the current time, we consider the vertex properties of this tag as expired after the specified seconds configured by ttl_duration has passed since the ttl_col field value. When the vertex has multiple tags, the TTL of each tag is processed separately. Setting a TTL Value \u00b6 Setting a TTL value for the existed tag. nebula> CREATE TAG t1(a timestamp); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 5; -- Setting ttl nebula> INSERT VERTEX t1(a) values 101:(now()); The vertex 101 property in tag t1 will expire after 5 seconds since specified by now(). Or you can set the TTL attribute when creating the tag. nebula> CREATE TAG t2(a int, b int, c string) ttl_duration= 100, ttl_col = \"a\"; nebula> INSERT VERTEX t2(a, b, c) values 102:(1584441231, 30, \"Word\"); The vertex 102 property in tag t2 will expire after 100 seconds since March 17 2020 at 18:33:51 CST i.e. the timestamp is 1584441231. When a vertex has multiple TAGs, the TTL of each TAG is independent from each other. nebula> CREATE TAG t3(a string); nebula> INSERT VERTEX t1(a),t3(a) values 200:(now(), \"hello\"); The vertex 200 property in tag t1 will expire after 5 seconds. nebula> FETCH PROP ON t1 200; Execution succeeded (Time spent: 5.945/7.492 ms) nebula> FETCH PROP ON t3 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ---------------------- nebula> FETCH PROP ON * 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ---------------------- Dropping TTL \u00b6 If you have set a TTL value for a field and later decide do not want it to ever automatically expire, you can drop the TTL value, set it to an empty string or invalidate it by setting it to 0. nebula> ALTER TAG t1 ttl_col = \"\"; -- drop ttl attribute; Drop the field a with the ttl attribute: nebula> ALTER TAG t1 DROP (a); -- drop ttl_col Invalidate the TTL: nebula> ALTER TAG t1 ttl_duration = 0; -- keep the ttl but the data never expires Tips on TTL \u00b6 If a field contains a ttl_col field, you can't make any change on the field. nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> ALTER TAG t1 CHANGE (a string); -- failed Note that the a tag or an edge cannot have both the TTL attribute and index at the same time, even if the ttl_col column is different from that of the index. nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(a); -- failed nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(b); -- failed nebula> CREATE TAG t1(a int, b int, c string); nebula> CREATE TAG INDEX id1 ON t1(a); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 100; -- failed Adding TTL to an edge is similar to a tag.","title":"TTL"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl_time-to-live","text":"With TTL , Nebula Graph provides the ability to delete the expired vertices or edges automatically. The system will automatically delete the expired data during the compaction phase. Before compaction, query will filter the expired data. TTl requires ttl_col and ttl_duration together. ttl_col indicates the TTL column, while ttl_duration indicates the duration of the TTL. When the sum of the TTL column and the ttl_duration is less than the current time, we consider the data as expired. The ttl_col type is integer or timestamp, and is set in seconds. ttl_duration is also set in seconds.","title":"TTL (time-to-live)"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#ttl_configuration","text":"The ttl_duration is set in seconds and ranges from 0 to max(int64). If it is set to 0, the vertex properties of this tag does not expire. If TTL is set, when the sum of the ttl_col and the ttl_duration is less than the current time, we consider the vertex properties of this tag as expired after the specified seconds configured by ttl_duration has passed since the ttl_col field value. When the vertex has multiple tags, the TTL of each tag is processed separately.","title":"TTL configuration"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#setting_a_ttl_value","text":"Setting a TTL value for the existed tag. nebula> CREATE TAG t1(a timestamp); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 5; -- Setting ttl nebula> INSERT VERTEX t1(a) values 101:(now()); The vertex 101 property in tag t1 will expire after 5 seconds since specified by now(). Or you can set the TTL attribute when creating the tag. nebula> CREATE TAG t2(a int, b int, c string) ttl_duration= 100, ttl_col = \"a\"; nebula> INSERT VERTEX t2(a, b, c) values 102:(1584441231, 30, \"Word\"); The vertex 102 property in tag t2 will expire after 100 seconds since March 17 2020 at 18:33:51 CST i.e. the timestamp is 1584441231. When a vertex has multiple TAGs, the TTL of each TAG is independent from each other. nebula> CREATE TAG t3(a string); nebula> INSERT VERTEX t1(a),t3(a) values 200:(now(), \"hello\"); The vertex 200 property in tag t1 will expire after 5 seconds. nebula> FETCH PROP ON t1 200; Execution succeeded (Time spent: 5.945/7.492 ms) nebula> FETCH PROP ON t3 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ---------------------- nebula> FETCH PROP ON * 200; ====================== | VertexID | t3.a | ====================== | 200 | hello | ----------------------","title":"Setting a TTL Value"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#dropping_ttl","text":"If you have set a TTL value for a field and later decide do not want it to ever automatically expire, you can drop the TTL value, set it to an empty string or invalidate it by setting it to 0. nebula> ALTER TAG t1 ttl_col = \"\"; -- drop ttl attribute; Drop the field a with the ttl attribute: nebula> ALTER TAG t1 DROP (a); -- drop ttl_col Invalidate the TTL: nebula> ALTER TAG t1 ttl_duration = 0; -- keep the ttl but the data never expires","title":"Dropping TTL"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/TTL/#tips_on_ttl","text":"If a field contains a ttl_col field, you can't make any change on the field. nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> ALTER TAG t1 CHANGE (a string); -- failed Note that the a tag or an edge cannot have both the TTL attribute and index at the same time, even if the ttl_col column is different from that of the index. nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(a); -- failed nebula> CREATE TAG t1(a int, b int, c string) ttl_duration = 100, ttl_col = \"a\"; nebula> CREATE TAG INDEX id1 ON t1(b); -- failed nebula> CREATE TAG t1(a int, b int, c string); nebula> CREATE TAG INDEX id1 ON t1(a); nebula> ALTER TAG t1 ttl_col = \"a\", ttl_duration = 100; -- failed Adding TTL to an edge is similar to a tag.","title":"Tips on TTL"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/alter-tag-edge-syntax/","text":"Alter Tag/Edge Syntax \u00b6 ALTER TAG | EDGE <tag_name> | <edge_name> <alter_definition> [, alter_definition] ...] [ttl_definition [, ttl_definition] ... ] alter_definition: | ADD (prop_name data_type) | DROP (prop_name) | CHANGE (prop_name data_type) ttl_definition: TTL_DURATION = ttl_duration, TTL_COL = prop_name ALTER statement changes the structure of a tag or an edge. For example, you can add or delete properties, change the data type of an existing property. You can also set a property as TTL (Time-To-Live), or change the TTL duration. Note: Nebula Graph automatically examines indexes when altering a tag or edge. When altering a tag or edge, Nebula Graph first checks whether the tag or edge is associated with any indexes then traverses all of them to check whether the column item to be dropped or changed exists in the index column. If existed, the alter is rejected. Otherwise, it is allowed. Please refer to Index Documentation on details about index. Multiple ADD , DROP , and CHANGE clauses are permitted in a single ALTER statements, separated by commas. But do NOT add, drop, change the same property in one statement. If you have to do so, make each operation as a clause of the ALTER statement. nebula> CREATE TAG t1 (name string, age int); nebula> ALTER TAG t1 ADD (id int, address string); nebula> CREATE EDGE e1 (prop3 int, prop4 int, prop5 int); nebula> ALTER EDGE e1 ADD (prop1 int, prop2 string), /* \u6dfb\u52a0 prop1 */ CHANGE (prop3 string), /* \u5c06 prop3 \u7c7b\u578b\u66f4\u6539\u4e3a\u5b57\u7b26 */ DROP (prop4, prop5); /* \u5220\u9664 prop4 \u548c prop5 */ nebula> ALTER EDGE e1 TTL_DURATION = 2, TTL_COL = prop1; Notice that TTL_COL only support INT and TIMESTAMP types.","title":"ALTER TAG EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/alter-tag-edge-syntax/#alter_tagedge_syntax","text":"ALTER TAG | EDGE <tag_name> | <edge_name> <alter_definition> [, alter_definition] ...] [ttl_definition [, ttl_definition] ... ] alter_definition: | ADD (prop_name data_type) | DROP (prop_name) | CHANGE (prop_name data_type) ttl_definition: TTL_DURATION = ttl_duration, TTL_COL = prop_name ALTER statement changes the structure of a tag or an edge. For example, you can add or delete properties, change the data type of an existing property. You can also set a property as TTL (Time-To-Live), or change the TTL duration. Note: Nebula Graph automatically examines indexes when altering a tag or edge. When altering a tag or edge, Nebula Graph first checks whether the tag or edge is associated with any indexes then traverses all of them to check whether the column item to be dropped or changed exists in the index column. If existed, the alter is rejected. Otherwise, it is allowed. Please refer to Index Documentation on details about index. Multiple ADD , DROP , and CHANGE clauses are permitted in a single ALTER statements, separated by commas. But do NOT add, drop, change the same property in one statement. If you have to do so, make each operation as a clause of the ALTER statement. nebula> CREATE TAG t1 (name string, age int); nebula> ALTER TAG t1 ADD (id int, address string); nebula> CREATE EDGE e1 (prop3 int, prop4 int, prop5 int); nebula> ALTER EDGE e1 ADD (prop1 int, prop2 string), /* \u6dfb\u52a0 prop1 */ CHANGE (prop3 string), /* \u5c06 prop3 \u7c7b\u578b\u66f4\u6539\u4e3a\u5b57\u7b26 */ DROP (prop4, prop5); /* \u5220\u9664 prop4 \u548c prop5 */ nebula> ALTER EDGE e1 TTL_DURATION = 2, TTL_COL = prop1; Notice that TTL_COL only support INT and TIMESTAMP types.","title":"Alter Tag/Edge Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/","text":"Create Space Syntax \u00b6 CREATE SPACE [IF NOT EXISTS] <space_name> [(partition_num = <part_num>, replica_factor = <raft_copy>, charset = <charset>, collate = <collate>)] This statement creates a new space with the given name. SPACE is a region that provides physically isolated graphs in Nebula Graph . An error occurs if the database exists. IF NOT EXISTS \u00b6 You can use the If NOT EXISTS keywords when creating spaces. This keyword automatically detects if the corresponding space exists. If it does not exist, a new one is created. Otherwise, no space is created. Note: The space existence detection here only compares the space name (excluding properties). Space Name \u00b6 space_name The name uniquely identifies the space in a cluster. The rules for the naming are given in Schema Object Names Customized Space Options \u00b6 When creating a space, the following two customized options can be given: partition_num partition_num specifies the number of partitions in one replica. The default value is 100. replica_factor replica_factor specifies the number of replicas in the cluster. The default replica factor is 1. The suggested number is 3 in cluster. charset charset is short for character set. A character set is a set of symbols and encodings. The default value is utf8. collate A collation is a set of rules for comparing characters in a character set. The default value is utf8_bin. However, if no option is given, Nebula Graph will create the space with the default partition number, replica factor, charset and collate. Example \u00b6 nebula> CREATE SPACE my_space_1; -- create space with default partition number and replica factor nebula> CREATE SPACE my_space_2(partition_num=10); -- create space with default replica factor nebula> CREATE SPACE my_space_3(replica_factor=1); -- create space with default partition number nebula> CREATE SPACE my_space_4(partition_num=10, replica_factor=1);","title":"CREATE SPACE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#create_space_syntax","text":"CREATE SPACE [IF NOT EXISTS] <space_name> [(partition_num = <part_num>, replica_factor = <raft_copy>, charset = <charset>, collate = <collate>)] This statement creates a new space with the given name. SPACE is a region that provides physically isolated graphs in Nebula Graph . An error occurs if the database exists.","title":"Create Space Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#if_not_exists","text":"You can use the If NOT EXISTS keywords when creating spaces. This keyword automatically detects if the corresponding space exists. If it does not exist, a new one is created. Otherwise, no space is created. Note: The space existence detection here only compares the space name (excluding properties).","title":"IF NOT EXISTS"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#space_name","text":"space_name The name uniquely identifies the space in a cluster. The rules for the naming are given in Schema Object Names","title":"Space Name"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#customized_space_options","text":"When creating a space, the following two customized options can be given: partition_num partition_num specifies the number of partitions in one replica. The default value is 100. replica_factor replica_factor specifies the number of replicas in the cluster. The default replica factor is 1. The suggested number is 3 in cluster. charset charset is short for character set. A character set is a set of symbols and encodings. The default value is utf8. collate A collation is a set of rules for comparing characters in a character set. The default value is utf8_bin. However, if no option is given, Nebula Graph will create the space with the default partition number, replica factor, charset and collate.","title":"Customized Space Options"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-space-syntax/#example","text":"nebula> CREATE SPACE my_space_1; -- create space with default partition number and replica factor nebula> CREATE SPACE my_space_2(partition_num=10); -- create space with default replica factor nebula> CREATE SPACE my_space_3(replica_factor=1); -- create space with default partition number nebula> CREATE SPACE my_space_4(partition_num=10, replica_factor=1);","title":"Example"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/","text":"Create TAG / EDGE Syntax \u00b6 CREATE {TAG | EDGE} [IF NOT EXISTS] {<tag_name> | <edge_name>} ([<create_definition>, ...]) [tag_edge_options] <create_definition> ::= <prop_name> <data_type> <tag_edge_options> ::= <option> [, <option> ...] <option> ::= TTL_DURATION [=] <ttl_duration> | TTL_COL [=] <prop_name> | DEFAULT <default_value> Nebula Graph 's schema is composed of tags and edges, either of which may have properties. CREATE TAG statement defines a tag with the given name. While CREATE EDGE statement is to define an edge type. The features of this syntax are described in the following sections: IF NOT EXISTS \u00b6 You can use the If NOT EXISTS keywords when creating tags or edges. This keyword automatically detects if the corresponding tag or edge exists. If it does not exist, a new one is created. Otherwise, no tag or edge is created. Note: The tag or edge existence detection here only compares the tag or edge name (excluding properties). Tag Name and Edge Type Name \u00b6 tag_name and edge_name The name of tags and edgeTypes must be unique within the space. Once the name is defined, it can not be altered. The rules of tag and edgeType names are the same as those for names of spaces. See Schema Object Name for detail. Property Name and Data Type \u00b6 prop_name prop_name indicates the name of properties. It must be unique for each tag or edgeType. data_type data_type represents the data type of each property. For more information about data types that Nebula Graph supports, see data-type section. NULL and NOT NULL constrain are not supported yet when creating tags/edges (comparing with relational databases). Default Constraint You can set the default value of a property when creating a tag/edge with the DEFAULT constraint. The default value will be added to all new vertices and edges if no other value is specified. The default value can be any of the data type supported by Nebula Graph or expressions. Also you can write a user-specified value if you don't want to use the default one. Using Alter to change the default value is not supported. Time-to-Live (TTL) Syntax \u00b6 TTL_DURATION ttl_duration specifies the life cycle of vertices (or edges). Data that exceeds the specified TTL will expire. The expiration threshold is the specified TTL_COL value plus the TTL_DURATION. If the value for ttl_duration is zero or negative, the vertices or edges will not expire. TTL_COL The data type of prop_name must be either int64 or timestamp. single TTL definition Only a single TTL_COL field can be specified. Details about TTL refer to the TTL Doc . Examples \u00b6 nebula> CREATE TAG course(name string, credits int) nebula> CREATE TAG notag() -- empty properties nebula> CREATE EDGE follow(start_time timestamp, grade double) nebula> CREATE EDGE noedge() -- empty properties nebula> CREATE TAG player_with_default(name string, age int DEFAULT 20) -- age is set to 20 by default nebula> CREATE EDGE follow_with_default(start_time timestamp DEFAULT 0, grade double DEFAULT 0.0) -- start_time is set to 0 by default, grade is set to 0.0 by default nebula> CREATE TAG woman(name string, age int, married bool, salary double, create_time timestamp) TTL_DURATION = 100, TTL_COL = \"create_time\" -- time interval is 100s, starting from the create_time filed nebula> CREATE EDGE marriage(location string, since timestamp) TTL_DURATION = 0, TTL_COL = \"since\" -- negative or zero, not expire nebula> CREATE TAG icecream(made timestamp, temperature int) TTL_DURATION = 100, TTL_COL = \"made\", -- Data expires after TTL_DURATION","title":"CREATE TAG EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#create_tag_edge_syntax","text":"CREATE {TAG | EDGE} [IF NOT EXISTS] {<tag_name> | <edge_name>} ([<create_definition>, ...]) [tag_edge_options] <create_definition> ::= <prop_name> <data_type> <tag_edge_options> ::= <option> [, <option> ...] <option> ::= TTL_DURATION [=] <ttl_duration> | TTL_COL [=] <prop_name> | DEFAULT <default_value> Nebula Graph 's schema is composed of tags and edges, either of which may have properties. CREATE TAG statement defines a tag with the given name. While CREATE EDGE statement is to define an edge type. The features of this syntax are described in the following sections:","title":"Create TAG / EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#if_not_exists","text":"You can use the If NOT EXISTS keywords when creating tags or edges. This keyword automatically detects if the corresponding tag or edge exists. If it does not exist, a new one is created. Otherwise, no tag or edge is created. Note: The tag or edge existence detection here only compares the tag or edge name (excluding properties).","title":"IF NOT EXISTS"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#tag_name_and_edge_type_name","text":"tag_name and edge_name The name of tags and edgeTypes must be unique within the space. Once the name is defined, it can not be altered. The rules of tag and edgeType names are the same as those for names of spaces. See Schema Object Name for detail.","title":"Tag Name and Edge Type Name"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#property_name_and_data_type","text":"prop_name prop_name indicates the name of properties. It must be unique for each tag or edgeType. data_type data_type represents the data type of each property. For more information about data types that Nebula Graph supports, see data-type section. NULL and NOT NULL constrain are not supported yet when creating tags/edges (comparing with relational databases). Default Constraint You can set the default value of a property when creating a tag/edge with the DEFAULT constraint. The default value will be added to all new vertices and edges if no other value is specified. The default value can be any of the data type supported by Nebula Graph or expressions. Also you can write a user-specified value if you don't want to use the default one. Using Alter to change the default value is not supported.","title":"Property Name and Data Type"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#time-to-live_ttl_syntax","text":"TTL_DURATION ttl_duration specifies the life cycle of vertices (or edges). Data that exceeds the specified TTL will expire. The expiration threshold is the specified TTL_COL value plus the TTL_DURATION. If the value for ttl_duration is zero or negative, the vertices or edges will not expire. TTL_COL The data type of prop_name must be either int64 or timestamp. single TTL definition Only a single TTL_COL field can be specified. Details about TTL refer to the TTL Doc .","title":"Time-to-Live (TTL) Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/create-tag-edge-syntax/#examples","text":"nebula> CREATE TAG course(name string, credits int) nebula> CREATE TAG notag() -- empty properties nebula> CREATE EDGE follow(start_time timestamp, grade double) nebula> CREATE EDGE noedge() -- empty properties nebula> CREATE TAG player_with_default(name string, age int DEFAULT 20) -- age is set to 20 by default nebula> CREATE EDGE follow_with_default(start_time timestamp DEFAULT 0, grade double DEFAULT 0.0) -- start_time is set to 0 by default, grade is set to 0.0 by default nebula> CREATE TAG woman(name string, age int, married bool, salary double, create_time timestamp) TTL_DURATION = 100, TTL_COL = \"create_time\" -- time interval is 100s, starting from the create_time filed nebula> CREATE EDGE marriage(location string, since timestamp) TTL_DURATION = 0, TTL_COL = \"since\" -- negative or zero, not expire nebula> CREATE TAG icecream(made timestamp, temperature int) TTL_DURATION = 100, TTL_COL = \"made\", -- Data expires after TTL_DURATION","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-edge-syntax/","text":"Drop Edge Syntax \u00b6 DROP EDGE [IF EXISTS] <edge_type_name> You must have the DROP privilege for the edge type. Note: When dropping an edge, Nebula Graph only checks whether the edge is associated with any indexes. If so the deletion is rejected. Please refer to Index Documentation on details about index. You can use the If EXISTS keywords when dropping edges. These keywords automatically detect if the corresponding edge exists. If it exists, it will be deleted. Otherwise, no edge is deleted. This statement removes all the edges (connections) within the specific edge type. This operation only deletes the Schema data, all the files and directories in the disk are NOT deleted directly, data is deleted in the next compaction.","title":"DROP EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-edge-syntax/#drop_edge_syntax","text":"DROP EDGE [IF EXISTS] <edge_type_name> You must have the DROP privilege for the edge type. Note: When dropping an edge, Nebula Graph only checks whether the edge is associated with any indexes. If so the deletion is rejected. Please refer to Index Documentation on details about index. You can use the If EXISTS keywords when dropping edges. These keywords automatically detect if the corresponding edge exists. If it exists, it will be deleted. Otherwise, no edge is deleted. This statement removes all the edges (connections) within the specific edge type. This operation only deletes the Schema data, all the files and directories in the disk are NOT deleted directly, data is deleted in the next compaction.","title":"Drop Edge Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-space-syntax/","text":"Drop Space Syntax \u00b6 DROP SPACE [IF EXISTS] <space_name> You must have the DROP privilege for the graph space. DROP SPACE deletes everything (all the vertices, edges, indices, and properties) in the specific space. You can use the If EXISTS keywords when dropping spaces. This keyword automatically detects if the corresponding space exists. If it exists, it will be deleted. Otherwise, no space is deleted. Other spaces remain unchanged. This statement does not immediately remove all the files and directories in the storage engine (and release disk space). The deletion depends on the implementation of different storage engines. Be very careful with this statement.","title":"DROP SPACE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-space-syntax/#drop_space_syntax","text":"DROP SPACE [IF EXISTS] <space_name> You must have the DROP privilege for the graph space. DROP SPACE deletes everything (all the vertices, edges, indices, and properties) in the specific space. You can use the If EXISTS keywords when dropping spaces. This keyword automatically detects if the corresponding space exists. If it exists, it will be deleted. Otherwise, no space is deleted. Other spaces remain unchanged. This statement does not immediately remove all the files and directories in the storage engine (and release disk space). The deletion depends on the implementation of different storage engines. Be very careful with this statement.","title":"Drop Space Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-tag-syntax/","text":"Drop Tag Syntax \u00b6 DROP TAG [IF EXISTS] <tag_name> You must have the DROP privilege for the tag. Be careful with this statement. Note: When dropping a tag, Nebula Graph only checks whether the tag is associated with any indexes. If so the deletion is rejected. Please refer to Index Documentation on details about index. You can use the If EXISTS keywords when dropping tags. These keywords automatically detect if the corresponding tag exists. If it exists, it will be deleted. Otherwise, no tag is deleted. A vertex can have either only one tag (types) or multiple tags (types). In the former case, such a vertex can NOT be accessible after the statement, and edges connected with such vertex may result in DANGLING. In the latter case, the dropped a vertex is still accessible. But all the properties defined by this dropped tag are not accessible. This operation only deletes the Schema data, all the files and directories in the disk are NOT deleted directly, data is deleted in the next compaction.","title":"DROP TAG Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/1.data-definition-statements/drop-tag-syntax/#drop_tag_syntax","text":"DROP TAG [IF EXISTS] <tag_name> You must have the DROP privilege for the tag. Be careful with this statement. Note: When dropping a tag, Nebula Graph only checks whether the tag is associated with any indexes. If so the deletion is rejected. Please refer to Index Documentation on details about index. You can use the If EXISTS keywords when dropping tags. These keywords automatically detect if the corresponding tag exists. If it exists, it will be deleted. Otherwise, no tag is deleted. A vertex can have either only one tag (types) or multiple tags (types). In the former case, such a vertex can NOT be accessible after the statement, and edges connected with such vertex may result in DANGLING. In the latter case, the dropped a vertex is still accessible. But all the properties defined by this dropped tag are not accessible. This operation only deletes the Schema data, all the files and directories in the disk are NOT deleted directly, data is deleted in the next compaction.","title":"Drop Tag Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-edge-syntax/","text":"Delete Edge Syntax \u00b6 The DELETE EDGE statement is used to delete edges. Given an edge type, the source vertex and the dest vertex, Nebula Graph supports DELETE the edge, its associated properties and the edge ranking. You can also delete an edge with a certain rank. The syntax is as follows: DELETE EDGE <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] Nebula Graph will find the properties associated with the edge and delete all of them. Atomic operation is not guaranteed during the entire process for now, so please retry when failure occurs.","title":"DELETE EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-edge-syntax/#delete_edge_syntax","text":"The DELETE EDGE statement is used to delete edges. Given an edge type, the source vertex and the dest vertex, Nebula Graph supports DELETE the edge, its associated properties and the edge ranking. You can also delete an edge with a certain rank. The syntax is as follows: DELETE EDGE <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] Nebula Graph will find the properties associated with the edge and delete all of them. Atomic operation is not guaranteed during the entire process for now, so please retry when failure occurs.","title":"Delete Edge Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-vertex-syntax/","text":"Delete Syntax \u00b6 Given a list of vertices IDs, hash IDs or UUIDs, Nebula Graph supports DELETE the vertices and their associated in and out edges, syntax as the follows: DELETE VERTEX <vid_list> Nebula Graph will find the in and out edges associated with the vertices and delete all of them, then delete information related to the vertices. Atomic operation is not guaranteed during the entire process for now, so please retry when failure occurs.","title":"DELETE VERTEX Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/delete-vertex-syntax/#delete_syntax","text":"Given a list of vertices IDs, hash IDs or UUIDs, Nebula Graph supports DELETE the vertices and their associated in and out edges, syntax as the follows: DELETE VERTEX <vid_list> Nebula Graph will find the in and out edges associated with the vertices and delete all of them, then delete information related to the vertices. Atomic operation is not guaranteed during the entire process for now, so please retry when failure occurs.","title":"Delete Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/","text":"Fetch Syntax \u00b6 The FETCH syntax is used to get vertex/edge's properties. Fetch Vertex property \u00b6 Use FETCH PROP ON to return a (list of) vertex's properties. Currently, you can get multiple vertices' properties with the same tag in one statement. FETCH PROP ON <tag_name> <vertex_id_list> [YIELD [DISTINCT] <return_list>] FETCH PROP ON * <vertex_id> * indicates returning all the properties of the given vertex. <tag_name> is the tag name. It must be the same tag within return_list. <vertex_id_list>::=[vertex_id [, vertex_id]] is a list of vertex IDs separated by comma(,). [YIELD [DISTINCT] <return_list>] is the property list returned. Please refer here YIELD Syntax . Examples \u00b6 -- return all the properties of vertex id 100. nebula> FETCH PROP ON * 100; -- return all the properties in tag player of vertex id 100 if no yield field is given. nebula> FETCH PROP ON player 100; -- return property name and age of vertex id 100. nebula> FETCH PROP ON player 100 YIELD player.name, player.age; -- hash string to int64 as vertex id, fetch name and player. nebula> FETCH PROP ON player hash(\"nebula\") YIELD player.name, player.age; -- find all neighbors of vertex 100 through edge follow. Then get the neighbors' name and age. nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | FETCH PROP ON player $-.id YIELD player.name, player.age; -- the same as above statement. nebula> $var = GO FROM 100 OVER follow YIELD follow._dst AS id; FETCH PROP ON player $var.id YIELD player.name, player.age; -- get three vertices 100, 101, 102 and return by unique(distinct) name and age. nebula> FETCH PROP ON player 100,101,102 YIELD DISTINCT player.name, player.age; Fetch Edge Property \u00b6 The FETCH usage of an edge is almost the same with vertex. You can get properties from multiple edges with the same type. FETCH PROP ON <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] [YIELD [DISTINCT] <return_list>] <edge_type> specifies the edge's type. It must be the same as those in <return_list> . <vid> -> <vid> denotes a starting vertex to (->) an ending vertex. Multiple edges are separated by comma(,). <ranking> specifies the edge weight of the same edge type; it's optional. [YIELD [DISTINCT] <return_list>] is the property list returned. Example \u00b6 -- from vertex 100 to 200 with edge type serve, get all the properties since no YIELD is given. nebula> FETCH PROP ON serve 100 -> 200; -- only return property start_year. nebula> FETCH PROP ON serve 100 -> 200 YIELD serve.start_year; -- for all the out going edges of vertex 100, get edge property degree. nebula> GO FROM 100 OVER follow YIELD follow.degree; -- the same as above statement. nebula> GO FROM 100 OVER follow YIELD follow._src AS s, follow._dst AS d \\ | FETCH PROP ON follow $-.s -> $-.d YIELD follow.degree; -- the same as above. nebula> $var = GO FROM 100 OVER follow YIELD follow._src AS s, follow._dst AS d;\\ FETCH PROP ON follow $var.s -> $var.d YIELD follow.degree;","title":"FETCH Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#fetch_syntax","text":"The FETCH syntax is used to get vertex/edge's properties.","title":"Fetch Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#fetch_vertex_property","text":"Use FETCH PROP ON to return a (list of) vertex's properties. Currently, you can get multiple vertices' properties with the same tag in one statement. FETCH PROP ON <tag_name> <vertex_id_list> [YIELD [DISTINCT] <return_list>] FETCH PROP ON * <vertex_id> * indicates returning all the properties of the given vertex. <tag_name> is the tag name. It must be the same tag within return_list. <vertex_id_list>::=[vertex_id [, vertex_id]] is a list of vertex IDs separated by comma(,). [YIELD [DISTINCT] <return_list>] is the property list returned. Please refer here YIELD Syntax .","title":"Fetch Vertex property"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#examples","text":"-- return all the properties of vertex id 100. nebula> FETCH PROP ON * 100; -- return all the properties in tag player of vertex id 100 if no yield field is given. nebula> FETCH PROP ON player 100; -- return property name and age of vertex id 100. nebula> FETCH PROP ON player 100 YIELD player.name, player.age; -- hash string to int64 as vertex id, fetch name and player. nebula> FETCH PROP ON player hash(\"nebula\") YIELD player.name, player.age; -- find all neighbors of vertex 100 through edge follow. Then get the neighbors' name and age. nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | FETCH PROP ON player $-.id YIELD player.name, player.age; -- the same as above statement. nebula> $var = GO FROM 100 OVER follow YIELD follow._dst AS id; FETCH PROP ON player $var.id YIELD player.name, player.age; -- get three vertices 100, 101, 102 and return by unique(distinct) name and age. nebula> FETCH PROP ON player 100,101,102 YIELD DISTINCT player.name, player.age;","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#fetch_edge_property","text":"The FETCH usage of an edge is almost the same with vertex. You can get properties from multiple edges with the same type. FETCH PROP ON <edge_type> <vid> -> <vid>[@<ranking>] [, <vid> -> <vid> ...] [YIELD [DISTINCT] <return_list>] <edge_type> specifies the edge's type. It must be the same as those in <return_list> . <vid> -> <vid> denotes a starting vertex to (->) an ending vertex. Multiple edges are separated by comma(,). <ranking> specifies the edge weight of the same edge type; it's optional. [YIELD [DISTINCT] <return_list>] is the property list returned.","title":"Fetch Edge Property"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/fetch-syntax/#example","text":"-- from vertex 100 to 200 with edge type serve, get all the properties since no YIELD is given. nebula> FETCH PROP ON serve 100 -> 200; -- only return property start_year. nebula> FETCH PROP ON serve 100 -> 200 YIELD serve.start_year; -- for all the out going edges of vertex 100, get edge property degree. nebula> GO FROM 100 OVER follow YIELD follow.degree; -- the same as above statement. nebula> GO FROM 100 OVER follow YIELD follow._src AS s, follow._dst AS d \\ | FETCH PROP ON follow $-.s -> $-.d YIELD follow.degree; -- the same as above. nebula> $var = GO FROM 100 OVER follow YIELD follow._src AS s, follow._dst AS d;\\ FETCH PROP ON follow $var.s -> $var.d YIELD follow.degree;","title":"Example"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/","text":"Go Syntax \u00b6 GO statement is the MOST commonly used clause in Nebula Graph . It indicates to traverse in a graph with specific filters (the WHERE clause), to fetch properties of vertices and edges, and return results (the YIELD clause) with given order (the ORDER BY ASC | DESC clause) and numbers (the LIMIT clause). The syntax of GO statement is very similar to SELECT in SQL. Notice that the major difference is that GO must start traversing from a (set of) vertex (vertices). GO [ <N> STEPS ] FROM <node_list> OVER <edge_type_list> [REVERSELY] [BIDIRECT] [ WHERE <expression> [ AND | OR expression ...]) ] YIELD [DISTINCT] <return_list> <node_list> | <vid> [, <vid> ...] | $-.id <edge_type_list> edge_type [, edge_type ...] * # `*` selects all the available edge types <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [ \\ STEPS ] specifies the N query hops is either a list of node's vid separated by comma(,), or a special place holder $-.id (refer PIPE syntax). is a list of edge types which graph traversal can go through. [ WHERE \\ ] extracts only those results that fulfill the specified conditions. WHERE syntax can be conditions for src-vertex, the edges, and dst-vertex. The logical AND, OR, NOT are also supported. See WHERE Syntax for more information. YIELD [DISTINCT] statement returns the result in column format and rename as an alias name. See YIELD syntax for more information. The DISTINCT syntax works the same as SQL. Examples \u00b6 nebula> GO FROM 107 OVER serve; \\ /* start from vertex 107 along with edge type serve, and get vertex 200, 201 */ ============== | serve._dst | ============== | 200 | -------------- | 201 | -------------- nebula> GO 2 STEPS FROM 103 OVER follow; \\ /* return the 2 hop friends of the vertex 103 */ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 109 OVER serve \\ WHERE serve.start_year > 1990 /* check edge (serve) property ( start_year) */ \\ YIELD $$.team.name AS team_name, serve.start_year as start_year; /* target vertex (team) property serve.start_year */ ========================== | team_name | start_year | ========================== | Nuggets | 2011 | -------------------------- | Rockets | 2017 | -------------------------- nebula> GO FROM 100,102 OVER serve \\ WHERE serve.start_year > 1995 /* check edge property */ \\ YIELD DISTINCT $$.team.name AS team_name, /* DISTINCT as SQL */ \\ serve.start_year as start_year, /* edge property */ \\ $^.player.name AS player_name /* source vertex (player) property */ ============================================== | team_name | start_year | player_name | ============================================== | Warriors | 2001 | LaMarcus Aldridge | ---------------------------------------------- | Warriors | 1997 | Tim Duncan | ---------------------------------------------- Traverse Along Multiple Edges Types \u00b6 Currently, Nebula Graph also supports traversing via multiple edge types with GO . The syntax is: GO FROM <node_list> OVER <edge_type_list | *> YIELD [DISTINCT] <return_list> For example: nebula> GO OVER FROM <node_list> edge1, edge2.... // traverse alone edge1 and edge2 or nebula> GO OVER FROM <node_list> * // * indicates traversing along all edge types Please note that when traversing along multiple edges, there are some special restrictions on the use of filters(namely the WHERE statement), for example filters like WHERE edge1.prop1 > edge2.prop2 is not supported. As for return results, if multiple edge properties are to be returned, Nebula Graph will place them in different rows. For example: nebula> GO FROM 100 OVER follow, serve YIELD follow.degree, serve.start_year; The following result is returned: ==================================== | follow.degree | serve.start_year | ==================================== | 0 | 1997 | ------------------------------------ | 95 | 0 | ------------------------------------ | 89 | 0 | ------------------------------------ | 90 | 0 | ------------------------------------ If there is no property, the default value will be placed. The default value for numeric type is 0, and for string type is an empty string, for bool is false, for timestamp is 0 (namely \u201c1970-01-01 00:00:00\u201d) and for double is 0.0. Of course, you can query without specifying `YIELD`, which returns the vids of the dest vertices of each edge. Again, default values (here is 0) will be placed if there is no property. For example, query `GO FROM 100 OVER follow, serve;` returns the follow lines: ============================ | follow._dst | serve._dst | ============================ | 0 | 200 | ---------------------------- | 101 | 0 | ---------------------------- | 102 | 0 | ---------------------------- | 106 | 0 | ---------------------------- For query statement GO FROM 100 OVER * , the result is similar to the above example: the non-existing property or vid is populated with default values. Please note that we can't tell which row belongs to which edge in the results. The future version will show the edge type in the result. Traverse Reversely \u00b6 Currently, Nebula Graph supports traversing reversely using keyword REVERSELY . The syntax is: GO FROM <node_list> OVER <edge_type_list> REVERSELY WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> For example: nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._src; -- returns 100 nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve WHERE $^.player.age > 20 YIELD $^.player.name AS FriendOf, $$.team.name AS Team; ============================ | FriendOf | Team | ============================ | Tony Parker | Warriors | ---------------------------- | Kyle Anderson | Warriors | ---------------------------- The above query first traverses players that follow player 100 and finds the teams they serve, then filter players who are older than 20, and finally it returns their names and teams. Of course, you can query without specifying YIELD, which will return the vids of the dest vertices of each edge by default. Traverse Bidirect \u00b6 Currently, Nebula Graph supports traversing along in and out edges using keyword BIDIRECT , the syntax is: GO FROM <node_list> OVER <edge_type_list> BIDIRECT WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> For example: nebula> GO FROM 102 OVER follow BIDIRECT; =============== | follow._dst | =============== | 101 | --------------- | 103 | --------------- | 135 | --------------- The above query returns players followed by 102 and follow 102 at the same time.","title":"GO Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#go_syntax","text":"GO statement is the MOST commonly used clause in Nebula Graph . It indicates to traverse in a graph with specific filters (the WHERE clause), to fetch properties of vertices and edges, and return results (the YIELD clause) with given order (the ORDER BY ASC | DESC clause) and numbers (the LIMIT clause). The syntax of GO statement is very similar to SELECT in SQL. Notice that the major difference is that GO must start traversing from a (set of) vertex (vertices). GO [ <N> STEPS ] FROM <node_list> OVER <edge_type_list> [REVERSELY] [BIDIRECT] [ WHERE <expression> [ AND | OR expression ...]) ] YIELD [DISTINCT] <return_list> <node_list> | <vid> [, <vid> ...] | $-.id <edge_type_list> edge_type [, edge_type ...] * # `*` selects all the available edge types <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [ \\ STEPS ] specifies the N query hops is either a list of node's vid separated by comma(,), or a special place holder $-.id (refer PIPE syntax). is a list of edge types which graph traversal can go through. [ WHERE \\ ] extracts only those results that fulfill the specified conditions. WHERE syntax can be conditions for src-vertex, the edges, and dst-vertex. The logical AND, OR, NOT are also supported. See WHERE Syntax for more information. YIELD [DISTINCT] statement returns the result in column format and rename as an alias name. See YIELD syntax for more information. The DISTINCT syntax works the same as SQL.","title":"Go Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#examples","text":"nebula> GO FROM 107 OVER serve; \\ /* start from vertex 107 along with edge type serve, and get vertex 200, 201 */ ============== | serve._dst | ============== | 200 | -------------- | 201 | -------------- nebula> GO 2 STEPS FROM 103 OVER follow; \\ /* return the 2 hop friends of the vertex 103 */ =============== | follow._dst | =============== | 101 | --------------- nebula> GO FROM 109 OVER serve \\ WHERE serve.start_year > 1990 /* check edge (serve) property ( start_year) */ \\ YIELD $$.team.name AS team_name, serve.start_year as start_year; /* target vertex (team) property serve.start_year */ ========================== | team_name | start_year | ========================== | Nuggets | 2011 | -------------------------- | Rockets | 2017 | -------------------------- nebula> GO FROM 100,102 OVER serve \\ WHERE serve.start_year > 1995 /* check edge property */ \\ YIELD DISTINCT $$.team.name AS team_name, /* DISTINCT as SQL */ \\ serve.start_year as start_year, /* edge property */ \\ $^.player.name AS player_name /* source vertex (player) property */ ============================================== | team_name | start_year | player_name | ============================================== | Warriors | 2001 | LaMarcus Aldridge | ---------------------------------------------- | Warriors | 1997 | Tim Duncan | ----------------------------------------------","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#traverse_along_multiple_edges_types","text":"Currently, Nebula Graph also supports traversing via multiple edge types with GO . The syntax is: GO FROM <node_list> OVER <edge_type_list | *> YIELD [DISTINCT] <return_list> For example: nebula> GO OVER FROM <node_list> edge1, edge2.... // traverse alone edge1 and edge2 or nebula> GO OVER FROM <node_list> * // * indicates traversing along all edge types Please note that when traversing along multiple edges, there are some special restrictions on the use of filters(namely the WHERE statement), for example filters like WHERE edge1.prop1 > edge2.prop2 is not supported. As for return results, if multiple edge properties are to be returned, Nebula Graph will place them in different rows. For example: nebula> GO FROM 100 OVER follow, serve YIELD follow.degree, serve.start_year; The following result is returned: ==================================== | follow.degree | serve.start_year | ==================================== | 0 | 1997 | ------------------------------------ | 95 | 0 | ------------------------------------ | 89 | 0 | ------------------------------------ | 90 | 0 | ------------------------------------ If there is no property, the default value will be placed. The default value for numeric type is 0, and for string type is an empty string, for bool is false, for timestamp is 0 (namely \u201c1970-01-01 00:00:00\u201d) and for double is 0.0. Of course, you can query without specifying `YIELD`, which returns the vids of the dest vertices of each edge. Again, default values (here is 0) will be placed if there is no property. For example, query `GO FROM 100 OVER follow, serve;` returns the follow lines: ============================ | follow._dst | serve._dst | ============================ | 0 | 200 | ---------------------------- | 101 | 0 | ---------------------------- | 102 | 0 | ---------------------------- | 106 | 0 | ---------------------------- For query statement GO FROM 100 OVER * , the result is similar to the above example: the non-existing property or vid is populated with default values. Please note that we can't tell which row belongs to which edge in the results. The future version will show the edge type in the result.","title":"Traverse Along Multiple Edges Types"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#traverse_reversely","text":"Currently, Nebula Graph supports traversing reversely using keyword REVERSELY . The syntax is: GO FROM <node_list> OVER <edge_type_list> REVERSELY WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> For example: nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._src; -- returns 100 nebula> GO FROM 100 OVER follow REVERSELY YIELD follow._dst AS id | \\ GO FROM $-.id OVER serve WHERE $^.player.age > 20 YIELD $^.player.name AS FriendOf, $$.team.name AS Team; ============================ | FriendOf | Team | ============================ | Tony Parker | Warriors | ---------------------------- | Kyle Anderson | Warriors | ---------------------------- The above query first traverses players that follow player 100 and finds the teams they serve, then filter players who are older than 20, and finally it returns their names and teams. Of course, you can query without specifying YIELD, which will return the vids of the dest vertices of each edge by default.","title":"Traverse Reversely"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/go-syntax/#traverse_bidirect","text":"Currently, Nebula Graph supports traversing along in and out edges using keyword BIDIRECT , the syntax is: GO FROM <node_list> OVER <edge_type_list> BIDIRECT WHERE (expression [ AND | OR expression ...]) YIELD [DISTINCT] <return_list> For example: nebula> GO FROM 102 OVER follow BIDIRECT; =============== | follow._dst | =============== | 101 | --------------- | 103 | --------------- | 135 | --------------- The above query returns players followed by 102 and follow 102 at the same time.","title":"Traverse Bidirect"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-edge-syntax/","text":"Insert Edge Syntax \u00b6 INSERT EDGE <edge_name> ( <prop_name_list> ) VALUES | VALUE <src_vid> -> <dst_vid>[@<ranking>] : ( <prop_value_list> ) [, <src_vid> -> <dst_vid> : ( <prop_value_list> ), ...] <prop_name_list> ::= [ <prop_name> [, <prop_name> ] ...] <prop_value_list> ::= [ <prop_value> [, <prop_value> ] ...] INSERT EDGE statement inserts a (directed) edge from a starting vertex (given by src_vid) to an ending vertex (given by dst_vid). <edge_name> denotes the edge type, which must be created before INSERT EDGE . <prop_name_list> is the property name list as the given <edge_name> . <prop_value_list> must provide the value list according to <prop_name_list> . If no value matches the type, an error will be returned. ranking is optional, it specifies the edge ranking of the same edge type, if not specified, the default value is 0. Examples \u00b6 nebula> CREATE EDGE e1() -- create edge t1 with empty property or default values nebula> INSERT EDGE e1 () VALUES 10->11:() -- insert an edge from vertex 10 to vertex 11 with empty property nebula> INSERT EDGE e1 () VALUES 10->11@1:() -- insert an edge from vertex 10 to vertex 11 with empty property, the edge ranking is 1 nebula> CREATE EDGE e2 (name string, age int) -- create edge e2 with two properties nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 1) -- insert edge from 11 to 13 with two properties nebula> INSERT EDGE e2 (name, age) VALUES \\ 12->13:(\"n1\", 1), 13->14:(\"n2\", 2) -- insert two edges nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", \"a13\") -- ERROR. \"a13\" is not int An edge can be inserted/wrote multiple times. Only the last written values can be read. -- insert edge with the new values. nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 12) nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 13) nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 14) -- the last version can be read","title":"INSERT EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-edge-syntax/#insert_edge_syntax","text":"INSERT EDGE <edge_name> ( <prop_name_list> ) VALUES | VALUE <src_vid> -> <dst_vid>[@<ranking>] : ( <prop_value_list> ) [, <src_vid> -> <dst_vid> : ( <prop_value_list> ), ...] <prop_name_list> ::= [ <prop_name> [, <prop_name> ] ...] <prop_value_list> ::= [ <prop_value> [, <prop_value> ] ...] INSERT EDGE statement inserts a (directed) edge from a starting vertex (given by src_vid) to an ending vertex (given by dst_vid). <edge_name> denotes the edge type, which must be created before INSERT EDGE . <prop_name_list> is the property name list as the given <edge_name> . <prop_value_list> must provide the value list according to <prop_name_list> . If no value matches the type, an error will be returned. ranking is optional, it specifies the edge ranking of the same edge type, if not specified, the default value is 0.","title":"Insert Edge Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-edge-syntax/#examples","text":"nebula> CREATE EDGE e1() -- create edge t1 with empty property or default values nebula> INSERT EDGE e1 () VALUES 10->11:() -- insert an edge from vertex 10 to vertex 11 with empty property nebula> INSERT EDGE e1 () VALUES 10->11@1:() -- insert an edge from vertex 10 to vertex 11 with empty property, the edge ranking is 1 nebula> CREATE EDGE e2 (name string, age int) -- create edge e2 with two properties nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 1) -- insert edge from 11 to 13 with two properties nebula> INSERT EDGE e2 (name, age) VALUES \\ 12->13:(\"n1\", 1), 13->14:(\"n2\", 2) -- insert two edges nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", \"a13\") -- ERROR. \"a13\" is not int An edge can be inserted/wrote multiple times. Only the last written values can be read. -- insert edge with the new values. nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 12) nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 13) nebula> INSERT EDGE e2 (name, age) VALUES 11->13:(\"n1\", 14) -- the last version can be read","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-vertex-syntax/","text":"Insert Vertex Syntax \u00b6 INSERT VERTEX <tag_name> [, <tag_name>, ...] (prop_name_list[, prop_name_list]) {VALUES | VALUE} vid: (prop_value_list[, prop_value_list]) prop_name_list: [prop_name [, prop_name] ...] prop_value_list: [prop_value [, prop_value] ...] INSERT VERTEX statement inserts one vertex into Nebula Graph . tag_name denotes the tag (vertex type), which must be created before INSERT VERTEX . prop_name_list is the property name list in the given tag_name . prop_value_list must provide the value list according to the prop_name_list . If no value matches the type, an error will be returned. Examples \u00b6 nebula> CREATE TAG t1() -- create tag t1 with empty property nebula> INSERT VERTEX t1 () VALUES 10:() -- insert vertex 10 with no property nebula> CREATE TAG t2 (name string, age int) -- create tag t2 with two properties nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n1\", 12) -- insert vertex 11 with two properties nebula> INSERT VERTEX t2 (name, age) VALUES 12:(\"n1\", \"a13\") -- ERROR. \"a13\" is not int nebula> INSERT VERTEX t2 (name, age) VALUES 13:(\"n3\", 12), 14:(\"n4\", 8) -- insert two vertices nebula> CREATE TAG t1(i1 int) nebula> CREATE TAG t2(s2 string) nebula> INSERT VERTEX t1 (i1), t2(s2) VALUES 21: (321, \"hello\") -- insert vertex 21 with two tags. A vertex can be inserted/wrote multiple times. Only the last written values can be read. -- insert vertex 11 with the new values. nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n2\", 13) nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n3\", 14) nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n4\", 15) -- the last version can be read","title":"INSERT VERTEX Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-vertex-syntax/#insert_vertex_syntax","text":"INSERT VERTEX <tag_name> [, <tag_name>, ...] (prop_name_list[, prop_name_list]) {VALUES | VALUE} vid: (prop_value_list[, prop_value_list]) prop_name_list: [prop_name [, prop_name] ...] prop_value_list: [prop_value [, prop_value] ...] INSERT VERTEX statement inserts one vertex into Nebula Graph . tag_name denotes the tag (vertex type), which must be created before INSERT VERTEX . prop_name_list is the property name list in the given tag_name . prop_value_list must provide the value list according to the prop_name_list . If no value matches the type, an error will be returned.","title":"Insert Vertex Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/insert-vertex-syntax/#examples","text":"nebula> CREATE TAG t1() -- create tag t1 with empty property nebula> INSERT VERTEX t1 () VALUES 10:() -- insert vertex 10 with no property nebula> CREATE TAG t2 (name string, age int) -- create tag t2 with two properties nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n1\", 12) -- insert vertex 11 with two properties nebula> INSERT VERTEX t2 (name, age) VALUES 12:(\"n1\", \"a13\") -- ERROR. \"a13\" is not int nebula> INSERT VERTEX t2 (name, age) VALUES 13:(\"n3\", 12), 14:(\"n4\", 8) -- insert two vertices nebula> CREATE TAG t1(i1 int) nebula> CREATE TAG t2(s2 string) nebula> INSERT VERTEX t1 (i1), t2(s2) VALUES 21: (321, \"hello\") -- insert vertex 21 with two tags. A vertex can be inserted/wrote multiple times. Only the last written values can be read. -- insert vertex 11 with the new values. nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n2\", 13) nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n3\", 14) nebula> INSERT VERTEX t2 (name, age) VALUES 11:(\"n4\", 15) -- the last version can be read","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/","text":"Lookup Syntax \u00b6 The LOOKUP statement is used to search for the filter condition in it. LOOKUP is often coupled with a WHERE clause which adds filters or predicates. Note: Before using the LOOKUP statement, please make sure that indexes are created. Read more about indexes in Index Documentation . LOOKUP ON {<vertex_tag> | <edge_type>} WHERE <expression> [ AND | OR expression ...]) ] [YIELD <return_list>] <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] LOOKUP clause finds the vertices or edges. WHERE extracts only those results that fulfill the specified conditions. The logical AND, OR, NOT are also supported. See WHERE Syntax for more information. Note: WHERE clause does not support the following operations in LOOKUP : $- and $^ In relational expressions, expressions with field-names on both sides of the operator are not currently supported, such as (tagName.column1> tagName.column2) Nested AliasProp expressions in operation expressions and function expressions are not supported at this time. YIELD clause returns particular results. If not specified, vertex ID is returned when LOOKUP tags, source vertex ID, dest vertex ID and ranking of the edges are returned when LOOKUP edges. Retrieve Vertices \u00b6 The following example returns vertices whose name is Tony Parker and tagged with player . nebula> CREATE TAG INDEX index_player ON player(name, age); nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\"; ============ | VertexID | ============ | 101 | ------------ nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\" \\ YIELD player.name, player.age; ======================================= | VertexID | player.name | player.age | ======================================= | 101 | Tony Parker | 36 | --------------------------------------- nebula> LOOKUP ON player WHERE player.name== \"Kobe Bryant\" YIELD player.name AS name | \\ GO FROM $-.VertexID OVER serve YIELD $-.name, serve.start_year, serve.end_year, $$.team.name; ================================================================== | $-.name | serve.start_year | serve.end_year | $$.team.name | ================================================================== | Kobe Bryant | 1996 | 2016 | Lakers | ------------------------------------------------------------------ Retrieve Edges \u00b6 The following example returns edges whose degree is 90 and the edge type is follow . nebula> CREATE EDGE INDEX index_follow ON follow(degree); nebula> LOOKUP ON follow WHERE follow.degree == 90; ============================= | SrcVID | DstVID | Ranking | ============================= | 100 | 106 | 0 | ----------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 90 YIELD follow.degree; ============================================= | SrcVID | DstVID | Ranking | follow.degree | ============================================= | 100 | 106 | 0 | 90 | --------------------------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 60 YIELD follow.degree AS Degree | \\ GO FROM $-.DstVID OVER serve YIELD $-.DstVID, serve.start_year, serve.end_year, $$.team.name; ================================================================ | $-.DstVID | serve.start_year | serve.end_year | $$.team.name | ================================================================ | 105 | 2010 | 2018 | Spurs | ---------------------------------------------------------------- | 105 | 2009 | 2010 | Cavaliers | ---------------------------------------------------------------- | 105 | 2018 | 2019 | Raptors | ----------------------------------------------------------------","title":"LOOK UP Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/#lookup_syntax","text":"The LOOKUP statement is used to search for the filter condition in it. LOOKUP is often coupled with a WHERE clause which adds filters or predicates. Note: Before using the LOOKUP statement, please make sure that indexes are created. Read more about indexes in Index Documentation . LOOKUP ON {<vertex_tag> | <edge_type>} WHERE <expression> [ AND | OR expression ...]) ] [YIELD <return_list>] <return_list> <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] LOOKUP clause finds the vertices or edges. WHERE extracts only those results that fulfill the specified conditions. The logical AND, OR, NOT are also supported. See WHERE Syntax for more information. Note: WHERE clause does not support the following operations in LOOKUP : $- and $^ In relational expressions, expressions with field-names on both sides of the operator are not currently supported, such as (tagName.column1> tagName.column2) Nested AliasProp expressions in operation expressions and function expressions are not supported at this time. YIELD clause returns particular results. If not specified, vertex ID is returned when LOOKUP tags, source vertex ID, dest vertex ID and ranking of the edges are returned when LOOKUP edges.","title":"Lookup Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/#retrieve_vertices","text":"The following example returns vertices whose name is Tony Parker and tagged with player . nebula> CREATE TAG INDEX index_player ON player(name, age); nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\"; ============ | VertexID | ============ | 101 | ------------ nebula> LOOKUP ON player WHERE player.name == \"Tony Parker\" \\ YIELD player.name, player.age; ======================================= | VertexID | player.name | player.age | ======================================= | 101 | Tony Parker | 36 | --------------------------------------- nebula> LOOKUP ON player WHERE player.name== \"Kobe Bryant\" YIELD player.name AS name | \\ GO FROM $-.VertexID OVER serve YIELD $-.name, serve.start_year, serve.end_year, $$.team.name; ================================================================== | $-.name | serve.start_year | serve.end_year | $$.team.name | ================================================================== | Kobe Bryant | 1996 | 2016 | Lakers | ------------------------------------------------------------------","title":"Retrieve Vertices"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/lookup-syntax/#retrieve_edges","text":"The following example returns edges whose degree is 90 and the edge type is follow . nebula> CREATE EDGE INDEX index_follow ON follow(degree); nebula> LOOKUP ON follow WHERE follow.degree == 90; ============================= | SrcVID | DstVID | Ranking | ============================= | 100 | 106 | 0 | ----------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 90 YIELD follow.degree; ============================================= | SrcVID | DstVID | Ranking | follow.degree | ============================================= | 100 | 106 | 0 | 90 | --------------------------------------------- nebula> LOOKUP ON follow WHERE follow.degree == 60 YIELD follow.degree AS Degree | \\ GO FROM $-.DstVID OVER serve YIELD $-.DstVID, serve.start_year, serve.end_year, $$.team.name; ================================================================ | $-.DstVID | serve.start_year | serve.end_year | $$.team.name | ================================================================ | 105 | 2010 | 2018 | Spurs | ---------------------------------------------------------------- | 105 | 2009 | 2010 | Cavaliers | ---------------------------------------------------------------- | 105 | 2018 | 2019 | Raptors | ----------------------------------------------------------------","title":"Retrieve Edges"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/return-syntax/","text":"Return Syntax \u00b6 The RETURN statement is used to return the result when the condition is true. If the condition is false, no result is returned. RETURN <var_ref> IF <var_ref> IS NOT NULL is a variable name, e.g. $var . Examples \u00b6 nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 101; \\ RETURN $rA IF $rA is NOT NULL; \\ /* Returns the result because $rA is not empty */ GO FROM $A.dst OVER follow; /* As the RETURN statement returns the result, the GO FROM statement is not executed*/ ========== | $A.dst | ========== | 101 | ---------- nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 300; \\ RETURN $rA IF $rA is NOT NULL; \\ /* Does not return the result because $rA is empty */ GO FROM $A.dst OVER follow; /* As the RETURN statement does not return the result, the GO FROM statement is executed */ =============== | follow._dst | =============== | 100 | --------------- | 101 | --------------- | 100 | --------------- | 102 | --------------- | 100 | --------------- | 107 | ---------------","title":"RETURN Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/return-syntax/#return_syntax","text":"The RETURN statement is used to return the result when the condition is true. If the condition is false, no result is returned. RETURN <var_ref> IF <var_ref> IS NOT NULL is a variable name, e.g. $var .","title":"Return Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/return-syntax/#examples","text":"nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 101; \\ RETURN $rA IF $rA is NOT NULL; \\ /* Returns the result because $rA is not empty */ GO FROM $A.dst OVER follow; /* As the RETURN statement returns the result, the GO FROM statement is not executed*/ ========== | $A.dst | ========== | 101 | ---------- nebula> $A = GO FROM 100 OVER follow YIELD follow._dst AS dst; \\ $rA = YIELD $A.* WHERE $A.dst == 300; \\ RETURN $rA IF $rA is NOT NULL; \\ /* Does not return the result because $rA is empty */ GO FROM $A.dst OVER follow; /* As the RETURN statement does not return the result, the GO FROM statement is executed */ =============== | follow._dst | =============== | 100 | --------------- | 101 | --------------- | 100 | --------------- | 102 | --------------- | 100 | --------------- | 107 | ---------------","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/","text":"Update Syntax \u00b6 Nebula Graph supports UPDATE properties of a vertex or an edge, as well as CAS operation and returning related properties. Update Vertex \u00b6 UPDATE VERTEX <vid> SET <update_columns> [WHEN <condition>] [YIELD <columns>] NOTE: WHEN and YIELD are optional. vid is the id of the vertex to be updated. update_columns is the properties of the vertex to be updated, for example, tag1.col1 = $^.tag2.col2 + 1 means to update tag1.col1 to tag2.col2+1 . NOTE: $^ indicates vertex to be updated. condition is some constraints, only when met, UPDATE will run successfully and expression operations are supported. columns is the columns to be returned, YIELD returns the latest updated values. Consider the following example: nebula> UPDATE VERTEX 101 SET player.age = $^.player.age + 1 \\ WHEN $^.player.name == \"Tony Parker\" \\ YIELD $^.player.name AS name, $^.player.age AS age; There are one tag in vertex 101, namely player. Update Edge \u00b6 UPDATE EDGE <edge> SET <update_columns> [WHEN <condition>] [YIELD <columns>] NOTE: WHEN and YIELD are optional. edge is the edge to be updated, the syntax is <src> -> <dst> [@ranking] OF <edge_type> . update_columns is the properties of the edge to be updated. condition is some constraints, only when met, UPDATE will run successfully and expression operations are supported. columns is the columns to be returned, YIELD returns the latest updated values. Consider the following example: nebula> UPDATE EDGE 100 -> 200@0 OF serve SET start_year = serve.start_year + 1 \\ YIELD $^.player.name AS name, serve.start_year AS start;","title":"UPDATE VERTEX EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/#update_syntax","text":"Nebula Graph supports UPDATE properties of a vertex or an edge, as well as CAS operation and returning related properties.","title":"Update Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/#update_vertex","text":"UPDATE VERTEX <vid> SET <update_columns> [WHEN <condition>] [YIELD <columns>] NOTE: WHEN and YIELD are optional. vid is the id of the vertex to be updated. update_columns is the properties of the vertex to be updated, for example, tag1.col1 = $^.tag2.col2 + 1 means to update tag1.col1 to tag2.col2+1 . NOTE: $^ indicates vertex to be updated. condition is some constraints, only when met, UPDATE will run successfully and expression operations are supported. columns is the columns to be returned, YIELD returns the latest updated values. Consider the following example: nebula> UPDATE VERTEX 101 SET player.age = $^.player.age + 1 \\ WHEN $^.player.name == \"Tony Parker\" \\ YIELD $^.player.name AS name, $^.player.age AS age; There are one tag in vertex 101, namely player.","title":"Update Vertex"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/update-vertex-edge-syntax/#update_edge","text":"UPDATE EDGE <edge> SET <update_columns> [WHEN <condition>] [YIELD <columns>] NOTE: WHEN and YIELD are optional. edge is the edge to be updated, the syntax is <src> -> <dst> [@ranking] OF <edge_type> . update_columns is the properties of the edge to be updated. condition is some constraints, only when met, UPDATE will run successfully and expression operations are supported. columns is the columns to be returned, YIELD returns the latest updated values. Consider the following example: nebula> UPDATE EDGE 100 -> 200@0 OF serve SET start_year = serve.start_year + 1 \\ YIELD $^.player.name AS name, serve.start_year AS start;","title":"Update Edge"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/upsert-syntax/","text":"Upsert Syntax \u00b6 UPSERT is used to insert a new vertex or edge or update an existing one. If the vertex or edge doesn\u2019t exist it will be created. UPSERT is a combination of INSERT and UPDATE . If the vertex or edge does not exist, a new one will be created regardless of whether the condition in WHEN clause is met; If the vertex or edge exists and the WHEN condition is met, the vertex or edge will be updated; If the vertex or edge exists and the WHEN condition is not met, nothing will be done. UPSERT {VERTEX <vid> | EDGE <edge>} SET <update_columns> [WHEN <condition>] [YIELD <columns>] vid is the ID of the vertex to be updated. edge is the edge to be updated, the syntax is <src> -> <dst> [@ranking] OF <edge_type> . update_columns is the properties of the vertex or edge to be updated, for example, tag1.col1 = $^.tag2.col2 + 1 means to update tag1.col1 to tag2.col2+1 . NOTE: $^ indicates vertex to be updated. condition is some constraints, only when met, UPSERT will run successfully and expression operations are supported. columns is the columns to be returned, YIELD returns the latest updated values. Consider the following example: nebula> INSERT VERTEX player(name, age) VALUES 111:(\"Ben Simmons\", 22); -- Insert a new vertex. nebula> UPSERT VERTEX 111 SET player.name = \"Dwight Howard\", player.age = $^.player.age + 11 WHEN $^.player.name == \"Ben Simmons\" && $^.player.age > 20 YIELD $^.player.name AS Name, $^.player.age AS Age; -- Do upsert on the vertex. ======================= | Name | Age | ======================= | Dwight Howard | 33 | -----------------------","title":"UPSERT Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/upsert-syntax/#upsert_syntax","text":"UPSERT is used to insert a new vertex or edge or update an existing one. If the vertex or edge doesn\u2019t exist it will be created. UPSERT is a combination of INSERT and UPDATE . If the vertex or edge does not exist, a new one will be created regardless of whether the condition in WHEN clause is met; If the vertex or edge exists and the WHEN condition is met, the vertex or edge will be updated; If the vertex or edge exists and the WHEN condition is not met, nothing will be done. UPSERT {VERTEX <vid> | EDGE <edge>} SET <update_columns> [WHEN <condition>] [YIELD <columns>] vid is the ID of the vertex to be updated. edge is the edge to be updated, the syntax is <src> -> <dst> [@ranking] OF <edge_type> . update_columns is the properties of the vertex or edge to be updated, for example, tag1.col1 = $^.tag2.col2 + 1 means to update tag1.col1 to tag2.col2+1 . NOTE: $^ indicates vertex to be updated. condition is some constraints, only when met, UPSERT will run successfully and expression operations are supported. columns is the columns to be returned, YIELD returns the latest updated values. Consider the following example: nebula> INSERT VERTEX player(name, age) VALUES 111:(\"Ben Simmons\", 22); -- Insert a new vertex. nebula> UPSERT VERTEX 111 SET player.name = \"Dwight Howard\", player.age = $^.player.age + 11 WHEN $^.player.name == \"Ben Simmons\" && $^.player.age > 20 YIELD $^.player.name AS Name, $^.player.age AS Age; -- Do upsert on the vertex. ======================= | Name | Age | ======================= | Dwight Howard | 33 | -----------------------","title":"Upsert Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/where-syntax/","text":"Where Syntax \u00b6 Currently, the WHERE statement only applies to the GO statement. WHERE <expression> [ AND | OR <expression> ...]) Usually, WHERE is a set of logical combination that filters vertex or edge properties. As syntactic sugar, logic AND is represented by AND or && and logic OR is represented by OR or || . Examples \u00b6 -- the degree property of edge follow is greater than 90. nebula> GO FROM 100 OVER follow WHERE follow.degree > 90; -- the following result is returned: =============== | follow._dst | =============== | 101 | --------------- -- find the dest vertex whose age is equal to the source vertex, player 104. nebula> GO FROM 104 OVER follow WHERE $^.player.age == $$.player.age; -- the following result is returned: =============== | follow._dst | =============== | 103 | --------------- -- logical combination is allowed. nebula> GO FROM 100 OVER follow WHERE follow.degree > 90 OR $$.player.age != 33 AND $$.player.name != \"Tony Parker\"; -- the following result is returned: =============== | follow._dst | =============== | 101 | --------------- | 106 | --------------- -- the condition in the WHERE clause is always TRUE. nebula> GO FROM 101 OVER follow WHERE 1 == 1 OR TRUE; -- the following result is returned: =============== | follow._dst | =============== | 100 | --------------- | 102 | ---------------","title":"WHERE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/where-syntax/#where_syntax","text":"Currently, the WHERE statement only applies to the GO statement. WHERE <expression> [ AND | OR <expression> ...]) Usually, WHERE is a set of logical combination that filters vertex or edge properties. As syntactic sugar, logic AND is represented by AND or && and logic OR is represented by OR or || .","title":"Where Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/where-syntax/#examples","text":"-- the degree property of edge follow is greater than 90. nebula> GO FROM 100 OVER follow WHERE follow.degree > 90; -- the following result is returned: =============== | follow._dst | =============== | 101 | --------------- -- find the dest vertex whose age is equal to the source vertex, player 104. nebula> GO FROM 104 OVER follow WHERE $^.player.age == $$.player.age; -- the following result is returned: =============== | follow._dst | =============== | 103 | --------------- -- logical combination is allowed. nebula> GO FROM 100 OVER follow WHERE follow.degree > 90 OR $$.player.age != 33 AND $$.player.name != \"Tony Parker\"; -- the following result is returned: =============== | follow._dst | =============== | 101 | --------------- | 106 | --------------- -- the condition in the WHERE clause is always TRUE. nebula> GO FROM 101 OVER follow WHERE 1 == 1 OR TRUE; -- the following result is returned: =============== | follow._dst | =============== | 100 | --------------- | 102 | ---------------","title":"Examples"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/","text":"Yield Clause and Statement \u00b6 Keyword YIELD can be used as a clause in a FETCH or GO statement, or as a separate statement in PIPE ( | ), or as a stand-alone statement for calculation. As Clause (With GO-Syntax) \u00b6 YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] YIELD is commonly used to return results generated with GO (Refer GO ). nebula> GO FROM 100 OVER follow YIELD $$.player.name AS Friend, $$.player.age AS Age; =========================== | Friend | Age | =========================== | Tony Parker | 36 | --------------------------- | LaMarcus Aldridge | 33 | --------------------------- | Kyle Anderson | 25 | --------------------------- For example: $$.player.name is used to get the property of the dest vertex ($$). As Statement \u00b6 Reference Inputs or Variables \u00b6 You can use the YIELD statement in PIPE . You can use the YIELD statement to reference variables. For statements that do not support YIELD statement, you can use it as a tool to control the output. YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [WHERE <conditions>] nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | YIELD $-.* WHERE $-.id == 106; ========= | $-.id | ========= | 106 | --------- nebula> $var1 = GO FROM 101 OVER follow; $var2 = GO FROM 105 OVER follow; YIELD $var1.* UNION YIELD $var2.*; ===================== | $var1.follow._dst | ===================== | 100 | --------------------- | 102 | --------------------- | 104 | --------------------- | 110 | --------------------- As Stand-alone Statement \u00b6 YIELD statement can be used independently to retrieve computation results without reference to any graph. You can use AS to rename it an alias. nebula> YIELD 1 + 1; ========= | (1+1) | ========= | 2 | --------- nebula> YIELD \"Hel\" + \"\\tlo\" AS HELLO_1, \", World!\" AS WORLD_2; ====================== | HELLO_1 | WORLD_2 | ====================== | Hel lo | , World! | ---------------------- nebula> YIELD hash(\"Tim\") % 100; ===================== | (hash(\"Tim\")%100) | ===================== | 42 | --------------------- Note: You can not use YIELD DISTINCT as a stand-alone statement. The following is a syntax error. nebula> YIELD DISTINCT 1 --- syntax error!","title":"YIELD Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#yield_clause_and_statement","text":"Keyword YIELD can be used as a clause in a FETCH or GO statement, or as a separate statement in PIPE ( | ), or as a stand-alone statement for calculation.","title":"Yield Clause and Statement"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#as_clause_with_go-syntax","text":"YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] YIELD is commonly used to return results generated with GO (Refer GO ). nebula> GO FROM 100 OVER follow YIELD $$.player.name AS Friend, $$.player.age AS Age; =========================== | Friend | Age | =========================== | Tony Parker | 36 | --------------------------- | LaMarcus Aldridge | 33 | --------------------------- | Kyle Anderson | 25 | --------------------------- For example: $$.player.name is used to get the property of the dest vertex ($$).","title":"As Clause (With GO-Syntax)"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#as_statement","text":"","title":"As Statement"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#reference_inputs_or_variables","text":"You can use the YIELD statement in PIPE . You can use the YIELD statement to reference variables. For statements that do not support YIELD statement, you can use it as a tool to control the output. YIELD [DISTINCT] <col_name> [AS <col_alias>] [, <col_name> [AS <col_alias>] ...] [WHERE <conditions>] nebula> GO FROM 100 OVER follow YIELD follow._dst AS id | YIELD $-.* WHERE $-.id == 106; ========= | $-.id | ========= | 106 | --------- nebula> $var1 = GO FROM 101 OVER follow; $var2 = GO FROM 105 OVER follow; YIELD $var1.* UNION YIELD $var2.*; ===================== | $var1.follow._dst | ===================== | 100 | --------------------- | 102 | --------------------- | 104 | --------------------- | 110 | ---------------------","title":"Reference Inputs or Variables"},{"location":"manual-EN/2.query-language/4.statement-syntax/2.data-query-and-manipulation-statements/yield-syntax/#as_stand-alone_statement","text":"YIELD statement can be used independently to retrieve computation results without reference to any graph. You can use AS to rename it an alias. nebula> YIELD 1 + 1; ========= | (1+1) | ========= | 2 | --------- nebula> YIELD \"Hel\" + \"\\tlo\" AS HELLO_1, \", World!\" AS WORLD_2; ====================== | HELLO_1 | WORLD_2 | ====================== | Hel lo | , World! | ---------------------- nebula> YIELD hash(\"Tim\") % 100; ===================== | (hash(\"Tim\")%100) | ===================== | 42 | --------------------- Note: You can not use YIELD DISTINCT as a stand-alone statement. The following is a syntax error. nebula> YIELD DISTINCT 1 --- syntax error!","title":"As Stand-alone Statement"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/describe-syntax/","text":"Describe Syntax \u00b6 DESCRIBE SPACE <space_name> DESCRIBE TAG <tag_name> DESCRIBE EDGE <edge_name> DESCRIBE {TAG | EDGE} INDEX <index_name> The DESCRIBE keyword is used to obtain information about space, tag and edge structure. Also notice that DESCRIBE is different from SHOW. Refer SHOW . Example \u00b6 Obtain information about space. nebula> DESCRIBE SPACE nba; ======================================================== | ID | Name | Partition number | Replica Factor | ======================================================== | 1 | nba | 100 | 1 | -------------------------------------------------------- Obtain information about tag in a given space. nebula> DESCRIBE TAG player; ================================================== | Field | Type | Null | Key | Default | Extra | ================================================== | name | string | false | | | | -------------------------------------------------- | age | int | false | | | | -------------------------------------------------- Obtain information about edge in a given space. nebula> DESCRIBE EDGE serve; ====================================================== | Field | Type | Null | Key | Default | Extra | ====================================================== | start_year | int | false | | | | ------------------------------------------------------ | end_year | int | false | | | | ------------------------------------------------------ Obtain information about the index. nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------","title":"DESCRIBE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/describe-syntax/#describe_syntax","text":"DESCRIBE SPACE <space_name> DESCRIBE TAG <tag_name> DESCRIBE EDGE <edge_name> DESCRIBE {TAG | EDGE} INDEX <index_name> The DESCRIBE keyword is used to obtain information about space, tag and edge structure. Also notice that DESCRIBE is different from SHOW. Refer SHOW .","title":"Describe Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/describe-syntax/#example","text":"Obtain information about space. nebula> DESCRIBE SPACE nba; ======================================================== | ID | Name | Partition number | Replica Factor | ======================================================== | 1 | nba | 100 | 1 | -------------------------------------------------------- Obtain information about tag in a given space. nebula> DESCRIBE TAG player; ================================================== | Field | Type | Null | Key | Default | Extra | ================================================== | name | string | false | | | | -------------------------------------------------- | age | int | false | | | | -------------------------------------------------- Obtain information about edge in a given space. nebula> DESCRIBE EDGE serve; ====================================================== | Field | Type | Null | Key | Default | Extra | ====================================================== | start_year | int | false | | | | ------------------------------------------------------ | end_year | int | false | | | | ------------------------------------------------------ Obtain information about the index. nebula> DESCRIBE TAG INDEX player_index_0; ================== | Field | Type | ================== | name | string | ------------------","title":"Example"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/use-syntax/","text":"Use Syntax \u00b6 USE <graph_space_name> The USE statement tells Nebula Graph to use the named (graph) space as the current working space for subsequent statements. This statement requires some privileges. The named space remains the default until the end of the session or another USE statement is issued: nebula> USE space1; -- Traverse in graph space1. nebula> GO FROM 1 OVER edge1; nebula> USE space2; -- Traverse in graph space2. These vertices and edges have no relevance with space1. nebula> GO FROM 2 OVER edge2; -- Now you are back to space1. Hereafter, you can not read any data from space2. nebula> USE space1; Different from SQL, making a space as the working space prevents you from accessing other spaces. The only way to traverse in a new graph space is to switch by the USE statement. SPACES are FULLY ISOLATED from each other. Unlike SQL, which allows you to select two tables from different databases in one statement, in Nebula Graph , you can only touch one space at a time.","title":"USE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/use-syntax/#use_syntax","text":"USE <graph_space_name> The USE statement tells Nebula Graph to use the named (graph) space as the current working space for subsequent statements. This statement requires some privileges. The named space remains the default until the end of the session or another USE statement is issued: nebula> USE space1; -- Traverse in graph space1. nebula> GO FROM 1 OVER edge1; nebula> USE space2; -- Traverse in graph space2. These vertices and edges have no relevance with space1. nebula> GO FROM 2 OVER edge2; -- Now you are back to space1. Hereafter, you can not read any data from space2. nebula> USE space1; Different from SQL, making a space as the working space prevents you from accessing other spaces. The only way to traverse in a new graph space is to switch by the USE statement. SPACES are FULLY ISOLATED from each other. Unlike SQL, which allows you to select two tables from different databases in one statement, in Nebula Graph , you can only touch one space at a time.","title":"Use Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-charset-syntax/","text":"SHOW CHARSET Syntax \u00b6 SHOW CHARSET SHOW CHARSET displays the available character sets. Currently available types are: utf8 and utf8mb4. The default charset type is utf8. Nebula Graph extends the uft8 to support four byte characters. Therefore utf8 and utf8mb4 equivalent. nebula> SHOW CHARSET; ======================================================== | Charset | Description | Default collation | Maxlen | ======================================================== | utf8 | UTF-8 Unicode | utf8_bin | 4 | -------------------------------------------------------- SHOW CHARSET output has these columns: Charset The character set name. Description A description of the character set. Default collation The default collation for the character set. Maxlen The maximum number of bytes required to store one character.","title":"SHOW CHARSET Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-charset-syntax/#show_charset_syntax","text":"SHOW CHARSET SHOW CHARSET displays the available character sets. Currently available types are: utf8 and utf8mb4. The default charset type is utf8. Nebula Graph extends the uft8 to support four byte characters. Therefore utf8 and utf8mb4 equivalent. nebula> SHOW CHARSET; ======================================================== | Charset | Description | Default collation | Maxlen | ======================================================== | utf8 | UTF-8 Unicode | utf8_bin | 4 | -------------------------------------------------------- SHOW CHARSET output has these columns: Charset The character set name. Description A description of the character set. Default collation The default collation for the character set. Maxlen The maximum number of bytes required to store one character.","title":"SHOW CHARSET Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-collation-syntax/","text":"SHOW COLLATION Syntax \u00b6 SHOW COLLATION SHOW COLLATION displays the collations supported by Nebula Graph . Currently available types are: utf8_bin, utf8_general_ci, utf8mb4_bin and utf8mb4_general_ci. When the character set is utf8, the default collate is utf8_bin; when the character set is utf8mb4, the default collate is utf8mb4_bin. Both utf8_general_ci and utf8mb4_general_ci are case-insensitive comparisons and behave the same as MySQL. nebula> SHOW COLLATION; ======================= | Collation | Charset | ======================= | utf8_bin | utf8 | ----------------------- SHOW COLLATION output has these columns: Collation The collation name. Charset The name of the character set with which the collation is associated.","title":"SHOW COLLATION Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-collation-syntax/#show_collation_syntax","text":"SHOW COLLATION SHOW COLLATION displays the collations supported by Nebula Graph . Currently available types are: utf8_bin, utf8_general_ci, utf8mb4_bin and utf8mb4_general_ci. When the character set is utf8, the default collate is utf8_bin; when the character set is utf8mb4, the default collate is utf8mb4_bin. Both utf8_general_ci and utf8mb4_general_ci are case-insensitive comparisons and behave the same as MySQL. nebula> SHOW COLLATION; ======================= | Collation | Charset | ======================= | utf8_bin | utf8 | ----------------------- SHOW COLLATION output has these columns: Collation The collation name. Charset The name of the character set with which the collation is associated.","title":"SHOW COLLATION Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-configs-syntax/","text":"SHOW CONFIGS Syntax \u00b6 SHOW CONFIGS [graph|meta|storage] SHOW CONFIGS lists the configuration information. SHOW CONFIGS output has these columns: module, name, type, mode and value. For more information about SHOW CONFIGS [graph|meta|storage] , please refer to configs syntax .","title":"SHOW CONFIGS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-configs-syntax/#show_configs_syntax","text":"SHOW CONFIGS [graph|meta|storage] SHOW CONFIGS lists the configuration information. SHOW CONFIGS output has these columns: module, name, type, mode and value. For more information about SHOW CONFIGS [graph|meta|storage] , please refer to configs syntax .","title":"SHOW CONFIGS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-space-syntax/","text":"SHOW CREATE SPACE Syntax \u00b6 SHOW CREATE SPACE <space_name> SHOW CREATE SPACE statement returns the specified graph space and its creation syntax. If the graph space contains a default value, the default value is also returned.","title":"SHOW CREATE SPACE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-space-syntax/#show_create_space_syntax","text":"SHOW CREATE SPACE <space_name> SHOW CREATE SPACE statement returns the specified graph space and its creation syntax. If the graph space contains a default value, the default value is also returned.","title":"SHOW CREATE SPACE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-tag-edge-syntax/","text":"SHOW CREATE TAGS/EDGES Syntax \u00b6 SHOW CREATE {TAG <tag_name> | EDGE <edge_name>} SHOW CREATE TAG and SHOW CREATE EDGE return the specified tag or edge type and their creation syntax in a given space. If the tag or edge type contains a default value, the default value is also returned.","title":"SHOW CREATE TAG EDGE Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-create-tag-edge-syntax/#show_create_tagsedges_syntax","text":"SHOW CREATE {TAG <tag_name> | EDGE <edge_name>} SHOW CREATE TAG and SHOW CREATE EDGE return the specified tag or edge type and their creation syntax in a given space. If the tag or edge type contains a default value, the default value is also returned.","title":"SHOW CREATE TAGS/EDGES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-hosts-syntax/","text":"SHOW HOSTS Syntax \u00b6 SHOW HOSTS SHOW HOSTS statement lists storage hosts registered by the meta server. SHOW HOSTS output has these columns:: ip, port, status (online/offline), leader count, leader distribution, partition distribution. nebula> SHOW HOSTS; ============================================================================================= | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ============================================================================================= | 172.28.2.1 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | 172.28.2.2 | 44500 | online | 2 | NBA: 1, gods: 1 | NBA: 1, gods: 1 | --------------------------------------------------------------------------------------------- | 172.28.2.3 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | Total | | | 2 | gods: 1, NBA: 1 | gods: 1, NBA: 1 | ---------------------------------------------------------------------------------------------","title":"SHOW HOSTS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-hosts-syntax/#show_hosts_syntax","text":"SHOW HOSTS SHOW HOSTS statement lists storage hosts registered by the meta server. SHOW HOSTS output has these columns:: ip, port, status (online/offline), leader count, leader distribution, partition distribution. nebula> SHOW HOSTS; ============================================================================================= | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ============================================================================================= | 172.28.2.1 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | 172.28.2.2 | 44500 | online | 2 | NBA: 1, gods: 1 | NBA: 1, gods: 1 | --------------------------------------------------------------------------------------------- | 172.28.2.3 | 44500 | online | 0 | No valid partition | No valid partition | --------------------------------------------------------------------------------------------- | Total | | | 2 | gods: 1, NBA: 1 | gods: 1, NBA: 1 | ---------------------------------------------------------------------------------------------","title":"SHOW HOSTS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-index-status/","text":"SHOW INDEX STATUS Syntax \u00b6 SHOW {TAG | EDGE} INDEX STATUS SHOW INDEX STATUS returns the defined tag/edg-type index status. For example, list the tag index status with the following command: nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------ Details on creating index refer to the Index doc.","title":"SHOW INDEX STATUS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-index-status/#show_index_status_syntax","text":"SHOW {TAG | EDGE} INDEX STATUS SHOW INDEX STATUS returns the defined tag/edg-type index status. For example, list the tag index status with the following command: nebula> SHOW TAG INDEX STATUS; ========================================== | Name | Tag Index Status | ========================================== | single_person_index | SUCCEEDED | ------------------------------------------ Details on creating index refer to the Index doc.","title":"SHOW INDEX STATUS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-indexes-syntax/","text":"SHOW INDEXES Syntax \u00b6 SHOW {TAG | EDGE} INDEXES SHOW INDEXES returns the defined tag/edg-type index information. SHOW INDEXES returns the following fields: index ID and index name.","title":"SHOW INDEXES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-indexes-syntax/#show_indexes_syntax","text":"SHOW {TAG | EDGE} INDEXES SHOW INDEXES returns the defined tag/edg-type index information. SHOW INDEXES returns the following fields: index ID and index name.","title":"SHOW INDEXES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-parts-syntax/","text":"SHOW PARTS Syntax \u00b6 SHOW PARTS <part_id> SHOW PARTS lists the partition information of the given SPACE. nebula> SHOW PARTS 1; ============================================================== | Partition ID | Leader | Peers | Losts | ============================================================== | 1 | 172.28.2.2:44500 | 172.28.2.2:44500 | | -------------------------------------------------------------- SHOW PARTS output has these columns: Partition ID Leader Peers Losts","title":"SHOW PARTS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-parts-syntax/#show_parts_syntax","text":"SHOW PARTS <part_id> SHOW PARTS lists the partition information of the given SPACE. nebula> SHOW PARTS 1; ============================================================== | Partition ID | Leader | Peers | Losts | ============================================================== | 1 | 172.28.2.2:44500 | 172.28.2.2:44500 | | -------------------------------------------------------------- SHOW PARTS output has these columns: Partition ID Leader Peers Losts","title":"SHOW PARTS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-roles-syntax/","text":"SHOW ROLES Syntax \u00b6 SHOW ROLES IN <space_name>> SHOW ROLES statement displays the roles that are assigned to a user account. SHOW ROLES output has these columns: account and role type.","title":"SHOW ROLES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-roles-syntax/#show_roles_syntax","text":"SHOW ROLES IN <space_name>> SHOW ROLES statement displays the roles that are assigned to a user account. SHOW ROLES output has these columns: account and role type.","title":"SHOW ROLES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-snapshots-syntax/","text":"SHOW SNAPSHOTS Syntax \u00b6 SHOW SNAPSHOTS SHOW SNAPSHOTS statement lists all the snapshots.","title":"SHOW SNAPSHOTS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-snapshots-syntax/#show_snapshots_syntax","text":"SHOW SNAPSHOTS SHOW SNAPSHOTS statement lists all the snapshots.","title":"SHOW SNAPSHOTS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-spaces-syntax/","text":"SHOW SPACES Syntax \u00b6 SHOW SPACES SHOW SPACES lists the SPACES on the Nebula Graph cluster.","title":"SHOW SPACES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-spaces-syntax/#show_spaces_syntax","text":"SHOW SPACES SHOW SPACES lists the SPACES on the Nebula Graph cluster.","title":"SHOW SPACES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-tags-edges-syntax/","text":"SHOW TAGS/EDGES Syntax \u00b6 SHOW {TAGS | EDGES} SHOW TAGS and SHOW EDGES return the defined tags and edge types in a given space, respectively.","title":"SHOW TAGS EDGES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-tags-edges-syntax/#show_tagsedges_syntax","text":"SHOW {TAGS | EDGES} SHOW TAGS and SHOW EDGES return the defined tags and edge types in a given space, respectively.","title":"SHOW TAGS/EDGES Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-users-syntax/","text":"SHOW USERS Syntax \u00b6 SHOW USERS SHOW USERS lists the users information. SHOW USERS output has these columns: account names.","title":"SHOW USERS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/3.utility-statements/show-statements/show-users-syntax/#show_users_syntax","text":"SHOW USERS SHOW USERS lists the users information. SHOW USERS output has these columns: account names.","title":"SHOW USERS Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/","text":"Find Path Syntax \u00b6 FIND PATH statement can be used to get the shortest path and all paths. FIND SHORTEST | ALL PATH FROM <vertex_id_list> TO <vertex_id_list> OVER <edge_type_list> [UPTO <N> STEPS] SHORTEST is the keyword to find the shortest path. ALL is the keyword to find all paths. <vertex_id_list>::=[vertex_id [, vertex_id]] is the vertex id list,multiple ids should be separated with commas, and $- and $var are supported. <edge_type_list> is the edge type list, multiple edge types should be separated with commas, and * can be referred as all edge types. <N> is hop number, and the default value is 5. Note \u00b6 When source and dest vertices are id lists, it means to find the shortest path from any source vertices to the dest vertices. There may be cycles when searching all paths. Examples \u00b6 Path is displayed as id <edge_name, ranking> id in console. nebula> FIND SHORTEST PATH FROM 100 to 200 OVER *; ============================= | _path_ | ============================= | 100 <serve,0> 200 ----------------------------- nebula>FIND ALL PATH FROM 100 to 200 OVER *; ============================================================================================================= | _path_ | ============================================================================================================= | 100 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 101 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 102 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 106 < serve,0> 200 -------------------------------------------------------------------------------------------------------------","title":"FIND PATH Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/#find_path_syntax","text":"FIND PATH statement can be used to get the shortest path and all paths. FIND SHORTEST | ALL PATH FROM <vertex_id_list> TO <vertex_id_list> OVER <edge_type_list> [UPTO <N> STEPS] SHORTEST is the keyword to find the shortest path. ALL is the keyword to find all paths. <vertex_id_list>::=[vertex_id [, vertex_id]] is the vertex id list,multiple ids should be separated with commas, and $- and $var are supported. <edge_type_list> is the edge type list, multiple edge types should be separated with commas, and * can be referred as all edge types. <N> is hop number, and the default value is 5.","title":"Find Path Syntax"},{"location":"manual-EN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/#note","text":"When source and dest vertices are id lists, it means to find the shortest path from any source vertices to the dest vertices. There may be cycles when searching all paths.","title":"Note"},{"location":"manual-EN/2.query-language/4.statement-syntax/4.graph-algorithms/find-path-syntax/#examples","text":"Path is displayed as id <edge_name, ranking> id in console. nebula> FIND SHORTEST PATH FROM 100 to 200 OVER *; ============================= | _path_ | ============================= | 100 <serve,0> 200 ----------------------------- nebula>FIND ALL PATH FROM 100 to 200 OVER *; ============================================================================================================= | _path_ | ============================================================================================================= | 100 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 101 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 102 < serve,0> 200 ------------------------------------------------------------------------------------------------------------- | 100 <follow,0> 106 < serve,0> 200 -------------------------------------------------------------------------------------------------------------","title":"Examples"},{"location":"manual-EN/3.build-develop-and-administration/0.README/","text":"Reader \u00b6 This chapter is mainly for engineers and administrators who want to build, deploy and manage the system.","title":"Reader"},{"location":"manual-EN/3.build-develop-and-administration/0.README/#reader","text":"This chapter is mainly for engineers and administrators who want to build, deploy and manage the system.","title":"Reader"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/","text":"Build From Source Code \u00b6 Overview \u00b6 We have tested building on various environments, including CentOS 6 to 8, Ubuntu 16.04 to 19.04, Fedora 28 to 30, GCC 7.1.0 to 9.2.0 and recent Clang++ and the devtoolset of Red Hat and CentOS. But due to the complexity of building environments, we still cannot guarantee that we have covered all kinds of situations. If any problem encountered, please fire an issue or open a pull request to let us know. Requirements \u00b6 CPU: x86_64 Memory: 4GB at least Disk space: 10GB at least Linux: 2.3.32 or higher, check with uname -r glibc: 2.12 or higher, check with ldd --version GCC: 7.1.0 or higher, check with g++ --version CMake: 3.5.0 or higher, check with cmake --version Access to the Internet For the time being, Nebula Graph can only run in a x86_64 box, with Linux 2.3.32+ and glibc 2.12+. Quick Steps to Build \u00b6 Installing Dependencies \u00b6 Please note that it requires root privileges to install packages. For CentOS, RedHat and Fedora users: $ yum update $ yum install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz \\ readline-devel \\ ncurses-devel \\ zlib-devel \\ gcc \\ gcc-c++ \\ cmake \\ gettext \\ curl \\ redhat-lsb-core # For CentOS 8+, RedHat 8+, and Fedora, you need to install libstdc++-static, libasan $ yum install -y libstdc++-static libasan For Debian and Ubuntu users: $ apt-get update $ apt-get install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz-utils \\ curl \\ lsb-core \\ build-essential \\ libreadline-dev \\ ncurses-dev \\ cmake \\ gettext For Arch and Gentoo users, you can definitely handle all of these on your own, right? To make sure your GCC and CMake are in the right version: $ g++ --version $ cmake --version If not, please refer to Install an Applicable CMake and Install an Applicable GCC . Cloning the Repo \u00b6 $ git clone https://github.com/vesoft-inc/nebula.git If you don't care about the commit history of the repo, and to make the cloning faster, you could perform a shallow clone: $ git clone --depth = 1 https://github.com/vesoft-inc/nebula.git Configuring and Building \u00b6 $ cd nebula $ mkdir build $ cd build $ cmake -DENABLE_TESTING = OFF -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = $PWD /install .. # Assuming cores is the number of cores and mem_gb is the memory size (in GB), the value of N is recommended to select the smaller one from cores and mem_gb / 2 # We suggest choosing release build type to speed up compilation $ make -jN $ make install $ ls install/ etc/ bin/ share/ scripts/ Since C++ templates are heavily used by Nebula Graph and its third party dependencies, especially Folly, fbthrift and boost, the building is very time-consuming. For your reference, it is expected to take about 35 minutes in CPU time(less than 4 minutes with -j16 ), given an Intel E5-2697 v3 processor and unit tests are disabled. Starting Nebula Graph Services \u00b6 After compiling and installing Nebula Graph , you can start Nebula Graph services. By default, Nebula Graph is installed in the /home/username/nebula/build/install directory, in which the username must be replaced by your username. Change your current directory to the directory where Nebula Graph is installed. $ cd /home/username/nebula/build/install Rename the configuration files for Nebula Graph services. $ cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf $ cp etc/nebula-metad.conf.default etc/nebula-metad.conf $ cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf Start Nebula Graph services. $ ./scripts/nebula.service start all Connect to Nebula Graph services. $ ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" Note : If you successfully connect to Nebula Graph services, you can see the Welcome to Nebula Graph message is displayed and automatically enter the ngql command line. Ways to Tweak the Building \u00b6 Until now, you might already have built Nebula Graph successfully. If so or not, we also provide ways to tweak the building process. CMake Arguments/Variables \u00b6 We provide several options to make one tweak the building, while some of these are builtins from CMake. These arguments are used at the configure(cmake) stage, like cmake -DArgument=Value .. . ENABLE_WERROR \u00b6 By default, Nebula Graph turns on the -Werror compiler option to regard any warnings as errors. If the building fails with such errors, you could still continue the building by set ENABLE_WERROR to OFF . ENABLE_TESTING \u00b6 This option allows to enable or disable the build of unit tests. We suggest to turn it off if you just need the service modules of Nebula Graph . Options are ON and OFF , and the default value is ON . ENABLE_ASAN \u00b6 This option enables or disables the ASan building, a.k.a AddressSanitizer, which is a memory error detector. It is meant to be used by Nebula Graph developers. This option is OFF by default. CMAKE_BUILD_TYPE \u00b6 There are a few building types supported: Debug , to build with debug info but without optimization, which is by default Release , to build with optimization but without debug info RelWithDebInfo , to build with optimization AND debug info MinSizeRel , to build with optimizations for code size CMAKE_INSTALL_PREFIX \u00b6 This option is to specify the location where the service modules, scripts, configuration files and tools are installed when make install is performed. It is set to /usr/local/nebula by default. CMAKE_CXX_COMPILER \u00b6 Normally, CMake will figure out and locate an applicable C++ compiler for us. But if your compiler installation is not at the standard location, or if you want to use a different one, you have to specify it explicitly as follows: $ cmake -DCMAKE_C_COMPILER = /path/to/gcc/bin/gcc -DCMAKE_CXX_COMPILER = /path/to/gcc/bin/g++ .. $ cmake -DCMAKE_C_COMPILER = /path/to/clang/bin/clang -DCMAKE_CXX_COMPILER = /path/to/clang/bin/clang++ .. ENABLE_CCACHE \u00b6 This option is to enable the use of ccache , which is for speeding up the compilation during daily development. By default, Nebula Graph will take advantage of ccache if it's found. So you don't have to enable it for yourself. If you want to disable ccache , it might be not enough to just turn ENABLE_CCACHE off. Since on some platforms, the ccache installation hooks up or precedes the compiler. For such a case, you have to set an environment variable export CCACHE_DISABLE=true , or add a line disable=true to ~/.ccache/ccache.conf . We may do this for you automatically in future. Please see the official documentation for more details. NEBULA_USE_LINKER \u00b6 This option allows users to use an alternative linker, e.g. gold . Options are bfd , lld and gold for now. Among them, bfd and gold belong to GNU binutils, while lld needs to install LLVM / Clang. In addition, you can use this parameter to specify the absolute path of the linker when needed. NEBULA_THIRDPARTY_ROOT \u00b6 This option is to explicitly specify the location of the third party. Installing Third Party Manually \u00b6 By default, at the configure(cmake) stage, a prebuilt third party will be downloaded and installed to the current build directory. If you would like to install it into another location for some reason, e.g. to rebuild by removing the whole build directory without downloading the third party again, you could perform the installation manually. Assume you are now at the build directory, run: # To install third party to /opt requires root privilege, you could change it to another location with --prefix. $ ../third-party/install-third-party.sh --prefix = /opt/vesoft/third-party If the third party is installed to /opt/vesoft/third-party , which is by default if no --prefix given, the building system of Nebula Graph would find it automatically. Otherwise, you need to specify the location with the CMake argument NEBULA_THIRDPARTY_ROOT as mentioned above, or set an environment variable to the location and export it. The precedence for Nebula Graph to find and choose the third party is: The CMake argument NEBULA_THIRDPARTY_ROOT third-party/install in the current build directory The NEBULA_THIRDPARTY_ROOT environment variable /opt/vesoft/third-party Install an Applicable CMake \u00b6 For users who don't have a usable CMake installation, we provide a script to automatically download and install one for you. Assuming you are now at the build directory, run: $ ../third-party/install-cmake.sh cmake-install CMake has been installed to prefix = cmake-install Run 'source cmake-install/bin/enable-cmake.sh' to make it ready to use. Run 'source cmake-install/bin/disable-cmake.sh' to disable it. $ source cmake-install/bin/enable-cmake.sh $ cmake --version cmake version 3 .15.5 Now you have an applicable CMake ready to use. At any time, you could run the command source cmake-install/bin/disable-cmake.sh to disable it. Install an Applicable GCC \u00b6 For users who don't have a usable GCC installation, we provide a prebuilt GCC and a script to automatically download and install it. Assuming you are now at the build directory, run: # To install GCC to /opt requires root privilege, you could change it to other locations $ ../third-party/install-gcc.sh --prefix = /opt GCC-7.5.0 has been installed to /opt/vesoft/toolset/gcc/7.5.0 Performing usability tests Performing regular C++14 tests...OK Performing LeakSanitizer tests...OK Run 'source /opt/vesoft/toolset/gcc/7.5.0/enable' to start using. Run 'source /opt/vesoft/toolset/gcc/7.5.0/disable' to stop using. # Please note that the path and specific version might be different from your environment $ source /opt/vesoft/toolset/gcc/7.5.0/enable # Only PATH was setup so as not to pollute your library path # You could run 'export LD_LIBRARY_PATH=/opt/vesoft/toolset/gcc/7.5.0/lib64:$LD_LIBRARY_PATH' if needed $ g++ --version g++ ( Nebula Graph Build ) 7 .5.0 Copyright ( C ) 2017 Free Software Foundation, Inc. Now you have an applicable GCC compiler ready to use. At any time, you could run the command source /opt/vesoft/toolset/gcc/7.5.0/disable to disable it. FAQ \u00b6 error: invalid argument type 'auto' to unary expression \u00b6 This error happens when building with Clang 9.0, as shown below: [ 5 % ] Building CXX object src/common/fs/CMakeFiles/fs_obj.dir/FileUtils.cpp.o In file included from src/common/fs/FileUtils.cpp:8: In file included from src/common/fs/FileUtils.h:12: src/common/base/StatusOr.h:57:19: error: invalid argument type 'auto' to unary expression static_assert ( !is_status_v<T>, \"`T' must not be of type `Status'\" ) ; ^~~~~~~~~~~~~~~ src/common/fs/FileUtils.cpp:90:34: note: in instantiation of template class 'nebula::StatusOr<std::__cxx11::basic_string<char> >' requested here StatusOr<std::string> FileUtils::readLink ( const char *path ) { ... It is due to a known bug of Clang 9.0 to deal with auto template variables , which has not been fixed until now(2020-01-20).","title":"Build Source Code"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#build_from_source_code","text":"","title":"Build From Source Code"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#overview","text":"We have tested building on various environments, including CentOS 6 to 8, Ubuntu 16.04 to 19.04, Fedora 28 to 30, GCC 7.1.0 to 9.2.0 and recent Clang++ and the devtoolset of Red Hat and CentOS. But due to the complexity of building environments, we still cannot guarantee that we have covered all kinds of situations. If any problem encountered, please fire an issue or open a pull request to let us know.","title":"Overview"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#requirements","text":"CPU: x86_64 Memory: 4GB at least Disk space: 10GB at least Linux: 2.3.32 or higher, check with uname -r glibc: 2.12 or higher, check with ldd --version GCC: 7.1.0 or higher, check with g++ --version CMake: 3.5.0 or higher, check with cmake --version Access to the Internet For the time being, Nebula Graph can only run in a x86_64 box, with Linux 2.3.32+ and glibc 2.12+.","title":"Requirements"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#quick_steps_to_build","text":"","title":"Quick Steps to Build"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#installing_dependencies","text":"Please note that it requires root privileges to install packages. For CentOS, RedHat and Fedora users: $ yum update $ yum install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz \\ readline-devel \\ ncurses-devel \\ zlib-devel \\ gcc \\ gcc-c++ \\ cmake \\ gettext \\ curl \\ redhat-lsb-core # For CentOS 8+, RedHat 8+, and Fedora, you need to install libstdc++-static, libasan $ yum install -y libstdc++-static libasan For Debian and Ubuntu users: $ apt-get update $ apt-get install -y make \\ m4 \\ git \\ wget \\ unzip \\ xz-utils \\ curl \\ lsb-core \\ build-essential \\ libreadline-dev \\ ncurses-dev \\ cmake \\ gettext For Arch and Gentoo users, you can definitely handle all of these on your own, right? To make sure your GCC and CMake are in the right version: $ g++ --version $ cmake --version If not, please refer to Install an Applicable CMake and Install an Applicable GCC .","title":"Installing Dependencies"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#cloning_the_repo","text":"$ git clone https://github.com/vesoft-inc/nebula.git If you don't care about the commit history of the repo, and to make the cloning faster, you could perform a shallow clone: $ git clone --depth = 1 https://github.com/vesoft-inc/nebula.git","title":"Cloning the Repo"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#configuring_and_building","text":"$ cd nebula $ mkdir build $ cd build $ cmake -DENABLE_TESTING = OFF -DCMAKE_BUILD_TYPE = Release -DCMAKE_INSTALL_PREFIX = $PWD /install .. # Assuming cores is the number of cores and mem_gb is the memory size (in GB), the value of N is recommended to select the smaller one from cores and mem_gb / 2 # We suggest choosing release build type to speed up compilation $ make -jN $ make install $ ls install/ etc/ bin/ share/ scripts/ Since C++ templates are heavily used by Nebula Graph and its third party dependencies, especially Folly, fbthrift and boost, the building is very time-consuming. For your reference, it is expected to take about 35 minutes in CPU time(less than 4 minutes with -j16 ), given an Intel E5-2697 v3 processor and unit tests are disabled.","title":"Configuring and Building"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#starting_nebula_graph_services","text":"After compiling and installing Nebula Graph , you can start Nebula Graph services. By default, Nebula Graph is installed in the /home/username/nebula/build/install directory, in which the username must be replaced by your username. Change your current directory to the directory where Nebula Graph is installed. $ cd /home/username/nebula/build/install Rename the configuration files for Nebula Graph services. $ cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf $ cp etc/nebula-metad.conf.default etc/nebula-metad.conf $ cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf Start Nebula Graph services. $ ./scripts/nebula.service start all Connect to Nebula Graph services. $ ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" Note : If you successfully connect to Nebula Graph services, you can see the Welcome to Nebula Graph message is displayed and automatically enter the ngql command line.","title":"Starting Nebula Graph Services"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#ways_to_tweak_the_building","text":"Until now, you might already have built Nebula Graph successfully. If so or not, we also provide ways to tweak the building process.","title":"Ways to Tweak the Building"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_argumentsvariables","text":"We provide several options to make one tweak the building, while some of these are builtins from CMake. These arguments are used at the configure(cmake) stage, like cmake -DArgument=Value .. .","title":"CMake Arguments/Variables"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_werror","text":"By default, Nebula Graph turns on the -Werror compiler option to regard any warnings as errors. If the building fails with such errors, you could still continue the building by set ENABLE_WERROR to OFF .","title":"ENABLE_WERROR"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_testing","text":"This option allows to enable or disable the build of unit tests. We suggest to turn it off if you just need the service modules of Nebula Graph . Options are ON and OFF , and the default value is ON .","title":"ENABLE_TESTING"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_asan","text":"This option enables or disables the ASan building, a.k.a AddressSanitizer, which is a memory error detector. It is meant to be used by Nebula Graph developers. This option is OFF by default.","title":"ENABLE_ASAN"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_build_type","text":"There are a few building types supported: Debug , to build with debug info but without optimization, which is by default Release , to build with optimization but without debug info RelWithDebInfo , to build with optimization AND debug info MinSizeRel , to build with optimizations for code size","title":"CMAKE_BUILD_TYPE"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_install_prefix","text":"This option is to specify the location where the service modules, scripts, configuration files and tools are installed when make install is performed. It is set to /usr/local/nebula by default.","title":"CMAKE_INSTALL_PREFIX"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#cmake_cxx_compiler","text":"Normally, CMake will figure out and locate an applicable C++ compiler for us. But if your compiler installation is not at the standard location, or if you want to use a different one, you have to specify it explicitly as follows: $ cmake -DCMAKE_C_COMPILER = /path/to/gcc/bin/gcc -DCMAKE_CXX_COMPILER = /path/to/gcc/bin/g++ .. $ cmake -DCMAKE_C_COMPILER = /path/to/clang/bin/clang -DCMAKE_CXX_COMPILER = /path/to/clang/bin/clang++ ..","title":"CMAKE_CXX_COMPILER"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#enable_ccache","text":"This option is to enable the use of ccache , which is for speeding up the compilation during daily development. By default, Nebula Graph will take advantage of ccache if it's found. So you don't have to enable it for yourself. If you want to disable ccache , it might be not enough to just turn ENABLE_CCACHE off. Since on some platforms, the ccache installation hooks up or precedes the compiler. For such a case, you have to set an environment variable export CCACHE_DISABLE=true , or add a line disable=true to ~/.ccache/ccache.conf . We may do this for you automatically in future. Please see the official documentation for more details.","title":"ENABLE_CCACHE"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#nebula_use_linker","text":"This option allows users to use an alternative linker, e.g. gold . Options are bfd , lld and gold for now. Among them, bfd and gold belong to GNU binutils, while lld needs to install LLVM / Clang. In addition, you can use this parameter to specify the absolute path of the linker when needed.","title":"NEBULA_USE_LINKER"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#nebula_thirdparty_root","text":"This option is to explicitly specify the location of the third party.","title":"NEBULA_THIRDPARTY_ROOT"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#installing_third_party_manually","text":"By default, at the configure(cmake) stage, a prebuilt third party will be downloaded and installed to the current build directory. If you would like to install it into another location for some reason, e.g. to rebuild by removing the whole build directory without downloading the third party again, you could perform the installation manually. Assume you are now at the build directory, run: # To install third party to /opt requires root privilege, you could change it to another location with --prefix. $ ../third-party/install-third-party.sh --prefix = /opt/vesoft/third-party If the third party is installed to /opt/vesoft/third-party , which is by default if no --prefix given, the building system of Nebula Graph would find it automatically. Otherwise, you need to specify the location with the CMake argument NEBULA_THIRDPARTY_ROOT as mentioned above, or set an environment variable to the location and export it. The precedence for Nebula Graph to find and choose the third party is: The CMake argument NEBULA_THIRDPARTY_ROOT third-party/install in the current build directory The NEBULA_THIRDPARTY_ROOT environment variable /opt/vesoft/third-party","title":"Installing Third Party Manually"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#install_an_applicable_cmake","text":"For users who don't have a usable CMake installation, we provide a script to automatically download and install one for you. Assuming you are now at the build directory, run: $ ../third-party/install-cmake.sh cmake-install CMake has been installed to prefix = cmake-install Run 'source cmake-install/bin/enable-cmake.sh' to make it ready to use. Run 'source cmake-install/bin/disable-cmake.sh' to disable it. $ source cmake-install/bin/enable-cmake.sh $ cmake --version cmake version 3 .15.5 Now you have an applicable CMake ready to use. At any time, you could run the command source cmake-install/bin/disable-cmake.sh to disable it.","title":"Install an Applicable CMake"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#install_an_applicable_gcc","text":"For users who don't have a usable GCC installation, we provide a prebuilt GCC and a script to automatically download and install it. Assuming you are now at the build directory, run: # To install GCC to /opt requires root privilege, you could change it to other locations $ ../third-party/install-gcc.sh --prefix = /opt GCC-7.5.0 has been installed to /opt/vesoft/toolset/gcc/7.5.0 Performing usability tests Performing regular C++14 tests...OK Performing LeakSanitizer tests...OK Run 'source /opt/vesoft/toolset/gcc/7.5.0/enable' to start using. Run 'source /opt/vesoft/toolset/gcc/7.5.0/disable' to stop using. # Please note that the path and specific version might be different from your environment $ source /opt/vesoft/toolset/gcc/7.5.0/enable # Only PATH was setup so as not to pollute your library path # You could run 'export LD_LIBRARY_PATH=/opt/vesoft/toolset/gcc/7.5.0/lib64:$LD_LIBRARY_PATH' if needed $ g++ --version g++ ( Nebula Graph Build ) 7 .5.0 Copyright ( C ) 2017 Free Software Foundation, Inc. Now you have an applicable GCC compiler ready to use. At any time, you could run the command source /opt/vesoft/toolset/gcc/7.5.0/disable to disable it.","title":"Install an Applicable GCC"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#faq","text":"","title":"FAQ"},{"location":"manual-EN/3.build-develop-and-administration/1.build/1.build-source-code/#error_invalid_argument_type_auto_to_unary_expression","text":"This error happens when building with Clang 9.0, as shown below: [ 5 % ] Building CXX object src/common/fs/CMakeFiles/fs_obj.dir/FileUtils.cpp.o In file included from src/common/fs/FileUtils.cpp:8: In file included from src/common/fs/FileUtils.h:12: src/common/base/StatusOr.h:57:19: error: invalid argument type 'auto' to unary expression static_assert ( !is_status_v<T>, \"`T' must not be of type `Status'\" ) ; ^~~~~~~~~~~~~~~ src/common/fs/FileUtils.cpp:90:34: note: in instantiation of template class 'nebula::StatusOr<std::__cxx11::basic_string<char> >' requested here StatusOr<std::string> FileUtils::readLink ( const char *path ) { ... It is due to a known bug of Clang 9.0 to deal with auto template variables , which has not been fixed until now(2020-01-20).","title":"error: invalid argument type 'auto' to unary expression"},{"location":"manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/","text":"Building With Docker Container \u00b6 Nebula Graph has provided a docker image with the whole compiling environment vesoft/nebula-dev , which will make it possible to change source code locally, build and debug within the container. Performing the following steps to start quick development: Pull Image From Docker Hub \u00b6 bash> docker pull vesoft/nebula-dev Run Docker Container \u00b6 Run docker container and mount your local source code directory into the container working_dir /home/nebula with the following command. bash> docker run --rm -ti \\ --security-opt seccomp = unconfined \\ -v /path/to/nebula/directory:/home/nebula \\ -w /home/nebula \\ vesoft/nebula-dev \\ bash Replace /path/to/nebula/directory with your local nebula source code directory . Compiling Within the Container \u00b6 docker> mkdir _build && cd _build docker> cmake .. docker> make docker> make install Run Nebula Graph service \u00b6 Once the preceding installation is completed, you can run Nebula Graph service within the container, the default installation directory is /usr/local/nebula . docker> cd /usr/local/nebula Rename config files of Nebula Graph service. docker> cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf docker> cp etc/nebula-metad.conf.default etc/nebula-metad.conf docker> cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf Start service. docker> ./scripts/nebula.service start all docker> ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" nebula> SHOW HOSTS ;","title":"Build by Docker"},{"location":"manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/#building_with_docker_container","text":"Nebula Graph has provided a docker image with the whole compiling environment vesoft/nebula-dev , which will make it possible to change source code locally, build and debug within the container. Performing the following steps to start quick development:","title":"Building With Docker Container"},{"location":"manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/#pull_image_from_docker_hub","text":"bash> docker pull vesoft/nebula-dev","title":"Pull Image From Docker Hub"},{"location":"manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/#run_docker_container","text":"Run docker container and mount your local source code directory into the container working_dir /home/nebula with the following command. bash> docker run --rm -ti \\ --security-opt seccomp = unconfined \\ -v /path/to/nebula/directory:/home/nebula \\ -w /home/nebula \\ vesoft/nebula-dev \\ bash Replace /path/to/nebula/directory with your local nebula source code directory .","title":"Run Docker Container"},{"location":"manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/#compiling_within_the_container","text":"docker> mkdir _build && cd _build docker> cmake .. docker> make docker> make install","title":"Compiling Within the Container"},{"location":"manual-EN/3.build-develop-and-administration/1.build/2.build-by-docker/#run_nebula_graph_service","text":"Once the preceding installation is completed, you can run Nebula Graph service within the container, the default installation directory is /usr/local/nebula . docker> cd /usr/local/nebula Rename config files of Nebula Graph service. docker> cp etc/nebula-graphd.conf.default etc/nebula-graphd.conf docker> cp etc/nebula-metad.conf.default etc/nebula-metad.conf docker> cp etc/nebula-storaged.conf.default etc/nebula-storaged.conf Start service. docker> ./scripts/nebula.service start all docker> ./bin/nebula -u user -p password --port 3699 --addr = \"127.0.0.1\" nebula> SHOW HOSTS ;","title":"Run Nebula Graph service"},{"location":"manual-EN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/","text":"KV interfaces \u00b6 Interface Demo \u00b6 Nebula Graph storage provides key-value interfaces. Users can perform kv operations through the StorageClient. Please note that users still need to create space through console. Currently supported interfaces are Get and Put. The interfaces are as follows. folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: ExecResponse >> put ( GraphSpaceID space , std :: vector < nebula :: cpp2 :: Pair > values , folly :: EventBase * evb = nullptr ); folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: GeneralResponse >> get ( GraphSpaceID space , const std :: vector < std :: string >& keys , folly :: EventBase * evb = nullptr ); Methods like remove, removeRange and scan will be provided later. Interfaces usage are demonstrated as follows: // Put interface std :: vector < nebula :: cpp2 :: Pair > pairs ; for ( int32_t i = 0 ; i < 1000 ; i ++ ) { auto key = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); auto value = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); pairs . emplace_back ( apache :: thrift :: FragileConstructor :: FRAGILE , std :: move ( key ), std :: move ( value )); } // Send requirements through StorageClient, the corresponding parameter is spaceId, the key-value pairs to put auto future = storageClient -> put ( spaceId , std :: move ( pairs )); // Get results auto resp = std :: move ( future ). get (); // Get interface std :: vector < std :: string > keys ; for ( auto & pair : pairs ) { keys . emplace_back ( pair . first ); } // Send requirements through StorageClient, the corresponding parameter is spaceId, the keys to get auto future = storageClient -> get ( spaceId , std :: move ( keys )); // Get results auto resp = std :: move ( future ). get () Processing Returned Results \u00b6 Check the returned results of the rpc to examine if the corresponding operation runs successfully. In addition, since Nebula Graph storage shards data, if one partition fails, the error code is also returned. If any of the partition fails, the entire requirement fails (resp.succeeded() is false). But those succeed are still read/written. Users can retry until all the requirements run successfully. Currently, auto retry is not supported by StorageClient. Users can decide whether to retry based on the error code. // Check if the call is successful if ( ! resp . succeeded ()) { LOG ( ERROR ) << \"Operation Failed\" ; return ; } // Failed partitions and the corresponding error code if ( ! resp . failedParts (). empty ()) { for ( const auto & partEntry : resp . failedParts ()) { LOG ( ERROR ) << \"Operation Failed in \" << partEntry . first << \", Code: \" << static_cast < int32_t > ( partEntry . second ); } return ; } Read Values \u00b6 For the Get interface, we need some more operations to get the corresponding values. Nebula Graph storage is a multi-copy based on Raft, and all read/written operations can only be sent to the leader of the corresponding partition. When a get request contains multiple keys across partitions, the Storage Client requests the keys from the Partition leader. Each rpc return is stored separately in an unordered_map, and the user is currently required to traverse these unordered_maps to check if the key exists. An example is as follows: // Examine whether the value corresponding to the key is in the returned result. If it exists, it is saved in the value. bool found = false ; std :: string value ; // resp.responses() it the results returned by the storage servers for ( const auto & result : resp . responses ()) { // result.values is the returned key-value pairs of a certain storage server auto iter = result . values . find ( key ); if ( iter != result . values . end ()) { value = iter -> second ; found = true ; break ; } }","title":"Kv Value API"},{"location":"manual-EN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#kv_interfaces","text":"","title":"KV interfaces"},{"location":"manual-EN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#interface_demo","text":"Nebula Graph storage provides key-value interfaces. Users can perform kv operations through the StorageClient. Please note that users still need to create space through console. Currently supported interfaces are Get and Put. The interfaces are as follows. folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: ExecResponse >> put ( GraphSpaceID space , std :: vector < nebula :: cpp2 :: Pair > values , folly :: EventBase * evb = nullptr ); folly :: SemiFuture < StorageRpcResponse < storage :: cpp2 :: GeneralResponse >> get ( GraphSpaceID space , const std :: vector < std :: string >& keys , folly :: EventBase * evb = nullptr ); Methods like remove, removeRange and scan will be provided later. Interfaces usage are demonstrated as follows: // Put interface std :: vector < nebula :: cpp2 :: Pair > pairs ; for ( int32_t i = 0 ; i < 1000 ; i ++ ) { auto key = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); auto value = std :: to_string ( folly :: Random :: rand32 ( 1000000000 )); pairs . emplace_back ( apache :: thrift :: FragileConstructor :: FRAGILE , std :: move ( key ), std :: move ( value )); } // Send requirements through StorageClient, the corresponding parameter is spaceId, the key-value pairs to put auto future = storageClient -> put ( spaceId , std :: move ( pairs )); // Get results auto resp = std :: move ( future ). get (); // Get interface std :: vector < std :: string > keys ; for ( auto & pair : pairs ) { keys . emplace_back ( pair . first ); } // Send requirements through StorageClient, the corresponding parameter is spaceId, the keys to get auto future = storageClient -> get ( spaceId , std :: move ( keys )); // Get results auto resp = std :: move ( future ). get ()","title":"Interface Demo"},{"location":"manual-EN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#processing_returned_results","text":"Check the returned results of the rpc to examine if the corresponding operation runs successfully. In addition, since Nebula Graph storage shards data, if one partition fails, the error code is also returned. If any of the partition fails, the entire requirement fails (resp.succeeded() is false). But those succeed are still read/written. Users can retry until all the requirements run successfully. Currently, auto retry is not supported by StorageClient. Users can decide whether to retry based on the error code. // Check if the call is successful if ( ! resp . succeeded ()) { LOG ( ERROR ) << \"Operation Failed\" ; return ; } // Failed partitions and the corresponding error code if ( ! resp . failedParts (). empty ()) { for ( const auto & partEntry : resp . failedParts ()) { LOG ( ERROR ) << \"Operation Failed in \" << partEntry . first << \", Code: \" << static_cast < int32_t > ( partEntry . second ); } return ; }","title":"Processing Returned Results"},{"location":"manual-EN/3.build-develop-and-administration/2.develop-and-interface/kv-interfaces/#read_values","text":"For the Get interface, we need some more operations to get the corresponding values. Nebula Graph storage is a multi-copy based on Raft, and all read/written operations can only be sent to the leader of the corresponding partition. When a get request contains multiple keys across partitions, the Storage Client requests the keys from the Partition leader. Each rpc return is stored separately in an unordered_map, and the user is currently required to traverse these unordered_maps to check if the key exists. An example is as follows: // Examine whether the value corresponding to the key is in the returned result. If it exists, it is saved in the value. bool found = false ; std :: string value ; // resp.responses() it the results returned by the storage servers for ( const auto & result : resp . responses ()) { // result.values is the returned key-value pairs of a certain storage server auto iter = result . values . find ( key ); if ( iter != result . values . end ()) { value = iter -> second ; found = true ; break ; } }","title":"Read Values"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/","text":"Reader \u00b6 This chapter is for developers and DBAs.","title":"Reader"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/#reader","text":"This chapter is for developers and DBAs.","title":"Reader"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/","text":"Configuration Description \u00b6 This documentation details the descriptions of the configuration files under the etc/ directory. Meta Service \u00b6 Property Name Default Value Description port 45500 Meta daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path. Multi-paths are not supported. meta_server_addrs \"\" A list of IPs split by comma, used in cluster deployment, the number of IPs is equal to that of the replica. If empty, it means a single node. local_ip \"\" Local ip specified for NetworkUtils::getLocalIP. num_io_threads 16 Number of IO threads. meta_http_thread_num 3 Number of meta daemon's http thread. num_worker_threads 32 Number of workers. part_man_type memory Memory, meta. pid_file \"pids/nebula-metad.pid\" File to hold the process ID. daemonize true Whether run as a daemon process. cluster_id 0 A unique id for each cluster. meta_ingest_thread_num 3 Meta daemon's ingest thread number. ws_http_port 11000 Port to listen on Meta with HTTP protocol are 11000. ws_h2_port 11002 Port to listen on Meta with HTTP/2 protocol is 11002. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service. Storage Service \u00b6 Property Name Default Value Description port 44500 Storage daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path, multi paths should be split by comma. For RocksDB engine, one path one instance. local_ip \"\" IP address used to identify this server, combined with the listen port. daemonize true Whether to run the process as a daemon. pid_file \"pids/nebula-storaged.pid\" File to hold the process ID. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. store_type \"nebula\" Which type of KVStore to be used by the storage daemon. Options can be nebula, HBase, etc. num_io_threads 16 Number of IO threads. storage_http_thread_num 3 Number of storage daemon's http thread. num_worker_threads 32 Number of workers. engine_type rocksdb RocksDB, memory... custom_filter_interval_secs 24 * 3600 Interval to trigger custom compaction. num_workers 4 Number of worker threads. rocksdb_disable_wal false Whether to disable the WAL in RocksDB. rocksdb_db_options \"{}\" Json string of DBOptions, all keys and values are string. rocksdb_column_family_options \"{}\" Json string of ColumnFamilyOptions, all keys and values are string. rocksdb_block_based_table_options \"{}\" Json string of BlockBasedTableOptions, all keys and values are string. rocksdb_batch_size 4 * 1024 Default reserved bytes for one batch operation. rocksdb_block_cache 1024 The default block cache size used in BlockBasedTable. The unit is MB. download_thread_num 3 Download thread number. min_vertices_per_bucket 3 The min vertices number in one bucket. max_appendlog_batch_size 128 The max number of logs in each appendLog request batch. max_outstanding_requests 1024 The max number of outstanding appendLog requests. raft_rpc_timeout_ms 500 RPC timeout for raft client. raft_heartbeat_interval_secs 5 Seconds between each heartbeat. max_batch_size 256 The max number of logs in a batch. ws_http_port 12000 Port to listen on Storage with HTTP protocol is 12000. ws_h2_port 12002 Port to listen on Storage with HTTP/2 protocol is 12002. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service. Graph Service \u00b6 Property Name Default Value Description port 3699 Nebula Graph daemon's listen port. client_idle_timeout_secs 0 Seconds before we close the idle connections, 0 for infinite. session_idle_timeout_secs 600 Seconds before we expire the idle sessions, 0 for infinite. session_reclaim_interval_secs 10 Period we try to reclaim expired sessions. num_netio_threads 0 Number of networking threads, 0 for number of physical CPU cores. num_accept_threads 1 Number of threads to accept incoming connections. num_worker_threads 0 Number of threads to execute user queries. reuse_port false Whether to turn on the SO_REUSEPORT option. listen_backlog 1024 Backlog of the listen socket. listen_netdev \"any\" The network device to listen on. pid_file \"pids/nebula-graphd.pid\" File to hold the process ID. redirect_stdout true Whether to redirect stdout and stderr to separate files. stdout_log_file \"graphd-stdout.log\" Destination filename of stdout. stderr_log_file \"graphd-stderr.log\" Destination filename of stderr. daemonize true Whether run as a daemon process. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. ws_http_port 13000 Port to listen on Graph with HTTP protocol is 13000. ws_h2_port 13002 Port to listen on Graph with HTTP/2 protocol is 13002. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service. Console \u00b6 Property Name Default Value Description addr \"127.0.0.1\" Graph daemon IP address. port 0 Graph daemon listening port. u \"\" Username used to authenticate. p \"\" Password used to authenticate. enable_history false Whether to force saving the command history. server_conn_timeout_ms 1000 Connection timeout in milliseconds.","title":"Configuration Description"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#configuration_description","text":"This documentation details the descriptions of the configuration files under the etc/ directory.","title":"Configuration Description"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#meta_service","text":"Property Name Default Value Description port 45500 Meta daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path. Multi-paths are not supported. meta_server_addrs \"\" A list of IPs split by comma, used in cluster deployment, the number of IPs is equal to that of the replica. If empty, it means a single node. local_ip \"\" Local ip specified for NetworkUtils::getLocalIP. num_io_threads 16 Number of IO threads. meta_http_thread_num 3 Number of meta daemon's http thread. num_worker_threads 32 Number of workers. part_man_type memory Memory, meta. pid_file \"pids/nebula-metad.pid\" File to hold the process ID. daemonize true Whether run as a daemon process. cluster_id 0 A unique id for each cluster. meta_ingest_thread_num 3 Meta daemon's ingest thread number. ws_http_port 11000 Port to listen on Meta with HTTP protocol are 11000. ws_h2_port 11002 Port to listen on Meta with HTTP/2 protocol is 11002. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service.","title":"Meta Service"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#storage_service","text":"Property Name Default Value Description port 44500 Storage daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path, multi paths should be split by comma. For RocksDB engine, one path one instance. local_ip \"\" IP address used to identify this server, combined with the listen port. daemonize true Whether to run the process as a daemon. pid_file \"pids/nebula-storaged.pid\" File to hold the process ID. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. store_type \"nebula\" Which type of KVStore to be used by the storage daemon. Options can be nebula, HBase, etc. num_io_threads 16 Number of IO threads. storage_http_thread_num 3 Number of storage daemon's http thread. num_worker_threads 32 Number of workers. engine_type rocksdb RocksDB, memory... custom_filter_interval_secs 24 * 3600 Interval to trigger custom compaction. num_workers 4 Number of worker threads. rocksdb_disable_wal false Whether to disable the WAL in RocksDB. rocksdb_db_options \"{}\" Json string of DBOptions, all keys and values are string. rocksdb_column_family_options \"{}\" Json string of ColumnFamilyOptions, all keys and values are string. rocksdb_block_based_table_options \"{}\" Json string of BlockBasedTableOptions, all keys and values are string. rocksdb_batch_size 4 * 1024 Default reserved bytes for one batch operation. rocksdb_block_cache 1024 The default block cache size used in BlockBasedTable. The unit is MB. download_thread_num 3 Download thread number. min_vertices_per_bucket 3 The min vertices number in one bucket. max_appendlog_batch_size 128 The max number of logs in each appendLog request batch. max_outstanding_requests 1024 The max number of outstanding appendLog requests. raft_rpc_timeout_ms 500 RPC timeout for raft client. raft_heartbeat_interval_secs 5 Seconds between each heartbeat. max_batch_size 256 The max number of logs in a batch. ws_http_port 12000 Port to listen on Storage with HTTP protocol is 12000. ws_h2_port 12002 Port to listen on Storage with HTTP/2 protocol is 12002. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service.","title":"Storage Service"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#graph_service","text":"Property Name Default Value Description port 3699 Nebula Graph daemon's listen port. client_idle_timeout_secs 0 Seconds before we close the idle connections, 0 for infinite. session_idle_timeout_secs 600 Seconds before we expire the idle sessions, 0 for infinite. session_reclaim_interval_secs 10 Period we try to reclaim expired sessions. num_netio_threads 0 Number of networking threads, 0 for number of physical CPU cores. num_accept_threads 1 Number of threads to accept incoming connections. num_worker_threads 0 Number of threads to execute user queries. reuse_port false Whether to turn on the SO_REUSEPORT option. listen_backlog 1024 Backlog of the listen socket. listen_netdev \"any\" The network device to listen on. pid_file \"pids/nebula-graphd.pid\" File to hold the process ID. redirect_stdout true Whether to redirect stdout and stderr to separate files. stdout_log_file \"graphd-stdout.log\" Destination filename of stdout. stderr_log_file \"graphd-stderr.log\" Destination filename of stderr. daemonize true Whether run as a daemon process. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. ws_http_port 13000 Port to listen on Graph with HTTP protocol is 13000. ws_h2_port 13002 Port to listen on Graph with HTTP/2 protocol is 13002. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service.","title":"Graph Service"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/configuration-description/#console","text":"Property Name Default Value Description addr \"127.0.0.1\" Graph daemon IP address. port 0 Graph daemon listening port. u \"\" Username used to authenticate. p \"\" Password used to authenticate. enable_history false Whether to force saving the command history. server_conn_timeout_ms 1000 Connection timeout in milliseconds.","title":"Console"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster-on-docker/","text":"Deploy Clusters on Docker \u00b6 Reference another repository: vesoft-inc/nebula-docker-compose","title":"Deploy Cluster on Docker"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster-on-docker/#deploy_clusters_on_docker","text":"Reference another repository: vesoft-inc/nebula-docker-compose","title":"Deploy Clusters on Docker"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/","text":"Deploy Cluster \u00b6 This section provides an introduction to deploy Nebula Graph cluster. Download and Install Package \u00b6 Currently, we have offered packages for CentOS 7.5 , CentOS 6.5 , Ubuntu 1604 and Ubuntu 1804 . You can download rpm or deb packages by clicking the Assets . For CentOS : rpm -ivh nebula- { VERSION } . { SYSTEM_VERSION } .x86_64.rpm For Ubuntu : dpkg -i nebula- { VERSION } . { SYSTEM_VERSION } .amd64.deb By default, the config files are under /usr/local/nebula/etc , you should modify the meta_server_addrs to set the Meta Server's address. In order to enable multi copy Meta services, you should set the meta addresses split by comma into meta_server_addrs . Use data_path to set Meta and Storage 's underlying storage directory. Start Up Nebula Graph Cluster \u00b6 Currently, we use scripts/services.sh to manage the Nebula Graph cluster. You can start , stop and restart the cluster with this script. It looks like the following command: scripts/services.sh <start | stop | restart | status | kill> The metas, storages and graphs contain the host of themselves. Connect to Nebula Graph \u00b6 > bin/nebula -u = user -p = password --addr ={ graphd IP address } --port ={ graphd listening port } -u is to set the user name, user is the default Nebula Graph user account -p is to set password, password is the default password for account user --addr is the graphd IP address --port is the the graphd server port and the default value is 3699 Then you\u2019re now ready to start using Nebula Graph . Configuration Reference \u00b6 Meta Service supports the following config properties. Property Name Default Value Description port 45500 Meta daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path. Multi-path is not supported meta_server_addrs \"\" It is a list of IPs split by comma, the ips number equals replica number. If empty, it means replica is 1. local_ip \"\" Local ip speicified for NetworkUtils::getLocalIP. num_io_threads 16 Number of IO threads. meta_http_thread_num 3 Number of meta daemon's http thread. num_worker_threads 32 Number of workers. part_man_type memory memory, meta. pid_file \"pids/nebula-metad.pid\" File to hold the process id. daemonize true Whether run as a daemon process. cluster_id 0 A unique id for each cluster. meta_ingest_thread_num 3. Meta daemon's ingest thread number. Storage Service supports the following config properties. Property Name Default Value Description port 44500 Storage daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path, multi paths should be split by comma. For rocksdb engine, one path one instance. local_ip \"\" IP address is used to identify this server, combined with the listen port. daemonize true Whether to run the process as a daemon. pid_file \"pids/nebula-storaged.pid\" File to hold the process id. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. store_type \"nebula\" Which type of KVStore to be used by the storage daemon.Options can be \\\"nebula\\\", \\\"hbase\\\", etc. num_io_threads 16 Number of IO threads storage_http_thread_num 3 Number of storage daemon's http thread. num_worker_threads 32 Number of workers. engine_type rocksdb rocksdb, memory... custom_filter_interval_secs 24 * 3600 Interval to trigger custom compaction. num_workers 4 Number of worker threads. rocksdb_disable_wal false Whether to disable the WAL in rocksdb. rocksdb_db_options \"\" DBOptions, each option will be given as : separated by. rocksdb_column_family_options \"\" ColumnFamilyOptions, each option will be given as : separated by. rocksdb_block_based_table_options \"\" BlockBasedTableOptions, each option will be given as : separated by. batch_size 4 * 1024 Default reserved bytes for one batch operation block_cache 4 BlockBasedTable:block_cache : MB download_thread_num 3 Download thread number. min_vertices_per_bucket 3 The min vertices number in one bucket. max_appendlog_batch_size 128 The max number of logs in each appendLog request batch. max_outstanding_requests 1024 The max number of outstanding appendLog requests. raft_rpc_timeout_ms 500 RPC timeout for raft client. accept_log_append_during_pulling false Whether to accept new logs during pulling the snapshot. raft_heartbeat_interval_secs 5 Seconds between each heartbeat. max_batch_size 256 The max number of logs in a batch. Graph Service supports the following config properties. Property Name Default Value Description port 3699 Nebula Graph daemon's listen port. client_idle_timeout_secs 0 Seconds before we close the idle connections, 0 for infinite. session_idle_timeout_secs 600 Seconds before we expire the idle sessions, 0 for infinite. session_reclaim_interval_secs 10 Period we try to reclaim expired sessions. num_netio_threads 0 Number of networking threads, 0 for number of physical CPU cores. num_accept_threads 1 Number of threads to accept incoming connections. num_worker_threads 1 Number of threads to execute user queries. reuse_port true Whether to turn on the SO_REUSEPORT option. listen_backlog 1024 Backlog of the listen socket. listen_netdev \"any\" The network device to listen on. pid_file \"pids/nebula-graphd.pid\" File to hold the process id. redirect_stdout true Whether to redirect stdout and stderr to separate files. stdout_log_file \"graphd-stdout.log\" Destination filename of stdout. stderr_log_file \"graphd-stderr.log\" Destination filename of stderr. daemonize true Whether run as a daemon process. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. Web Service supports the following config properties. Property Name Default Value Description ws_http_port 11000 Port to listen on with HTTP protocol. ws_h2_port 11002 Port to listen on with HTTP/2 protocol. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service. ws_meta_http_port 11000 Port to listen on Meta with HTTP protocol. ws_meta_h2_port 11002 Port to listen on Meta with HTTP/2 protocol. ws_storage_http_port 12000 Port to listen on Storage with HTTP protocol. ws_storage_h2_port 12002 Port to listen on Storage with HTTP/2 protocol. Console supports the following config properties. Property Name Default Value Description addr \"127.0.0.1\" Nebula Graph daemon IP address port 0 Nebula Graph daemon listening port. u \"\" Username used to authenticate. p \"\" Password used to authenticate. enable_history false Whether to force saving the command history. server_conn_timeout_ms 1000 Connection timeout in milliseconds. Note: Please make sure the ports are not blocked by the firewall during configuration.","title":"Deploy Cluster"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#deploy_cluster","text":"This section provides an introduction to deploy Nebula Graph cluster.","title":"Deploy Cluster"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#download_and_install_package","text":"Currently, we have offered packages for CentOS 7.5 , CentOS 6.5 , Ubuntu 1604 and Ubuntu 1804 . You can download rpm or deb packages by clicking the Assets . For CentOS : rpm -ivh nebula- { VERSION } . { SYSTEM_VERSION } .x86_64.rpm For Ubuntu : dpkg -i nebula- { VERSION } . { SYSTEM_VERSION } .amd64.deb By default, the config files are under /usr/local/nebula/etc , you should modify the meta_server_addrs to set the Meta Server's address. In order to enable multi copy Meta services, you should set the meta addresses split by comma into meta_server_addrs . Use data_path to set Meta and Storage 's underlying storage directory.","title":"Download and Install Package"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#start_up_nebula_graph_cluster","text":"Currently, we use scripts/services.sh to manage the Nebula Graph cluster. You can start , stop and restart the cluster with this script. It looks like the following command: scripts/services.sh <start | stop | restart | status | kill> The metas, storages and graphs contain the host of themselves.","title":"Start Up Nebula Graph Cluster"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#connect_to_nebula_graph","text":"> bin/nebula -u = user -p = password --addr ={ graphd IP address } --port ={ graphd listening port } -u is to set the user name, user is the default Nebula Graph user account -p is to set password, password is the default password for account user --addr is the graphd IP address --port is the the graphd server port and the default value is 3699 Then you\u2019re now ready to start using Nebula Graph .","title":"Connect to Nebula Graph"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/deploy-cluster/#configuration_reference","text":"Meta Service supports the following config properties. Property Name Default Value Description port 45500 Meta daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path. Multi-path is not supported meta_server_addrs \"\" It is a list of IPs split by comma, the ips number equals replica number. If empty, it means replica is 1. local_ip \"\" Local ip speicified for NetworkUtils::getLocalIP. num_io_threads 16 Number of IO threads. meta_http_thread_num 3 Number of meta daemon's http thread. num_worker_threads 32 Number of workers. part_man_type memory memory, meta. pid_file \"pids/nebula-metad.pid\" File to hold the process id. daemonize true Whether run as a daemon process. cluster_id 0 A unique id for each cluster. meta_ingest_thread_num 3. Meta daemon's ingest thread number. Storage Service supports the following config properties. Property Name Default Value Description port 44500 Storage daemon listening port. reuse_port true Whether to turn on the SO_REUSEPORT option. data_path \"\" Root data path, multi paths should be split by comma. For rocksdb engine, one path one instance. local_ip \"\" IP address is used to identify this server, combined with the listen port. daemonize true Whether to run the process as a daemon. pid_file \"pids/nebula-storaged.pid\" File to hold the process id. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. store_type \"nebula\" Which type of KVStore to be used by the storage daemon.Options can be \\\"nebula\\\", \\\"hbase\\\", etc. num_io_threads 16 Number of IO threads storage_http_thread_num 3 Number of storage daemon's http thread. num_worker_threads 32 Number of workers. engine_type rocksdb rocksdb, memory... custom_filter_interval_secs 24 * 3600 Interval to trigger custom compaction. num_workers 4 Number of worker threads. rocksdb_disable_wal false Whether to disable the WAL in rocksdb. rocksdb_db_options \"\" DBOptions, each option will be given as : separated by. rocksdb_column_family_options \"\" ColumnFamilyOptions, each option will be given as : separated by. rocksdb_block_based_table_options \"\" BlockBasedTableOptions, each option will be given as : separated by. batch_size 4 * 1024 Default reserved bytes for one batch operation block_cache 4 BlockBasedTable:block_cache : MB download_thread_num 3 Download thread number. min_vertices_per_bucket 3 The min vertices number in one bucket. max_appendlog_batch_size 128 The max number of logs in each appendLog request batch. max_outstanding_requests 1024 The max number of outstanding appendLog requests. raft_rpc_timeout_ms 500 RPC timeout for raft client. accept_log_append_during_pulling false Whether to accept new logs during pulling the snapshot. raft_heartbeat_interval_secs 5 Seconds between each heartbeat. max_batch_size 256 The max number of logs in a batch. Graph Service supports the following config properties. Property Name Default Value Description port 3699 Nebula Graph daemon's listen port. client_idle_timeout_secs 0 Seconds before we close the idle connections, 0 for infinite. session_idle_timeout_secs 600 Seconds before we expire the idle sessions, 0 for infinite. session_reclaim_interval_secs 10 Period we try to reclaim expired sessions. num_netio_threads 0 Number of networking threads, 0 for number of physical CPU cores. num_accept_threads 1 Number of threads to accept incoming connections. num_worker_threads 1 Number of threads to execute user queries. reuse_port true Whether to turn on the SO_REUSEPORT option. listen_backlog 1024 Backlog of the listen socket. listen_netdev \"any\" The network device to listen on. pid_file \"pids/nebula-graphd.pid\" File to hold the process id. redirect_stdout true Whether to redirect stdout and stderr to separate files. stdout_log_file \"graphd-stdout.log\" Destination filename of stdout. stderr_log_file \"graphd-stderr.log\" Destination filename of stderr. daemonize true Whether run as a daemon process. meta_server_addrs \"\" List of meta server addresses, the format looks like ip1:port1, ip2:port2, ip3:port3. Web Service supports the following config properties. Property Name Default Value Description ws_http_port 11000 Port to listen on with HTTP protocol. ws_h2_port 11002 Port to listen on with HTTP/2 protocol. ws_ip \"127.0.0.1\" IP/Hostname to bind to. ws_threads 4 Number of threads for the web service. ws_meta_http_port 11000 Port to listen on Meta with HTTP protocol. ws_meta_h2_port 11002 Port to listen on Meta with HTTP/2 protocol. ws_storage_http_port 12000 Port to listen on Storage with HTTP protocol. ws_storage_h2_port 12002 Port to listen on Storage with HTTP/2 protocol. Console supports the following config properties. Property Name Default Value Description addr \"127.0.0.1\" Nebula Graph daemon IP address port 0 Nebula Graph daemon listening port. u \"\" Username used to authenticate. p \"\" Password used to authenticate. enable_history false Whether to force saving the command history. server_conn_timeout_ms 1000 Connection timeout in milliseconds. Note: Please make sure the ports are not blocked by the firewall during configuration.","title":"Configuration Reference"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/","text":"Nebula Graph Installation with rpm/deb Package \u00b6 Overview \u00b6 This guide will walk you through the process of installing Nebula Graph with rpm/deb packages. Prerequisites \u00b6 Before getting started, ensure that you meet the following requirements: Hard disk: 50 GB Memory: 8 GB Installing Nebula Graph \u00b6 To install Nebula Graph with a rpm/deb package, you must complete the following steps: Download packages. Method one: Download via GitHub. Log in to GitHub and click rpm/deb to locate the rpm/deb package Under the Actions tab, click package on the left. All packages available are displayed. Click the latest package on the top of the package list. Click the Artifacts list on the upper right corner to select a package to download. Method two: Download via OSS. Obtaining the release version information. The URL format is as follows: Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1604 The ${release_version} in the link is the release version information. For example, use the follow command to download the 1.0.0-rc2 Centos 7 package. bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/1.0.0-rc2/nebula-1.0.0-rc2.el7-5.x86_64.rpm b. Obtaining the nightly version. The URL format is as follows: Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1804 The ${date} in the link specifies the date. For example, use the follow command to download the April 1st 2020 Centos 7 package. bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/nightly/2020. 04.01/nebula-2020.04.01-nightly.el7-5.x86_64.rpm Install Nebula Graph . For a rpm file, install Nebula Graph with the following command: $ sudo rpm -ivh nebula-2019.12.23-nightly.el6-5.x86_64.rpm For a deb file, install Nebula Graph with the following command: $ sudo dpkg -i nebula-2019.12.23-nightly.ubuntu1604.amd64.deb Install Nebula Graph to your customized directory with the following command: rpm -ivh --prefix = ${ your_dir } nebula-graph- ${ version } .rpm Package Nebula Graph to one package with the following command: cd nebula/package ./package.sh -v <version> Package Nebula Graph to multiple packages with the following command: cd nebula/package ./package.sh -v <version> -n OFF Note : Replace the above file name with your own file name, otherwise, this command might fail. Nebula Graph is installed in the /usr/local/nebula directory by default. Starting Nebula Graph Services \u00b6 After Nebula Graph is installed successfully, you can start Nebula Graph services with the following command: $ sudo /usr/local/nebula/scripts/nebula.service start all Checking Nebula Graph Services \u00b6 You can check the Nebula Graph services with the following command: $ sudo /usr/local/nebula/scripts/nebula.service status all Connecting to Nebula Graph Services \u00b6 You can connect to Nebula Graph services with the following command: $ sudo /usr/local/nebula/bin/nebula -u user -p password Note : If you successfully connect to Nebula Graph , the Welcome to Nebula Graph information is returned. Stopping Nebula Graph Services \u00b6 If you want to stop Nebula Graph services, you can enter the following command: $ sudo /usr/local/nebula/scripts/nebula.service stop all","title":"Install With rpm Package"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#nebula_graph_installation_with_rpmdeb_package","text":"","title":"Nebula Graph Installation with rpm/deb Package"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#overview","text":"This guide will walk you through the process of installing Nebula Graph with rpm/deb packages.","title":"Overview"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#prerequisites","text":"Before getting started, ensure that you meet the following requirements: Hard disk: 50 GB Memory: 8 GB","title":"Prerequisites"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#installing_nebula_graph","text":"To install Nebula Graph with a rpm/deb package, you must complete the following steps: Download packages. Method one: Download via GitHub. Log in to GitHub and click rpm/deb to locate the rpm/deb package Under the Actions tab, click package on the left. All packages available are displayed. Click the latest package on the top of the package list. Click the Artifacts list on the upper right corner to select a package to download. Method two: Download via OSS. Obtaining the release version information. The URL format is as follows: Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1604 The ${release_version} in the link is the release version information. For example, use the follow command to download the 1.0.0-rc2 Centos 7 package. bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/1.0.0-rc2/nebula-1.0.0-rc2.el7-5.x86_64.rpm b. Obtaining the nightly version. The URL format is as follows: Centos 6 Centos 7 Ubuntu 1604 Ubuntu 1804 The ${date} in the link specifies the date. For example, use the follow command to download the April 1st 2020 Centos 7 package. bash $ wget https://nebula-graph.oss-cn-hangzhou.aliyuncs.com/package/nightly/2020. 04.01/nebula-2020.04.01-nightly.el7-5.x86_64.rpm Install Nebula Graph . For a rpm file, install Nebula Graph with the following command: $ sudo rpm -ivh nebula-2019.12.23-nightly.el6-5.x86_64.rpm For a deb file, install Nebula Graph with the following command: $ sudo dpkg -i nebula-2019.12.23-nightly.ubuntu1604.amd64.deb Install Nebula Graph to your customized directory with the following command: rpm -ivh --prefix = ${ your_dir } nebula-graph- ${ version } .rpm Package Nebula Graph to one package with the following command: cd nebula/package ./package.sh -v <version> Package Nebula Graph to multiple packages with the following command: cd nebula/package ./package.sh -v <version> -n OFF Note : Replace the above file name with your own file name, otherwise, this command might fail. Nebula Graph is installed in the /usr/local/nebula directory by default.","title":"Installing Nebula Graph"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#starting_nebula_graph_services","text":"After Nebula Graph is installed successfully, you can start Nebula Graph services with the following command: $ sudo /usr/local/nebula/scripts/nebula.service start all","title":"Starting Nebula Graph Services"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#checking_nebula_graph_services","text":"You can check the Nebula Graph services with the following command: $ sudo /usr/local/nebula/scripts/nebula.service status all","title":"Checking Nebula Graph Services"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#connecting_to_nebula_graph_services","text":"You can connect to Nebula Graph services with the following command: $ sudo /usr/local/nebula/bin/nebula -u user -p password Note : If you successfully connect to Nebula Graph , the Welcome to Nebula Graph information is returned.","title":"Connecting to Nebula Graph Services"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/deployment/install-with-rpm-deb/#stopping_nebula_graph_services","text":"If you want to stop Nebula Graph services, you can enter the following command: $ sudo /usr/local/nebula/scripts/nebula.service stop all","title":"Stopping Nebula Graph Services"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/alter-user-syntax/","text":"Alter User Syntax \u00b6 ALTER USER <user_name> WITH PASSWORD <password> The ALTER USER statement modifies Nebula Graph user accounts. ALTER USER requires the global CREATE USER privilege. An error occurs if you try to modify a user that does not exist. ALTER does not require password verification.","title":"ALTER USER Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/alter-user-syntax/#alter_user_syntax","text":"ALTER USER <user_name> WITH PASSWORD <password> The ALTER USER statement modifies Nebula Graph user accounts. ALTER USER requires the global CREATE USER privilege. An error occurs if you try to modify a user that does not exist. ALTER does not require password verification.","title":"Alter User Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/built-in-roles/","text":"Built-in Roles \u00b6 Nebula Graph provides the following roles: God The initial root user (similar to the Root in Linux and Administrator in Windows). All the operation access. A cluster can only have one God. God manages all the spaces in the cluster. The God role is automatically initialized by meta and cannot be granted by users. Admin The administration user. Read/write access to both the schema and data limited to its authorized space. Authorization access to users limited to its authorized space. DBA Read/write access to both the schema and data limited to its authorized space. No authorization access to users. User Read/write access to data limited to its authorized space. Read-only access to the schema limited to its authorized space. Guest Read-only access to both the schema and data limited to its authorized space. If the authorization is enabled, the default user name and password are root and nebula respectively, and the user name is immutable. Set the enable_authorize parameter in the /usr/local/nebula/etc/nebula-graphd.conf file to true to enable the authorization. A user who has no assigned roles will not have any accesses to the space. A user can only have one assigned role in the same space. A user can have different roles in different spaces. The set of executor prescribed by each role are described below. Divided by operation permissions. OPERATION STATEMENTS Read space Use, DescribeSpace Write space CreateSpace, DropSpace, CreateSnapshot, DropSnapshot, Balance, Admin, Config, Ingest, Download Read schema DescribeTag, DescribeEdge, DescribeTagIndex, DescribeEdgeIndex Write schema CreateTag, AlterTag, CreateEdge, AlterEdge, DropTag, DropEdge, CreateTagIndex, CreateEdgeIndex, DropTagIndex, DropEdgeIndex Write user CreateUser, DropUser, AlterUser Write role Grant, Revoke Read data Go, Set, Pipe, Match, Assignment, Lookup, Yield, OrderBy, FetchVertices, Find, FetchEdges, FindPath, Limit, GroupBy, Return Write data BuildTagIndex, BuildEdgeIndex, InsertVertex, UpdateVertex, InsertEdge, UpdateEdge, DeleteVertex, DeleteEdges Special operation Show, ChangePassword Divided by operations. OPERATION GOD ADMIN DBA USER GUEST Read space Y Y Y Y Y Write space Y Read schema Y Y Y Y Y Write schema Y Y Y Write user Y Write role Y Y Read data Y Y Y Y Y Write data Y Y Y Y Special operation Y Y Y Y Y","title":"Built-in Roles"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/built-in-roles/#built-in_roles","text":"Nebula Graph provides the following roles: God The initial root user (similar to the Root in Linux and Administrator in Windows). All the operation access. A cluster can only have one God. God manages all the spaces in the cluster. The God role is automatically initialized by meta and cannot be granted by users. Admin The administration user. Read/write access to both the schema and data limited to its authorized space. Authorization access to users limited to its authorized space. DBA Read/write access to both the schema and data limited to its authorized space. No authorization access to users. User Read/write access to data limited to its authorized space. Read-only access to the schema limited to its authorized space. Guest Read-only access to both the schema and data limited to its authorized space. If the authorization is enabled, the default user name and password are root and nebula respectively, and the user name is immutable. Set the enable_authorize parameter in the /usr/local/nebula/etc/nebula-graphd.conf file to true to enable the authorization. A user who has no assigned roles will not have any accesses to the space. A user can only have one assigned role in the same space. A user can have different roles in different spaces. The set of executor prescribed by each role are described below. Divided by operation permissions. OPERATION STATEMENTS Read space Use, DescribeSpace Write space CreateSpace, DropSpace, CreateSnapshot, DropSnapshot, Balance, Admin, Config, Ingest, Download Read schema DescribeTag, DescribeEdge, DescribeTagIndex, DescribeEdgeIndex Write schema CreateTag, AlterTag, CreateEdge, AlterEdge, DropTag, DropEdge, CreateTagIndex, CreateEdgeIndex, DropTagIndex, DropEdgeIndex Write user CreateUser, DropUser, AlterUser Write role Grant, Revoke Read data Go, Set, Pipe, Match, Assignment, Lookup, Yield, OrderBy, FetchVertices, Find, FetchEdges, FindPath, Limit, GroupBy, Return Write data BuildTagIndex, BuildEdgeIndex, InsertVertex, UpdateVertex, InsertEdge, UpdateEdge, DeleteVertex, DeleteEdges Special operation Show, ChangePassword Divided by operations. OPERATION GOD ADMIN DBA USER GUEST Read space Y Y Y Y Y Write space Y Read schema Y Y Y Y Y Write schema Y Y Y Write user Y Write role Y Y Read data Y Y Y Y Y Write data Y Y Y Y Special operation Y Y Y Y Y","title":"Built-in Roles"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/change-password/","text":"CHANGE PASSWORD Syntax \u00b6 CHANGE PASSWORD <user_name> FROM <old_psw> TO <new-psw> The CHANGE PASSWORD statement changes a password to a Nebula Graph user account. The old password is required in addition to the new one.","title":"CHANGE PASSWORD Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/change-password/#change_password_syntax","text":"CHANGE PASSWORD <user_name> FROM <old_psw> TO <new-psw> The CHANGE PASSWORD statement changes a password to a Nebula Graph user account. The old password is required in addition to the new one.","title":"CHANGE PASSWORD Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/create-user-syntax/","text":"Create User Syntax \u00b6 CREATE USER [IF NOT EXISTS] <user_name> [WITH PASSWORD <password>] The CREATE USER statement creates new Nebula Graph accounts. To use CREATE USER , you must have the global CREATE USER privilege. By default, an error occurs if you try to create a user that already exists. If the IF NOT EXISTS clause is given, the statement produces a warning for each named user that already exists, rather than an error.","title":"CREATE USER Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/create-user-syntax/#create_user_syntax","text":"CREATE USER [IF NOT EXISTS] <user_name> [WITH PASSWORD <password>] The CREATE USER statement creates new Nebula Graph accounts. To use CREATE USER , you must have the global CREATE USER privilege. By default, an error occurs if you try to create a user that already exists. If the IF NOT EXISTS clause is given, the statement produces a warning for each named user that already exists, rather than an error.","title":"Create User Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/drop-user-syntax/","text":"Drop User Syntax \u00b6 DROP USER [IF EXISTS] user_name Only God and Admin users have the DROP privilege for the sentence. DROP USER does not automatically close any already opened client session.","title":"DROP USER Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/drop-user-syntax/#drop_user_syntax","text":"DROP USER [IF EXISTS] user_name Only God and Admin users have the DROP privilege for the sentence. DROP USER does not automatically close any already opened client session.","title":"Drop User Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/grant-role-syntax/","text":"Grant Role Syntax \u00b6 GRANT ROLE <role_type> ON <space> TO <user> The GRANT statement assigns role to Nebula Graph user account. To use GRANT , you must have the GRANT privilege. Currently, there are five roles in Nebula Graph : GOD , ADMIN , DBA , USER and GUEST . Normally, first use CREATE USER to create an account then use GRANT to define its privileges (assume you have the CREATE and GRANT privilege). Each role and user account to be granted must exist, or errors will occur. The <space> clause must be specified as an existed graph space or an error will occur.","title":"GRANT ROLE Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/grant-role-syntax/#grant_role_syntax","text":"GRANT ROLE <role_type> ON <space> TO <user> The GRANT statement assigns role to Nebula Graph user account. To use GRANT , you must have the GRANT privilege. Currently, there are five roles in Nebula Graph : GOD , ADMIN , DBA , USER and GUEST . Normally, first use CREATE USER to create an account then use GRANT to define its privileges (assume you have the CREATE and GRANT privilege). Each role and user account to be granted must exist, or errors will occur. The <space> clause must be specified as an existed graph space or an error will occur.","title":"Grant Role Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/revoke-syntax/","text":"Revoke Syntax \u00b6 REVOKE ROLE <role_type> ON <space> FROM <user> The REVOKE statement removes access privileges from Nebula Graph user accounts. To use REVOKE , you must have the REVOKE privilege. Currently, there are five roles in Nebula Graph : GOD , ADMIN , DBA , USER and GUEST . User accounts and roles are to be revoked must exist, or errors will occur. The <space> clause must be specified as an existed graph space or an error will occur.","title":"REVOKE Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/account-management-statements/revoke-syntax/#revoke_syntax","text":"REVOKE ROLE <role_type> ON <space> FROM <user> The REVOKE statement removes access privileges from Nebula Graph user accounts. To use REVOKE , you must have the REVOKE privilege. Currently, there are five roles in Nebula Graph : GOD , ADMIN , DBA , USER and GUEST . User accounts and roles are to be revoked must exist, or errors will occur. The <space> clause must be specified as an existed graph space or an error will occur.","title":"Revoke Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/","text":"CONFIG Syntax \u00b6 Introduction to Configuration \u00b6 Nebula Graph gets configuration from meta by default. If you want to get configuration locally, please add the --local_config=true option in the configuration files metad.conf , storaged.conf , graphd.conf (directory is /home/user/nebula/build/install/etc ) respectively. Note: Configuration precedence: meta > console > environment variable > configuration files. If set --local_config to true, the configuration files take precedence. Restart the services after changing the configuration files to take effect. Configuration changes in console take effect in real time. gflag Parameters \u00b6 Nebula Graph uses gflags for run-time configurations. gflags parameters see the following table. Name Type Description max_edge_returned_per_vertex MUTABLE Control the max edges returned by a certain vertex. minloglevel MUTABLE Minimum log level. v MUTABLE Debug log level. heartbeat_interval_secs MUTABLE Heartbeat interval. meta_client_retry_times MUTABLE Meta client retry times. slow_op_threshhold_ms MUTABLE Default threshold for slow operation, set in ms wal_ttl MUTABLE Default value is 14400 secondes rocksdb_db_options NESTED Parameter in json format, and the key and value of them are in string format. rocksdb_column_family_options NESTED Parameter in json format, and the key and value of them are in string format. rocksdb_block_based_table_options NESTED Parameter in json format, and the key and value of them are in string format. For example, you can set as follows in the conf file of storage: rocksdb_db_options = {\"stats_dump_period_sec\":\"200\", \"enable_write_thread_adaptive_yield\":\"false\", \"write_thread_max_yield_usec\":\"600\"} rocksdb_column_family_options = {\"max_write_buffer_number\":\"4\", \"min_write_buffer_number_to_merge\":\"2\", \"max_write_buffer_number_to_maintain\":\"1\"} rocksdb_block_based_table_options = {\"block_restart_interval\":\"2\"} \"max_edge_returned_per_vertex\":\"INT_MAX\" Nebula Graph supports changing some rocksdb parameters in storage service as follows: // rocksdb_column_family_options disable_auto_compactions write_buffer_size max_write_buffer_number level0_file_num_compaction_trigger level0_slowdown_writes_trigger level0_stop_writes_trigger target_file_size_base target_file_size_multiplier max_bytes_for_level_base max_bytes_for_level_multiplier // rocksdb_db_options max_total_wal_size delete_obsolete_files_period_micros max_background_jobs stats_dump_period_sec compaction_readahead_size writable_file_max_buffer_size bytes_per_sync wal_bytes_per_sync delayed_write_rate avoid_flush_during_shutdown max_open_files For example nebula> UPDATE CONFIGS storage:rocksdb_column_family_options = \\ { disable_auto_compactions = false , level0_file_num_compaction_trigger = 10 } Reservoir Sampling Parameters \u00b6 Set the following parameters in the configuration file storaged-conf : enable_reservoir_sampling = true/false # Enable reservoir sampling with true. max_edge_returned_per_vertex = number # Set the sampling number. For super vertex with a large number of edges, currently there are two truncation strategies: Truncate directly. Set the enable_reservoir_sampling parameter to false . A certain number of edges specified in the Max_edge_returned_per_vertex parameter are truncated by default. Truncate with the reservoir sampling algorithm. Based on the algorithm, a certain number of edges specified in the Max_edge_returned_per_vertex parameter are truncated with equal probability from the total n edges. Equal probability sampling is useful in some business scenarios. However, the performance is effected compared to direct truncation due to the probability calculation. SHOW CONFIGS \u00b6 SHOW CONFIGS [graph|meta|storage] For example nebula> SHOW CONFIGS meta ============================================================================================================================ | module | name | type | mode | value | ============================================================================================================================ | META | v | INT64 | IMMUTABLE | 4 | ---------------------------------------------------------------------------------------------------------------------------- | META | help | BOOL | IMMUTABLE | False | ---------------------------------------------------------------------------------------------------------------------------- | META | port | INT64 | IMMUTABLE | 45500 | ---------------------------------------------------------------------------------------------------------------------------- Get CONFIGS \u00b6 GET CONFIGS [graph|meta|storage :] var For example nebula> GET CONFIGS storage:local_ip ======================================================= | module | name | type | mode | value | ======================================================= | STORAGE | local_ip | STRING | IMMUTABLE | 127.0.0.1 | ------------------------------------------------------- nebula> GET CONFIGS heartbeat_interval_secs ================================================================= | module | name | type | mode | value | ================================================================= | GRAPH | heartbeat_interval_secs | INT64 | MUTABLE | 10 | ----------------------------------------------------------------- | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 10 | ----------------------------------------------------------------- Update CONFIGS \u00b6 UPDATE CONFIGS [graph|meta|storage :] var = value The updated CONFIGS will be stored into meta-service permanently. If the configuration's mode is MUTABLE , the change will take effects immediately. Otherwise, if the mode is REBOOT , the change will not work until server restart. Expression is supported in UPDATE CONFIGS. For example nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1 nebula> GET CONFIGS storage:heartbeat_interval_secs =============================================================== | module | name | type | mode | value | =============================================================== | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 1 | ---------------------------------------------------------------","title":"Configs Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#config_syntax","text":"","title":"CONFIG Syntax"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#introduction_to_configuration","text":"Nebula Graph gets configuration from meta by default. If you want to get configuration locally, please add the --local_config=true option in the configuration files metad.conf , storaged.conf , graphd.conf (directory is /home/user/nebula/build/install/etc ) respectively. Note: Configuration precedence: meta > console > environment variable > configuration files. If set --local_config to true, the configuration files take precedence. Restart the services after changing the configuration files to take effect. Configuration changes in console take effect in real time.","title":"Introduction to Configuration"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#gflag_parameters","text":"Nebula Graph uses gflags for run-time configurations. gflags parameters see the following table. Name Type Description max_edge_returned_per_vertex MUTABLE Control the max edges returned by a certain vertex. minloglevel MUTABLE Minimum log level. v MUTABLE Debug log level. heartbeat_interval_secs MUTABLE Heartbeat interval. meta_client_retry_times MUTABLE Meta client retry times. slow_op_threshhold_ms MUTABLE Default threshold for slow operation, set in ms wal_ttl MUTABLE Default value is 14400 secondes rocksdb_db_options NESTED Parameter in json format, and the key and value of them are in string format. rocksdb_column_family_options NESTED Parameter in json format, and the key and value of them are in string format. rocksdb_block_based_table_options NESTED Parameter in json format, and the key and value of them are in string format. For example, you can set as follows in the conf file of storage: rocksdb_db_options = {\"stats_dump_period_sec\":\"200\", \"enable_write_thread_adaptive_yield\":\"false\", \"write_thread_max_yield_usec\":\"600\"} rocksdb_column_family_options = {\"max_write_buffer_number\":\"4\", \"min_write_buffer_number_to_merge\":\"2\", \"max_write_buffer_number_to_maintain\":\"1\"} rocksdb_block_based_table_options = {\"block_restart_interval\":\"2\"} \"max_edge_returned_per_vertex\":\"INT_MAX\" Nebula Graph supports changing some rocksdb parameters in storage service as follows: // rocksdb_column_family_options disable_auto_compactions write_buffer_size max_write_buffer_number level0_file_num_compaction_trigger level0_slowdown_writes_trigger level0_stop_writes_trigger target_file_size_base target_file_size_multiplier max_bytes_for_level_base max_bytes_for_level_multiplier // rocksdb_db_options max_total_wal_size delete_obsolete_files_period_micros max_background_jobs stats_dump_period_sec compaction_readahead_size writable_file_max_buffer_size bytes_per_sync wal_bytes_per_sync delayed_write_rate avoid_flush_during_shutdown max_open_files For example nebula> UPDATE CONFIGS storage:rocksdb_column_family_options = \\ { disable_auto_compactions = false , level0_file_num_compaction_trigger = 10 }","title":"gflag Parameters"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#reservoir_sampling_parameters","text":"Set the following parameters in the configuration file storaged-conf : enable_reservoir_sampling = true/false # Enable reservoir sampling with true. max_edge_returned_per_vertex = number # Set the sampling number. For super vertex with a large number of edges, currently there are two truncation strategies: Truncate directly. Set the enable_reservoir_sampling parameter to false . A certain number of edges specified in the Max_edge_returned_per_vertex parameter are truncated by default. Truncate with the reservoir sampling algorithm. Based on the algorithm, a certain number of edges specified in the Max_edge_returned_per_vertex parameter are truncated with equal probability from the total n edges. Equal probability sampling is useful in some business scenarios. However, the performance is effected compared to direct truncation due to the probability calculation.","title":"Reservoir Sampling Parameters"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#show_configs","text":"SHOW CONFIGS [graph|meta|storage] For example nebula> SHOW CONFIGS meta ============================================================================================================================ | module | name | type | mode | value | ============================================================================================================================ | META | v | INT64 | IMMUTABLE | 4 | ---------------------------------------------------------------------------------------------------------------------------- | META | help | BOOL | IMMUTABLE | False | ---------------------------------------------------------------------------------------------------------------------------- | META | port | INT64 | IMMUTABLE | 45500 | ----------------------------------------------------------------------------------------------------------------------------","title":"SHOW CONFIGS"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#get_configs","text":"GET CONFIGS [graph|meta|storage :] var For example nebula> GET CONFIGS storage:local_ip ======================================================= | module | name | type | mode | value | ======================================================= | STORAGE | local_ip | STRING | IMMUTABLE | 127.0.0.1 | ------------------------------------------------------- nebula> GET CONFIGS heartbeat_interval_secs ================================================================= | module | name | type | mode | value | ================================================================= | GRAPH | heartbeat_interval_secs | INT64 | MUTABLE | 10 | ----------------------------------------------------------------- | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 10 | -----------------------------------------------------------------","title":"Get CONFIGS"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/configs-syntax/#update_configs","text":"UPDATE CONFIGS [graph|meta|storage :] var = value The updated CONFIGS will be stored into meta-service permanently. If the configuration's mode is MUTABLE , the change will take effects immediately. Otherwise, if the mode is REBOOT , the change will not work until server restart. Expression is supported in UPDATE CONFIGS. For example nebula> UPDATE CONFIGS storage:heartbeat_interval_secs=1 nebula> GET CONFIGS storage:heartbeat_interval_secs =============================================================== | module | name | type | mode | value | =============================================================== | STORAGE | heartbeat_interval_secs | INT64 | MUTABLE | 1 | ---------------------------------------------------------------","title":"Update CONFIGS"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/","text":"Logs \u00b6 Nebula Graph uses glog to print logs, gflag to control the severity level of the log, and provides an HTTP interface to dynamically change the log level at runtime to facilitate tracking. Log File Location \u00b6 Logs are stored under /usr/local/nebula/logs/ by default. If you delete the entire log directory ( rm -rf ./* ) at runtime, no logs will output thereafter. You can restart the process to resume log output. Parameter Description \u00b6 Two most commonly used flags in glog \u00b6 minloglevel 0-3: the numbers of severity levels INFO(DEBUG), WARNING, ERROR, and FATAL are 0, 1, 2, and 3, respectively. Usually specified as 0 in debug, 1 in production. If you set the minloglevel to 4, no logs are printed. v 0-4: when minloglevel is set to 0, you can further set the severity level of the debug log. The larger the value, the more detailed the log. Configuration Files \u00b6 The default severity level for the metad, graphd, storaged logs can be found in the configuration files (usually under /usr/local/nebula/etc/ ). Check and Change Severity Levels Dynamically \u00b6 Check all the flag values (log values included) of the current glags with the following command. > curl ${ ws_ip } : ${ ws_port } /get_flags Parameters: ws_ip is the HTTP service IP, which can be found in the above configuration files (default IP is 127.0.0.1) ws_port is the HTTP port, the default value for metad is 11000, storaged is 12000 and graphd is 13000 For example, check the severity minloglevel of storaged: > curl 127 .0.0.1:12000/get_flags | grep minloglevel # storage > curl 127 .0.0.1:13000/get_flags # metad Change the logs severity level to most detailed with the following command. > curl \"http://127.0.0.1:12000/set_flags?flag=v&value=3\" > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=0\" In Nebula Graph console, check the severity minloglevel of graphd and set it to most detailed with the following commands. nebula> GET CONFIGS graph:minloglevel nebula> UPDATE CONFIGS graph:minloglevel=0 To change the severity of the storage log, replace graph in the above command with storage . Note that Nebula Graph only supports modifying the graph and storage log severity via console, meta log cannot be changed. Or close all logs print (FATAL only). > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=3\"","title":"Logs"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#logs","text":"Nebula Graph uses glog to print logs, gflag to control the severity level of the log, and provides an HTTP interface to dynamically change the log level at runtime to facilitate tracking.","title":"Logs"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#log_file_location","text":"Logs are stored under /usr/local/nebula/logs/ by default. If you delete the entire log directory ( rm -rf ./* ) at runtime, no logs will output thereafter. You can restart the process to resume log output.","title":"Log File Location"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#parameter_description","text":"","title":"Parameter Description"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#two_most_commonly_used_flags_in_glog","text":"minloglevel 0-3: the numbers of severity levels INFO(DEBUG), WARNING, ERROR, and FATAL are 0, 1, 2, and 3, respectively. Usually specified as 0 in debug, 1 in production. If you set the minloglevel to 4, no logs are printed. v 0-4: when minloglevel is set to 0, you can further set the severity level of the debug log. The larger the value, the more detailed the log.","title":"Two most commonly used flags in glog"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#configuration_files","text":"The default severity level for the metad, graphd, storaged logs can be found in the configuration files (usually under /usr/local/nebula/etc/ ).","title":"Configuration Files"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/configuration-statements/log/#check_and_change_severity_levels_dynamically","text":"Check all the flag values (log values included) of the current glags with the following command. > curl ${ ws_ip } : ${ ws_port } /get_flags Parameters: ws_ip is the HTTP service IP, which can be found in the above configuration files (default IP is 127.0.0.1) ws_port is the HTTP port, the default value for metad is 11000, storaged is 12000 and graphd is 13000 For example, check the severity minloglevel of storaged: > curl 127 .0.0.1:12000/get_flags | grep minloglevel # storage > curl 127 .0.0.1:13000/get_flags # metad Change the logs severity level to most detailed with the following command. > curl \"http://127.0.0.1:12000/set_flags?flag=v&value=3\" > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=0\" In Nebula Graph console, check the severity minloglevel of graphd and set it to most detailed with the following commands. nebula> GET CONFIGS graph:minloglevel nebula> UPDATE CONFIGS graph:minloglevel=0 To change the severity of the storage log, replace graph in the above command with storage . Note that Nebula Graph only supports modifying the graph and storage log severity via console, meta log cannot be changed. Or close all logs print (FATAL only). > curl \"http://127.0.0.1:12000/set_flags?flag=minloglevel&value=3\"","title":"Check and Change Severity Levels Dynamically"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/","text":"Graph Metrics \u00b6 Introduction \u00b6 Currently, Nebula Graph supports obtaining the basic performance metric for the graph service via HTTP. Each performance metrics consists of three parts, namely <counter_name>.<statistic_type>.<time_range> . Counter Names \u00b6 Each counter name is composed of the interface name and the counter name. Currently, the supported interfaces are: graph_storageClient // Requests sent via storageClient, when sending requests to multiple storages concurrently, counted as one graph_metaClient // Requests sent via metaClient graph_graph_all // Requests sent by the client to the graph, when a request contains multiple queries, counted as one graph_insertVertex // Insert a vertex graph_insertEdge // Insert an edge graph_deleteVertex // Delete a vertex graph_deleteEdge // Delete an edge // Not supported yet graph_updateVertex // Update properties of a vertex graph_updateEdge // Update properties of an edge graph_go // Execute the go command graph_findPath // Find the shortest path or the full path graph_fetchVertex // Fetch the vertex's properties. Only count the commands executed rather than the total number of fetched vertices. graph_fetchEdge // Fetch the edge's properties. Only count the commands executed rather than the total number of fetched edges. Each interface has three metrics, namely latency (in the units of us), QPS and QPS with errors. The suffixes are as follows: _latency _qps _error_qps The complete metric concatenates the interface name with the corresponding metric, such as graph_insertVertex_latency , graph_insertVertex_qps and graph_insertVertex_error_qps , representing the latency of inserting a vertex, QPS and the QPS with errors, respectively. Statistics Type \u00b6 Currently supported types are SUM, COUNT, AVG, RATE and P quantiles (P99, P999, ..., P999999). Among which: Metrics have suffixes _qps and _error_qps support SUM, COUNT, AVG, RATE but don't support P quantiles. Metrics have suffixes _latency support SUM, COUNT, AVG, RATE, and P quantiles. Time Range \u00b6 Currently, the supported time ranges are 60s, 600s, and 3600s, which correspond to the last minute, the last ten minutes, and the last hour till now. Obtain the Corresponding Metrics via HTTP Interface \u00b6 According to the above introduction, you can make a complete metrics name. Here are some examples: graph_insertVertex_latency . avg .60 // the average latency of successfully inserting a vertex in the last minute graph_updateEdge_error_qps . count .3600 // total number of failures in updating an edge in the last hour Assume that a graph service is started locally, and the ws_http_port port number is set to 13000 when starting. It is sent through the GET interface of HTTP. The method name is get_stats , and the parameter is stats plus the corresponding metrics name. Here's an example of getting metrics via the HTTP interface: # obtain a metrics curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60\" # graph_insertVertex_qps.rate.60=3069 # obtain multiple metrics at the same time curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60\" # graph_insertVertex_qps.rate.60=3069 # graph_deleteVertex_latency.avg.60=837 # obtain multiple metrics at the same time and return in json format curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60&returnjson\" # [{\"value\":2373,\"name\":\"graph_insertVertex_qps.rate.60\"},{\"value\":760,\"name\":\"graph_deleteVertex_latency.avg.60\"}] # obtain all the metrics curl -G \"http://127.0.0.1:13000/get_stats?stats\" # or curl -G \"http://127.0.0.1:13000/get_stats\"","title":"Graph Metrics"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#graph_metrics","text":"","title":"Graph Metrics"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#introduction","text":"Currently, Nebula Graph supports obtaining the basic performance metric for the graph service via HTTP. Each performance metrics consists of three parts, namely <counter_name>.<statistic_type>.<time_range> .","title":"Introduction"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#counter_names","text":"Each counter name is composed of the interface name and the counter name. Currently, the supported interfaces are: graph_storageClient // Requests sent via storageClient, when sending requests to multiple storages concurrently, counted as one graph_metaClient // Requests sent via metaClient graph_graph_all // Requests sent by the client to the graph, when a request contains multiple queries, counted as one graph_insertVertex // Insert a vertex graph_insertEdge // Insert an edge graph_deleteVertex // Delete a vertex graph_deleteEdge // Delete an edge // Not supported yet graph_updateVertex // Update properties of a vertex graph_updateEdge // Update properties of an edge graph_go // Execute the go command graph_findPath // Find the shortest path or the full path graph_fetchVertex // Fetch the vertex's properties. Only count the commands executed rather than the total number of fetched vertices. graph_fetchEdge // Fetch the edge's properties. Only count the commands executed rather than the total number of fetched edges. Each interface has three metrics, namely latency (in the units of us), QPS and QPS with errors. The suffixes are as follows: _latency _qps _error_qps The complete metric concatenates the interface name with the corresponding metric, such as graph_insertVertex_latency , graph_insertVertex_qps and graph_insertVertex_error_qps , representing the latency of inserting a vertex, QPS and the QPS with errors, respectively.","title":"Counter Names"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#statistics_type","text":"Currently supported types are SUM, COUNT, AVG, RATE and P quantiles (P99, P999, ..., P999999). Among which: Metrics have suffixes _qps and _error_qps support SUM, COUNT, AVG, RATE but don't support P quantiles. Metrics have suffixes _latency support SUM, COUNT, AVG, RATE, and P quantiles.","title":"Statistics Type"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#time_range","text":"Currently, the supported time ranges are 60s, 600s, and 3600s, which correspond to the last minute, the last ten minutes, and the last hour till now.","title":"Time Range"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/graph-service-administration/graph-metrics/#obtain_the_corresponding_metrics_via_http_interface","text":"According to the above introduction, you can make a complete metrics name. Here are some examples: graph_insertVertex_latency . avg .60 // the average latency of successfully inserting a vertex in the last minute graph_updateEdge_error_qps . count .3600 // total number of failures in updating an edge in the last hour Assume that a graph service is started locally, and the ws_http_port port number is set to 13000 when starting. It is sent through the GET interface of HTTP. The method name is get_stats , and the parameter is stats plus the corresponding metrics name. Here's an example of getting metrics via the HTTP interface: # obtain a metrics curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60\" # graph_insertVertex_qps.rate.60=3069 # obtain multiple metrics at the same time curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60\" # graph_insertVertex_qps.rate.60=3069 # graph_deleteVertex_latency.avg.60=837 # obtain multiple metrics at the same time and return in json format curl -G \"http://127.0.0.1:13000/get_stats?stats=graph_insertVertex_qps.rate.60, graph_deleteVertex_latency.avg.60&returnjson\" # [{\"value\":2373,\"name\":\"graph_insertVertex_qps.rate.60\"},{\"value\":760,\"name\":\"graph_deleteVertex_latency.avg.60\"}] # obtain all the metrics curl -G \"http://127.0.0.1:13000/get_stats?stats\" # or curl -G \"http://127.0.0.1:13000/get_stats\"","title":"Obtain the Corresponding Metrics via HTTP Interface"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/","text":"Meta Metrics \u00b6 Introduction \u00b6 Currently, Nebula Graph supports obtaining the basic performance metrics for the meta service via HTTP. Each performance metric consists of three parts, namely <counter_name>.<statistic_type>.<time_range> . Counter Names \u00b6 Each counter name is composed of the interface name and the counter name. Meta service only counts the heartbeat. Currently, the supported interfaces are: meta_heartbeat_qps meta_heartbeat_error_qps meta_heartbeat_latency Statistics Type \u00b6 Currently supported types are SUM, COUNT, AVG, RATE and P quantiles (P99, P999, ..., P999999). Among which: Metrics have suffixes _qps and _error_qps support SUM, COUNT, AVG, RATE but don't support P quantiles. Metrics have suffixes _latency support SUM, COUNT, AVG, RATE, and P quantiles. Time Range \u00b6 Currently, the supported time ranges are 60s, 600s, and 3600s, which correspond to the last minute, the last ten minutes, and the last hour till now. Obtain the Corresponding Metrics via HTTP Interface \u00b6 Here are some examples: meta_heartbeat_qps . avg .60 // the average QPS of the heart beat in the last minute meta_heartbeat_error_qps . count .60 // the total errors occurred of the heart beat in the last minute meta_heartbeat_latency . avg .60 // the average latency of the heart beat in the last minute Assume that a Nebula Graph meta service is started locally, and the ws_http_port port number is set to 11000 when starting. It is sent through the GET interface of HTTP. The method name is get_stats , and the parameter is stats plus the corresponding metrics name. Here's an example of getting metrics via the HTTP interface: # obtain a metrics curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60\" # meta_heartbeat_qps.avg.60=580 # obtain multiple metrics at the same time curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60\" # meta_heartbeat_qps.avg.60=537 # meta_heartbeat_error_qps.avg.60=579 # obtain multiple metrics at the same time and return in json format curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60&returnjson\" # [{\"value\":533,\"name\":\"meta_heartbeat_qps.avg.60\"},{\"value\":574,\"name\":\"meta_heartbeat_error_qps.avg.60\"}] # obtain all the metrics curl -G \"http://127.0.0.1:11000/get_stats?stats\" # or curl -G \"http://127.0.0.1:11000/get_stats\"","title":"Meta Metrics"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#meta_metrics","text":"","title":"Meta Metrics"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#introduction","text":"Currently, Nebula Graph supports obtaining the basic performance metrics for the meta service via HTTP. Each performance metric consists of three parts, namely <counter_name>.<statistic_type>.<time_range> .","title":"Introduction"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#counter_names","text":"Each counter name is composed of the interface name and the counter name. Meta service only counts the heartbeat. Currently, the supported interfaces are: meta_heartbeat_qps meta_heartbeat_error_qps meta_heartbeat_latency","title":"Counter Names"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#statistics_type","text":"Currently supported types are SUM, COUNT, AVG, RATE and P quantiles (P99, P999, ..., P999999). Among which: Metrics have suffixes _qps and _error_qps support SUM, COUNT, AVG, RATE but don't support P quantiles. Metrics have suffixes _latency support SUM, COUNT, AVG, RATE, and P quantiles.","title":"Statistics Type"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#time_range","text":"Currently, the supported time ranges are 60s, 600s, and 3600s, which correspond to the last minute, the last ten minutes, and the last hour till now.","title":"Time Range"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/meta-service-administration/meta-metrics/#obtain_the_corresponding_metrics_via_http_interface","text":"Here are some examples: meta_heartbeat_qps . avg .60 // the average QPS of the heart beat in the last minute meta_heartbeat_error_qps . count .60 // the total errors occurred of the heart beat in the last minute meta_heartbeat_latency . avg .60 // the average latency of the heart beat in the last minute Assume that a Nebula Graph meta service is started locally, and the ws_http_port port number is set to 11000 when starting. It is sent through the GET interface of HTTP. The method name is get_stats , and the parameter is stats plus the corresponding metrics name. Here's an example of getting metrics via the HTTP interface: # obtain a metrics curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60\" # meta_heartbeat_qps.avg.60=580 # obtain multiple metrics at the same time curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60\" # meta_heartbeat_qps.avg.60=537 # meta_heartbeat_error_qps.avg.60=579 # obtain multiple metrics at the same time and return in json format curl -G \"http://127.0.0.1:11000/get_stats?stats=meta_heartbeat_qps.avg.60,meta_heartbeat_error_qps.avg.60&returnjson\" # [{\"value\":533,\"name\":\"meta_heartbeat_qps.avg.60\"},{\"value\":574,\"name\":\"meta_heartbeat_error_qps.avg.60\"}] # obtain all the metrics curl -G \"http://127.0.0.1:11000/get_stats?stats\" # or curl -G \"http://127.0.0.1:11000/get_stats\"","title":"Obtain the Corresponding Metrics via HTTP Interface"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/","text":"Cluster Snapshot \u00b6 Create Snapshot \u00b6 The CREATE SNAPSHOT command creates a snapshot at the current point in time for the whole cluster. The snapshot name is composed of the timestamp of the meta server. If snapshot creation fails in the current version, you must use the DROP SNAPSHOT to clear the invalid snapshots. The current version does not support creating snapshot for the specified graph spaces, and executing CREATE SNAPSHOT creates a snapshot for all graph spaces in the cluster. For example: nebula> CREATE SNAPSHOT; Execution succeeded (Time spent: 22892/23923 us) Show Snapshots \u00b6 The command SHOW SNAPSHOT looks at the states (VALID or INVALID), names and the IP addresses of all storage servers when the snapshots are created in the cluster. For example: nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_36 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- Delete Snapshot \u00b6 The DROP SNAPSHOT command deletes a snapshot with the specified name, the syntax is: DROP SNAPSHOT <snapshot-name> You can get the snapshot names with the command SHOW SNAPSHOTS . DROP SNAPSHOT can delete both valid snapshots and invalid snapshots that failed during creation. For example: nebula> DROP SNAPSHOT SNAPSHOT_2019_12_04_10_54_36; nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- Now the deletes snapshot is not in the show snapshots list. Tips \u00b6 When the system structure changes, it is better to create a snapshot immediately. For example, when you add host, drop host, create space, drop space or balance. The current version does not support automatic garbage collection for the failed snapshots in creation. We will develop cluster checker in meta server to check the cluster state via asynchronous threads and automatically collect the garbage files in failure snapshot creation. The current version does not support customized snapshot directory. The snapshots are created in the data_path/nebula directory by default. The current version does not support snapshot restore. Users need to write a shell script based on their actual productions to restore snapshots. The implementation logic is rather simple, you copy the snapshots of the engine servers to the specified folder, set this folder to data_path/ , then start the cluster.","title":"Cluster Snapshot"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#cluster_snapshot","text":"","title":"Cluster Snapshot"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#create_snapshot","text":"The CREATE SNAPSHOT command creates a snapshot at the current point in time for the whole cluster. The snapshot name is composed of the timestamp of the meta server. If snapshot creation fails in the current version, you must use the DROP SNAPSHOT to clear the invalid snapshots. The current version does not support creating snapshot for the specified graph spaces, and executing CREATE SNAPSHOT creates a snapshot for all graph spaces in the cluster. For example: nebula> CREATE SNAPSHOT; Execution succeeded (Time spent: 22892/23923 us)","title":"Create Snapshot"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#show_snapshots","text":"The command SHOW SNAPSHOT looks at the states (VALID or INVALID), names and the IP addresses of all storage servers when the snapshots are created in the cluster. For example: nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_36 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | -----------------------------------------------------------","title":"Show Snapshots"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#delete_snapshot","text":"The DROP SNAPSHOT command deletes a snapshot with the specified name, the syntax is: DROP SNAPSHOT <snapshot-name> You can get the snapshot names with the command SHOW SNAPSHOTS . DROP SNAPSHOT can delete both valid snapshots and invalid snapshots that failed during creation. For example: nebula> DROP SNAPSHOT SNAPSHOT_2019_12_04_10_54_36; nebula> SHOW SNAPSHOTS; =========================================================== | Name | Status | Hosts | =========================================================== | SNAPSHOT_2019_12_04_10_54_42 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- | SNAPSHOT_2019_12_04_10_54_44 | VALID | 127.0.0.1:77833 | ----------------------------------------------------------- Now the deletes snapshot is not in the show snapshots list.","title":"Delete Snapshot"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/cluster-snapshot/#tips","text":"When the system structure changes, it is better to create a snapshot immediately. For example, when you add host, drop host, create space, drop space or balance. The current version does not support automatic garbage collection for the failed snapshots in creation. We will develop cluster checker in meta server to check the cluster state via asynchronous threads and automatically collect the garbage files in failure snapshot creation. The current version does not support customized snapshot directory. The snapshots are created in the data_path/nebula directory by default. The current version does not support snapshot restore. Users need to write a shell script based on their actual productions to restore snapshots. The implementation logic is rather simple, you copy the snapshots of the engine servers to the specified folder, set this folder to data_path/ , then start the cluster.","title":"Tips"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/","text":"Job Manager \u00b6 The job here refers to the long tasks running at the storage layer. For example, compact and flush . The manager means to manage the jobs. For example, you can run, show, stop and recover jobs. Statements List \u00b6 submit job compact / flush \u00b6 The submit job compact/flush statement creates a new job and returns the job ID in the job manager, and executes the compact/flush command in the storage. The example is as follows: nebula> SUBMIT JOB COMPACT; ============== | New Job Id | ============== | 40 | -------------- nebula> SUBMIT JOB FLUSH; ============== | New Job Id | ============== | 2 | -------------- SHOW JOB \u00b6 List Single Job Information \u00b6 The SHOW JOB <job_id> statement shows a job with certain ID and all its tasks. After a job arrives to Meta, Meta will split the job to tasks, and send them to storage. nebula> SHOW JOB 40 ===================================================================================== | Job Id(TaskId) | Command(Dest) | Status | Start Time | Stop Time | ===================================================================================== | 40 | flush nba | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- | 40-0 | 192.168.8.5 | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- The above statement returns one to multiple rows, which is determined by the storage number where the space is located. What's in the returned results: 40 is the job ID flush nba indicates that a flush operation is performed on space nba finished is the job status, which indicates that the job execution is finished and successful. Other job status are Queue, running, failed and stopped 12/17/19 17:21:30 is the start time, which is initially empty(Queue). The value is set if and only if the job status is running. 12/17/19 17:21:30 is the stop time, which is empty when the job status is Queue or running. The value is set when the job status is finished, failed and stopped 40-0 indicated that the job ID is 40, the task ID is 0 192.168.8.5 shows which machine the job is running on finished is the job status, which indicates that the job execution is finished and successful. Other job status are Queue, running, failed and stopped 12/17/19 17:21:30 is the start time, which can never be empty because the initial status is running 12/17/19 17:21:30 is the end time, which is empty when the job status is running. The value is set when the job status is finished, failed and stopped Note: There are five job status, i.e. QUEUE, RUNNING, FINISHED, FAILED, STOPPED. Status switching is described below: Queue -- running -- finished -- removed \\ \\ / \\ \\ -- failed -- / \\ \\ / \\ ---------- stopped -/ List All Jobs \u00b6 The SHOW JOBS statement lists all the jobs that are not expired. The default job expiration time is one week. You can change it with meta flag job_expired_secs . nebula> SHOW JOBS ============================================================================= | Job Id | Command | Status | Start Time | Stop Time | ============================================================================= | 22 | flush test2 | failed | 12/06/19 14:46:22 | 12/06/19 14:46:22 | ----------------------------------------------------------------------------- | 23 | compact test2 | stopped | 12/06/19 15:07:09 | 12/06/19 15:07:33 | ----------------------------------------------------------------------------- | 24 | compact test2 | stopped | 12/06/19 15:07:11 | 12/06/19 15:07:20 | ----------------------------------------------------------------------------- | 25 | compact test2 | stopped | 12/06/19 15:07:13 | 12/06/19 15:07:24 | ----------------------------------------------------------------------------- For details on the returned results, please refer to the previous section List Single Job Information . STOP JOB \u00b6 The STOP JOB statement stops jobs that are not finished. nebula> STOP JOB 22 ========================= | STOP Result | ========================= | stop 1 jobs 2 tasks | ------------------------- RECOVER JOB \u00b6 The RECOVER JOB statement re-executes the failed jobs and returns the number of the recovered jobs. nebula> RECOVER JOB ===================== | Recovered job num | ===================== | 5 job recovered | ---------------------","title":"Job Manager"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#job_manager","text":"The job here refers to the long tasks running at the storage layer. For example, compact and flush . The manager means to manage the jobs. For example, you can run, show, stop and recover jobs.","title":"Job Manager"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#statements_list","text":"","title":"Statements List"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#submit_job_compact_flush","text":"The submit job compact/flush statement creates a new job and returns the job ID in the job manager, and executes the compact/flush command in the storage. The example is as follows: nebula> SUBMIT JOB COMPACT; ============== | New Job Id | ============== | 40 | -------------- nebula> SUBMIT JOB FLUSH; ============== | New Job Id | ============== | 2 | --------------","title":"submit job compact / flush"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#show_job","text":"","title":"SHOW JOB"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#list_single_job_information","text":"The SHOW JOB <job_id> statement shows a job with certain ID and all its tasks. After a job arrives to Meta, Meta will split the job to tasks, and send them to storage. nebula> SHOW JOB 40 ===================================================================================== | Job Id(TaskId) | Command(Dest) | Status | Start Time | Stop Time | ===================================================================================== | 40 | flush nba | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- | 40-0 | 192.168.8.5 | finished | 12/17/19 17:21:30 | 12/17/19 17:21:30 | ------------------------------------------------------------------------------------- The above statement returns one to multiple rows, which is determined by the storage number where the space is located. What's in the returned results: 40 is the job ID flush nba indicates that a flush operation is performed on space nba finished is the job status, which indicates that the job execution is finished and successful. Other job status are Queue, running, failed and stopped 12/17/19 17:21:30 is the start time, which is initially empty(Queue). The value is set if and only if the job status is running. 12/17/19 17:21:30 is the stop time, which is empty when the job status is Queue or running. The value is set when the job status is finished, failed and stopped 40-0 indicated that the job ID is 40, the task ID is 0 192.168.8.5 shows which machine the job is running on finished is the job status, which indicates that the job execution is finished and successful. Other job status are Queue, running, failed and stopped 12/17/19 17:21:30 is the start time, which can never be empty because the initial status is running 12/17/19 17:21:30 is the end time, which is empty when the job status is running. The value is set when the job status is finished, failed and stopped Note: There are five job status, i.e. QUEUE, RUNNING, FINISHED, FAILED, STOPPED. Status switching is described below: Queue -- running -- finished -- removed \\ \\ / \\ \\ -- failed -- / \\ \\ / \\ ---------- stopped -/","title":"List Single Job Information"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#list_all_jobs","text":"The SHOW JOBS statement lists all the jobs that are not expired. The default job expiration time is one week. You can change it with meta flag job_expired_secs . nebula> SHOW JOBS ============================================================================= | Job Id | Command | Status | Start Time | Stop Time | ============================================================================= | 22 | flush test2 | failed | 12/06/19 14:46:22 | 12/06/19 14:46:22 | ----------------------------------------------------------------------------- | 23 | compact test2 | stopped | 12/06/19 15:07:09 | 12/06/19 15:07:33 | ----------------------------------------------------------------------------- | 24 | compact test2 | stopped | 12/06/19 15:07:11 | 12/06/19 15:07:20 | ----------------------------------------------------------------------------- | 25 | compact test2 | stopped | 12/06/19 15:07:13 | 12/06/19 15:07:24 | ----------------------------------------------------------------------------- For details on the returned results, please refer to the previous section List Single Job Information .","title":"List All Jobs"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#stop_job","text":"The STOP JOB statement stops jobs that are not finished. nebula> STOP JOB 22 ========================= | STOP Result | ========================= | stop 1 jobs 2 tasks | -------------------------","title":"STOP JOB"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/job-manager/#recover_job","text":"The RECOVER JOB statement re-executes the failed jobs and returns the number of the recovered jobs. nebula> RECOVER JOB ===================== | Recovered job num | ===================== | 5 job recovered | ---------------------","title":"RECOVER JOB"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/","text":"Storage Balance Usage \u00b6 Nebula Graph 's services are composed of three parts: graphd, storaged and metad. The balance in this document focuses on the operation of storage. Currently, storage can be scaled horizontally by the command balance . There are two kinds of balance command, one is to move data, which is BALANCE DATA ; the other one only changes the distribution of leader partition to balance load without moving data, which is BALANCE LEADER . Balance data \u00b6 Let's use an example to expand the cluster from 3 instances to 8 to show how to BALANCE DATA. Step 1 Prerequisites \u00b6 Deploy a cluster with three replicas, one graphd, one metad and three storaged. Check cluster status using command SHOW HOSTS . Step 1.1 \u00b6 nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ Explanations on the returned results: IP and Port are the present storage instance, the cluster starts with three storaged instances (192.168.8.210:34600, 192.168.8.210:34700, 192.168.8.210:34500) without any data. Status shows the state of the present instance, currently there are two kind of states, i.e. online/offline. When a machine is out of service, metad will turn it to offline if no heart beat received for certain time threshold. The default threshold is 10 minutes and can be changed in parameter expired_threshold_sec when starting metad service. Leader count shows RAFT leader number of the present process. Leader distribution shows how the present leader is distributed in each graph space. No space is created for now. Partition distribution shows how many partitions are served by each host. Step 1.2 \u00b6 Create a graph space named test with 100 partition and 3 replicas. nebula> CREATE SPACE test(PARTITION_NUM=100, REPLICA_FACTOR=3) Get the new partition distribution by the command SHOW HOSTS . nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------ Step 2 Add new hosts into the cluster \u00b6 Now, add some new hosts (storaged instances) into the cluster. Again, show the new status using command SHOW HOSTS . You can see there are already eight hosts in serving. But no partition is running on the new hosts. nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ Step 3 Data migration \u00b6 Check the current balance plan ID using command BALANCE DATA if the cluster is balanced. Otherwise, a new plan ID will be generated by the command. nebula> BALANCE DATA ============== | ID | ============== | 1570761786 | -------------- Check the progress of balance using command BALANCE DATA $id . nebula> BALANCE DATA 1570761786 =============================================================================== | balanceId, spaceId:partId, src->dst | status | =============================================================================== | [1570761786, 1:1, 192.168.8.210:34600->192.168.8.210:44920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34700->192.168.8.210:34920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34500->192.168.8.210:34800] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:2, 192.168.8.210:34600->192.168.8.210:44920] | in progress | ------------------------------------------------------------------------------- | [1570761786, 1:2, 192.168.8.210:34700->192.168.8.210:34920] | in progress | ------------------------------------------------------------------------------- | [1570761786, 1:2, 192.168.8.210:34500->192.168.8.210:34800] | in progress | ------------------------------------------------------------------------------- | [1570761786, 1:3, 192.168.8.210:34600->192.168.8.210:44920] | succeeded | ------------------------------------------------------------------------------- ... | Total:189, Succeeded:170, Failed:0, In Progress:19, Invalid:0 | 89.947090% | Explanations on the returned results: The first column is a specific balance task. Take 1570761786, 1:88, 192.168.8.210:34700->192.168.8.210:35940 for example 1570761786 is the balance ID 1:88 , 1 is the spaceId, 88 is the moved partId 192.168.8.210:34700->192.168.8.210:3594 , moving data from 192.168.8.210:34700 to 192.168.8.210:35940 The second column shows the state (result) of the task, there are four states: Succeeded Failed In progress Invalid The last row is the summary of the tasks. Some partitions are yet to be migrated. Step 4 Migration confirmation \u00b6 In most cases, data migration will take hours or even days. During the migration, Nebula Graph services are not affected. Once migration is done, the progress will show 100%. You can retry BALANCE DATA to fix a failed task. If it can't be fixed after several attempts, please contact us at GitHub . Now, you can check partition distribution using command SHOW HOSTS when balance completed. nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 3 | test: 3 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | test: 0 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 35 | test: 35 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 24 | test: 24 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 38 | test: 38 | test: 38 | ------------------------------------------------------------------------------------------------ Now partitions and data are evenly distributed on the machines. Balance stop \u00b6 BALANCE DATA STOP command stops the running balance data plan. If there is no running balance plan, an error is thrown. If there is a running plan, the related plan ID is returned. Since each balance plan includes several balance tasks, BALANCE DATA STOP doesn't stop the started tasks , but rather cancel the subsequent tasks. The started tasks will continue until the executions are completed. Input BALANCE DATA $id after BALANCE DATA STOP to check the status of the stopped balance plan. After all the tasks being executed are completed, rerun the BALANCE DATA command to restart balance. If there are failed tasks in the stopped plan, the plan will continue. Otherwise, if all the tasks are succeed, a new balance plan is created and executed. Batch Scale in \u00b6 Nebula supports specifying hosts that need to go offline to conduct batch scale in. The syntax is BALANCE DATA REMOVE $host_list . For example, statement BALANCE DATA REMOVE 192.168.0.1:50000,192.168.0.2:50000 removes two hosts, i.e. 192.168.0.1:50000\uff0c192.168.0.2:50000, during the balance process. If replica number cannot meet the requirement after removing (for example, the number of remaining hosts is less than the number of replicas or when one of the three replica is offline, one of the remaining two replicas is required to be removed), Nebula Graph will reject the balance request and return an error code. Balance leader \u00b6 Command BALANCE DATA only migrates partitions. But the leader distribution remains unbalanced, which means old hosts are overloaded, while the new ones are not fully used. Redistribute RAFT leader using the command BALANCE LEADER . nebula> BALANCE LEADER Seconds later, check the results using the command SHOW HOSTS . The RAFT leaders are distributed evenly over all the hosts in the cluster. nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------","title":"Storage Balance"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#storage_balance_usage","text":"Nebula Graph 's services are composed of three parts: graphd, storaged and metad. The balance in this document focuses on the operation of storage. Currently, storage can be scaled horizontally by the command balance . There are two kinds of balance command, one is to move data, which is BALANCE DATA ; the other one only changes the distribution of leader partition to balance load without moving data, which is BALANCE LEADER .","title":"Storage Balance Usage"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#balance_data","text":"Let's use an example to expand the cluster from 3 instances to 8 to show how to BALANCE DATA.","title":"Balance data"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_1_prerequisites","text":"Deploy a cluster with three replicas, one graphd, one metad and three storaged. Check cluster status using command SHOW HOSTS .","title":"Step 1 Prerequisites"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_11","text":"nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ Explanations on the returned results: IP and Port are the present storage instance, the cluster starts with three storaged instances (192.168.8.210:34600, 192.168.8.210:34700, 192.168.8.210:34500) without any data. Status shows the state of the present instance, currently there are two kind of states, i.e. online/offline. When a machine is out of service, metad will turn it to offline if no heart beat received for certain time threshold. The default threshold is 10 minutes and can be changed in parameter expired_threshold_sec when starting metad service. Leader count shows RAFT leader number of the present process. Leader distribution shows how the present leader is distributed in each graph space. No space is created for now. Partition distribution shows how many partitions are served by each host.","title":"Step 1.1"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_12","text":"Create a graph space named test with 100 partition and 3 replicas. nebula> CREATE SPACE test(PARTITION_NUM=100, REPLICA_FACTOR=3) Get the new partition distribution by the command SHOW HOSTS . nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------","title":"Step 1.2"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_2_add_new_hosts_into_the_cluster","text":"Now, add some new hosts (storaged instances) into the cluster. Again, show the new status using command SHOW HOSTS . You can see there are already eight hosts in serving. But no partition is running on the new hosts. nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 0 | test: 0 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 52 | test: 52 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 48 | test: 48 | test: 100 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 0 | No valid partition | No valid partition | ------------------------------------------------------------------------------------------------","title":"Step 2 Add new hosts into the cluster"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_3_data_migration","text":"Check the current balance plan ID using command BALANCE DATA if the cluster is balanced. Otherwise, a new plan ID will be generated by the command. nebula> BALANCE DATA ============== | ID | ============== | 1570761786 | -------------- Check the progress of balance using command BALANCE DATA $id . nebula> BALANCE DATA 1570761786 =============================================================================== | balanceId, spaceId:partId, src->dst | status | =============================================================================== | [1570761786, 1:1, 192.168.8.210:34600->192.168.8.210:44920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34700->192.168.8.210:34920] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:1, 192.168.8.210:34500->192.168.8.210:34800] | succeeded | ------------------------------------------------------------------------------- | [1570761786, 1:2, 192.168.8.210:34600->192.168.8.210:44920] | in progress | ------------------------------------------------------------------------------- | [1570761786, 1:2, 192.168.8.210:34700->192.168.8.210:34920] | in progress | ------------------------------------------------------------------------------- | [1570761786, 1:2, 192.168.8.210:34500->192.168.8.210:34800] | in progress | ------------------------------------------------------------------------------- | [1570761786, 1:3, 192.168.8.210:34600->192.168.8.210:44920] | succeeded | ------------------------------------------------------------------------------- ... | Total:189, Succeeded:170, Failed:0, In Progress:19, Invalid:0 | 89.947090% | Explanations on the returned results: The first column is a specific balance task. Take 1570761786, 1:88, 192.168.8.210:34700->192.168.8.210:35940 for example 1570761786 is the balance ID 1:88 , 1 is the spaceId, 88 is the moved partId 192.168.8.210:34700->192.168.8.210:3594 , moving data from 192.168.8.210:34700 to 192.168.8.210:35940 The second column shows the state (result) of the task, there are four states: Succeeded Failed In progress Invalid The last row is the summary of the tasks. Some partitions are yet to be migrated.","title":"Step 3 Data migration"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#step_4_migration_confirmation","text":"In most cases, data migration will take hours or even days. During the migration, Nebula Graph services are not affected. Once migration is done, the progress will show 100%. You can retry BALANCE DATA to fix a failed task. If it can't be fixed after several attempts, please contact us at GitHub . Now, you can check partition distribution using command SHOW HOSTS when balance completed. nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 3 | test: 3 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 0 | test: 0 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 0 | test: 0 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 35 | test: 35 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 24 | test: 24 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 38 | test: 38 | test: 38 | ------------------------------------------------------------------------------------------------ Now partitions and data are evenly distributed on the machines.","title":"Step 4 Migration confirmation"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#balance_stop","text":"BALANCE DATA STOP command stops the running balance data plan. If there is no running balance plan, an error is thrown. If there is a running plan, the related plan ID is returned. Since each balance plan includes several balance tasks, BALANCE DATA STOP doesn't stop the started tasks , but rather cancel the subsequent tasks. The started tasks will continue until the executions are completed. Input BALANCE DATA $id after BALANCE DATA STOP to check the status of the stopped balance plan. After all the tasks being executed are completed, rerun the BALANCE DATA command to restart balance. If there are failed tasks in the stopped plan, the plan will continue. Otherwise, if all the tasks are succeed, a new balance plan is created and executed.","title":"Balance stop"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#batch_scale_in","text":"Nebula supports specifying hosts that need to go offline to conduct batch scale in. The syntax is BALANCE DATA REMOVE $host_list . For example, statement BALANCE DATA REMOVE 192.168.0.1:50000,192.168.0.2:50000 removes two hosts, i.e. 192.168.0.1:50000\uff0c192.168.0.2:50000, during the balance process. If replica number cannot meet the requirement after removing (for example, the number of remaining hosts is less than the number of replicas or when one of the three replica is offline, one of the remaining two replicas is required to be removed), Nebula Graph will reject the balance request and return an error code.","title":"Batch Scale in"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-balance/#balance_leader","text":"Command BALANCE DATA only migrates partitions. But the leader distribution remains unbalanced, which means old hosts are overloaded, while the new ones are not fully used. Redistribute RAFT leader using the command BALANCE LEADER . nebula> BALANCE LEADER Seconds later, check the results using the command SHOW HOSTS . The RAFT leaders are distributed evenly over all the hosts in the cluster. nebula> SHOW HOSTS ================================================================================================ | Ip | Port | Status | Leader count | Leader distribution | Partition distribution | ================================================================================================ | 192.168.8.210 | 34600 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34900 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 35940 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34920 | online | 12 | test: 12 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 44920 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34700 | online | 12 | test: 12 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34500 | online | 13 | test: 13 | test: 37 | ------------------------------------------------------------------------------------------------ | 192.168.8.210 | 34800 | online | 13 | test: 13 | test: 38 | ------------------------------------------------------------------------------------------------","title":"Balance leader"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/","text":"Storage Metrics \u00b6 Introduction \u00b6 Currently, Nebula Graph supports obtaining the basic performance metrics for the storage service via HTTP. Each performance metric consists of three parts, namely <counter_name>.<statistic_type>.<time_range> , details are introduced as the follows. Counter Names \u00b6 Each counter name is composed of the interface name and the counter name. Currently, the supported interfaces are: storage_vertex_props // obtain properties of a vertex storage_edge_props // obtain properties of an edge storage_add_vertex // insert a vertex storage_add_edge // insert an edge storage_del_vertex // delete a vertex storage_update_vertex // update properties of a vertex storage_update_edge // update properties of an edge storage_get_kv // read kv pair storage_put_kv // put kv pair storage_get_bound // internal use only Each interface has three metrics, namely latency (in the units of us), QPS and QPS with errors. The suffixes are as follows: _latency _qps _error_qps The complete metric concatenates the interface name with the corresponding metric, such as storage_add_vertex_latency , storage_add_vertex_qps and storage_add_vertex_error_qps , representing the latency, QPS, and the QPS with errors of inserting a vertex, respectively. Statistics Type \u00b6 Currently supported types are SUM, COUNT, AVG, RATE, and P quantiles (P99, P999, ..., P999999). Among which: Metrics have suffixes _qps and _error_qps support SUM, COUNT, AVG, RATE but don't support P quantiles. Metrics have suffixes _latency support SUM, COUNT, AVG, RATE, and P quantiles. Time Range \u00b6 Currently, the supported time ranges are 60s, 600s, and 3600s, which correspond to the last minute, the last ten minutes, and the last hour till now. Obtain the Corresponding Metrics via HTTP Interface \u00b6 According to the above introduction, you can make a complete metrics name, here are some examples: storage_add_vertex_latency . avg .60 // the average latency of inserting a vertex in the last minute storage_get_bound_qps . rate .600 // obtain neighbor's QPS in the last ten minutes storage_update_edge_error_qps . count .3600 // errors occurred in updating an edge in the last hour Assume that a Nebula Graph storage service is started locally, and the ws_http_port port number is set to 12000 when starting. It is sent through the GET interface of HTTP. The method name is get_stats , and the parameter is stats plus the corresponding metrics name. Here's an example of getting metrics via the HTTP interface: # obtain a metrics curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60\" # storage_vertex_props_qps.rate.60=2674 # obtain multiple metrics at the same time curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60\" # storage_vertex_props_qps.rate.60=2638 # storage_vertex_props_latency.avg.60=812 # obtain multiple metrics at the same time and return in json format curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60&returnjson\" # [{\"value\":2723,\"name\":\"storage_vertex_props_qps.rate.60\"},{\"value\":804,\"name\":\"storage_vertex_props_latency.avg.60\"}] # obtain all the metrics curl -G \"http://127.0.0.1:12000/get_stats?stats\" # or curl -G \"http://127.0.0.1:12000/get_stats\"","title":"Storage Metrics"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#storage_metrics","text":"","title":"Storage Metrics"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#introduction","text":"Currently, Nebula Graph supports obtaining the basic performance metrics for the storage service via HTTP. Each performance metric consists of three parts, namely <counter_name>.<statistic_type>.<time_range> , details are introduced as the follows.","title":"Introduction"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#counter_names","text":"Each counter name is composed of the interface name and the counter name. Currently, the supported interfaces are: storage_vertex_props // obtain properties of a vertex storage_edge_props // obtain properties of an edge storage_add_vertex // insert a vertex storage_add_edge // insert an edge storage_del_vertex // delete a vertex storage_update_vertex // update properties of a vertex storage_update_edge // update properties of an edge storage_get_kv // read kv pair storage_put_kv // put kv pair storage_get_bound // internal use only Each interface has three metrics, namely latency (in the units of us), QPS and QPS with errors. The suffixes are as follows: _latency _qps _error_qps The complete metric concatenates the interface name with the corresponding metric, such as storage_add_vertex_latency , storage_add_vertex_qps and storage_add_vertex_error_qps , representing the latency, QPS, and the QPS with errors of inserting a vertex, respectively.","title":"Counter Names"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#statistics_type","text":"Currently supported types are SUM, COUNT, AVG, RATE, and P quantiles (P99, P999, ..., P999999). Among which: Metrics have suffixes _qps and _error_qps support SUM, COUNT, AVG, RATE but don't support P quantiles. Metrics have suffixes _latency support SUM, COUNT, AVG, RATE, and P quantiles.","title":"Statistics Type"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#time_range","text":"Currently, the supported time ranges are 60s, 600s, and 3600s, which correspond to the last minute, the last ten minutes, and the last hour till now.","title":"Time Range"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/storage-metrics/#obtain_the_corresponding_metrics_via_http_interface","text":"According to the above introduction, you can make a complete metrics name, here are some examples: storage_add_vertex_latency . avg .60 // the average latency of inserting a vertex in the last minute storage_get_bound_qps . rate .600 // obtain neighbor's QPS in the last ten minutes storage_update_edge_error_qps . count .3600 // errors occurred in updating an edge in the last hour Assume that a Nebula Graph storage service is started locally, and the ws_http_port port number is set to 12000 when starting. It is sent through the GET interface of HTTP. The method name is get_stats , and the parameter is stats plus the corresponding metrics name. Here's an example of getting metrics via the HTTP interface: # obtain a metrics curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60\" # storage_vertex_props_qps.rate.60=2674 # obtain multiple metrics at the same time curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60\" # storage_vertex_props_qps.rate.60=2638 # storage_vertex_props_latency.avg.60=812 # obtain multiple metrics at the same time and return in json format curl -G \"http://127.0.0.1:12000/get_stats?stats=storage_vertex_props_qps.rate.60,storage_vertex_props_latency.avg.60&returnjson\" # [{\"value\":2723,\"name\":\"storage_vertex_props_qps.rate.60\"},{\"value\":804,\"name\":\"storage_vertex_props_latency.avg.60\"}] # obtain all the metrics curl -G \"http://127.0.0.1:12000/get_stats?stats\" # or curl -G \"http://127.0.0.1:12000/get_stats\"","title":"Obtain the Corresponding Metrics via HTTP Interface"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/","text":"Dump Tool \u00b6 Dump Tool is a single-machine off-line data dumping tool that can be used to dump or count data with specified conditions. How to Get \u00b6 The source code of the dump tool is under nebula/src/tools/db_dump . You can use command make db_dump to compile it. Before using this tool, you can use the SHOW HOSTS statement in the Nebula Graph CLI to check the distribution of the partitions. Also, you can use the vertex_id % partition_num statement to calculate which partition the vertex's corresponding key is located. Note: The Dump Tool is located in the rpm package and its directory is nebula/bin/ . Since the tool dumps data by opening the RockDB, you need to use it on the machines that have the storage service deployed and make sure the meta_server is started. Please refer to the following section on detailed usage. How to Use \u00b6 The db_dump command displays information about how to use the dump tool. Parameter space is required. Parameters db_path and meta_server both have default values and you can configure them based on your actual situation. You can combine parameters vids , parts , tags and edges arbitrarily to dump the data you want. ./db_dump --space = <space name> required: --space = <space name> # A space name must be given. optional: --db_path = <path to rocksdb> # Path to the RocksDB data directory. If nebula was installed in `/usr/local/nebula`, # the db_path would be /usr/local/nebula/data/storage/nebula/ # Default: ./ --meta_server = <ip:port,...> # A list of meta severs' ip:port separated by comma. # Default: 127.0.0.1:45500 --mode = scan | stat # scan: print to screen when records meet the condition, and also print statistics to screen in final. # stat: print statistics to screen. # Default: scan --vids = <list of vid> # A list of vids separated by comma. This parameter means vertex_id/edge_src_id # Would scan the whole space's records if it is not given. --parts = <list of partition id> # A list of partition ids separated by comma. # Would output all partitions if it is not given. --tags = <list of tag name> # A list of tag name separated by comma. --edges = <list of edge name> # A list of edge name separated by comma. --limit = <N> # A positive number that limits the output. # Would output all if set to 0 or negative. # Default: 1000 Following is an example: // Specify a space to dump data ./db_dump --space = space_name // Specify space, db_path, meta_server ./db_dump --space = space_name --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // Set mode to stat, only stats are returned, no data is printed ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // Specify vid to dump the vertex and the edges sourcing from it ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --vids = 123 ,456 // Specify tag and dump vertices with the tag ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --tags = tag1,tag2 The returned data format: // vertices, key: part_id, vertex_id, tag_name, value: <prop_list> [ vertex ] key: 1 , 0 , poi value:mid:0,8191765721868409651,8025713627522363385,1993089399535188613,3926276052777355165,5123607763506443893,2990089379644866415,poi_name_0,\u4e0a\u6d77,\u534e\u4e1c,30.2824,120.016,poi_stat_0,poi_fc_0,poi_sc_0,0,poi_star_0, // edges, key: part_id, src_id, edge_name, ranking, dst_id, value: <prop_list> [ edge ] key: 1 , 0 , consume_poi_reverse, 0 , 656384 value:mid:656384,mid:0,7.19312,mid:656384,3897457441682646732,mun:656384,4038264117233984707,dun:656384,empe:656384,mobile:656384,gender:656384,age:656384,rs:656384,fpd:656384,0.75313,1.34433,fpd:656384,0.03567,7.56212, // stats ======================================================= COUNT: 10 # total number of data dumped VERTEX COUNT: 1 # number of vertices dumped EDGE COUNT: 9 # number of edges dumped TAG STATISTICS: # number of tags dumped poi : 1 EDGE STATISTICS: # number of edge types dumped consume_poi_reverse : 9 =======================================================","title":"Dump Tool"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/#dump_tool","text":"Dump Tool is a single-machine off-line data dumping tool that can be used to dump or count data with specified conditions.","title":"Dump Tool"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/#how_to_get","text":"The source code of the dump tool is under nebula/src/tools/db_dump . You can use command make db_dump to compile it. Before using this tool, you can use the SHOW HOSTS statement in the Nebula Graph CLI to check the distribution of the partitions. Also, you can use the vertex_id % partition_num statement to calculate which partition the vertex's corresponding key is located. Note: The Dump Tool is located in the rpm package and its directory is nebula/bin/ . Since the tool dumps data by opening the RockDB, you need to use it on the machines that have the storage service deployed and make sure the meta_server is started. Please refer to the following section on detailed usage.","title":"How to Get"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-export/dump-tool/#how_to_use","text":"The db_dump command displays information about how to use the dump tool. Parameter space is required. Parameters db_path and meta_server both have default values and you can configure them based on your actual situation. You can combine parameters vids , parts , tags and edges arbitrarily to dump the data you want. ./db_dump --space = <space name> required: --space = <space name> # A space name must be given. optional: --db_path = <path to rocksdb> # Path to the RocksDB data directory. If nebula was installed in `/usr/local/nebula`, # the db_path would be /usr/local/nebula/data/storage/nebula/ # Default: ./ --meta_server = <ip:port,...> # A list of meta severs' ip:port separated by comma. # Default: 127.0.0.1:45500 --mode = scan | stat # scan: print to screen when records meet the condition, and also print statistics to screen in final. # stat: print statistics to screen. # Default: scan --vids = <list of vid> # A list of vids separated by comma. This parameter means vertex_id/edge_src_id # Would scan the whole space's records if it is not given. --parts = <list of partition id> # A list of partition ids separated by comma. # Would output all partitions if it is not given. --tags = <list of tag name> # A list of tag name separated by comma. --edges = <list of edge name> # A list of edge name separated by comma. --limit = <N> # A positive number that limits the output. # Would output all if set to 0 or negative. # Default: 1000 Following is an example: // Specify a space to dump data ./db_dump --space = space_name // Specify space, db_path, meta_server ./db_dump --space = space_name --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // Set mode to stat, only stats are returned, no data is printed ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 // Specify vid to dump the vertex and the edges sourcing from it ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --vids = 123 ,456 // Specify tag and dump vertices with the tag ./db_dump --space = space_name --mode = stat --db_path = /usr/local/nebula/data/storage/nebula/ --meta_server = 127 .0.0.1:45513 --tags = tag1,tag2 The returned data format: // vertices, key: part_id, vertex_id, tag_name, value: <prop_list> [ vertex ] key: 1 , 0 , poi value:mid:0,8191765721868409651,8025713627522363385,1993089399535188613,3926276052777355165,5123607763506443893,2990089379644866415,poi_name_0,\u4e0a\u6d77,\u534e\u4e1c,30.2824,120.016,poi_stat_0,poi_fc_0,poi_sc_0,0,poi_star_0, // edges, key: part_id, src_id, edge_name, ranking, dst_id, value: <prop_list> [ edge ] key: 1 , 0 , consume_poi_reverse, 0 , 656384 value:mid:656384,mid:0,7.19312,mid:656384,3897457441682646732,mun:656384,4038264117233984707,dun:656384,empe:656384,mobile:656384,gender:656384,age:656384,rs:656384,fpd:656384,0.75313,1.34433,fpd:656384,0.03567,7.56212, // stats ======================================================= COUNT: 10 # total number of data dumped VERTEX COUNT: 1 # number of vertices dumped EDGE COUNT: 9 # number of edges dumped TAG STATISTICS: # number of tags dumped poi : 1 EDGE STATISTICS: # number of edge types dumped consume_poi_reverse : 9 =======================================================","title":"How to Use"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/download-and-ingest-sst-file/","text":"Download and Ingest \u00b6 Nebula Graph uses RocksDB as the default key-value storage engine. Therefore, when you are trying to load a large amount of data, the SST files of RocksDB can be generated offline by running a map-reduce job and distributed directly to the servers. Nebula Graph provides Spark-SSTFile-Generator tool. Spark-SSTFile-Generator generates SST files from the hive table via the mapping files. For details on how to use it, please refer Spark application command line reference . The execution will generate SST files on HDFS . The directory structure is as follows: |---1 (this is partition number) | | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst |---2 | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst .... Each directory is a partition number. SST file name format is {TYPE}-${FIRST_KEY_IN_THIS_FILE}.sst , where TYPE is data type, FIRST_KEY_IN_THIS_FILE is the start Key of the file. (If you want to write your own tools to generate SST files, you need to ensure that the keys in each SST file are ordered.) Please confirm that all servers have Hadoop installed and HADOOP_HOME set. Run Nebula Graph console and execute the download command: nebula > DOWNLOAD HDFS \"hdfs://${HADOOP_HOST}:${HADOOP_PORT}/${HADOOP_PATH}\" Download the SST files of each server into directory data/download respectively via the DOWNLOAD command and meta in the storage servers. Explanation of the above command: HADOOP_HOST specifies Hadoop NameNode address HADOOP_PORT specifies Hadoop NameNode port number HADOOP_PATH specifies Hadoop data storage directory If error occurs when downloading, delete the corresponding data files in data/download directory and try to download again. If error occurs again, please raise us an issue on GitHub . When data download is done, re-execute the command leads to no actions. When the offline SST data download is done, it can be ingested into the storage service via INGEST command. INGEST command is as follows: nebula > INGEST The command will ingest the SST files in data/download directory. Note: ingest will block RocksDB when the data amount is large, please avoid running the command at requirement peak.","title":"Download and Ingest sst File"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/download-and-ingest-sst-file/#download_and_ingest","text":"Nebula Graph uses RocksDB as the default key-value storage engine. Therefore, when you are trying to load a large amount of data, the SST files of RocksDB can be generated offline by running a map-reduce job and distributed directly to the servers. Nebula Graph provides Spark-SSTFile-Generator tool. Spark-SSTFile-Generator generates SST files from the hive table via the mapping files. For details on how to use it, please refer Spark application command line reference . The execution will generate SST files on HDFS . The directory structure is as follows: |---1 (this is partition number) | | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst |---2 | ---- vertex-${FIRST_KEY_IN_THIS_FILE}.sst | ---- edge-${FIRST_KEY_IN_THIS_FILE}.sst .... Each directory is a partition number. SST file name format is {TYPE}-${FIRST_KEY_IN_THIS_FILE}.sst , where TYPE is data type, FIRST_KEY_IN_THIS_FILE is the start Key of the file. (If you want to write your own tools to generate SST files, you need to ensure that the keys in each SST file are ordered.) Please confirm that all servers have Hadoop installed and HADOOP_HOME set. Run Nebula Graph console and execute the download command: nebula > DOWNLOAD HDFS \"hdfs://${HADOOP_HOST}:${HADOOP_PORT}/${HADOOP_PATH}\" Download the SST files of each server into directory data/download respectively via the DOWNLOAD command and meta in the storage servers. Explanation of the above command: HADOOP_HOST specifies Hadoop NameNode address HADOOP_PORT specifies Hadoop NameNode port number HADOOP_PATH specifies Hadoop data storage directory If error occurs when downloading, delete the corresponding data files in data/download directory and try to download again. If error occurs again, please raise us an issue on GitHub . When data download is done, re-execute the command leads to no actions. When the offline SST data download is done, it can be ingested into the storage service via INGEST command. INGEST command is as follows: nebula > INGEST The command will ingest the SST files in data/download directory. Note: ingest will block RocksDB when the data amount is large, please avoid running the command at requirement peak.","title":"Download and Ingest"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/import-csv-file/","text":"Import csv File \u00b6 See vesoft-inc/nebula-importer .","title":"Import csv File"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/import-csv-file/#import_csv_file","text":"See vesoft-inc/nebula-importer .","title":"Import csv File"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/","text":"Spark Writer \u00b6 Overview \u00b6 Spark Writer is Nebula Graph's Spark-based distributed data import tool that converts data from multiple data repositories into vertices and edges of graphs and batch imports data into the graph database. Currently supported data repositories are: HDFS, including Parquet, JSON, ORC and CSV HIVE Spark Writer supports concurrent importing multiple tags and edges, and configuring different data repositories on different tags and edges. Prerequisites \u00b6 Note: To use Nebula Graph Spark Writer , please make sure you have: Spark 2.0 or above Hive 2.3 or above Hadoop 2.0 or above Get Spark Writer \u00b6 From Source Code \u00b6 git clone https://github.com/vesoft-inc/nebula.git cd nebula/src/tools/spark-sstfile-generator mvn compile package Or you can download from OSS. Download From Cloud Storage OSS \u00b6 wget https://nebula-graph.oss-accelerate.aliyuncs.com/jar-packages/sst.generator-1.0.0-beta.jar User Guide \u00b6 This section includes the following steps: Create a graph space and its schema in Nebula Graph Write data files Write input source mapping file Import data Create Graph Space \u00b6 Please refer to the example graph in Quick Start . Note: Please create a space and define the schema in Nebula Graph first, then use this tool to import data to Nebula Graph. Example Data \u00b6 Vertices \u00b6 A vertex data file consists of multiple rows, with each line in the file representing a point and its properties. In general, the first column is the ID of the vertex. This ID column is specified in the mapping file. Other columns are the properties of the vertex. Consider the following example in JSON format. Player data {\"id\":100,\"name\":\"Tim Duncan\",\"age\":42} {\"id\":101,\"name\":\"Tony Parker\",\"age\":36} {\"id\":102,\"name\":\"LaMarcus Aldridge\",\"age\":33} Edges \u00b6 An edge data file consists of multiple rows, with each line in the file representing a point and its properties. In general, the first column is the ID of the source vertex, the second column is the ID of the dest vertex. These ID columns are specified in the mapping file. Other columns are the properties of the edge. Consider the following example in JSON format. Take edge follow as example: Edge without rank {\"source\":100,\"target\":101,\"likeness\":95} {\"source\":101,\"target\":100,\"likeness\":95} {\"source\":101,\"target\":102,\"likeness\":90} Edge with rank {\"source\":100,\"target\":101,\"likeness\":95,\"ranking\":2} {\"source\":101,\"target\":100,\"likeness\":95,\"ranking\":1} {\"source\":101,\"target\":102,\"likeness\":90,\"ranking\":3} Spatial Data Geo \u00b6 Spark Writer supports importing Geo data. Geo data contains latitude and longitude , and the data type is double. {\"latitude\":30.2822095,\"longitude\":120.0298785,\"target\":0,\"dp_poi_name\":\"0\"} {\"latitude\":30.2813834,\"longitude\":120.0208692,\"target\":1,\"dp_poi_name\":\"1\"} {\"latitude\":30.2807347,\"longitude\":120.0181162,\"target\":2,\"dp_poi_name\":\"2\"} {\"latitude\":30.2812694,\"longitude\":120.0164896,\"target\":3,\"dp_poi_name\":\"3\"} Data Source Files \u00b6 The currently supported data sources by Spark Writer are: HDFS HIVE HDFS Files \u00b6 HDFS supports the following file formats: Parquet JSON CSV ORC Player data in Parquet format: +-------+---+---------+ |age| id| name| +-------+---+---------+ | 42|100| Tim Duncan | | 36|101| Tony Parker| +-------+---+---------+ In JSON: { \"id\" : 100 , \"name\" : \"Tim Duncan\" , \"age\" : 42 } { \"id\" : 101 , \"name\" : \"Tony Parker\" , \"age\" : 36 } In CSV: age,id,name 42,100,Tim Duncan 36,101,Tony Parker Database \u00b6 Spark Writer supports database as the data source, and only HIVE is available now. Player format as follows: col_name data_type comment id int name string age int Write Configuration Files \u00b6 The configuration files consist of Spark related information, Nebula Graph related information, and tags mapping and edges mapping blocks. Spark information is configured with the associated parameters running Spark. Nebula Graph information is configured with information such as user name and password to connect Nebula Graph. Tags mapping and edges mapping correspond to the input source mapping of multiple tag/edges respectively, describing the basic information like each tag/edge's data source. It's possible that different tag/edge come from different data sources. Example of a mapping file for the input source: { # Spark related configurations. # See also: http://spark.apache.org/docs/latest/configuration.html spark: { app: { name: Spark Writer } driver: { cores: 1 maxResultSize: 1G } cores { max: 16 } } # Nebula Graph related configurations. nebula: { # Query engine address list. addresses: [\"127.0.0.1:3699\"] # Nebula Graph access user name and password. user: user pswd: password # Nebula Graph space's name. space: test # The thrift connection timeout and retry times. # If no configurations are set, the default values are 3000 and 3 respectively. connection { timeout: 3000 retry: 3 } # The nGQL execution retry times. # If no configuration is set, the default value is 3. execution { retry: 3 } } # Processing tags tags: [ # Loading tag from HDFS and the data type is parquet. # The tag's name is tag_name_0. # field_0, field_1 and field_2 from HDFS's Parquet file are written into tag_name_0 # and the vertex column is vertex_key_field. { name: tag_name_0 type: parquet path: hdfs_path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } vertex: vertex_key_field batch : 16 } # Similar to the above. # Loading from Hive will execute command ${exec} as data set. { name: tag_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } vertex: vertex_id_field } ] # Processing edges edges: [ # Loading edge from HDFS and data type is JSON. # The edge's name is edge_name_0. # field_0, field_1 and field_2 from HDFS's JSON file are written into edge_name_0 # The source column is source_field, target column is target_field and ranking column is ranking_field. { name: edge_name_0 type: json path: hdfs_path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } source: source_field target: target_field ranking: ranking_field } # Loading from Hive will execute command ${exec} as data set. # Ranking is optional. { name: edge_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } source: source_id_field target: target_id_field } ] } Spark Properties \u00b6 The following table gives some example properties, all of which can be found in Spark Available Properties . Field Default Required Description spark.app.name Spark Writer No The name of your application spark.driver.cores 1 No Number of cores to use for the driver process, only in cluster mode. spark.driver.maxResultSize 1G No Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. It must be at least 1M, or 0 for unlimited. spark.cores.max (not set) No When running on a standalone deploy cluster or a Mesos cluster in \"coarse-grained\" sharing mode, the maximum amount of CPU cores to request for the application from across the cluster (not from each machine). If not set, the default will be spark.deploy.defaultCores on Spark's standalone cluster manager, or infinite (all available cores) on Mesos. Nebula Graph Configuration \u00b6 Field Default Value Required Description nebula.addresses / yes query engine IP list, separated with comma nebula.user / yes user name, the default value is user nebula.pswd / yes password, the default user password is password nebula.space / yes space to import data, the space name is test in this document nebula.connection.timeout 3000 no Thrift timeout nebula.connection.retry 3 no Thrift retry times nebula.execution.retry 3 no nGQL execution retry times Mapping of Tags and Edges \u00b6 The options for tag and edge mapping are very similar. The following describes the same options first, and then introduces the unique options of tag mapping and edge mapping . Same Options type is a case insensitive required field that specifies data type in the context, and currently supports Parquet, JSON, ORC and CSV path is applied to HDFS data source and specifies the absolute path of HDFS file or directory. It is a required field when the type is HDFS exec is applied to Hive data source. It is a required filed when the query type is HIVE fields is a required filed that maps the columns of the data source to properties of tag / edge unique options for tag mapping vertex is a required field that specifies a column as the vertex ID column unique options for edge mapping source is a required field that specifies a column in the input source as the source vertex ID column target is a required field that specifies a column as the dest vertex ID column ranking is an optional field that specifies a column as the edge ranking column when the inserted edge has a ranking value Data Source Mapping \u00b6 HDFS Parquet Files type specifies the input source type. When it is parquet, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be the absolute directory HDFS JSON Files type specifies the type of the input source. When it is JSON, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be absolute directory HIVE ORC Files type specifies the input source type. When it is ORC, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be the absolute directory HIVE CSV Files type specifies the input source type. When it is CSV, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be the absolute directory HIVE type specifies the input source type. When it is HIVE, it is a case insensitive required field exec is a required field that specifies the HIVE executed query Import Data \u00b6 Input data with the following command: bin/spark-submit \\ --class com.vesoft.nebula.tools.generator.v2.SparkClientGenerator \\ --master ${ MASTER -URL } \\ ${ SPARK_WRITER_JAR_PACKAGE } -c conf/test.conf -h -d Parameter descriptions: Abbreviation Required Default Description Example --class yes / Specify the program's main class --master yes / Specify spark cluster master url. Refer to master urls for detail e.g. spark://23.195.26.187:7077 -c / --config yes / The configuration file path in the context -h / --hive no false Used to specify whether to support Hive -d / --directly no false True for console insertion; false for sst import (TODO) -D / --dry no false Check if the configuration file is correct Performance \u00b6 It takes about four minutes (i.e. 400k QPS) to input 100 million rows (each row contains three fields, each batch contains 64 rows) into three nodes (56 core, 250G memory, 10G network, SSD).","title":"Spark Writer"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#spark_writer","text":"","title":"Spark Writer"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#overview","text":"Spark Writer is Nebula Graph's Spark-based distributed data import tool that converts data from multiple data repositories into vertices and edges of graphs and batch imports data into the graph database. Currently supported data repositories are: HDFS, including Parquet, JSON, ORC and CSV HIVE Spark Writer supports concurrent importing multiple tags and edges, and configuring different data repositories on different tags and edges.","title":"Overview"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#prerequisites","text":"Note: To use Nebula Graph Spark Writer , please make sure you have: Spark 2.0 or above Hive 2.3 or above Hadoop 2.0 or above","title":"Prerequisites"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#get_spark_writer","text":"","title":"Get Spark Writer"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#from_source_code","text":"git clone https://github.com/vesoft-inc/nebula.git cd nebula/src/tools/spark-sstfile-generator mvn compile package Or you can download from OSS.","title":"From Source Code"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#download_from_cloud_storage_oss","text":"wget https://nebula-graph.oss-accelerate.aliyuncs.com/jar-packages/sst.generator-1.0.0-beta.jar","title":"Download From Cloud Storage OSS"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#user_guide","text":"This section includes the following steps: Create a graph space and its schema in Nebula Graph Write data files Write input source mapping file Import data","title":"User Guide"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#create_graph_space","text":"Please refer to the example graph in Quick Start . Note: Please create a space and define the schema in Nebula Graph first, then use this tool to import data to Nebula Graph.","title":"Create Graph Space"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#example_data","text":"","title":"Example Data"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#vertices","text":"A vertex data file consists of multiple rows, with each line in the file representing a point and its properties. In general, the first column is the ID of the vertex. This ID column is specified in the mapping file. Other columns are the properties of the vertex. Consider the following example in JSON format. Player data {\"id\":100,\"name\":\"Tim Duncan\",\"age\":42} {\"id\":101,\"name\":\"Tony Parker\",\"age\":36} {\"id\":102,\"name\":\"LaMarcus Aldridge\",\"age\":33}","title":"Vertices"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#edges","text":"An edge data file consists of multiple rows, with each line in the file representing a point and its properties. In general, the first column is the ID of the source vertex, the second column is the ID of the dest vertex. These ID columns are specified in the mapping file. Other columns are the properties of the edge. Consider the following example in JSON format. Take edge follow as example: Edge without rank {\"source\":100,\"target\":101,\"likeness\":95} {\"source\":101,\"target\":100,\"likeness\":95} {\"source\":101,\"target\":102,\"likeness\":90} Edge with rank {\"source\":100,\"target\":101,\"likeness\":95,\"ranking\":2} {\"source\":101,\"target\":100,\"likeness\":95,\"ranking\":1} {\"source\":101,\"target\":102,\"likeness\":90,\"ranking\":3}","title":"Edges"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#spatial_data_geo","text":"Spark Writer supports importing Geo data. Geo data contains latitude and longitude , and the data type is double. {\"latitude\":30.2822095,\"longitude\":120.0298785,\"target\":0,\"dp_poi_name\":\"0\"} {\"latitude\":30.2813834,\"longitude\":120.0208692,\"target\":1,\"dp_poi_name\":\"1\"} {\"latitude\":30.2807347,\"longitude\":120.0181162,\"target\":2,\"dp_poi_name\":\"2\"} {\"latitude\":30.2812694,\"longitude\":120.0164896,\"target\":3,\"dp_poi_name\":\"3\"}","title":"Spatial Data Geo"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#data_source_files","text":"The currently supported data sources by Spark Writer are: HDFS HIVE","title":"Data Source Files"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#hdfs_files","text":"HDFS supports the following file formats: Parquet JSON CSV ORC Player data in Parquet format: +-------+---+---------+ |age| id| name| +-------+---+---------+ | 42|100| Tim Duncan | | 36|101| Tony Parker| +-------+---+---------+ In JSON: { \"id\" : 100 , \"name\" : \"Tim Duncan\" , \"age\" : 42 } { \"id\" : 101 , \"name\" : \"Tony Parker\" , \"age\" : 36 } In CSV: age,id,name 42,100,Tim Duncan 36,101,Tony Parker","title":"HDFS Files"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#database","text":"Spark Writer supports database as the data source, and only HIVE is available now. Player format as follows: col_name data_type comment id int name string age int","title":"Database"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#write_configuration_files","text":"The configuration files consist of Spark related information, Nebula Graph related information, and tags mapping and edges mapping blocks. Spark information is configured with the associated parameters running Spark. Nebula Graph information is configured with information such as user name and password to connect Nebula Graph. Tags mapping and edges mapping correspond to the input source mapping of multiple tag/edges respectively, describing the basic information like each tag/edge's data source. It's possible that different tag/edge come from different data sources. Example of a mapping file for the input source: { # Spark related configurations. # See also: http://spark.apache.org/docs/latest/configuration.html spark: { app: { name: Spark Writer } driver: { cores: 1 maxResultSize: 1G } cores { max: 16 } } # Nebula Graph related configurations. nebula: { # Query engine address list. addresses: [\"127.0.0.1:3699\"] # Nebula Graph access user name and password. user: user pswd: password # Nebula Graph space's name. space: test # The thrift connection timeout and retry times. # If no configurations are set, the default values are 3000 and 3 respectively. connection { timeout: 3000 retry: 3 } # The nGQL execution retry times. # If no configuration is set, the default value is 3. execution { retry: 3 } } # Processing tags tags: [ # Loading tag from HDFS and the data type is parquet. # The tag's name is tag_name_0. # field_0, field_1 and field_2 from HDFS's Parquet file are written into tag_name_0 # and the vertex column is vertex_key_field. { name: tag_name_0 type: parquet path: hdfs_path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } vertex: vertex_key_field batch : 16 } # Similar to the above. # Loading from Hive will execute command ${exec} as data set. { name: tag_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } vertex: vertex_id_field } ] # Processing edges edges: [ # Loading edge from HDFS and data type is JSON. # The edge's name is edge_name_0. # field_0, field_1 and field_2 from HDFS's JSON file are written into edge_name_0 # The source column is source_field, target column is target_field and ranking column is ranking_field. { name: edge_name_0 type: json path: hdfs_path fields: { field_0: nebula_field_0, field_1: nebula_field_1, field_2: nebula_field_2 } source: source_field target: target_field ranking: ranking_field } # Loading from Hive will execute command ${exec} as data set. # Ranking is optional. { name: edge_name_1 type: hive exec: \"select hive_field_0, hive_field_1, hive_field_2 from database.table\" fields: { hive_field_0: nebula_field_0, hive_field_1: nebula_field_1, hive_field_2: nebula_field_2 } source: source_id_field target: target_id_field } ] }","title":"Write Configuration Files"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#spark_properties","text":"The following table gives some example properties, all of which can be found in Spark Available Properties . Field Default Required Description spark.app.name Spark Writer No The name of your application spark.driver.cores 1 No Number of cores to use for the driver process, only in cluster mode. spark.driver.maxResultSize 1G No Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. It must be at least 1M, or 0 for unlimited. spark.cores.max (not set) No When running on a standalone deploy cluster or a Mesos cluster in \"coarse-grained\" sharing mode, the maximum amount of CPU cores to request for the application from across the cluster (not from each machine). If not set, the default will be spark.deploy.defaultCores on Spark's standalone cluster manager, or infinite (all available cores) on Mesos.","title":"Spark Properties"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#nebula_graph_configuration","text":"Field Default Value Required Description nebula.addresses / yes query engine IP list, separated with comma nebula.user / yes user name, the default value is user nebula.pswd / yes password, the default user password is password nebula.space / yes space to import data, the space name is test in this document nebula.connection.timeout 3000 no Thrift timeout nebula.connection.retry 3 no Thrift retry times nebula.execution.retry 3 no nGQL execution retry times","title":"Nebula Graph Configuration"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#mapping_of_tags_and_edges","text":"The options for tag and edge mapping are very similar. The following describes the same options first, and then introduces the unique options of tag mapping and edge mapping . Same Options type is a case insensitive required field that specifies data type in the context, and currently supports Parquet, JSON, ORC and CSV path is applied to HDFS data source and specifies the absolute path of HDFS file or directory. It is a required field when the type is HDFS exec is applied to Hive data source. It is a required filed when the query type is HIVE fields is a required filed that maps the columns of the data source to properties of tag / edge unique options for tag mapping vertex is a required field that specifies a column as the vertex ID column unique options for edge mapping source is a required field that specifies a column in the input source as the source vertex ID column target is a required field that specifies a column as the dest vertex ID column ranking is an optional field that specifies a column as the edge ranking column when the inserted edge has a ranking value","title":"Mapping of Tags and Edges"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#data_source_mapping","text":"HDFS Parquet Files type specifies the input source type. When it is parquet, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be the absolute directory HDFS JSON Files type specifies the type of the input source. When it is JSON, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be absolute directory HIVE ORC Files type specifies the input source type. When it is ORC, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be the absolute directory HIVE CSV Files type specifies the input source type. When it is CSV, it is a case insensitive required field path specifies the HDFS file directory. It is a required field that must be the absolute directory HIVE type specifies the input source type. When it is HIVE, it is a case insensitive required field exec is a required field that specifies the HIVE executed query","title":"Data Source Mapping"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#import_data","text":"Input data with the following command: bin/spark-submit \\ --class com.vesoft.nebula.tools.generator.v2.SparkClientGenerator \\ --master ${ MASTER -URL } \\ ${ SPARK_WRITER_JAR_PACKAGE } -c conf/test.conf -h -d Parameter descriptions: Abbreviation Required Default Description Example --class yes / Specify the program's main class --master yes / Specify spark cluster master url. Refer to master urls for detail e.g. spark://23.195.26.187:7077 -c / --config yes / The configuration file path in the context -h / --hive no false Used to specify whether to support Hive -d / --directly no false True for console insertion; false for sst import (TODO) -D / --dry no false Check if the configuration file is correct","title":"Import Data"},{"location":"manual-EN/3.build-develop-and-administration/3.deploy-and-administrations/server-administration/storage-service-administration/data-import/spark-writer/#performance","text":"It takes about four minutes (i.e. 400k QPS) to input 100 million rows (each row contains three fields, each batch contains 64 rows) into three nodes (56 core, 250G memory, 10G network, SSD).","title":"Performance"},{"location":"manual-EN/4.contributions/","text":"Reader \u00b6 This chapter is a guideline for the contributors and developers.","title":"Reader"},{"location":"manual-EN/4.contributions/#reader","text":"This chapter is a guideline for the contributors and developers.","title":"Reader"},{"location":"manual-EN/4.contributions/contribute-to-documentation/","text":"Contribute to Documentation \u00b6 Contributing to the Nebula Graph documentation can be a rewarding experience. We welcome your participation to help make the documentation better! How to Contribute to the Docs \u00b6 There are many ways to contribute: Raise a documentation issue on GitHub . Fork the documentation, make changes or add new content on your local branch, and submit a pull request (PR) to the master branch for the docs.","title":"Contribute to Documentation"},{"location":"manual-EN/4.contributions/contribute-to-documentation/#contribute_to_documentation","text":"Contributing to the Nebula Graph documentation can be a rewarding experience. We welcome your participation to help make the documentation better!","title":"Contribute to Documentation"},{"location":"manual-EN/4.contributions/contribute-to-documentation/#how_to_contribute_to_the_docs","text":"There are many ways to contribute: Raise a documentation issue on GitHub . Fork the documentation, make changes or add new content on your local branch, and submit a pull request (PR) to the master branch for the docs.","title":"How to Contribute to the Docs"},{"location":"manual-EN/4.contributions/cpp-coding-style/","text":"Cpp Coding Style \u00b6 Please Refer to Google C++ Style Guide .","title":"cpp Coding Style"},{"location":"manual-EN/4.contributions/cpp-coding-style/#cpp_coding_style","text":"Please Refer to Google C++ Style Guide .","title":"Cpp Coding Style"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/","text":"Developer Documentation Style Guide \u00b6 Key Point: Use this guide as a style reference for our developer documentation. Goals \u00b6 The guide can help you avoid making decisions about the same issue over and over, can provide editorial assistance on structuring and writing your documentation, and can help you keep your documentation consistent with our other documentation. Non-Goals \u00b6 This guide isn't intended to provide an industry documentation standard, nor to compete with other well-known style guides. It's a description of our house style, not a statement that our decisions are objectively correct. This guide is a living document; it changes over time, and when it changes, we generally don't change previously published documentation to match. We strive for consistency to the extent feasible, but at any given time there are certain to be parts of our documentation that don't match this style guide. When in doubt, follow this guide rather than imitating existing documents. Breaking the \"Rules\" \u00b6 In most contexts, Nebula Graph has no ability nor desire to enforce these guidelines if they're not appropriate to the context. But we hope that you'll join us in striving for high-quality documentation. Like most style guides, our style guide aims to improve our documentation, especially by improving consistency; therefore, there may be contexts where it makes sense to diverge from our guidelines in order to make your documentation better. Style and Authorial Tone \u00b6 Aim, in your documents, for a voice and tone that's conversational, friendly, and respectful without being overly colloquial or frivolous; a voice that's casual and natural and approachable, not pedantic or pushy. Try to sound like a knowledgeable friend who understands what the developer wants to do. Don't try to write exactly the way you speak; you probably speak more colloquially and verbosely than you should write, at least for developer documentation. But aim for a conversational tone rather than a formal one. Some Techniques and Approaches to Consider \u00b6 If you're having trouble expressing something, step back and ask yourself, \"What am I trying to say?\" Often, the answer you give yourself reveals what you should be saying in the document. If you're uncertain about your phrasing or tone, ask a colleague to take a look. Try reading parts of your document out loud, or at least mouthing the words. Does it sound natural? Not every sentence has to sound natural when spoken; these are written documents. But if you come across a sentence that's awkward or confusing when spoken, consider whether you can make it more conversational. Use transitions between sentences. Phrases like \"Though\" or \"This way\" can make paragraphs less stilted. (Then again, sometimes transitions like \"However\" or \"Nonetheless\" can make paragraphs more stilted.) Even if you're having trouble hitting the right tone, make sure you're communicating useful information in a clear and direct way; that's the most important part. Tense \u00b6 In general, use present tense rather than future tense; in particular, try to avoid using will where possible. The fact that the reader will be writing and running code in the future isn't a good reason to use future tense. Stick with present tense where. Also avoid the hypothetical future would . Links \u00b6 When you're writing link text, use a phrase that describes what the reader will see after following the link. That can take either of two forms: The exact title of the linked-to page, capitalized the same way the title is capitalized. A description of the linked-to page, capitalized like ordinary text instead of like a title. A couple of specific things to not do in link text: Don't use the phrase \"click here.\" (It's bad for accessibility and bad for scannability.) Similarly, don't use phrases like \"this document.\" (It's easy to read \"this\" as meaning \"the one you're reading now\" rather than \"the one I'm pointing to.\") Don't use a URL as link text. Instead, use the page title or a description of the page. Punctuation With Links \u00b6 If you have punctuation immediately before or after a link, put the punctuation outside of the link tags where possible. In particular, put quotation marks outside of link tags. Accessible Content \u00b6 General dos and Don'ts \u00b6 Ensure that readers can reach all parts of the document (including tabs, form-submission buttons, and interactive elements) using only a keyboard, without a mouse or trackpad. Don't use color, size, location, or other visual cues as the primary way of communicating information. If you're using color, icon, or outline thickness to convey state, then also provide a secondary cue, such as a change in the text label. Refer to buttons and other elements by their label (or aria-label , if they\u2019re visual elements), not by location or shape. Avoid unnecessary font formatting. (Screen readers explicitly describe text modifications.) If you're documenting a product that includes specialized accessibility features, then explicitly document those features. For example, the gcloud command-line tool includes togglable accessibility features such as percentage progress bars and ASCII box rendering. Images \u00b6 For every image, provide alt text that adequately summarizes the intent of each image. Don't present new information in images; always provide an equivalent text explanation with the image. Use SVG files or crushed PNG images. Provide high-resolution images when practical. Tables \u00b6 If your tables include both row and column headings, then mark heading cells with the scope attribute. If your tables have more than one row containing column headings, then use the headers attribute. Forms \u00b6 Label every input field, using a <label> element. Place labels outside of fields. When you're creating an error message for form validation, clearly state what went wrong and how to fix it. For example: \"Name is a required field.\" Videos \u00b6 Provide captions. Ensure that captions can be translated into major languages. Language and Grammar \u00b6 Use second person: \"you\" rather than \"we.\" Use active voice; make clear who's performing the action. Use standard American spelling and punctuation. Put conditional clauses before instructions, not after. For usage and spelling of specific words, see the word list. Formatting, Punctuation, and Organization \u00b6 Use sentence case for document titles and section headings. Use numbered lists for sequences. Use bulleted lists for most other lists. Use description lists for pairs of related pieces of data. Use serial commas . Put code-related text in code font . Put UI elements in bold . Use unambiguous date formatting .","title":"Developer Documentation Style Guide"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#developer_documentation_style_guide","text":"Key Point: Use this guide as a style reference for our developer documentation.","title":"Developer Documentation Style Guide"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#goals","text":"The guide can help you avoid making decisions about the same issue over and over, can provide editorial assistance on structuring and writing your documentation, and can help you keep your documentation consistent with our other documentation.","title":"Goals"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#non-goals","text":"This guide isn't intended to provide an industry documentation standard, nor to compete with other well-known style guides. It's a description of our house style, not a statement that our decisions are objectively correct. This guide is a living document; it changes over time, and when it changes, we generally don't change previously published documentation to match. We strive for consistency to the extent feasible, but at any given time there are certain to be parts of our documentation that don't match this style guide. When in doubt, follow this guide rather than imitating existing documents.","title":"Non-Goals"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#breaking_the_rules","text":"In most contexts, Nebula Graph has no ability nor desire to enforce these guidelines if they're not appropriate to the context. But we hope that you'll join us in striving for high-quality documentation. Like most style guides, our style guide aims to improve our documentation, especially by improving consistency; therefore, there may be contexts where it makes sense to diverge from our guidelines in order to make your documentation better.","title":"Breaking the \"Rules\""},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#style_and_authorial_tone","text":"Aim, in your documents, for a voice and tone that's conversational, friendly, and respectful without being overly colloquial or frivolous; a voice that's casual and natural and approachable, not pedantic or pushy. Try to sound like a knowledgeable friend who understands what the developer wants to do. Don't try to write exactly the way you speak; you probably speak more colloquially and verbosely than you should write, at least for developer documentation. But aim for a conversational tone rather than a formal one.","title":"Style and Authorial Tone"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#some_techniques_and_approaches_to_consider","text":"If you're having trouble expressing something, step back and ask yourself, \"What am I trying to say?\" Often, the answer you give yourself reveals what you should be saying in the document. If you're uncertain about your phrasing or tone, ask a colleague to take a look. Try reading parts of your document out loud, or at least mouthing the words. Does it sound natural? Not every sentence has to sound natural when spoken; these are written documents. But if you come across a sentence that's awkward or confusing when spoken, consider whether you can make it more conversational. Use transitions between sentences. Phrases like \"Though\" or \"This way\" can make paragraphs less stilted. (Then again, sometimes transitions like \"However\" or \"Nonetheless\" can make paragraphs more stilted.) Even if you're having trouble hitting the right tone, make sure you're communicating useful information in a clear and direct way; that's the most important part.","title":"Some Techniques and Approaches to Consider"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#tense","text":"In general, use present tense rather than future tense; in particular, try to avoid using will where possible. The fact that the reader will be writing and running code in the future isn't a good reason to use future tense. Stick with present tense where. Also avoid the hypothetical future would .","title":"Tense"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#links","text":"When you're writing link text, use a phrase that describes what the reader will see after following the link. That can take either of two forms: The exact title of the linked-to page, capitalized the same way the title is capitalized. A description of the linked-to page, capitalized like ordinary text instead of like a title. A couple of specific things to not do in link text: Don't use the phrase \"click here.\" (It's bad for accessibility and bad for scannability.) Similarly, don't use phrases like \"this document.\" (It's easy to read \"this\" as meaning \"the one you're reading now\" rather than \"the one I'm pointing to.\") Don't use a URL as link text. Instead, use the page title or a description of the page.","title":"Links"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#punctuation_with_links","text":"If you have punctuation immediately before or after a link, put the punctuation outside of the link tags where possible. In particular, put quotation marks outside of link tags.","title":"Punctuation With Links"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#accessible_content","text":"","title":"Accessible Content"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#general_dos_and_donts","text":"Ensure that readers can reach all parts of the document (including tabs, form-submission buttons, and interactive elements) using only a keyboard, without a mouse or trackpad. Don't use color, size, location, or other visual cues as the primary way of communicating information. If you're using color, icon, or outline thickness to convey state, then also provide a secondary cue, such as a change in the text label. Refer to buttons and other elements by their label (or aria-label , if they\u2019re visual elements), not by location or shape. Avoid unnecessary font formatting. (Screen readers explicitly describe text modifications.) If you're documenting a product that includes specialized accessibility features, then explicitly document those features. For example, the gcloud command-line tool includes togglable accessibility features such as percentage progress bars and ASCII box rendering.","title":"General dos and Don'ts"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#images","text":"For every image, provide alt text that adequately summarizes the intent of each image. Don't present new information in images; always provide an equivalent text explanation with the image. Use SVG files or crushed PNG images. Provide high-resolution images when practical.","title":"Images"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#tables","text":"If your tables include both row and column headings, then mark heading cells with the scope attribute. If your tables have more than one row containing column headings, then use the headers attribute.","title":"Tables"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#forms","text":"Label every input field, using a <label> element. Place labels outside of fields. When you're creating an error message for form validation, clearly state what went wrong and how to fix it. For example: \"Name is a required field.\"","title":"Forms"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#videos","text":"Provide captions. Ensure that captions can be translated into major languages.","title":"Videos"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#language_and_grammar","text":"Use second person: \"you\" rather than \"we.\" Use active voice; make clear who's performing the action. Use standard American spelling and punctuation. Put conditional clauses before instructions, not after. For usage and spelling of specific words, see the word list.","title":"Language and Grammar"},{"location":"manual-EN/4.contributions/developer-documentation-style-guide/#formatting_punctuation_and_organization","text":"Use sentence case for document titles and section headings. Use numbered lists for sequences. Use bulleted lists for most other lists. Use description lists for pairs of related pieces of data. Use serial commas . Put code-related text in code font . Put UI elements in bold . Use unambiguous date formatting .","title":"Formatting, Punctuation, and Organization"},{"location":"manual-EN/4.contributions/how-to-contribute/","text":"How to Contribute \u00b6 Step 1: Fork in the Cloud \u00b6 Visit https://github.com/vesoft-inc/nebula Click Fork button (top right) to establish a cloud-based fork. Step 2: Clone Fork to Local Storage \u00b6 Define a local working directory: # Define your working directory working_dir = $HOME /Workspace Set user to match your Github profile name: user ={ your Github profile name } Create your clone: mkdir -p $working_dir cd $working_dir git clone https://github.com/ $user /nebula.git # the following is recommended # or: git clone git@github.com:$user/nebula.git cd $working_dir /nebula git remote add upstream https://github.com/vesoft-inc/nebula.git # or: git remote add upstream git@github.com:vesoft-inc/nebula.git # Never push to upstream master since you do not have write access. git remote set-url --push upstream no_push # Confirm that your remotes make sense: # It should look like: # origin git@github.com:$(user)/nebula.git (fetch) # origin git@github.com:$(user)/nebula.git (push) # upstream https://github.com/vesoft-inc/nebula (fetch) # upstream no_push (push) git remote -v Define a Pre-Commit Hook \u00b6 Please link the Nebula Graph pre-commit hook into your .git directory. This hook checks your commits for formatting, building, doc generation, etc. cd $working_dir /nebula/.git/hooks ln -s ../../.linters/cpp/hooks/pre-commit.sh . Sometimes, pre-commit hook can not be executable. In such case, you have to make it executable manually. cd $working_dir /nebula/.git/hooks chmod +x pre-commit Step 3: Branch \u00b6 Get your local master up to date: cd $working_dir /nebula git fetch upstream git checkout master git rebase upstream/master Checkout a new branch from master: git checkout -b myfeature NOTE : Because your PR often consists of several commits, which might be squashed while being merged into upstream, we strongly suggest you open a separate topic branch to make your changes on. After merged, this topic branch could be just abandoned, thus you could synchronize your master branch with upstream easily with a rebase like above. Otherwise, if you commit your changes directly into master, maybe you must use a hard reset on the master branch, like: git fetch upstream git checkout master git reset --hard upstream/master git push --force origin master Step 4: Develop \u00b6 Edit the Code \u00b6 You can now edit the code on myfeature branch. Please be noted that we are following Google C++ Style Guide . Verifying Your Code \u00b6 Compiling the Source Code \u00b6 Please refer to the build source code documentation to compile. Code Verification \u00b6 Replace the binary files The compiled binary files of the three services are in nebula/build/src/daemon/_build/ directory. The compiled console is in nebula/build/src/console/_build directory. You can replace the binary files in the bin directory, restart the services and verify. - Add unit tests There is a test directory in the modified code module. You can add unit tests in it, then compile and run the unit tests. Please make sure your submitted codes pass all the unit tests. - Run all the unit tests bash cd nebula/build ctest -j$(nproc) Step 5: Keep Your Branch in Sync \u00b6 # While on your myfeature branch. git fetch upstream git rebase upstream/master Step 6: Commit \u00b6 Commit your changes. git commit Likely you'll go back and edit/build/test some more than commit --amend in a few cycles. Step 7: Push \u00b6 When ready to review (or just to establish an offsite backup or your work), push your branch to your fork on github.com : git push -f origin myfeature Step 8: Create a Pull Request \u00b6 Visit your fork at https://github.com/$user/nebula (replace $user obviously). Click the Compare & pull request button next to your myfeature branch. Step 9: Get a Code Review \u00b6 Once your pull request has been opened, it will be assigned to at least two reviewers. Those reviewers will do a thorough code review to ensure the changes meet the repository's contributing guidelines and other quality standards.","title":"How to Contribute"},{"location":"manual-EN/4.contributions/how-to-contribute/#how_to_contribute","text":"","title":"How to Contribute"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_1_fork_in_the_cloud","text":"Visit https://github.com/vesoft-inc/nebula Click Fork button (top right) to establish a cloud-based fork.","title":"Step 1: Fork in the Cloud"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_2_clone_fork_to_local_storage","text":"Define a local working directory: # Define your working directory working_dir = $HOME /Workspace Set user to match your Github profile name: user ={ your Github profile name } Create your clone: mkdir -p $working_dir cd $working_dir git clone https://github.com/ $user /nebula.git # the following is recommended # or: git clone git@github.com:$user/nebula.git cd $working_dir /nebula git remote add upstream https://github.com/vesoft-inc/nebula.git # or: git remote add upstream git@github.com:vesoft-inc/nebula.git # Never push to upstream master since you do not have write access. git remote set-url --push upstream no_push # Confirm that your remotes make sense: # It should look like: # origin git@github.com:$(user)/nebula.git (fetch) # origin git@github.com:$(user)/nebula.git (push) # upstream https://github.com/vesoft-inc/nebula (fetch) # upstream no_push (push) git remote -v","title":"Step 2: Clone Fork to Local Storage"},{"location":"manual-EN/4.contributions/how-to-contribute/#define_a_pre-commit_hook","text":"Please link the Nebula Graph pre-commit hook into your .git directory. This hook checks your commits for formatting, building, doc generation, etc. cd $working_dir /nebula/.git/hooks ln -s ../../.linters/cpp/hooks/pre-commit.sh . Sometimes, pre-commit hook can not be executable. In such case, you have to make it executable manually. cd $working_dir /nebula/.git/hooks chmod +x pre-commit","title":"Define a Pre-Commit Hook"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_3_branch","text":"Get your local master up to date: cd $working_dir /nebula git fetch upstream git checkout master git rebase upstream/master Checkout a new branch from master: git checkout -b myfeature NOTE : Because your PR often consists of several commits, which might be squashed while being merged into upstream, we strongly suggest you open a separate topic branch to make your changes on. After merged, this topic branch could be just abandoned, thus you could synchronize your master branch with upstream easily with a rebase like above. Otherwise, if you commit your changes directly into master, maybe you must use a hard reset on the master branch, like: git fetch upstream git checkout master git reset --hard upstream/master git push --force origin master","title":"Step 3: Branch"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_4_develop","text":"","title":"Step 4: Develop"},{"location":"manual-EN/4.contributions/how-to-contribute/#edit_the_code","text":"You can now edit the code on myfeature branch. Please be noted that we are following Google C++ Style Guide .","title":"Edit the Code"},{"location":"manual-EN/4.contributions/how-to-contribute/#verifying_your_code","text":"","title":"Verifying Your Code"},{"location":"manual-EN/4.contributions/how-to-contribute/#compiling_the_source_code","text":"Please refer to the build source code documentation to compile.","title":"Compiling the Source Code"},{"location":"manual-EN/4.contributions/how-to-contribute/#code_verification","text":"Replace the binary files The compiled binary files of the three services are in nebula/build/src/daemon/_build/ directory. The compiled console is in nebula/build/src/console/_build directory. You can replace the binary files in the bin directory, restart the services and verify. - Add unit tests There is a test directory in the modified code module. You can add unit tests in it, then compile and run the unit tests. Please make sure your submitted codes pass all the unit tests. - Run all the unit tests bash cd nebula/build ctest -j$(nproc)","title":"Code Verification"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_5_keep_your_branch_in_sync","text":"# While on your myfeature branch. git fetch upstream git rebase upstream/master","title":"Step 5: Keep Your Branch in Sync"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_6_commit","text":"Commit your changes. git commit Likely you'll go back and edit/build/test some more than commit --amend in a few cycles.","title":"Step 6: Commit"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_7_push","text":"When ready to review (or just to establish an offsite backup or your work), push your branch to your fork on github.com : git push -f origin myfeature","title":"Step 7: Push"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_8_create_a_pull_request","text":"Visit your fork at https://github.com/$user/nebula (replace $user obviously). Click the Compare & pull request button next to your myfeature branch.","title":"Step 8: Create a Pull Request"},{"location":"manual-EN/4.contributions/how-to-contribute/#step_9_get_a_code_review","text":"Once your pull request has been opened, it will be assigned to at least two reviewers. Those reviewers will do a thorough code review to ensure the changes meet the repository's contributing guidelines and other quality standards.","title":"Step 9: Get a Code Review"},{"location":"manual-EN/4.contributions/pull-request-commit-message-guidelines/","text":"Pull Request and Commit Message Guidelines \u00b6 This document describes the commit message and Pull Request style applied to all Nebula Graph repositories. Every commit made directly to the master branch must follow the below guidelines. Commit Message \u00b6 <type> ( <scope> ) : <subject> // scope is optional, subject is must <body> // optional <footer> // optional These rules are adopted from the AngularJS commit convention . <Type> describes the kind of change that this commit is providing. <subject> is a short description of the change. If additional details are required, add a blank line, and then provide explanation and context in paragraph format. Commit Types \u00b6 Type Description Feature New features Fix Bug fix Doc Documentation changes Style Formatting, missing semi colons, ... Refactor Code cleanup Test New tests Chore Maintain Pull Request \u00b6 When you submit a Pull Request, please include enough details about all changes in the title but keep it concise. The title of a pull request must briefly describe the changes made. For very simple changes, you can leave the description blank as there\u2019s no need to describe what will be obvious from looking at the diff. For more complex changes, give an overview of the changes. If the PR fixes an issue, make sure to include the GitHub issue-number in the description. Pull Request Template \u00b6 What changes were proposed in this pull request? Why are the changes needed? Does this PR introduce any user-facing change? How was this patch tested?","title":"Pull Request and Commit Message Guidelines"},{"location":"manual-EN/4.contributions/pull-request-commit-message-guidelines/#pull_request_and_commit_message_guidelines","text":"This document describes the commit message and Pull Request style applied to all Nebula Graph repositories. Every commit made directly to the master branch must follow the below guidelines.","title":"Pull Request and Commit Message Guidelines"},{"location":"manual-EN/4.contributions/pull-request-commit-message-guidelines/#commit_message","text":"<type> ( <scope> ) : <subject> // scope is optional, subject is must <body> // optional <footer> // optional These rules are adopted from the AngularJS commit convention . <Type> describes the kind of change that this commit is providing. <subject> is a short description of the change. If additional details are required, add a blank line, and then provide explanation and context in paragraph format.","title":"Commit Message"},{"location":"manual-EN/4.contributions/pull-request-commit-message-guidelines/#commit_types","text":"Type Description Feature New features Fix Bug fix Doc Documentation changes Style Formatting, missing semi colons, ... Refactor Code cleanup Test New tests Chore Maintain","title":"Commit Types"},{"location":"manual-EN/4.contributions/pull-request-commit-message-guidelines/#pull_request","text":"When you submit a Pull Request, please include enough details about all changes in the title but keep it concise. The title of a pull request must briefly describe the changes made. For very simple changes, you can leave the description blank as there\u2019s no need to describe what will be obvious from looking at the diff. For more complex changes, give an overview of the changes. If the PR fixes an issue, make sure to include the GitHub issue-number in the description.","title":"Pull Request"},{"location":"manual-EN/4.contributions/pull-request-commit-message-guidelines/#pull_request_template","text":"What changes were proposed in this pull request? Why are the changes needed? Does this PR introduce any user-facing change? How was this patch tested?","title":"Pull Request Template"},{"location":"manual-EN/5.appendix/cypher-ngql/","text":"Comparison Between Cypher and nGQL \u00b6 Conceptual Comparisons \u00b6 Name Cypher nGQL vertex, node node vertex edge, relationship relationship edge vertex type label tag edge type relationship type edge type vertex identifier node id generated by default vid edge identifier edge id generated by default Basic Graph Operations \u00b6 Operations Cypher nGQL List all labels/tags * MATCH (n) RETURN distinct labels(n); * call db.labels(); SHOW TAGS Insert a vertex with a specified type CREATE (:Person {age: 16}) INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) Insert an edge with specified edge type CREATE (src)-[rel:LIKES]->(dst) SET rel.prop = V INSERT EDGE ( ) VALUES -> [@ ]: ( ) Delete a vertex MATCH (n) WHERE ID(n) = vid DETACH DELETE n DELETE VERTEX \\ Delete an edge MATCH ()-[r]->() WHERE ID(r)=edgeID DELETE r DELETE EDGE \\ -> \\ [@ ] Update a vertex property SET n.name = V UPDATE VERTEX \\ SET Fetch vertice prop MATCH (n) WHERE ID(n) = vid RETURN properties(n) FETCH PROP ON \\ Fetch edges prop MATCH (n)-[r]->() WHERE ID(r)=edgeID return properties(r) FETCH PROP ON -> [@ ] Query a vertex along specified edge type MATCH (n)-[r:edge_type]->() WHERE ID(n) = vid GO FROM \\ OVER \\ Query a vertex along specified edge type reversely MATCH (n)<-[r:edge_type]-() WHERE ID(n) = vid GO FROM \\ OVER \\ REVERSELY Get the N-Hop along a specified edge type MATCH (n)-[r:edge_type*N]->() WHERE ID(n) = vid return r GO N STEPS FROM \\ OVER \\ Find path between two vertices MATCH p =(a)-[]->(b) WHERE ID(a) = a_vid AND ID(b) = b_vid RETURN p FIND ALL PATH FROM \\ TO \\ OVER * Example Queries \u00b6 The example queries are based on the graph below: Insert data # insert vertex nebula> INSERT VERTEX character(name, age, type) VALUES hash(\"saturn\"):(\"saturn\", 10000, \"titan\"), hash(\"jupiter\"):(\"jupiter\", 5000, \"god\"); # insert edge nebula> INSERT EDGE father() VALUES hash(\"jupiter\")->hash(\"saturn\"):(); // cypher cypher> CREATE (src:character {name:\"saturn\", age: 10000, type:\"titan\"}) > CREATE (dst:character {name:\"jupiter\", age: 5000, type:\"god\"}) > CREATE (src)-[rel:father]->(dst) ``` - Delete vertex ```ngql nebula> DELETE VERTEX hash(\"prometheus\"); cypher> MATCH (n:character {name:\"prometheus\"}) > DETACH DELETE n Update vertex nebula> UPDATE VERTEX hash(\"jesus\") SET character.type = 'titan'; cypher> MATCH (n:character {name:\"jesus\"}) > SET n.type = 'titan' Fetch vertices properties nebula> FETCH PROP ON character hash(\"saturn\"); =================================================== | character.name | character.age | character.type | =================================================== | saturn | 10000 | titan | --------------------------------------------------- cypher> MATCH (n:character {name:\"saturn\"}) > RETURN properties(n) \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"properties(n)\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502{\"name\":\"saturn\",\"type\":\"titan\",\"age\":10000}\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find the name of hercules's grandfather nebula> GO 2 STEPS FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | saturn | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father*2]->(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"satun\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find the name of hercules's father nebula> GO FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | jupiter | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father]->(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"jupiter\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find the the centenarians' name. nebula> # coming soon cypher> MATCH (src:character) > WHERE src.age > 100 > RETURN src.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"src.name\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"saturn\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"jupiter\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 \u2502 \"pluto\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find who live with pluto nebula> GO FROM hash(\"pluto\") OVER lives YIELD lives._dst AS place | GO FROM $-.place OVER lives REVERSELY WHERE \\ > $$.character.name != \"pluto\" YIELD $$.character.name AS cohabitants; =============== | cohabitants | =============== | cerberus | --------------- cypher> MATCH (src:character{name:\"pluto\"})-[r1:lives]->()<-[r2:lives]-(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"cerberus\"\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find pluto's brother and their habitations? nebula> GO FROM hash(\"pluto\") OVER brother YIELD brother._dst AS god | \\ > GO FROM $-.god OVER lives YIELD $^.character.name AS Brother, $$.location.name AS Habitations; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- cypher> MATCH (src:Character{name:\"pluto\"})-[r1:brother]->(bro:Character)-[r2:lives]->(dst) > RETURN bro.name, dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"bro.name\" \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"jupiter\" \u2502 \"sky\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \"sea\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Cypher & nGQL"},{"location":"manual-EN/5.appendix/cypher-ngql/#comparison_between_cypher_and_ngql","text":"","title":"Comparison Between Cypher and nGQL"},{"location":"manual-EN/5.appendix/cypher-ngql/#conceptual_comparisons","text":"Name Cypher nGQL vertex, node node vertex edge, relationship relationship edge vertex type label tag edge type relationship type edge type vertex identifier node id generated by default vid edge identifier edge id generated by default","title":"Conceptual Comparisons"},{"location":"manual-EN/5.appendix/cypher-ngql/#basic_graph_operations","text":"Operations Cypher nGQL List all labels/tags * MATCH (n) RETURN distinct labels(n); * call db.labels(); SHOW TAGS Insert a vertex with a specified type CREATE (:Person {age: 16}) INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) Insert an edge with specified edge type CREATE (src)-[rel:LIKES]->(dst) SET rel.prop = V INSERT EDGE ( ) VALUES -> [@ ]: ( ) Delete a vertex MATCH (n) WHERE ID(n) = vid DETACH DELETE n DELETE VERTEX \\ Delete an edge MATCH ()-[r]->() WHERE ID(r)=edgeID DELETE r DELETE EDGE \\ -> \\ [@ ] Update a vertex property SET n.name = V UPDATE VERTEX \\ SET Fetch vertice prop MATCH (n) WHERE ID(n) = vid RETURN properties(n) FETCH PROP ON \\ Fetch edges prop MATCH (n)-[r]->() WHERE ID(r)=edgeID return properties(r) FETCH PROP ON -> [@ ] Query a vertex along specified edge type MATCH (n)-[r:edge_type]->() WHERE ID(n) = vid GO FROM \\ OVER \\ Query a vertex along specified edge type reversely MATCH (n)<-[r:edge_type]-() WHERE ID(n) = vid GO FROM \\ OVER \\ REVERSELY Get the N-Hop along a specified edge type MATCH (n)-[r:edge_type*N]->() WHERE ID(n) = vid return r GO N STEPS FROM \\ OVER \\ Find path between two vertices MATCH p =(a)-[]->(b) WHERE ID(a) = a_vid AND ID(b) = b_vid RETURN p FIND ALL PATH FROM \\ TO \\ OVER *","title":"Basic Graph Operations"},{"location":"manual-EN/5.appendix/cypher-ngql/#example_queries","text":"The example queries are based on the graph below: Insert data # insert vertex nebula> INSERT VERTEX character(name, age, type) VALUES hash(\"saturn\"):(\"saturn\", 10000, \"titan\"), hash(\"jupiter\"):(\"jupiter\", 5000, \"god\"); # insert edge nebula> INSERT EDGE father() VALUES hash(\"jupiter\")->hash(\"saturn\"):(); // cypher cypher> CREATE (src:character {name:\"saturn\", age: 10000, type:\"titan\"}) > CREATE (dst:character {name:\"jupiter\", age: 5000, type:\"god\"}) > CREATE (src)-[rel:father]->(dst) ``` - Delete vertex ```ngql nebula> DELETE VERTEX hash(\"prometheus\"); cypher> MATCH (n:character {name:\"prometheus\"}) > DETACH DELETE n Update vertex nebula> UPDATE VERTEX hash(\"jesus\") SET character.type = 'titan'; cypher> MATCH (n:character {name:\"jesus\"}) > SET n.type = 'titan' Fetch vertices properties nebula> FETCH PROP ON character hash(\"saturn\"); =================================================== | character.name | character.age | character.type | =================================================== | saturn | 10000 | titan | --------------------------------------------------- cypher> MATCH (n:character {name:\"saturn\"}) > RETURN properties(n) \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"properties(n)\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502{\"name\":\"saturn\",\"type\":\"titan\",\"age\":10000}\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find the name of hercules's grandfather nebula> GO 2 STEPS FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | saturn | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father*2]->(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"satun\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find the name of hercules's father nebula> GO FROM hash(\"hercules\") OVER father YIELD $$.character.name; ===================== | $$.character.name | ===================== | jupiter | --------------------- cypher> MATCH (src:character{name:\"hercules\"})-[r:father]->(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"jupiter\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find the the centenarians' name. nebula> # coming soon cypher> MATCH (src:character) > WHERE src.age > 100 > RETURN src.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"src.name\" \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"saturn\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"jupiter\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 \u2502 \"pluto\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find who live with pluto nebula> GO FROM hash(\"pluto\") OVER lives YIELD lives._dst AS place | GO FROM $-.place OVER lives REVERSELY WHERE \\ > $$.character.name != \"pluto\" YIELD $$.character.name AS cohabitants; =============== | cohabitants | =============== | cerberus | --------------- cypher> MATCH (src:character{name:\"pluto\"})-[r1:lives]->()<-[r2:lives]-(dst:character) > RETURN dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502\"cerberus\"\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find pluto's brother and their habitations? nebula> GO FROM hash(\"pluto\") OVER brother YIELD brother._dst AS god | \\ > GO FROM $-.god OVER lives YIELD $^.character.name AS Brother, $$.location.name AS Habitations; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- cypher> MATCH (src:Character{name:\"pluto\"})-[r1:brother]->(bro:Character)-[r2:lives]->(dst) > RETURN bro.name, dst.name \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555 \u2502\"bro.name\" \u2502\"dst.name\"\u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 \"jupiter\" \u2502 \"sky\" \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \"neptune\" \u2502 \"sea\" \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Example Queries"},{"location":"manual-EN/5.appendix/gremlin-ngql/","text":"Comparison Between Gremlin and nGQL \u00b6 Introduction to Gremlin \u00b6 Gremlin is a graph traversal language developed by Apache TinkerPop. It can be either declarative or imperative. Gremlin is Groovy-based, but has many language variants that allow developers to write Gremlin queries natively in many modern programming languages such as Java, JavaScript, Python, Scala, Clojure and Groovy. Introduction to nGQL \u00b6 Nebula Graph introduces its own query language, nGQL , which is a declarative, textual query language like SQL, but for graphs. Unlike SQL, nGQL is all about expressing graph patterns. The features of nGQL are as follows: Syntax is close to SQL, but not exactly the same (Easy to learn) Expandable Keyword is case insensitive Support basic graph traverse Support pattern matching Support aggregation Support graph mutation Support distributed transaction (future release) Statement composition, but NO statement embedding (Easy to read) Conceptual Comparisons \u00b6 Name Gremlin nGQL vertex, node vertex vertex edge, relationship edge edge vertex type label tag edge type label edge type vertex id vid vid edge id eid not support In Gremlin and nGQL, vertices and edges are identified with unique identifiers. In Nebula Graph , you can either specify identifiers or generate automatically with the hash or uuid function. Basic Graph Operations \u00b6 Name Gremlin nGQL Create a new graph g = TinkerGraph.open().traversal() CREATE SPACE gods Show vertices' types g.V().label() SHOW TAGS Insert a vertex with a specified type g.addV(String vertexLabel).property() INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) Insert an edge with specified edge type g.addE(String edgeLabel).from(v1).to(v2).property() INSERT EDGE ( ) VALUES -> : ( ) Delete a vertex g.V(\\ ).drop() DELETE VERTEX \\ Delete an edge g.E(\\ ).outE(\\ ).where(otherV().is(\\ ))drop() DELETE EDGE \\ -> \\ Update a vertex property g.V(\\ ).property() UPDATE VERTEX \\ SET Fetch vertices with ID g.V(\\ ) FETCH PROP ON \\ Fetch edges with ID g.E( >> ) FETCH PROP ON -> Query a vertex along specified edge type g.V(\\ ).outE( \\ ) GO FROM \\ OVER \\ Query a vertex along specified edge type reversely g.V(\\ ).in( \\ ) GO FROM \\ OVER \\ REVERSELY Query N hops along a specified edge g.V(\\ ).repeat(out(\\ )).times(N) GO N STEPS FROM \\ OVER \\ Find path between two vertices g.V(\\ ).repeat(out()).until(\\ ).path() FIND ALL PATH FROM \\ TO \\ OVER * Example Queries \u00b6 The examples in this section make extensive use of the toy graph distributed with Janus Graph called The Graphs of Gods . This graph is diagrammed below. The abstract data model is known as a Property Graph Model and this particular instance describes the relationships between the beings and places of the Roman pantheon. Insert data # insert vertex nebula> INSERT VERTEX character ( name,age, type ) VALUES hash ( \"saturn\" ) : ( \"saturn\" , 10000 , \"titan\" ) , hash ( \"jupiter\" ) : ( \"jupiter\" , 5000 , \"god\" ) ; gremlin> saturn = g.addV ( \"character\" ) .property ( T.id, 1 ) .property ( 'name' , 'saturn' ) .property ( 'age' , 10000 ) .property ( 'type' , 'titan' ) .next () ; == >v [ 1 ] gremlin> jupiter = g.addV ( \"character\" ) .property ( T.id, 2 ) .property ( 'name' , 'jupiter' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 2 ] gremlin> prometheus = g.addV ( \"character\" ) .property ( T.id, 31 ) .property ( 'name' , 'prometheus' ) .property ( 'age' , 1000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 31 ] gremlin> jesus = g.addV ( \"character\" ) property ( T.id, 32 ) .property ( 'name' , 'jesus' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 32 ] # insert edge nebula> INSERT EDGE father () VALUES hash ( \"jupiter\" ) ->hash ( \"saturn\" ) : () ; gremlin> g.addE ( \"father\" ) .from ( jupiter ) .to ( saturn ) .property ( T.id, 13 ) ; == >e [ 13 ][ 2 -father->1 ] Delete vertex nebula> DELETE VERTEX hash ( \"prometheus\" ) ; gremlin> g.V ( prometheus ) .drop () ; Update vertex nebula> UPDATE VERTEX hash ( \"jesus\" ) SET character.type = 'titan' ; gremlin> g.V ( jesus ) .property ( 'age' , 6000 ) ; Fetch data nebula> FETCH PROP ON character hash ( \"saturn\" ) ; ================================================== | character.name | character.age | character.type | ================================================== | saturn | 10000 | titan | -------------------------------------------------- gremlin> g.V ( saturn ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] Find the name of hercules's grandfather nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO 2 STEPS FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | saturn | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .out ( 'father' ) .values ( 'name' ) ; == >saturn Find the name of hercules's father nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .values ( 'name' ) ; == >jupiter Find the characters with age > 100 nebula> LOOKUP ON character WHERE character.age > 100 YIELD character.name ; ========================================= | VertexID | character.name | ========================================= | 6761447489613431910 | pluto | ----------------------------------------- | -5860788569139907963 | neptune | ----------------------------------------- | 4863977009196259577 | jupiter | ----------------------------------------- | -4316810810681305233 | saturn | ----------------------------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'age' ,gt ( 100 )) .values ( 'name' ) ; == >saturn == >jupiter == >neptune == >pluto Find who are pluto's cohabitants nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | \\ GO FROM $- .place OVER lives REVERSELY YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | pluto | --------------- | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .values ( 'name' ) ; == >pluto == >cerberus pluto can't be his own cohabitant nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus Pluto's Brothers # where do pluto's brothers live? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS brother | \\ GO FROM $- .brother OVER lives YIELD $$ .location.name ; ==================== | $$ .location.name | ==================== | sky | -------------------- | sea | -------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .out ( 'lives' ) .values ( 'name' ) ; == >sky == >sea # which brother lives in which place? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS god | \\ GO FROM $- .god OVER lives YIELD $^.character.name AS Brother, $$ .location.name AS Habitations ; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .as ( 'god' ) .out ( 'lives' ) .as ( 'place' ) .select ( 'god' , 'place' ) .by ( 'name' ) ; == > [ god:jupiter, place:sky ] == > [ god:neptune, place:sea ] Advance Queries \u00b6 Graph Exploration \u00b6 # Gremlin version gremlin> Gremlin.version () ; == >3.3.5 # Return all the vertices gremlin> g.V () ; == >v [ 1 ] == >v [ 2 ] ... nebula> # Coming soon # Count all the vertices gremlin> g.V () .count () ; == >12 nebula> # Coming soon # Count the vertices and edges by label gremlin> g.V () .groupCount () .by ( label ) ; == > [ character:9,location:3 ] gremlin> g.E () .groupCount () .by ( label ) ; == > [ mother:1,lives:5,father:2,brother:6,battled:3,pet:1 ] nebula> # Coming soon # Return all edges gremlin> g.E () ; == >e [ 13 ][ 2 -father->1 ] == >e [ 14 ][ 2 -lives->3 ] ... nebula> # Coming soon # Return vertices labels gremlin> g.V () .label () .dedup () ; == >character == >location nebula> SHOW TAGS ; ================== | ID | Name | ================== | 15 | character | ------------------ | 16 | location | ------------------ # Return edge types gremlin> g.E () .label () .dedup () ; == >father == >lives ...nebula> SHOW EDGES ; ================ | ID | Name | ================ | 17 | father | ---------------- | 18 | brother | ---------------- ... # Return all vertices properties gremlin> g.V () .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ... nebula> # Coming soon # Return properties of vertices labeled character gremlin> g.V () .hasLabel ( 'character' ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ... Traversing Edges \u00b6 Name Gremlin nGQL Out adjacent vertices to the vertex out(\\ ) GO FROM \\ OVER \\ In adjacent vertices to the vertex in(\\ ) GO FROM \\ OVER \\ REVERSELY Both adjacent vertices of the vertex both(\\ ) GO FROM \\ OVER \\ BIDIRECT # Find the out adjacent vertices of a vertex along an edge gremlin> g.V ( jupiter ) .out ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother ; ======================== | brother._dst | ======================== | 6761447489613431910 | ------------------------ | -5860788569139907963 | ------------------------ # Find the in adjacent vertices of a vertex along an edge gremlin> g.V ( jupiter ) .in ( 'brother' ) ; == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother REVERSELY ; ======================= | brother._dst | ======================= | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # Find the both adjacent vertices of a vertex along an edge gremlin> g.V ( jupiter ) .both ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother BIDIRECT ; ======================= | brother._dst | ======================= | 6761447489613431910 | ------------------------ | -5860788569139907963 | | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # Two hops out traverse gremlin> g.V ( hercules ) .out ( 'father' ) .out ( 'lives' ) ; == >v [ 3 ] nebula> GO FROM hash ( \"hercules\" ) OVER father YIELD father._dst AS id | \\ GO FROM $- .id OVER lives ; ======================== | lives._dst | ======================== | -1121386748834253737 | ------------------------ Has Filter Condition \u00b6 Name Gremlin nGQL Filter vertex via identifier hasId(\\ ) FETCH PROP ON \\ Filter vertex or edge via label, key and value has(\\ , \\ , \\ ) LOOKUP \\ | \\ WHERE \\ # Filter vertex with ID saturn gremlin> g.V () .hasId ( saturn ) ; == >v [ 1 ] nebula> FETCH PROP ON * hash ( \"saturn\" ) ; ========================================================================== | VertexID | character.name | character.age | character.type | ========================================================================== | -4316810810681305233 | saturn | 10000 | titan | -------------------------------------------------------------------------- # Find for vertices with tag \"character\" and \"name\" attribute value \"hercules\" gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .valueMap () ; == > [ name: [ hercules ] ,type: [ demigod ] ,age: [ 30 ]] nebula> LOOKUP ON character WHERE character.name == 'hercules' YIELD character.name, character.age, character.type ; ========================================================================= | VertexID | character.name | character.age | character.type | ========================================================================= | 5976696804486077889 | hercules | 30 | demigod | ------------------------------------------------------------------------- Limiting Returned Results \u00b6 Name Gremlin nGQL Constrain the number of rows to return limit() LIMIT Emit the last n-objects tail() ORDER BY \\ DESC LIMIT Skip n-objects skip() LIMIT \\ # Find the first two records gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .limit ( 2 ) ; == >v [ 9 ] == >v [ 10 ] nebula> GO FROM hash ( 'hercules' ) OVER battled | LIMIT 2 ; ======================= | battled._dst | ======================= | 530133512982221454 | ----------------------- | -695163537569412701 | ----------------------- # Find the last record gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .tail ( 1 ) ; == >cerberus nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ; ============ | name | ============ | cerberus | ------------ # Skip the first record and return one record gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .skip ( 1 ) .limit ( 1 ) ; == >hydra nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ,1 ; ========= | name | ========= | hydra | --------- Finding Path \u00b6 Name Gremlin nGQL All path path() FIND ALL PATH Exclude cycles path simplePath() \\ Only cycles path cyclicPath() \\ Shortest path \\ FIND SHORTEST PATH NOTE: Nebula Graph requires the source vertex and the dest vertex to find path while Gremlin only needs the source vertex. # Find path from vertex pluto to the out adjacent vertices gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .out () .path () ; == > [ v [ 8 ] ,v [ 12 ]] == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] == > [ v [ 8 ] ,v [ 11 ]] # Find the shortest path from vertex pluto to vertex jupiter nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ FIND SHORTEST PATH FROM $- .VertexID TO hash ( \"jupiter\" ) OVER * ; ============================================================ | _path_ | ============================================================ | 6761447489613431910 <brother,0> 4863977009196259577 ------------------------------------------------------------ Traversing N Hops \u00b6 Name Gremlin nGQL Loop over a traversal repeat() N STEPS Times the traverser has gone through a loop times() N STEPS Specify when to end the loop until() \\ Specify when to collect data emit() \\ # Find vertex pluto's out adjacent neighbors gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .repeat ( out ()) .times ( 1 ) ; == >v [ 12 ] == >v [ 2 ] == >v [ 5 ] == >v [ 11 ] nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ GO FROM $- .VertexID OVER * ; ================================================================================================================ | father._dst | brother._dst | lives._dst | mother._dst | pet._dst | battled._dst | ================================================================================================================ | 0 | -5860788569139907963 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 4863977009196259577 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | -4331657707562925133 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | 0 | 0 | 4594048193862126013 | 0 | ---------------------------------------------------------------------------------------------------------------- # Find path between vertex hercules and vertex cerberus # Stop traversing when the dest vertex is cerberus gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .until ( has ( 'name' , 'cerberus' )) .path () ; == > [ v [ 6 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 8 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 5 ] ,v [ 8 ] ,v [ 11 ]] ... nebula> # Coming soon # Find path sourcing from vertex hercules # And the dest vertex type is character gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .emit ( hasLabel ( 'character' )) .path () ; == > [ v [ 6 ] ,v [ 7 ]] == > [ v [ 6 ] ,v [ 2 ]] == > [ v [ 6 ] ,v [ 9 ]] == > [ v [ 6 ] ,v [ 10 ]] ... nebula> # Coming soon # Find shortest path between pluto and saturn over any edge # And the deepest loop is 3 gremlin> g.V ( 'pluto' ) .repeat ( out () .simplePath ()) .until ( hasId ( 'saturn' ) .and () .loops () .is ( lte ( 3 ))) .hasId ( 'saturn' ) .path () ; nebula> FIND SHORTEST PATH FROM hash ( 'pluto' ) TO hash ( 'saturn' ) OVER * UPTO 3 STEPS ; ================================================================================================= | _path_ | ================================================================================================= | 6761447489613431910 <brother,0> 4863977009196259577 <father,0> -4316810810681305233 ------------------------------------------------------------------------------------------------- Ordering Results \u00b6 Name Gremlin nGQL Order the items increasingly order().by() ORDER BY Order the items decreasingly order().by(decr) ORDER BY DESC Randomize the records order order().by(shuffle) \\ # Find pluto's brother and order by age decreasingly. gremlin> g.V ( pluto ) .out ( 'brother' ) .order () .by ( 'age' , decr ) .valueMap () ; == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] == > [ name: [ neptune ] ,type: [ god ] ,age: [ 4500 ]] nebula> GO FROM hash ( 'pluto' ) OVER brother YIELD $$ .character.name AS Name, $$ .character.age as Age | ORDER BY Age DESC ; ================== | Name | Age | ================== | jupiter | 5000 | ------------------ | neptune | 4500 | ------------------ Group By \u00b6 Name Gremlin nGQL Group by items group().by() GROUP BY Remove repeated items dedup() DISTINCT Group by items and count groupCount() GROUP BY COUNT Note: The GROUP BY function can only be applied in the YIELD clause. # Group vertices by label then count gremlin> g.V () .group () .by ( label ) .by ( count ()) ; == > [ character:9,location:3 ] nebula> # Coming soon # Find vertex jupiter's out adjacency vertices, group by name, then count gremlin> g.V ( jupiter ) .out () .group () .by ( 'name' ) .by ( count ()) ; == > [ sky:1,saturn:1,neptune:1,pluto:1 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD $$ .character.name AS Name, $$ .character.age as Age, $$ .location.name | \\ GROUP BY $- .Name YIELD $- .Name, COUNT ( * ) ; ====================== | $- .Name | COUNT ( * ) | ====================== | | 1 | ---------------------- | pluto | 1 | ---------------------- | saturn | 1 | ---------------------- | neptune | 1 | ---------------------- # Find the distinct dest vertices sourcing from vertex jupiter gremlin> g.V ( jupiter ) .out () .hasLabel ( 'character' ) .dedup () ; == >v [ 1 ] == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD DISTINCT $$ .character.name, $$ .character.age, $$ .location.name ; =========================================================== | $$ .character.name | $$ .character.age | $$ .location.name | =========================================================== | pluto | 4000 | | ----------------------------------------------------------- | neptune | 4500 | | ----------------------------------------------------------- | saturn | 10000 | | ----------------------------------------------------------- | | 0 | sky | ----------------------------------------------------------- Where Filter Condition \u00b6 Name Gremlin nGQL Where filter condition where() WHERE Predicates comparison: Name Gremlin nGQL Equal to eq(object) == Not equal to neq(object) != Less than lt(number) < Less than or equal to lte(number) <= Greater than gt(number) > Greater than or equal to gte(number) >= Whether a value is within the array within(objects\u2026\u200b) udf_is_in() gremlin> eq ( 2 ) .test ( 3 ) ; == >false nebula> YIELD 3 == 2 ; ========== | ( 3 == 2 ) | ========== | false | ---------- gremlin> within ( 'a' , 'b' , 'c' ) .test ( 'd' ) ; == >false nebula> YIELD udf_is_in ( 'd' , 'a' , 'b' , 'c' ) ; ====================== | udf_is_in ( d,a,b,c ) | ====================== | false | ---------------------- # Find pluto's co-habitants and exclude himself gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | --------------- Logical Operators \u00b6 Name Gremlin nGQL Is is() == Not not() != And and() AND Or or() OR # Find age greater than or equal to 30 gremlin> g.V () .values ( 'age' ) .is ( gte ( 30 )) ; == >10000 == >5000 == >4500 == >30 == >45 == >4000 nebula> LOOKUP ON character WHERE character.age > = 30 YIELD character.age ; ======================================== | VertexID | character.age | ======================================== | -4316810810681305233 | 10000 | ---------------------------------------\u2013 | 4863977009196259577 | 5000 | ---------------------------------------\u2013 | -5860788569139907963 | 4500 | ---------------------------------------\u2013 | 5976696804486077889 | 30 | ---------------------------------------\u2013 | -6780323075177699500 | 45 | ---------------------------------------\u2013 | 6761447489613431910 | 4000 | ---------------------------------------\u2013 # Find character with name pluto and age 4000 gremlin> g.V () .has ( 'name' , 'pluto' ) .and () .has ( 'age' ,4000 ) ; == >v [ 8 ] nebula> LOOKUP ON character WHERE character.name == 'pluto' AND character.age == 4000 ; ======================= | VertexID | ======================= | 6761447489613431910 | ----------------------- # Logical not gremlin> g.V () .has ( 'name' , 'pluto' ) .out ( 'brother' ) .not ( values ( 'name' ) .is ( 'neptune' )) .values ( 'name' ) ; == >jupiter nebula> LOOKUP ON character WHERE character.name == 'pluto' YIELD character.name AS name | \\ GO FROM $- .VertexID OVER brother WHERE $$ .character.name ! = 'neptune' YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | --------------------- Statistical Operations \u00b6 Name Gremlin nGQL Sum sum() SUM() Max max() MAX() Min min() MIN() Mean mean() AVG() Nebula Graph statistical operations must be applied with GROUP BY . # Calculate the sum of ages of all characters gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .sum () ; == >23595 nebula> # Coming soon # Calculate the sum of the out brother edges of all characters gremlin> g.V () .hasLabel ( 'character' ) .map ( outE ( 'brother' ) .count ()) .sum () ; == >6 nebula> # Coming soon # Return the max age of all characters gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .max () ; == >10000 nebula> # Coming soon Selecting and Filtering Paths \u00b6 # Select the results of steps 1 and 3 from the path as the final result gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) ; == > [ a:v [ 8 ] ,c:v [ 3 ]] == > [ a:v [ 8 ] ,c:v [ 1 ]] ... nebula> # Coming soon # Specify dimensions via by() gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:pluto,c:sky ] == > [ a:pluto,c:saturn ] ... nebula> # Coming soon # Selects the specified key value from the map gremlin> g.V () .valueMap () .select ( 'name' ) .dedup () ; == > [ saturn ] == > [ jupiter ] ... nebula> # Coming soon Branches \u00b6 # Traverse all vertices with label 'character' # If name is 'jupiter', return the age property # Else return the name property gremlin> g.V () .hasLabel ( 'character' ) .choose ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 == >neptune ... # Lambda gremlin> g.V () .branch { it.get () .value ( 'name' )} .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 ... # Traversal gremlin> g.V () .branch ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 # Branch gremlin> g.V () .choose ( has ( 'name' , 'jupiter' ) ,values ( 'age' ) ,values ( 'name' )) ; == >saturn == >5000 # Group based on if then gremlin> g.V () .hasLabel ( \"character\" ) .groupCount () .by ( values ( \"age\" ) .choose ( is ( lt ( 40 )) ,constant ( \"young\" ) , choose ( is ( lt ( 4500 )) , constant ( \"old\" ) , constant ( \"very old\" )))) ; == > [ young:4,old:2,very old:3 ] Similar function is yet to be supported in Nebula Graph . Coalesce \u00b6 The coalesce() step evaluates the provided traversals in order and returns the first traversal that emits at least one element. The optional() step returns the result of the specified traversal if it yields a result else it returns the calling element, i.e. the identity(). The union() step supports the merging of the results of an arbitrary number of traversals. # If type is monster, return type. Else return 'Not a monster'. gremlin> g.V ( pluto ) .coalesce ( has ( 'type' , 'monster' ) .values ( 'type' ) ,constant ( \"Not a monster\" )) ; == >Not a monster # Find the following edges and adjacent vertices of jupiter in order, and stop when finding one # 1. Edge brother out adjacent vertices # 2. Edge father out adjacent vertices # 3. Edge father in adjacent vertices gremlin> g.V ( jupiter ) .coalesce ( outE ( 'brother' ) , outE ( 'father' ) , inE ( 'father' )) .inV () .path () .by ( 'name' ) .by ( label ) ; == > [ jupiter,brother,pluto ] == > [ jupiter,brother,neptune ] # Find pluto's father, if there is not any then return pluto himself gremlin> g.V ( pluto ) .optional ( out ( 'father' )) .valueMap () ; == > [ name: [ pluto ] ,type: [ god ] ,age: [ 4000 ]] # Find pluto's father and brother, union the results then return the paths gremlin> g.V ( pluto ) .union ( out ( 'father' ) ,both ( 'brother' )) .path () ; == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] Similar function is yet to be supported in Nebula Graph . Aggregating and Unfolding Results \u00b6 # Collect results of the first step into set x # Note: This operation doesn't affect subsequent results gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) ; == >v [ 12 ] == >v [ 2 ] ... # Specify the aggregation dimensions via by () gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .by ( 'name' ) .cap ( 'x' ) ; == > [ tartarus,jupiter,neptune,cerberus ] # Find pluto's 2 hop out adjacent neighbors # Collect the results in set x # Show the neighbors' name gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .out () .aggregate ( 'x' ) .cap ( 'x' ) .unfold () .values ( 'name' ) ; == >tartarus == >tartarus ... Similar function is yet to be supported in Nebula Graph . Matching Patterns \u00b6 The match() step provides a more declarative form of graph querying based on the notion of pattern matching. With match(), the user provides a collection of \"traversal fragments,\" called patterns, that have variables defined that must hold true throughout the duration of the match(). # Matching each vertex with the following pattern. If pattern is met, return map<String, Object>, els filter it. # Pattern 1: a is jupiter's son # Pattern 2: b is jupiter # Pattern 3: c is jupiter's brother, whose age is 4000 gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) ; == > [ a:v [ 6 ] ,b:v [ 2 ] ,c:v [ 8 ]] # match() can be applied with select() to select partial results from Map <String, Object> gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ] # match () can be applied with where () to filter the results gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .where ( 'a' , neq ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ] Random filtering \u00b6 The sample() step accepts an integer value and samples the maximum number of the specified results randomly from the previous traverser. The coin() step can randomly filter out a traverser with the given probability. You give coin a value indicating how biased the toss should be. # Randomly select 2 out edges from all vertices gremlin> g.V () .outE () .sample ( 2 ) ; == >e [ 15 ][ 2 -brother->5 ] == >e [ 18 ][ 5 -brother->2 ] # Pick 3 names randomly from all vertices gremlin> g.V () .values ( 'name' ) .sample ( 3 ) ; == >hercules == >sea == >jupiter # Pick 3 randomly from all characters based on age gremlin> g.V () .hasLabel ( 'character' ) .sample ( 3 ) .by ( 'age' ) ; == >v [ 1 ] == >v [ 2 ] == >v [ 6 ] # Applied with local to do random walk # Starting from pluto, conduct random walk 3 times gremlin> g.V ( pluto ) .repeat ( local ( bothE () .sample ( 1 ) .otherV ())) .times ( 3 ) .path () ; == > [ v [ 8 ] ,e [ 26 ][ 8 -brother->5 ] ,v [ 5 ] ,e [ 18 ][ 5 -brother->2 ] ,v [ 2 ] ,e [ 13 ][ 2 -father->1 ] ,v [ 1 ]] # Filter each vertex with a probability of 0.5 gremlin> g.V () .coin ( 0 .5 ) ; == >v [ 1 ] == >v [ 2 ] ... # Return the name attribute of all vertices labeled location, otherwise return not a location gremlin> g.V () .choose ( hasLabel ( 'location' ) , values ( 'name' ) , constant ( 'not a location' )) ; == >not a location == >not a location == >sky ... Sack \u00b6 A traverser that contains a local data structure is called a \"sack\". The sack() step is used to read and write sacks. Each sack of each traverser is created with withSack() . # Defines a Gremlin sack with a value of one and return values in the sack gremlin> g.withSack ( 1 ) .V () .sack () ; == >1 == >1 ... Barrier \u00b6 The barrier() step turns the lazy traversal pipeline into a bulk-synchronous pipeline. It's useful when everything prior to barrier() needs to be executed before moving onto the steps after the barrier(). # Calculate the Eigenvector Centrality with barrier # Including groupCount and cap, sorted in descending order gremlin> g.V () .repeat ( both () .groupCount ( 'm' )) .times ( 5 ) .cap ( 'm' ) .order ( local ) .by ( values, decr ) ; Local \u00b6 A GraphTraversal operates on a continuous stream of objects. In many situations, it is important to operate on a single element within that stream. To do such object-local traversal computations, local() step exists. # Without local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .properties ( 'age' ) .order () .by ( value,decr ) .limit ( 2 ) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () ; == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] # With local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .local ( properties ( 'age' ) .order () .by ( value ) .limit ( 2 )) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] == > [ character:neptune,age:4500 ] == > [ character:hercules,age:30 ] ... # Return the property map of monster gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'type' ) .propertyMap () ; == > [ name: [ vp [ name->nemean ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->20 ]]] == > [ name: [ vp [ name->hydra ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] == > [ name: [ vp [ name->cerberus ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] # Find number of monster gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'monster' ) .propertyMap () .count ( local ) ; == >3 == >3 == >3 # Find the max vertices number labeled tha same tag gremlin> g.V () .groupCount () .by ( label ) .select ( values ) .max ( local ) ; == >9 # List the first attribute of all vertices gremlin> g.V () .valueMap () .limit ( local, 1 ) ; == > [ name: [ saturn ]] == > [ name: [ jupiter ]] == > [ name: [ sky ]] ... # Without local gremlin> g.V () .valueMap () .limit ( 1 ) ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] # All vertices as a set, sample 2 from it gremlin> g.V () .fold () .sample ( local,2 ) ; == > [ v [ 8 ] ,v [ 1 ]] Statistics and Analysis \u00b6 Gremlin provides two steps for statistics and analysis of the executed query statements: The explain() step will return a TraversalExplanation. A traversal explanation details how the traversal (prior to explain()) will be compiled given the registered traversal strategies. The profile() step allows developers to profile their traversals to determine statistical information like step runtime, counts, etc.","title":"Gremlin & nGQL"},{"location":"manual-EN/5.appendix/gremlin-ngql/#comparison_between_gremlin_and_ngql","text":"","title":"Comparison Between Gremlin and nGQL"},{"location":"manual-EN/5.appendix/gremlin-ngql/#introduction_to_gremlin","text":"Gremlin is a graph traversal language developed by Apache TinkerPop. It can be either declarative or imperative. Gremlin is Groovy-based, but has many language variants that allow developers to write Gremlin queries natively in many modern programming languages such as Java, JavaScript, Python, Scala, Clojure and Groovy.","title":"Introduction to Gremlin"},{"location":"manual-EN/5.appendix/gremlin-ngql/#introduction_to_ngql","text":"Nebula Graph introduces its own query language, nGQL , which is a declarative, textual query language like SQL, but for graphs. Unlike SQL, nGQL is all about expressing graph patterns. The features of nGQL are as follows: Syntax is close to SQL, but not exactly the same (Easy to learn) Expandable Keyword is case insensitive Support basic graph traverse Support pattern matching Support aggregation Support graph mutation Support distributed transaction (future release) Statement composition, but NO statement embedding (Easy to read)","title":"Introduction to nGQL"},{"location":"manual-EN/5.appendix/gremlin-ngql/#conceptual_comparisons","text":"Name Gremlin nGQL vertex, node vertex vertex edge, relationship edge edge vertex type label tag edge type label edge type vertex id vid vid edge id eid not support In Gremlin and nGQL, vertices and edges are identified with unique identifiers. In Nebula Graph , you can either specify identifiers or generate automatically with the hash or uuid function.","title":"Conceptual Comparisons"},{"location":"manual-EN/5.appendix/gremlin-ngql/#basic_graph_operations","text":"Name Gremlin nGQL Create a new graph g = TinkerGraph.open().traversal() CREATE SPACE gods Show vertices' types g.V().label() SHOW TAGS Insert a vertex with a specified type g.addV(String vertexLabel).property() INSERT VERTEX (prop_name_list) VALUES \\ :(prop_value_list) Insert an edge with specified edge type g.addE(String edgeLabel).from(v1).to(v2).property() INSERT EDGE ( ) VALUES -> : ( ) Delete a vertex g.V(\\ ).drop() DELETE VERTEX \\ Delete an edge g.E(\\ ).outE(\\ ).where(otherV().is(\\ ))drop() DELETE EDGE \\ -> \\ Update a vertex property g.V(\\ ).property() UPDATE VERTEX \\ SET Fetch vertices with ID g.V(\\ ) FETCH PROP ON \\ Fetch edges with ID g.E( >> ) FETCH PROP ON -> Query a vertex along specified edge type g.V(\\ ).outE( \\ ) GO FROM \\ OVER \\ Query a vertex along specified edge type reversely g.V(\\ ).in( \\ ) GO FROM \\ OVER \\ REVERSELY Query N hops along a specified edge g.V(\\ ).repeat(out(\\ )).times(N) GO N STEPS FROM \\ OVER \\ Find path between two vertices g.V(\\ ).repeat(out()).until(\\ ).path() FIND ALL PATH FROM \\ TO \\ OVER *","title":"Basic Graph Operations"},{"location":"manual-EN/5.appendix/gremlin-ngql/#example_queries","text":"The examples in this section make extensive use of the toy graph distributed with Janus Graph called The Graphs of Gods . This graph is diagrammed below. The abstract data model is known as a Property Graph Model and this particular instance describes the relationships between the beings and places of the Roman pantheon. Insert data # insert vertex nebula> INSERT VERTEX character ( name,age, type ) VALUES hash ( \"saturn\" ) : ( \"saturn\" , 10000 , \"titan\" ) , hash ( \"jupiter\" ) : ( \"jupiter\" , 5000 , \"god\" ) ; gremlin> saturn = g.addV ( \"character\" ) .property ( T.id, 1 ) .property ( 'name' , 'saturn' ) .property ( 'age' , 10000 ) .property ( 'type' , 'titan' ) .next () ; == >v [ 1 ] gremlin> jupiter = g.addV ( \"character\" ) .property ( T.id, 2 ) .property ( 'name' , 'jupiter' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 2 ] gremlin> prometheus = g.addV ( \"character\" ) .property ( T.id, 31 ) .property ( 'name' , 'prometheus' ) .property ( 'age' , 1000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 31 ] gremlin> jesus = g.addV ( \"character\" ) property ( T.id, 32 ) .property ( 'name' , 'jesus' ) .property ( 'age' , 5000 ) .property ( 'type' , 'god' ) .next () ; == >v [ 32 ] # insert edge nebula> INSERT EDGE father () VALUES hash ( \"jupiter\" ) ->hash ( \"saturn\" ) : () ; gremlin> g.addE ( \"father\" ) .from ( jupiter ) .to ( saturn ) .property ( T.id, 13 ) ; == >e [ 13 ][ 2 -father->1 ] Delete vertex nebula> DELETE VERTEX hash ( \"prometheus\" ) ; gremlin> g.V ( prometheus ) .drop () ; Update vertex nebula> UPDATE VERTEX hash ( \"jesus\" ) SET character.type = 'titan' ; gremlin> g.V ( jesus ) .property ( 'age' , 6000 ) ; Fetch data nebula> FETCH PROP ON character hash ( \"saturn\" ) ; ================================================== | character.name | character.age | character.type | ================================================== | saturn | 10000 | titan | -------------------------------------------------- gremlin> g.V ( saturn ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] Find the name of hercules's grandfather nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO 2 STEPS FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | saturn | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .out ( 'father' ) .values ( 'name' ) ; == >saturn Find the name of hercules's father nebula> LOOKUP ON character WHERE character.name == 'hercules' | \\ -> GO FROM $- .VertexID OVER father YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | --------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .out ( 'father' ) .values ( 'name' ) ; == >jupiter Find the characters with age > 100 nebula> LOOKUP ON character WHERE character.age > 100 YIELD character.name ; ========================================= | VertexID | character.name | ========================================= | 6761447489613431910 | pluto | ----------------------------------------- | -5860788569139907963 | neptune | ----------------------------------------- | 4863977009196259577 | jupiter | ----------------------------------------- | -4316810810681305233 | saturn | ----------------------------------------- gremlin> g.V () .hasLabel ( 'character' ) .has ( 'age' ,gt ( 100 )) .values ( 'name' ) ; == >saturn == >jupiter == >neptune == >pluto Find who are pluto's cohabitants nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | \\ GO FROM $- .place OVER lives REVERSELY YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | pluto | --------------- | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .values ( 'name' ) ; == >pluto == >cerberus pluto can't be his own cohabitant nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | --------------- gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus Pluto's Brothers # where do pluto's brothers live? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS brother | \\ GO FROM $- .brother OVER lives YIELD $$ .location.name ; ==================== | $$ .location.name | ==================== | sky | -------------------- | sea | -------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .out ( 'lives' ) .values ( 'name' ) ; == >sky == >sea # which brother lives in which place? nebula> GO FROM hash ( \"pluto\" ) OVER brother YIELD brother._dst AS god | \\ GO FROM $- .god OVER lives YIELD $^.character.name AS Brother, $$ .location.name AS Habitations ; ========================= | Brother | Habitations | ========================= | jupiter | sky | ------------------------- | neptune | sea | ------------------------- gremlin> g.V ( pluto ) .out ( 'brother' ) .as ( 'god' ) .out ( 'lives' ) .as ( 'place' ) .select ( 'god' , 'place' ) .by ( 'name' ) ; == > [ god:jupiter, place:sky ] == > [ god:neptune, place:sea ]","title":"Example Queries"},{"location":"manual-EN/5.appendix/gremlin-ngql/#advance_queries","text":"","title":"Advance Queries"},{"location":"manual-EN/5.appendix/gremlin-ngql/#graph_exploration","text":"# Gremlin version gremlin> Gremlin.version () ; == >3.3.5 # Return all the vertices gremlin> g.V () ; == >v [ 1 ] == >v [ 2 ] ... nebula> # Coming soon # Count all the vertices gremlin> g.V () .count () ; == >12 nebula> # Coming soon # Count the vertices and edges by label gremlin> g.V () .groupCount () .by ( label ) ; == > [ character:9,location:3 ] gremlin> g.E () .groupCount () .by ( label ) ; == > [ mother:1,lives:5,father:2,brother:6,battled:3,pet:1 ] nebula> # Coming soon # Return all edges gremlin> g.E () ; == >e [ 13 ][ 2 -father->1 ] == >e [ 14 ][ 2 -lives->3 ] ... nebula> # Coming soon # Return vertices labels gremlin> g.V () .label () .dedup () ; == >character == >location nebula> SHOW TAGS ; ================== | ID | Name | ================== | 15 | character | ------------------ | 16 | location | ------------------ # Return edge types gremlin> g.E () .label () .dedup () ; == >father == >lives ...nebula> SHOW EDGES ; ================ | ID | Name | ================ | 17 | father | ---------------- | 18 | brother | ---------------- ... # Return all vertices properties gremlin> g.V () .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ... nebula> # Coming soon # Return properties of vertices labeled character gremlin> g.V () .hasLabel ( 'character' ) .valueMap () ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] ...","title":"Graph Exploration"},{"location":"manual-EN/5.appendix/gremlin-ngql/#traversing_edges","text":"Name Gremlin nGQL Out adjacent vertices to the vertex out(\\ ) GO FROM \\ OVER \\ In adjacent vertices to the vertex in(\\ ) GO FROM \\ OVER \\ REVERSELY Both adjacent vertices of the vertex both(\\ ) GO FROM \\ OVER \\ BIDIRECT # Find the out adjacent vertices of a vertex along an edge gremlin> g.V ( jupiter ) .out ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother ; ======================== | brother._dst | ======================== | 6761447489613431910 | ------------------------ | -5860788569139907963 | ------------------------ # Find the in adjacent vertices of a vertex along an edge gremlin> g.V ( jupiter ) .in ( 'brother' ) ; == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother REVERSELY ; ======================= | brother._dst | ======================= | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # Find the both adjacent vertices of a vertex along an edge gremlin> g.V ( jupiter ) .both ( 'brother' ) ; == >v [ 8 ] == >v [ 5 ] == >v [ 5 ] == >v [ 8 ] nebula> GO FROM hash ( \"jupiter\" ) OVER brother BIDIRECT ; ======================= | brother._dst | ======================= | 6761447489613431910 | ------------------------ | -5860788569139907963 | | 4863977009196259577 | ----------------------- | 4863977009196259577 | ----------------------- # Two hops out traverse gremlin> g.V ( hercules ) .out ( 'father' ) .out ( 'lives' ) ; == >v [ 3 ] nebula> GO FROM hash ( \"hercules\" ) OVER father YIELD father._dst AS id | \\ GO FROM $- .id OVER lives ; ======================== | lives._dst | ======================== | -1121386748834253737 | ------------------------","title":"Traversing Edges"},{"location":"manual-EN/5.appendix/gremlin-ngql/#has_filter_condition","text":"Name Gremlin nGQL Filter vertex via identifier hasId(\\ ) FETCH PROP ON \\ Filter vertex or edge via label, key and value has(\\ , \\ , \\ ) LOOKUP \\ | \\ WHERE \\ # Filter vertex with ID saturn gremlin> g.V () .hasId ( saturn ) ; == >v [ 1 ] nebula> FETCH PROP ON * hash ( \"saturn\" ) ; ========================================================================== | VertexID | character.name | character.age | character.type | ========================================================================== | -4316810810681305233 | saturn | 10000 | titan | -------------------------------------------------------------------------- # Find for vertices with tag \"character\" and \"name\" attribute value \"hercules\" gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .valueMap () ; == > [ name: [ hercules ] ,type: [ demigod ] ,age: [ 30 ]] nebula> LOOKUP ON character WHERE character.name == 'hercules' YIELD character.name, character.age, character.type ; ========================================================================= | VertexID | character.name | character.age | character.type | ========================================================================= | 5976696804486077889 | hercules | 30 | demigod | -------------------------------------------------------------------------","title":"Has Filter Condition"},{"location":"manual-EN/5.appendix/gremlin-ngql/#limiting_returned_results","text":"Name Gremlin nGQL Constrain the number of rows to return limit() LIMIT Emit the last n-objects tail() ORDER BY \\ DESC LIMIT Skip n-objects skip() LIMIT \\ # Find the first two records gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .limit ( 2 ) ; == >v [ 9 ] == >v [ 10 ] nebula> GO FROM hash ( 'hercules' ) OVER battled | LIMIT 2 ; ======================= | battled._dst | ======================= | 530133512982221454 | ----------------------- | -695163537569412701 | ----------------------- # Find the last record gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .tail ( 1 ) ; == >cerberus nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ; ============ | name | ============ | cerberus | ------------ # Skip the first record and return one record gremlin> g.V () .has ( 'character' , 'name' , 'hercules' ) .out ( 'battled' ) .values ( 'name' ) .skip ( 1 ) .limit ( 1 ) ; == >hydra nebula> GO FROM hash ( 'hercules' ) OVER battled YIELD $$ .character.name AS name | ORDER BY name | LIMIT 1 ,1 ; ========= | name | ========= | hydra | ---------","title":"Limiting Returned Results"},{"location":"manual-EN/5.appendix/gremlin-ngql/#finding_path","text":"Name Gremlin nGQL All path path() FIND ALL PATH Exclude cycles path simplePath() \\ Only cycles path cyclicPath() \\ Shortest path \\ FIND SHORTEST PATH NOTE: Nebula Graph requires the source vertex and the dest vertex to find path while Gremlin only needs the source vertex. # Find path from vertex pluto to the out adjacent vertices gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .out () .path () ; == > [ v [ 8 ] ,v [ 12 ]] == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] == > [ v [ 8 ] ,v [ 11 ]] # Find the shortest path from vertex pluto to vertex jupiter nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ FIND SHORTEST PATH FROM $- .VertexID TO hash ( \"jupiter\" ) OVER * ; ============================================================ | _path_ | ============================================================ | 6761447489613431910 <brother,0> 4863977009196259577 ------------------------------------------------------------","title":"Finding Path"},{"location":"manual-EN/5.appendix/gremlin-ngql/#traversing_n_hops","text":"Name Gremlin nGQL Loop over a traversal repeat() N STEPS Times the traverser has gone through a loop times() N STEPS Specify when to end the loop until() \\ Specify when to collect data emit() \\ # Find vertex pluto's out adjacent neighbors gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'pluto' ) .repeat ( out ()) .times ( 1 ) ; == >v [ 12 ] == >v [ 2 ] == >v [ 5 ] == >v [ 11 ] nebula> LOOKUP ON character WHERE character.name == \"pluto\" YIELD character.name AS name | \\ GO FROM $- .VertexID OVER * ; ================================================================================================================ | father._dst | brother._dst | lives._dst | mother._dst | pet._dst | battled._dst | ================================================================================================================ | 0 | -5860788569139907963 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 4863977009196259577 | 0 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | -4331657707562925133 | 0 | 0 | 0 | ---------------------------------------------------------------------------------------------------------------- | 0 | 0 | 0 | 0 | 4594048193862126013 | 0 | ---------------------------------------------------------------------------------------------------------------- # Find path between vertex hercules and vertex cerberus # Stop traversing when the dest vertex is cerberus gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .until ( has ( 'name' , 'cerberus' )) .path () ; == > [ v [ 6 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 8 ] ,v [ 11 ]] == > [ v [ 6 ] ,v [ 2 ] ,v [ 5 ] ,v [ 8 ] ,v [ 11 ]] ... nebula> # Coming soon # Find path sourcing from vertex hercules # And the dest vertex type is character gremlin> g.V () .hasLabel ( 'character' ) .has ( 'name' , 'hercules' ) .repeat ( out ()) .emit ( hasLabel ( 'character' )) .path () ; == > [ v [ 6 ] ,v [ 7 ]] == > [ v [ 6 ] ,v [ 2 ]] == > [ v [ 6 ] ,v [ 9 ]] == > [ v [ 6 ] ,v [ 10 ]] ... nebula> # Coming soon # Find shortest path between pluto and saturn over any edge # And the deepest loop is 3 gremlin> g.V ( 'pluto' ) .repeat ( out () .simplePath ()) .until ( hasId ( 'saturn' ) .and () .loops () .is ( lte ( 3 ))) .hasId ( 'saturn' ) .path () ; nebula> FIND SHORTEST PATH FROM hash ( 'pluto' ) TO hash ( 'saturn' ) OVER * UPTO 3 STEPS ; ================================================================================================= | _path_ | ================================================================================================= | 6761447489613431910 <brother,0> 4863977009196259577 <father,0> -4316810810681305233 -------------------------------------------------------------------------------------------------","title":"Traversing N Hops"},{"location":"manual-EN/5.appendix/gremlin-ngql/#ordering_results","text":"Name Gremlin nGQL Order the items increasingly order().by() ORDER BY Order the items decreasingly order().by(decr) ORDER BY DESC Randomize the records order order().by(shuffle) \\ # Find pluto's brother and order by age decreasingly. gremlin> g.V ( pluto ) .out ( 'brother' ) .order () .by ( 'age' , decr ) .valueMap () ; == > [ name: [ jupiter ] ,type: [ god ] ,age: [ 5000 ]] == > [ name: [ neptune ] ,type: [ god ] ,age: [ 4500 ]] nebula> GO FROM hash ( 'pluto' ) OVER brother YIELD $$ .character.name AS Name, $$ .character.age as Age | ORDER BY Age DESC ; ================== | Name | Age | ================== | jupiter | 5000 | ------------------ | neptune | 4500 | ------------------","title":"Ordering Results"},{"location":"manual-EN/5.appendix/gremlin-ngql/#group_by","text":"Name Gremlin nGQL Group by items group().by() GROUP BY Remove repeated items dedup() DISTINCT Group by items and count groupCount() GROUP BY COUNT Note: The GROUP BY function can only be applied in the YIELD clause. # Group vertices by label then count gremlin> g.V () .group () .by ( label ) .by ( count ()) ; == > [ character:9,location:3 ] nebula> # Coming soon # Find vertex jupiter's out adjacency vertices, group by name, then count gremlin> g.V ( jupiter ) .out () .group () .by ( 'name' ) .by ( count ()) ; == > [ sky:1,saturn:1,neptune:1,pluto:1 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD $$ .character.name AS Name, $$ .character.age as Age, $$ .location.name | \\ GROUP BY $- .Name YIELD $- .Name, COUNT ( * ) ; ====================== | $- .Name | COUNT ( * ) | ====================== | | 1 | ---------------------- | pluto | 1 | ---------------------- | saturn | 1 | ---------------------- | neptune | 1 | ---------------------- # Find the distinct dest vertices sourcing from vertex jupiter gremlin> g.V ( jupiter ) .out () .hasLabel ( 'character' ) .dedup () ; == >v [ 1 ] == >v [ 8 ] == >v [ 5 ] nebula> GO FROM hash ( 'jupiter' ) OVER * YIELD DISTINCT $$ .character.name, $$ .character.age, $$ .location.name ; =========================================================== | $$ .character.name | $$ .character.age | $$ .location.name | =========================================================== | pluto | 4000 | | ----------------------------------------------------------- | neptune | 4500 | | ----------------------------------------------------------- | saturn | 10000 | | ----------------------------------------------------------- | | 0 | sky | -----------------------------------------------------------","title":"Group By"},{"location":"manual-EN/5.appendix/gremlin-ngql/#where_filter_condition","text":"Name Gremlin nGQL Where filter condition where() WHERE Predicates comparison: Name Gremlin nGQL Equal to eq(object) == Not equal to neq(object) != Less than lt(number) < Less than or equal to lte(number) <= Greater than gt(number) > Greater than or equal to gte(number) >= Whether a value is within the array within(objects\u2026\u200b) udf_is_in() gremlin> eq ( 2 ) .test ( 3 ) ; == >false nebula> YIELD 3 == 2 ; ========== | ( 3 == 2 ) | ========== | false | ---------- gremlin> within ( 'a' , 'b' , 'c' ) .test ( 'd' ) ; == >false nebula> YIELD udf_is_in ( 'd' , 'a' , 'b' , 'c' ) ; ====================== | udf_is_in ( d,a,b,c ) | ====================== | false | ---------------------- # Find pluto's co-habitants and exclude himself gremlin> g.V ( pluto ) .out ( 'lives' ) .in ( 'lives' ) .where ( is ( neq ( pluto ))) .values ( 'name' ) ; == >cerberus nebula> GO FROM hash ( \"pluto\" ) OVER lives YIELD lives._dst AS place | GO FROM $- .place OVER lives REVERSELY WHERE \\ $$ .character.name ! = \"pluto\" YIELD $$ .character.name AS cohabitants ; =============== | cohabitants | =============== | cerberus | ---------------","title":"Where Filter Condition"},{"location":"manual-EN/5.appendix/gremlin-ngql/#logical_operators","text":"Name Gremlin nGQL Is is() == Not not() != And and() AND Or or() OR # Find age greater than or equal to 30 gremlin> g.V () .values ( 'age' ) .is ( gte ( 30 )) ; == >10000 == >5000 == >4500 == >30 == >45 == >4000 nebula> LOOKUP ON character WHERE character.age > = 30 YIELD character.age ; ======================================== | VertexID | character.age | ======================================== | -4316810810681305233 | 10000 | ---------------------------------------\u2013 | 4863977009196259577 | 5000 | ---------------------------------------\u2013 | -5860788569139907963 | 4500 | ---------------------------------------\u2013 | 5976696804486077889 | 30 | ---------------------------------------\u2013 | -6780323075177699500 | 45 | ---------------------------------------\u2013 | 6761447489613431910 | 4000 | ---------------------------------------\u2013 # Find character with name pluto and age 4000 gremlin> g.V () .has ( 'name' , 'pluto' ) .and () .has ( 'age' ,4000 ) ; == >v [ 8 ] nebula> LOOKUP ON character WHERE character.name == 'pluto' AND character.age == 4000 ; ======================= | VertexID | ======================= | 6761447489613431910 | ----------------------- # Logical not gremlin> g.V () .has ( 'name' , 'pluto' ) .out ( 'brother' ) .not ( values ( 'name' ) .is ( 'neptune' )) .values ( 'name' ) ; == >jupiter nebula> LOOKUP ON character WHERE character.name == 'pluto' YIELD character.name AS name | \\ GO FROM $- .VertexID OVER brother WHERE $$ .character.name ! = 'neptune' YIELD $$ .character.name ; ===================== | $$ .character.name | ===================== | jupiter | ---------------------","title":"Logical Operators"},{"location":"manual-EN/5.appendix/gremlin-ngql/#statistical_operations","text":"Name Gremlin nGQL Sum sum() SUM() Max max() MAX() Min min() MIN() Mean mean() AVG() Nebula Graph statistical operations must be applied with GROUP BY . # Calculate the sum of ages of all characters gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .sum () ; == >23595 nebula> # Coming soon # Calculate the sum of the out brother edges of all characters gremlin> g.V () .hasLabel ( 'character' ) .map ( outE ( 'brother' ) .count ()) .sum () ; == >6 nebula> # Coming soon # Return the max age of all characters gremlin> g.V () .hasLabel ( 'character' ) .values ( 'age' ) .max () ; == >10000 nebula> # Coming soon","title":"Statistical Operations"},{"location":"manual-EN/5.appendix/gremlin-ngql/#selecting_and_filtering_paths","text":"# Select the results of steps 1 and 3 from the path as the final result gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) ; == > [ a:v [ 8 ] ,c:v [ 3 ]] == > [ a:v [ 8 ] ,c:v [ 1 ]] ... nebula> # Coming soon # Specify dimensions via by() gremlin> g.V ( pluto ) .as ( 'a' ) .out () .as ( 'b' ) .out () .as ( 'c' ) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:pluto,c:sky ] == > [ a:pluto,c:saturn ] ... nebula> # Coming soon # Selects the specified key value from the map gremlin> g.V () .valueMap () .select ( 'name' ) .dedup () ; == > [ saturn ] == > [ jupiter ] ... nebula> # Coming soon","title":"Selecting and Filtering Paths"},{"location":"manual-EN/5.appendix/gremlin-ngql/#branches","text":"# Traverse all vertices with label 'character' # If name is 'jupiter', return the age property # Else return the name property gremlin> g.V () .hasLabel ( 'character' ) .choose ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 == >neptune ... # Lambda gremlin> g.V () .branch { it.get () .value ( 'name' )} .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 ... # Traversal gremlin> g.V () .branch ( values ( 'name' )) .option ( 'jupiter' , values ( 'age' )) .option ( none, values ( 'name' )) ; == >saturn == >5000 # Branch gremlin> g.V () .choose ( has ( 'name' , 'jupiter' ) ,values ( 'age' ) ,values ( 'name' )) ; == >saturn == >5000 # Group based on if then gremlin> g.V () .hasLabel ( \"character\" ) .groupCount () .by ( values ( \"age\" ) .choose ( is ( lt ( 40 )) ,constant ( \"young\" ) , choose ( is ( lt ( 4500 )) , constant ( \"old\" ) , constant ( \"very old\" )))) ; == > [ young:4,old:2,very old:3 ] Similar function is yet to be supported in Nebula Graph .","title":"Branches"},{"location":"manual-EN/5.appendix/gremlin-ngql/#coalesce","text":"The coalesce() step evaluates the provided traversals in order and returns the first traversal that emits at least one element. The optional() step returns the result of the specified traversal if it yields a result else it returns the calling element, i.e. the identity(). The union() step supports the merging of the results of an arbitrary number of traversals. # If type is monster, return type. Else return 'Not a monster'. gremlin> g.V ( pluto ) .coalesce ( has ( 'type' , 'monster' ) .values ( 'type' ) ,constant ( \"Not a monster\" )) ; == >Not a monster # Find the following edges and adjacent vertices of jupiter in order, and stop when finding one # 1. Edge brother out adjacent vertices # 2. Edge father out adjacent vertices # 3. Edge father in adjacent vertices gremlin> g.V ( jupiter ) .coalesce ( outE ( 'brother' ) , outE ( 'father' ) , inE ( 'father' )) .inV () .path () .by ( 'name' ) .by ( label ) ; == > [ jupiter,brother,pluto ] == > [ jupiter,brother,neptune ] # Find pluto's father, if there is not any then return pluto himself gremlin> g.V ( pluto ) .optional ( out ( 'father' )) .valueMap () ; == > [ name: [ pluto ] ,type: [ god ] ,age: [ 4000 ]] # Find pluto's father and brother, union the results then return the paths gremlin> g.V ( pluto ) .union ( out ( 'father' ) ,both ( 'brother' )) .path () ; == > [ v [ 8 ] ,v [ 2 ]] == > [ v [ 8 ] ,v [ 5 ]] Similar function is yet to be supported in Nebula Graph .","title":"Coalesce"},{"location":"manual-EN/5.appendix/gremlin-ngql/#aggregating_and_unfolding_results","text":"# Collect results of the first step into set x # Note: This operation doesn't affect subsequent results gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) ; == >v [ 12 ] == >v [ 2 ] ... # Specify the aggregation dimensions via by () gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .by ( 'name' ) .cap ( 'x' ) ; == > [ tartarus,jupiter,neptune,cerberus ] # Find pluto's 2 hop out adjacent neighbors # Collect the results in set x # Show the neighbors' name gremlin> g.V ( pluto ) .out () .aggregate ( 'x' ) .out () .aggregate ( 'x' ) .cap ( 'x' ) .unfold () .values ( 'name' ) ; == >tartarus == >tartarus ... Similar function is yet to be supported in Nebula Graph .","title":"Aggregating and Unfolding Results"},{"location":"manual-EN/5.appendix/gremlin-ngql/#matching_patterns","text":"The match() step provides a more declarative form of graph querying based on the notion of pattern matching. With match(), the user provides a collection of \"traversal fragments,\" called patterns, that have variables defined that must hold true throughout the duration of the match(). # Matching each vertex with the following pattern. If pattern is met, return map<String, Object>, els filter it. # Pattern 1: a is jupiter's son # Pattern 2: b is jupiter # Pattern 3: c is jupiter's brother, whose age is 4000 gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) ; == > [ a:v [ 6 ] ,b:v [ 2 ] ,c:v [ 8 ]] # match() can be applied with select() to select partial results from Map <String, Object> gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ] # match () can be applied with where () to filter the results gremlin> g.V () .match ( __.as ( 'a' ) .out ( 'father' ) .has ( 'name' , 'jupiter' ) .as ( 'b' ) , __.as ( 'b' ) .in ( 'brother' ) .has ( 'age' , 4000 ) .as ( 'c' )) .where ( 'a' , neq ( 'c' )) .select ( 'a' , 'c' ) .by ( 'name' ) ; == > [ a:hercules,c:pluto ]","title":"Matching Patterns"},{"location":"manual-EN/5.appendix/gremlin-ngql/#random_filtering","text":"The sample() step accepts an integer value and samples the maximum number of the specified results randomly from the previous traverser. The coin() step can randomly filter out a traverser with the given probability. You give coin a value indicating how biased the toss should be. # Randomly select 2 out edges from all vertices gremlin> g.V () .outE () .sample ( 2 ) ; == >e [ 15 ][ 2 -brother->5 ] == >e [ 18 ][ 5 -brother->2 ] # Pick 3 names randomly from all vertices gremlin> g.V () .values ( 'name' ) .sample ( 3 ) ; == >hercules == >sea == >jupiter # Pick 3 randomly from all characters based on age gremlin> g.V () .hasLabel ( 'character' ) .sample ( 3 ) .by ( 'age' ) ; == >v [ 1 ] == >v [ 2 ] == >v [ 6 ] # Applied with local to do random walk # Starting from pluto, conduct random walk 3 times gremlin> g.V ( pluto ) .repeat ( local ( bothE () .sample ( 1 ) .otherV ())) .times ( 3 ) .path () ; == > [ v [ 8 ] ,e [ 26 ][ 8 -brother->5 ] ,v [ 5 ] ,e [ 18 ][ 5 -brother->2 ] ,v [ 2 ] ,e [ 13 ][ 2 -father->1 ] ,v [ 1 ]] # Filter each vertex with a probability of 0.5 gremlin> g.V () .coin ( 0 .5 ) ; == >v [ 1 ] == >v [ 2 ] ... # Return the name attribute of all vertices labeled location, otherwise return not a location gremlin> g.V () .choose ( hasLabel ( 'location' ) , values ( 'name' ) , constant ( 'not a location' )) ; == >not a location == >not a location == >sky ...","title":"Random filtering"},{"location":"manual-EN/5.appendix/gremlin-ngql/#sack","text":"A traverser that contains a local data structure is called a \"sack\". The sack() step is used to read and write sacks. Each sack of each traverser is created with withSack() . # Defines a Gremlin sack with a value of one and return values in the sack gremlin> g.withSack ( 1 ) .V () .sack () ; == >1 == >1 ...","title":"Sack"},{"location":"manual-EN/5.appendix/gremlin-ngql/#barrier","text":"The barrier() step turns the lazy traversal pipeline into a bulk-synchronous pipeline. It's useful when everything prior to barrier() needs to be executed before moving onto the steps after the barrier(). # Calculate the Eigenvector Centrality with barrier # Including groupCount and cap, sorted in descending order gremlin> g.V () .repeat ( both () .groupCount ( 'm' )) .times ( 5 ) .cap ( 'm' ) .order ( local ) .by ( values, decr ) ;","title":"Barrier"},{"location":"manual-EN/5.appendix/gremlin-ngql/#local","text":"A GraphTraversal operates on a continuous stream of objects. In many situations, it is important to operate on a single element within that stream. To do such object-local traversal computations, local() step exists. # Without local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .properties ( 'age' ) .order () .by ( value,decr ) .limit ( 2 ) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () ; == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] # With local() gremlin> g.V () .hasLabel ( 'character' ) .as ( 'character' ) .local ( properties ( 'age' ) .order () .by ( value ) .limit ( 2 )) .value () .as ( 'age' ) .select ( 'character' , 'age' ) .by ( 'name' ) .by () == > [ character:saturn,age:10000 ] == > [ character:jupiter,age:5000 ] == > [ character:neptune,age:4500 ] == > [ character:hercules,age:30 ] ... # Return the property map of monster gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'type' ) .propertyMap () ; == > [ name: [ vp [ name->nemean ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->20 ]]] == > [ name: [ vp [ name->hydra ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] == > [ name: [ vp [ name->cerberus ]] ,type: [ vp [ type->monster ]] ,age: [ vp [ age->0 ]]] # Find number of monster gremlin> g.V () hasLabel ( 'character' ) .has ( 'type' , 'monster' ) .propertyMap () .count ( local ) ; == >3 == >3 == >3 # Find the max vertices number labeled tha same tag gremlin> g.V () .groupCount () .by ( label ) .select ( values ) .max ( local ) ; == >9 # List the first attribute of all vertices gremlin> g.V () .valueMap () .limit ( local, 1 ) ; == > [ name: [ saturn ]] == > [ name: [ jupiter ]] == > [ name: [ sky ]] ... # Without local gremlin> g.V () .valueMap () .limit ( 1 ) ; == > [ name: [ saturn ] ,type: [ titan ] ,age: [ 10000 ]] # All vertices as a set, sample 2 from it gremlin> g.V () .fold () .sample ( local,2 ) ; == > [ v [ 8 ] ,v [ 1 ]]","title":"Local"},{"location":"manual-EN/5.appendix/gremlin-ngql/#statistics_and_analysis","text":"Gremlin provides two steps for statistics and analysis of the executed query statements: The explain() step will return a TraversalExplanation. A traversal explanation details how the traversal (prior to explain()) will be compiled given the registered traversal strategies. The profile() step allows developers to profile their traversals to determine statistical information like step runtime, counts, etc.","title":"Statistics and Analysis"},{"location":"manual-EN/5.appendix/upgrade-guide/","text":"Nebula Graph Upgrading Guide \u00b6 This document describes how to upgrade Nebula Graph. Find the corresponding upgrade guide to your version below. Upgrading From Nebula Graph RC3 t RC4 \u00b6 Stop all the Nebula services Run scripts/nebula.service stop all command on each machine Then run scripts/nebula.service status all command to confirm all services have exited successfully Install the new rpm package on each machine Run https://github.com/vesoft-inc/nebula/releases/tag/v1.0.0-rc4 command to download the package Then run rpm -Uvh nebula-1.0.0-rc4.el7-5.x86_64.rpm command to install Nebula Start Nebula services Run scripts/nebula.service start all command on each machine Then run scripts/nebula.service status all command to confirm all services have started successfully Reimport your data","title":"Upgrading Nebula Graph"},{"location":"manual-EN/5.appendix/upgrade-guide/#nebula_graph_upgrading_guide","text":"This document describes how to upgrade Nebula Graph. Find the corresponding upgrade guide to your version below.","title":"Nebula Graph Upgrading Guide"},{"location":"manual-EN/5.appendix/upgrade-guide/#upgrading_from_nebula_graph_rc3_t_rc4","text":"Stop all the Nebula services Run scripts/nebula.service stop all command on each machine Then run scripts/nebula.service status all command to confirm all services have exited successfully Install the new rpm package on each machine Run https://github.com/vesoft-inc/nebula/releases/tag/v1.0.0-rc4 command to download the package Then run rpm -Uvh nebula-1.0.0-rc4.el7-5.x86_64.rpm command to install Nebula Start Nebula services Run scripts/nebula.service start all command on each machine Then run scripts/nebula.service status all command to confirm all services have started successfully Reimport your data","title":"Upgrading From Nebula Graph RC3 t RC4"}]}