{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to NebulaGraph 2.6.2 Documentation","text":"<p>Danger</p> <p>A new version has been released.</p>"},{"location":"nebula-algorithm/","title":"Nebula Algorithm","text":"<p>Nebula Algorithm (Algorithm) is a Spark application based on GraphX. It uses a complete algorithm tool to perform graph computing on the data in the NebulaGraph database by submitting a Spark task. You can also programmatically use the algorithm under the lib repository to perform graph computing on DataFrame.</p>"},{"location":"nebula-algorithm/#prerequisites","title":"Prerequisites","text":"<p>Before using the Nebula Algorithm, users need to confirm the following information:</p> <ul> <li>The NebulaGraph services have been deployed and started. For details, see Nebula Installation.</li> </ul> <ul> <li>The Spark version is 2.4.x.</li> </ul> <ul> <li>The Scala version is 2.11.</li> </ul> <ul> <li>(Optional) If users need to clone, compile, and package the latest Algorithm in Github, install Maven.</li> </ul>"},{"location":"nebula-algorithm/#limitations","title":"Limitations","text":"<ul> <li>The data of the vertex ID must be an integer. That is, the vertex ID can be INT or String, but the data itself is an integer.</li> </ul> <ul> <li>For non-integer String data, it is recommended to use the algorithm interface. You can use the <code>dense_rank</code> function of SparkSQL to encode the data as the Long type instead of the String type.</li> </ul> <ul> <li>Graph computing outputs vertex datasets, and the algorithm results are stored in DataFrames as the properties of vertices. You can do further operations such as statistics and filtering according to your business requirements.</li> </ul>"},{"location":"nebula-algorithm/#supported_algorithms","title":"Supported algorithms","text":"<p>The graph computing algorithms supported by Nebula Algorithm are as follows.</p> Algorithm Description Scenario PageRank The rank of pages Web page ranking, key node mining Louvain Community discovery Community mining, hierarchical clustering KCore K core Community discovery, financial risk control LabelPropagation Label propagation Information spreading, advertising, and community discovery ConnectedComponent Connected component Community discovery, island discovery StronglyConnectedComponent Strongly connected component Community discovery ShortestPath The shortest path Path planning, network planning TriangleCount Triangle counting Network structure analysis GraphTriangleCount Graph triangle counting Network structure and tightness analysis BetweennessCentrality Intermediate centrality Key node mining, node influence computing DegreeStatic Degree of statistical Graph structure analysis"},{"location":"nebula-algorithm/#implementation_methods","title":"Implementation methods","text":"<p>Nebula Algorithm implements the graph calculating as follows:</p> <ol> <li> <p>Read the graph data of DataFrame from the NebulaGraph database using the Nebula Spark Connector.</p> </li> <li> <p>Transform the graph data of DataFrame to the GraphX graph.</p> </li> <li> <p>Use graph algorithms provided by GraphX (such as PageRank) or self-implemented algorithms (such as Louvain).</p> </li> </ol> <p>For detailed implementation methods, see Scala file.</p>"},{"location":"nebula-algorithm/#get_nebula_algorithm","title":"Get Nebula Algorithm","text":""},{"location":"nebula-algorithm/#compile_and_package","title":"Compile and package","text":"<ol> <li> <p>Clone the repository <code>nebula-algorithm</code>.</p> <pre><code>$ git clone -b v2.5 https://github.com/vesoft-inc/nebula-algorithm.git\n</code></pre> </li> <li> <p>Enter the directory <code>nebula-algorithm</code>.</p> <pre><code>$ cd nebula-algorithm\n</code></pre> </li> <li> <p>Compile and package.</p> <pre><code>$ mvn clean package -Dgpg.skip -Dmaven.javadoc.skip=true -Dmaven.test.skip=true\n</code></pre> </li> </ol> <p>After the compilation, a similar file <code>nebula-algorithm-2.5.1.jar</code> is generated in the directory <code>nebula-algorithm/target</code>.</p>"},{"location":"nebula-algorithm/#download_maven_from_the_remote_repository","title":"Download maven from the remote repository","text":"<p>Download address</p>"},{"location":"nebula-algorithm/#how_to_use","title":"How to use","text":""},{"location":"nebula-algorithm/#use_algorithm_interface_recommended","title":"Use algorithm interface (recommended)","text":"<p>The <code>lib</code> repository provides 10 common graph algorithms.</p> <ol> <li> <p>Add dependencies to the file <code>pom.xml</code>.</p> <pre><code>&lt;dependency&gt;\n     &lt;groupId&gt;com.vesoft&lt;/groupId&gt;\n     &lt;artifactId&gt;nebula-algorithm&lt;/artifactId&gt;\n     &lt;version&gt;2.5.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> </li> <li> <p>Use the algorithm (take PageRank as an example) by filling in parameters. For more example, see example.</p> <p>Note</p> <p>By default, the DataFrame that executes the algorithm sets the first column as the starting vertex, the second column as the destination vertex, and the third column as the edge weights (not the rank in the NebulaGraph).</p> <pre><code>val prConfig = new PRConfig(5, 1.0)\nval louvainResult = PageRankAlgo.apply(spark, data, prConfig, false)\n</code></pre> </li> </ol>"},{"location":"nebula-algorithm/#submit_the_algorithm_package_directly","title":"Submit the algorithm package directly","text":"<p>Note</p> <p>There are limitations to use sealed packages. For example, when sinking a repository into NebulaGraph, the property name of the tag created in the sunk graph space must match the preset name in the code. The first method is recommended if the user has development skills.</p> <ol> <li> <p>Set the Configuration file.</p> <pre><code>{\n# Configurations related to Spark\nspark: {\napp: {\nname: LPA\n        # The number of partitions of Spark\npartitionNum:100\n    }\nmaster:local\n  }\n\ndata: {\n# Data source. Optional values are nebula, csv, and json.\nsource: csv\n    # Data sink. The algorithm result will be written into this sink. Optional values are nebula, csv, and text.\nsink: nebula\n    # Whether the algorithm has a weight.\nhasWeight: false\n}\n\n# Configurations related to NebulaGraph\nnebula: {\n# Data source. When NebulaGraph is the data source of the graph computing, the configuration of `nebula.read` is valid.\nread: {\n# The IP addresses and ports of all Meta services. Multiple addresses are separated by commas (,). Example: \"ip1:port1,ip2:port2\".\n# To deploy NebulaGraph by using Docker Compose, fill in the port with which Docker Compose maps to the outside.\n# Check the status with `docker-compose ps`.\nmetaAddress: \"192.168.*.10:9559\"\n# The name of the graph space in NebulaGraph.\nspace: basketballplayer\n        # Edge types in NebulaGraph. When there are multiple labels, the data of multiple edges will be merged.\nlabels: [\"serve\"]\n# The property name of each edge type in NebulaGraph. This property will be used as the weight column of the algorithm. Make sure that it corresponds to the edge type.\nweightCols: [\"start_year\"]\n}\n\n# Data sink. When the graph computing result sinks into NebulaGraph, the configuration of `nebula.write` is valid.\nwrite:{\n# The IP addresses and ports of all Graph services. Multiple addresses are separated by commas (,). Example: \"ip1:port1,ip2:port2\".\n# To deploy by using Docker Compose, fill in the port with which Docker Compose maps to the outside.\n# Check the status with `docker-compose ps`.\ngraphAddress: \"192.168.*.11:9669\"\n# The IP addresses and ports of all Meta services. Multiple addresses are separated by commas (,). Example: \"ip1:port1,ip2:port2\".\n# To deploy NebulaGraph by using Docker Compose, fill in the port with which Docker Compose maps to the outside.\n# Check the staus with `docker-compose ps`.\nmetaAddress: \"192.168.*.12:9559\"\nuser:root\n        pswd:nebula\n        # Before submitting the graph computing task, create the graph space and tag.\n# The name of the graph space in NebulaGraph.\nspace:nb\n        # The name of the tag in NebulaGraph. The graph computing result will be written into this tag. The property name of this tag is as follows.\n# PageRank: pagerank\n# Louvain: louvain\n# ConnectedComponent: cc\n# StronglyConnectedComponent: scc\n# LabelPropagation: lpa\n# ShortestPath: shortestpath\n# DegreeStatic: degree\u3001inDegree\u3001outDegree\n# KCore: kcore\n# TriangleCount: tranglecpunt\n# BetweennessCentrality: betweennedss\ntag:pagerank\n    }\n}  local: {\n# Data source. When the data source is csv or json, the configuration of `local.read` is valid.\nread:{\nfilePath: \"hdfs://127.0.0.1:9000/edge/work_for.csv\"\n# If the CSV file has a header or it is a json file, use the header. If not, use [_c0, _c1, _c2, ..., _cn] instead.\n# The header of the source VID column.\nsrcId:\"_c0\"\n# The header of the destination VID column.\ndstId:\"_c1\"\n# The header of the weight column.\nweight: \"_c2\"\n# Whether the csv file has a header.\nheader: false\n# The delimiter in the csv file.\ndelimiter:\",\"\n}\n\n# Data sink. When the graph computing result sinks to the csv or text file, the configuration of `local.write` is valid.\nwrite:{\nresultPath:/tmp/\n    }\n}\n\n\nalgorithm: {\n# The algorithm to execute. Optional values are pagerank, louvain, connectedcomponent,\n# labelpropagation, shortestpaths, degreestatic, kcore,\n# stronglyconnectedcomponent, trianglecount, betweenness,\nexecuteAlgo: pagerank\n\n    # PageRank\npagerank: {\nmaxIter: 10\nresetProb: 0.15  # The default value is 0.15\n}\n\n# Louvain\nlouvain: {\nmaxIter: 20\ninternalIter: 10\ntol: 0.5\n    }\n\n# ConnectedComponent/StronglyConnectedComponent\nconnectedcomponent: {\nmaxIter: 20\n}\n\n# LabelPropagation\nlabelpropagation: {\nmaxIter: 20\n}\n\n# ShortestPath\nshortestpaths: {\n# several vertices to compute the shortest path to all vertices.\nlandmarks: \"1\"\n}\n\n# DegreeStatic\ndegreestatic: {}\n\n# KCore\nkcore:{\nmaxIter:10\n        degree:1\n    }\n\n# TriangleCount\ntrianglecount:{}\n\n# BetweennessCentrality\nbetweenness:{\nmaxIter:5\n    }\n}\n}\n</code></pre> </li> <li> <p>Submit the graph computing task.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master &lt;mode&gt; --class com.vesoft.nebula.algorithm.Main &lt;nebula-algorithm-2.5.1.jar_path&gt; -p &lt;application.conf_path&gt;\n</code></pre> <p>Example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.algorithm.Main /root/nebula-algorithm/target/nebula-algorithm-2.5.1.jar -p /root/nebula-algorithm/src/main/resources/application.conf\n</code></pre> </li> </ol>"},{"location":"nebula-analytics/","title":"Nebula Analytics","text":"<p>Nebula Analytics is a high-performance graph computing framework tool that performs graph analysis of data in the NebulaGraph database.</p> <p>Enterpriseonly</p> <p>Only available for the NebulaGraph Enterprise Edition.</p>"},{"location":"nebula-analytics/#scenarios","title":"Scenarios","text":"<p>You can import data from data sources as NebulaGraph clusters, CSV files on HDFS, or local CSV files into Nebula Analytics and export the graph computation results to NebulaGraph clusters, CSV files on HDFS, or local CSV files from Nebula Analytics.</p>"},{"location":"nebula-analytics/#limitations","title":"Limitations","text":"<p>When you import NebulaGraph cluster data into Nebula Analytics and export the graph computation results from Nebula Analytics to a NebulaGraph cluster, the graph computation results can only be exported to the graph space where the data source is located.</p>"},{"location":"nebula-analytics/#version_compatibility","title":"Version compatibility","text":"<p>The version correspondence between Nebula Analytics and NebulaGraph is as follows.</p> Nebula Analytics NebulaGraph 0.9.0 2.6.2"},{"location":"nebula-analytics/#graph_algorithms","title":"Graph algorithms","text":"<p>Nebula Analytics supports the following graph algorithms.</p> Algorithm Description Category APSP All Pair Shortest Path Path SSSP Single Source Shortest Path Path BFS Breadth-first search Path PageRank It is used to rank web pages. Node importance measurement KCore k-Cores Node importance measurement DegreeCentrality It is a simple count of the total number of connections linked to a vertex. Node importance measurement TriangleCount It counts the number of triangles. Graph feature LPA Label Propagation Algorithm Community discovery WCC World Competitive Contests Community discovery LOUVAIN It detects communities in large networks. Community discovery HANP Hop attenuation &amp; Node Preference Community discovery Clustering Coefficient It is a measure of the degree to which nodes in a graph tend to cluster together. Clustering"},{"location":"nebula-analytics/#install_nebula_analytics","title":"Install Nebula Analytics","text":"<p>When installing a cluster of multiple Nebula Analytics on multiple nodes, you need to install Nebula Analytics to the same path and set up SSH-free login between nodes.</p> <pre><code>sudo rpm -i nebula-analytics-0.9.0-centos.x86_64.rpm  --prefix /home/xxx/nebula-analytics\n</code></pre>"},{"location":"nebula-analytics/#how_to_use_nebula_analytics","title":"How to use Nebula Analytics","text":"<p>After installation, you can set parameters of different algorithms and then execute a script to obtain the results of the algorithms and export them to the specified format.</p> <ol> <li> <p>Select one node from the Nebula Analytics cluster and then access the <code>scripts</code> directory.</p> <pre><code>$ cd scripts\n</code></pre> </li> <li> <p>Confirm the data source and export path. Configuration steps are as follows.</p> <ul> <li> <p>NebulaGraph clusters as the data source</p> <ol> <li> <p>Modify the configuration file <code>nebula.conf</code> to configure the NebulaGraph cluster. </p> <pre><code># The number of retries connecting to NebulaGraph.\n--retry=3  # The name of the graph space where you read or write data.\n--space=baskeyballplayer  # Read data from NebulaGraph.\n# The metad process address.\n--meta_server_addrs=192.168.8.100:9559, 192.168.8.101:9559, 192.168.8.102:9559\n# The name of edges.\n--edges=LIKES  # The name of the property to be read as the weight of the edge. Can be either the attribute name or _rank.\n#--edge_data_fields \n# The number of rows read per scan.\n--read_batch_size=10000  # Write data to NebulaGraph.\n# The graphd process address.\n--graph_server_addrs=192.168.8.100:9669  # The account to log into NebulaGraph.\n--user=root  # The password to log into NebulaGraph.\n--password=nebula  # The pattern used to write data back to NebulaGraph: insert or update.\n--mode=insert  # The tag name written back to NebulaGraph.\n--tag=pagerank  # The property name corresponding to the tag.\n--prop=pr  # The property type corresponding the the tag.\n--type=double # The number of rows per write. \n--write_batch_size=1000 # The file path where the data failed to be written back to NebulaGraph is stored.\n--err_file=/home/xxx/analytics/err.txt </code></pre> </li> <li> <p>Modify the related parameters in the script to be used, such as <code>run_pagerank.sh</code>. </p> <pre><code># The sum of the number of processes running on all machines in the cluster. It is recommended to be the number of machines or the number of nodes in the NUMA architecture.\nWNUM=3 # The number of threads per process. It is recommended to set the maximum value to be the number of hardware threads of the machine.\nWCORES=4  # The path to the data source.\n# Set to read data from NebulaGraph via the nebula.conf file.\nINPUT=${INPUT:=\"nebula:$PROJECT/scripts/nebula.conf\"}  # Set to read data from the CSV files on HDFS or on local directories.\n# #INPUT=${INPUT:=\"$PROJECT/data/graph/v100_e2150_ua_c3.csv\"}\n\n# The export path to the graph computation results.\n# Data can be exported to a NebulaGraph. If the data source is also a NebulaGraph, the results will be exported to the graph space specified in nebula.conf.\nOUTPUT=${OUTPUT:=\"nebula:$PROJECT/scripts/nebula.conf\"}\n# Data can also be exported to the CSV files on HDFS or on local directories.\n# OUTPUT=${OUTPUT:='hdfs://192.168.8.100:9000/_test/output'}\n\n# If the value is true, it is a directed graph, if false, it is an undirected graph.\nIS_DIRECTED=${IS_DIRECTED:=true}\n# Set whether to encode ID or not.\nNEED_ENCODE=${NEED_ENCODE:=true}\n# The ID type of the data source vertices. For example string, int32, and int64.\nVTYPE=${VTYPE:=int32}\n# Encoding type. The value distributed specifies the distributed vertex ID encoding. The value single specifies the single-machine vertex ID encoding. \nENCODER=${ENCODER:=\"distributed\"}\n# The parameter for the PageRank algorithm. Algorithms differ in parameters.\nEPS=${EPS:=0.0001}\nDAMPING=${DAMPING:=0.85}\n# The number of iterations.\nITERATIONS=${ITERATIONS:=100}\n</code></pre> </li> </ol> </li> </ul> <ul> <li> <p>Local or HDFS CSV files as the data source</p> <p>Modify parameters in the script to be used, such as <code>run_pagerank.sh</code>.</p> <pre><code># The sum of the number of processes running on all machines in the cluster. It is recommended to be the number of machines or the number of nodes in the NUMA architecture.\nWNUM=3 # The number of threads per process. It is recommended to set the maximum value to be the number of hardware threads of the machine.\nWCORES=4  # The path to the data source.\n# Set to read data from NebulaGraph via the nebula.conf file.\n# INPUT=${INPUT:=\"nebula:$PROJECT/scripts/nebula.conf\"}  \n# Set to read data from the CSV files on HDFS or on local directories.\nINPUT=${INPUT:=\"$PROJECT/data/graph/v100_e2150_ua_c3.csv\"}\n\n# The export path to the graph computation results.\n# Data can be exported to a NebulaGraph. If the data source is also a NebulaGraph, the results will be exported to the graph space specified in nebula.conf.\n# OUTPUT=${OUTPUT:=\"nebula:$PROJECT/scripts/nebula.conf\"}\n# Data can also be exported to the CSV files on HDFS or on local directories.\nOUTPUT=${OUTPUT:='hdfs://192.168.8.100:9000/_test/output'}\n\n# If the value is true, it is a directed graph, if false, it is an undirected graph.\nIS_DIRECTED=${IS_DIRECTED:=true}\n# Set whether to encode ID or not.\nNEED_ENCODE=${NEED_ENCODE:=true}\n# The ID type of the data source vertices. For example string, int32, and int64.\nVTYPE=${VTYPE:=int32}\n# The value distributed specifies the distributed vertex ID encoding. The value single specifies the single-machine vertex ID encoding. \nENCODER=${ENCODER:=\"distributed\"}\n# The parameter for the PageRank algorithm. Algorithms differ in parameters.\nEPS=${EPS:=0.0001}\nDAMPING=${DAMPING:=0.85}\n# The number of iterations.\nITERATIONS=${ITERATIONS:=100}\n</code></pre> </li> </ul> </li> <li> <p>Modify the configuration file <code>cluster</code> to set the Nebula Analytics cluster nodes and task assignment weights for executing the algorithm.</p> <pre><code># Nebula Analytics Cluster Node IP Addresses: Task Assignment Weights\n192.168.8.200:1\n192.168.8.201:1\n192.168.8.202:1\n</code></pre> </li> <li> <p>Run the algorithm script. For example:</p> <pre><code>./run_pagerank.sh\n</code></pre> </li> <li> <p>View the graph computation results in the export path.</p> <ul> <li>For exporting to a NebulaGraph cluster, check the results according to the settings in <code>nebula.conf</code>.</li> </ul> <ul> <li>For exporting the results to the CSV files on HDFS or on local directories, check the results according to the settings in <code>OUTPUT</code>, which is a compressed file in the <code>.gz</code> format.</li> </ul> </li> </ol>"},{"location":"nebula-bench/","title":"Nebula Bench","text":"<p>Nebula Bench is a performance test tool for NebulaGraph using the LDBC data set.</p>"},{"location":"nebula-bench/#scenario","title":"Scenario","text":"<ul> <li>Generate test data and import NebulaGraph.</li> </ul> <ul> <li>Performance testing in the NebulaGraph cluster.</li> </ul>"},{"location":"nebula-bench/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-bench/#test_process","title":"Test process","text":"<ol> <li> <p>Generate test data by using ldbc_snb_datagen.</p> </li> <li> <p>Import data to NebulaGraph by using the Importer.</p> </li> <li> <p>Performance testing by using K6 with the XK6-Nebula plug-in.</p> </li> </ol> <p>For detailed usage instructions, see Nebula Bench.</p>"},{"location":"nebula-flink-connector/","title":"Nebula Flink Connector","text":"<p>Nebula Flink Connector is a connector that helps Flink users quickly access NebulaGraph. Nebula Flink Connector supports reading data from the NebulaGraph database or writing other external data to the NebulaGraph database.</p> <p>For more information, see Nebula Flink Connector.</p>"},{"location":"nebula-flink-connector/#use_cases","title":"Use cases","text":"<p>Nebula Flink Connector applies to the following scenarios:</p> <ul> <li>Migrate data between different NebulaGraph clusters.</li> </ul> <ul> <li>Migrate data between different graph spaces in the same NebulaGraph cluster.</li> </ul> <ul> <li>Migrate data between NebulaGraph and other data sources.</li> </ul>"},{"location":"nebula-flink-connector/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-spark-connector/","title":"Nebula Spark Connector","text":"<p>Nebula Spark Connector is a Spark connector application for reading and writing NebulaGraph data in Spark standard format. Nebula Spark Connector consists of two parts: Reader and Writer.</p> <ul> <li> <p>Reader</p> <p>Provides a Spark SQL interface. This interface can be used to read NebulaGraph data. It reads one vertex or edge type data at a time and assemble the result into a Spark DataFrame.</p> </li> </ul> <ul> <li> <p>Writer</p> <p>Provides a Spark SQL interface. This interface can be used to write DataFrames into NebulaGraph in a row-by-row or batch-import way.</p> </li> </ul> <p>For more information, see Nebula Spark Connector.</p>"},{"location":"nebula-spark-connector/#use_cases","title":"Use cases","text":"<p>Nebula Spark Connector applies to the following scenarios:</p> <ul> <li>Migrate data between different NebulaGraph clusters.</li> </ul> <ul> <li>Migrate data between different graph spaces in the same NebulaGraph cluster.</li> </ul> <ul> <li>Migrate data between NebulaGraph and other data sources.</li> </ul> <ul> <li>Graph computing with Nebula Algorithm.</li> </ul>"},{"location":"nebula-spark-connector/#benefits","title":"Benefits","text":"<p>The features of Nebula Spark Connector 2.6.1 are as follows:</p> <ul> <li>Supports multiple connection settings, such as timeout period, number of connection retries, number of execution retries, etc.</li> </ul> <ul> <li>Supports multiple settings for data writing, such as setting the corresponding column as vertex ID, starting vertex ID, destination vertex ID or attributes.</li> </ul> <ul> <li>Supports non-attribute reading and full attribute reading.</li> </ul> <ul> <li>Supports reading NebulaGraph data into VertexRDD and EdgeRDD, and supports non-Long vertex IDs.</li> </ul> <ul> <li>Unifies the extended data source of SparkSQL, and uses DataSourceV2 to extend NebulaGraph data.</li> </ul> <ul> <li>Three write modes, <code>insert</code>, <code>update</code> and <code>delete</code>, are supported. <code>insert</code> mode will insert (overwrite) data, <code>update</code> mode will only update existing data, and <code>delete</code> mode will only delete data.</li> </ul>"},{"location":"nebula-spark-connector/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-spark-connector/#get_nebula_spark_connector","title":"Get Nebula Spark Connector","text":""},{"location":"nebula-spark-connector/#compile_package","title":"Compile package","text":"<p>Note</p> <p>Install Nebula Spark Connector of version 2.4.x.</p> <ol> <li> <p>Clone repository <code>nebula-spark-connector</code>.</p> <pre><code>$ git clone -b v2.6 https://github.com/vesoft-inc/nebula-spark-connector.git\n</code></pre> </li> <li> <p>Make the <code>nebula-spark-connector</code> directory the current working directory.</p> <pre><code>$ cd nebula-spark-connector/nebula-spark-connector\n</code></pre> </li> <li> <p>Compile package.</p> <pre><code>$ mvn clean package -Dmaven.test.skip=true -Dgpg.skip -Dmaven.javadoc.skip=true\n</code></pre> </li> </ol> <p>After compilation, a similar file <code>nebula-spark-connector-2.6.1-SHANPSHOT.jar</code> is generated in the directory <code>nebula-spark-connector/nebula-spark-connector/target/</code>.</p>"},{"location":"nebula-spark-connector/#download_maven_remote_repository","title":"Download maven remote repository","text":"<p>Download</p>"},{"location":"nebula-spark-connector/#how_to_use","title":"How to use","text":"<p>When using Nebula Spark Connector to reading and writing NebulaGraph data, You can refer to the following code.</p> <pre><code># Read vertex and edge data from NebulaGraph.\nspark.read.nebula().loadVerticesToDF()\nspark.read.nebula().loadEdgesToDF()\n\n# Write dataframe data into NebulaGraph as vertex and edges.\ndataframe.write.nebula().writeVertices()\ndataframe.write.nebula().writeEdges()\n</code></pre> <p><code>nebula()</code> receives two configuration parameters, including connection configuration and read-write configuration.</p>"},{"location":"nebula-spark-connector/#reading_data_from_nebulagraph","title":"Reading data from NebulaGraph","text":"<pre><code>val config = NebulaConnectionConfig\n.builder()\n.withMetaAddress(\"127.0.0.1:9559\")\n.withConenctionRetry(2)\n.withExecuteRetry(2)\n.withTimeout(6000)\n.build()\n\nval nebulaReadVertexConfig: ReadNebulaConfig = ReadNebulaConfig\n.builder()\n.withSpace(\"test\")\n.withLabel(\"person\")\n.withNoColumn(false)\n.withReturnCols(List(\"birthday\"))\n.withLimit(10)\n.withPartitionNum(10)\n.build()\nval vertex = spark.read.nebula(config, nebulaReadVertexConfig).loadVerticesToDF()\n\nval nebulaReadEdgeConfig: ReadNebulaConfig = ReadNebulaConfig\n.builder()\n.withSpace(\"test\")\n.withLabel(\"knows\")\n.withNoColumn(false)\n.withReturnCols(List(\"degree\"))\n.withLimit(10)\n.withPartitionNum(10)\n.build()\nval edge = spark.read.nebula(config, nebulaReadEdgeConfig).loadEdgesToDF()\n</code></pre> <ul> <li> <p><code>NebulaConnectionConfig</code> is the configuration for connecting to the NebulaGraph, as described below.</p> Parameter Required Description <code>withMetaAddress</code> Yes Specifies the IP addresses and ports of all Meta Services. Separate multiple addresses with commas. The format is <code>ip1:port1,ip2:port2,...</code>. Read data is no need to configure <code>withGraphAddress</code>. <code>withConnectionRetry</code> No The number of retries that the Nebula Java Client connected to the NebulaGraph. The default value is <code>1</code>. <code>withExecuteRetry</code> No The number of retries that the Nebula Java Client executed query statements. The default value is <code>1</code>. <code>withTimeout</code> No The timeout for the Nebula Java Client request response. The default value is <code>6000</code>, Unit: ms. </li> </ul> <ul> <li> <p><code>ReadNebulaConfig</code> is the configuration to read NebulaGraph data, as described below.</p> Parameter Required Description <code>withSpace</code> Yes NebulaGraph space name. <code>withLabel</code> Yes The Tag or Edge type name within the NebulaGraph space. <code>withNoColumn</code> No Whether the property is not read. The default value is <code>false</code>, read property. If the value is <code>true</code>, the property is not read, the <code>withReturnCols</code> configuration is invalid. <code>withReturnCols</code> No Configures the set of properties for vertex or edges to read. the format is <code>List(property1,property2,...)</code>, The default value is <code>List()</code>, indicating that all properties are read. <code>withLimit</code> No Configure the number of rows of data read from the server by the Nebula Java Storage Client at a time. The default value is <code>1000</code>. <code>withPartitionNum</code> No Configures the number of Spark partitions to read the NebulaGraph data. The default value is <code>100</code>. This value should not exceed the number of slices in the graph space (partition_num). </li> </ul>"},{"location":"nebula-spark-connector/#write_data_into_nebulagraph","title":"Write data into NebulaGraph","text":"<p>Note</p> <p>The values of columns in a dataframe are automatically written to the NebulaGraph as property values.</p> <pre><code>val config = NebulaConnectionConfig\n.builder()\n.withMetaAddress(\"127.0.0.1:9559\")\n.withGraphAddress(\"127.0.0.1:9669\")\n.withConenctionRetry(2)\n.build()\n\nval nebulaWriteVertexConfig: WriteNebulaVertexConfig = WriteNebulaVertexConfig      .builder()\n.withSpace(\"test\")\n.withTag(\"person\")\n.withVidField(\"id\")\n.withVidPolicy(\"hash\")\n.withVidAsProp(true)\n.withUser(\"root\")\n.withPasswd(\"nebula\")\n.withBatch(1000)\n.build()    df.write.nebula(config, nebulaWriteVertexConfig).writeVertices()\n\nval nebulaWriteEdgeConfig: WriteNebulaEdgeConfig = WriteNebulaEdgeConfig      .builder()\n.withSpace(\"test\")\n.withEdge(\"friend\")\n.withSrcIdField(\"src\")\n.withSrcPolicy(null)\n.withDstIdField(\"dst\")\n.withDstPolicy(null)\n.withRankField(\"degree\")\n.withSrcAsProperty(true)\n.withDstAsProperty(true)\n.withRankAsProperty(true)\n.withUser(\"root\")\n.withPasswd(\"nebula\")\n.withBatch(1000)\n.build()\ndf.write.nebula(config, nebulaWriteEdgeConfig).writeEdges()\n</code></pre> <p>The default write mode is <code>insert</code>, which can be changed to <code>update</code> via <code>withWriteMode</code> configuration:</p> <pre><code>val config = NebulaConnectionConfig\n.builder()\n.withMetaAddress(\"127.0.0.1:9559\")\n.withGraphAddress(\"127.0.0.1:9669\")\n.build()\nval nebulaWriteVertexConfig = WriteNebulaVertexConfig\n.builder()\n.withSpace(\"test\")\n.withTag(\"person\")\n.withVidField(\"id\")\n.withVidAsProp(true)\n.withBatch(1000)\n.withWriteMode(WriteMode.UPDATE)\n.build()\ndf.write.nebula(config, nebulaWriteVertexConfig).writeVertices()\n</code></pre> <ul> <li> <p><code>NebulaConnectionConfig</code> is the configuration for connecting to the NebulaGraph, as described below.</p> Parameter Required Description <code>withMetaAddress</code> Yes Specifies the IP addresses and ports of all Meta Services. Separate multiple addresses with commas. The format is <code>ip1:port1,ip2:port2,...</code>. <code>withGraphAddress</code> Yes Specifies the IP addresses and ports of Graph Services. Separate multiple addresses with commas. The format is <code>ip1:port1,ip2:port2,...</code>. <code>withConnectionRetry</code> No Number of retries that the Nebula Java Client connected to the NebulaGraph. The default value is <code>1</code>. </li> </ul> <ul> <li> <p><code>WriteNebulaVertexConfig</code> is the configuration of the write vertex, as described below.</p> Parameter Required Description <code>withSpace</code> Yes NebulaGraph space name. <code>withTag</code> Yes The Tag name that needs to be associated when a vertex is written. <code>withVidField</code> Yes The column in the DataFrame as the vertex ID. <code>withVidPolicy</code> No When writing the vertex ID, NebulaGraph 2.x use mapping function, supports HASH only. No mapping is performed by default. <code>withVidAsProp</code> No Whether the column in the DataFrame that is the vertex ID is also written as an property. The default value is <code>false</code>. If set to <code>true</code>, make sure the Tag has the same property name as <code>VidField</code>. <code>withUser</code> No NebulaGraph user name. If authentication is disabled, you do not need to configure the user name and password. <code>withPasswd</code> No The password for the NebulaGraph user name. <code>withBatch</code> Yes The number of rows of data written at a time. The default value is  <code>1000</code>. <code>withWriteMode</code> No Write mode. The optional values are <code>insert</code> and <code>update</code>. The default value is <code>insert</code>. </li> </ul> <ul> <li> <p><code>WriteNebulaEdgeConfig</code> is the configuration of the write edge, as described below.</p> Parameter Required Description <code>withSpace</code> Yes NebulaGraph space name. <code>withEdge</code> Yes The Edge type name that needs to be associated when a edge is written. <code>withSrcIdField</code> Yes The column in the DataFrame as the vertex ID. <code>withSrcPolicy</code> No When writing the starting vertex ID, NebulaGraph 2.x use mapping function, supports HASH only. No mapping is performed by default. <code>withDstIdField</code> Yes The column in the DataFrame that serves as the destination vertex. <code>withDstPolicy</code> No When writing the destination vertex ID, NebulaGraph 2.x use mapping function, supports HASH only. No mapping is performed by default. <code>withRankField</code> No The column in the DataFrame as the rank. Rank is not written by default. <code>withSrcAsProperty</code> No Whether the column in the DataFrame that is the starting vertex is also written as an property.  The default value is <code>false</code>. If set to <code>true</code>, make sure Edge type has the same property name as <code>SrcIdField</code>. <code>withDstAsProperty</code> No Whether column that are destination vertex in the DataFrame are also written as property. The default value is <code>false</code>. If set to <code>true</code>, make sure Edge type has the same property name as <code>DstIdField</code>. <code>withRankAsProperty</code> No Whether column in the DataFrame that is the rank is also written as property.The default value is <code>false</code>. If set to <code>true</code>, make sure Edge type has the same property name as <code>RankField</code>. <code>withUser</code> No NebulaGraph user name. If authentication is disabled, you do not need to configure the user name and password. <code>withPasswd</code> No The password for the NebulaGraph user name. <code>withBatch</code> Yes The number of rows of data written at a time. The default value is  <code>1000</code>. <code>withWriteMode</code> No Write mode. The optional values are <code>insert</code> and <code>update</code>. The default value is <code>insert</code>. </li> </ul>"},{"location":"1.introduction/1.what-is-nebula-graph/","title":"What is NebulaGraph","text":"<p>NebulaGraph is an open-source, distributed, easily scalable, and native graph database. It is capable of hosting graphs with hundreds of billions of vertices and trillions of edges, and serving queries with millisecond-latency.</p> <p></p>"},{"location":"1.introduction/1.what-is-nebula-graph/#what_is_a_graph_database","title":"What is a graph database","text":"<p>A graph database, such as NebulaGraph, is a database that specializes in storing vast graph networks and retrieving information from them. It efficiently stores data as vertices (nodes) and edges (relationships) in labeled property graphs. Properties can be attached to both vertices and edges. Each vertex can have one or multiple tags (labels).</p> <p></p> <p>Graph databases are well suited for storing most kinds of data models abstracted from reality. Things are connected in almost all fields in the world. Modeling systems like relational databases extract the relationships between entities and squeeze them into table columns alone, with their types and properties stored in other columns or even other tables. This makes the data management time-consuming and cost-ineffective.</p> <p>NebulaGraph, as a typical native graph database, allows you to store the rich relationships as edges with edge types and properties directly attached to them.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#benefits_of_nebulagraph","title":"Benefits of NebulaGraph","text":""},{"location":"1.introduction/1.what-is-nebula-graph/#open-source","title":"Open-source","text":"<p>NebulaGraph is open under the Apache 2.0. More and more people such as database developers, data scientists, security experts, and algorithm engineers are participating in the designing and development of NebulaGraph. To join the opening of source code and ideas, surf the NebulaGraph GitHub page.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#outstanding_performance","title":"Outstanding performance","text":"<p>Written in C++ and born for graph, NebulaGraph handles graph queries in milliseconds. Among most databases, NebulaGraph shows superior performance in providing graph data services. The larger the data size, the greater the superiority of NebulaGraph. For more information, see NebulaGraph benchmarking.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#high_scalability","title":"High scalability","text":"<p>NebulaGraph is designed in a shared-nothing architecture and supports scaling in and out without interrupting the database service.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#developer_friendly","title":"Developer friendly","text":"<p>NebulaGraph supports clients in popular programming languages like Java, Python, C++, and Go, and more are being developed. For more information, see NebulaGraph clients.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#reliable_access_control","title":"Reliable access control","text":"<p>NebulaGraph supports strict role-based access control and external authentication servers such as LDAP (Lightweight Directory Access Protocol) servers to enhance data security. For more information, see Authentication and authorization.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#diversified_ecosystem","title":"Diversified ecosystem","text":"<p>More and more native tools of NebulaGraph have been released, such as NebulaGraph Studio, Nebula Console, and Nebula Exchange. For more ecosystem tools, see Ecosystem tools overview.</p> <p>Besides, NebulaGraph has the ability to be integrated with many cutting-edge technologies, such as Spark, Flink, and HBase, for the purpose of mutual strengthening in a world of increasing challenges and chances. For more information, see Ecosystem development.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#opencypher-compatible_query_language","title":"OpenCypher-compatible query language","text":"<p>The native NebulaGraph Query Language, also known as nGQL, is a declarative, openCypher-compatible textual query language. It is easy to understand and easy to use. For more information, see nGQL guide.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#future-oriented_hardware_with_balanced_reading_and_writing","title":"Future-oriented hardware with balanced reading and writing","text":"<p>Solid-state drives have extremely high performance and they are getting cheaper.  NebulaGraph is a product based on SSD. Compared with products based on HDD and large memory, it is more suitable for future hardware trends and easier to achieve balanced reading and writing.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#easy_data_modeling_and_high_flexibility","title":"Easy data modeling and high flexibility","text":"<p>You can easily model the connected data into NebulaGraph for your business without forcing them into a structure such as a relational table, and properties can be added, updated, and deleted freely. For more information, see Data modeling.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#high_popularity","title":"High popularity","text":"<p>NebulaGraph is being used by tech leaders such as Tencent, Vivo, Meituan, and JD Digits. For more information, visit the NebulaGraph official website.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#use_cases","title":"Use cases","text":"<p>NebulaGraph can be used to support various graph-based scenarios. To spare the time spent on pushing the kinds of data mentioned in this section into relational databases and on bothering with join queries, use NebulaGraph.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#fraud_detection","title":"Fraud detection","text":"<p>Financial institutions have to traverse countless transactions to piece together potential crimes and understand how combinations of transactions and devices might be related to a single fraud scheme. This kind of scenario can be modeled in graphs, and with the help of NebulaGraph, fraud rings and other sophisticated scams can be easily detected.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#real-time_recommendation","title":"Real-time recommendation","text":"<p>NebulaGraph offers the ability to instantly process the real-time information produced by a visitor and make accurate recommendations on articles, videos, products, and services.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#intelligent_question-answer_system","title":"Intelligent question-answer system","text":"<p>Natural languages can be transformed into knowledge graphs and stored in NebulaGraph. A question organized in a natural language can be resolved by a semantic parser in an intelligent question-answer system and re-organized. Then, possible answers to the question can be retrieved from the knowledge graph and provided to the one who asked the question.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#social_networking","title":"Social networking","text":"<p>Information on people and their relationships are typical graph data. NebulaGraph can easily handle the social networking information of billions of people and trillions of relationships, and provide lightning-fast queries for friend recommendations and job promotions in the case of massive concurrency.</p>"},{"location":"1.introduction/1.what-is-nebula-graph/#related_links","title":"Related links","text":"<ul> <li>Official website</li> <li>Docs</li> <li>Blog</li> <li>Forum</li> <li>GitHub</li> </ul>"},{"location":"1.introduction/2.1.path/","title":"Path types","text":"<p>In graph theory, a path in a graph is a finite or infinite sequence of edges which joins a sequence of vertices. Paths are fundamental concepts of graph theory.</p> <p>Paths can be categorized into 3 types: <code>walk</code>, <code>trail</code>, and <code>path</code>. For more information, see Wikipedia.</p> <p>The following picture is an example for a brief introduction.</p> <p></p>"},{"location":"1.introduction/2.1.path/#walk","title":"Walk","text":"<p>A <code>walk</code> is a finite or infinite sequence of edges. Both vertices and edges can be repeatedly visited in graph traversal.</p> <p>In the above picture C, D, and E form a cycle. So, this picture contains infinite paths, such as <code>A-&gt;B-&gt;C-&gt;D-&gt;E</code>, <code>A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;C</code>, and <code>A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;C-&gt;D</code>.</p> <p>Note</p> <p><code>GO</code> statements use <code>walk</code>.</p>"},{"location":"1.introduction/2.1.path/#trail","title":"Trail","text":"<p>A <code>trail</code> is a finite sequence of edges. Only vertices can be repeatedly visited in graph traversal. The Seven Bridges of K\u00f6nigsberg is a typical <code>trail</code>.</p> <p>In the above picture, edges cannot be repeatedly visited. So, this picture contains finite paths. The longest path in this picture consists of 5 edges: <code>A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;C</code>.</p> <p>Note</p> <p><code>MATCH</code>, <code>FIND PATH</code>, and <code>GET SUBGRAPH</code> statements use <code>trail</code>.</p> <p>There are two special cases of trail, <code>cycle</code>, and <code>circuit</code>. The following picture is an example for a brief introduction.</p> <p></p> <ul> <li> <p>cycle</p> <p>A <code>cycle</code> refers to a closed <code>trail</code>. Only the terminal vertices can be repeatedly visited. The longest path in this picture consists of 3 edges: <code>A-&gt;B-&gt;C-&gt;A</code> or <code>C-&gt;D-&gt;E-&gt;C</code>.</p> </li> </ul> <ul> <li> <p>circuit</p> <p>A <code>circuit</code> refers to a closed <code>trail</code>. Edges cannot be repeatedly visited in graph traversal. Apart from the terminal vertices, other vertices can also be repeatedly visited. The longest path in this picture: <code>A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;C-&gt;A</code>.</p> </li> </ul>"},{"location":"1.introduction/2.1.path/#path","title":"Path","text":"<p>A <code>path</code> is a finite sequence of edges. Neither vertices nor edges can be repeatedly visited in graph traversal.</p> <p>So, the above picture contains finite paths. The longest path in this picture consists of 4 edges: <code>A-&gt;B-&gt;C-&gt;D-&gt;E</code>.</p>"},{"location":"1.introduction/2.data-model/","title":"Data modeling","text":"<p>A data model is a model that organizes data and specifies how they are related to one another. This topic describes the Nebula\u00a0Graph data model and provides suggestions for data modeling with NebulaGraph.</p>"},{"location":"1.introduction/2.data-model/#data_structures","title":"Data structures","text":"<p>NebulaGraph data model uses six data structures to store data. They are graph spaces, vertices, edges, tags, edge types and properties.</p> <ul> <li>Graph spaces: Graph spaces are used to isolate data from different teams or programs. Data stored in different graph spaces are securely isolated. Storage replications, privileges, and partitions can be assigned.</li> <li>Vertices: Vertices are used to store entities.<ul> <li>In Nebula\u00a0Graph, vertices are identified with vertex identifiers (i.e. <code>VID</code>). The <code>VID</code> must be unique in the same graph space. VID should be int64, or fixed_string(N).</li> <li>A vertex must have at least one tag or multiple tags.</li> </ul> </li> <li>Edges: Edges are used to connect vertices. An edge is a connection or behavior between two vertices.<ul> <li>There can be multiple edges between two vertices.</li> <li>Edges are directed. <code>-&gt;</code> identifies the directions of edges. Edges can be traversed in either direction.</li> <li>An edge is identified uniquely with a source vertex, an edge type, a rank value, and a destination vertex. Edges have no EID.</li> <li>An edge must have one and only one edge type.</li> <li>The rank value is an immutable user-assigned 64-bit signed integer. It identifies the edges with the same edge type between two vertices. Edges are sorted by their rank values. The edge with the greatest rank value is listed first. The default rank value is zero.</li> </ul> </li> <li>Tags: Tags are used to categorize vertices. Vertices that have the same tag share the same definition of properties.</li> <li>Edge types: Edge types are used to categorize edges. Edges that have the same edge type share the same definition of properties.</li> <li>Properties: Properties are key-value pairs. Both vertices and edges are containers for properties.</li> </ul> <p>Note</p> <p>Tag and Edge type are similar to the vertex table and edge table in the relational databases.</p>"},{"location":"1.introduction/2.data-model/#directed_property_graph","title":"Directed property graph","text":"<p>NebulaGraph stores data in directed property graphs. A directed property graph has a set of vertices connected by directed edges. Both vertices and edges can have properties. A directed property graph is represented as:</p> <p>G = &lt; V, E, PV, PE &gt;</p> <ul> <li>V is a set of vertices.</li> <li>E is a set of directed edges.</li> <li>PV is the property of vertices.</li> <li>PE is the property of edges.</li> </ul> <p>The following table is an example of the structure of the basketball player dataset. We have two types of vertices, that is player and team, and two types of edges, that is serve and follow.</p> Element Name Property name (Data type) Description Tag player name (string) age (int) Represents players in the team. Tag team name (string) Represents the teams. Edge type serve start_year (int)  end_year (int) Represents actions taken by players in the team.An action links a player with a team, and the direction is from a player to a team. Edge type follow degree (int) Represents actions taken by players in the team.An action links a player with another player, and the direction is from one player to the other player. <p>Note</p> <p>NebulaGraph supports only directed edges.</p> <p>Compatibility</p> <p>NebulaGraph 2.6.2 allows dangling edges. Therefore, when adding or deleting, you need to ensure the corresponding source vertex and destination vertex of an edge exist. For details, see INSERT VERTEX, DELETE VERTEX, INSERT EDGE, and DELETE EDGE.</p> <p>The MERGE statement in openCypher is not supported.</p>"},{"location":"1.introduction/3.vid/","title":"VID","text":"<p>In NebulaGraph, a vertex is uniquely identified by its ID, which is called a VID or a Vertex ID.</p>"},{"location":"1.introduction/3.vid/#features","title":"Features","text":"<ul> <li>The data types of VIDs are restricted to <code>FIXED_STRING(&lt;N&gt;)</code> or <code>INT64</code>; a graph space can only select one VID type.</li> </ul> <ul> <li>A VID in a graph space is unique. It functions just as a primary key in a relational database. VIDs in different graph spaces are independent.</li> </ul> <ul> <li>The VID generation method must be set by users, because NebulaGraph does not provide auto increasing ID, or UUID.</li> </ul> <ul> <li> <p>Vertices with the same VID will be identified as the same one. For example:</p> <ul> <li>A VID is the unique identifier of an entity, like a person's ID card number. A tag means the type of an entity,  such as driver, and boss. Different tags define two groups of different properties, such as driving license number, driving age, order amount, order taking alt, and job number, payroll, debt ceiling, business phone number.</li> </ul> <ul> <li>When two <code>INSERT</code> statements (neither uses a parameter of <code>IF NOT EXISTS</code>) with the same VID and tag are operated at the same time, the latter <code>INSERT</code> will overwrite the former.</li> </ul> <ul> <li>When two <code>INSERT</code> statements with the same VID but different tags, like <code>TAG A</code> and <code>TAG B</code>, are operated at the same time, the operation of <code>Tag A</code> will not affect <code>Tag B</code>.</li> </ul> </li> </ul> <ul> <li>VIDs will usually be indexed and stored into memory (in the way of LSM-tree). Thus, direct access to VIDs enjoys peak performance.</li> </ul>"},{"location":"1.introduction/3.vid/#vid_operation","title":"VID Operation","text":"<ul> <li>NebulaGraph 1.x only supports <code>INT64</code> while NebulaGraph 2.x supports <code>INT64</code> and <code>FIXED_STRING(&lt;N&gt;)</code>. In <code>CREATE SPACE</code>, VID types can be set via <code>vid_type</code>.</li> </ul> <ul> <li><code>id()</code> function can be used to specify or locate a VID.</li> </ul> <ul> <li><code>LOOKUP</code> or <code>MATCH</code> statements can be used to find a VID via property index.</li> </ul> <ul> <li>Direct access to vertices statements via VIDs enjoys peak performance, such as <code>DELETE xxx WHERE id(xxx) == \"player100\"</code> or <code>GO FROM \"player100\"</code>. Finding VIDs via properties and then operating the graph will cause poor performance, such as <code>LOOKUP | GO FROM $-.ids</code>, which will run both <code>LOOKUP</code> and <code>|</code> one more time.</li> </ul>"},{"location":"1.introduction/3.vid/#vid_generation","title":"VID Generation","text":"<p>VIDs can be generated via applications. Here are some tips:</p> <ul> <li>(Optimal) Directly take a unique primary key or property as a VID. Property access depends on the VID.</li> </ul> <ul> <li>Generate a VID via a unique combination of properties. Property access depends on property index.</li> </ul> <ul> <li>Generate a VID via algorithms like snowflake. Property access depends on property index.</li> </ul> <ul> <li>If short primary keys greatly outnumber long primary keys, do not enlarge the <code>N</code> of <code>FIXED_STRING(&lt;N&gt;)</code> too much. Otherwise, it will occupy a lot of memory and hard disks, and slow down performance. Generate VIDs via BASE64, MD5, hash by encoding and splicing.</li> </ul> <ul> <li>If you generate inte64 VID via hash, the probability of collision is about 1/10 when there are 1 billion vertices. The number of edges has no concern with the probability of collision.</li> </ul>"},{"location":"1.introduction/3.vid/#define_and_modify_the_data_type_of_vids","title":"Define and modify the data type of VIDs","text":"<p>The data type of VIDs must be defined when you create the graph space. Once defined, it cannot be modified.</p>"},{"location":"1.introduction/3.vid/#query_start_vid_and_global_scan","title":"Query <code>start vid</code> and global scan","text":"<p>In most cases, the execution plan of query statements in NebulaGraph (<code>MATCH</code>, <code>GO</code>, and <code>LOOKUP</code>) must query the <code>start vid</code> in a certain way.</p> <p>There are only two ways to locate <code>start vid</code>:</p> <ol> <li> <p>For example, <code>GO FROM \"player100\" OVER</code> explicitly indicates in the statement that <code>start vid</code> is \"player100\".</p> </li> <li> <p>For example, <code>LOOKUP ON player WHERE player.name == \"Tony Parker\"</code> or <code>MATCH (v:player {name:\"Tony Parker\"})</code> locates <code>start vid</code> by the index of the property <code>player.name</code>.</p> </li> </ol> <p>You cannot perform a global scan without <code>start vid</code></p> <p>For example, <code>match (n) return n;</code> returns an error because <code>start vid</code> cannot be located at this time. As a global scan, it is forbidden.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/1.architecture-overview/","title":"Architecture overview","text":"<p>NebulaGraph consists of three services: the Graph Service, the Storage Service, and the Meta Service. It applies the separation of storage and computing architecture.</p> <p>Each service has its executable binaries and processes launched from the binaries. Users can deploy a NebulaGraph cluster on a single machine or multiple machines using these binaries.</p> <p>The following figure shows the architecture of a typical NebulaGraph cluster.</p> <p></p>"},{"location":"1.introduction/3.nebula-graph-architecture/1.architecture-overview/#the_meta_service","title":"The Meta Service","text":"<p>The Meta Service in the NebulaGraph architecture is run by the nebula-metad processes. It is responsible for metadata management, such as schema operations, cluster administration, and user privilege management.</p> <p>For details on the Meta Service, see Meta Service.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/1.architecture-overview/#the_graph_service_and_the_storage_service","title":"The Graph Service and the Storage Service","text":"<p>NebulaGraph applies the separation of storage and computing architecture. The Graph Service is responsible for querying. The Storage Service is responsible for storage. They are run by different processes, i.e., nebula-graphd and nebula-storaged. The benefits of the separation of storage and computing architecture are as follows:</p> <ul> <li> <p>Great scalability</p> <p>The separated structure makes both the Graph Service and the Storage Service flexible and easy to scale in or out.</p> </li> </ul> <ul> <li> <p>High availability</p> <p>If part of the Graph Service fails, the data stored by the Storage Service suffers no loss. And if the rest part of the Graph Service is still able to serve the clients, service recovery can be performed quickly, even unfelt by the users.</p> </li> </ul> <ul> <li> <p>Cost-effective</p> <p>The separation of storage and computing architecture provides a higher resource utilization rate, and it enables clients to manage the cost flexibly according to business demands. The cost savings can be more distinct if the NebulaGraph Cloud service is used.</p> </li> </ul> <ul> <li> <p>Open to more possibilities</p> <p>With the ability to run separately, the Graph Service may work with multiple types of storage engines, and the Storage Service may also serve more types of computing engines.</p> </li> </ul> <p>For details on the Graph Service and the Storage Service, see Graph Service and Storage Service.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/","title":"Meta Service","text":"<p>This topic introduces the architecture and functions of the Meta Service.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#the_architecture_of_the_meta_service","title":"The architecture of the Meta Service","text":"<p>The architecture of the Meta Service is as follows:</p> <p></p> <p>The Meta Service is run by nebula-metad processes. Users can deploy nebula-metad processes according to the scenario:</p> <ul> <li>In a test environment, users can deploy one or three nebula-metad processes on different machines or a single machine.</li> <li>In a production environment, we recommend that users deploy three nebula-metad processes on different machines for high availability.</li> </ul> <p>All the nebula-metad processes form a Raft-based cluster, with one process as the leader and the others as the followers.</p> <p>The leader is elected by the majorities and only the leader can provide service to the clients or other components of NebulaGraph. The followers will be run in a standby way and each has a data replication of the leader. Once the leader fails, one of the followers will be elected as the new leader.</p> <p>Note</p> <p>The data of the leader and the followers will keep consistent through Raft. Thus the breakdown and election of the leader will not cause data inconsistency. For more information on Raft, see Storage service architecture.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#functions_of_the_meta_service","title":"Functions of the Meta Service","text":""},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#manages_user_accounts","title":"Manages user accounts","text":"<p>The Meta Service stores the information of user accounts and the privileges granted to the accounts. When the clients send queries to the Meta Service through an account, the Meta Service checks the account information and whether the account has the right privileges to execute the queries or not.</p> <p>For more information on NebulaGraph access control, see Authentication and authorization.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#manages_partitions","title":"Manages partitions","text":"<p>The Meta Service stores and manages the locations of the storage partitions and helps balance the partitions.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#manages_graph_spaces","title":"Manages graph spaces","text":"<p>NebulaGraph supports multiple graph spaces. Data stored in different graph spaces are securely isolated. The Meta Service stores the metadata of all graph spaces and tracks the changes of them, such as adding or dropping a graph space.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#manages_schema_information","title":"Manages schema information","text":"<p>NebulaGraph is a strong-typed graph database. Its schema contains tags (i.e., the vertex types), edge types, tag properties, and edge type properties.</p> <p>The Meta Service stores the schema information. Besides, it performs the addition, modification, and deletion of the schema, and logs the versions of them.</p> <p>For more information on NebulaGraph schema, see Data model.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#manages_ttl_information","title":"Manages TTL information","text":"<p>The Meta Service stores the definition of TTL (Time to Live) options which are used to control data expiration. The Storage Service takes care of the expiring and evicting processes. For more information, see TTL.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/2.meta-service/#manages_jobs","title":"Manages jobs","text":"<p>The Job Management module in the Meta Service is responsible for the creation, queuing, querying, and deletion of jobs.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/","title":"Graph Service","text":"<p>Graph Service is used to process the query. It has four submodules: Parser, Validator, Planner, and Executor. This topic will describe Graph Service accordingly.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/#the_architecture_of_graph_service","title":"The architecture of Graph Service","text":"<p>After a query is sent to Graph Service, it will be processed by the following four submodules:</p> <ol> <li> <p>Parser: Performs lexical analysis and syntax analysis.</p> </li> <li> <p>Validator: Validates the statements.</p> </li> <li> <p>Planner: Generates and optimizes the execution plans.</p> </li> <li> <p>Executor: Executes the operators.</p> </li> </ol>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/#parser","title":"Parser","text":"<p>After receiving a request, the statements will be parsed by the Parser composed of Flex (lexical analysis tool) and Bison (syntax analysis tool), and its corresponding AST will be generated. Statements will be directly intercepted in this stage because of its invalid syntax.</p> <p>For example, the structure of the AST of <code>GO FROM \"Tim\" OVER like WHERE properties(edge).likeness &gt; 8.0 YIELD dst(edge)</code> is shown in the following picture.</p> <p></p>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/#validator","title":"Validator","text":"<p>Validator performs a series of validations on the AST. It mainly works on these tasks:</p> <ul> <li>Validating metadata<p>Validator will validate whether the metadata is correct or not.</p> <p>When parsing the <code>OVER</code>, <code>WHERE</code>, and <code>YIELD</code> clauses, Validator looks up the Schema and verifies whether the edge type and tag data exist or not. For an <code>INSERT</code> statement, Validator verifies whether the types of the inserted data are the same as the ones defined in the Schema.</p> </li> </ul> <ul> <li>Validating contextual reference<p>Validator will verify whether the cited variable exists or not, or whether the cited property is variable or not.</p> <p>For composite statements, like <code>$var = GO FROM \"Tim\" OVER like YIELD dst(edge) AS ID; GO FROM $var.ID OVER serve YIELD dst(edge)</code>, Validator verifies first to see if <code>var</code> is defined, and then to check if the <code>ID</code> property is attached to the <code>var</code> variable.</p> </li> </ul> <ul> <li>Validating type inference<p>Validator infers what type the result of an expression is and verifies the type against the specified clause.</p> <p>For example, the <code>WHERE</code> clause requires the result to be a <code>bool</code> value, a <code>NULL</code> value, or <code>empty</code>.</p> </li> </ul> <ul> <li>Validating the information of <code>*</code><p>Validator needs to verify all the Schema that involves <code>*</code> when verifying the clause if there is a <code>*</code> in the statement.</p> <p>Take a statement like <code>GO FROM \"Tim\" OVER * YIELD dst(edge), properties(edge).likeness, dst(edge)</code> as an example. When verifying the <code>OVER</code> clause, Validator needs to verify all the edge types. If the edge type includes <code>like</code> and <code>serve</code>, the statement would be <code>GO FROM \"Tim\" OVER like,serve YIELD dst(edge), properties(edge).likeness, dst(edge)</code>.</p> </li> </ul> <ul> <li>Validating input and output<p>Validator will check the consistency of the clauses before and after the <code>|</code>.</p> <p>In the statement <code>GO FROM \"Tim\" OVER like YIELD dst(edge) AS ID | GO FROM $-.ID OVER serve YIELD dst(edge)</code>, Validator will verify whether <code>$-.ID</code> is defined in the clause before the <code>|</code>.</p> </li> </ul> <p>When the validation succeeds, an execution plan will be generated. Its data structure will be stored in the <code>src/planner</code> directory.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/#planner","title":"Planner","text":"<p>In the <code>nebula-graphd.conf</code> file, when <code>enable_optimizer</code> is set to be <code>false</code>, Planner will not optimize the execution plans generated by Validator. It will be executed by Executor directly.</p> <p>In the <code>nebula-graphd.conf</code> file, when <code>enable_optimizer</code> is set to be <code>true</code>, Planner will optimize the execution plans generated by Validator. The structure is as follows.</p> <p></p> <ul> <li>Before optimization<p>In the execution plan on the right side of the preceding picture, each node directly depends on other nodes. For example, the root node <code>Project</code> depends on the <code>Filter</code> node, the <code>Filter</code> node depends on the <code>GetNeighbor</code> node, and so on, up to the leaf node <code>Start</code>. Then the execution plan is (not truly) executed.</p> <p>During this stage, every node has its input and output variables, which are stored in a hash table. The execution plan is not truly executed, so the value of each key in the associated hash table is empty (except for the <code>Start</code> node, where the input variables hold the starting data), and the hash table is defined in <code>src/context/ExecutionContext.cpp</code> under the <code>nebula-graph</code> repository.</p> <p>For example, if the hash table is named as <code>ResultMap</code> when creating the <code>Filter</code> node, users can determine that the node takes data from <code>ResultMap[\"GN1\"]</code>, then puts the result into <code>ResultMap[\"Filter2\"]</code>, and so on. All these work as the input and output of each node.</p> </li> </ul> <ul> <li>Process of optimization<p>The optimization rules that Planner has implemented so far are considered RBO (Rule-Based Optimization), namely the pre-defined optimization rules. The CBO (Cost-Based Optimization) feature is under development. The optimized code is in the <code>src/optimizer/</code> directory under the <code>nebula-graph</code> repository.</p> <p>RBO is a \u201cbottom-up\u201d exploration process. For each rule, the root node of the execution plan (in this case, the <code>Project</code> node) is the entry point, and step by step along with the node dependencies, it reaches the node at the bottom to see if it matches the rule.</p> <p>As shown in the preceding figure, when the <code>Filter</code> node is explored, it is found that its children node is <code>GetNeighbors</code>, which matches successfully with the pre-defined rules, so a transformation is initiated to integrate the <code>Filter</code> node into the <code>GetNeighbors</code> node, the <code>Filter</code> node is removed, and then the process continues to the next rule. Therefore, when the <code>GetNeighbor</code> operator calls interfaces of the Storage layer to get the neighboring edges of a vertex during the execution stage, the Storage layer will directly filter out the unqualified edges internally. Such optimization greatly reduces the amount of data transfer, which is commonly known as filter pushdown.</p> </li> </ul> <p>Note</p> <p>NebulaGraph 2.6.2 will not run optimization by default.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/#executor","title":"Executor","text":"<p>The Executor module consists of Scheduler and Executor. The Scheduler generates the corresponding execution operators against the execution plan, starting from the leaf nodes and ending at the root node. The structure is as follows.</p> <p></p> <p>Each node of the execution plan has one execution operator node, whose input and output have been determined in the execution plan. Each operator only needs to get the values for the input variables, compute them, and finally put the results into the corresponding output variables. Therefore, it is only necessary to execute step by step from <code>Start</code>, and the result of the last operator is returned to the user as the final result.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/3.graph-service/#source_code_hierarchy","title":"Source code hierarchy","text":"<p>The source code hierarchy under the nebula-graph repository is as follows.</p> <pre><code>|--src\n   |--context    //contexts for validation and execution\n   |--daemons\n   |--executor   //execution operators\n   |--mock\n   |--optimizer  //optimization rules\n   |--parser     //lexical analysis and syntax analysis\n   |--planner    //structure of the execution plans\n   |--scheduler  //scheduler\n   |--service\n   |--util       //basic components\n   |--validator  //validation of the statements\n   |--visitor\n</code></pre>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/","title":"Storage Service","text":"<p>The persistent data of NebulaGraph have two parts. One is the Meta Service that stores the meta-related data.</p> <p>The other is the Storage Service that stores the data, which is run by the nebula-storaged process. This topic will describe the architecture of Storage Service.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#advantages","title":"Advantages","text":"<ul> <li>High performance (Customized built-in KVStore)</li> </ul> <ul> <li>Great scalability (Shared-nothing architecture, not rely on NAS/SAN-like devices)</li> </ul> <ul> <li>Strong consistency (Raft)</li> </ul> <ul> <li>High availability (Raft)</li> </ul> <ul> <li>Supports synchronizing with the third party systems, such as Elasticsearch.</li> </ul>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#the_architecture_of_storage_service","title":"The architecture of Storage Service","text":"<p>Storage Service is run by the nebula-storaged process. Users can deploy nebula-storaged processes on different occasions. For example, users can deploy 1 nebula-storaged process in a test environment and deploy 3 nebula-storaged processes in a production environment.</p> <p>All the nebula-storaged processes consist of a Raft-based cluster. There are three layers in the Storage Service:</p> <ul> <li> <p>Storage interface</p> <p>The top layer is the storage interface. It defines a set of APIs that are related to the graph concepts. These API requests will be translated into a set of KV operations targeting the corresponding Partition. For example:</p> <ul> <li><code>getNeighbors</code>: query the in-edge or out-edge of a set of vertices, return the edges and the corresponding properties, and support conditional filtering.</li> </ul> <ul> <li><code>insert vertex/edge</code>: insert a vertex or edge and its properties.</li> </ul> <ul> <li><code>getProps</code>: get the properties of a vertex or an edge.</li> </ul> <p>It is this layer that makes the Storage Service a real graph storage. Otherwise, it is just a KV storage.</p> </li> </ul> <ul> <li> <p>Consensus</p> <p>Below the storage interface is the consensus layer that implements Multi Group Raft, which ensures the strong consistency and high availability of the Storage Service.</p> </li> </ul> <ul> <li> <p>Store engine</p> <p>The bottom layer is the local storage engine library, providing operations like <code>get</code>, <code>put</code>, and <code>scan</code> on local disks. The related interfaces are stored in <code>KVStore.h</code> and <code>KVEngine.h</code> files. Users can develop their own local store plugins based on their needs.</p> </li> </ul> <p>The following will describe some features of Storage Service based on the above architecture.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#kvstore","title":"KVStore","text":"<p>NebulaGraph develops and customizes its built-in KVStore for the following reasons.</p> <ul> <li>It is a high-performance KVStore.</li> </ul> <ul> <li>It is provided as a (kv) library and can be easily developed for the filtering-pushdown purpose. As a strong-typed database, how to provide Schema during pushdown is the key to efficiency for NebulaGraph.</li> </ul> <ul> <li>It has strong data consistency.</li> </ul> <p>Therefore, NebulaGraph develops its own KVStore with RocksDB as the local storage engine. The advantages are as follows.</p> <ul> <li>For multiple local hard disks, NebulaGraph can make full use of its concurrent capacities through deploying multiple data directories.</li> </ul> <ul> <li> <p>Meta Service manages all the Storage servers. All the partition distribution data and current machine status can be found in the meta service. Accordingly, users can execute a manual load balancing plan in meta service.</p> <p>Note</p> <p>NebulaGraph does not support auto load balancing because auto data transfer will affect online business.</p> </li> </ul> <ul> <li>NebulaGraph provides its own WAL mode so one can customize the WAL. Each partition owns its WAL.</li> </ul> <ul> <li>One NebulaGraph KVStore cluster supports multiple graph spaces, and each graph space has its own partition number and replica copies. Different graph spaces are isolated physically from each other in the same cluster.</li> </ul>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#data_storage_formats","title":"Data storage formats","text":"<p>NebulaGraph stores vertices and edges. Efficient property filtering is critical for a Graph Database. So, NebulaGraph uses keys to store vertices and edges, while uses values to store the related properties.</p> <p>NebulaGraph 2.0 has changed a lot over its releases. The following will introduce the old and new data storage formats and cover their differences.</p> <ul> <li>Vertex format<p></p> Field Description <code>Type</code> One byte, used to indicate the key type. <code>PartID</code> Three bytes, used to indicate the sharding partition and to scan the partition data based on the prefix when re-balancing the partition. <code>VertexID</code> Used to indicate vertex ID. For an integer VertexID, it occupies eight bytes. However, for a string VertexID, it is changed to <code>fixed_string</code> of a fixed length which needs to be specified by users when they create the space. <code>TagID</code> Four bytes, used to indicate the tags that vertex relate with. </li> </ul> <ul> <li>Edge Format<p></p> Field Description <code>Type</code> One byte, used to indicate the key type. <code>PartID</code> Three bytes, used to indicate the sharding partition. This field can be used to scan the partition data based on the prefix when re-balancing the partition. <code>VertexID</code> Used to indicate vertex ID. The former VID refers to source VID in out-edge and dest VID in in-edge, while the latter VID refers to dest VID in out-edge and source VID in in-edge. <code>Edge Type</code> Four bytes, used to indicate edge type. Greater than zero means out-edge, less than zero means in-edge. <code>Rank</code> Eight bytes, used to indicate multiple edges in one edge type. Users can set the field based on needs and store weight, such as transaction time and transaction number. <code>PlaceHolder</code> One byte. Reserved. </li> </ul> <p>Legacy version compatibility</p> <p>The differences between NebulaGraph 1.x and 2.0 are as follows:</p> <ul> <li>In NebulaGraph 1.x, a vertex and an edge have the same <code>Type</code> byte, while in NebulaGraph 2.0, the Type byte differs from each other, which separates vertices and edges physically so that all tags of a vertex can be easily queried.</li> <li>NebulaGraph 1.x supports only int IDs, while NebulaGraph 2.0 is compatible with both int IDs and string IDs.</li> <li>NebulaGraph 2.0 removes <code>Timestamp</code> in both vertex and edge key formats.</li> <li>NebulaGraph 2.0 adds <code>PlaceHolder</code> to edge key format.</li> <li>NebulaGraph 2.0 has changed the formats of indexes for a range query.</li> </ul>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#property_descriptions","title":"Property descriptions","text":"<p>NebulaGraph uses strong-typed Schema.</p> <p>NebulaGraph will store the properties of vertex and edges in order after encoding them. Since the length of properties is fixed, queries can be made in no time according to offset. Before decoding, NebulaGraph needs to get (and cache) the schema information in the Meta Service. In addition, when encoding properties, NebulaGraph will add the corresponding schema version to support online schema change.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#data_partitioning","title":"Data partitioning","text":"<p>Since in an ultra-large-scale relational network, vertices can be as many as tens to hundreds of billions, and edges are even more than trillions. Even if only vertices and edges are stored, the storage capacity of both exceeds that of ordinary servers. Therefore, NebulaGraph uses hash to shard the graph elements and store them in different partitions.</p> <p></p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#edge_and_storage_amplification","title":"Edge and storage amplification","text":"<p>In NebulaGraph, an edge corresponds to two key-value pairs on the hard disk. When there are lots of edges and each has many properties, storage amplification will be obvious. The storage format of edges is shown in the picture below.</p> <p></p> <p>In this example, ScrVertex connects DstVertex via EdgeA, forming the path of <code>(SrcVertex)-[EdgeA]-&gt;(DstVertex)</code>. ScrVertex, DstVertex, and EdgeA will all be stored in Partition x and Partition y as four key-value pairs in the storage layer. Details are as follows:</p> <ul> <li>The key value of SrcVertex is stored in Partition x. Key fields include Type, PartID(x), VID(Src), and TagID. SerializedValue, namely Value, refers to serialized vertex properties.</li> </ul> <ul> <li>The first key value of EdgeA, namely EdgeA_Out, is stored in the same partition as the ScrVertex. Key fields include Type, PartID(x), VID(Src), EdgeType(+ means out-edge), Rank(0), VID(Dst), and PlaceHolder. SerializedValue, namely Value, refers to serialized edge properties.</li> </ul> <ul> <li>The key value of DstVertex is stored in Partition y. Key fields include Type, PartID(y), VID(Dst), and TagID. SerializedValue, namely Value, refers to serialized vertex properties.</li> </ul> <ul> <li>The second key value of EdgeA, namely EdgeA_In, is stored in the same partition as the DstVertex. Key fields include Type, PartID(y), VID(Dst), EdgeType(- means in-edge), Rank(0), VID(Src), and PlaceHolder. SerializedValue, namely Value, refers to serialized edge properties, which is exactly the same as that in EdgeA_Out.</li> </ul> <p>EdgeA_Out and EdgeA_In are stored in storage layer with opposite directions, constituting EdgeA logically. EdgeA_Out is used for traversal requests starting from SrcVertex, such as <code>(a)-[]-&gt;()</code>; EdgeA_In is used for traversal requests starting from DstVertex, such as <code>()-[]-&gt;(a)</code>.</p> <p>Like EdgeA_Out and EdgeA_In, NebulaGraph redundantly stores the information of each edge, which doubles the actual capacities needed for edge storage. The key corresponding to the edge occupies a small hard disk space, but the space occupied by Value is proportional to the length and amount of the property value. Therefore, it will occupy a relatively large hard disk space if the property value of the edge is large or there are many edge property values.</p> <p>To ensure the final consistency of the two key-value pairs when operating on edges, enable the TOSS function. After that, the operation will be performed in Partition x first where the out-edge is located, and then in Partition y where the in-edge is located. Finally, the result is returned.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#partition_algorithm","title":"Partition algorithm","text":"<p>NebulaGraph uses a static Hash strategy to shard data through a modulo operation on vertex ID. All the out-keys, in-keys, and tag data will be placed in the same partition. In this way, query efficiency is increased dramatically.</p> <p>Note</p> <p>The number of partitions needs to be determined when users are creating a graph space since it cannot be changed afterward. Users are supposed to take into consideration the demands of future business when setting it.</p> <p>When inserting into NebulaGraph, vertices and edges are distributed across different partitions. And the partitions are located on different machines. The number of partitions is set in the CREATE SPACE statement and cannot be changed afterward.</p> <p>If certain vertices need to be placed on the same partition (i.e., on the same machine), see Formula/code. </p> <p>The following code will briefly describe the relationship between VID and partition.</p> <pre><code>// If VertexID occupies 8 bytes, it will be stored in int64 to be compatible with the version 1.0.\nuint64_t vid = 0;\nif (id.size() == 8) {\n    memcpy(static_cast&lt;void*&gt;(&amp;vid), id.data(), 8);\n} else {\n    MurmurHash2 hash;\n    vid = hash(id.data());\n}\nPartitionID pId = vid % numParts + 1;\n</code></pre> <p>Roughly speaking, after hashing a fixed string to int64, (the hashing of int64 is the number itself), do modulo, and then plus one, namely:</p> <pre><code>pId = vid % numParts + 1;\n</code></pre> <p>Parameters and descriptions of the preceding formula are as follows:</p> Parameter Description <code>%</code> The modulo operation. <code>numParts</code> The number of partitions for the graph space where the <code>VID</code> is located, namely the value of <code>partition_num</code> in the CREATE SPACE statement. <code>pId</code> The ID for the partition where the <code>VID</code> is located. <p>Suppose there are 100 partitions, the vertices with <code>VID</code> 1, 101, and 1001 will be stored on the same partition. But, the mapping between the partition ID and the machine address is random. Therefore, we cannot assume that any two partitions are located on the same machine.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#raft","title":"Raft","text":""},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#raft_implementation","title":"Raft implementation","text":"<p>In a distributed system, one data usually has multiple replicas so that the system can still run normally even if a few copies fail. It requires certain technical means to ensure consistency between replicas.</p> <p>Basic principle: Raft is designed to ensure consistency between replicas. Raft uses election between replicas, and the (candidate) replica that wins more than half of the votes will become the Leader, providing external services on behalf of all replicas. The rest Followers will play backups. When the Leader fails (due to communication failure, operation and maintenance commands, etc.), the rest Followers will conduct a new round of elections and vote for a new Leader. The Leader and Followers will detect each other's survival through heartbeats and write them to the hard disk in Raft-wal mode. Replicas that do not respond to more than multiple heartbeats will be considered faulty.</p> <p>Note</p> <p>Raft-wal needs to be written into the hard disk periodically. If hard disk bottlenecks to write, Raft will fail to send a heartbeat and conduct a new round of elections. If the hard disk IO is severely blocked, there will be no Leader for a long time.</p> <p>Read and write: For every writing request of the clients, the Leader will initiate a Raft-wal and synchronize it with the Followers. Only after over half replicas have received the Raft-wal will it return to the clients successfully. For every reading request of the clients, it will get to the Leader directly, while Followers will not be involved.</p> <p>Failure: Scenario 1: Take a (space) cluster of a single replica as an example. If the system has only one replica, the Leader will be itself. If failure happens, the system will be completely unavailable. Scenario 2: Take a (space) cluster of three replicas as an example. If the system has three replicas, one of them will be the Leader and the rest will be the Followers. If the Leader fails, the rest two can still vote for a new Leader (and a Follower), and the system is still available. But if any of the two Followers fails again, the system will be completely unavailable due to inadequate voters.</p> <p>Note</p> <p>Raft and HDFS have different modes of duplication. Raft is based on a quorum vote, so the number of replicas cannot be even.</p> <p>Listener: As is a special role in Raft, it cannot vote or keep data consistency. In NebulaGraph, it reads Raft-wal from the Leader and synchronizes it to ElasticSearch cluster.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#multi_group_raft","title":"Multi Group Raft","text":"<p>Storage Service supports a distributed cluster architecture, so NebulaGraph implements Multi Group Raft according to Raft protocol. Each Raft group stores all the replicas of each partition. One replica is the leader, while others are followers. In this way, NebulaGraph achieves strong consistency and high availability. The functions of Raft are as follows.</p> <p>NebulaGraph uses Multi Group Raft to improve performance when there are many partitions because Raft-wal cannot be NULL. When there are too many partitions, costs will increase, such as storing information in Raft group, WAL files, or batch operation in low load.</p> <p>There are two key points to implement the Multi Raft Group:</p> <ul> <li> <p>To share transport layer</p> <p>Each Raft Group sends messages to its corresponding peers. So if the transport layer cannot be shared, the connection costs will be very high.</p> </li> </ul> <ul> <li> <p>To share thread pool</p> <p>Raft Groups share the same thread pool to prevent starting too many threads and a high context switch cost.</p> </li> </ul>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#batch","title":"Batch","text":"<p>For each partition, it is necessary to do a batch to improve throughput when writing the WAL serially. As NebulaGraph uses WAL to implement some special functions, batches need to be grouped, which is a feature of NebulaGraph.</p> <p>For example, lock-free CAS operations will execute after all the previous WALs are committed. So for a batch, if there are several WALs in CAS type, we need to divide this batch into several smaller groups and make sure they are committed serially.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#listener","title":"Listener","text":"<p>The Listener is designed for storage horizontal scaling. It takes a long time for the newly added machines to be synchronized with data. Therefore, these machines cannot join the group followers, otherwise, the availability of the entire cluster will decrease.</p> <p>The Listener will write into the command WAL. If the leader finds a command of <code>add learner</code> when writing the WAL, it will add the listener to its peers and mark it as a Listener. Listeners cannot join the quorum votes, but logs will still be sent to them as usual. Listeners themselves will not initiate elections.</p> <p>Raft listener can write the data into Elasticsearch cluster after receiving them from Learner to implement full-text search. For more information, see Deploy Raft Listener. </p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#transfer_leadership","title":"Transfer Leadership","text":"<p>Transfer leadership is extremely important for balance. When moving a partition from one machine to another, NebulaGraph first checks if the source is a leader. If so, it should be moved to another peer. After data migration is completed, it is important to balance leader distribution again.</p> <p>When a transfer leadership command is committed, the leader will abandon its leadership and the followers will start a leader election.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#peer_changes","title":"Peer changes","text":"<p>To avoid split-brain, when members in a Raft Group change, an intermediate state is required. In such a state, the quorum of the old group and new group always have an overlap. Thus it prevents the old or new group from making decisions unilaterally. To make it even simpler, in his doctoral thesis Diego Ongaro suggests adding or removing a peer once to ensure the overlap between the quorum of the new group and the old group. NebulaGraph also uses this approach, except that the way to add or remove a member is different. For details, please refer to addPeer/removePeer in the Raft Part class.</p>"},{"location":"1.introduction/3.nebula-graph-architecture/4.storage-service/#differences_with_hdfs","title":"Differences with HDFS","text":"<p>Storage Service is a Raft-based distributed architecture, which has certain differences with that of HDFS. For example:</p> <ul> <li>Storage Service ensures consistency through Raft. Usually, the number of its replicas is odd to elect a leader. However, DataNode used by HDFS ensures consistency through NameNode, which has no limit on the number of replicas.</li> </ul> <ul> <li>In Storage Service, only the replicas of the leader can read and write, while in HDFS all the replicas can do so.</li> </ul> <ul> <li>In Storage Service, the number of replicas needs to be determined when creating a space, since it cannot be changed afterward. But in HDFS, the number of replicas can be changed freely.</li> </ul> <ul> <li>Storage Service can access the file system directly. While the applications of HDFS (such as HBase) have to access HDFS before the file system, which requires more RPC times.</li> </ul> <p>In a word, Storage Service is more lightweight with some functions simplified and its architecture is simpler than HDFS, which can effectively improve the read and write performance of a smaller block of data.</p>"},{"location":"14.client/1.nebula-client/","title":"Clients overview","text":"<p>NebulaGraph supports multiple types of clients for users to connect to and manage the NebulaGraph database.</p> <ul> <li>Nebula Console: the native CLI client</li> </ul> <ul> <li>Nebula CPP: the NebulaGraph client for C++</li> </ul> <ul> <li>Nebula Java: the NebulaGraph client for Java</li> </ul> <ul> <li>Nebula Python: the NebulaGraph client for Python</li> </ul> <ul> <li>Nebula Go: the NebulaGraph client for Golang</li> </ul> <p>Note</p> <p>No clients are thread-safe.</p>"},{"location":"14.client/3.nebula-cpp-client/","title":"Nebula CPP","text":"<p>Nebula CPP is a C++ client for connecting to and managing the NebulaGraph database.</p>"},{"location":"14.client/3.nebula-cpp-client/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have installed C++ and GCC 4.8 or later versions.</li> </ul> <ul> <li>You have prepared the correct resources.</li> </ul>"},{"location":"14.client/3.nebula-cpp-client/#compatibility_with_nebulagraph","title":"Compatibility with NebulaGraph","text":"NebulaGraph version Nebula CPP version 2.6.2 2.5.0 2.0.1 2.0.0 2.0.0 2.0.0"},{"location":"14.client/3.nebula-cpp-client/#install_nebula_cpp","title":"Install Nebula CPP","text":"<ol> <li> <p>Clone the Nebula CPP source code to the host.</p> <ul> <li> <p>(Recommended) To install a specific version of Nebula CPP, use the Git option <code>--branch</code> to specify the branch. For example, to install v2.5.0, run the following command:</p> <pre><code>$ git clone --branch v2.5.0 https://github.com/vesoft-inc/nebula-cpp.git\n</code></pre> </li> </ul> <ul> <li> <p>To install the daily development version, run the following command to download the source code from the <code>master</code> branch:</p> <pre><code>$ git clone https://github.com/vesoft-inc/nebula-cpp.git\n</code></pre> </li> </ul> </li> <li> <p>Change the working directory to <code>nebula-cpp</code>.</p> <pre><code>$ cd nebula-cpp\n</code></pre> </li> <li> <p>Create a directory named <code>build</code> and change the working directory to it.</p> <pre><code>$ mkdir build &amp;&amp; cd build\n</code></pre> </li> <li> <p>Generate the <code>makefile</code> file with CMake.</p> <p>Note</p> <p>The default installation path is <code>/usr/local/nebula</code>. To modify it, add the <code>-DCMAKE_INSTALL_PREFIX=&lt;installation_path&gt;</code> option while running the following command.</p> <pre><code>$ cmake -DCMAKE_BUILD_TYPE=Release ..\n</code></pre> <p>Note</p> <p>If G++ does not support C++ 11, add the option <code>-DDISABLE_CXX11_ABI=ON</code>.</p> </li> <li> <p>Compile Nebula CPP.</p> <p>To speed up the compiling, use the <code>-j</code> option to set a concurrent number <code>N</code>. It should be \\(\\min(\\text{CPU}core number,\\frac{the_memory_size(GB)}{2})\\).</p> <pre><code>$ make -j{N}\n</code></pre> </li> <li> <p>Install Nebula CPP.</p> <pre><code>$ sudo make install\n</code></pre> </li> <li> <p>Update the dynamic link library.</p> <pre><code>$ sudo ldconfig\n</code></pre> </li> </ol>"},{"location":"14.client/3.nebula-cpp-client/#use_nebula_cpp","title":"Use Nebula CPP","text":"<p>Compile the CPP file to an executable file, then you can use it. The following steps take using <code>SessionExample.cpp</code> for example.</p> <ol> <li> <p>Use the example code to create the <code>SessionExample.cpp</code> file.</p> </li> <li> <p>Run the following command to compile the file.</p> <pre><code>$ LIBRARY_PATH=&lt;library_folder_path&gt;:$LIBRARY_PATH g++ -std=c++11 SessionExample.cpp -I&lt;include_folder_path&gt; -lnebula_graph_client -o session_example\n</code></pre> <ul> <li><code>library_folder_path</code>: The storage path of the NebulaGraph dynamic libraries. The default path is <code>/usr/local/nebula/lib64</code>.</li> </ul> <ul> <li><code>include_folder_path</code>: The storage of the NebulaGraph header files. The default path is <code>/usr/local/nebula/include</code>.</li> </ul> </li> </ol> <p>For example:</p> <pre><code>$ LIBRARY_PATH=/usr/local/nebula/lib64:$LIBRARY_PATH g++ -std=c++11 SessionExample.cpp -I/usr/local/nebula/include -lnebula_graph_client -o session_example\n</code></pre>"},{"location":"14.client/3.nebula-cpp-client/#core_of_the_example_code","title":"Core of the example code","text":"<p>This sub-section shows the core of the example code. For all the code, see SessionExample.</p> <pre><code>nebula::init(&amp;argc, &amp;argv);\nauto address = \"192.168.xx.1:9669\";\nnebula::ConnectionPool pool;\npool.init({address}, nebula::Config{});\nauto session = pool.getSession(\"root\", \"nebula\");\n\nauto result = session.execute(\"SHOW HOSTS\");\nstd::cout &lt;&lt; *result.data;\n\nstd::atomic_bool complete{false};\nsession.asyncExecute(\"SHOW HOSTS\", [&amp;complete](nebula::ExecutionResponse&amp;&amp; cbResult) {\nstd::cout &lt;&lt; *cbResult.data;\ncomplete.store(true);\n});\nsession.release();\n</code></pre>"},{"location":"14.client/4.nebula-java-client/","title":"Nebula Java","text":"<p>Nebula Java is a Java client for connecting to and managing the NebulaGraph database.</p>"},{"location":"14.client/4.nebula-java-client/#prerequisites","title":"Prerequisites","text":"<p>You have installed Java 8.0 or later versions.</p>"},{"location":"14.client/4.nebula-java-client/#compatibility_with_nebulagraph","title":"Compatibility with NebulaGraph","text":"NebulaGraph version Nebula Java version 2.6.2 2.6.1 2.0.1 2.0.0 2.0.0 2.0.0 2.0.0-rc1 2.0.0-rc1"},{"location":"14.client/4.nebula-java-client/#download_nebula_java","title":"Download Nebula Java","text":"<ul> <li> <p>(Recommended) To install a specific version of Nebula Java, use the Git option <code>--branch</code> to specify the branch. For example, to install v2.6.1, run the following command:</p> <pre><code>$ git clone --branch v2.6.1 https://github.com/vesoft-inc/nebula-java.git\n</code></pre> </li> </ul> <ul> <li> <p>To install the daily development version, run the following command to download the source code from the <code>master</code> branch:</p> <pre><code>$ git clone https://github.com/vesoft-inc/nebula-java.git\n</code></pre> </li> </ul>"},{"location":"14.client/4.nebula-java-client/#use_nebula_java","title":"Use Nebula Java","text":"<p>Note</p> <p>We recommend that each thread uses one session. If multiple threads use the same session, the performance will be reduced.</p> <p>When importing a Maven project with tools such as IDEA, set the following dependency in <code>pom.xml</code>.</p> <p>Note</p> <p><code>2.0.0-SNAPSHOT</code> indicates the daily development version that may have unknown issues. We recommend that you replace <code>2.0.0-SNAPSHOT</code> with a released version number to use a table version.</p> <pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;com.vesoft&lt;/groupId&gt;\n  &lt;artifactId&gt;client&lt;/artifactId&gt;\n  &lt;version&gt;2.0.0-SNAPSHOT&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>If you cannot download the dependency for the daily development version, set the following content in <code>pom.xml</code>. Released versions have no such issue.</p> <pre><code>&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt; &lt;/repository&gt; \n&lt;/repositories&gt;\n</code></pre> <p>If there is no Maven to manage the project, manually download the JAR file to install Nebula Java.</p>"},{"location":"14.client/4.nebula-java-client/#core_of_the_example_code","title":"Core of the example code","text":"<p>This sub-section shows the core of the example code. For all the code, see GraphClientExample.</p> <pre><code>NebulaPool pool = new NebulaPool();\nSession session = null;\ntry {\nNebulaPoolConfig nebulaPoolConfig = new NebulaPoolConfig();\nnebulaPoolConfig.setMaxConnSize(100);\nList&lt;HostAddress&gt; addresses = Arrays.asList(new HostAddress(\"192.168.xx.1\", 9669),\nnew HostAddress(\"192.168.xx.2\", 9670));\npool.init(addresses, nebulaPoolConfig);\nsession = pool.getSession(\"root\", \"nebula\", false);\n\n//create space\nString space = \"test\";\nString createSpace = \"CREATE SPACE IF NOT EXISTS \" + space + \" (partition_num=15, replica_factor=1, vid_type=fixed_string(30)); \";\nResultSet resp = session.execute(createSpace);\n\n\n//create schema\nString createSchema = \"USE \" + space + \"; CREATE TAG IF NOT EXISTS person(name string, age int);\"\n+ \"CREATE EDGE IF NOT EXISTS like(likeness double)\";\nResultSet resp = session.execute(createSchema);\n\n//insert vertex\nString insertVertexes = \"INSERT VERTEX person(name, age) VALUES \" + \"'Bob':('Bob', 10), \"\n+ \"'Lily':('Lily', 9), \" + \"'Tom':('Tom', 10), \" + \"'Jerry':('Jerry', 13), \"\n+ \"'John':('John', 11);\";\nResultSet resp = session.execute(insertVertexes);\n\n// inert edge\nString insertEdges = \"INSERT EDGE like(likeness) VALUES \" + \"'Bob'-&gt;'Lily':(80.0), \"\n+ \"'Bob'-&gt;'Tom':(70.0), \" + \"'Lily'-&gt;'Jerry':(84.0), \" + \"'Tom'-&gt;'Jerry':(68.3), \"\n+ \"'Bob'-&gt;'John':(97.2);\";\nResultSet resp = session.execute(insertEdges);\n\n// query\nString query = \"GO FROM \\\"Bob\\\" OVER like \" + \"YIELD properties($$).name, properties($$).age, properties(edge).likeness\";\nResultSet resp = session.execute(query);\nprintResult(resp);\n}finally {\nif (session != null) {\nsession.release();\n}\npool.close();\n}\n</code></pre>"},{"location":"14.client/5.nebula-python-client/","title":"Nebula Python","text":"<p>Nebula Python is a Python client for connecting to and managing the NebulaGraph database.</p>"},{"location":"14.client/5.nebula-python-client/#prerequisites","title":"Prerequisites","text":"<p>You have installed Python 3.5 or later versions.</p>"},{"location":"14.client/5.nebula-python-client/#compatibility_with_nebulagraph","title":"Compatibility with NebulaGraph","text":"NebulaGraph version Nebula Python version 2.6.2 2.6.1 2.0.1 2.0.0 2.0.0 2.0.0 2.0.0-rc1 2.0.0rc1"},{"location":"14.client/5.nebula-python-client/#install_nebula_python","title":"Install Nebula Python","text":""},{"location":"14.client/5.nebula-python-client/#install_nebula_python_with_pip","title":"Install Nebula Python with pip","text":"<pre><code>$ pip install nebula2-python==&lt;version&gt;\n</code></pre>"},{"location":"14.client/5.nebula-python-client/#install_nebula_python_from_the_source_code","title":"Install Nebula Python from the source code","text":"<ol> <li> <p>Clone the Nebula Python source code to the host.</p> <ul> <li> <p>(Recommended) To install a specific version of Nebula Python, use the Git option <code>--branch</code> to specify the branch. For example, to install v2.6.1, run the following command:</p> <pre><code>$ git clone --branch v2.6.1 https://github.com/vesoft-inc/nebula-python.git\n</code></pre> </li> </ul> <ul> <li> <p>To install the daily development version, run the following command to download the source code from the <code>master</code> branch:</p> <pre><code>$ git clone https://github.com/vesoft-inc/nebula-python.git\n</code></pre> </li> </ul> </li> <li> <p>Change the working directory to nebula-python.</p> <pre><code>$ cd nebula-python\n</code></pre> </li> <li> <p>Run the following command to install dependencies.</p> <pre><code>$ pip install -r requirements.txt\n</code></pre> <p>Note</p> <p>To run unit tests in the development mode, install dependencies of <code>requirements-dev.txt</code>.</p> </li> <li> <p>Run the following command to install Nebula Python.</p> <pre><code>$ sudo python3 setup.py install\n</code></pre> </li> </ol>"},{"location":"14.client/5.nebula-python-client/#core_of_the_example_code","title":"Core of the example code","text":"<p>This section shows the core of the example code. For all the code, see Example.</p>"},{"location":"14.client/5.nebula-python-client/#connect_to_the_graph_service","title":"Connect to the Graph Service","text":"<pre><code># Customize configurations.\nconfig = Config()\nconfig.max_connection_pool_size = 10\n# Initialize the connection pool.\nconnection_pool = ConnectionPool()\n# Returns true if the server is healthy, false otherwise.\nok = connection_pool.init([('192.168.xx.1', 9669)], config)\n\n# Method 1: Manually specify when to release the session.\n# Get the session from the connection pool.\nsession = connection_pool.get_session('root', 'nebula')\n\n# Select a graph space.\nsession.execute('USE basketballplayer')\n\n# Run the SHOW TAGS statement.\nresult = session.execute('SHOW TAGS')\nprint(result)\n\n# Release the session.\nsession.release()\n\n# Method 2: Use session_context to automatically release the session.\nwith connection_pool.session_context('root', 'nebula') as session:\n    session.execute('USE basketballplayer;')\n    result = session.execute('SHOW TAGS;')\n    print(result)\n\n# Close the connection pool.\nconnection_pool.close()\n</code></pre>"},{"location":"14.client/5.nebula-python-client/#connect_to_the_storage_server","title":"Connect to the Storage Server","text":"<pre><code># Set the IP addresses of all Meta servers.\nmeta_cache = MetaCache([('192.168.xx.1', 9559),\n                        ('192.168.xx.2', 9559),\n                        ('192.168.xx.3', 9559)],\n                       50000)\ngraph_storage_client = GraphStorageClient(meta_cache)\n\nresp = graph_storage_client.scan_vertex(\n        space_name='ScanSpace',\n        tag_name='person')\nwhile resp.has_next():\n    result = resp.next()\n    for vertex_data in result:\n        print(vertex_data)\n\nresp = graph_storage_client.scan_edge(\n    space_name='ScanSpace',\n    edge_name='friend')\nwhile resp.has_next():\n    result = resp.next()\n    for edge_data in result:\n        print(edge_data)\n</code></pre>"},{"location":"14.client/6.nebula-go-client/","title":"Nebula Go","text":"<p>Nebula Go is a Golang client for connecting to and managing the NebulaGraph database.</p>"},{"location":"14.client/6.nebula-go-client/#prerequisites","title":"Prerequisites","text":"<p>You have installed Golang 1.13 or later versions.</p>"},{"location":"14.client/6.nebula-go-client/#compatibility_with_nebulagraph","title":"Compatibility with NebulaGraph","text":"NebulaGraph version Nebula Go version 2.6.2 2.6.0 2.0.1 2.0.0-GA 2.0.0 2.0.0-GA"},{"location":"14.client/6.nebula-go-client/#download_nebula_go","title":"Download Nebula Go","text":"<ul> <li> <p>(Recommended) To install a specific version of Nebula Go, use the Git option <code>--branch</code> to specify the branch. For example, to install v2.6.0, run the following command:</p> <pre><code>$ git clone --branch v2.6.0 https://github.com/vesoft-inc/nebula-go.git\n</code></pre> </li> </ul> <ul> <li> <p>To install the daily development version, run the following command to download the source code from the <code>master</code> branch:</p> <pre><code>$ git clone https://github.com/vesoft-inc/nebula-go.git\n</code></pre> </li> </ul>"},{"location":"14.client/6.nebula-go-client/#install_or_update","title":"Install or update","text":"<p>Run the following command to install or update Nebula Go:</p> <pre><code>go get -u -v github.com/vesoft-inc/nebula-go/v2@v2.6.0\n</code></pre>"},{"location":"14.client/6.nebula-go-client/#core_of_the_example_code","title":"Core of the example code","text":"<p>This section shows the core of the example code. For all the code, see graph_client_basic_example and graph_client_goroutines_example.</p> <pre><code>const (\naddress = \"192.168.xx.1\"\nport     = 9669\nusername = \"root\"\npassword = \"nebula\"\n)\n\nfunc main() {\nhostAddress := nebula.HostAddress{Host: address, Port: port}\nhostList := []nebula.HostAddress{hostAddress}\ntestPoolConfig := nebula.GetDefaultConf()\npool, err := nebula.NewConnectionPool(hostList, testPoolConfig, log)\ndefer pool.Close()\nsession, err := pool.GetSession(username, password)\ndefer session.Release()\n\ncheckResultSet := func(prefix string, res *nebula.ResultSet) {\nif !res.IsSucceed() {\nlog.Fatal(fmt.Sprintf(\"%s, ErrorCode: %v, ErrorMsg: %s\", prefix, res.GetErrorCode(), res.GetErrorMsg()))\n}\n}\n{\ncreateSchema := \"CREATE SPACE IF NOT EXISTS basic_example_space(vid_type=FIXED_STRING(20)); \" +\n            \"USE basic_example_space;\" +\n            \"CREATE TAG IF NOT EXISTS person(name string, age int);\" +\n            \"CREATE EDGE IF NOT EXISTS like(likeness double)\"\nresultSet, err := session.Execute(createSchema)\ncheckResultSet(createSchema, resultSet)\n}\nfmt.Print(\"\\n\")\nlog.Info(\"Nebula Go Client Basic Example Finished\")\n}\n</code></pre>"},{"location":"15.contribution/how-to-contribute/","title":"How to Contribute","text":""},{"location":"15.contribution/how-to-contribute/#before_you_get_started","title":"Before you get started","text":""},{"location":"15.contribution/how-to-contribute/#commit_an_issue_on_the_github_or_forum","title":"Commit an issue on the github or forum","text":"<p>You are welcome to contribute any code or files to the project. But firstly we suggest you raise an issue on the github or the forum to start a discussion with the community. Check through the topic for Github.</p>"},{"location":"15.contribution/how-to-contribute/#sign_the_contributor_license_agreement_cla","title":"Sign the Contributor License Agreement (CLA)","text":"<p>What is CLA?</p> <p>Here is the vesoft inc. Contributor License Agreement.</p> <p>Click the Sign in with GitHub to agree button to sign the CLA.</p> <p>If you have any questions, send an email to <code>info@vesoft.com</code>.</p>"},{"location":"15.contribution/how-to-contribute/#modify_a_single_document","title":"Modify a single document","text":"<p>This manual is written in the Markdown language. Click the <code>pencil</code> icon on the right of the document title to commit the modification.</p> <p>This method applies to modify a single document only.</p>"},{"location":"15.contribution/how-to-contribute/#batch_modify_or_add_files","title":"Batch modify or add files","text":"<p>This method applies to contribute codes, modify multiple documents in batches, or add new documents.</p>"},{"location":"15.contribution/how-to-contribute/#step_1_fork_in_the_githubcom","title":"Step 1: Fork in the github.com","text":"<p>The NebulaGraph project has many repositories. Take the nebula-graph repository for example:</p> <ol> <li> <p>Visit https://github.com/vesoft-inc/nebula.</p> </li> <li> <p>Click the <code>Fork</code> button to establish an online fork.</p> </li> </ol>"},{"location":"15.contribution/how-to-contribute/#step_2_clone_fork_to_local_storage","title":"Step 2: Clone Fork to Local Storage","text":"<ol> <li> <p>Define a local working directory.</p> <pre><code># Define the working directory.\nworking_dir=$HOME/Workspace\n</code></pre> </li> <li> <p>Set <code>user</code> to match the Github profile name.</p> <pre><code>user={the Github profile name}\n</code></pre> </li> <li> <p>Create your clone.</p> <pre><code>mkdir -p $working_dir\ncd $working_dir\ngit clone https://github.com/$user/nebula-graph.git\n# or: git clone git@github.com:$user/nebula-graph.git\n\ncd $working_dir/nebula\ngit remote add upstream https://github.com/vesoft-inc/nebula.git\n# or: git remote add upstream git@github.com:vesoft-inc/nebula.git\n\n# Never push to upstream master since you do not have write access.\ngit remote set-url --push upstream no_push\n\n# Confirm that the remote branch is valid.\n# The correct format is:\n# origin    git@github.com:$(user)/nebula-graph.git (fetch)\n# origin    git@github.com:$(user)/nebula-graph.git (push)\n# upstream  https://github.com/vesoft-inc/nebula (fetch)\n# upstream  no_push (push)\ngit remote -v\n</code></pre> </li> <li> <p>(Optional) Define a pre-commit hook.</p> <p>Please link the NebulaGraph pre-commit hook into the <code>.git</code> directory.</p> <p>This hook checks the commits for formatting, building, doc generation, etc.</p> <pre><code>cd $working_dir/nebula-graph/.git/hooks\nln -s $working_dir/nebula-graph/.linters/cpp/hooks/pre-commit.sh .\n</code></pre> <p>Sometimes, the pre-commit hook cannot be executed. You have to execute it manually.</p> <pre><code>cd $working_dir/nebula-graph/.git/hooks\nchmod +x pre-commit\n</code></pre> </li> </ol>"},{"location":"15.contribution/how-to-contribute/#step_3_branch","title":"Step 3: Branch","text":"<ol> <li> <p>Get your local master up to date.</p> <pre><code>cd $working_dir/nebula\ngit fetch upstream\ngit checkout master\ngit rebase upstream/master\n</code></pre> </li> <li> <p>Checkout a new branch from master.</p> <pre><code>git checkout -b myfeature\n</code></pre> <p>Note</p> <p>Because the PR often consists of several commits, which might be squashed while being merged into upstream. We strongly suggest you to open a separate topic branch to make your changes on. After merged, this topic branch can be just abandoned, thus you could synchronize your master branch with upstream easily with a rebase like above. Otherwise, if you commit your changes directly into master, you need to use a hard reset on the master branch. For example:</p> <pre><code>git fetch upstream\ngit checkout master\ngit reset --hard upstream/master\ngit push --force origin master\n</code></pre> </li> </ol>"},{"location":"15.contribution/how-to-contribute/#step_4_develop","title":"Step 4: Develop","text":"<ul> <li> <p>Code style</p> <p>NebulaGraph adopts <code>cpplint</code> to make sure that the project conforms to Google's coding style guides. The checker will be implemented before the code is committed.</p> </li> </ul> <ul> <li> <p>Unit tests requirements</p> <p>Please add unit tests for the new features or bug fixes.</p> </li> </ul> <ul> <li> <p>Build your code with unit tests enabled</p> <p>For more information, see Install NebulaGraph by compiling the source code.</p> <p>Note</p> <p>Make sure you have enabled the building of unit tests by setting <code>-DENABLE_TESTING=ON</code>.</p> </li> </ul> <ul> <li> <p>Run tests</p> <p>In the root directory of <code>nebula</code>, run the following command:</p> <pre><code>cd nebula/build\nctest -j$(nproc)\n</code></pre> </li> </ul>"},{"location":"15.contribution/how-to-contribute/#step_5_bring_your_branch_update_to_date","title":"Step 5: Bring Your Branch Update to Date","text":"<pre><code># While on your myfeature branch.\ngit fetch upstream\ngit rebase upstream/master\n</code></pre> <p>Users need to bring the head branch up to date after other contributors merge PR to the base branch.</p>"},{"location":"15.contribution/how-to-contribute/#step_6_commit","title":"Step 6: Commit","text":"<p>Commit your changes.</p> <pre><code>git commit -a\n</code></pre> <p>Users can use the command <code>--amend</code> to re-edit the previous code.</p>"},{"location":"15.contribution/how-to-contribute/#step_7_push","title":"Step 7: Push","text":"<p>When ready to review or just to establish an offsite backup, push your branch to your fork on <code>github.com</code>:</p> <pre><code>git push origin myfeature\n</code></pre>"},{"location":"15.contribution/how-to-contribute/#step_8_create_a_pull_request","title":"Step 8: Create a Pull Request","text":"<ol> <li> <p>Visit your fork at <code>https://github.com/$user/nebula-graph</code> (replace <code>$user</code> here).</p> </li> <li> <p>Click the <code>Compare &amp; pull request</code> button next to your <code>myfeature</code> branch.</p> </li> </ol>"},{"location":"15.contribution/how-to-contribute/#step_9_get_a_code_review","title":"Step 9: Get a Code Review","text":"<p>Once your pull request has been created, it will be assigned to at least two reviewers. Those reviewers will do a thorough code review to make sure that the changes meet the repository's contributing guidelines and other quality standards.</p>"},{"location":"15.contribution/how-to-contribute/#add_test_cases","title":"Add test cases","text":"<p>For detailed methods, see How to add test cases.</p>"},{"location":"15.contribution/how-to-contribute/#donation","title":"Donation","text":""},{"location":"15.contribution/how-to-contribute/#step_1_confirm_the_project_donation","title":"Step 1: Confirm the project donation","text":"<p>Contact the official NebulaGraph staff via email, WeChat, Slack, etc. to confirm the donation project. The project will be donated to the Nebula Contrib organization.</p> <p>Email address: info@vesoft.com</p> <p>WeChat: NebulaGraphbot</p> <p>Slack: Join Slack</p>"},{"location":"15.contribution/how-to-contribute/#step_2_get_the_information_of_the_project_recipient","title":"Step 2: Get the information of the project recipient","text":"<p>The NebulaGraph official staff will give the recipient ID of the Nebula Contrib project.</p>"},{"location":"15.contribution/how-to-contribute/#step_3_donate_a_project","title":"Step 3: Donate a project","text":"<p>The user transfers the project to the recipient of this donation, and the recipient transfers the project to the Nebula Contrib organization. After the donation, the user will continue to lead the development of community projects as a Maintainer.</p> <p>For operations of transferring a repository on GitHub, see Transferring a repository owned by your user account.</p>"},{"location":"2.quick-start/1.quick-start-workflow/","title":"Quick start workflow","text":"<p>The quick start introduces the simplest workflow to use NebulaGraph, including deploying NebulaGraph, connecting to NebulaGraph, and doing basic CRUD.</p>"},{"location":"2.quick-start/1.quick-start-workflow/#documents","title":"Documents","text":"<p>Users can quickly deploy and use NebulaGraph in the following steps.</p> <ol> <li> <p>Deploy NebulaGraph</p> <p>Users can use the RPM or DEB file to quickly deploy NebulaGraph. For other ways to deploy NebulaGraph and corresponding preparations, see deployment and installation.</p> </li> <li> <p>Start NebulaGraph</p> <p>Users need to start NebulaGraph after deployment.</p> </li> <li> <p>Connect to NebulaGraph</p> <p>Then users can use clients to connect to NebulaGraph. NebulaGraph supports a variety of clients. This topic will describe how to use Nebula Console to connect to NebulaGraph.</p> </li> <li> <p>CRUD in NebulaGraph</p> <p>Users can use nGQL (NebulaGraph Query Language) to run CRUD after connecting to NebulaGraph.</p> </li> </ol>"},{"location":"2.quick-start/2.install-nebula-graph/","title":"Step 1: Install NebulaGraph","text":"<p>RPM and DEB are common package formats on Linux systems. This topic shows how to quickly install NebulaGraph with the RPM or DEB package.</p>"},{"location":"2.quick-start/2.install-nebula-graph/#prerequisites","title":"Prerequisites","text":"<p>Prepare the right resources.</p> <p>Note</p> <p>The console is not complied or packaged with NebulaGraph server binaries. You can install nebula-console by yourself.</p> <p>Enterpriseonly</p> <p>For the Enterprise Edition, please send an email to inquiry@vesoft.com.</p>"},{"location":"2.quick-start/2.install-nebula-graph/#download_the_package_from_cloud_service","title":"Download the package from cloud service","text":"<ul> <li>Download the released version.<p>URL: </p> <pre><code>//Centos 6 \nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el6.x86_64.rpm\n\n//Centos 7\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el7.x86_64.rpm\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el8.x86_64.rpm\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1604.amd64.deb\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1804.amd64.deb\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu2004.amd64.deb\n</code></pre> <p>For example, download release package 2.6.2 for <code>Centos 7.5</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.rpm\nwget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.rpm.sha256sum.txt\n</code></pre> <p>download release package <code>2.6.2</code> for <code>Ubuntu 1804</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.ubuntu1804.amd64.deb\nwget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.ubuntu1804.amd64.deb.sha256sum.txt\n</code></pre> </li> </ul> <ul> <li> <p>Download the nightly version.</p> <p>Danger</p> <ul> <li>Nightly versions are usually used to test new features. Don't use it for production.</li> <li>Nightly versions may not be build successfully every night. And the names may change from day to day.</li> </ul> <p>URL: </p> <pre><code>//Centos 6 \nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el6.x86_64.rpm\n\n//Centos 7\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el7.x86_64.rpm\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el8.x86_64.rpm\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu1604.amd64.deb\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu1804.amd64.deb\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu2004.amd64.deb\n</code></pre> <p>For example, download the <code>Centos 7.5</code> package developed and built in <code>2021.03.28</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.el7.x86_64.rpm\nwget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.el7.x86_64.rpm.sha256sum.txt\n</code></pre> <p>For example, download the <code>Ubuntu 1804</code> package developed and built in <code>2021.03.28</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.ubuntu1804.amd64.deb\nwget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.ubuntu1804.amd64.deb.sha256sum.txt\n</code></pre> </li> </ul>"},{"location":"2.quick-start/2.install-nebula-graph/#install_nebulagraph","title":"Install NebulaGraph","text":"<ul> <li> <p>Use the following syntax to install with an RPM package.</p> <pre><code>$ sudo rpm -ivh --prefix=&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> <p>For example, to install an RPM package in the default path for the 2.6.2 version.</p> <pre><code>sudo rpm -ivh nebula-graph-2.6.2.el7.x86_64.rpm\n</code></pre> </li> </ul> <ul> <li> <p>Use the following syntax to install with a DEB package.</p> <pre><code>$ sudo dpkg -i --instdir==&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> <p>For example, to install a DEB package in the default path for the 2.6.2 version.</p> <pre><code>sudo dpkg -i nebula-graph-2.6.2.ubuntu1804.amd64.deb\n</code></pre> <p>Note</p> <p>The default installation path is <code>/usr/local/nebula/</code>.</p> </li> </ul>"},{"location":"2.quick-start/2.install-nebula-graph/#whats_next","title":"What's next","text":"<ul> <li>(Enterprise Edition)Deploy license</li> <li>start NebulaGraph </li> <li>connect to NebulaGraph</li> </ul>"},{"location":"2.quick-start/3.connect-to-nebula-graph/","title":"Step 3: Connect to NebulaGraph","text":"<p>NebulaGraph supports multiple types of clients, including a CLI client, a GUI client, and clients developed in popular programming languages. This topic provides an overview of NebulaGraph clients and basic instructions on how to use the native CLI client, Nebula Console.</p>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#nebulagraph_clients","title":"NebulaGraph clients","text":"<p>You can use supported clients or console to connect to NebulaGraph.</p>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#use_nebula_console_to_connect_to_nebulagraph","title":"Use Nebula Console to connect to NebulaGraph","text":""},{"location":"2.quick-start/3.connect-to-nebula-graph/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have started the NebulaGraph services. For how to start the services, see Start and Stop NebulaGraph.</li> <li>The machine you plan to run Nebula Console on has network access to the NebulaGraph services.</li> </ul>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#steps","title":"Steps","text":"<ol> <li> <p>On the nebula-console page, select a Nebula Console version and click Assets.</p> <p>Note</p> <p>We recommend that you select the latest release.</p> <p></p> </li> <li> <p>In the Assets area, find the correct binary file for the machine where you want to run Nebula Console and download the file to the machine.</p> <p></p> </li> <li> <p>(Optional) Rename the binary file to <code>nebula-console</code> for convenience.</p> <p>Note</p> <p>For Windows, rename the file to <code>nebula-console.exe</code>.</p> </li> <li> <p>On the machine to run Nebula Console, grant the execute permission of the nebula-console binary file to the user.</p> <p>Note</p> <p>For Windows, skip this step.</p> <pre><code>$ chmod 111 nebula-console\n</code></pre> </li> <li> <p>In the command line interface, change the working directory to the one where the nebula-console binary file is stored.</p> </li> <li> <p>Run the following command to connect to NebulaGraph.</p> <ul> <li>For Linux or macOS:</li> </ul> <pre><code>$ ./nebula-console -addr &lt;ip&gt; -port &lt;port&gt; -u &lt;username&gt; -p &lt;password&gt;\n[-t 120] [-e \"nGQL_statement\" | -f filename.nGQL]\n</code></pre> <ul> <li>For Windows:</li> </ul> <pre><code>&gt; nebula-console.exe -addr &lt;ip&gt; -port &lt;port&gt; -u &lt;username&gt; -p &lt;password&gt;\n[-t 120] [-e \"nGQL_statement\" | -f filename.nGQL]\n</code></pre> <p>The description of the parameters is as follows.</p> Option Description <code>-h</code> Shows the help menu. <code>-addr</code> Sets the IP address of the graphd service. The default address is 127.0.0.1. <code>-port</code> Sets the port number of the graphd service. The default port number is 9669. <code>-u/-user</code> Sets the username of your NebulaGraph account. Before enabling authentication, you can use any existing username. The default username is <code>root</code>. <code>-p/-password</code> Sets the password of your NebulaGraph account. Before enabling authentication, you can use any characters as the password. <code>-t/-timeout</code> Sets an integer-type timeout threshold of the connection. The unit is second. The default value is 120. <code>-e/-eval</code> Sets a string-type nGQL statement. The nGQL statement is executed once the connection succeeds. The connection stops after the result is returned. <code>-f/-file</code> Sets the path of an nGQL file. The nGQL statements in the file are executed once the connection succeeds. You'll get the return messages and the connection stops then. </li> </ol> <p>You can find more details in the Nebula Console Repository.</p>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#nebula_console_commands","title":"Nebula Console commands","text":"<p>Nebula Console can export CSV file, DOT file, and import too.</p> <p>Note</p> <p>The commands are case insensitive.</p>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#export_a_csv_file","title":"Export a CSV file","text":"<p>CSV files save the return result of a executed command.</p> <p>Note</p> <ul> <li>A CSV file will be saved in the working directory, i.e., what linux command <code>pwd</code> show;</li> </ul> <ul> <li>This command only works for the next query statement.</li> </ul> <p>The command to export a csv file.</p> <pre><code>nebula&gt; :CSV &lt;file_name.csv&gt;\n</code></pre>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#export_a_dot_file","title":"Export a DOT file","text":"<p>DOT files save the return result of a executed command, and the result information is different from CSV files.</p> <p>Note</p> <ul> <li>A DOT file will be saved in the working directory, i.e., what linux command <code>pwd</code> show;</li> </ul> <ul> <li>You can copy the contents of DOT file, and paste in GraphvizOnline, to visualize the excution plan;</li> </ul> <ul> <li>This command only works for the next query statement.</li> </ul> <p>The command to export a DOT file.</p> <pre><code>nebula&gt; :dot &lt;file_name.dot&gt;\n</code></pre> <p>For example,</p> <pre><code>nebula&gt; :dot a.dot\nnebula&gt; PROFILE FORMAT=\"dot\" GO FROM \"player100\" OVER follow;\n</code></pre>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#importing_a_testing_dataset","title":"Importing a testing dataset","text":"<p>The testing dataset is named <code>nba</code>. Details about schema and data can be seen by commands <code>SHOW</code>.</p> <p>Using the following command to import the testing dataset,</p> <pre><code>nebula&gt; :play nba\n</code></pre>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#run_a_command_multiple_times","title":"Run a command multiple times","text":"<p>Sometimes, you want to run a command multiple times. Run the following command.</p> <pre><code>nebula&gt; :repeat N\n</code></pre> <p>For example,</p> <pre><code>nebula&gt; :repeat 3\nnebula&gt; GO FROM \"player100\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 2602/3214 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 583/849 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 496/671 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\nExecuted 3 times, (total time spent 3681/4734 us), (average time spent 1227/1578 us)\n</code></pre>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#sleep_to_wait","title":"Sleep to wait","text":"<p>Sleep N seconds.</p> <p>It is usually used when altering schema. Since schema is altered in async way, and take effects in the next heartbeat cycle.</p> <pre><code>nebula&gt; :sleep N\n</code></pre>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#disconnect_nebula_console_from_nebulagraph","title":"Disconnect Nebula Console from NebulaGraph","text":"<p>You can use <code>:EXIT</code> or <code>:QUIT</code> to disconnect from NebulaGraph. For convenience, Nebula Console supports using these commands in lower case without the colon (\":\"), such as <code>quit</code>.</p> <pre><code>nebula&gt; :QUIT\n\nBye root!\n</code></pre>"},{"location":"2.quick-start/3.connect-to-nebula-graph/#faq","title":"FAQ","text":""},{"location":"2.quick-start/3.connect-to-nebula-graph/#how_can_i_install_nebula_console_from_the_source_code","title":"How can I install Nebula Console from the source code","text":"<p>To download and compile the latest source code of Nebula Console, follow the instructions on the nebula console GitHub page.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/","title":"Step 4: Use nGQL (CRUD)","text":"<p>This topic will describe the basic CRUD operations in NebulaGraph.</p> <p>For more information, see nGQL guide.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#graph_space_and_nebulagraph_schema","title":"Graph space and NebulaGraph schema","text":"<p>A NebulaGraph instance consists of one or more graph spaces. Graph spaces are physically isolated from each other. You can use different graph spaces in the same instance to store different datasets.</p> <p></p> <p>To insert data into a graph space, define a schema for the graph database. NebulaGraph schema is based on the following components.</p> Schema component Description Vertex Represents an entity in the real world. A vertex can have one or more tags. Tag The type of the same group of vertices. It defines a set of properties that describes the types of vertices. Edge Represents a directed relationship between two vertices. Edge type The type of an edge. It defines a group of properties that describes the types of edges. <p>For more information, see Data modeling.</p> <p>In this topic, we will use the following dataset to demonstrate basic CRUD operations.</p> <p></p>"},{"location":"2.quick-start/4.nebula-graph-crud/#check_the_machine_status_in_the_nebulagraph_cluster","title":"Check the machine status in the NebulaGraph cluster","text":"<p>Note</p> <p>First, we recommend that you check the machine status to make sure that all the Storage services are connected to the Meta services. Run <code>SHOW HOSTS</code> as follows.</p> <pre><code>nebula&gt; SHOW HOSTS;\n+-------------+-----------+-----------+--------------+----------------------+------------------------+\n| Host        | Port      | Status    | Leader count | Leader distribution  | Partition distribution |\n+-------------+-----------+-----------+--------------+----------------------+------------------------+\n| \"storaged0\" | 9779      | \"ONLINE\"  | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"storaged1\" | 9779      | \"ONLINE\"  | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"storaged2\" | 9779      | \"ONLINE\"  | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"Total\"     | __EMPTY__ | __EMPTY__ | 0            | __EMPTY__            | __EMPTY__              |\n+-------------+-----------+-----------+--------------+----------------------+------------------------+\n</code></pre> <p>From the Status column of the table in the return results, you can see that all the Storage services are online.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#asynchronous_implementation_of_creation_and_alteration","title":"Asynchronous implementation of creation and alteration","text":"<p>Caution</p> <p>In NebulaGraph, the following <code>CREATE</code> or <code>ALTER</code> commands are implemented in an async way and take effect in the next heartbeat cycle. Otherwise, an error will be returned. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds.</p> <ul> <li><code>CREATE SPACE</code></li> <li><code>CREATE TAG</code></li> <li><code>CREATE EDGE</code></li> <li><code>ALTER TAG</code></li> <li><code>ALTER EDGE</code></li> <li><code>CREATE TAG INDEX</code></li> <li><code>CREATE EDGE INDEX</code></li> </ul> <p>Note</p> <p>The default heartbeat interval is 10 seconds. To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> parameter in the configuration files for all services.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#create_and_use_a_graph_space","title":"Create and use a graph space","text":""},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax","title":"nGQL syntax","text":"<ul> <li>Create a graph space:<pre><code>CREATE SPACE [IF NOT EXISTS] &lt;graph_space_name&gt; (\n[partition_num = &lt;partition_number&gt;,]\n[replica_factor = &lt;replica_number&gt;,]\nvid_type = {FIXED_STRING(&lt;N&gt;) | INT64}\n)\n[COMMENT = '&lt;comment&gt;'];\n</code></pre> <p>For more information on parameters, see CREATE SPACE.</p> </li> </ul> <ul> <li>List graph spaces and check if the creation is successful:<pre><code>nebula&gt; SHOW SPACES;\n</code></pre> </li> </ul> <ul> <li>Use a graph space:<pre><code>USE &lt;graph_space_name&gt;;\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples","title":"Examples","text":"<ol> <li> <p>Use the following statement to create a graph space named <code>basketballplayer</code>.</p> <pre><code>nebula&gt; CREATE SPACE basketballplayer(partition_num=15, replica_factor=1, vid_type=fixed_string(30));\n</code></pre> </li> <li> <p>Check the partition distribution with <code>SHOW HOSTS</code> to make sure that the partitions are distributed in a balanced way.</p> <pre><code>nebula&gt; SHOW HOSTS;\n+-------------+-----------+-----------+--------------+----------------------------------+------------------------+\n| Host        | Port      | Status    | Leader count | Leader distribution              | Partition distribution |\n+-------------+-----------+-----------+--------------+----------------------------------+------------------------+\n| \"storaged0\" | 9779      | \"ONLINE\"  | 5            | \"basketballplayer:5\"             | \"basketballplayer:5\"   |\n| \"storaged1\" | 9779      | \"ONLINE\"  | 5            | \"basketballplayer:5\"             | \"basketballplayer:5\"   |\n| \"storaged2\" | 9779      | \"ONLINE\"  | 5            | \"basketballplayer:5\"             | \"basketballplayer:5\"   |\n| \"Total\"     |           |           | 15           | \"basketballplayer:15\"            | \"basketballplayer:15\"  |\n+-------------+-----------+-----------+--------------+----------------------------------+------------------------+\n</code></pre> <p>If the Leader distribution is uneven, use <code>BALANCE LEADER</code> to redistribute the partitions. For more information, see BALANCE.</p> </li> <li> <p>Use the <code>basketballplayer</code> graph space.</p> <pre><code>nebula[(none)]&gt; USE basketballplayer;\n</code></pre> <p>You can use <code>SHOW SPACES</code> to check the graph space you created.</p> <pre><code>nebula&gt; SHOW SPACES;\n+--------------------+\n| Name               |\n+--------------------+\n| \"basketballplayer\" |\n+--------------------+\n</code></pre> </li> </ol>"},{"location":"2.quick-start/4.nebula-graph-crud/#create_tags_and_edge_types","title":"Create tags and edge types","text":""},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax_1","title":"nGQL syntax","text":"<pre><code>CREATE {TAG | EDGE} {&lt;tag_name&gt; | &lt;edge_type&gt;}(&lt;property_name&gt; &lt;data_type&gt;\n[, &lt;property_name&gt; &lt;data_type&gt; ...])\n[COMMENT = '&lt;comment&gt;'];\n</code></pre> <p>For more information on parameters, see CREATE TAG and CREATE EDGE.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples_1","title":"Examples","text":"<p>Create tags <code>player</code> and <code>team</code>, edge types <code>follow</code> and <code>serve</code>. Descriptions are as follows.</p> Component name Type Property player Tag name (string), age (int) team Tag name (string) follow Edge type degree (int) serve Edge type start_year (int), end_year (int) <pre><code>nebula&gt; CREATE TAG player(name string, age int);\n\nnebula&gt; CREATE TAG team(name string);\n\nnebula&gt; CREATE EDGE follow(degree int);\n\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre>"},{"location":"2.quick-start/4.nebula-graph-crud/#insert_vertices_and_edges","title":"Insert vertices and edges","text":"<p>Users can use the <code>INSERT</code> statement to insert vertices or edges based on existing tags or edge types.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax_2","title":"nGQL syntax","text":"<ul> <li>Insert vertices:<pre><code>INSERT VERTEX [IF NOT EXISTS] &lt;tag_name&gt; (&lt;property_name&gt;[, &lt;property_name&gt;...])\n[, &lt;tag_name&gt; (&lt;property_name&gt;[, &lt;property_name&gt;...]), ...]\n{VALUES | VALUE} &lt;vid&gt;: (&lt;property_value&gt;[, &lt;property_value&gt;...])\n[, &lt;vid&gt;: (&lt;property_value&gt;[, &lt;property_value&gt;...];\n</code></pre> <p><code>VID</code> is short for Vertex ID. A <code>VID</code> must be a unique string value in a graph space. For details, see INSERT VERTEX.</p> </li> </ul> <ul> <li> <p>Insert edges:</p> <pre><code>INSERT EDGE [IF NOT EXISTS] &lt;edge_type&gt; (&lt;property_name&gt;[, &lt;property_name&gt;...])\n{VALUES | VALUE} &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] : (&lt;property_value&gt;[, &lt;property_value&gt;...])\n[, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] : (&lt;property_name&gt;[, &lt;property_name&gt;...]), ...];\n</code></pre> <p>For more information on parameters, see INSERT EDGE.</p> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples_2","title":"Examples","text":"<ul> <li>Insert vertices representing basketball players and teams:<pre><code>nebula&gt; INSERT VERTEX player(name, age) VALUES \"player100\":(\"Tim Duncan\", 42);\n\nnebula&gt; INSERT VERTEX player(name, age) VALUES \"player101\":(\"Tony Parker\", 36);\n\nnebula&gt; INSERT VERTEX player(name, age) VALUES \"player102\":(\"LaMarcus Aldridge\", 33);\n\nnebula&gt; INSERT VERTEX team(name) VALUES \"team203\":(\"Trail Blazers\"), \"team204\":(\"Spurs\");\n</code></pre> </li> </ul> <ul> <li>Insert edges representing the relations between basketball players and teams:<pre><code>nebula&gt; INSERT EDGE follow(degree) VALUES \"player101\" -&gt; \"player100\":(95);\n\nnebula&gt; INSERT EDGE follow(degree) VALUES \"player101\" -&gt; \"player102\":(90);\n\nnebula&gt; INSERT EDGE follow(degree) VALUES \"player102\" -&gt; \"player100\":(75);\n\nnebula&gt; INSERT EDGE serve(start_year, end_year) VALUES \"player101\" -&gt; \"team204\":(1999, 2018),\"player102\" -&gt; \"team203\":(2006,  2015);\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#read_data","title":"Read data","text":"<ul> <li>The GO statement can traverse the database based on specific conditions. A <code>GO</code> traversal starts from one or more vertices, along one or more edges, and returns information in a form specified in the <code>YIELD</code> clause.</li> </ul> <ul> <li>The FETCH statement is used to get properties from vertices or edges.</li> </ul> <ul> <li>The LOOKUP statement is based on indexes. It is used together with the <code>WHERE</code> clause to search for the data that meet the specific conditions.</li> </ul> <ul> <li>The MATCH statement is the most commonly used statement for graph data querying. It can describe all kinds of graph patterns, but it relies on indexes to match data patterns in NebulaGraph. Therefore, its performance still needs optimization.</li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax_3","title":"nGQL syntax","text":"<ul> <li><code>GO</code><pre><code>GO [[&lt;M&gt; TO] &lt;N&gt; STEPS ] FROM &lt;vertex_list&gt;\nOVER &lt;edge_type_list&gt; [{REVERSELY | BIDIRECT}]\n[ WHERE &lt;conditions&gt;\u00a0]\n[YIELD\u00a0[DISTINCT] &lt;return_list&gt;]\n[{SAMPLE &lt;sample_list&gt; | LIMIT &lt;limit_list&gt;}]\n[| GROUP BY {col_name | expr | position} YIELD &lt;col_name&gt;]\n[| ORDER BY &lt;expression&gt; [{ASC | DESC}]]\n[| LIMIT [&lt;offset&gt;,] &lt;number_rows&gt;];\n</code></pre> </li> </ul> <ul> <li> <p><code>FETCH</code></p> <ul> <li> <p>Fetch properties on tags:</p> <pre><code>FETCH PROP ON {&lt;tag_name&gt;[, tag_name ...] | *}\n&lt;vid&gt; [, vid ...]\n[YIELD &lt;return_list&gt; [AS &lt;alias&gt;]];\n</code></pre> </li> </ul> <ul> <li> <p>Fetch properties on edges:</p> <pre><code>FETCH PROP ON &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] [, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt; ...]\n[YIELD &lt;output&gt;];\n</code></pre> </li> </ul> </li> </ul> <ul> <li><code>LOOKUP</code><pre><code>LOOKUP ON {&lt;vertex_tag&gt; | &lt;edge_type&gt;}\n[WHERE &lt;expression&gt; [AND &lt;expression&gt; ...]]\n[YIELD &lt;return_list&gt; [AS &lt;alias&gt;]];\n</code></pre> </li> </ul> <ul> <li><code>MATCH</code><pre><code>MATCH &lt;pattern&gt; [&lt;WHERE clause&gt;] RETURN &lt;output&gt;;\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples_of_go_statement","title":"Examples of <code>GO</code> statement","text":"<ul> <li>Search for the players that the player with VID <code>player101</code> follows.<pre><code>nebula&gt; GO FROM \"player101\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player100\" |\n| \"player102\" |\n+-------------+\n</code></pre> </li> </ul> <ul> <li>Filter the players that the player with VID <code>player101</code> follows whose age is equal to or greater than 35. Rename the corresponding columns in the results with <code>Teammate</code> and <code>Age</code>.<pre><code>nebula&gt; GO FROM \"player101\" OVER follow WHERE $$.player.age &gt;= 35 \\\n        YIELD properties($$).name AS Teammate, properties($$).age AS Age;\n+--------------+-----+\n| Teammate     | Age |\n+--------------+-----+\n| \"Tim Duncan\" | 42  |\n+--------------+-----+\n</code></pre> <p>| Clause/Sign | Description                                                         |   |-------------+---------------------------------------------------------------------|   | <code>YIELD</code>     | Specifies what values or results you want to return from the query. |   | <code>$$</code>        | Represents the target vertices.                                     |   | <code>\\</code>         | A line-breaker.                                                     |</p> </li> </ul> <ul> <li> <p>Search for the players that the player with VID <code>player101</code> follows. Then Retrieve the teams of the players that the player with VID <code>player100</code> follows. To combine the two queries, use a pipe or a temporary variable.</p> <ul> <li> <p>With a pipe:</p> <pre><code>nebula&gt; GO FROM \"player101\" OVER follow YIELD dst(edge) AS id | \\\n        GO FROM $-.id OVER serve YIELD properties($$).name AS Team, \\\n        properties($^).name AS Player;\n+-----------------+---------------------+\n| Team            | Player              |\n+-----------------+---------------------+\n| \"Trail Blazers\" | \"LaMarcus Aldridge\" |\n+-----------------+---------------------+\n</code></pre> Clause/Sign Description <code>$^</code> Represents the source vertex of the edge. <code>|</code> A pipe symbol can combine multiple queries. <code>$-</code> Represents the outputs of the query before the pipe symbol. </li> </ul> <ul> <li> <p>With a temporary variable:</p> <p>Note</p> <p>Once a composite statement is submitted to the server as a whole, the life cycle of the temporary variables in the statement ends.</p> <pre><code>nebula&gt; $var = GO FROM \"player101\" OVER follow YIELD dst(edge) AS id; \\\n        GO FROM $var.id OVER serve YIELD properties($$).name AS Team, \\\n        properties($^).name AS Player;\n+-----------------+---------------------+\n| Team            | Player              |\n+-----------------+---------------------+\n| \"Trail Blazers\" | \"LaMarcus Aldridge\" |\n+-----------------+---------------------+\n</code></pre> </li> </ul> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#example_of_fetch_statement","title":"Example of <code>FETCH</code> statement","text":"<p>Use <code>FETCH</code>: Fetch the properties of the player with VID <code>player100</code>.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player100\";\n+----------------------------------------------------+\n| vertices_                                          |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n</code></pre> <p>Note</p> <p>The examples of <code>LOOKUP</code> and <code>MATCH</code> statements are in indexes.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#update_vertices_and_edges","title":"Update vertices and edges","text":"<p>Users can use the <code>UPDATE</code> or the <code>UPSERT</code> statements to update existing data.</p> <p><code>UPSERT</code> is the combination of <code>UPDATE</code> and <code>INSERT</code>. If you update a vertex or an edge with <code>UPSERT</code>, the database will insert a new vertex or edge if it does not exist.</p> <p>Note</p> <p><code>UPSERT</code> operates serially in a partition-based order. Therefore, it is slower than <code>INSERT</code> OR <code>UPDATE</code>. And <code>UPSERT</code> has concurrency only between multiple partitions.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax_4","title":"nGQL syntax","text":"<ul> <li><code>UPDATE</code> vertices:<pre><code>UPDATE VERTEX &lt;vid&gt; SET &lt;properties to be updated&gt;\n[WHEN &lt;condition&gt;] [YIELD &lt;columns&gt;];\n</code></pre> </li> </ul> <ul> <li><code>UPDATE</code> edges:<pre><code>UPDATE EDGE &lt;source vid&gt; -&gt; &lt;destination vid&gt; [@rank] OF &lt;edge_type&gt;\nSET &lt;properties to be updated&gt; [WHEN &lt;condition&gt;] [YIELD &lt;columns to be output&gt;];\n</code></pre> </li> </ul> <ul> <li><code>UPSERT</code> vertices or edges:<pre><code>UPSERT {VERTEX &lt;vid&gt; | EDGE &lt;edge_type&gt;} SET &lt;update_columns&gt;\n[WHEN &lt;condition&gt;] [YIELD &lt;columns&gt;];\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples_3","title":"Examples","text":"<ul> <li><code>UPDATE</code> the <code>name</code> property of the vertex with VID <code>player100</code> and check the result with the <code>FETCH</code> statement.<pre><code>nebula&gt; UPDATE VERTEX \"player100\" SET player.name = \"Tim\";\n\nnebula&gt; FETCH PROP ON player \"player100\";\n+---------------------------------------------+\n| vertices_                                   |\n+---------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim\"}) |\n+---------------------------------------------+\n</code></pre> </li> </ul> <ul> <li><code>UPDATE</code> the <code>degree</code> property of an edge and check the result with the <code>FETCH</code> statement.<pre><code>nebula&gt; UPDATE EDGE \"player101\" -&gt; \"player100\" OF follow SET degree = 96;\n\nnebula&gt; FETCH PROP ON follow \"player101\" -&gt; \"player100\";\n+----------------------------------------------------+\n| edges_                                             |\n+----------------------------------------------------+\n| [:follow \"player101\"-&gt;\"player100\" @0 {degree: 96}] |\n+----------------------------------------------------+\n</code></pre> </li> </ul> <ul> <li>Insert a vertex with VID <code>player111</code> and <code>UPSERT</code> it.<pre><code>nebula&gt; INSERT VERTEX player(name,age) values \"player111\":(\"David West\", 38);\n\nnebula&gt; UPSERT VERTEX \"player111\" SET player.name = \"David\", player.age = $^.player.age + 11 \\\n        WHEN $^.player.name == \"David West\" AND $^.player.age &gt; 20 \\\n        YIELD $^.player.name AS Name, $^.player.age AS Age;\n+---------+-----+\n| Name    | Age |\n+---------+-----+\n| \"David\" | 49  |\n+---------+-----+\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#delete_vertices_and_edges","title":"Delete vertices and edges","text":""},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax_5","title":"nGQL syntax","text":"<ul> <li>Delete vertices:<pre><code>DELETE VERTEX &lt;vid1&gt;[, &lt;vid2&gt;...]\n</code></pre> </li> </ul> <ul> <li>Delete edges:<pre><code>DELETE EDGE &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;]\n[, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;...]\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples_4","title":"Examples","text":"<ul> <li>Delete vertices:<pre><code>nebula&gt; DELETE VERTEX \"player111\", \"team203\";\n</code></pre> </li> </ul> <ul> <li>Delete edges:<pre><code>nebula&gt; DELETE EDGE follow \"player101\" -&gt; \"team204\";\n</code></pre> </li> </ul>"},{"location":"2.quick-start/4.nebula-graph-crud/#about_indexes","title":"About indexes","text":"<p>Users can add indexes to tags and edge types with the CREATE INDEX statement.</p> <p>Must-read for using indexes</p> <p>Both <code>MATCH</code> and <code>LOOKUP</code> statements depend on the indexes. But indexes can dramatically reduce the write performance (as much as 90% or even more). DO NOT use indexes in production environments unless you are fully aware of their influences on your service.</p> <p>Users MUST rebuild indexes for pre-existing data. Otherwise, the pre-existing data cannot be indexed and therefore cannot be returned in <code>MATCH</code> or <code>LOOKUP</code> statements. For more information, see REBUILD INDEX.</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#ngql_syntax_6","title":"nGQL syntax","text":"<ul> <li>Create an index:<pre><code>CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] &lt;index_name&gt;\nON {&lt;tag_name&gt; | &lt;edge_name&gt;} ([&lt;prop_name_list&gt;]) [COMMENT = '&lt;comment&gt;'];\n</code></pre> </li> </ul> <ul> <li>Rebuild an index:<pre><code>REBUILD {TAG | EDGE} INDEX &lt;index_name&gt;;\n</code></pre> </li> </ul> <p>Note</p> <p>Define the index length when creating an index for a variable-length property. In UTF-8 encoding, a non-ascii character occupies 3 bytes. You should set an appropriate index length according to the variable-length property. For example, the index should be 30 bytes for 10 non-ascii characters. For more information, see CREATE INDEX</p>"},{"location":"2.quick-start/4.nebula-graph-crud/#examples_of_lookup_and_match_index-based","title":"Examples of <code>LOOKUP</code> and <code>MATCH</code> (index-based)","text":"<p>Make sure there is an index for <code>LOOKUP</code> or <code>MATCH</code> to use. If there is not, create an index first.</p> <p>Find the information of the vertex with the tag <code>player</code> and its value of the <code>name</code> property is <code>Tony Parker</code>.</p> <p>This example creates the index <code>player_index_1</code> on the player name property.</p> <pre><code>nebula&gt; CREATE TAG INDEX player_index_1 ON player(name(20));\n</code></pre> <p>This example rebuilds the index to make sure it takes effect on pre-existing data.</p> <pre><code>nebula&gt; REBUILD TAG INDEX player_index_1\n+------------+\n| New Job Id |\n+------------+\n| 31         |\n+------------+\nGot 1 rows (time spent 2379/3033 us)\n</code></pre> <p>This example uses the <code>LOOKUP</code> statement to retrieve the vertex property.</p> <pre><code>nebula&gt; LOOKUP ON player WHERE player.name == \"Tony Parker\" \\\n        YIELD properties(vertex).name AS name, properties(vertex).age AS age;\n+-------------+---------------+-----+\n| VertexID    | name          | age |\n+-------------+---------------+-----+\n| \"player101\" | \"Tony Parker\" | 36  |\n+-------------+---------------+-----+\n</code></pre> <p>This example uses the <code>MATCH</code> statement to retrieve the vertex property.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tony Parker\"}) RETURN v;\n+-----------------------------------------------------+\n| v                                                   |\n+-----------------------------------------------------+\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"}) |\n+-----------------------------------------------------+\n</code></pre>"},{"location":"2.quick-start/5.start-stop-service/","title":"Step 2: Manage NebulaGraph Service","text":"<p>You can use the <code>nebula.service</code> script to start, stop, restart, terminate, and check the NebulaGraph services. This topic takes starting, stopping and checking the NebulaGraph services for examples.</p> <p><code>nebula.service</code> is stored in the <code>/usr/local/nebula/</code> directory by default, which is also the default installation path of NebulaGraph. If you have customized the path, use the actual path in your environment.</p>"},{"location":"2.quick-start/5.start-stop-service/#syntax","title":"Syntax","text":"<pre><code>$ sudo /usr/local/nebula/scripts/nebula.service [-v] [-c &lt;config_file_path&gt;]\n&lt;start|stop|restart|status|kill&gt;\n&lt;metad|graphd|storaged|all&gt;\n</code></pre> Parameter Description <code>-v</code> Display detailed debugging information. <code>-c</code> Specify the configuration file path. The default path is <code>/usr/local/nebula/etc/</code>. <code>start</code> Start the target services. <code>stop</code> Stop the target services. <code>restart</code> Restart the target services. <code>kill</code> Terminate the target services. <code>status</code> Check the status of the target services. <code>metad</code> Set the Meta Service as the target service. <code>graphd</code> Set the Graph Service as the target service. <code>storaged</code> Set the Storage Service as the target service. <code>all</code> Set all the NebulaGraph services as the target services."},{"location":"2.quick-start/5.start-stop-service/#start_nebulagraph","title":"Start NebulaGraph","text":""},{"location":"2.quick-start/5.start-stop-service/#in_non-container_environment","title":"In non-container environment","text":"<p>Run the following command to start NebulaGraph.</p> <pre><code>$ sudo /usr/local/nebula/scripts/nebula.service start all\n[INFO] Starting nebula-metad...\n[INFO] Done\n[INFO] Starting nebula-graphd...\n[INFO] Done\n[INFO] Starting nebula-storaged...\n[INFO] Done\n</code></pre>"},{"location":"2.quick-start/5.start-stop-service/#in_docker_container_deployed_with_docker-compose","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to start NebulaGraph.</p> <pre><code>nebula-docker-compose]$ docker-compose up -d\nBuilding with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/\nCreating network \"nebula-docker-compose_nebula-net\" with the default driver\nCreating nebula-docker-compose_metad0_1 ... done\nCreating nebula-docker-compose_metad2_1 ... done\nCreating nebula-docker-compose_metad1_1 ... done\nCreating nebula-docker-compose_storaged2_1 ... done\nCreating nebula-docker-compose_graphd1_1   ... done\nCreating nebula-docker-compose_storaged1_1 ... done\nCreating nebula-docker-compose_storaged0_1 ... done\nCreating nebula-docker-compose_graphd2_1   ... done\nCreating nebula-docker-compose_graphd_1    ... done\n</code></pre>"},{"location":"2.quick-start/5.start-stop-service/#stop_nebulagraph","title":"Stop NebulaGraph","text":"<p>Danger</p> <p>Don't run <code>kill -9</code> to forcibly terminate the processes, otherwise, there is a low probability of data loss.</p>"},{"location":"2.quick-start/5.start-stop-service/#in_non-container_environment_1","title":"In non-container environment","text":"<p>Run the following command to stop NebulaGraph.</p> <pre><code>sudo /usr/local/nebula/scripts/nebula.service stop all\n[INFO] Stopping nebula-metad...\n[INFO] Done\n[INFO] Stopping nebula-graphd...\n[INFO] Done\n[INFO] Stopping nebula-storaged...\n[INFO] Done\n</code></pre>"},{"location":"2.quick-start/5.start-stop-service/#in_docker_container_deployed_with_docker-compose_1","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to stop NebulaGraph.</p> <pre><code>nebula-docker-compose]$ docker-compose down\nStopping nebula-docker-compose_graphd_1    ... done\nStopping nebula-docker-compose_graphd2_1   ... done\nStopping nebula-docker-compose_storaged0_1 ... done\nStopping nebula-docker-compose_storaged1_1 ... done\nStopping nebula-docker-compose_graphd1_1   ... done\nStopping nebula-docker-compose_storaged2_1 ... done\nStopping nebula-docker-compose_metad1_1    ... done\nStopping nebula-docker-compose_metad2_1    ... done\nStopping nebula-docker-compose_metad0_1    ... done\nRemoving nebula-docker-compose_graphd_1    ... done\nRemoving nebula-docker-compose_graphd2_1   ... done\nRemoving nebula-docker-compose_storaged0_1 ... done\nRemoving nebula-docker-compose_storaged1_1 ... done\nRemoving nebula-docker-compose_graphd1_1   ... done\nRemoving nebula-docker-compose_storaged2_1 ... done\nRemoving nebula-docker-compose_metad1_1    ... done\nRemoving nebula-docker-compose_metad2_1    ... done\nRemoving nebula-docker-compose_metad0_1    ... done\nRemoving network nebula-docker-compose_nebula-net\n</code></pre> <p>If you are using a development or nightly version for testing and have compatibility issues, try to run <code>docker-compose down -v</code> to DELETE all data stored in NebulaGraph and import data again.</p>"},{"location":"2.quick-start/5.start-stop-service/#check_the_service_status","title":"Check the service status","text":""},{"location":"2.quick-start/5.start-stop-service/#in_non-container_environment_2","title":"In non-container environment","text":"<p>Run the following command to check the service status of NebulaGraph.</p> <pre><code>$ sudo /usr/local/nebula/scripts/nebula.service status all\n</code></pre> <ul> <li>NebulaGraph is running normally if the following information is returned.</li> </ul> <pre><code>[INFO] nebula-metad(3ba41bd): Running as 26601, Listening on 9559\n[INFO] nebula-graphd(3ba41bd): Running as 26644, Listening on 9669\n[INFO] nebula-storaged(3ba41bd): Running as 26709, Listening on 9779\n</code></pre> <ul> <li>If the return information is similar to the following one, there is a problem.</li> </ul> <pre><code>[INFO] nebula-metad(de03025): Running as 25600, Listening on 9559\n[INFO] nebula-graphd(de03025): Exited\n[INFO] nebula-storaged(de03025): Running as 25646, Listening on 9779\n</code></pre> <p>The NebulaGraph services consist of the Meta Service, Graph Service, and Storage Service. The configuration files for all three services are stored in the <code>/usr/local/nebula/etc/</code> directory by default. You can check the configuration files according to the return information to troubleshoot problems.</p> <p>You may also go to the NebulaGraph community for help.</p>"},{"location":"2.quick-start/5.start-stop-service/#in_docker_container_deployed_with_docker-compose_2","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to check the service status of NebulaGraph.</p> <pre><code>[nebula-docker-compose]$ docker-compose ps\nCONTAINER ID   IMAGE                               COMMAND                  CREATED          STATUS                    PORTS                                                                                                  NAMES\n2a6c56c405f5   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:49230-&gt;9669/tcp, 0.0.0.0:49229-&gt;19669/tcp, 0.0.0.0:49228-&gt;19670/tcp                            nebula-docker-compose_graphd2_1\n7042e0a8e83d   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49227-&gt;9779/tcp, 0.0.0.0:49226-&gt;19779/tcp, 0.0.0.0:49225-&gt;19780/tcp   nebula-docker-compose_storaged2_1\n18e3ea63ad65   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49219-&gt;9779/tcp, 0.0.0.0:49218-&gt;19779/tcp, 0.0.0.0:49217-&gt;19780/tcp   nebula-docker-compose_storaged0_1\n4dcabfe8677a   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:49224-&gt;9669/tcp, 0.0.0.0:49223-&gt;19669/tcp, 0.0.0.0:49222-&gt;19670/tcp                            nebula-docker-compose_graphd1_1\na74054c6ae25   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:9669-&gt;9669/tcp, 0.0.0.0:49221-&gt;19669/tcp, 0.0.0.0:49220-&gt;19670/tcp                             nebula-docker-compose_graphd_1\n880025a3858c   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49216-&gt;9779/tcp, 0.0.0.0:49215-&gt;19779/tcp, 0.0.0.0:49214-&gt;19780/tcp   nebula-docker-compose_storaged1_1\n45736a32a23a   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49213-&gt;9559/tcp, 0.0.0.0:49212-&gt;19559/tcp, 0.0.0.0:49211-&gt;19560/tcp                  nebula-docker-compose_metad0_1\n3b2c90eb073e   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49207-&gt;9559/tcp, 0.0.0.0:49206-&gt;19559/tcp, 0.0.0.0:49205-&gt;19560/tcp                  nebula-docker-compose_metad2_1\n7bb31b7a5b3f   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49210-&gt;9559/tcp, 0.0.0.0:49209-&gt;19559/tcp, 0.0.0.0:49208-&gt;19560/tcp                  nebula-docker-compose_metad1_1\n</code></pre> <p>Use the <code>CONTAINER ID</code> to log in the container and troubleshoot.</p> <pre><code>nebula-docker-compose]$ docker exec -it 2a6c56c405f5 bash\n[root@2a6c56c405f5 nebula]#\n</code></pre>"},{"location":"2.quick-start/5.start-stop-service/#whats_next","title":"What's next","text":"<p>Connect to NebulaGraph</p>"},{"location":"2.quick-start/6.cheatsheet-for-ngql/","title":"nGQL cheatsheet","text":""},{"location":"2.quick-start/6.cheatsheet-for-ngql/#functions","title":"Functions","text":"<ul> <li> <p>Math functions</p> Function Description double abs(double x) Returns the absolute value of the argument. double floor(double x) Returns the largest integer value smaller than or equal to the argument. (Rounds down) double ceil(double x) Returns the smallest integer greater than or equal to the argument. (Rounds up) double round(double x) Returns the integer value nearest to the argument. Returns a number farther away from 0 if the argument is in the middle. double sqrt(double x) Returns the square root of the argument. double cbrt(double x) sReturns the cubic root of the argument. double hypot(double x, double y) Returns the hypotenuse of a right-angled triangle. double pow(double x, double y) Returns the result of \\(x^y\\). double exp(double x) Returns the result of \\(e^x\\). double exp2(double x) Returns the result of \\(2^x\\). double log(double x) Returns the base-e logarithm of the argument. double log2(double x) Returns the base-2 logarithm of the argument. double log10(double x) Returns the base-10 logarithm of the argument. double sin(double x) Returns the sine of the argument. double asin(double x) Returns the inverse sine of the argument. double cos(double x) Returns the cosine of the argument. double acos(double x) Returns the inverse cosine of the argument. double tan(double x) Returns the tangent of the argument. double atan(double x) Returns the inverse tangent of the argument. double rand() Returns a random floating point number in the range from 0 (inclusive) to 1 (exclusive); i.e.[0,1). int rand32(int min, int max) Returns a random 32-bit integer in <code>[min, max)</code>.If you set only one argument, it is parsed as <code>max</code> and <code>min</code> is <code>0</code> by default.If you set no argument, the system returns a random signed 32-bit integer. int rand64(int min, int max) Returns a random 64-bit integer in <code>[min, max)</code>.If you set only one argument, it is parsed as <code>max</code> and <code>min</code> is <code>0</code> by default.If you set no argument, the system returns a random signed 64-bit integer. collect() Puts all the collected values into a list. avg() Returns the average value of the argument. count() Returns the number of records. max() Returns the maximum value. min() Returns the minimum value. std() Returns the population standard deviation. sum() Returns the sum value. bit_and() Bitwise AND. bit_or() Bitwise OR. bit_xor() Bitwise XOR. int size() Returns the number of elements in a list or a map. int range(int start, int end, int step) Returns a list of integers from <code>[start,end]</code> in the specified steps. <code>step</code> is 1 by default. int sign(double x) Returns the signum of the given number.If the number is 0, the system returns 0.If the number is negative, the system returns -1.If the number is positive, the system returns 1. double e() Returns the base of the natural logarithm, e (2.718281828459045). double pi() Returns the mathematical constant pi (3.141592653589793). double radians() Converts degrees to radians. <code>radians(180)</code> returns <code>3.141592653589793</code>. </li> </ul> <ul> <li> <p>String functions</p> Function Description int strcasecmp(string a, string b) Compares string a and b without case sensitivity. When a = b, the return value is 0. When a &gt; b, the return value is greater than 0. When a &lt; b, the return value is less than 0. string lower(string a) Returns the argument in lowercase. string toLower(string a) The same as <code>lower()</code>. string upper(string a) Returns the argument in uppercase. string toUpper(string a) The same as <code>upper()</code>. int length(string a) Returns the length of the given string in bytes. string trim(string a) Removes leading and trailing spaces. string ltrim(string a) Removes leading spaces. string rtrim(string a) Removes trailing spaces. string left(string a, int count) Returns a substring consisting of <code>count</code> characters from the left side of string a. If string a is shorter than <code>count</code>, the system returns string a. string right(string a, int count) Returns a substring consisting of <code>count</code> characters from the right side of string a. If string a is shorter than <code>count</code>, the system returns string a. string lpad(string a, int size, string letters) Left-pads string a with string <code>letters</code> and returns a substring with the length of <code>size</code>. string rpad(string a, int size, string letters) Right-pads string a with string <code>letters</code> and returns a substring with the length of <code>size</code>. string substr(string a, int pos, int count) Returns a substring extracting <code>count</code> characters starting from the specified position <code>pos</code> of string a. string substring(string a, int pos, int count) The same as <code>substr()</code>. string reverse(string) Returns a string in reverse order. string replace(string a, string b, string c) Replaces string b in string a with string c. list split(string a, string b) Splits string a at string b and returns a list of strings. string toString() Takes in any data type and converts it into a string. int hash() Takes in any data type and encodes it into a hash value. </li> </ul> <ul> <li> <p>Data and time functions</p> Function Description int now() Returns the current date and time of the system time zone. timestamp timestamp() Returns the current date and time of the system time zone. date date() Returns the current UTC date based on the current system. time time() Returns the current UTC time based on the current system. datetime datetime() Returns the current UTC date and time based on the current system. </li> </ul> <ul> <li> <p>Schema functions</p> Function Description id(vertex) Returns the ID of a vertex. The data type of the result is the same as the vertex ID. map properties(vertex) Returns the properties of a vertex. map properties(edge) Returns the properties of an edge. string type(edge) Returns the edge type of an edge. src(edge) Returns the source vertex ID of an edge. The data type of the result is the same as the vertex ID. dst(edge) Returns the destination vertex ID of an edge. The data type of the result is the same as the vertex ID. int rank(edge) Returns the rank value of an edge. </li> </ul> <ul> <li> <p>List functions</p> Function Description keys(expr) Returns a list containing the string representations for all the property names of vertices, edges, or maps. labels(vertex) Returns the list containing all the tags of a vertex. nodes(path) Returns the list containing all the vertices in a path. range(start, end [, step]) Returns the list containing all the fixed-length steps in <code>[start,end]</code>. <code>step</code> is 1 by default. relationships(path) Returns the list containing all the relationships in a path. reverse(list) Returns the list reversing the order of all elements in the original list. tail(list) Returns all the elements of the original list, excluding the first one. head(list) Returns the first element of a list. last(list) Returns the last element of a list. coalesce(list) Returns the first not null value in a list. reduce() See reduce() function\u3002 </li> </ul> <ul> <li> <p>count() function</p> Function Description count() Syntax: <code>count({expr | *})</code> .<code>count()</code>returns the number of rows (including NULL). <code>count(expr)</code>returns the number of non-NULL values that meet the expression. count() and size() are different. </li> </ul> <ul> <li> <p>collect() function</p> Function Description collect() The collect() function returns a list containing the values returned by an expression. Using this function aggregates data by merging multiple records or values into a single list. </li> </ul> <ul> <li> <p>reduce() function</p> Function Syntax Description reduce() <code>reduce(&lt;accumulator&gt; = &lt;initial&gt;, &lt;variable&gt; IN &lt;list&gt; | &lt;expression&gt;)</code> The <code>reduce()</code> function applies an expression to each element in a list one by one, chains the result to the next iteration by taking it as the initial value, and returns the final result. </li> </ul> <ul> <li> <p>hash() function</p> Function Description hash() The <code>hash()</code> function returns the hash value of the argument. The argument can be a number, a string, a list, a boolean, null, or an expression that evaluates to a value of the preceding data types. The source code of the <code>hash()</code> function (MurmurHash2), seed (<code>0xc70f6907UL</code>), and other parameters can be found in <code>MurmurHash2.h</code>. </li> </ul> <ul> <li> <p>concat() function</p> Function Description concat() The <code>concat()</code> function requires at least two or more strings. All the parameters are concatenated into one string.Syntax: <code>concat(string1,string2,...)</code> </li> </ul> <ul> <li> <p>concat_ws() function</p> Function Description concat_ws() The <code>concat_ws()</code> function connects two or more strings with a predefined separator. </li> </ul> <ul> <li> <p>Predicate functions</p> <p>Predicate functions return <code>true</code> or <code>false</code>. They are most commonly used in <code>WHERE</code> clauses.</p> <pre><code>&lt;predicate&gt;(&lt;variable&gt; IN &lt;list&gt; WHERE &lt;condition&gt;)\n</code></pre> Functions Description exists() Returns <code>true</code> if the specified property exists in the vertex, edge or map. Otherwise, returns <code>false</code>. any() Returns <code>true</code> if the specified predicate holds for at least one element in the given list. Otherwise, returns <code>false</code>. all() Returns <code>true</code> if the specified predicate holds for all elements in the given list. Otherwise, returns <code>false</code>. none() Returns <code>true</code> if the specified predicate holds for no element in the given list. Otherwise, returns <code>false</code>. single() Returns <code>true</code> if the specified predicate holds for exactly one of the elements in the given list. Otherwise, returns <code>false</code>. </li> </ul> <ul> <li> <p>CASE expressions</p> <p>The <code>CASE</code> expression uses conditions to filter the result of an nGQL query statement. It is usually used in the <code>YIELD</code> and <code>RETURN</code> clauses. The <code>CASE</code> expression will traverse all the conditions. When the first condition is met, the <code>CASE</code> expression stops reading the conditions and returns the result. If no conditions are met, it returns the result in the <code>ELSE</code> clause. If there is no <code>ELSE</code> clause and no conditions are met, it returns <code>NULL</code>.</p> <p>Syntax:</p> <pre><code>CASE &lt;comparer&gt;\nWHEN &lt;value&gt; THEN &lt;result&gt;\n[WHEN ...]\n[ELSE &lt;default&gt;]\nEND\n</code></pre> </li> </ul> Parameter Description <code>comparer</code> A value or a valid expression that outputs a value. This value is used to compare with the <code>value</code>. <code>value</code> It will be compared with the <code>comparer</code>. If the <code>value</code> matches the <code>comparer</code>, then this condition is met. <code>result</code> The <code>result</code> is returned by the <code>CASE</code> expression if the <code>value</code> matches the <code>comparer</code>. <code>default</code> The <code>default</code> is returned by the <code>CASE</code> expression if no conditions are met."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#general_queries_statements","title":"General queries statements","text":"<ul> <li> <p>MATCH</p> <pre><code>MATCH &lt;pattern&gt; [&lt;WHERE clause&gt;] RETURN &lt;output&gt;\n</code></pre> Pattern Example Description Match vertices <code>(v)</code> You can use a user-defined variable in a pair of parentheses to represent a vertex in a pattern. For example: <code>(v)</code>. Match tags <code>MATCH (v:player) RETURN v</code> You can specify a tag with <code>:&lt;tag_name&gt;</code> after the vertex in a pattern. Match vertex properties <code>MATCH (v:player{name:\"Tim Duncan\"}) RETURN v</code> You can specify a vertex property with <code>{&lt;prop_name&gt;: &lt;prop_value&gt;}</code> after the tag in a pattern. Match a VID. <code>MATCH (v) WHERE id(v) == 'player101' RETURN v</code> You can use the VID to match a vertex. The <code>id()</code> function can retrieve the VID of a vertex. Match multiple VIDs. <code>MATCH (v:player { name: 'Tim Duncan' })--(v2) WHERE id(v2) IN [\"player101\", \"player102\"] RETURN v2</code> To match multiple VIDs, use <code>WHERE id(v) IN [vid_list]</code>. Match connected vertices <code>MATCH (v:player{name:\"Tim Duncan\"})--(v2) RETURN v2.name AS Name</code> You can use the <code>--</code> symbol to represent edges of both directions and match vertices connected by these edges. You can add a <code>&gt;</code> or <code>&lt;</code> to the <code>--</code> symbol to specify the direction of an edge. Match paths <code>MATCH p=(v:player{name:\"Tim Duncan\"})--&gt;(v2) RETURN p</code> Connected vertices and edges form a path. You can use a user-defined variable to name a path as follows. Match edges <code>MATCH (v:player{name:\"Tim Duncan\"})-[e]-(v2) RETURN e</code> Besides using <code>--</code>, <code>--&gt;</code>, or <code>&lt;--</code> to indicate a nameless edge, you can use a user-defined variable in a pair of square brackets to represent a named edge. For example: <code>-[e]-</code>. Match an edge type <code>MATCH ()-[e:follow]-() RETURN e</code> Just like vertices, you can specify an edge type with <code>:&lt;edge_type&gt;</code> in a pattern. For example: <code>-[e:follow]-</code>. Match edge type properties <code>MATCH (v:player{name:\"Tim Duncan\"})-[e:follow{degree:95}]-&gt;(v2) RETURN e</code> You can specify edge type properties with <code>{&lt;prop_name&gt;: &lt;prop_value&gt;}</code> in a pattern. For example: <code>[e:follow{likeness:95}]</code>. Match multiple edge types <code>MATCH (v:player{name:\"Tim Duncan\"})-[e:follow | :serve]-&gt;(v2) RETURN e</code> The <code>|</code> symbol can help matching multiple edge types. For example: <code>[e:follow|:serve]</code>. The English colon (:) before the first edge type cannot be omitted, but the English colon before the subsequent edge type can be omitted, such as <code>[e:follow|serve]</code>. Match multiple edges <code>MATCH (v:player{name:\"Tim Duncan\"})-[]-&gt;(v2)&lt;-[e:serve]-(v3) RETURN v2, v3</code> You can extend a pattern to match multiple edges in a path. Match fixed-length paths <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*2]-&gt;(v2) RETURN DISTINCT v2 AS Friends</code> You can use the <code>:&lt;edge_type&gt;*&lt;hop&gt;</code> pattern to match a fixed-length path. <code>hop</code> must be a non-negative integer. The data type of <code>e</code> is the list. Match variable-length paths <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*1..3]-&gt;(v2) RETURN v2 AS Friends</code> <code>minHop</code>: Optional. It represents the minimum length of the path. <code>minHop</code>: must be a non-negative integer. The default value is 1.<code>maxHop</code>: Required. It represents the maximum length of the path. <code>maxHop</code> must be a non-negative integer. It has no default value. The data type of <code>e</code> is the list. Match variable-length paths with multiple edge types <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow | serve*2]-&gt;(v2) RETURN DISTINCT v2</code> You can specify multiple edge types in a fixed-length or variable-length pattern. In this case, <code>hop</code>, <code>minHop</code>, and <code>maxHop</code> take effect on all edge types. The data type of <code>e</code> is the list. Retrieve vertex or edge information <code>MATCH (v:player{name:\"Tim Duncan\"}) RETURN v</code><code>MATCH (v:player{name:\"Tim Duncan\"})-[e]-&gt;(v2) RETURN e</code> Use <code>RETURN {&lt;vertex_name&gt; | &lt;edge_name&gt;}</code> to retrieve all the information of a vertex or an edge. Retrieve VIDs <code>MATCH (v:player{name:\"Tim Duncan\"}) RETURN id(v)</code> Use the <code>id()</code> function to retrieve VIDs. Retrieve tags <code>MATCH (v:player{name:\"Tim Duncan\"}) RETURN labels(v)</code> Use the <code>labels()</code> function to retrieve the list of tags on a vertex.To retrieve the nth element in the <code>labels(v)</code> list, use <code>labels(v)[n-1]</code>. Retrieve a single property on a vertex or an edge <code>MATCH (v:player{name:\"Tim Duncan\"}) RETURN v.age</code> Use <code>RETURN {&lt;vertex_name&gt; | &lt;edge_name&gt;}.&lt;property&gt;</code> to retrieve a single property.Use <code>AS</code> to specify an alias for a property. Retrieve all properties on a vertex or an edge <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[]-&gt;(v2) RETURN properties(v2)</code> Use the <code>properties()</code> function to retrieve all properties on a vertex or an edge. Retrieve edge types <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[e]-&gt;() RETURN DISTINCT type(e)</code> Use the <code>type()</code> function to retrieve the matched edge types. Retrieve paths <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[*3]-&gt;() RETURN p</code> Use <code>RETURN &lt;path_name&gt;</code> to retrieve all the information of the matched paths. Retrieve vertices in a path <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[]-&gt;(v2) RETURN nodes(p)</code> Use the <code>nodes()</code> function to retrieve all vertices in a path. Retrieve edges in a path <code>MATCH p=(v:player{name:\"Tim Duncan\"})-[]-&gt;(v2) RETURN relationships(p)</code> Use the <code>relationships()</code> function to retrieve all edges in a path. Retrieve path length <code>MATCH p=(v:player{name:\"Tim Duncan\"&gt;})-[*..2]-&gt;(v2) RETURN p AS Paths, length(p) AS Length</code> Use the <code>length()</code> function to retrieve the length of a path. </li> </ul> <ul> <li> <p>LOOKUP</p> <pre><code>LOOKUP ON {&lt;vertex_tag&gt; | &lt;edge_type&gt;} \n[WHERE &lt;expression&gt; [AND &lt;expression&gt; ...]] \n[YIELD &lt;return_list&gt; [AS &lt;alias&gt;]]\n</code></pre> Pattern Example Description Retrieve vertices <code>LOOKUP ON player WHERE player.name == \"Tony Parker\" YIELD player.name AS name, player.age AS age</code> The following example returns vertices whose <code>name</code> is <code>Tony Parker</code> and the tag is <code>player</code>. Retrieve edges <code>LOOKUP ON follow WHERE follow.degree == 90 YIELD follow.degree</code> Returns edges whose <code>degree</code> is <code>90</code> and the edge type is <code>follow</code>. List vertices with a tag <code>LOOKUP ON player</code> Shows how to retrieve the VID of all vertices tagged with <code>player</code>. List edges with an edge types <code>LOOKUP ON like</code> Shows how to retrieve the source Vertex IDs, destination vertex IDs, and ranks of all edges of the <code>like</code> edge type. Count the numbers of vertices or edges <code>LOOKUP ON player | YIELD COUNT(*) AS Player_Number</code> Shows how to count the number of vertices tagged with <code>player</code>. Count the numbers of edges <code>LOOKUP ON like | YIELD COUNT(*) AS Like_Number</code> Shows how to count the number of edges of the <code>like</code> edge type. </li> </ul> <ul> <li> <p>GO</p> <pre><code>GO [[&lt;M&gt; TO] &lt;N&gt; STEPS ] FROM &lt;vertex_list&gt;\nOVER &lt;edge_type_list&gt; [{REVERSELY | BIDIRECT}]\n[ WHERE &lt;conditions&gt; ]\n[YIELD [DISTINCT] &lt;return_list&gt;]\n[| GROUP BY {col_name | expr | position} YIELD &lt;col_name&gt;]\n[| ORDER BY &lt;expression&gt; [{ASC | DESC}]]\n[| LIMIT [&lt;offset_value&gt;,] &lt;number_rows&gt;]\n</code></pre> Example Description <code>GO FROM \"player102\" OVER serve</code> Returns the teams that player 102 serves. <code>GO 2 STEPS FROM \"player102\" OVER follow</code> Returns the friends of player 102 with 2 hops. <code>GO FROM \"player100\", \"player102\" OVER serve WHERE serve.start_year &gt; 1995 YIELD DISTINCT properties($$).name AS team_name, properties(edge).start_year AS start_year, properties($^).name AS player_name</code> Adds a filter for the traversal. <code>GO FROM \"player100\" OVER follow, serve YIELD properties(edge).degree, properties(edge).start_year</code> The following example traverses along with multiple edge types. If there is no value for a property, the output is <code>UNKNOWN_PROP</code>. <code>GO FROM \"player100\" OVER follow REVERSELY YIELD src(edge) AS destination</code> The following example returns the neighbor vertices in the incoming direction of player 100. <code>GO FROM \"player100\" OVER follow REVERSELY YIELD src(edge) AS id | GO FROM $-.id OVER serve WHERE $^.player.age &gt; 20 YIELD properties($^).name AS FriendOf, properties($$).name AS Team</code> The following example retrieves the friends of player 100 and the teams that they serve. <code>GO FROM \"player102\" OVER follow YIELD dst(edge) AS both</code> The following example returns all the neighbor vertices of player 102. <code>GO 2 STEPS FROM \"player100\" OVER follow YIELD src(edge) AS src, dst(edge) AS dst, properties($$).age AS age | GROUP BY $-.dst YIELD $-.dst AS dst, collect_set($-.src) AS src, collect($-.age) AS age</code> The following example the outputs according to age. </li> </ul> <ul> <li> <p>FETCH</p> <pre><code>FETCH PROP ON {&lt;tag_name&gt;[, tag_name ...] | *} \n&lt;vid&gt; [, vid ...] \n[YIELD &lt;return_list&gt; [AS &lt;alias&gt;]]\n</code></pre> Example Description <code>FETCH PROP ON player \"player100\"</code> Specify a tag in the <code>FETCH</code> statement to fetch the vertex properties by that tag. <code>FETCH PROP ON player \"player100\" YIELD player.name AS name</code> Use a <code>YIELD</code> clause to specify the properties to be returned. <code>FETCH PROP ON player \"player101\", \"player102\", \"player103\"</code> Specify multiple VIDs (vertex IDs) to fetch properties of multiple vertices. Separate the VIDs with commas. <code>FETCH PROP ON player, t1 \"player100\", \"player103\"</code> Specify multiple tags in the <code>FETCH</code> statement to fetch the vertex properties by the tags. Separate the tags with commas. <code>FETCH PROP ON * \"player100\", \"player106\", \"team200\"</code> Set an asterisk symbol <code>*</code> to fetch properties by all tags in the current graph space. <code>FETCH PROP ON serve \"player102\" -&gt; \"player106\" YIELD dst(edge)</code> Syntax: <code>FETCH PROP ON &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] [, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt; ...] [YIELD &lt;output&gt;]</code> <code>FETCH PROP ON serve \"player100\" -&gt; \"team204\"</code> The following statement fetches all the properties of the <code>serve</code> edge that connects vertex <code>\"player100\"</code> and vertex <code>\"team204\"</code>. <code>FETCH PROP ON serve \"player100\" -&gt; \"team204\" YIELD serve.start_year</code> Use a <code>YIELD</code> clause to fetch specific properties of an edge. <code>FETCH PROP ON serve \"player100\" -&gt; \"team204\", \"player133\" -&gt; \"team202\"</code> Specify multiple edge patterns (<code>&lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;]</code>) to fetch properties of multiple edges. Separate the edge patterns with commas. <code>FETCH PROP ON serve \"player100\" -&gt; \"team204\"@1</code> To fetch on an edge whose rank is not 0, set its rank in the FETCH statement. <code>GO FROM \"player101\" OVER follow YIELD follow._src AS s, follow._dst AS d | FETCH PROP ON follow $-.s -&gt; $-.d YIELD follow.degree</code> The following statement returns the <code>degree</code> values of the <code>follow</code> edges that start from vertex <code>\"player101\"</code>. <code>$var = GO FROM \"player101\" OVER follow YIELD follow._src AS s, follow._dst AS d; FETCH PROP ON follow $var.s -&gt; $var.d YIELD follow.degree</code> You can use user-defined variables to construct similar queries. </li> </ul> <ul> <li> <p>UNWIND</p> <pre><code>UNWIND &lt;list&gt; AS &lt;alias&gt; &lt;RETURN clause&gt;\n</code></pre> Example Description <code>UNWIND [1,2,3] AS n RETURN n</code> The following example splits the list <code>[1,2,3]</code> into three rows. <code>WITH [1,1,2,2,3,3] AS n UNWIND n AS r WITH DISTINCT r AS r ORDER BY r RETURN collect(r)</code> 1. Splits the list <code>[1,1,2,2,3,3]</code> into rows. 2. Removes duplicated rows. 3. Sorts the rows. 4. Transforms the rows to a list. <code>MATCH p=(v:player{name:\"Tim Duncan\"})--(v2) WITH nodes(p) AS n UNWIND n AS r WITH DISTINCT r AS r RETURN collect(r)</code> 1. Outputs the vertices on the matched path into a list. 2. Splits the list into rows. 3. Removes duplicated rows. 4. Transforms the rows to a list. </li> </ul> <ul> <li> <p>SHOW</p> Statement Syntax Example Description SHOW CHARSET <code>SHOW CHARSET</code> <code>SHOW CHARSET</code> Shows the available character sets. SHOW COLLATION <code>SHOW COLLATION</code> <code>SHOW COLLATION</code> Shows the collations supported by NebulaGraph. SHOW CREATE SPACE <code>SHOW CREATE SPACE &lt;space_name&gt;</code> <code>SHOW CREATE SPACE basketballplayer</code> Shows the creating statement of the specified graph space. SHOW CREATE TAG/EDGE <code>SHOW CREATE {TAG &lt;tag_name&gt; | EDGE &lt;edge_name&gt;}</code> <code>SHOW CREATE TAG player</code> Shows the basic information of the specified tag. SHOW HOSTS <code>SHOW HOSTS [GRAPH | STORAGE | META]</code> <code>SHOW HOSTS</code><code>SHOW HOSTS GRAPH</code> Shows the host and version information of Graph Service, Storage Service, and Meta Service. SHOW INDEX STATUS <code>SHOW {TAG | EDGE} INDEX STATUS</code> <code>SHOW TAG INDEX STATUS</code> Shows the status of jobs that rebuild native indexes, which helps check whether a native index is successfully rebuilt or not. SHOW INDEXES <code>SHOW {TAG | EDGE} INDEXES</code> <code>SHOW TAG INDEXES</code> Shows the names of existing native indexes. SHOW PARTS <code>SHOW PARTS [&lt;part_id&gt;]</code> <code>SHOW PARTS</code> Shows the information of a specified partition or all partitions in a graph space. SHOW ROLES <code>SHOW ROLES IN &lt;space_name&gt;</code> <code>SHOW ROLES in basketballplayer</code> Shows the roles that are assigned to a user account. SHOW SNAPSHOTS <code>SHOW SNAPSHOTS</code> <code>SHOW SNAPSHOTS</code> Shows the information of all the snapshots. SHOW SPACES <code>SHOW SPACES</code> <code>SHOW SPACES</code> Shows existing graph spaces in NebulaGraph. SHOW STATS <code>SHOW STATS</code> <code>SHOW STATS</code> Shows the statistics of the graph space collected by the latest <code>STATS</code> job. SHOW TAGS/EDGES <code>SHOW TAGS | EDGES</code> <code>SHOW TAGS</code>\u3001<code>SHOW EDGES</code> Shows all the tags in the current graph space. SHOW USERS <code>SHOW USERS</code> <code>SHOW USERS</code> Shows the user information. SHOW SESSIONS <code>SHOW SESSIONS</code> <code>SHOW SESSIONS</code> Shows the information of all the sessions. SHOW SESSIONS <code>SHOW SESSION &lt;Session_Id&gt;</code> <code>SHOW SESSION 1623304491050858</code> Shows a specified session with its ID. SHOW QUERIES <code>SHOW [ALL] QUERIES</code> <code>SHOW QUERIES</code> Shows the information of working queries in the current session. SHOW META LEADER <code>SHOW META LEADER</code> <code>SHOW META LEADER</code> Shows the information of the leader in the current Meta cluster. </li> </ul>"},{"location":"2.quick-start/6.cheatsheet-for-ngql/#clauses_and_options","title":"Clauses and options","text":"Clause Syntax Example Description GROUP BY <code>GROUP BY &lt;var&gt; YIELD &lt;var&gt;, &lt;aggregation_function(var)&gt;</code> <code>GO FROM \"player100\" OVER follow BIDIRECT YIELD $$.player.name as Name | GROUP BY $-.Name YIELD $-.Name as Player, count(*) AS Name_Count</code> Finds all the vertices connected directly to vertex <code>\"player100\"</code>, groups the result set by player names, and counts how many times the name shows up in the result set. LIMIT <code>YIELD &lt;var&gt; [| LIMIT [&lt;offset_value&gt;,] &lt;number_rows&gt;]</code> <code>O FROM \"player100\" OVER follow REVERSELY YIELD $$.player.name AS Friend, $$.player.age AS Age | ORDER BY $-.Age, $-.Friend | LIMIT 1, 3</code> Returns the 3 rows of data starting from the second row of the sorted output. SKIP <code>RETURN &lt;var&gt; [SKIP &lt;offset&gt;] [LIMIT &lt;number_rows&gt;]</code> <code>MATCH (v:player{name:\"Tim Duncan\"}) --&gt; (v2) RETURN v2.name AS Name, v2.age AS Age ORDER BY Age DESC SKIP 1</code> <code>SKIP</code> can be used alone to set the offset and return the data after the specified position. ORDER BY <code>&lt;YIELD clause&gt; ORDER BY &lt;expression&gt; [ASC | DESC] [, &lt;expression&gt; [ASC | DESC] ...]</code> <code>FETCH PROP ON player \"player100\", \"player101\", \"player102\", \"player103\" YIELD player.age AS age, player.name AS name | ORDER BY $-.age ASC, $-.name DESC</code> The <code>ORDER BY</code> clause specifies the order of the rows in the output. RETURN <code>RETURN {&lt;vertex_name&gt;|&lt;edge_name&gt;|&lt;vertex_name&gt;.&lt;property&gt;|&lt;edge_name&gt;.&lt;property&gt;|...}</code> <code>MATCH (v:player) RETURN v.name, v.age LIMIT 3</code> Returns the first three rows with values of the vertex properties <code>name</code> and <code>age</code>. TTL <code>CREATE TAG &lt;tag_name&gt;(&lt;property_name_1&gt; &lt;property_value_1&gt;, &lt;property_name_2&gt; &lt;property_value_2&gt;, ...) ttl_duration= &lt;value_int&gt;, ttl_col = &lt;property_name&gt;</code> <code>CREATE TAG t2(a int, b int, c string) ttl_duration= 100, ttl_col = \"a\"</code> Create a tag and set the TTL options. WHERE <code>WHERE {&lt;vertex|edge_alias&gt;.&lt;property_name&gt; {&gt;|==|&lt;|...} &lt;value&gt;...}</code> <code>MATCH (v:player) WHERE v.name == \"Tim Duncan\" XOR (v.age &lt; 30 AND v.name == \"Yao Ming\") OR NOT (v.name == \"Yao Ming\" OR v.name == \"Tim Duncan\") RETURN v.name, v.age</code> The <code>WHERE</code> clause filters the output by conditions. The <code>WHERE</code> clause usually works in Native nGQL <code>GO</code> and <code>LOOKUP</code> statements, and OpenCypher <code>MATCH</code> and <code>WITH</code> statements. YIELD <code>YIELD [DISTINCT] &lt;col&gt; [AS &lt;alias&gt;] [, &lt;col&gt; [AS &lt;alias&gt;] ...] [WHERE &lt;conditions&gt;];</code> <code>GO FROM \"player100\" OVER follow YIELD dst(edge) AS ID | FETCH PROP ON player $-.ID YIELD player.age AS Age | YIELD AVG($-.Age) as Avg_age, count(*)as Num_friends</code> Finds the players that \"player100\" follows and calculates their average age. WITH <code>MATCH $expressions WITH {nodes()|labels()|...}</code> <code>MATCH p=(v:player{name:\"Tim Duncan\"})--() WITH nodes(p) AS n UNWIND n AS n1 RETURN DISTINCT n1</code> The <code>WITH</code> clause can retrieve the output from a query part, process it, and pass it to the next query part as the input."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#space_statements","title":"Space statements","text":"Statement Syntax Example Description CREATE SPACE <code>CREATE SPACE [IF NOT EXISTS] &lt;graph_space_name&gt; ( [partition_num = &lt;partition_number&gt;,] [replica_factor = &lt;replica_number&gt;,] vid_type = {FIXED_STRING(&lt;N&gt;)| INT[64]} )  [COMMENT = '&lt;comment&gt;']</code> <code>CREATE SPACE my_space_1 (vid_type=FIXED_STRING(30))</code> Creates a graph space with CREATE SPACE <code>CREATE SPACE &lt;new_graph_space_name&gt; AS &lt;old_graph_space_name&gt;</code> <code>CREATE SPACE my_space_4 as my_space_3</code> Clone a graph space. USE <code>USE &lt;graph_space_name&gt;</code> <code>USE space1</code> Specifies a graph space as the current working graph space for subsequent queries. SHOW SPACES <code>SHOW SPACES</code> <code>SHOW SPACES</code> Lists all the graph spaces in the NebulaGraph examples. DESCRIBE SPACE <code>DESC[RIBE] SPACE &lt;graph_space_name&gt;</code> <code>DESCRIBE SPACE basketballplayer</code> Returns the information about the specified graph space.\u606f\u3002 DROP SPACE <code>DROP SPACE [IF EXISTS] &lt;graph_space_name&gt;</code> <code>DROP SPACE basketballplayer</code> Deletes everything in the specified graph space."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#tag_statements","title":"TAG statements","text":"Statement Syntax Example Description CREATE TAG <code>CREATE TAG [IF NOT EXISTS] &lt;tag_name&gt; ( &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;'] [{, &lt;prop_name&gt; &lt;data_type&gt; [NULL |  NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;']} ...] ) [TTL_DURATION = &lt;ttl_duration&gt;] [TTL_COL = &lt;prop_name&gt;] [COMMENT = '&lt;comment&gt;']</code> <code>CREATE TAG woman(name string, age int, married bool, salary double, create_time timestamp) TTL_DURATION = 100, TTL_COL = \"create_time\"</code> Creates a tag with the given name in a graph space. DROP TAG <code>DROP TAG [IF EXISTS] &lt;tag_name&gt;</code> <code>CREATE TAG test(p1 string, p2 int)</code> Drops a tag with the given name in the current working graph space. ALTER TAG <code>ALTER TAG &lt;tag_name&gt;    &lt;alter_definition&gt; [, alter_definition] ...]    [ttl_definition [, ttl_definition] ... ]    [COMMENT = '&lt;comment&gt;']</code> <code>ALTER TAG t1 ADD (p3 int, p4 string)</code> Alters the structure of a tag with the given name in a graph space. You can add or drop properties, and change the data type of an existing property. You can also set a TTL\uff08Time-To-Live\uff09on a property, or change its TTL duration. SHOW TAGS <code>SHOW TAGS</code> <code>SHOW TAGS</code> Shows the name of all tags in the current graph space. DESCRIBE TAG <code>DESC[RIBE] TAG &lt;tag_name&gt;</code> <code>DESCRIBE TAG player</code> Returns the information about a tag with the given name in a graph space, such as field names, data type, and so on. DELETE TAG <code>DELETE TAG &lt;tag_name_list&gt; FROM &lt;VID&gt;</code> <code>DELETE TAG test1 FROM \"test\"</code> Deletes a tag with the given name on a specified vertex."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#edge_type_statements","title":"Edge type statements","text":"Statement Syntax Example Description CREATE EDGE <code>CREATE EDGE [IF NOT EXISTS] &lt;edge_type_name&gt;    ( &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;'] [{, &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;']} ...] ) [TTL_DURATION = &lt;ttl_duration&gt;] [TTL_COL = &lt;prop_name&gt;] [COMMENT = '&lt;comment&gt;']</code> <code>CREATE EDGE e1(p1 string, p2 int, p3 timestamp) TTL_DURATION = 100, TTL_COL = \"p2\"</code> Creates an edge type with the given name in a graph space.type\u3002 DROP EDGE <code>DROP EDGE [IF EXISTS] &lt;edge_type_name&gt;</code> <code>DROP EDGE e1</code> Drops an edge type with the given name in a graph space. ALTER EDGE <code>ALTER EDGE &lt;edge_type_name&gt;    &lt;alter_definition&gt; [, alter_definition] ...]    [ttl_definition [, ttl_definition] ... ]    [COMMENT = '&lt;comment&gt;']</code> <code>ALTER EDGE e1 ADD (p3 int, p4 string)</code> Alters the structure of an edge type with the given name in a graph space. SHOW EDGES <code>SHOW EDGES</code> <code>SHOW EDGES</code> Shows all edge types in the current graph space. DESCRIBE EDGE <code>DESC[RIBE] EDGE &lt;edge_type_name&gt;</code> <code>DESCRIBE EDGE follow</code> Returns the information about an edge type with the given name in a graph space, such as field names, data type, and so on."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#vertex_statements","title":"Vertex statements","text":"Statement Syntax Example Description INSERT VERTEX <code>INSERT VERTEX [IF NOT EXISTS] &lt;tag_name&gt; (&lt;prop_name_list&gt;) [, &lt;tag_name&gt; (&lt;prop_name_list&gt;), ...]  {VALUES | VALUE} VID: (&lt;prop_value_list&gt;[, &lt;prop_value_list&gt;])</code> <code>INSERT VERTEX t2 (name, age) VALUES \"13\":(\"n3\", 12), \"14\":(\"n4\", 8)</code> Inserts one or more vertices into a graph space in NebulaGraph. DELETE VERTEX <code>DELETE VERTEX &lt;vid&gt; [, &lt;vid&gt; ...]</code> <code>DELETE VERTEX \"team1\"</code> Deletes vertices and the related incoming and outgoing edges of the vertices. UPDATE VERTEX <code>UPDATE VERTEX ON &lt;tag_name&gt; &lt;vid&gt; SET &lt;update_prop&gt; [WHEN &lt;condition&gt;] [YIELD &lt;output&gt;]</code> <code>UPDATE VERTEX ON player \"player101\" SET age = age + 2</code> Updates properties on tags of a vertex. UPSERT VERTEX <code>UPSERT VERTEX ON &lt;tag&gt; &lt;vid&gt; SET &lt;update_prop&gt; [WHEN &lt;condition&gt;] [YIELD &lt;output&gt;]</code> <code>UPSERT VERTEX ON player \"player667\" SET age = 31</code> The <code>UPSERT</code> statement is a combination of <code>UPDATE</code> and <code>INSERT</code>. You can use <code>UPSERT VERTEX</code> to update the properties of a vertex if it exists or insert a new vertex if it does not exist."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#edge_statements","title":"Edge statements","text":"Statement Syntax Example Description INSERT EDGE <code>INSERT EDGE [IF NOT EXISTS] &lt;edge_type&gt; ( &lt;prop_name_list&gt; ) {VALUES | VALUE} &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] : ( &lt;prop_value_list&gt; ) [, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] : ( &lt;prop_value_list&gt; ), ...]</code> <code>INSERT EDGE e2 (name, age) VALUES \"11\"-&gt;\"13\":(\"n1\", 1)</code> Inserts an edge or multiple edges into a graph space from a source vertex (given by src_vid) to a destination vertex (given by dst_vid) with a specific rank in NebulaGraph. DELETE EDGE <code>DELETE EDGE &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] [, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] ...]</code> <code>DELETE EDGE serve \"player100\" -&gt; \"team204\"@0</code> Deletes one edge or multiple edges at a time. UPDATE EDGE <code>UPDATE EDGE ON &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt; [@&lt;rank&gt;] SET &lt;update_prop&gt; [WHEN &lt;condition&gt;] [YIELD &lt;output&gt;]</code> <code>UPDATE EDGE ON serve \"player100\" -&gt; \"team204\"@0 SET start_year = start_year + 1</code> Updates properties on an edge. UPSERT EDGE <code>UPSERT EDGE ON &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt; [@rank] SET &lt;update_prop&gt; [WHEN &lt;condition&gt;] [YIELD &lt;properties&gt;]</code> <code>UPSERT EDGE on serve \"player666\" -&gt; \"team200\"@0 SET end_year = 2021</code> The <code>UPSERT</code> statement is a combination of <code>UPDATE</code> and <code>INSERT</code>. You can use <code>UPSERT EDGE</code> to update the properties of an edge if it exists or insert a new edge if it does not exist."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#index","title":"Index","text":"<ul> <li> <p>Native index</p> <p>You can use native indexes together with <code>LOOKUP</code> and <code>MATCH</code> statements.</p> Statement Syntax Example Description CREATE INDEX <code>CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] &lt;index_name&gt; ON {&lt;tag_name&gt; | &lt;edge_name&gt;} ([&lt;prop_name_list&gt;]) [COMMENT = '&lt;comment&gt;']</code> <code>CREATE TAG INDEX player_index on player()</code> Add native indexes for the existing tags, edge types, or properties. SHOW CREATE INDEX <code>SHOW CREATE {TAG | EDGE} INDEX &lt;index_name&gt;</code> <code>show create tag index index_2</code> Shows the statement used when creating a tag or an edge type. It contains detailed information about the index, such as its associated properties. SHOW INDEXES <code>SHOW {TAG | EDGE} INDEXES</code> <code>SHOW TAG INDEXES</code> Shows the defined tag or edge type indexes names in the current graph space. DESCRIBE INDEX <code>DESCRIBE {TAG | EDGE} INDEX &lt;index_name&gt;</code> <code>DESCRIBE TAG INDEX player_index_0</code> Gets the information about the index with a given name, including the property name (Field) and the property type (Type) of the index. REBUILD INDEX <code>REBUILD {TAG | EDGE} INDEX [&lt;index_name_list&gt;]</code> <code>REBUILD TAG INDEX single_person_index</code> Rebuilds the created tag or edge type index. If data is updated or inserted before the creation of the index, you must rebuild the indexes manually to make sure that the indexes contain the previously added data. SHOW INDEX STATUS <code>SHOW {TAG | EDGE} INDEX STATUS</code> <code>SHOW TAG INDEX STATUS</code> Returns the name of the created tag or edge type index and its status. DROP INDEX <code>DROP {TAG | EDGE} INDEX [IF EXISTS] &lt;index_name&gt;</code> <code>DROP TAG INDEX player_index_0</code> Removes an existing index from the current graph space. </li> </ul> <ul> <li> <p>Full-tex index</p> Syntax Example Description <code>SIGN IN TEXT SERVICE [(&lt;elastic_ip:port&gt; [,&lt;username&gt;, &lt;password&gt;]), (&lt;elastic_ip:port&gt;), ...]</code> <code>SIGN IN TEXT SERVICE (127.0.0.1:9200)</code> The full-text indexes is implemented based on Elasticsearch. After deploying an Elasticsearch cluster, you can use the <code>SIGN IN</code> statement to log in to the Elasticsearch client. <code>SHOW TEXT SEARCH CLIENTS</code> <code>SHOW TEXT SEARCH CLIENTS</code> Shows text search clients. <code>SIGN OUT TEXT SERVICE</code> <code>SIGN OUT TEXT SERVICE</code> Signs out to the text search clients. <code>CREATE FULLTEXT {TAG | EDGE} INDEX &lt;index_name&gt; ON {&lt;tag_name&gt; |  &lt;edge_name&gt;} ([&lt;prop_name_list&gt;])</code> <code>CREATE FULLTEXT TAG INDEX nebula_index_1 ON player(name)</code> Creates full-text indexes. <code>SHOW FULLTEXT INDEXES</code> <code>SHOW FULLTEXT INDEXES</code> Show full-text indexes. <code>REBUILD FULLTEXT INDEX</code> <code>REBUILD FULLTEXT INDEX</code> Rebuild full-text indexes. <code>DROP FULLTEXT INDEX &lt;index_name&gt;</code> <code>DROP FULLTEXT INDEX nebula_index_1</code> Drop full-text indexes. <code>LOOKUP ON {&lt;tag&gt; | &lt;edge_type&gt;} WHERE &lt;expression&gt; [YIELD &lt;return_list&gt;]</code> <code>LOOKUP ON player WHERE FUZZY(player.name, \"Tim Dunncan\", AUTO, OR) YIELD player.name</code> Use query options. </li> </ul>"},{"location":"2.quick-start/6.cheatsheet-for-ngql/#subgraph_and_path_statements","title":"Subgraph and path statements","text":"Type Syntax Example Description GET SUBGRAPH <code>GET SUBGRAPH [WITH PROP] [&lt;step_count&gt; STEPS] FROM {&lt;vid&gt;, &lt;vid&gt;...} [{IN | OUT | BOTH} &lt;edge_type&gt;, &lt;edge_type&gt;...] [YIELD [VERTICES AS &lt;vertex_alias&gt;] [,EDGES AS &lt;edge_alias&gt;]]</code> <code>GET SUBGRAPH 1 STEPS FROM \"player100\" YIELD VERTICES AS nodes, EDGES AS relationships</code> Retrieves information of vertices and edges reachable from the source vertices of the specified edge types and returns information of the subgraph. FIND PATH <code>FIND { SHORTEST | ALL | NOLOOP } PATH [WITH PROP] FROM &lt;vertex_id_list&gt; TO &lt;vertex_id_list&gt;&lt;br/&gt;OVER &lt;edge_type_list&gt; [REVERSELY | BIDIRECT] [&lt;WHERE clause&gt;] [UPTO &lt;N&gt; STEPS] [| ORDER BY $-.path] [| LIMIT &lt;M&gt;]</code> <code>FIND SHORTEST PATH FROM \"player102\" TO \"team204\" OVER *</code> Finds the paths between the selected source vertices and destination vertices. A returned path is like <code>(&lt;vertex_id&gt;)-[:&lt;edge_type_name&gt;@&lt;rank&gt;]-&gt;(&lt;vertex_id)</code>."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#query_tuning_statements","title":"Query tuning statements","text":"Type Syntax Example Description EXPLAIN <code>EXPLAIN [format=\"row\" | \"dot\"] &lt;your_nGQL_statement&gt;</code> <code>EXPLAIN format=\"row\" SHOW TAGS</code><code>EXPLAIN format=\"dot\" SHOW TAGS</code> Helps output the execution plan of an nGQL statement without executing the statement. PROFILE <code>PROFILE [format=\"row\" | \"dot\"] &lt;your_nGQL_statement&gt;</code> <code>PROFILE format=\"row\" SHOW TAGS</code><code>EXPLAIN format=\"dot\" SHOW TAGS</code> Executes the statement, then outputs the execution plan as well as the execution profile."},{"location":"2.quick-start/6.cheatsheet-for-ngql/#operation_and_maintenance_statements","title":"Operation and maintenance statements","text":"<ul> <li> <p>BALANCE</p> Syntax Description <code>BALANCE DATA</code> Starts a task to balance the distribution of storage partitions in a NebulaGraph cluster or a Group. It returns the task ID (<code>balance_id</code>). <code>BALANCE DATA &lt;balance_id&gt;</code> Shows the status of the <code>BALANCE DATA</code> task. <code>BALANCE DATA STOP</code> Stops the <code>BALANCE DATA</code> task. <code>BALANCE DATA REMOVE &lt;host_list&gt;</code> Scales in the NebulaGraph cluster and detaches specific storage hosts. <code>BALANCE LEADER</code> Balances the distribution of storage raft leaders in a NebulaGraph cluster or a Group. </li> </ul> <ul> <li> <p>Job statements</p> Syntax Description <code>SUBMIT JOB COMPACT</code> Triggers the long-term RocksDB <code>compact</code> operation. <code>SUBMIT JOB FLUSH</code> Writes the RocksDB memfile in the memory to the hard disk. <code>SUBMIT JOB STATS</code> Starts a job that makes the statistics of the current graph space. Once this job succeeds, you can use the <code>SHOW STATS</code> statement to list the statistics. <code>SHOW JOB &lt;job_id&gt;</code> Shows the information about a specific job and all its tasks in the current graph space. The Meta Service parses a <code>SUBMIT JOB</code> request into multiple tasks and assigns them to the nebula-storaged processes. <code>SHOW JOBS</code> Lists all the unexpired jobs in the current graph space. <code>STOP JOB</code> Stops jobs that are not finished in the current graph space. <code>RECOVER JOB</code> Re-executes the failed jobs in the current graph space and returns the number of recovered jobs. </li> </ul> <ul> <li> <p>Kill queries</p> Syntax Example Description <code>KILL QUERY (session=&lt;session_id&gt;, plan=&lt;plan_id&gt;)</code> <code>KILL QUERY(SESSION=1625553545984255,PLAN=163)</code> Terminates the query being executed, and is often used to terminate slow queries. </li> </ul>"},{"location":"20.appendix/0.FAQ/","title":"FAQ","text":"<p>This topic lists the frequently asked questions for using NebulaGraph 2.6.2. You can use the search box in the help center or the search function of the browser to match the questions you are looking for.</p> <p>If the solutions described in this topic cannot solve your problems, ask for help on the NebulaGraph forum or submit an issue on GitHub issue.</p>"},{"location":"20.appendix/0.FAQ/#about_manual_updates","title":"About manual updates","text":""},{"location":"20.appendix/0.FAQ/#why_is_the_behavior_in_the_manual_not_consistent_with_the_system","title":"\"Why is the behavior in the manual not consistent with the system?\"","text":"<p>NebulaGraph is still under development. Its behavior changes from time to time. Users can submit an issue to inform the team if the manual and the system are not consistent.</p> <p>Note</p> <p>If you find some errors in this topic:</p> <ol> <li>Click the <code>pencil</code> button at the top right side of this page.</li> <li>Use markdown to fix this error. Then click \"Commit changes\" at the bottom, which will start a Github pull request.</li> <li>Sign the CLA. This pull request will be merged after the acceptance of at least two reviewers.</li> </ol>"},{"location":"20.appendix/0.FAQ/#about_legacy_version_compatibility","title":"About legacy version compatibility","text":"<p><code>X</code> version compatibility</p> <p>Neubla Graph 2.6.2 is not compatible with NebulaGraph 1.x nor 2.0-RC in both data formats and RPC-protocols, and vice versa. To upgrade data formats, see Upgrade NebulaGraph to the current version. Users must upgrade all clients.</p> <p><code>Y</code> version compatibility</p> <p>Data formats of Neubla Graph 2.6.2 are compatible with NebulaGraph 2.0, while their clients are incompatible.</p>"},{"location":"20.appendix/0.FAQ/#about_executions","title":"About executions","text":""},{"location":"20.appendix/0.FAQ/#why_is_there_no_line_separating_each_row_in_the_returned_result_of_nebulagraph_260","title":"Why is there no line separating each row in the returned result of NebulaGraph 2.6.0?","text":"<p>This is caused by the release of Nebula Console 2.6.0, not the change of NebulaGraph core. And it will not affect the content of the returned data itself.</p>"},{"location":"20.appendix/0.FAQ/#about_dangling_edges","title":"About dangling edges","text":"<p>A dangling edge is an edge that only connects to a single vertex and only one part of the edge connects to the vertex.</p> <p>Dangling edges may appear in NebulaGraph 2.6.2 under unusual conditions. And there is no <code>MERGE</code> statements of openCypher. The guarantee for dangling edges depends entirely on the application level. For more information, see INSERT VERTEX, DELETE VERTEX, INSERT EDGE, DELETE EDGE.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_error_-1005_used_memory_hits_the_high_watermark0800000_of_total_system_memory","title":"\"How to resolve <code>[ERROR (-1005)]: Used memory hits the high watermark(0.800000) of total system memory.</code>?\"","text":"<p>The reason for this error may be that <code>system_memory_high_watermark_ratio</code> specifies the trigger threshold of the memory high watermark alarm mechanism. The default value is <code>0.8</code>. If the system memory usage is higher than this value, an alarm mechanism will be triggered, and NebulaGraph will stop querying.</p> <p>Possible solutions are as follows:</p> <ul> <li>Clean the system memory to make it below the threshold.</li> <li> <p>Modify the Graph configuration. Add the <code>system_memory_high_watermark_ratio</code> parameter to the configuration files of all Graph servers, and set it greater than <code>0.8</code>, such as <code>0.9</code>.</p> <p>Note</p> <p>Only the Graph service supports <code>system_memory_high_watermark_ratio</code>, while the Storage and Meta services do not.</p> </li> </ul>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_storage_error_e_rpc_failure","title":"\"How to resolve the error <code>Storage Error E_RPC_FAILURE</code>?\"","text":"<p>The reason for this error is usually that the storaged process returns too many data back to the graphd process. Possible solutions are as follows:</p> <ul> <li>Modify configuration files: Modify the value of <code>--storage_client_timeout_ms</code> in the <code>nebula-graphd.conf</code> file to extend the connection timeout of the Storage client. This configuration is measured in milliseconds (ms). For example, set <code>--storage_client_timeout_ms=60000</code>. If this parameter is not specified in the <code>nebula-graphd.conf</code> file, specify it manually. Tip: Add <code>--local_config=true</code> at the beginning of the configuration file and restart the service.</li> <li>Optimize the query statement: Reduce queries that scan the entire database. No matter whether <code>LIMIT</code> is used to limit the number of returned results, use the <code>GO</code> statement to rewrite the <code>MATCH</code> statement (the former is optimized, while the latter is not).</li> <li>Check whether the Storaged process has OOM. (<code>dmesg |grep nebula</code>).</li> <li>Use better SSD or memory for the Storage Server.</li> <li>Retry.</li> </ul>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_the_leader_has_changed_try_again_later","title":"\"How to resolve the error <code>The leader has changed. Try again later</code>?\"","text":"<p>It is a known issue. Just retry 1 to N times, where N is the partition number. The reason is that the meta client needs some heartbeats to update or errors to trigger the new leader information.</p>"},{"location":"20.appendix/0.FAQ/#how_is_the_time_spent_value_at_the_end_of_each_return_message_calculated","title":"\"How is the <code>time spent</code> value at the end of each return message calculated?\"","text":"<p>Take the returned message of <code>SHOW SPACES</code> as an example:</p> <pre><code>nebula&gt; SHOW SPACES;\n+--------------------+\n| Name               |\n+--------------------+\n| \"basketballplayer\" |\n+--------------------+\nGot 1 rows (time spent 1235/1934 us)\n</code></pre> <ul> <li>The first number <code>1235</code> shows the time spent by the database itself, that is, the time it takes for the query engine to receive a query from the client, fetch the data from the storage server, and perform a series of calculations.</li> </ul> <ul> <li>The second number <code>1934</code> shows the time spent from the client's perspective, that is, the time it takes for the client from sending a request, receiving a response, and displaying the result on the screen.</li> </ul>"},{"location":"20.appendix/0.FAQ/#can_i_set_replica_factor_as_an_even_number_in_create_space_statements_eg_replica_factor_2","title":"\"Can I set <code>replica_factor</code> as an even number in <code>CREATE SPACE</code> statements, e.g., <code>replica_factor = 2</code>?\"","text":"<p>NO.</p> <p>The Storage service guarantees its availability based on the Raft consensus protocol. The number of failed replicas must not exceed half of the total replica number.</p> <p>When the number of machines is 1, <code>replica_factor</code> can only be set to<code>1</code>.</p> <p>When there are enough machines and <code>replica_factor=2</code>, if one replica fails, the Storage service fails. No matter <code>replica_factor=3</code> or <code>replica_factor=4</code>, if more than one replica fails, the Storage Service fails. To prevent unnecessary waste of resources, we recommend that you set an odd replica number.</p> <p>We suggest that you set <code>replica_factor=3</code> for a production environment and <code>replica_factor=1</code> for a test environment. Do not use an even number.</p>"},{"location":"20.appendix/0.FAQ/#is_stopping_or_killing_slow_queries_supported","title":"\"Is stopping or killing slow queries supported?\"","text":"<p>Yes. For more information, see Kill query.</p>"},{"location":"20.appendix/0.FAQ/#why_are_the_query_results_different_when_using_go_and_match_to_execute_the_same_semantic_query","title":"\"Why are the query results different when using <code>GO</code> and <code>MATCH</code> to execute the same semantic query?\"","text":"<p>The possible reasons are listed as follows.</p> <ul> <li><code>GO</code> statements find the dangling edges.</li> </ul> <ul> <li><code>RETURN</code> commands do not specify the sequence.</li> </ul> <ul> <li>The dense vertex truncation limitation defined by <code>max_edge_returned_per_vertex</code> in the Storage service is triggered.</li> </ul> <ul> <li> <p>Using different types of paths may cause different query results.</p> <ul> <li><code>GO</code> statements use <code>walk</code>. Both vertices and edges can be repeatedly visited in graph traversal.</li> </ul> <ul> <li><code>MATCH</code> statements are compatible with openCypher and use <code>trail</code>. Only vertices can be repeatedly visited in graph traversal.</li> </ul> </li> </ul> <p>The example is as follows.</p> <p></p> <p>All queries that start from <code>A</code> with 5 hops will end at <code>C</code> (<code>A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;C</code>). If it is 6 hops, the <code>GO</code> statement will end at <code>D</code> (<code>A-&gt;B-&gt;C-&gt;D-&gt;E-&gt;C-&gt;D</code>), because the edge <code>C-&gt;D</code> can be visited repeatedly. However, the <code>MATCH</code> statement returns empty, because edges cannot be visited repeatedly.</p> <p>Therefore, using <code>GO</code> and <code>MATCH</code> to execute the same semantic query may cause different query results.</p> <p>For more information, see Wikipedia.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_error_-7_syntaxerror_syntax_error_near","title":"\"How to resolve <code>[ERROR (-7)]: SyntaxError: syntax error near</code>?\"","text":"<p>In most cases, a query statement requires a <code>YIELD</code> or a <code>RETURN</code>. Check your query statement to see if <code>YIELD</code> or <code>RETURN</code> is provided.</p>"},{"location":"20.appendix/0.FAQ/#how_to_count_the_verticesedges_number_of_each_tagedge_type","title":"\"How to count the vertices/edges number of each tag/edge type?\"","text":"<p>See show-stats.</p>"},{"location":"20.appendix/0.FAQ/#how_to_get_all_the_verticesedge_of_each_tagedge_type","title":"\"How to get all the vertices/edge of each tag/edge type?\"","text":"<ol> <li> <p>Create and rebuild the index.</p> <pre><code>&gt; CREATE TAG INDEX IF NOT EXISTS i_player ON player();\n&gt; REBUILD TAG INDEX IF NOT EXISTS i_player;\n</code></pre> </li> <li> <p>Use <code>LOOKUP</code> or <code>MATCH</code>. For example:</p> <pre><code>&gt; LOOKUP ON player;\n&gt; MATCH (n:player) RETURN n;\n</code></pre> </li> </ol> <p>For more information, see <code>INDEX</code>, <code>LOOKUP</code>, and <code>MATCH</code>.</p>"},{"location":"20.appendix/0.FAQ/#how_to_get_all_the_verticesedges_without_specifying_the_types","title":"\"How to get all the vertices/edges without specifying the types?\"","text":"<p>By nGQL, you CAN NOT directly getting all the vertices without specifying the tags, neither the edges.</p> <p>E.g., You CAN NOT run <code>MATCH (n) RETURN (n)</code>. An error like <code>can\u2019t solve the start vids from the sentence</code> will be returned.</p> <p>You can use Nebula Algorithm.</p> <p>Or get vertices by each tag, and then group them by yourself.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_cant_solve_the_start_vids_from_the_sentence","title":"\"How to resolve the error <code>can\u2019t solve the start vids from the sentence</code>?\"","text":"<p>The graphd process requires <code>start vids</code> to begin a graph traversal. The <code>start vids</code> can be specified by the user. For example:</p> <pre><code>&gt; GO FROM ${vids} ...\n&gt; MATCH (src) WHERE id(src) == ${vids}\n# The \"start vids\" are explicitly given by ${vids}.\n</code></pre> <p>It can also be found from a property index. For example:</p> <pre><code># CREATE TAG INDEX IF NOT EXISTS i_player ON player(name(20));\n# REBUILD TAG INDEX i_player;\n\n&gt; LOOKUP ON player WHERE player.name == \"abc\" | ... YIELD ...\n&gt; MATCH (src) WHERE src.name == \"abc\" ...\n# The \"start vids\" are found from the property index \"name\".\n</code></pre> <p>Otherwise, an error like <code>can\u2019t solve the start vids from the sentence</code> will be returned.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_wrong_vertex_id_type_1001","title":"\"How to resolve the error <code>Wrong vertex id type: 1001</code>?\"","text":"<p>Check whether the VID is <code>INT64</code> or <code>FIXED_STRING(N)</code> set by <code>create space</code>. For more information, see create space.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_the_vid_must_be_a_64-bit_integer_or_a_string_fitting_space_vertex_id_length_limit","title":"\"How to resolve the error <code>The VID must be a 64-bit integer or a string fitting space vertex id length limit.</code>?\"","text":"<p>Check whether the length of the VID exceeds the limitation. For more information, see create space.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_edge_conflict_or_vertex_conflict","title":"\"How to resolve the error <code>edge conflict</code> or <code>vertex conflict</code>?\"","text":"<p>NebulaGraph may return such errors when the Storage service receives multiple requests to insert or update the same vertex or edge within milliseconds. Try the failed requests again later.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_rpc_failure_in_metaclient_connection_refused","title":"\"How to resolve the error <code>RPC failure in MetaClient: Connection refused</code>?\"","text":"<p>The reason for this error is usually that the metad service status is unusual, or the network of the machine where the metad and graphd services are located is disconnected. Possible solutions are as follows:</p> <ul> <li>Check the metad service status on the server where the metad is located. If the service status is unusual, restart the metad service.</li> </ul> <ul> <li>Use <code>telnet meta-ip:port</code> to check the network status under the server that returns an error.</li> </ul> <ul> <li>Check the port information in the configuration file. If the port is different from the one used when connecting, use the port in the configuration file or modify the configuration.</li> </ul>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_storageclientbaseinl214_request_to_xxxx9779_failed_n6apache6thrift9transport19ttransportexceptione_timed_out_in_nebula-graphinfo","title":"\"How to resolve the error <code>StorageClientBase.inl:214] Request to \"x.x.x.x\":9779 failed: N6apache6thrift9transport19TTransportExceptionE: Timed Out</code> in <code>nebula-graph.INFO</code>?\"","text":"<p>The reason for this error may be that the amount of data to be queried is too large, and the storaged process has timed out. Possible solutions are as follows:</p> <ul> <li>When importing data, set Compaction manually to make read faster.</li> </ul> <ul> <li>Extend the RPC connection timeout of the Graph service and the Storage service. Modify the value of <code>--storage_client_timeout_ms</code> in the <code>nebula-storaged.conf</code> file. This configuration is measured in milliseconds (ms). The default value is 60000ms.</li> </ul>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_the_error_metaclientcpp65_heartbeat_failed_statuswrong_cluster_in_nebula-storagedinfo_or_hbprocessorcpp54_reject_wrong_cluster_host_xxxx9771_in_nebula-metadinfo","title":"\"How to resolve the error <code>MetaClient.cpp:65] Heartbeat failed, status:Wrong cluster!</code> in <code>nebula-storaged.INFO</code>, or <code>HBProcessor.cpp:54] Reject wrong cluster host \"x.x.x.x\":9771!</code> in <code>nebula-metad.INFO</code>?","text":"<p>The reason for this error may be that the user has modified the IP or the port information of the metad process, or the storage service has joined other clusters before. Possible solutions are as follows:</p> <p>Delete the <code>cluster.id</code> file in the installation directory where the storage machine is deployed (the default installation directory is <code>/usr/local/nebula</code>), and restart the storaged service.</p>"},{"location":"20.appendix/0.FAQ/#can_non-english_characters_be_used_as_identifiers_such_as_the_names_of_graph_spaces_tags_edge_types_properties_and_indexes","title":"Can non-English characters be used as identifiers, such as the names of graph spaces, tags, edge types, properties, and indexes?","text":"<p>No.</p> <p>The names of graph spaces, tags, edge types, properties, and indexes must use English letters, numbers, or underlines. Non-English characters are not currently supported.</p> <p>Meanwhile, the above identifiers are case-sensitive and cannot use Keywords and reserved words.</p>"},{"location":"20.appendix/0.FAQ/#how_to_get_the_out-degreethe_in-degree_of_a_vertex_with_a_given_name","title":"\"How to get the out-degree/the in-degree of a vertex with a given name\"?","text":"<p>The out-degree of a vertex refers to the number of edges starting from that vertex, while the in-degree refers to the number of edges pointing to that vertex.</p> <pre><code>nebula &gt; MATCH (s)-[e]-&gt;() WHERE id(s) == \"given\" RETURN count(e); #Out-degree\nnebula &gt; MATCH (s)&lt;-[e]-() WHERE id(s) == \"given\" RETURN count(e); #In-degree\n</code></pre>"},{"location":"20.appendix/0.FAQ/#how_to_quickly_get_the_out-degree_and_in-degree_of_all_vertices","title":"\"How to quickly get the out-degree and in-degree of all vertices?\"","text":"<p>There is no such command.</p> <p>You can use Nebula Algorithm.</p>"},{"location":"20.appendix/0.FAQ/#how_to_resolve_error_-1005_schema_not_exist_xxx","title":"\"How to resolve <code>[ERROR (-1005)]: Schema not exist: xxx</code>?\"","text":"<p>If the system returns <code>Schema not exist</code> when querying, make sure that:</p> <ul> <li>Whether there is a tag or an edge type in the Schema.</li> </ul> <ul> <li>-Whether the name of the tag or the edge type is a keyword. If it is a keyword, enclose them with backquotes (`). For more information, see Keywords.</li> </ul>"},{"location":"20.appendix/0.FAQ/#about_operation_and_maintenance","title":"About operation and maintenance","text":""},{"location":"20.appendix/0.FAQ/#the_log_files_are_too_large_how_to_recycle_the_logs","title":"\"The log files are too large. How to recycle the logs?\"","text":"<p>By default, the logs of NebulaGraph are stored in  <code>/usr/local/nebula/logs/</code>. The INFO level log files are <code>nebula-graphd.INFO, nebula-storaged.INFO, nebula-metad.INFO</code>. If an alarm or error occurs, the suffixes are modified as <code>.WARNING</code> or <code>.ERROR</code>.</p> <p>NebulaGraph uses glog to print logs. <code>glog</code> cannot recycle the outdated files. You can use crontab to delete them by yourself. For more information, see <code>Glog should delete old log files automatically</code>.</p>"},{"location":"20.appendix/0.FAQ/#how_to_check_the_nebulagraph_version","title":"\"How to check the NebulaGraph version?\"","text":"<p>If the service is running: run command <code>SHOW HOSTS META</code> in <code>nebula-console</code>. See SHOW HOSTS.</p> <p>If the service is not running:</p> <p>Different installation methods make the method of checking the version different. The instructions are as follows:</p> <p>If the service is not running, run the command <code>./&lt;binary_name&gt; --version</code> to get the version and the Git commit IDs of the NebulaGraph binary files. For example:</p> <pre><code>$ ./nebula-graphd --version\nnebula-graphd version 2.5.0, Git: c397299c, Build Time: Aug 19 2021 11:20:18\n</code></pre> <ul> <li> <p>If you deploy NebulaGraph with Docker Compose</p> <p>Check the version of NebulaGraph deployed by Docker Compose. The method is similar to the previous method, except that you have to enter the container first. The commands are as follows:</p> <pre><code>docker exec -it nebula-docker-compose_graphd_1 bash\ncd bin/\n./nebula-graphd --version\n</code></pre> </li> </ul> <ul> <li> <p>If you install NebulaGraph with RPM/DEB package</p> <p>Run <code>rpm -qa |grep nebula</code> to check the version of NebulaGraph.</p> </li> </ul>"},{"location":"20.appendix/0.FAQ/#how_to_scale_out_or_scale_in","title":"\"How to scale out or scale in?\"","text":"<p>NebulaGraph 2.6.2 does not provide any commands or tools to support automatic scale out/in. You can refer to the following steps:</p> <ol> <li> <p>Scale out and scale in metad: The metad process can not be scaled out or scale in. The process cannot be moved to a new machine. You cannot add a new metad process to the service.</p> <p>Note</p> <p>You can use the Meta transfer script tool to migrate Meta services. Note that the Meta-related settings in the configuration files of Storage and Graph services need to be modified correspondingly.</p> </li> <li> <p>Scale in graphd: Remove the IP of the graphd process from the code in the client. Close this graphd process.</p> </li> <li> <p>Scale out graphd: Prepare the binary and config files of the graphd process in the new host. Modify the config files and add all existing addresses of the metad processes. Then start the new graphd process.</p> </li> <li> <p>Scale in storaged: (The number of replicas must be greater than 1) See Balance remove command. After the command is finished, stop this storaged process.</p> </li> <li> <p>Scale out storaged: (The number of replicas must be greater than 1) Prepare the binary and config files of the storaged process in the new host, Modify the config files and add all existing addresses of the metad processes. Then start the new storaged process.</p> </li> </ol> <p>You also need to run Balance Data and Balance leader after scaling in/out storaged.</p>"},{"location":"20.appendix/0.FAQ/#after_changing_the_name_of_the_host_the_old_one_keeps_displaying_offline_what_should_i_do","title":"\"After changing the name of the host, the old one keeps displaying <code>OFFLINE</code>. What should I do?\"","text":"<p>Hosts with the status of <code>OFFLINE</code> will be automatically deleted after one day.</p>"},{"location":"20.appendix/0.FAQ/#about_connections","title":"About connections","text":""},{"location":"20.appendix/0.FAQ/#which_ports_should_be_opened_on_the_firewalls","title":"\"Which ports should be opened on the firewalls?\"","text":"<p>If you have not modified the predefined ports in the Configurations, open the following ports for the NebulaGraph services:</p> <p>| Service | Port                      | |---------+---------------------------| | Meta    | 9559, 9560, 19559, 19560  | | Graph   | 9669, 19669, 19670        | | Storage | 9777 ~ 9780, 19779, 19780 |</p> <p>If you have customized the configuration files and changed the predefined ports, find the port numbers in your configuration files and open them on the firewalls.</p> <p>For those eco-tools, see the corresponding document.</p>"},{"location":"20.appendix/0.FAQ/#how_to_test_whether_a_port_is_open_or_closed","title":"\"How to test whether a port is open or closed?\"","text":"<p>You can use telnet as follows to check for port status.</p> <pre><code>telnet &lt;ip&gt; &lt;port&gt;\n</code></pre> <p>Note</p> <p>If you cannot use the telnet command, check if telnet is installed or enabled on your host.</p> <p>For example:</p> <pre><code>// If the port is open:\n$ telnet 192.168.1.10 9669\nTrying 192.168.1.10...\nConnected to 192.168.1.10.\nEscape character is '^]'.\n\n// If the port is closed or blocked:\n$ telnet 192.168.1.10 9777\nTrying 192.168.1.10...\ntelnet: connect to address 192.168.1.10: Connection refused\n</code></pre>"},{"location":"20.appendix/0.vid/","title":"0.vid","text":"<p>TODO(doc)</p>"},{"location":"20.appendix/0.vid/#vid","title":"VID","text":"<p><code>VID</code> is short for vertex identifier.</p> <p>In NebulaGraph, vertices are identified with vertex identifiers (i.e. <code>VID</code>s).  The VID can be an int64 or a fixed length string. When inserting a vertex, you must specify a <code>VID</code> for it. </p> <p>You can also call <code>hash()</code> to generate an int64 VID if the graph has less than one billion vertices.</p> <p><code>VID</code> must be unique in a graph space.</p> <p>That is, in the same graph space, two vertices that have the same <code>VID</code> are considered as the same vertex.</p> <p>In addition, one <code>VID</code> can have multiple <code>TAG</code>s. E.g., One person (<code>VID</code>) can have two roles (<code>tags</code>).</p> <p>Two <code>VID</code>s in two different graph spaces are totally independent of each other.</p>"},{"location":"20.appendix/3.system-design/","title":"3.system design","text":"<p>TODO(doc)</p>"},{"location":"20.appendix/4.raft/","title":"4.raft","text":"<p>TODO(doc)</p>"},{"location":"20.appendix/5.partition/","title":"Partition ID","text":"<p>When inserting into NebulaGraph, vertices and edges are distributed across different partitions. And the partitions are located on different machines. If you want certain vertices to locate on the same partition (i.e., on the same machine), you can control the generation of the <code>VID</code>s by using the following formula / code.</p> <pre><code>    // If the length of the id is 8, we will treat it as int64_t to be compatible\n// with the version 1.0\nuint64_t vid = 0;\nif (id.size() == 8) {\nmemcpy(static_cast&lt;void*&gt;(&amp;vid), id.data(), 8);\n} else {\nMurmurHash2 hash;\nvid = hash(id.data());\n}\nPartitionID pId = vid % numParts + 1;\n</code></pre> <p>Roughly say, after hashing a fixed string to int64, (the hashing of int64 is the number itself), do modulo and then plus one.</p> <pre><code>pId = vid % numParts + 1;\n</code></pre> <p>In the preceding formula,</p> <ul> <li><code>%</code> is the modulo operation.</li> <li><code>numParts</code> is the number of partition for the graph space where the <code>VID</code> is located, namely the value of <code>partition_num</code> in the CREATE SPACE statement.</li> <li><code>pId</code> is the ID for the partition where the <code>VID</code> is located.</li> </ul> <p>For example, if there are 100 partitions, the vertices with <code>VID</code> 1, 101, 1001 will be stored on the same partition.</p> <p>But, the mapping between the <code>partition ID</code> and the machine address is random. Therefore, you can't assume that any two partitions are located on the same machine.</p>"},{"location":"20.appendix/6.eco-tool-version/","title":"Ecosystem tools overview","text":"<p>Compatibility</p> <p>The core release number naming rule is <code>X.Y.Z</code>, which means <code>Major version X</code>, <code>Medium version Y</code>, and <code>Minor version Z</code>. The upgrade requirements for the client are:</p> <ul> <li>Upgrade the core from <code>X.Y.Z1</code> to <code>X.Y.Z2</code>: It means that the core is fully forward compatible and is usually used for bugfixes. It is recommended to upgrade the minor version of the core as soon as possible. At this time, the client can stay not upgraded.</li> </ul> <ul> <li>Upgrade the core from <code>X.Y1.*</code> to <code>X.Y2.*</code>: It means that there is some incompatibility of API, syntax, and return value. It is usually used to add functions, improve performance, and optimize code. The client needs to be upgraded to <code>X.Y2.*</code>.</li> </ul> <ul> <li>Upgrade the core from <code>X1.*.*</code> to <code>X2.*.*</code>: It means that there is a major incompatibility in storage formats, API, syntax, etc. You need to use tools to upgrade the core data. The client must be upgraded.</li> </ul> <ul> <li>The default core and client do not support downgrade: You cannot downgrade from <code>X.Y.Z2</code> to <code>X.Y.Z1</code>.</li> </ul> <ul> <li>The release cycle of a <code>Y</code> version is about 6 months, and its maintenance and support cycle is 6 months.</li> </ul> <ul> <li>The version released at the beginning of the year is usually named <code>X.0.0</code>, and in the middle of the year, it is named <code>X.5.0</code>.</li> </ul> <ul> <li>The file name contains <code>RC</code> to indicate an unofficial version (<code>Release Candidate</code>) that is only used for preview. Its maintenance period is only until the next RC or official version is released. Its client, data compatibility, etc. are not guaranteed.</li> </ul> <ul> <li>The files with <code>nightly</code>, <code>SNAPSHOT</code>, or date are the nightly versions. There is no quality assurance and maintenance period.</li> </ul> <p>Compatibility</p> <p>All ecosystem tools of 1.x did not support NebulaGraph 2.x core.</p>"},{"location":"20.appendix/6.eco-tool-version/#nebulagraph_studio","title":"NebulaGraph Studio","text":"<p>NebulaGraph Studio (Studio for short) is a graph database visualization tool that can be accessed through the Web. It can be used with NebulaGraph DBMS to provide one-stop services such as composition, data import, writing nGQL queries, and graph exploration. For details, see What is NebulaGraph Studio.</p> <p>Note</p> <p>The release of the Studio is independent of NebulaGraph core, and its naming method is also not the same as the core naming rules. The compatible relationship between them is as follows.</p> NebulaGraph version Studio version(commit id) 2.6.2 3.1.1(3754219)"},{"location":"20.appendix/6.eco-tool-version/#nebula_dashboard_community_edition","title":"Nebula Dashboard Community Edition","text":"<p>Nebula Dashboard Community Edition (Dashboard for short) is a visualization tool for monitoring the status of machines and services in the NebulaGraph cluster. For details, see What is Nebula Dashboard.</p> NebulaGraph version Dashboard version (commit id) 2.6.2 1.0.2(a610013)"},{"location":"20.appendix/6.eco-tool-version/#nebula_dashboard_enterprise_edition","title":"Nebula Dashboard Enterprise Edition","text":"<p>Nebula Dashboard Enterprise Edition (Dashboard for short) is a visualization tool that monitors and manages the status of machines and services in NebulaGraph cluster. For details, see What is Nebula Dashboard.</p> NebulaGraph version Dashboard version (commit id) 2.6.2 1.0.0(3474c78)"},{"location":"20.appendix/6.eco-tool-version/#nebula_explorer","title":"Nebula Explorer","text":"<p>Nebula Explorer (Explorer for short) is a graph exploration visualization tool that can be accessed through the Web. It is used with the NebulaGraph core to visualize interaction with graph data. Users can quickly become map experts, even without experience in map data manipulation. For details, see What is Nebula Explorer.</p> NebulaGraph version Explorer version (commit id) 2.6.2 2.1.0(3acdd02)"},{"location":"20.appendix/6.eco-tool-version/#nebula_exchange","title":"Nebula Exchange","text":"<p>Nebula Exchange (Exchange for short) is an Apache Spark&amp;trade application for batch migration of data in a cluster to NebulaGraph in a distributed environment. It can support the migration of batch data and streaming data in a variety of different formats. For details, see What is Nebula Exchange.</p> NebulaGraph version Exchange community version (commit id) Exchange enterprise\uff08commit id\uff09 2.6.2 2.6.1\uff08e6d8601\uff09 2.6.1\uff088712390\uff09"},{"location":"20.appendix/6.eco-tool-version/#nebula_operator","title":"Nebula Operator","text":"<p>Nebula Operator (Operator for short) is a tool to automate the deployment, operation, and maintenance of NebulaGraph clusters on Kubernetes. Building upon the excellent scalability mechanism of Kubernetes, NebulaGraph introduced its operation and maintenance knowledge into the Kubernetes system, which makes NebulaGraph a real cloud-native graph database. For more information, see What is Nebula Operator.</p> NebulaGraph version Operator version\uff08commit id\uff09 2.6.2 0.9.0\uff08ba88e28\uff09"},{"location":"20.appendix/6.eco-tool-version/#nebula_importer","title":"Nebula Importer","text":"<p>Nebula Importer (Importer for short) is a CSV file import tool for NebulaGraph. The Importer can read the local CSV file, and then import the data into the NebulaGraph database. For details, see What is Nebula Importer.</p> NebulaGraph version Importer version (commit id) 2.6.2 2.6.0(43234f3)"},{"location":"20.appendix/6.eco-tool-version/#nebula_spark_connector","title":"Nebula Spark Connector","text":"<p>Nebula Spark Connector is a Spark connector that provides the ability to read and write NebulaGraph data in the Spark standard format. Nebula Spark Connector consists of two parts, Reader and Writer. For details, see What is Nebula Spark Connector.</p> NebulaGraph version Spark Connector version (commit id) 2.6.2 2.6.1(aac22e1)"},{"location":"20.appendix/6.eco-tool-version/#nebula_flink_connector","title":"Nebula Flink Connector","text":"<p>Nebula Flink Connector is a connector that helps Flink users quickly access NebulaGraph. It supports reading data from the NebulaGraph database or writing data read from other external data sources to the NebulaGraph database. For details, see What is Nebula Flink Connector.</p> NebulaGraph version Flink Connector version (commit id) 2.6.2 2.6.1(79bd8d4)"},{"location":"20.appendix/6.eco-tool-version/#nebula_algorithm","title":"Nebula Algorithm","text":"<p>Nebula Algorithm (Algorithm for short) is a Spark application based on GraphX, which uses a complete algorithm tool to analyze data in the NebulaGraph database by submitting a Spark task To perform graph computing, use the algorithm under the lib repository through programming to perform graph computing for DataFrame. For details, see What is Nebula Algorithm.</p> NebulaGraph version Algorithm version (commit id) 2.6.2 2.5.1(2c61ca5)"},{"location":"20.appendix/6.eco-tool-version/#nebula_console","title":"Nebula Console","text":"<p>Nebula Console is the native CLI client of NebulaGraph. For how to use it, see Connect NebulaGraph.</p> NebulaGraph version Console version (commit id) 2.6.2 2.6.0(0834198)"},{"location":"20.appendix/6.eco-tool-version/#nebula_docker_compose","title":"Nebula Docker Compose","text":"<p>Docker Compose can quickly deploy NebulaGraph clusters. For how to use it, please refer to Docker Compose Deployment NebulaGraph.</p> NebulaGraph version Docker Compose version (commit id) 2.6.2 2.6(a6e9d78)"},{"location":"20.appendix/6.eco-tool-version/#nebula_bench","title":"Nebula Bench","text":"<p>Nebula Bench is used to test the baseline performance data of NebulaGraph. It uses the standard data set of LDBC v0.3.3.</p> NebulaGraph version Nebula Bench version (commit id) 2.6.2 1.0.0(661f871)"},{"location":"20.appendix/6.eco-tool-version/#api_sdk","title":"API, SDK","text":"<p>Compatibility</p> <p>Select the latest version of <code>X.Y.*</code> which is the same as the core version.</p> NebulaGraph version Language (commit id) 2.6.2 C++\uff0800e2625\uff09 2.6.2 Go\uff0802eb246\uff09 2.6.2 Python\uff08f9e8b11\uff09 2.6.2 Java\uff08064f3a4\uff09"},{"location":"20.appendix/6.eco-tool-version/#not_released","title":"Not Released","text":"<ul> <li> <p>API</p> <ul> <li>Rust Client</li> </ul> <ul> <li>Node.js Client</li> </ul> <ul> <li>HTTP Client</li> </ul> <ul> <li>[Object Graph Mapping Library (OGM, or ORM)] Java, Python (TODO: in design)</li> </ul> </li> </ul> <ul> <li> <p>Monitoring</p> <ul> <li>Promethus connector</li> </ul> <ul> <li>[Graph Computing] (TODO: in coding)</li> </ul> </li> </ul> <ul> <li> <p>Test</p> <ul> <li>Chaos Test</li> </ul> </li> </ul> <ul> <li>Backup &amp; Restore</li> </ul>"},{"location":"20.appendix/comments/","title":"Comments","text":""},{"location":"20.appendix/comments/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<ul> <li>In NebulaGraph 1.0, four comment styles: <code>#</code>, <code>--</code>, <code>//</code>, <code>/* */</code>.</li> <li>In NebulaGraph 2.0, <code>--</code> represents an edge, and can not be used as comments.</li> </ul>"},{"location":"20.appendix/comments/#examples","title":"Examples","text":"<pre><code>nebula&gt; # Do nothing this line\nnebula&gt; RETURN 1+1;     # This comment continues to the end of line\nnebula&gt; RETURN 1+1;     // This comment continues to the end of line\nnebula&gt; RETURN 1 /* This is an in-line comment */ + 1 == 2;\nnebula&gt; RETURN 11 +            \\\n/* Multiple-line comment       \\\nUse backslash as line break.   \\\n*/ 12;\n</code></pre> <p>The backslash <code>\\</code> in a line indicates a line break.</p>"},{"location":"20.appendix/comments/#opencypher_compatibility","title":"OpenCypher Compatibility","text":"<p>You must add a <code>\\</code> at the end of every line, even in multi-line comments <code>\\* *\\</code>.</p> <pre><code>/* The openCypher style:\nThe following comment\nspans more than\none line */\nMATCH (n:label)\nRETURN n\n</code></pre> <pre><code>/* The native nGQL style:    \\\nThe following comment \\\nspans more than       \\\none line */           \\\nMATCH (n:tag)             \\\nRETURN n\n</code></pre>"},{"location":"20.appendix/identifier-case-sensitivity/","title":"Identifer Case Sensitivity","text":""},{"location":"20.appendix/identifier-case-sensitivity/#identifiers_are_case-sensitive","title":"Identifiers are Case-Sensitive","text":"<p>The following statements would not work because they refer to two different spaces, i.e. <code>my_space</code> and <code>MY_SPACE</code>:</p> <pre><code>nebula&gt; CREATE SPACE IF NOT EXISTS my_space;\nnebula&gt; use MY_SPACE;\n[ERROR (-8)]: SpaceNotFound:\n# my_space and MY_SPACE are two different spaces\n</code></pre>"},{"location":"20.appendix/identifier-case-sensitivity/#keywords_and_reserved_words_are_case-insensitive","title":"Keywords and Reserved Words are Case-Insensitive","text":"<p>The following statements are equivalent:</p> <pre><code>nebula&gt; show spaces;  # show and spaces are keywords.\nnebula&gt; SHOW SPACES;\nnebula&gt; SHOW spaces;\nnebula&gt; show SPACES;\n</code></pre>"},{"location":"20.appendix/keywords-and-reserved-words/","title":"Keywords and Reserved Words","text":"<p>Keywords have significance in nGQL. Certain keywords are reserved and require special treatment for use as identifiers.</p> <p>Non-reserved keywords are permitted as identifiers without quoting. Non-reserved keywords are case-insensitive. To use reserved keywords as identifiers, quote them with back quotes such as `AND`.</p> <pre><code>nebula&gt; CREATE TAG TAG(name string);\n[ERROR (-7)]: SyntaxError: syntax error near `TAG'\n\n// SPACE is an unreserved keyword.\nnebula&gt; CREATE TAG SPACE(name string);\nExecution succeeded\n</code></pre> <p><code>TAG</code> is a reserved keyword. To use <code>TAG</code> as an identifier, you must quote it with a backtick. <code>SPACE</code> is a non-reserved keyword. You can use <code>SPACE</code> as an identifier without quoting it. </p> <p>Note</p> <p>There is a small pitfall when you use the non-reserved keyword. Unquoted non-reserved keyword will be converted to lower-case words. For example,  <code>SPACE</code> or <code>Space</code> will become <code>space</code>.</p> <pre><code>// TAG is a reserved keyword here.\nnebula&gt; CREATE TAG `TAG` (name string);\nExecution succeeded\n</code></pre>"},{"location":"20.appendix/keywords-and-reserved-words/#reserved_words","title":"Reserved Words","text":"<p>The following list shows reserved words in nGQL.</p> <pre><code>ADD\nALTER\nAND\nAS\nASC\nBALANCE\nBOOL\nBY\nCASE\nCHANGE\nCOMPACT\nCREATE\nDATE\nDATETIME\nDELETE\nDESC\nDESCRIBE\nDISTINCT\nDOUBLE\nDOWNLOAD\nDROP\nEDGE\nEDGES\nEXISTS\nEXPLAIN\nFETCH\nFIND\nFIXED_STRING\nFLOAT\nFLUSH\nFORMAT\nFROM\nGET\nGO\nGRANT\nIF\nIN\nINDEX\nINDEXES\nINGEST\nINSERT\nINT\nINT16\nINT32\nINT64\nINT8\nINTERSECT\nIS\nLIMIT\nLOOKUP\nMATCH\nMINUS\nNO\nNOT\nNULL\nOF\nOFFSET\nON\nOR\nORDER\nOVER\nOVERWRITE\nPROFILE\nPROP\nREBUILD\nRECOVER\nREMOVE\nRETURN\nREVERSELY\nREVOKE\nSET\nSHOW\nSTEP\nSTEPS\nSTOP\nSTRING\nSUBMIT\nTAG\nTAGS\nTIME\nTIMESTAMP\nTO\nUNION\nUPDATE\nUPSERT\nUPTO\nUSE\nVERTEX\nWHEN\nWHERE\nWITH\nXOR\nYIELD\n</code></pre>"},{"location":"20.appendix/keywords-and-reserved-words/#non-reserved_keywords","title":"Non-Reserved Keywords","text":"<pre><code>ACCOUNT\nADMIN\nALL\nANY\nATOMIC_EDGE\nAUTO\nAVG\nBIDIRECT\nBIT_AND\nBIT_OR\nBIT_XOR\nBOTH\nCHARSET\nCLIENTS\nCOLLATE\nCOLLATION\nCOLLECT\nCOLLECT_SET\nCONFIGS\nCONTAINS\nCOUNT\nCOUNT_DISTINCT\nDATA\nDBA\nDEFAULT\nELASTICSEARCH\nELSE\nEND\nENDS\nFALSE\nFORCE\nFUZZY\nGOD\nGRAPH\nGROUP\nGROUPS\nGUEST\nHDFS\nHOST\nHOSTS\nINTO\nJOB\nJOBS\nLEADER\nLISTENER\nMAX\nMETA\nMIN\nNOLOOP\nNONE\nOPTIONAL\nOUT\nPART\nPARTITION_NUM\nPARTS\nPASSWORD\nPATH\nPLAN\nPREFIX\nREGEXP\nREPLICA_FACTOR\nRESET\nROLE\nROLES\nSEARCH\nSERVICE\nSHORTEST\nSIGN\nSINGLE\nSKIP\nSNAPSHOT\nSNAPSHOTS\nSPACE\nSPACES\nSTARTS\nSTATS\nSTATUS\nSTD\nSTORAGE\nSUBGRAPH\nSUM\nTEXT\nTEXT_SEARCH\nTHEN\nTRUE\nTTL_COL\nTTL_DURATION\nUNWIND\nUSER\nUSERS\nUUID\nVALUE\nVALUES\nVID_TYPE\nWILDCARD\nZONE\nZONES\n</code></pre>"},{"location":"20.appendix/learning-path/","title":"NebulaGraph learning path","text":"<p>This topic is for anyone interested in learning more about NebulaGraph. You can master NebulaGraph from zero to hero through the documentation and videos in NebulaGraph learning path. </p> <p></p>"},{"location":"20.appendix/learning-path/#1_about_nebulagraph","title":"1. About NebulaGraph","text":""},{"location":"20.appendix/learning-path/#11_what_is_nebulagraph","title":"1.1 What is NebulaGraph?","text":"Document Video What is NebulaGraph NebulaGraph"},{"location":"20.appendix/learning-path/#12_data_models","title":"1.2 Data models","text":"Document Data modeling"},{"location":"20.appendix/learning-path/#13_path","title":"1.3 Path","text":"Document Path"},{"location":"20.appendix/learning-path/#14_nebulagraph_architecture","title":"1.4 NebulaGraph architecture","text":"Document Meta service Graph service Storage service"},{"location":"20.appendix/learning-path/#2_quick_start","title":"2. Quick start","text":""},{"location":"20.appendix/learning-path/#21_install_nebulagraph","title":"2.1 Install NebulaGraph","text":"Document Video Install with a RPM or DEB package - Install with a TAR package - Install with Docker Install NebulaGraph with Docker and Docker Compose Install from source Install NebulaGraph with Source Code"},{"location":"20.appendix/learning-path/#22_start_nebulagraph","title":"2.2 Start NebulaGraph","text":"Document Start and stop NebulaGraph"},{"location":"20.appendix/learning-path/#23_connect_to_nebulagraph","title":"2.3 Connect to NebulaGraph","text":"Document Connect to NebulaGraph"},{"location":"20.appendix/learning-path/#24_use_ngql_statements","title":"2.4 Use nGQL statements","text":"Document nGQL cheatsheet"},{"location":"20.appendix/learning-path/#3_hands-on_practices","title":"3. Hands-on practices","text":""},{"location":"20.appendix/learning-path/#31_deploy_a_multi-machine_cluster","title":"3.1 Deploy a multi-machine cluster","text":"Document Deploy a NebulaGraph cluster with RPM/DEB"},{"location":"20.appendix/learning-path/#32_upgrade_nebulagraph","title":"3.2 Upgrade NebulaGraph","text":"Document Upgrade NebulaGraph to v2.6.2 Upgrade NebulaGraph from v2.0.x to v2.6.2"},{"location":"20.appendix/learning-path/#33_configure_nebulagraph","title":"3.3 Configure NebulaGraph","text":"Document Configure Meta Configure Graph Configure Storage Configure Linux kernel"},{"location":"20.appendix/learning-path/#34_configure_logs","title":"3.4 Configure logs","text":"Document Log managements"},{"location":"20.appendix/learning-path/#35_om_and_management","title":"3.5 O&amp;M and Management","text":"<ul> <li> <p>Account authentication and authorization</p> Document Local authentication OpenLDAP User management Roles and privileges </li> </ul> <ul> <li> <p>Balance the distribution of partitions</p> Document Storage load balancing </li> </ul> <ul> <li> <p>Monitoring</p> Document NebulaGraph metrics RocksDB statistics </li> </ul> <ul> <li> <p>Data snapshot</p> Document Create snapshots </li> </ul> <ul> <li> <p>Resource isolation</p> Document Group &amp; Zone </li> </ul> <ul> <li> <p>SSL encryption</p> Document SSL </li> </ul>"},{"location":"20.appendix/learning-path/#36_performance_tuning","title":"3.6 Performance tuning","text":"Document Graph data modeling suggestions System design suggestions Compaction"},{"location":"20.appendix/learning-path/#37_derivative_software","title":"3.7 Derivative software","text":"<ul> <li> <p>Visualization</p> Visualization tools Document Video Data visualization NebulaGraph Studio Nebula Studio Data monitoring and O&amp;M Nebula Dashboard Community Edition\u548c Nebula Dashboard Enterprise Edition - Data analysis Nebula Explorer Enterprise Edition - </li> </ul> <ul> <li> <p>Data import and export</p> Import and export Document Video Data import Nebula Importer Nebula Importer Data import Nebula Spark Connector - Data import Nebula Flink Connector - Data import Nebula Exchange Community Edition - Data export Nebula Exchange Enterprise Edition - </li> </ul> <ul> <li> <p>Performance test</p> Document Nebula Bench </li> </ul> <ul> <li> <p>Cluster O&amp;M</p> Document Nebula Operator </li> </ul> <ul> <li> <p>Graph algorithm</p> Document Nebula Algorithm </li> </ul> <ul> <li> <p>Clients</p> Document Nebula Console Nebula CPP Nebula Java Nebula Python Nebula Go </li> </ul>"},{"location":"20.appendix/learning-path/#4_api_sdk","title":"4. API &amp; SDK","text":"Document API &amp; SDK"},{"location":"20.appendix/learning-path/#5_best_practices","title":"5. Best practices","text":"Document Handling Tens of Billions of Threat Intelligence Data with Graph Database at Kuaishou Import data from Neo4j to NebulaGraph via Nebula Exchange: Best Practices Hands-On Experience: Import Data to NebulaGraph with Spark How to Select a Graph Database: Best Practices at RoyalFlush Practicing Nebula Operator on Cloud Using Ansible to Automate Deployment of NebulaGraph Cluster"},{"location":"20.appendix/learning-path/#6_faq","title":"6. FAQ","text":"Document FAQ"},{"location":"20.appendix/learning-path/#7_practical_tasks","title":"7. Practical tasks","text":"<p>You can check if you have mastered NebulaGraph by completing the following practical tasks. </p> Task Reference Compile the source code of NebulaGraph Install NebulaGraph by compiling the source code Deploy Studio, Dashboard, and Explorer Deploy Studio, Deploy Dashboard, and Deploy Explorer Load test NebulaGraph with K6 Nebula Bench Query LDBC data\uff08such as queries for vertices, paths, or subgraphs.\uff09 LDBC and interactive-short-1.cypher"},{"location":"20.appendix/releasenote/","title":"NebulaGraph 2.6.2 release notes","text":""},{"location":"20.appendix/releasenote/#bug_fix","title":"Bug fix","text":"<ul> <li>Fixed the bug that memory was not released when default value was used \u200b\u200bwhen no value was specified in nGQL. #3806</li> </ul> <ul> <li>Fixed the bug of reading memory stats under Cgroup v2. #3792</li> </ul> <ul> <li>Fixed the bug that failed to create a full-text index for the same tag or edge internal id in different SPACE. #3793</li> </ul>"},{"location":"20.appendix/releasenote/#legacy_versions","title":"Legacy versions","text":"<p>Release notes of legacy versions</p>"},{"location":"20.appendix/write-tools/","title":"Import tools","text":"<p>There are many ways to write NebulaGraph 2.6.2:</p> <ul> <li>Import with the command -f: This method imports a small number of prepared nGQL files, which is suitable to prepare for a small amount of manual test data.</li> <li>Import with Studio: This method uses a browser to import multiple csv files of this machine. A single file cannot exceed 100 MB, and its format is limited.</li> <li>Import with Importer: This method imports multiple csv files on a single machine with unlimited size and flexible format.</li> <li>Import with Exchange: This method imports from various distribution sources, such as Neo4j, Hive, MySQL, etc., which requires a Spark cluster.</li> <li>Import with Spark-connector/Flink-connector: This method has corresponding components (Spark/Flink) and writes a small amount of code.</li> <li>Import with C++/GO/Java/Python SDK: This method imports in the way of writing programs, which requires certain programming and tuning skills.</li> </ul> <p>The following figure shows the positions of these ways:</p> <p></p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/","title":"NebulaGraph Query Language (nGQL)","text":"<p>This topic gives an introduction to the query language of NebulaGraph, nGQL.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#what_is_ngql","title":"What is nGQL","text":"<p>nGQL is a declarative graph query language for NebulaGraph. It allows expressive and efficient graph patterns. nGQL is designed for both developers and operations professionals. nGQL is an SQL-like query language, so it's easy to learn.</p> <p>nGQL is a project in progress. New features and optimizations are done steadily. There can be differences between syntax and implementation. Submit an issue to inform the NebulaGraph team if you find a new issue of this type. NebulaGraph 2.0 or later releases will support openCypher 9.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#what_can_ngql_do","title":"What can nGQL do","text":"<ul> <li>Supports graph traversals</li> <li>Supports pattern match</li> <li>Supports aggregation</li> <li>Supports graph mutation</li> <li>Supports access control</li> <li>Supports composite queries</li> <li>Supports index</li> <li>Supports most openCypher 9 graph query syntax (but mutations and controls syntax are not supported)</li> </ul>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#example_data_basketballplayer","title":"Example data Basketballplayer","text":"<p>Users can download the example data Basketballplayer in NebulaGraph. After downloading the example data, you can import it to NebulaGraph by using the <code>-f</code> option in NebulaGraph Console.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#placeholder_identifiers_and_values","title":"Placeholder identifiers and values","text":"<p>Refer to the following standards in nGQL:</p> <ul> <li>(Draft) ISO/IEC JTC1 N14279 SC 32 - Database_Languages - GQL</li> </ul> <ul> <li>(Draft) ISO/IEC JTC1 SC32 N3228 - SQL_Property_Graph_Queries - SQLPGQ</li> </ul> <ul> <li>OpenCypher 9</li> </ul> <p>In template code, any token that is not a keyword, a literal value, or punctuation is a placeholder identifier or a placeholder value.</p> <p>For details of the symbols in nGQL syntax, see the following table:</p> Token Meaning &lt; &gt; name of a syntactic element ::= formula that defines an element [ ] optional elements { } explicitly specified elements | complete alternative elements ... may be repeated any number of times <p>For example, create vertices or edges in nGQL syntax:</p> <pre><code>CREATE {TAG | EDGE} {&lt;tag_name&gt; | &lt;edge_type&gt;}(&lt;property_name&gt; &lt;data_type&gt;\n[, &lt;property_name&gt; &lt;data_type&gt; ...]);\n</code></pre> <p>Example statement:</p> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS player(name string, age int);\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#about_opencypher_compatibility","title":"About openCypher compatibility","text":""},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#native_ngql_and_opencypher","title":"Native nGQL and openCypher","text":"<p>Native nGQL is the part of a graph query language designed and implemented by NebulaGraph. OpenCypher is a graph query language maintained by openCypher Implementers Group.</p> <p>The latest release is openCypher 9. The compatible parts of openCypher in nGQL are called openCypher compatible sentences (short as openCypher).</p> <p>Note</p> <p><code>nGQL</code> = <code>native nGQL</code> + <code>openCypher compatible sentences</code></p> <p>Undefined behavior</p> <p>Do not put together <code>native nGQL</code> and <code>openCypher compatible sentences</code> in one composite statement because this behavior is undefined.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#is_ngql_compatible_with_opencypher_9_completely","title":"Is nGQL compatible with openCypher 9 completely?","text":"<p>NO.</p> <p>nGQL is partially compatible with DQL in openCypher 9</p> <p>nGQL is designed to be compatible with part of DQL (match) and is not planned to be compatible with any DDL, DML, or DCL.</p> <p>Multiple known incompatible items are listed in NebulaGraph Issues. Submit an issue with the <code>incompatible</code> tag if you find a new issue of this type. Users can search in this manual with the keyword <code>compatibility</code> to find major compatibility issues.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#what_are_the_major_differences_between_ngql_and_opencypher_9","title":"What are the major differences between nGQL and openCypher 9?","text":"<p>The following are some major differences (by design incompatible) between nGQL and openCypher.</p> Category openCypher 9 nGQL Schema Optional Schema Strong Schema Equality operator <code>=</code> <code>==</code> Math exponentiation <code>^</code> <code>^</code> not supported. Use pow(x, y) instead. Edge rank no such concept edge rank (reference by @) Statement - All DMLs (<code>CREATE</code>, <code>MERGE</code>, etc) of openCypher 9, and <code>OPTIONAL MATCH</code> are not supported. Label and tag A label is used for searching a vertex, namely an index of vertex. A tag defines the type of a vertex and its corresponding properties. It cannot be used as an index. Pre-compiling and parameterized query support not supported <p>Compatibility</p> <p>OpenCypher 9 and Cypher have some differences in grammar and licence. For example,</p> <ol> <li> <p>Cypher requires that All Cypher statements are explicitly run within a transaction. While openCypher has no such requirement. And nGQL does not support transactions.</p> </li> <li> <p>Cypher has a variety of constraints, including Unique node property constraints, Node property existence constraints, Relationship property existence constraints, and Node key constraints. While OpenCypher has no such constraints. As a strong schema system, most of the constraints mentioned above can be solved through schema definitions (including NOT NULL) in nGQL. The only function that cannot be supported is the UNIQUE constraint.</p> </li> <li> <p>Cypher has APoC, while openCypher 9 does not have APoC. Cypher has Blot protocol support requirements, while openCypher 9 does not.</p> </li> </ol>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#where_can_i_find_more_ngql_examples","title":"Where can I find more nGQL examples?","text":"<p>Users can find more than 2500 nGQL examples in the features directory on the NebulaGraph GitHub page.</p> <p>The <code>features</code> directory consists of <code>.feature</code> files. Each file records scenarios that you can use as nGQL examples. Here is an example:</p> <pre><code>Feature: Basic match\n\n  Background:\n    Given a graph with space named \"basketballplayer\"\n\n  Scenario: Single node\n    When executing query:\n      \"\"\"\n      MATCH (v:player {name: \"Yao Ming\"}) RETURN v;\n      \"\"\"\n    Then the result should be, in any order, with relax comparison:\n      | v                                                |\n      | (\"player133\" :player{age: 38, name: \"Yao Ming\"}) |\n\n  Scenario: One step\n    When executing query:\n      \"\"\"\n      MATCH (v1:player{name: \"LeBron James\"}) -[r]-&gt; (v2)\n      RETURN type(r) AS Type, v2.name AS Name\n      \"\"\"\n    Then the result should be, in any order:\n\n      | Type     | Name        |\n      | \"follow\" | \"Ray Allen\" |\n      | \"serve\"  | \"Lakers\"    |\n      | \"serve\"  | \"Heat\"      |\n      | \"serve\"  | \"Cavaliers\" |\n\nFeature:  Comparison of where clause\n\n  Background:\n    Given a graph with space named \"basketballplayer\"\n\n    Scenario: push edge props filter down\n      When profiling query:\n        \"\"\"\n        GO FROM \"player100\" OVER follow \n        WHERE follow.degree IN [v IN [95,99] WHERE v &gt; 0] \n        YIELD dst(edge), properties(edge).degree\n        \"\"\"\n      Then the result should be, in any order:\n        | follow._dst | follow.degree |\n        | \"player101\" | 95            |\n        | \"player125\" | 95            |\n      And the execution plan should be:\n        | id | name         | dependencies | operator info                                               |\n        | 0  | Project      | 1            |                                                             |\n        | 1  | GetNeighbors | 2            | {\"filter\": \"(properties(edge).degree IN [v IN [95,99] WHERE (v&gt;0)])\"} |\n        | 2  | Start        |              |                                                             |\n</code></pre> <p>The keywords in the preceding example are described as follows.</p> Keyword Description <code>Feature</code> Describes the topic of the current <code>.feature</code> file. <code>Background</code> Describes the background information of the current <code>.feature</code> file. <code>Given</code> Describes the prerequisites of running the test statements in the current <code>.feature</code> file. <code>Scenario</code> Describes the scenarios. If there is the <code>@skip</code> before one <code>Scenario</code>, this scenario may not work and do not use it as a working example in a production environment. <code>When</code> Describes the nGQL statement to be executed. It can be a <code>executing query</code> or <code>profiling query</code>. <code>Then</code> Describes the expected return results of running the statement in the <code>When</code> clause. If the return results in your environment do not match the results described in the <code>.feature</code> file, submit an issue to inform the NebulaGraph team. <code>And</code> Describes the side effects of running the statement in the <code>When</code> clause. <code>@skip</code> This test case will be skipped. Commonly, the to-be-tested code is not ready. <p>Welcome to add more tck case and return automatically to the using statements in CI/CD.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#does_it_support_tinkerpop_gremlin","title":"Does it support TinkerPop Gremlin?","text":"<p>No. And no plan to support that.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/1.overview/#does_nebulagraph_support_w3c_rdf_sparql_or_graphql","title":"Does NebulaGraph support W3C RDF (SPARQL) or GraphQL?","text":"<p>No. And no plan to support that.</p> <p>The data model of NebulaGraph is the property graph. And as a strong schema system, NebulaGraph does not support RDF.</p> <p>NebulaGraph Query Language does not support <code>SPARQL</code> nor <code>GraphQL</code>.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/","title":"Patterns","text":"<p>Patterns and graph pattern matching are the very heart of a graph query language. This topic will describe the patterns in NebulaGraph, some of which have not yet been implemented.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#patterns_for_vertices","title":"Patterns for vertices","text":"<p>A vertex is described using a pair of parentheses and is typically given a name. For example:</p> <pre><code>(a)\n</code></pre> <p>This simple pattern describes a single vertex and names that vertex using the variable <code>a</code>.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#patterns_for_related_vertices","title":"Patterns for related vertices","text":"<p>A more powerful construct is a pattern that describes multiple vertices and edges between them. Patterns describe an edge by employing an arrow between two vertices. For example:</p> <pre><code>(a)-[]-&gt;(b)\n</code></pre> <p>This pattern describes a very simple data structure: two vertices and a single edge from one to the other. In this example, the two vertices are named as <code>a</code> and <code>b</code> respectively and the edge is <code>directed</code>: it goes from <code>a</code> to <code>b</code>.</p> <p>This manner of describing vertices and edges can be extended to cover an arbitrary number of vertices and the edges between them, for example:</p> <pre><code>(a)-[]-&gt;(b)&lt;-[]-(c)\n</code></pre> <p>Such a series of connected vertices and edges is called a <code>path</code>.</p> <p>Note that the naming of the vertices in these patterns is only necessary when one needs to refer to the same vertex again, either later in the pattern or elsewhere in the query. If not, the name may be omitted as follows:</p> <pre><code>(a)-[]-&gt;()&lt;-[]-(c)\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#patterns_for_tags","title":"Patterns for tags","text":"<p>Note</p> <p>The concept of <code>tag</code> in nGQL has a few differences from that of <code>label</code> in openCypher. For example, users must create a <code>tag</code> before using it. And a <code>tag</code> also defines the type of properties.</p> <p>In addition to simply describing the vertices in the graphs, patterns can also describe the tags of the vertices. For example:</p> <pre><code>(a:User)-[]-&gt;(b)\n</code></pre> <p>Patterns can also describe a vertex that has multiple tags. For example:</p> <pre><code>(a:User:Admin)-[]-&gt;(b)\n</code></pre> <p>OpenCypher compatibility</p> <p>The <code>MATCH</code> statement in nGQL does not support matching multiple tags with <code>(a:User:Admin)</code>. If users need to match multiple tags, use filtering conditions, such as <code>WHERE \"User\" IN tags(n) AND \"Admin\" IN tags(n)</code>.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#patterns_for_properties","title":"Patterns for properties","text":"<p>Vertices and edges are the fundamental elements in a graph. In nGQL, properties are added to them for richer models.</p> <p>In the patterns, the properties can be expressed as follows: some key-value pairs are enclosed in curly brackets and separated by commas. For example, a vertex with two properties will be like:</p> <pre><code>(a {name: 'Andres', sport: 'Brazilian Ju-Jitsu'})\n</code></pre> <p>One of the edges that connect to this vertex can be like:</p> <pre><code>(a)-[{blocked: false}]-&gt;(b)\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#patterns_for_edges","title":"Patterns for edges","text":"<p>The simplest way to describe an edge is by using the arrow between two vertices, as in the previous examples.</p> <p>Users can describe an edge and its direction using the following statement. If users do not care about its direction, the arrowhead can be omitted. For example:</p> <pre><code>(a)-[]-(b)\n</code></pre> <p>Like vertices, edges can also be named. A pair of square brackets will be used to separate the arrow and the variable will be placed between them. For example:</p> <pre><code>(a)-[r]-&gt;(b)\n</code></pre> <p>Like the tags on vertices, edges can also have types. To describe an edge with a specific type, use the pattern as follows:</p> <pre><code>(a)-[r:REL_TYPE]-&gt;(b)\n</code></pre> <p>An edge can only have one edge type. But if we'd like to describe some data such that the edge could have a set of types, then they can all be listed in the pattern, separating them with the pipe symbol <code>|</code> like this:</p> <pre><code>(a)-[r:TYPE1|TYPE2]-&gt;(b)\n</code></pre> <p>Like vertices, the name of an edge can be omitted. For example:</p> <pre><code>(a)-[:REL_TYPE]-&gt;(b)\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#variable-length_pattern","title":"Variable-length pattern","text":"<p>Rather than describing a long path using a sequence of many vertex and edge descriptions in a pattern, many edges (and the intermediate vertices) can be described by specifying a length in the edge description of a pattern. For example:</p> <pre><code>(a)-[*2]-&gt;(b)\n</code></pre> <p>The following pattern describes a graph of three vertices and two edges, all in one path (a path of length 2). It is equivalent to:</p> <pre><code>(a)-[]-&gt;()-[]-&gt;(b)\n</code></pre> <p>The range of lengths can also be specified. Such edge patterns are called <code>variable-length edges</code>. For example:</p> <pre><code>(a)-[*3..5]-&gt;(b)\n</code></pre> <p>The preceding example defines a path with a minimum length of 3 and a maximum length of 5.</p> <p>It describes a graph of either 4 vertices and 3 edges, 5 vertices and 4 edges, or 6 vertices and 5 edges, all connected in a single path.</p> <p>The lower bound can be omitted. For example, to describe paths of length 5 or less, use:</p> <pre><code>(a)-[*..5]-&gt;(b)\n</code></pre> <p>Note</p> <p>The upper bound must be specified. The following are NOT accepted.</p> <pre><code>(a)-[*3..]-&gt;(b)\n(a)-[*]-&gt;(b)\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/3.graph-patterns/#assigning_to_path_variables","title":"Assigning to path variables","text":"<p>As described above, a series of connected vertices and edges is called a <code>path</code>. nGQL allows paths to be named using variables. For example:</p> <pre><code>p = (a)-[*3..5]-&gt;(b)\n</code></pre> <p>Users can do this in the <code>MATCH</code> statement.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/comments/","title":"Comments","text":"<p>This topic will describe the comments in nGQL.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/comments/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<ul> <li>In NebulaGraph 1.x, there are four comment styles: <code>#</code>, <code>--</code>, <code>//</code>, <code>/* */</code>.</li> <li>In NebulaGraph 2.x, <code>--</code> cannot be used as comments.</li> </ul>"},{"location":"3.ngql-guide/1.nGQL-overview/comments/#examples","title":"Examples","text":"<pre><code>nebula&gt; # Do nothing in this line\nnebula&gt; RETURN 1+1;     # This comment continues to the end of this line.\nnebula&gt; RETURN 1+1;     // This comment continues to the end of this line.\nnebula&gt; RETURN 1 /* This is an in-line comment. */ + 1 == 2;\nnebula&gt; RETURN 11 +            \\\n/* Multi-line comment.       \\\nUse a backslash as a line break.   \\\n*/ 12;\n</code></pre> <p>In nGQL statement, the backslash <code>\\</code> in a line indicates a line break.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/comments/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>In nGQL, you must add a <code>\\</code> at the end of every line, even in multi-line comments <code>/* */</code>.</li> <li>In openCypher, there is no need to use a <code>\\</code> as a line break.</li> </ul> <pre><code>/* openCypher style:\nThe following comment\nspans more than\none line */\nMATCH (n:label)\nRETURN n;\n</code></pre> <pre><code>/* nGQL style:  \\\nThe following comment       \\\nspans more than     \\\none line */       \\\nMATCH (n:tag) \\\nRETURN n;\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/identifier-case-sensitivity/","title":"Identifier case sensitivity","text":""},{"location":"3.ngql-guide/1.nGQL-overview/identifier-case-sensitivity/#identifiers_are_case-sensitive","title":"Identifiers are Case-Sensitive","text":"<p>The following statements will not work because they refer to two different spaces, i.e. <code>my_space</code> and <code>MY_SPACE</code>.</p> <pre><code>nebula&gt; CREATE SPACE IF NOT EXISTS my_space (vid_type=FIXED_STRING(30));\nnebula&gt; use MY_SPACE;\n[ERROR (-8)]: SpaceNotFound:\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/identifier-case-sensitivity/#keywords_and_reserved_words_are_case-insensitive","title":"Keywords and Reserved Words are Case-Insensitive","text":"<p>The following statements are equivalent since <code>show</code> and <code>spaces</code> are keywords.</p> <pre><code>nebula&gt; show spaces;  \nnebula&gt; SHOW SPACES;\nnebula&gt; SHOW spaces;\nnebula&gt; show SPACES;\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/identifier-case-sensitivity/#functions_are_case-insensitive","title":"Functions are Case-Insensitive","text":"<p>Functions are case-insensitive. For example, <code>count()</code>, <code>COUNT()</code>, and <code>couNT()</code> are equivalent.</p> <pre><code>nebula&gt; WITH [NULL, 1, 1, 2, 2] As a \\\n        UNWIND a AS b \\\n        RETURN count(b), COUNT(*), couNT(DISTINCT b);\n+----------+----------+-------------------+\n| count(b) | COUNT(*) | couNT(distinct b) |\n+----------+----------+-------------------+\n| 4        | 5        | 2                 |\n+----------+----------+-------------------+\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/keywords-and-reserved-words/","title":"Keywords","text":"<p>Keywords have significance in nGQL. It can be classified into reserved keywords and non-reserved keywords.</p> <p>Non-reserved keywords are permitted as identifiers without quoting. To use reserved keywords as identifiers, quote them with backticks such as <code>AND</code>.</p> <p>Note</p> <p>Keywords are case-insensitive.</p> <pre><code>nebula&gt; CREATE TAG TAG(name string);\n[ERROR (-7)]: SyntaxError: syntax error near `TAG'\n\nnebula&gt; CREATE TAG `TAG` (name string);\nExecution succeeded\n\nnebula&gt; CREATE TAG SPACE(name string);\nExecution succeeded\n</code></pre> <ul> <li><code>TAG</code> is a reserved keyword. To use <code>TAG</code> as an identifier, you must quote it with backticks.</li> </ul> <ul> <li><code>SPACE</code> is a non-reserved keyword. You can use it as an identifier without quoting it.</li> </ul>"},{"location":"3.ngql-guide/1.nGQL-overview/keywords-and-reserved-words/#reserved_keywords","title":"Reserved keywords","text":"<pre><code>GO\nAS\nTO\nOR\nAND\nXOR\nUSE\nSET\nFROM\nWHERE\nMATCH\nINSERT\nYIELD\nRETURN\nDESCRIBE\nDESC\nVERTEX\nVERTICES\nEDGE\nEDGES\nUPDATE\nUPSERT\nWHEN\nDELETE\nFIND\nLOOKUP\nALTER\nSTEPS\nSTEP\nOVER\nUPTO\nREVERSELY\nINDEX\nINDEXES\nREBUILD\nBOOL\nINT8\nINT16\nINT32\nINT64\nINT\nFLOAT\nDOUBLE\nSTRING\nFIXED_STRING\nTIMESTAMP\nDATE\nTIME\nDATETIME\nTAG\nTAGS\nUNION\nINTERSECT\nMINUS\nNO\nOVERWRITE\nSHOW\nADD\nCREATE\nDROP\nREMOVE\nIF\nNOT\nEXISTS\nWITH\nCHANGE\nGRANT\nREVOKE\nON\nBY\nIN\nNOT_IN\nDOWNLOAD\nGET\nOF\nORDER\nINGEST\nCOMPACT\nFLUSH\nSUBMIT\nASC\nASCENDING\nDESCENDING\nDISTINCT\nFETCH\nPROP\nBALANCE\nSTOP\nLIMIT\nOFFSET\nIS\nNULL\nRECOVER\nEXPLAIN\nPROFILE\nFORMAT\nCASE\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/keywords-and-reserved-words/#non-reserved_keywords","title":"Non-reserved keywords","text":"<pre><code>HOST\nHOSTS\nSPACE\nSPACES\nVALUE\nVALUES\nUSER\nUSERS\nPASSWORD\nROLE\nROLES\nGOD\nADMIN\nDBA\nGUEST\nGROUP\nPARTITION_NUM\nREPLICA_FACTOR\nVID_TYPE\nCHARSET\nCOLLATE\nCOLLATION\nATOMIC_EDGE\nALL\nANY\nSINGLE\nNONE\nREDUCE\nLEADER\nUUID\nDATA\nSNAPSHOT\nSNAPSHOTS\nACCOUNT\nJOBS\nJOB\nPATH\nBIDIRECT\nSTATS\nSTATUS\nFORCE\nPART\nPARTS\nDEFAULT\nHDFS\nCONFIGS\nTTL_DURATION\nTTL_COL\nGRAPH\nMETA\nSTORAGE\nSHORTEST\nNOLOOP\nOUT\nBOTH\nSUBGRAPH\nCONTAINS\nNOT_CONTAINS\nSTARTS\nSTARTS_WITH\nNOT_STARTS_WITH\nENDS\nENDS_WITH\nNOT_ENDS_WITH\nIS_NULL\nIS_NOT_NULL\nIS_EMPTY\nIS_NOT_EMPTY\nUNWIND\nSKIP\nOPTIONAL\nTHEN\nELSE\nEND\nGROUPS\nZONE\nZONES\nINTO\nLISTENER\nELASTICSEARCH\nFULLTEXT\nAUTO\nFUZZY\nPREFIX\nREGEXP\nWILDCARD\nTEXT\nSEARCH\nCLIENTS\nSIGN\nSERVICE\nTEXT_SEARCH\nRESET\nPLAN\nCOMMENT\nSESSIONS\nSESSION\nSAMPLE\nQUERIES\nQUERY\nKILL\nTOP\nTRUE\nFALSE\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/ngql-style-guide/","title":"nGQL style guide","text":"<p>nGQL does not have strict formatting requirements, but creating nGQL statements according to an appropriate and uniform style can improve readability and avoid ambiguity. Using the same nGQL style in the same organization or project helps reduce maintenance costs and avoid problems caused by format confusion or misunderstanding. This topic will provide a style guide for writing nGQL statements.</p> <p>Compatibility</p> <p>The styles of nGQL and Cypher Style Guide are different.</p>"},{"location":"3.ngql-guide/1.nGQL-overview/ngql-style-guide/#newline","title":"Newline","text":"<ol> <li> <p>Start a new line to write a clause.</p> <p>Not recommended:</p> <pre><code>GO FROM \"player100\" OVER follow REVERSELY YIELD src(edge) AS id;\n</code></pre> <p>Recommended:</p> <pre><code>GO FROM \"player100\" \\\nOVER follow REVERSELY \\\nYIELD src(edge) AS id;\n</code></pre> </li> <li> <p>Start a new line to write different statements in a composite statement.</p> <p>Not recommended:</p> <pre><code>GO FROM \"player100\" OVER follow REVERSELY YIELD src(edge) AS id | GO FROM $-.id \\\nOVER serve WHERE $^.player.age &gt; 20 YIELD properties($^).name AS FriendOf, properties($$).name AS Team;\n</code></pre> <p>Recommended:</p> <pre><code>GO FROM \"player100\" \\\nOVER follow REVERSELY \\\nYIELD src(edge) AS id | \\\nGO FROM $-.id OVER serve \\\nWHERE $^.player.age &gt; 20 \\\nYIELD properties($^).name AS FriendOf, properties($$).name AS Team;\n</code></pre> </li> <li> <p>If the clause exceeds 80 characters, start a new line at the appropriate place.</p> <p>Not recommended:</p> <pre><code>MATCH (v:player{name:\"Tim Duncan\"})-[e]-&gt;(v2) \\\nWHERE (v2.name STARTS WITH \"Y\" AND v2.age &gt; 35 AND v2.age &lt; v.age) OR (v2.name STARTS WITH \"T\" AND v2.age &lt; 45 AND v2.age &gt; v.age) \\\nRETURN v2;\n</code></pre> <p>Recommended:</p> <pre><code>MATCH (v:player{name:\"Tim Duncan\"})-[e]-&gt;(v2) \\\nWHERE (v2.name STARTS WITH \"Y\" AND v2.age &gt; 35 AND v2.age &lt; v.age) \\\nOR (v2.name STARTS WITH \"T\" AND v2.age &lt; 45 AND v2.age &gt; v.age) \\\nRETURN v2;\n</code></pre> </li> </ol> <p>Note</p> <p>If needed, you can also start a new line for better understanding, even if the clause does not exceed 80 characters. </p>"},{"location":"3.ngql-guide/1.nGQL-overview/ngql-style-guide/#identifier_naming","title":"Identifier naming","text":"<p>In nGQL statements, characters other than keywords, punctuation marks, and blanks are all identifiers. Recommended methods to name the identifiers are as follows.</p> <ol> <li> <p>Use singular nouns to name tags, and use the base form of verbs or verb phrases to form Edge types.</p> <p>Not recommended:</p> <pre><code>MATCH p=(v:players)-[e:are_following]-(v2) \\\nRETURN nodes(p);\n</code></pre> <p>Recommended:</p> <pre><code>MATCH p=(v:player)-[e:follow]-(v2) \\\nRETURN nodes(p);\n</code></pre> </li> <li> <p>Use the snake case to name identifiers, and connect words with underscores (_) with all the letters lowercase.</p> <p>Not recommended:</p> <pre><code>MATCH (v:basketballTeam) \\\nRETURN v;\n</code></pre> <p>Recommended:</p> <pre><code>MATCH (v:basketball_team) \\\nRETURN v;\n</code></pre> </li> <li> <p>Use uppercase keywords and lowercase variables.</p> <p>Not recommended:</p> <pre><code>go from \"player100\" over Follow\n</code></pre> <p>Recommended:</p> <pre><code>GO FROM \"player100\" OVER follow\n</code></pre> </li> </ol>"},{"location":"3.ngql-guide/1.nGQL-overview/ngql-style-guide/#pattern","title":"Pattern","text":"<ol> <li> <p>Start a new line on the right side of the arrow indicating an edge when writing patterns.</p> <p>Not recommended:</p> <pre><code>MATCH (v:player{name: \"Tim Duncan\", age: 42}) \\\n-[e:follow]-&gt;()-[e:serve]-&gt;()&lt;--(v3) \\\nRETURN v, e, v2;\n</code></pre> <p>Recommended:</p> <pre><code>MATCH (v:player{name: \"Tim Duncan\", age: 42})-[e:follow]-&gt; \\\n()-[e:serve]-&gt;()&lt;--(v3) \\\nRETURN v, e, v2;\n</code></pre> </li> <li> <p>Anonymize the vertices and edges that do not need to be queried.</p> <p>Not recommended:</p> <pre><code>MATCH (v:player)-[e:follow]-&gt;(v2) \\\nRETURN v;\n</code></pre> <p>Recommended:</p> <pre><code>MATCH (v:player)-[:follow]-&gt;() \\\nRETURN v;\n</code></pre> </li> <li> <p>Place named vertices in front of anonymous vertices.</p> <p>Not recommended:</p> <pre><code>MATCH ()-[:follow]-&gt;(v) \\\nRETURN v;\n</code></pre> <p>Recommended:</p> <pre><code>MATCH (v)&lt;-[:follow]-() \\\nRETURN v;\n</code></pre> </li> </ol>"},{"location":"3.ngql-guide/1.nGQL-overview/ngql-style-guide/#string","title":"String","text":"<p>The strings should be surrounded by double quotes.</p> <p>Not recommended:</p> <pre><code>RETURN 'Hello Nebula!';\n</code></pre> <p>Recommended:</p> <pre><code>RETURN \"Hello Nebula!\\\"123\\\"\";\n</code></pre> <p>Note</p> <p>When single or double quotes need to be nested in a string, use a backslash () to escape. For example:</p> <pre><code>RETURN \"\\\"NebulaGraph is amazing,\\\" the user says.\";\n</code></pre>"},{"location":"3.ngql-guide/1.nGQL-overview/ngql-style-guide/#statement_termination","title":"Statement termination","text":"<ol> <li> <p>End the nGQL statements with an English semicolon (;).</p> <p>Not recommended:</p> <pre><code>FETCH PROP ON player \"player100\"\n</code></pre> <p>Recommended:</p> <pre><code>FETCH PROP ON player \"player100\";\n</code></pre> </li> <li> <p>Use a pipe (|) to separate a composite statement, and end the statement with an English semicolon at the end of the last line. Using an English semicolon before a pipe will cause the statement to fail.</p> <p>Not supported:</p> <pre><code>GO FROM \"player100\" \\\nOVER follow \\\nYIELD dst(edge) AS id; | \\\nGO FROM $-.id \\\nOVER serve \\\nYIELD properties($$).name AS Team, properties($^).name AS Player;\n</code></pre> <p>Supported:</p> <pre><code>GO FROM \"player100\" \\\nOVER follow \\\nYIELD dst(edge) AS id | \\\nGO FROM $-.id \\\nOVER serve \\\nYIELD properties($$).name AS Team, properties($^).name AS Player;\n</code></pre> </li> <li> <p>In a composite statement that contains user-defined variables, use an English semicolon to end the statements that define the variables. If you do not follow the rules to add a semicolon or use a pipe to end the composite statement, the execution will fail.</p> <p>Not supported:</p> <pre><code>$var = GO FROM \"player100\" \\\nOVER follow \\\nYIELD follow._dst AS id \\\nGO FROM $var.id \\\nOVER serve \\\nYIELD $$.team.name AS Team, $^.player.name AS Player;\n</code></pre> <p>Not supported:</p> <pre><code>$var = GO FROM \"player100\" \\\nOVER follow \\\nYIELD follow._dst AS id | \\\nGO FROM $var.id \\\nOVER serve \\\nYIELD $$.team.name AS Team, $^.player.name AS Player;\n</code></pre> <p>Supported:</p> <pre><code>$var = GO FROM \"player100\" \\\nOVER follow \\\nYIELD follow._dst AS id; \\\nGO FROM $var.id \\\nOVER serve \\\nYIELD $$.team.name AS Team, $^.player.name AS Player;\n</code></pre> </li> </ol>"},{"location":"3.ngql-guide/10.tag-statements/1.create-tag/","title":"CREATE TAG","text":"<p><code>CREATE TAG</code> creates a tag with the given name in a graph space.</p>"},{"location":"3.ngql-guide/10.tag-statements/1.create-tag/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>Tags in nGQL are similar to labels in openCypher. But they are also quite different. For example, the ways to create them are different.</p> <ul> <li>In openCypher, labels are created together with vertices in <code>CREATE</code> statements.</li> <li>In nGQL, tags are created separately using <code>CREATE TAG</code> statements. Tags in nGQL are more like tables in MySQL.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/1.create-tag/#prerequisites","title":"Prerequisites","text":"<p>Running the <code>CREATE TAG</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/10.tag-statements/1.create-tag/#syntax","title":"Syntax","text":"<p>To create a tag in a specific graph space, you must specify the current working space with the <code>USE</code> statement.</p> <pre><code>CREATE TAG [IF NOT EXISTS] &lt;tag_name&gt;\n    (\n      &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;']\n      [{, &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;']} ...] \n    )\n    [TTL_DURATION = &lt;ttl_duration&gt;]\n    [TTL_COL = &lt;prop_name&gt;]\n    [COMMENT = '&lt;comment&gt;'];\n</code></pre> Parameter Description <code>IF NOT EXISTS</code> Detects if the tag that you want to create exists. If it does not exist, a new one will be created. The tag existence detection here only compares the tag names (excluding properties). <code>&lt;tag_name&gt;</code> The tag name must be unique in a graph space. Once the tag name is set, it can not be altered. The rules for permitted tag names are the same as those for graph space names. For prohibited names, see Keywords and reserved words. <code>&lt;prop_name&gt;</code> The name of the property. It must be unique for each tag. The rules for permitted property names are the same as those for tag names. <code>&lt;data_type&gt;</code> Shows the data type of each property. For a full description of the property data types, see Data types and Boolean. <code>NULL \\| NOT NULL</code> Specifies if the property supports <code>NULL | NOT NULL</code>. The default value is <code>NULL</code>. <code>DEFAULT</code> Specifies a default value for a property. The default value can be a literal value or an expression supported by NebulaGraph. If no value is specified, the default value is used when inserting a new vertex. <code>COMMENT</code> The remarks of a certain property or the tag itself. The maximum length is 256 bytes. By default, there will be no comments on a tag. <code>TTL_DURATION</code> Specifies the life cycle for the property. The property that exceeds the specified TTL expires. The expiration threshold is the <code>TTL_COL</code> value plus the <code>TTL_DURATION</code>. The default value of <code>TTL_DURATION</code> is <code>0</code>. It means the data never expires. <code>TTL_COL</code> Specifies the property to set a timeout on. The data type of the property must be <code>int</code> or <code>timestamp</code>. A tag can only specify one field as <code>TTL_COL</code>. For more information on TTL, see TTL options."},{"location":"3.ngql-guide/10.tag-statements/1.create-tag/#examples","title":"Examples","text":"<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS player(name string, age int);\n\n# The following example creates a tag with no properties.\nnebula&gt; CREATE TAG IF NOT EXISTS no_property();\u00a0\n\n# The following example creates a tag with a default value.\nnebula&gt; CREATE TAG IF NOT EXISTS player_with_default(name string, age int DEFAULT 20);\n\n# In the following example, the TTL of the create_time field is set to be 100 seconds.\nnebula&gt; CREATE TAG IF NOT EXISTS woman(name string, age int, \\\n        married bool, salary double, create_time timestamp) \\\n        TTL_DURATION = 100, TTL_COL = \"create_time\";\n</code></pre>"},{"location":"3.ngql-guide/10.tag-statements/1.create-tag/#implementation_of_the_operation","title":"Implementation of the operation","text":"<p>Trying to use a newly created tag may fail because the creation of the tag is implemented asynchronously. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds.</p> <p>To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> parameter in the configuration files for all services.</p>"},{"location":"3.ngql-guide/10.tag-statements/2.drop-tag/","title":"DROP TAG","text":"<p><code>DROP TAG</code> drops a tag with the given name in the current working graph space.</p> <p>A vertex can have one or more tags.</p> <ul> <li>If a vertex has only one tag, the vertex CANNOT be accessed after you drop it. But its edges are available. The vertex will be dropped in the next compaction.</li> </ul> <ul> <li>If a vertex has multiple tags, the vertex is still accessible after you drop one of them. But all the properties defined by this dropped tag CANNOT be accessed.</li> </ul> <p>This operation only deletes the Schema data. All the files or directories in the disk will not be deleted directly until the next compaction.</p>"},{"location":"3.ngql-guide/10.tag-statements/2.drop-tag/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running the <code>DROP TAG</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</li> </ul> <ul> <li>Before you drop a tag, make sure that the tag does not have any indexes. Otherwise, the conflict error (<code>[ERROR (-8)]: Conflict!</code>) will be returned when you run the <code>DROP TAG</code> statement. To drop an index, see DROP INDEX.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/2.drop-tag/#syntax","title":"Syntax","text":"<pre><code>DROP TAG [IF EXISTS] &lt;tag_name&gt;;\n</code></pre> <ul> <li><code>IF NOT EXISTS</code>: Detects if the tag that you want to drop exists. Only when it exists will it be dropped.</li> </ul> <ul> <li><code>tag_name</code>: Specifies the tag name that you want to drop. You can drop only one tag in one statement.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/2.drop-tag/#example","title":"Example","text":"<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS test(p1 string, p2 int);\nnebula&gt; DROP TAG test;\n</code></pre> <p>Note</p> <p>In nGQL, there is no such statement to drop a certain tag of a vertex with the given name.</p> <ul> <li>In openCypher, you can use the statement <code>REMOVE v:LABEL</code> to drop the tag <code>LABLE</code> of the vertex <code>v</code>.</li> <li>In nGQL, after <code>CREATE TAG</code> and <code>INSERT VERTEX</code>, you can add a <code>TAG</code> on the vertex. But there is no way to drop the <code>TAG</code> afterward.</li> </ul> <p>We recommend you to add a field to identify the logical deletion in the schema. For example, add <code>removed</code> to the schema of each tag.</p>"},{"location":"3.ngql-guide/10.tag-statements/3.alter-tag/","title":"ALTER TAG","text":"<p><code>ALTER TAG</code> alters the structure of a tag with the given name in a graph space. You can add or drop properties, and change the data type of an existing property. You can also set a TTL (Time-To-Live) on a property, or change its TTL duration.</p>"},{"location":"3.ngql-guide/10.tag-statements/3.alter-tag/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running the <code>ALTER TAG</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</li> </ul> <ul> <li>Before you alter properties for a tag, make sure that the properties are not indexed. If the properties contain any indexes, the conflict error <code>[ERROR (-8)]: Conflict!</code> will occur when you <code>ALTER TAG</code>. For more information on dropping an index, see DROP INDEX.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/3.alter-tag/#syntax","title":"Syntax","text":"<pre><code>ALTER TAG &lt;tag_name&gt;\n    &lt;alter_definition&gt; [[, alter_definition] ...]\n    [ttl_definition [, ttl_definition] ... ]\n    [COMMENT = '&lt;comment&gt;'];\n\nalter_definition:\n| ADD    (prop_name data_type)\n| DROP   (prop_name)\n| CHANGE (prop_name data_type)\n\nttl_definition:\n    TTL_DURATION = ttl_duration, TTL_COL = prop_name\n</code></pre> <ul> <li><code>tag_name</code>: Specifies the tag name that you want to alter. You can alter only one tag in one statement. Before you alter a tag, make sure that the tag exists in the current working graph space. If the tag does not exist, an error will occur when you alter it.</li> </ul> <ul> <li>Multiple <code>ADD</code>, <code>DROP</code>, and <code>CHANGE</code> clauses are permitted in a single <code>ALTER TAG</code> statement, separated by commas.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/3.alter-tag/#examples","title":"Examples","text":"<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS t1 (p1 string, p2 int);\nnebula&gt; ALTER TAG t1 ADD (p3 int, p4 string);\nnebula&gt; ALTER TAG t1 TTL_DURATION = 2, TTL_COL = \"p2\";\nnebula&gt; ALTER TAG t1 COMMENT = 'test1';\n</code></pre>"},{"location":"3.ngql-guide/10.tag-statements/3.alter-tag/#implementation_of_the_operation","title":"Implementation of the operation","text":"<p>Trying to use a newly altered tag may fail because the alteration of the tag is implemented asynchronously. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds.</p> <p>To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> parameter in the configuration files for all services.</p>"},{"location":"3.ngql-guide/10.tag-statements/4.show-tags/","title":"SHOW TAGS","text":"<p>The <code>SHOW TAGS</code> statement shows the name of all tags in the current graph space.</p> <p>You do not need any privileges for the graph space to run the <code>SHOW TAGS</code> statement. But the returned results are different based on role privileges.</p>"},{"location":"3.ngql-guide/10.tag-statements/4.show-tags/#syntax","title":"Syntax","text":"<pre><code>SHOW TAGS;\n</code></pre>"},{"location":"3.ngql-guide/10.tag-statements/4.show-tags/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW TAGS;\n+----------+\n| Name     |\n+----------+\n| \"player\" |\n| \"team\"   |\n+----------+\n</code></pre>"},{"location":"3.ngql-guide/10.tag-statements/5.describe-tag/","title":"DESCRIBE TAG","text":"<p><code>DESCRIBE TAG</code> returns the information about a tag with the given name in a graph space, such as field names, data type, and so on.</p>"},{"location":"3.ngql-guide/10.tag-statements/5.describe-tag/#prerequisite","title":"Prerequisite","text":"<p>Running the <code>DESCRIBE TAG</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/10.tag-statements/5.describe-tag/#syntax","title":"Syntax","text":"<pre><code>DESC[RIBE] TAG &lt;tag_name&gt;;\n</code></pre> <p>You can use <code>DESC</code> instead of <code>DESCRIBE</code> for short.</p>"},{"location":"3.ngql-guide/10.tag-statements/5.describe-tag/#example","title":"Example","text":"<pre><code>nebula&gt; DESCRIBE TAG player;\n+--------+----------+-------+---------+---------+\n| Field  | Type     | Null  | Default | Comment |\n+--------+----------+-------+---------+---------+\n| \"name\" | \"string\" | \"YES\" |         |         |\n| \"age\"  | \"int64\"  | \"YES\" |         |         |\n+--------+----------+-------+---------+---------+\n</code></pre>"},{"location":"3.ngql-guide/10.tag-statements/6.delete-tag/","title":"DELETE TAG","text":"<p><code>DELETE TAG</code> deletes a tag with the given name on a specified vertex.</p> <p>A vertex can have one or more tags.</p> <ul> <li>If a vertex has only one tag, the vertex CANNOT be accessed after you delete the tag. But its edges are available. The vertex will be deleted in the next compaction.</li> </ul> <ul> <li>If a vertex has multiple tags, the vertex is still accessible after you delete one of them. But all the properties defined by this deleted tag CANNOT be accessed.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/6.delete-tag/#prerequisites","title":"Prerequisites","text":"<p>Running the <code>DELETE TAG</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/10.tag-statements/6.delete-tag/#syntax","title":"Syntax","text":"<pre><code>DELETE TAG &lt;tag_name_list&gt; FROM &lt;VID&gt;;\n</code></pre> <ul> <li><code>tag_name_list</code>: Specifies the name of the tag. Multiple tags are separated with commas (,). <code>*</code> means all tags.</li> </ul> <ul> <li><code>VID</code>: Specifies the VID of the tag to delete.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/6.delete-tag/#example","title":"Example","text":"<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS test1(p1 string, p2 int);\nnebula&gt; CREATE TAG IF NOT EXISTS test2(p3 string, p4 int);\nnebula&gt; INSERT VERTEX test1(p1, p2),test2(p3, p4) VALUES \"test\":(\"123\", 1, \"456\", 2);\nnebula&gt; FETCH PROP ON * \"test\";\n+------------------------------------------------------------+\n| vertices_                                                  |\n+------------------------------------------------------------+\n| (\"test\" :test2{p3: \"456\", p4: 2} :test1{p1: \"123\", p2: 1}) |\n+------------------------------------------------------------+\n\nnebula&gt; DELETE TAG test1 FROM \"test\";\nnebula&gt; FETCH PROP ON * \"test\";\n+-----------------------------------+\n| vertices_                         |\n+-----------------------------------+\n| (\"test\" :test2{p3: \"456\", p4: 2}) |\n+-----------------------------------+\n\nnebula&gt; DELETE TAG * FROM \"test\";\nnebula&gt; FETCH PROP ON * \"test\";\n+-----------+\n| vertices_ |\n+-----------+\n+-----------+\n</code></pre> <p>Compatibility</p> <ul> <li>In openCypher, you can use the statement <code>REMOVE v:LABEL</code> to delete the tag <code>LABEL</code> of the vertex <code>v</code>.</li> <li><code>DELETE TAG</code> and <code>DROP TAG</code> have the same semantics but different syntax. In nGQL, use <code>DELETE TAG</code>.</li> </ul>"},{"location":"3.ngql-guide/10.tag-statements/improve-query-by-tag-index/","title":"Add and delete tags","text":"<p>OpenCypher has the features of <code>SET label</code> and <code>REMOVE label</code> to speed up the process of querying or labeling.</p> <p>NebulaGraph achieves the same operations by creating and inserting tags to an existing vertex, which can quickly query vertices based on the tag name. Users can also run <code>DELETE TAG</code> to delete some vertices that are no longer needed.</p> <p>Caution</p> <p>Make sure that there is another tag on the vertex. Otherwise, the vertex will be deleted when the last tag is deleted.</p>"},{"location":"3.ngql-guide/10.tag-statements/improve-query-by-tag-index/#examples","title":"Examples","text":"<p>For example, in the <code>basketballplayer</code> data set, some basketball players are also team shareholders. Users can create an index for the shareholder tag <code>shareholder</code> for quick search. If the player is no longer a shareholder, users can delete the shareholder tag of the corresponding player by <code>DELETE TAG</code>.</p> <pre><code>//This example creates the shareholder tag and index.\nnebula&gt; CREATE TAG IF NOT EXISTS shareholder();\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS shareholder_tag on shareholder();\n\n//This example adds a tag on the vertex.\nnebula&gt; INSERT VERTEX shareholder() VALUES \"player100\":();\nnebula&gt; INSERT VERTEX shareholder() VALUES \"player101\":();\n\n//This example queries all the shareholders.\nnebula&gt; MATCH (v:shareholder) RETURN v;\n+--------------------------------------------------------------------+\n| v                                                                  |\n+--------------------------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"} :shareholder{})  |\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"} :shareholder{}) |\n+--------------------------------------------------------------------+\nnebula&gt; LOOKUP ON shareholder;\n+-------------+\n| VertexID    |\n+-------------+\n| \"player100\" |\n| \"player101\" |\n+-------------+\n\n//In this example, the \"player100\" is no longer a shareholder.\nnebula&gt; DELETE TAG shareholder FROM \"player100\";\nnebula&gt; LOOKUP ON shareholder;\n+-------------+\n| VertexID    |\n+-------------+\n| \"player101\" |\n+-------------+\n</code></pre> <p>Note</p> <p>If the index is created after inserting the test data, use the <code>REBUILD TAG INDEX &lt;index_name_list&gt;;</code> statement to rebuild the index.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/1.create-edge/","title":"CREATE EDGE","text":"<p><code>CREATE EDGE</code> creates an edge type with the given name in a graph space.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/1.create-edge/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>Edge types in nGQL are similar to relationship types in openCypher. But they are also quite different. For example, the ways to create them are different.</p> <ul> <li>In openCypher, relationship types are created together with vertices in <code>CREATE</code> statements.</li> <li>In nGQL, edge types are created separately using <code>CREATE EDGE</code> statements. Edge types in nGQL are more like tables in MySQL.</li> </ul>"},{"location":"3.ngql-guide/11.edge-type-statements/1.create-edge/#prerequisites","title":"Prerequisites","text":"<p>Running the <code>CREATE EDGE</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/1.create-edge/#syntax","title":"Syntax","text":"<p>To create an edge type in a specific graph space, you must specify the current working space with the <code>USE</code> statement.</p> <pre><code>CREATE EDGE [IF NOT EXISTS] &lt;edge_type_name&gt;\n    (\n      &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;']\n      [{, &lt;prop_name&gt; &lt;data_type&gt; [NULL | NOT NULL] [DEFAULT &lt;default_value&gt;] [COMMENT '&lt;comment&gt;']} ...] \n    )\n    [TTL_DURATION = &lt;ttl_duration&gt;]\n    [TTL_COL = &lt;prop_name&gt;]\n    [COMMENT = '&lt;comment&gt;'];\n</code></pre> Parameter Description <code>IF NOT EXISTS</code> Detects if the edge type that you want to create exists. If it does not exist, a new one will be created. The edge type existence detection here only compares the edge type names (excluding properties). <code>&lt;edge_type_name&gt;</code> The edge type name must be unique in a graph space. Once the edge type name is set, it can not be altered. The rules for permitted edge type names are the same as those for graph space names. For prohibited names, see Keywords and reserved words. <code>&lt;prop_name&gt;</code> The name of the property. It must be unique for each edge type. The rules for permitted property names are the same as those for edge type names. <code>&lt;data_type&gt;</code> Shows the data type of each property. For a full description of the property data types, see Data types and Boolean. <code>NULL \\| NOT NULL</code> Specifies if the property supports <code>NULL | NOT NULL</code>. The default value is <code>NULL</code>. <code>DEFAULT</code> Specifies a default value for a property. The default value can be a literal value or an expression supported by NebulaGraph. If no value is specified, the default value is used when inserting a new edge. <code>COMMENT</code> The remarks of a certain property or the edge type itself. The maximum length is 256 bytes. By default, there will be no comments on an edge type. <code>TTL_DURATION</code> Specifies the life cycle for the property. The property that exceeds the specified TTL expires. The expiration threshold is the <code>TTL_COL</code> value plus the <code>TTL_DURATION</code>. The default value of <code>TTL_DURATION</code> is <code>0</code>. It means the data never expires. <code>TTL_COL</code> Specifies the property to set a timeout on. The data type of the property must be <code>int</code> or <code>timestamp</code>. An edge type can only specify one field as <code>TTL_COL</code>. For more information on TTL, see TTL options."},{"location":"3.ngql-guide/11.edge-type-statements/1.create-edge/#examples","title":"Examples","text":"<pre><code>nebula&gt; CREATE EDGE IF NOT EXISTS follow(degree int);\n\n# The following example creates an edge type with no properties.\nnebula&gt; CREATE EDGE IF NOT EXISTS no_property();\n\n# The following example creates an edge type with a default value.\nnebula&gt; CREATE EDGE IF NOT EXISTS follow_with_default(degree int DEFAULT 20);\n\n# In the following example, the TTL of the p2 field is set to be 100 seconds.\nnebula&gt; CREATE EDGE IF NOT EXISTS e1(p1 string, p2 int, p3 timestamp) \\\n        TTL_DURATION = 100, TTL_COL = \"p2\";\n</code></pre>"},{"location":"3.ngql-guide/11.edge-type-statements/1.create-edge/#implementation_of_the_operation","title":"Implementation of the operation","text":"<p>Trying to use a newly created edge type may fail because the creation of the edge type is implemented asynchronously. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds.</p> <p>To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> parameter in the configuration files for all services.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/2.drop-edge/","title":"DROP EDGE","text":"<p><code>DROP EDGE</code> drops an edge type with the given name in a graph space.</p> <p>An edge can have only one edge type. After you drop it, the edge CANNOT be accessed. The edge will be deleted in the next compaction.</p> <p>This operation only deletes the Schema data. All the files or directories in the disk will not be deleted directly until the next compaction.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/2.drop-edge/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running the <code>DROP EDGE</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</li> </ul> <ul> <li>Before you drop an edge type, make sure that the edge type does not have any indexes. Otherwise, the conflict error (<code>[ERROR (-8)]: Conflict!</code>) will be returned. To drop an index, see DROP INDEX.</li> </ul>"},{"location":"3.ngql-guide/11.edge-type-statements/2.drop-edge/#syntax","title":"Syntax","text":"<pre><code>DROP EDGE [IF EXISTS] &lt;edge_type_name&gt;\n</code></pre>"},{"location":"3.ngql-guide/11.edge-type-statements/2.drop-edge/#edge_type_name","title":"Edge type name","text":"<ul> <li><code>IF NOT EXISTS</code>: Detects if the edge type that you want to drop exists. Only when it exists will it be dropped.</li> </ul> <ul> <li><code>edge_type_name</code>: Specifies the edge type name that you want to drop. You can drop only one edge type in one statement.</li> </ul>"},{"location":"3.ngql-guide/11.edge-type-statements/2.drop-edge/#example","title":"Example","text":"<pre><code>nebula&gt; CREATE EDGE IF NOT EXISTS e1(p1 string, p2 int);\nnebula&gt; DROP EDGE e1;\n</code></pre>"},{"location":"3.ngql-guide/11.edge-type-statements/3.alter-edge/","title":"ALTER EDGE","text":"<p><code>ALTER EDGE</code> alters the structure of an edge type with the given name in a graph space. You can add or drop properties, and change the data type of an existing property. You can also set a TTL (Time-To-Live) on a property, or change its TTL duration.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/3.alter-edge/#prerequisites","title":"Prerequisites","text":"<ul> <li>Running the <code>ALTER EDGE</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</li> </ul> <ul> <li>Before you alter properties for an edge type, make sure that the properties are not indexed. If the properties contain any indexes, the conflict error <code>[ERROR (-8)]: Conflict!</code> will occur when you <code>ALTER EDGE</code>. For more information on dropping an index, see DROP INDEX.</li> </ul>"},{"location":"3.ngql-guide/11.edge-type-statements/3.alter-edge/#syntax","title":"Syntax","text":"<pre><code>ALTER EDGE &lt;edge_type_name&gt;\n    &lt;alter_definition&gt; [, alter_definition] ...]\n    [ttl_definition [, ttl_definition] ... ]\n    [COMMENT = '&lt;comment&gt;'];\n\nalter_definition:\n| ADD    (prop_name data_type)\n| DROP   (prop_name)\n| CHANGE (prop_name data_type)\n\nttl_definition:\n    TTL_DURATION = ttl_duration, TTL_COL = prop_name\n</code></pre> <ul> <li><code>edge_type_name</code>: Specifies the edge type name that you want to alter. You can alter only one edge type in one statement. Before you alter an edge type, make sure that the edge type exists in the graph space. If the edge type does not exist, an error occurs when you alter it.</li> </ul> <ul> <li>Multiple <code>ADD</code>, <code>DROP</code>, and <code>CHANGE</code> clauses are permitted in a single <code>ALTER EDGE</code> statement, separated by commas.</li> </ul>"},{"location":"3.ngql-guide/11.edge-type-statements/3.alter-edge/#example","title":"Example","text":"<pre><code>nebula&gt; CREATE EDGE IF NOT EXISTS e1(p1 string, p2 int);\nnebula&gt; ALTER EDGE e1 ADD (p3 int, p4 string);\nnebula&gt; ALTER EDGE e1 TTL_DURATION = 2, TTL_COL = \"p2\";\nnebula&gt; ALTER EDGE e1 COMMENT = 'edge1';\n</code></pre>"},{"location":"3.ngql-guide/11.edge-type-statements/3.alter-edge/#implementation_of_the_operation","title":"Implementation of the operation","text":"<p>Trying to use a newly altered edge type may fail because the alteration of the edge type is implemented asynchronously. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds.</p> <p>To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> parameter in the configuration files for all services.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/4.show-edges/","title":"SHOW EDGES","text":"<p><code>SHOW EDGES</code> shows all edge types in the current graph space.</p> <p>You do not need any privileges for the graph space to run the <code>SHOW EDGES</code> statement. But the returned results are different based on role privileges.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/4.show-edges/#syntax","title":"Syntax","text":"<pre><code>SHOW EDGES;\n</code></pre>"},{"location":"3.ngql-guide/11.edge-type-statements/4.show-edges/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW EDGES;\n+----------+\n| Name     |\n+----------+\n| \"follow\" |\n| \"serve\"  |\n+----------+\n</code></pre>"},{"location":"3.ngql-guide/11.edge-type-statements/5.describe-edge/","title":"DESCRIBE EDGE","text":"<p><code>DESCRIBE EDGE</code> returns the information about an edge type with the given name in a graph space, such as field names, data type, and so on.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/5.describe-edge/#prerequisites","title":"Prerequisites","text":"<p>Running the <code>DESCRIBE EDGE</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/5.describe-edge/#syntax","title":"Syntax","text":"<pre><code>DESC[RIBE] EDGE &lt;edge_type_name&gt;\n</code></pre> <p>You can use <code>DESC</code> instead of <code>DESCRIBE</code> for short.</p>"},{"location":"3.ngql-guide/11.edge-type-statements/5.describe-edge/#example","title":"Example","text":"<pre><code>nebula&gt; DESCRIBE EDGE follow;\n+----------+---------+-------+---------+---------+\n| Field    | Type    | Null  | Default | Comment |\n+----------+---------+-------+---------+---------+\n| \"degree\" | \"int64\" | \"YES\" |         |         |\n+----------+---------+-------+---------+---------+\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/1.insert-vertex/","title":"INSERT VERTEX","text":"<p>The <code>INSERT VERTEX</code> statement inserts one or more vertices into a graph space in NebulaGraph.</p>"},{"location":"3.ngql-guide/12.vertex-statements/1.insert-vertex/#prerequisites","title":"Prerequisites","text":"<p>Running the <code>INSERT VERTEX</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/12.vertex-statements/1.insert-vertex/#syntax","title":"Syntax","text":"<pre><code>INSERT VERTEX [IF NOT EXISTS] &lt;tag_name&gt; (&lt;prop_name_list&gt;) [, &lt;tag_name&gt; (&lt;prop_name_list&gt;), ...]\n     {VALUES | VALUE} VID: (&lt;prop_value_list&gt;[, &lt;prop_value_list&gt;])\n\nprop_name_list:\n  [prop_name [, prop_name] ...]\n\nprop_value_list:\n  [prop_value [, prop_value] ...]\n</code></pre> <ul> <li> <p><code>IF NOT EXISTS</code> detects if the VID that you want to insert exists. If it does not exist, a new one will be inserted.</p> <p>Note</p> <ul> <li><code>IF NOT EXISTS</code> only compares the names of the VID and the tag (excluding properties).</li> <li><code>IF NOT EXISTS</code> will read to check whether the data exists, which will have a significant impact on performance.</li> </ul> </li> </ul> <ul> <li><code>tag_name</code> denotes the tag (vertex type), which must be created before <code>INSERT VERTEX</code>. For more information, see CREATE TAG.</li> </ul> <ul> <li><code>prop_name_list</code> contains the names of the properties on the tag.</li> </ul> <ul> <li><code>VID</code> is the vertex ID. In NebulaGraph 2.0, string and integer VID types are supported. The VID type is set when a graph space is created. For more information, see CREATE SPACE.</li> </ul> <ul> <li><code>prop_value_list</code> must provide the property values according to the <code>prop_name_list</code>. If the property values do not match the data type in the tag, an error is returned. When the <code>NOT NULL</code> constraint is set for a given property, an error is returned if no property is given. When the default value for a property is <code>NULL</code>, you can omit to specify the property value. For details, see CREATE TAG.</li> </ul> <p>Caution</p> <p><code>INSERT VERTEX</code> and <code>CREATE</code> have different semantics.</p> <ul> <li>The semantics of <code>INSERT VERTEX</code> is closer to that of INSERT in NoSQL (key-value), or <code>UPSERT</code> (<code>UPDATE</code> or <code>INSERT</code>) in SQL.</li> <li>When two INSERT statements (neither uses <code>IF NOT EXISTS</code>) with the same <code>VID</code> and <code>TAG</code> are operated at the same time, the latter INSERT will overwrite the former.</li> <li>When two INSERT statements with the same <code>VID</code> but different <code>TAGS</code> are operated at the same time, the operation of different tags will not overwrite each other.</li> </ul> <p>Examples are as follows.</p>"},{"location":"3.ngql-guide/12.vertex-statements/1.insert-vertex/#examples","title":"Examples","text":"<pre><code># The following examples create tag t1 with no property and inserts vertex \"10\" with no property.\nnebula&gt; CREATE TAG IF NOT EXISTS t1();                   \nnebula&gt; INSERT VERTEX t1() VALUE \"10\":(); \n</code></pre> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS t2 (name string, age int);                \nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"11\":(\"n1\", 12);\n\n#  In the following example, the insertion fails because \"a13\" is not int.\nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"12\":(\"n1\", \"a13\"); \n\n# The following example inserts two vertices at one time.\nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"13\":(\"n3\", 12), \"14\":(\"n4\", 8); \n</code></pre> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS t3(p1 int);\nnebula&gt; CREATE TAG IF NOT EXISTS t4(p2 string);\n\n# The following example inserts vertex \"21\" with two tags.\nnebula&gt; INSERT VERTEX t3 (p1), t4(p2) VALUES \"21\": (321, \"hello\");\n</code></pre> <p>A vertex can be inserted/written with new values multiple times. Only the last written values can be read.</p> <pre><code># The following examples insert vertex \"11\" with new values for multiple times.\nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"11\":(\"n2\", 13);\nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"11\":(\"n3\", 14);\nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"11\":(\"n4\", 15);\nnebula&gt; FETCH PROP ON t2 \"11\";\n+---------------------------------+\n| vertices_                       |\n+---------------------------------+\n| (\"11\" :t2{age: 15, name: \"n4\"}) |\n+---------------------------------+\n</code></pre> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS t5(p1 fixed_string(5) NOT NULL, p2 int, p3 int DEFAULT NULL);\nnebula&gt; INSERT VERTEX t5(p1, p2, p3) VALUES \"001\":(\"Abe\", 2, 3);\n\n# In the following example, the insertion fails because the value of p1 cannot be NULL.\nnebula&gt; INSERT VERTEX t5(p1, p2, p3) VALUES \"002\":(NULL, 4, 5);\n[ERROR (-1005)]: Storage Error: The not null field cannot be null.\n\n# In the following example, the value of p3 is the default NULL.\nnebula&gt; INSERT VERTEX t5(p1, p2) VALUES \"003\":(\"cd\", 5);\nnebula&gt; FETCH PROP ON t5 \"003\";\n+--------------------------------------------+\n| vertices_                                  |\n+--------------------------------------------+\n| (\"003\" :t5{p1: \"cd\", p2: 5, p3: __NULL__}) |\n+--------------------------------------------+\n\n# In the following example, the allowed maximum length of p1 is 5.\nnebula&gt; INSERT VERTEX t5(p1, p2) VALUES \"004\":(\"shalalalala\", 4);\nnebula&gt; FETCH PROP on t5 \"004\";\n+-----------------------------------------------+\n| vertices_                                     |\n+-----------------------------------------------+\n| (\"004\" :t5{p1: \"shala\", p2: 4, p3: __NULL__}) |\n+-----------------------------------------------+\n</code></pre> <p>If you insert a vertex that already exists with <code>IF NOT EXISTS</code>, there will be no modification.</p> <pre><code># The following example inserts vertex \"1\".\nnebula&gt; INSERT VERTEX t2 (name, age) VALUES \"1\":(\"n2\", 13);\n# Modify vertex \"1\" with IF NOT EXISTS. But there will be no modification as vertex \"1\" already exists.\nnebula&gt; INSERT VERTEX IF NOT EXISTS t2 (name, age) VALUES \"1\":(\"n3\", 14);\nnebula&gt; FETCH PROP ON t2 \"1\";\n+--------------------------------+\n| vertices_                      |\n+--------------------------------+\n| (\"1\" :t2{age: 13, name: \"n2\"}) |\n+--------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/2.update-vertex/","title":"UPDATE VERTEX","text":"<p>The <code>UPDATE VERTEX</code> statement updates properties on tags of a vertex.</p> <p>In NebulaGraph, <code>UPDATE VERTEX</code> supports compare-and-set (CAS).</p> <p>Note</p> <p>An <code>UPDATE VERTEX</code> statement can only update properties on ONE TAG of a vertex.</p>"},{"location":"3.ngql-guide/12.vertex-statements/2.update-vertex/#syntax","title":"Syntax","text":"<pre><code>UPDATE VERTEX ON &lt;tag_name&gt; &lt;vid&gt;\nSET &lt;update_prop&gt;\n[WHEN &lt;condition&gt;]\n[YIELD &lt;output&gt;]\n</code></pre> Parameter Required Description Example <code>ON &lt;tag_name&gt;</code> Yes Specifies the tag of the vertex. The properties to be updated must be on this tag. <code>ON player</code> <code>&lt;vid&gt;</code> Yes Specifies the ID of the vertex to be updated. <code>\"player100\"</code> <code>SET &lt;update_prop&gt;</code> Yes Specifies the properties to be updated and how they will be updated. <code>SET age = age +1</code> <code>WHEN &lt;condition&gt;</code> No Specifies the filter conditions. If <code>&lt;condition&gt;</code> evaluates to <code>false</code>, the <code>SET</code> clause will not take effect. <code>WHEN name == \"Tim\"</code> <code>YIELD &lt;output&gt;</code> No Specifies the output format of the statement. <code>YIELD name AS Name</code>"},{"location":"3.ngql-guide/12.vertex-statements/2.update-vertex/#example","title":"Example","text":"<pre><code>// This query checks the properties of vertex \"player101\".\nnebula&gt; FETCH PROP ON player \"player101\";\n+-----------------------------------------------------+\n| vertices_                                           |\n+-----------------------------------------------------+\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"}) |\n+-----------------------------------------------------+\n\n// This query updates the age property and returns name and the new age.\nnebula&gt; UPDATE VERTEX ON player \"player101\" \\\n        SET age = age + 2 \\\n        WHEN name == \"Tony Parker\" \\\n        YIELD name AS Name, age AS Age;\n+---------------+-----+\n| Name          | Age |\n+---------------+-----+\n| \"Tony Parker\" | 38  |\n+---------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/3.upsert-vertex/","title":"UPSERT VERTEX","text":"<p>The <code>UPSERT</code> statement is a combination of <code>UPDATE</code> and <code>INSERT</code>. You can use <code>UPSERT VERTEX</code> to update the properties of a vertex if it exists or insert a new vertex if it does not exist.</p> <p>Note</p> <p>An <code>UPSERT VERTEX</code> statement can only update the properties on ONE TAG of a vertex.</p> <p>The performance of <code>UPSERT</code> is much lower than that of <code>INSERT</code> because <code>UPSERT</code> is a read-modify-write serialization operation at the partition level.</p> <p>Danger</p> <p>Don't use <code>UPSERT</code> for scenarios with highly concurrent writes. You can use <code>UPDATE</code> or <code>INSERT</code> instead.</p>"},{"location":"3.ngql-guide/12.vertex-statements/3.upsert-vertex/#syntax","title":"Syntax","text":"<pre><code>UPSERT VERTEX ON &lt;tag&gt; &lt;vid&gt;\nSET &lt;update_prop&gt;\n[WHEN &lt;condition&gt;]\n[YIELD &lt;output&gt;]\n</code></pre> <p>| Parameter           | Required | Description                                                                        | Example              | |---------------------+----------+------------------------------------------------------------------------------------+----------------------| | <code>ON &lt;tag&gt;</code>          | Yes      | Specifies the tag of the vertex. The properties to be updated must be on this tag. | <code>ON player</code>          | | <code>&lt;vid&gt;</code>             | Yes      | Specifies the ID of the vertex to be updated or inserted.                          | <code>\"player100\"</code>        | | <code>SET &lt;update_prop&gt;</code> | Yes      | Specifies the properties to be updated and how they will be updated.               | <code>SET age = age +1</code>   | | <code>WHEN &lt;condition&gt;</code>  | No       | Specifies the filter conditions.                                                   | <code>WHEN name == \"Tim\"</code> | | <code>YIELD &lt;output&gt;</code>    | No       | Specifies the output format of the statement.                                      | <code>YIELD name AS Name</code> |</p>"},{"location":"3.ngql-guide/12.vertex-statements/3.upsert-vertex/#insert_a_vertex_if_it_does_not_exist","title":"Insert a vertex if it does not exist","text":"<p>If a vertex does not exist, it is created no matter the conditions in the <code>WHEN</code> clause are met or not, and the <code>SET</code> clause always takes effect. The property values of the new vertex depend on:</p> <ul> <li>How the <code>SET</code> clause is defined.</li> </ul> <ul> <li>Whether the property has a default value.</li> </ul> <p>For example, if:</p> <ul> <li>The vertex to be inserted will have properties <code>name</code> and <code>age</code> based on the tag <code>player</code>.</li> </ul> <ul> <li>The <code>SET</code> clause specifies that <code>age = 30</code>.</li> </ul> <p>Then the property values in different cases are listed as follows:</p> <p>| Are <code>WHEN</code> conditions met | If properties have default values | Value of <code>name</code>   | Value of <code>age</code> | |---------------------------+-----------------------------------+-------------------+----------------| | Yes                       | Yes                               | The default value | <code>30</code>           | | Yes                       | No                                | <code>NULL</code>            | <code>30</code>           | | No                        | Yes                               | The default value | <code>30</code>           | | No                        | No                                | <code>NULL</code>            | <code>30</code>           |</p> <p>Here are some examples:</p> <pre><code>// This query checks if the following three vertices exist. The result \"Empty set\" indicates that the vertices do not exist.\nnebula&gt; FETCH PROP ON * \"player666\", \"player667\", \"player668\";\n+-----------+\n| vertices_ |\n+-----------+\n+-----------+\nEmpty set\n\nnebula&gt; UPSERT VERTEX ON player \"player666\" \\\n        SET age = 30 \\\n        WHEN name == \"Joe\" \\\n        YIELD name AS Name, age AS Age;\n+----------+----------+\n| Name     | Age      |\n+----------+----------+\n| __NULL__ | 30       |\n+----------+----------+\n\nnebula&gt; UPSERT VERTEX ON player \"player666\" \\\n        SET age = 31 \\\n        WHEN name == \"Joe\" \\\n        YIELD name AS Name, age AS Age;\n+----------+-----+\n| Name     | Age |\n+----------+-----+\n| __NULL__ | 30  |\n+----------+-----+\n\nnebula&gt; UPSERT VERTEX ON player \"player667\" \\\n        SET age = 31 \\\n        YIELD name AS Name, age AS Age;\n+----------+-----+\n| Name     | Age |\n+----------+-----+\n| __NULL__ | 31  |\n+----------+-----+\n\nnebula&gt; UPSERT VERTEX ON player \"player668\" \\\n        SET name = \"Amber\", age = age + 1 \\\n        YIELD name AS Name, age AS Age;\n+---------+----------+\n| Name    | Age      |\n+---------+----------+\n| \"Amber\" | __NULL__ |\n+---------+----------+\n</code></pre> <p>In the last query of the preceding examples, since <code>age</code> has no default value, when the vertex is created, <code>age</code> is <code>NULL</code>, and <code>age = age + 1</code> does not take effect. But if <code>age</code> has a default value, <code>age = age + 1</code> will take effect. For example:</p> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS player_with_default(name string, age int DEFAULT 20);\nExecution succeeded\n\nnebula&gt; UPSERT VERTEX ON player_with_default \"player101\" \\\n        SET age = age + 1 \\\n        YIELD name AS Name, age AS Age;\n\n+----------+-----+\n| Name     | Age |\n+----------+-----+\n| __NULL__ | 21  |\n+----------+-----+\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/3.upsert-vertex/#update_a_vertex_if_it_exists","title":"Update a vertex if it exists","text":"<p>If the vertex exists and the <code>WHEN</code> conditions are met, the vertex is updated.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player101\";\n+-----------------------------------------------------+\n| vertices_                                           |\n+-----------------------------------------------------+\n| (\"player101\" :player{age: 42, name: \"Tony Parker\"}) |\n+-----------------------------------------------------+\n\nnebula&gt; UPSERT VERTEX ON player \"player101\" \\\n        SET age = age + 2 \\\n        WHEN name == \"Tony Parker\" \\\n        YIELD name AS Name, age AS Age;\n+---------------+-----+\n| Name          | Age |\n+---------------+-----+\n| \"Tony Parker\" | 44  |\n+---------------+-----+\n</code></pre> <p>If the vertex exists and the <code>WHEN</code> conditions are not met, the update does not take effect.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player101\";\n+-----------------------------------------------------+\n| vertices_                                           |\n+-----------------------------------------------------+\n| (\"player101\" :player{age: 44, name: \"Tony Parker\"}) |\n+-----------------------------------------------------+\n\nnebula&gt; UPSERT VERTEX ON player \"player101\" \\\n        SET age = age + 2 \\\n        WHEN name == \"Someone else\" \\\n        YIELD name AS Name, age AS Age;\n+---------------+-----+\n| Name          | Age |\n+---------------+-----+\n| \"Tony Parker\" | 44  |\n+---------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/4.delete-vertex/","title":"DELETE VERTEX","text":"<p>The <code>DELETE VERTEX</code> statement deletes vertices and the related incoming and outgoing edges of the vertices.</p> <p>The <code>DELETE VERTEX</code> statement deletes one vertex or multiple vertices at a time. You can use <code>DELETE VERTEX</code> together with pipes. For more information about pipe, see Pipe operator.</p> <p>Note</p> <ul> <li><code>DELETE VERTEX</code> deletes vertices and related edges directly.</li> </ul> <ul> <li><code>DELETE TAG</code> deletes a tag with the given name on a specified vertex. When a vertex has only one tag, <code>DELETE TAG</code> deletes the vertex and keeps the related edges.</li> </ul>"},{"location":"3.ngql-guide/12.vertex-statements/4.delete-vertex/#syntax","title":"Syntax","text":"<pre><code>DELETE VERTEX &lt;vid&gt; [, &lt;vid&gt; ...];\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/4.delete-vertex/#examples","title":"Examples","text":"<p>This query deletes the vertex whose ID is \"team1\".</p> <pre><code>nebula&gt; DELETE VERTEX \"team1\";\n</code></pre> <p>This query shows that you can use <code>DELETE VERTEX</code> together with pipe to delete vertices.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER serve WHERE serve.start_year == \"2021\" YIELD dst(edge) AS id | DELETE VERTEX $-.id;\n</code></pre>"},{"location":"3.ngql-guide/12.vertex-statements/4.delete-vertex/#delete_the_process_and_the_related_edges","title":"Delete the process and the related edges","text":"<p>NebulaGraph traverses the incoming and outgoing edges related to the vertices and deletes them all. Then NebulaGraph deletes the vertices.</p> <p>Caution</p> <ul> <li>Atomic deletion is not supported during the entire process for now. Please retry when a failure occurs to avoid partial deletion, which will cause pendent edges.</li> <li>Deleting a supernode takes a lot of time. To avoid connection timeout before the deletion is complete, you can modify the parameter <code>--storage_client_timeout_ms</code> in <code>nebula-graphd.conf</code> to extend the timeout period.</li> </ul>"},{"location":"3.ngql-guide/13.edge-statements/1.insert-edge/","title":"INSERT EDGE","text":"<p>The <code>INSERT EDGE</code> statement inserts an edge or multiple edges into a graph space from a source vertex (given by src_vid) to a destination vertex (given by dst_vid) with a specific rank in NebulaGraph.</p> <p>When inserting an edge that already exists, <code>INSERT VERTEX</code> overrides the edge.</p>"},{"location":"3.ngql-guide/13.edge-statements/1.insert-edge/#syntax","title":"Syntax","text":"<pre><code>INSERT EDGE [IF NOT EXISTS] &lt;edge_type&gt; ( &lt;prop_name_list&gt; ) {VALUES | VALUE}\n&lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] : ( &lt;prop_value_list&gt; )\n[, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] : ( &lt;prop_value_list&gt; ), ...];\n\n&lt;prop_name_list&gt; ::=\n  [ &lt;prop_name&gt; [, &lt;prop_name&gt; ] ...]\n\n&lt;prop_value_list&gt; ::=\n  [ &lt;prop_value&gt; [, &lt;prop_value&gt; ] ...]\n</code></pre> <ul> <li> <p><code>IF NOT EXISTS</code> detects if the edge that you want to insert exists. If it does not exist, a new one will be inserted.</p> <p>Note</p> <ul> <li><code>IF NOT EXISTS</code> only detects whether  exist and does not detect whether the property values overlap. <li><code>IF NOT EXISTS</code> will read to check whether the data exists, which will have a significant impact on performance.</li> <ul> <li><code>&lt;edge_type&gt;</code> denotes the edge type, which must be created before <code>INSERT EDGE</code>. Only one edge type can be specified in this statement.</li> </ul> <ul> <li><code>&lt;prop_name_list&gt;</code> is the property name list in the given <code>&lt;edge_type&gt;</code>.</li> </ul> <ul> <li><code>src_vid</code> is the VID of the source vertex. It specifies the start of an edge.</li> </ul> <ul> <li><code>dst_vid</code> is the VID of the destination vertex. It specifies the end of an edge.</li> </ul> <ul> <li> <p><code>rank</code> is optional. It specifies the edge rank of the same edge type. If not specified, the default value is <code>0</code>. You can insert many edges with the same edge type, source vertex, and destination vertex by using different rank values.</p> <p>OpenCypher compatibility</p> <p>OpenCypher has no such concept as rank.</p> </li> </ul> <ul> <li><code>&lt;prop_value_list&gt;</code> must provide the value list according to <code>&lt;prop_name_list&gt;</code>. If the property values do not match the data type in the edge type, an error is returned. When the <code>NOT NULL</code> constraint is set for a given property, an error is returned if no property is given. When the default value for a property is <code>NULL</code>, you can omit to specify the property value. For details, see CREATE EDGE.</li> </ul>"},{"location":"3.ngql-guide/13.edge-statements/1.insert-edge/#examples","title":"Examples","text":"<pre><code># The following example creates edge type e1 with no property and inserts an edge from vertex \"10\" to vertex \"11\" with no property.\nnebula&gt; CREATE EDGE IF NOT EXISTS e1();                 \nnebula&gt; INSERT EDGE e1 () VALUES \"10\"-&gt;\"11\":();  \n\n# The following example inserts an edge from vertex \"10\" to vertex \"11\" with no property. The edge rank is 1.\nnebula&gt; INSERT EDGE e1 () VALUES \"10\"-&gt;\"11\"@1:(); \n</code></pre> <pre><code>nebula&gt; CREATE EDGE IF NOT EXISTS e2 (name string, age int); \nnebula&gt; INSERT EDGE e2 (name, age) VALUES \"11\"-&gt;\"13\":(\"n1\", 1);\n\n# The following example creates edge type e2 with two properties.\nnebula&gt; INSERT EDGE e2 (name, age) VALUES \\\n        \"12\"-&gt;\"13\":(\"n1\", 1), \"13\"-&gt;\"14\":(\"n2\", 2); \n\n# In the following example, the insertion fails because \"a13\" is not int.\nnebula&gt; INSERT EDGE e2 (name, age) VALUES \"11\"-&gt;\"13\":(\"n1\", \"a13\");\n</code></pre> <p>An edge can be inserted/written with property values multiple times. Only the last written values can be read.</p> <pre><code>The following examples insert edge e2 with the new values for multiple times.\nnebula&gt; INSERT EDGE e2 (name, age) VALUES \"11\"-&gt;\"13\":(\"n1\", 12);\nnebula&gt; INSERT EDGE e2 (name, age) VALUES \"11\"-&gt;\"13\":(\"n1\", 13);\nnebula&gt; INSERT EDGE e2 (name, age) VALUES \"11\"-&gt;\"13\":(\"n1\", 14);\nnebula&gt; FETCH PROP ON e2 \"11\"-&gt;\"13\";\n+-------------------------------------------+\n| edges_                                    |\n+-------------------------------------------+\n| [:e2 \"11\"-&gt;\"13\" @0 {age: 14, name: \"n1\"}] |\n+-------------------------------------------+\n</code></pre> <p>If you insert an edge that already exists with <code>IF NOT EXISTS</code>, there will be no modification.</p> <pre><code># The following example inserts edge e2 from vertex \"14\" to vertex \"15\".\nnebula&gt; INSERT EDGE e2 (name, age) VALUES \"14\"-&gt;\"15\"@1:(\"n1\", 12);\n# The following example alters the edge with IF NOT EXISTS. But there will be no alteration because edge e2 already exists.\nnebula&gt; INSERT EDGE IF NOT EXISTS e2 (name, age) VALUES \"14\"-&gt;\"15\"@1:(\"n2\", 13);\nnebula&gt; FETCH PROP ON e2 \"14\"-&gt;\"15\"@1;\n+-------------------------------------------+\n| edges_                                    |\n+-------------------------------------------+\n| [:e2 \"14\"-&gt;\"15\" @1 {age: 12, name: \"n1\"}] |\n+-------------------------------------------+\n</code></pre> <p>Note</p> <ul> <li>NebulaGraph 2.6.2 allows dangling edges. Therefore, you can write the edge before the source vertex or the destination vertex exists. At this time, you can get the (not written) vertex VID through <code>&lt;edgetype&gt;._src</code> or <code>&lt;edgetype&gt;._dst</code> (which is not recommended).</li> <li>Atomic operation is not guaranteed during the entire process for now. If it fails, please try again. Otherwise, partial writing will occur. At this time, the behavior of reading the data is undefined.</li> <li>Concurrently writing the same edge will cause an <code>edge conflict</code> error, so please try again later.</li> <li>The inserting speed of an edge is about half that of a vertex. Because in the storaged process, the insertion of an edge involves two tasks, while the insertion of a vertex involves only one task.</li> </ul>"},{"location":"3.ngql-guide/13.edge-statements/2.update-edge/","title":"UPDATE EDGE","text":"<p>The <code>UPDATE EDGE</code> statement updates properties on an edge.</p> <p>In NebulaGraph, <code>UPDATE EDGE</code> supports compare-and-swap (CAS).</p>"},{"location":"3.ngql-guide/13.edge-statements/2.update-edge/#syntax","title":"Syntax","text":"<pre><code>UPDATE EDGE ON &lt;edge_type&gt;\n&lt;src_vid&gt; -&gt; &lt;dst_vid&gt; [@&lt;rank&gt;]\nSET &lt;update_prop&gt;\n[WHEN &lt;condition&gt;]\n[YIELD &lt;output&gt;]\n</code></pre> Parameter Required Description Example <code>ON &lt;edge_type&gt;</code> Yes Specifies the edge type. The properties to be updated must be on this edge type. <code>ON serve</code> <code>&lt;src_vid&gt;</code> Yes Specifies the source vertex ID of the edge. <code>\"player100\"</code> <code>&lt;dst_vid&gt;</code> Yes Specifies the destination vertex ID of the edge. <code>\"team204\"</code> <code>&lt;rank&gt;</code> No Specifies the rank of the edge. <code>10</code> <code>SET &lt;update_prop&gt;</code> Yes Specifies the properties to be updated and how they will be updated. <code>SET start_year = start_year +1</code> <code>WHEN &lt;condition&gt;</code> No Specifies the filter conditions. If <code>&lt;condition&gt;</code> evaluates to <code>false</code>, the <code>SET</code> clause does not take effect. <code>WHEN end_year &lt; 2010</code> <code>YIELD &lt;output&gt;</code> No Specifies the output format of the statement. <code>YIELD start_year AS Start_Year</code>"},{"location":"3.ngql-guide/13.edge-statements/2.update-edge/#example","title":"Example","text":"<p>The following example checks the properties of the edge with the GO statement.</p> <pre><code>nebula&gt; GO FROM \"player100\" \\\n        OVER serve \\\n        YIELD properties(edge).start_year, properties(edge).end_year;\n+------------------+----------------+\n| serve.start_year | serve.end_year |\n+------------------+----------------+\n| 1997             | 2016           |\n+------------------+----------------+\n</code></pre> <p>The following example updates the <code>start_year</code> property and returns the <code>end_year</code> and the new <code>start_year</code>.</p> <pre><code>nebula&gt; UPDATE EDGE on serve \"player100\" -&gt; \"team204\"@0 \\\n        SET start_year = start_year + 1 \\\n        WHEN end_year &gt; 2010 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| 1998       | 2016     |\n+------------+----------+\n</code></pre>"},{"location":"3.ngql-guide/13.edge-statements/3.upsert-edge/","title":"UPSERT EDGE","text":"<p>The <code>UPSERT</code> statement is a combination of <code>UPDATE</code> and <code>INSERT</code>. You can use <code>UPSERT EDGE</code> to update the properties of an edge if it exists or insert a new edge if it does not exist.</p> <p>The performance of <code>UPSERT</code> is much lower than that of <code>INSERT</code> because <code>UPSERT</code> is a read-modify-write serialization operation at the partition level.</p> <p>Danger</p> <p>Do not use <code>UPSERT</code> for scenarios with highly concurrent writes. You can use <code>UPDATE</code> or <code>INSERT</code> instead.</p>"},{"location":"3.ngql-guide/13.edge-statements/3.upsert-edge/#syntax","title":"Syntax","text":"<pre><code>UPSERT EDGE ON &lt;edge_type&gt;\n&lt;src_vid&gt; -&gt; &lt;dst_vid&gt; [@rank]\nSET &lt;update_prop&gt;\n[WHEN &lt;condition&gt;]\n[YIELD &lt;properties&gt;]\n</code></pre> <p>| Parameter           | Required | Description                                                                      | Example                          | |---------------------+----------+----------------------------------------------------------------------------------+----------------------------------| | <code>ON &lt;edge_type&gt;</code>    | Yes      | Specifies the edge type. The properties to be updated must be on this edge type. | <code>ON serve</code>                       | | <code>&lt;src_vid&gt;</code>         | Yes      | Specifies the source vertex ID of the edge.                                      | <code>\"player100\"</code>                    | | <code>&lt;dst_vid&gt;</code>         | Yes      | Specifies the destination vertex ID of the edge.                                 | <code>\"team204\"</code>                      | | <code>&lt;rank&gt;</code>            | No       | Specifies the rank of the edge.                                                  | <code>10</code>                             | | <code>SET &lt;update_prop&gt;</code> | Yes      | Specifies the properties to be updated and how they will be updated.             | <code>SET start_year = start_year +1</code> | | <code>WHEN &lt;condition&gt;</code>  | No       | Specifies the filter conditions.                                                 | <code>WHEN end_year &lt; 2010</code>           | | <code>YIELD &lt;output&gt;</code>    | No       | Specifies the output format of the statement.                                    | <code>YIELD start_year AS Start_Year</code> |</p>"},{"location":"3.ngql-guide/13.edge-statements/3.upsert-edge/#insert_an_edge_if_it_does_not_exist","title":"Insert an edge if it does not exist","text":"<p>If an edge does not exist, it is created no matter the conditions in the <code>WHEN</code> clause are met or not, and the <code>SET</code> clause takes effect. The property values of the new edge depend on:</p> <ul> <li>How the <code>SET</code> clause is defined.</li> </ul> <ul> <li>Whether the property has a default value.</li> </ul> <p>For example, if:</p> <ul> <li>The edge to be inserted will have properties <code>start_year</code> and <code>end_year</code> based on the edge type <code>serve</code>.</li> </ul> <ul> <li>The <code>SET</code> clause specifies that <code>end_year = 2021</code>.</li> </ul> <p>Then the property values in different cases are listed as follows:</p> Are <code>WHEN</code> conditions met If properties have default values Value of <code>start_year</code> Value of <code>end_year</code> Yes Yes The default value <code>2021</code> Yes No <code>NULL</code> <code>2021</code> No Yes The default value <code>2021</code> No No <code>NULL</code> <code>2021</code> <p>Here are some examples:</p> <pre><code>// This example checks if the following three vertices have any outgoing serve edge. The result \"Empty set\" indicates that such an edge does not exist.\nnebula&gt; GO FROM \"player666\", \"player667\", \"player668\" \\\n        OVER serve \\\n        YIELD serve.start_year, serve.end_year;\nEmpty set\n\nnebula&gt; UPSERT EDGE on serve \\\n        \"player666\" -&gt; \"team200\"@0 \\\n        SET end_year = 2021 \\\n        WHEN end_year == 2010 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| __NULL__   | 2021     |\n+------------+----------+\n\nnebula&gt; UPSERT EDGE on serve \\\n        \"player666\" -&gt; \"team200\"@0 \\\n        SET end_year = 2022 \\\n        WHEN end_year == 2010 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| __NULL__   | 2021     |\n+------------+----------+\n\nnebula&gt; UPSERT EDGE on serve \\\n        \"player667\" -&gt; \"team200\"@0 \\\n        SET end_year = 2022 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| __NULL__   | 2022     |\n+------------+----------+\n\nnebula&gt; UPSERT EDGE on serve \\\n        \"player668\" -&gt; \"team200\"@0 \\\n        SET start_year = 2000, end_year = end_year + 1 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| 2000       | __NULL__ |\n+------------+----------+\n</code></pre> <p>In the last query of the preceding example, since <code>end_year</code> has no default value, when the edge is created, <code>end_year</code> is <code>NULL</code>, and <code>end_year = end_year + 1</code> does not take effect. But if <code>end_year</code> has a default value, <code>end_year = end_year + 1</code> will take effect. For example:</p> <pre><code>nebula&gt; CREATE EDGE IF NOT EXISTS serve_with_default(start_year int, end_year int DEFAULT 2010);\nExecution succeeded\n\nnebula&gt; UPSERT EDGE on serve_with_default \\\n        \"player668\" -&gt; \"team200\" \\\n        SET end_year = end_year + 1 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| __NULL__   | 2011     |\n+------------+----------+\n</code></pre>"},{"location":"3.ngql-guide/13.edge-statements/3.upsert-edge/#update_an_edge_if_it_exists","title":"Update an edge if it exists","text":"<p>If the edge exists and the <code>WHEN</code> conditions are met, the edge is updated.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Ben Simmons\"})-[e:serve]-(v2) \\\n        RETURN e;\n+-----------------------------------------------------------------------+\n| e                                                                     |\n+-----------------------------------------------------------------------+\n| [:serve \"player149\"-&gt;\"team219\" @0 {end_year: 2019, start_year: 2016}] |\n+-----------------------------------------------------------------------+\n\nnebula&gt; UPSERT EDGE on serve \\\n        \"player149\" -&gt; \"team219\" \\\n        SET end_year = end_year + 1 \\\n        WHEN start_year == 2016 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| 2016       | 2020     |\n+------------+----------+\n</code></pre> <p>If the edge exists and the <code>WHEN</code> conditions are not met, the update does not take effect.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Ben Simmons\"})-[e:serve]-(v2) \\\n        RETURN e;\n+-----------------------------------------------------------------------+\n| e                                                                     |\n+-----------------------------------------------------------------------+\n| [:serve \"player149\"-&gt;\"team219\" @0 {end_year: 2020, start_year: 2016}] |\n+-----------------------------------------------------------------------+\n\n\nnebula&gt; UPSERT EDGE on serve \\\n        \"player149\" -&gt; \"team219\" \\\n        SET end_year = end_year + 1 \\\n        WHEN start_year != 2016 \\\n        YIELD start_year, end_year;\n+------------+----------+\n| start_year | end_year |\n+------------+----------+\n| 2016       | 2020     |\n+------------+----------+\n</code></pre>"},{"location":"3.ngql-guide/13.edge-statements/4.delete-edge/","title":"DELETE EDGE","text":"<p>The <code>DELETE EDGE</code> statement deletes one edge or multiple edges at a time. You can use <code>DELETE EDGE</code> together with pipe operators. For more information, see PIPE OPERATORS.</p> <p>To delete all the outgoing edges for a vertex, please delete the vertex. For more information, see DELETE VERTEX.</p> <p>Note</p> <p>Atomic operation is not guaranteed during the entire process for now, so please retry when a failure occurs.</p>"},{"location":"3.ngql-guide/13.edge-statements/4.delete-edge/#syntax","title":"Syntax","text":"<pre><code>DELETE EDGE &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] [, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] ...]\n</code></pre>"},{"location":"3.ngql-guide/13.edge-statements/4.delete-edge/#examples","title":"Examples","text":"<pre><code>nebula&gt; DELETE EDGE serve \"player100\" -&gt; \"team204\"@0;\n</code></pre> <p>The following example shows that you can use <code>DELETE EDGE</code> together with pipe operators to delete edges that meet the conditions.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        WHERE dst(edge) == \"team204\" \\\n        YIELD src(edge) AS src, dst(edge) AS dst, rank(edge) AS rank \\\n        | DELETE EDGE follow $-.src-&gt;$-.dst @ $-.rank;\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/","title":"Index overview","text":"<p>Indexes are built to fast process graph queries. Nebula\u00a0Graph supports two kinds of indexes: native indexes and full-text indexes. This topic introduces the index types and helps choose the right index.</p>"},{"location":"3.ngql-guide/14.native-index-statements/#native_indexes","title":"Native indexes","text":"<p>Native indexes allow querying data based on a given property. Features are as follows.</p> <ul> <li>There are two kinds of native indexes: tag index and edge type index.</li> </ul> <ul> <li>Native indexes must be updated manually. You can use the <code>REBUILD INDEX</code> statement to update native indexes.</li> </ul> <ul> <li>Native indexes support indexing multiple properties on a tag or an edge type (composite indexes), but do not support indexing across multiple tags or edge types.</li> </ul>"},{"location":"3.ngql-guide/14.native-index-statements/#operations_on_native_indexes","title":"Operations on native indexes","text":"<ul> <li>CREATE INDEX</li> </ul> <ul> <li>SHOW CREATE INDEX</li> </ul> <ul> <li>SHOW INDEXES</li> </ul> <ul> <li>DESCRIBE INDEX</li> </ul> <ul> <li>REBUILD INDEX</li> </ul> <ul> <li>SHOW INDEX STATUS</li> </ul> <ul> <li>DROP INDEX</li> </ul> <ul> <li>LOOKUP</li> </ul> <ul> <li>MATCH</li> </ul>"},{"location":"3.ngql-guide/14.native-index-statements/#full-text_indexes","title":"Full-text indexes","text":"<p>Full-text indexes are used to do prefix, wildcard, regexp, and fuzzy search on a string property. Features are as follows.</p> <ul> <li>Full-text indexes allow indexing just one property.</li> </ul> <ul> <li>Only strings within a specified length (no longer than 256 bytes) are indexed.</li> </ul> <ul> <li>Full-text indexes do not support logical operations such as <code>AND</code>, <code>OR</code>, and <code>NOT</code>.</li> </ul> <p>Note</p> <p>To do complete string matches, use native indexes.</p>"},{"location":"3.ngql-guide/14.native-index-statements/#operations_on_full-text_indexes","title":"Operations on full-text indexes","text":"<p>Before doing any operations on full-text indexes, please make sure that you deploy full-text indexes. Details on full-text indexes deployment, see Deploy Elasticsearch and Deploy Listener.</p> <p>At this time, full-text indexes are created automatically on the Elasticsearch cluster. And rebuilding or altering full-text indexes are not supported. To drop full-text indexes, you need to drop them on the Elasticsearch cluster manually.</p> <p>To query full-text indexes, see Search with full-text indexes.</p>"},{"location":"3.ngql-guide/14.native-index-statements/#null_values","title":"Null values","text":"<p>Indexes do not support indexing null values.</p>"},{"location":"3.ngql-guide/14.native-index-statements/#range_queries","title":"Range queries","text":"<p>In addition to querying single results from native indexes, you can also do range queries. Not all the native indexes support range queries. You can only do range searches for numeric, date, and time type properties.</p>"},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/","title":"CREATE INDEX","text":""},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/#prerequisites","title":"Prerequisites","text":"<p>Before you create an index, make sure that the relative tag or edge type is created. For how to create tags or edge types, see CREATE TAG and CREATE EDGE.</p> <p>For how to create full-text indexes, see Deploy full-text index.</p>"},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/#must-read_for_using_indexes","title":"Must-read for using indexes","text":"<p>The concept and using restrictions of indexes are comparatively complex. You can use it together with <code>LOOKUP</code> and <code>MATCH</code> statements.</p> <p>You can use <code>CREATE INDEX</code> to add native indexes for the existing tags, edge types, or properties. They are usually called as tag indexes, edge type indexes, and property indexes.</p> <ul> <li>Tag indexes and edge type indexes apply to queries related to the tag and the edge type, but do not apply to queries that are based on certain properties on the tag. For example, you can use <code>LOOKUP</code> to retrieve all the vertices with the tag <code>player</code>.</li> </ul> <ul> <li>Property indexes apply to property-based queries. For example, you can use the <code>age</code> property to retrieve the VID of all vertices that meet <code>age == 19</code>.</li> </ul> <p>If a property index <code>i_TA</code> is created for the property <code>A</code> of the tag <code>T</code>, the indexes can be replaced as follows (the same for edge type indexes):</p> <ul> <li>The query engine can use <code>i_TA</code> to replace <code>i_T</code>.</li> </ul> <ul> <li>In the <code>MATCH</code> statement, <code>i_T</code> cannot replace <code>i_TA</code> for querying properties.</li> </ul> <ul> <li> <p>In the <code>LOOKUP</code> statement, <code>i_T</code> may replace <code>i_TA</code> for querying properties.</p> <p>Legacy version compatibility</p> <p>In previous releases, the tag or edge type index in the <code>LOOKUP</code> statement cannot replace the property index for property queries.</p> </li> </ul> <p>Although the same results can be obtained by using alternative indexes for queries, the query performance varies according to the selected index.</p> <p>Caution</p> <p>Indexes can dramatically reduce the write performance. The performance reduction can be as much as 90% or even more. DO NOT use indexes in production environments unless you are fully aware of their influences on your service.</p> <p>Indexes cannot make queries faster. It can only locate a vertex or an edge according to properties or count the number of vertices or edges.</p> <p>Long indexes decrease the scan performance of the Storage Service and use more memory. We suggest that you set the indexing length the same as that of the longest string to be indexed. The longest index length is 255 bytes. Strings longer than 255 bytes will be truncated.</p> <p>If you must use indexes, we suggest that you:</p> <ol> <li> <p>Import the data into NebulaGraph.</p> </li> <li> <p>Create indexes.</p> </li> <li> <p>Rebuild indexes.</p> </li> <li> <p>After the index is created and the data is imported, you can use LOOKUP or MATCH to retrieve the data. You do not need to specify which indexes to use in a query, NebulaGraph figures that out by itself.</p> </li> </ol> <p>Note</p> <p>If you create an index before importing the data, the importing speed will be extremely slow due to the reduction in the write performance.</p> <p>Keep <code>--disable_auto_compaction = false</code> during daily incremental writing.</p> <p>The newly created index will not take effect immediately. Trying to use a newly created index (such as <code>LOOKUP</code> or<code>REBUILD INDEX</code>) may fail and return <code>can't find xxx in the space</code> because the creation is implemented asynchronously. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds. To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> in the configuration files for all services.</p> <p>Danger</p> <p>After creating a new index, or dropping the old index and creating a new one with the same name again, you must <code>REBUILD INDEX</code>. Otherwise, these data cannot be returned in the <code>MATCH</code> and <code>LOOKUP</code> statements.</p>"},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/#syntax","title":"Syntax","text":"<pre><code>CREATE {TAG | EDGE} INDEX [IF NOT EXISTS] &lt;index_name&gt; ON {&lt;tag_name&gt; | &lt;edge_name&gt;} ([&lt;prop_name_list&gt;]) [COMMENT = '&lt;comment&gt;'];\n</code></pre> Parameter Description <code>TAG \\| EDGE</code> Specifies the index type that you want to create. <code>IF NOT EXISTS</code> Detects if the index that you want to create exists. If it does not exist, a new one will be created. <code>&lt;index_name&gt;</code> The name of the index. It must be unique in a graph space. A recommended way of naming is <code>i_tagName_propName</code>. The name of the index is case-sensitive and allows letters, numbers, or underlines. Keywords and reserved words are not allowed. <code>&lt;tag_name&gt; \\| &lt;edge_name&gt;</code> Specifies the name of the tag or edge associated with the index. <code>&lt;prop_name_list&gt;</code> To index a variable-length string property, you must use <code>prop_name(length)</code> to specify the index length. To index a tag or an edge type, ignore the <code>prop_name_list</code>. <code>COMMENT</code> The remarks of the index. The maximum length is 256 bytes. By default, there will be no comments on an index."},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/#create_tagedge_type_indexes","title":"Create tag/edge type indexes","text":"<pre><code>nebula&gt; CREATE TAG INDEX IF NOT EXISTS player_index on player();\n</code></pre> <pre><code>nebula&gt; CREATE EDGE INDEX IF NOT EXISTS follow_index on follow();\n</code></pre> <p>After indexing a tag or an edge type, you can use the <code>LOOKUP</code> statement to retrieve the VID of all vertices <code>with the tag</code>, or <code>the source vertex ID, destination vertex ID, and ranks</code> of <code>all edges with the edge type</code>. For more information, see LOOKUP.</p>"},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/#create_single-property_indexes","title":"Create single-property indexes","text":"<pre><code>nebula&gt; CREATE TAG INDEX IF NOT EXISTS player_index_0 on player(name(10));\n</code></pre> <p>The preceding example creates an index for the <code>name</code> property on all vertices carrying the <code>player</code> tag. This example creates an index using the first 10 characters of the <code>name</code> property.</p> <pre><code># To index a variable-length string property, you need to specify the index length.\nnebula&gt; CREATE TAG IF NOT EXISTS var_string(p1 string);\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS var ON var_string(p1(10));\n\n# To index a fixed-length string property, you do not need to specify the index length.\nnebula&gt; CREATE TAG IF NOT EXISTS fix_string(p1 FIXED_STRING(10));\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS fix ON fix_string(p1);\n</code></pre> <pre><code>nebula&gt; CREATE EDGE INDEX IF NOT EXISTS follow_index_0 on follow(degree);\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/1.create-native-index/#create_composite_property_indexes","title":"Create composite property indexes","text":"<p>An index on multiple properties on a tag (or an edge type) is called a composite property index.</p> <pre><code>nebula&gt; CREATE TAG INDEX IF NOT EXISTS player_index_1 on player(name(10), age);\n</code></pre> <p>Caution</p> <p>Creating composite property indexes across multiple tags or edge types is not supported.</p> <p>Note</p> <p>NebulaGraph follows the left matching principle to select indexes.</p>"},{"location":"3.ngql-guide/14.native-index-statements/2.1.show-create-index/","title":"SHOW CREATE INDEX","text":"<p><code>SHOW CREATE INDEX</code> shows the statement used when creating a tag or an edge type. It contains detailed information about the index, such as its associated properties.</p>"},{"location":"3.ngql-guide/14.native-index-statements/2.1.show-create-index/#syntax","title":"Syntax","text":"<pre><code>SHOW CREATE {TAG | EDGE} INDEX &lt;index_name&gt;;\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/2.1.show-create-index/#examples","title":"Examples","text":"<p>You can run <code>SHOW TAG INDEXES</code> to list all tag indexes, and then use <code>SHOW CREATE TAG INDEX</code> to show the information about the creation of the specified index.</p> <pre><code>nebula&gt; SHOW TAG INDEXES;\n+------------------+----------+----------+\n| Index Name       | By Tag   | Columns  |\n+------------------+----------+----------+\n| \"player_index_0\" | \"player\" | []       |\n| \"player_index_1\" | \"player\" | [\"name\"] |\n+------------------+----------+----------+\n\nnebula&gt; SHOW CREATE TAG INDEX player_index_1;\n+------------------+--------------------------------------------------+\n| Tag Index Name   | Create Tag Index                                 |\n+------------------+--------------------------------------------------+\n| \"player_index_1\" | \"CREATE TAG INDEX `player_index_1` ON `player` ( |\n|                  |  `name`(20)                                      |\n|                  | )\"                                               |\n+------------------+--------------------------------------------------+\n</code></pre> <p>Edge indexes can be queried through a similar approach.</p> <pre><code>nebula&gt; SHOW EDGE INDEXES;\n+----------------+----------+---------+\n| Index Name     | By Edge  | Columns |\n+----------------+----------+---------+\n| \"follow_index\" | \"follow\" | []      |\n+----------------+----------+---------+\n\nnebula&gt; SHOW CREATE EDGE INDEX follow_index;\n+-----------------+-------------------------------------------------+\n| Edge Index Name | Create Edge Index                               |\n+-----------------+-------------------------------------------------+\n| \"follow_index\"  | \"CREATE EDGE INDEX `follow_index` ON `follow` ( |\n|                 | )\"                                              |\n+-----------------+-------------------------------------------------+\n</code></pre> <p>Legacy version compatibility</p> <p>In NebulaGraph 2.0.1, the <code>SHOW TAG/EDGE INDEXES</code> statement only returns <code>Names</code>.</p>"},{"location":"3.ngql-guide/14.native-index-statements/2.show-native-indexes/","title":"SHOW INDEXES","text":"<p><code>SHOW INDEXES</code> shows the defined tag or edge type indexes names in the current graph space.</p>"},{"location":"3.ngql-guide/14.native-index-statements/2.show-native-indexes/#syntax","title":"Syntax","text":"<pre><code>SHOW {TAG | EDGE} INDEXES\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/2.show-native-indexes/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW TAG INDEXES;\n+------------------+--------------+-----------------+\n| Index Name       | By Tag       | Columns         |\n+------------------+--------------+-----------------+\n| \"fix\"            | \"fix_string\" | [\"p1\"]          |\n| \"player_index_0\" | \"player\"     | [\"name\"]        |\n| \"player_index_1\" | \"player\"     | [\"name\", \"age\"] |\n| \"var\"            | \"var_string\" | [\"p1\"]          |\n+------------------+--------------+-----------------+\n\nnebula&gt; SHOW EDGE INDEXES;\n+----------------+----------+---------+\n| Index Name     | By Edge  | Columns |\n| \"follow_index\" | \"follow\" | []      |\n+----------------+----------+---------+\n</code></pre> <p>Legacy version compatibility</p> <p>In NebulaGraph 2.0.1, the <code>SHOW TAG/EDGE INDEXES</code> statement only returns <code>Names</code>.</p>"},{"location":"3.ngql-guide/14.native-index-statements/3.describe-native-index/","title":"DESCRIBE INDEX","text":"<p><code>DESCRIBE INDEX</code> can get the information about the index with a given name, including the property name (Field) and the property type (Type) of the index.</p>"},{"location":"3.ngql-guide/14.native-index-statements/3.describe-native-index/#syntax","title":"Syntax","text":"<pre><code>DESCRIBE {TAG | EDGE} INDEX &lt;index_name&gt;;\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/3.describe-native-index/#examples","title":"Examples","text":"<pre><code>nebula&gt; DESCRIBE TAG INDEX player_index_0;\n+--------+--------------------+\n| Field  | Type               |\n+--------+--------------------+\n| \"name\" | \"fixed_string(30)\" |\n+--------+--------------------+\n\nnebula&gt; DESCRIBE TAG INDEX player_index_1;\n+--------+--------------------+\n| Field  | Type               |\n+--------+--------------------+\n| \"name\" | \"fixed_string(10)\" |\n| \"age\"  | \"int64\"            |\n+--------+--------------------+\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/4.rebuild-native-index/","title":"REBUILD INDEX","text":"<p>Danger</p> <p>If data is updated or inserted before the creation of the index, you must rebuild the indexes manually to make sure that the indexes contain the previously added data. Otherwise, you cannot use <code>LOOKUP</code> and <code>MATCH</code> to query the data based on the index. If the index is created before any data insertion, there is no need to rebuild the index.</p> <p>During the rebuilding, all queries skip the index and perform sequential scans. This means that the return results can be different because not all the data is indexed during rebuilding.</p> <p>You can use <code>REBUILD INDEX</code> to rebuild the created tag or edge type index. For details on how to create an index, see CREATE INDEX.</p>"},{"location":"3.ngql-guide/14.native-index-statements/4.rebuild-native-index/#syntax","title":"Syntax","text":"<pre><code>REBUILD {TAG | EDGE} INDEX [&lt;index_name_list&gt;];\n\n&lt;index_name_list&gt;::=\n    [index_name [, index_name] ...]\n</code></pre> <ul> <li>Multiple indexes are permitted in a single <code>REBUILD</code> statement, separated by commas. When the index name is not specified, all tag or edge indexes are rebuilt.</li> </ul> <ul> <li>After the rebuilding is complete, you can use the <code>SHOW {TAG | EDGE} INDEX STATUS</code> command to check if the index is successfully rebuilt. For details on index status, see SHOW INDEX STATUS.</li> </ul>"},{"location":"3.ngql-guide/14.native-index-statements/4.rebuild-native-index/#examples","title":"Examples","text":"<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS person(name string, age int, gender string, email string);\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS single_person_index ON person(name(10));\n\n# The following example rebuilds an index and returns the job ID.\nnebula&gt; REBUILD TAG INDEX single_person_index;\n+------------+\n| New Job Id |\n+------------+\n| 31         |\n+------------+\n\n# The following example checks the index status.\nnebula&gt; SHOW TAG INDEX STATUS;\n+-----------------------+--------------+\n| Name                  | Index Status |\n+-----------------------+--------------+\n| \"single_person_index\" | \"FINISHED\"   |\n+-----------------------+--------------+\n\n# You can also use \"SHOW JOB &lt;job_id&gt;\" to check if the rebuilding process is complete.\nnebula&gt; SHOW JOB 31;\n+----------------+---------------------+------------+-------------------------+-------------------------+\n| Job Id(TaskId) | Command(Dest)       | Status     | Start Time              | Stop Time               |\n+----------------+---------------------+------------+-------------------------+-------------------------+\n| 31             | \"REBUILD_TAG_INDEX\" | \"FINISHED\" | 2021-07-07T09:04:24.000 | 2021-07-07T09:04:24.000 |\n| 0              | \"storaged1\"         | \"FINISHED\" | 2021-07-07T09:04:24.000 | 2021-07-07T09:04:28.000 |\n| 1              | \"storaged2\"         | \"FINISHED\" | 2021-07-07T09:04:24.000 | 2021-07-07T09:04:28.000 |\n| 2              | \"storaged0\"         | \"FINISHED\" | 2021-07-07T09:04:24.000 | 2021-07-07T09:04:28.000 |\n+----------------+---------------------+------------+-------------------------+-------------------------+\n</code></pre> <p>NebulaGraph creates a job to rebuild the index. The job ID is displayed in the preceding return message. To check if the rebuilding process is complete, use the <code>SHOW JOB &lt;job_id&gt;</code> statement. For more information, see SHOW JOB.</p>"},{"location":"3.ngql-guide/14.native-index-statements/4.rebuild-native-index/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<p>In NebulaGraph 2.x, the <code>OFFLINE</code> option is no longer needed or supported.</p>"},{"location":"3.ngql-guide/14.native-index-statements/5.show-native-index-status/","title":"SHOW INDEX STATUS","text":"<p><code>SHOW INDEX STATUS</code> returns the name of the created tag or edge type index and its status.</p> <p>The index status includes:</p> <ul> <li><code>QUEUE</code>: The job is in a queue.</li> <li><code>RUNNING</code>: The job is running.</li> <li><code>FINISHED</code>: The job is finished.</li> <li><code>FAILED</code>: The job has failed.</li> <li><code>STOPPED</code>: The job has stopped.</li> <li><code>INVALID</code>: The job is invalid.</li> </ul> <p>Note</p> <p>For details on how to create an index, see CREATE INDEX.</p>"},{"location":"3.ngql-guide/14.native-index-statements/5.show-native-index-status/#syntax","title":"Syntax","text":"<pre><code>SHOW {TAG | EDGE} INDEX STATUS;\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/5.show-native-index-status/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW TAG INDEX STATUS;\n+----------------------+--------------+\n| Name                 | Index Status |\n+----------------------+--------------+\n| \"player_index_0\"     | \"FINISHED\"   |\n| \"player_index_1\"     | \"FINISHED\"   |\n+----------------------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/14.native-index-statements/6.drop-native-index/","title":"DROP INDEX","text":"<p><code>DROP INDEX</code> removes an existing index from the current graph space.</p>"},{"location":"3.ngql-guide/14.native-index-statements/6.drop-native-index/#prerequisite","title":"Prerequisite","text":"<p>Running the <code>DROP INDEX</code> statement requires some privileges of <code>DROP TAG INDEX</code> and <code>DROP EDGE INDEX</code> in the given graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/14.native-index-statements/6.drop-native-index/#syntax","title":"Syntax","text":"<pre><code>DROP {TAG | EDGE} INDEX [IF EXISTS] &lt;index_name&gt;;\n</code></pre> <p><code>IF NOT EXISTS</code>: Detects whether the index that you want to drop exists. If it exists, it will be dropped.</p>"},{"location":"3.ngql-guide/14.native-index-statements/6.drop-native-index/#example","title":"Example","text":"<pre><code>nebula&gt; DROP TAG INDEX player_index_0;\n</code></pre>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/","title":"Full-text indexes","text":"<p>Full-text indexes are used to do prefix, wildcard, regexp, and fuzzy search on a string property.</p> <p>You can use the <code>WHERE</code> clause to specify the search strings in <code>LOOKUP</code> statements.</p>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#prerequisite","title":"Prerequisite","text":"<p>Before using the full-text index, make sure that you have deployed a Elasticsearch cluster and a Listener cluster. For more information, see Deploy Elasticsearch and Deploy Listener.</p>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#precaution","title":"Precaution","text":"<p>Before using the full-text index, make sure that you know the restrictions.</p>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#natural_language_full-text_search","title":"Natural language full-text search","text":"<p>A natural language search interprets the search string as a phrase in natural human language. The search is case-insensitive. By default, each substring (separated by spaces) will be searched separately. For example, there are three vertices with the tag <code>player</code>. The tag <code>player</code> contains the property <code>name</code>. The <code>name</code> of these three vertices are <code>Kevin Durant</code>, <code>Tim Duncan</code>, and <code>David Beckham</code>. Now that the full-text index of <code>player.name</code> is established, these three vertices will be queried when using the prefix search statement <code>LOOKUP ON player WHERE PREFIX(player.name,\"d\");</code>.</p>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#syntax","title":"Syntax","text":""},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#create_full-text_indexes","title":"Create full-text indexes","text":"<pre><code>CREATE FULLTEXT {TAG | EDGE} INDEX &lt;index_name&gt; ON {&lt;tag_name&gt; | &lt;edge_name&gt;} ([&lt;prop_name_list&gt;]);\n</code></pre>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#show_full-text_indexes","title":"Show full-text indexes","text":"<pre><code>SHOW FULLTEXT INDEXES;\n</code></pre>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#rebuild_full-text_indexes","title":"Rebuild full-text indexes","text":"<pre><code>REBUILD FULLTEXT INDEX;\n</code></pre>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#drop_full-text_indexes","title":"Drop full-text indexes","text":"<pre><code>DROP FULLTEXT INDEX &lt;index_name&gt;;\n</code></pre>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#use_query_options","title":"Use query options","text":"<pre><code>LOOKUP ON {&lt;tag&gt; | &lt;edge_type&gt;} WHERE &lt;expression&gt; [YIELD &lt;return_list&gt;];\n\n&lt;expression&gt; ::=\n    PREFIX | WILDCARD | REGEXP | FUZZY\n\n&lt;return_list&gt;\n    &lt;prop_name&gt; [AS &lt;prop_alias&gt;] [, &lt;prop_name&gt; [AS &lt;prop_alias&gt;] ...]\n</code></pre> <ul> <li>PREFIX(schema_name.prop_name, prefix_string, row_limit, timeout)</li> </ul> <ul> <li>WILDCARD(schema_name.prop_name, wildcard_string, row_limit, timeout)</li> </ul> <ul> <li>REGEXP(schema_name.prop_name, regexp_string, row_limit, timeout)</li> </ul> <ul> <li> <p>FUZZY(schema_name.prop_name, fuzzy_string, fuzziness, operator, row_limit, timeout)</p> <ul> <li><code>fuzziness</code> (optional): Maximum edit distance allowed for matching. The default value is <code>AUTO</code>. For other valid values and more information, see Elasticsearch document.</li> </ul> <ul> <li><code>operator</code> (optional): Boolean logic used to interpret the text. Valid values are <code>OR</code> (default) and <code>AND</code>.</li> </ul> </li> </ul> <ul> <li><code>row_limit</code> (optional): Specifies the number of rows to return. The default value is <code>100</code>.</li> </ul> <ul> <li><code>timeout</code> (optional): Specifies the timeout time. The default value is <code>200ms</code>.</li> </ul>"},{"location":"3.ngql-guide/15.full-text-index-statements/1.search-with-text-based-index/#examples","title":"Examples","text":"<pre><code>// This example creates the graph space.\nnebula&gt; CREATE SPACE IF NOT EXISTS basketballplayer (partition_num=3,replica_factor=1, vid_type=fixed_string(30));\n\n// This example signs in the text service.\nnebula&gt; SIGN IN TEXT SERVICE (127.0.0.1:9200);\n\n// This example switches the graph space.\nnebula&gt; USE basketballplayer;\n\n// This example adds the listener to the NebulaGraph cluster.\nnebula&gt; ADD LISTENER ELASTICSEARCH 192.168.8.5:9789;\n\n// This example creates the tag.\nnebula&gt; CREATE TAG IF NOT EXISTS player(name string, age int);\n\n// This example creates the native index.\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS name ON player(name(20));\n\n// This example rebuilds the native index.\nnebula&gt; REBUILD TAG INDEX;\n\n// This example creates the full-text index. The index name starts with \"nebula\".\nnebula&gt; CREATE FULLTEXT TAG INDEX nebula_index_1 ON player(name);\n\n// This example rebuilds the full-text index.\nnebula&gt; REBUILD FULLTEXT INDEX;\n\n// This example shows the full-text index.\nnebula&gt; SHOW FULLTEXT INDEXES;\n+------------------+-------------+-------------+--------+\n| Name             | Schema Type | Schema Name | Fields |\n+------------------+-------------+-------------+--------+\n| \"nebula_index_1\" | \"Tag\"       | \"player\"    | \"name\" |\n+------------------+-------------+-------------+--------+\n\n// This example inserts the test data.\nnebula&gt; INSERT VERTEX player(name, age) VALUES \\\n  \"Russell Westbrook\": (\"Russell Westbrook\", 30), \\\n  \"Chris Paul\": (\"Chris Paul\", 33),\\\n  \"Boris Diaw\": (\"Boris Diaw\", 36),\\\n  \"David West\": (\"David West\", 38),\\\n  \"Danny Green\": (\"Danny Green\", 31),\\\n  \"Tim Duncan\": (\"Tim Duncan\", 42),\\\n  \"James Harden\": (\"James Harden\", 29),\\\n  \"Tony Parker\": (\"Tony Parker\", 36),\\\n  \"Aron Baynes\": (\"Aron Baynes\", 32),\\\n  \"Ben Simmons\": (\"Ben Simmons\", 22),\\\n  \"Blake Griffin\": (\"Blake Griffin\", 30);\n\n// These examples run test queries.\nnebula&gt; LOOKUP ON player WHERE PREFIX(player.name, \"B\");\n+-----------------+\n| _vid            |\n+-----------------+\n| \"Boris Diaw\"    |\n| \"Ben Simmons\"   |\n| \"Blake Griffin\" |\n+-----------------+\n\nnebula&gt; LOOKUP ON player WHERE WILDCARD(player.name, \"*ri*\") YIELD player.name, player.age;\n+-----------------+-----------------+-----+\n| _vid            | name            | age |\n+-----------------+-----------------+-----+\n| \"Chris Paul\"    | \"Chris Paul\"    | 33  |\n| \"Boris Diaw\"    | \"Boris Diaw\"    | 36  |\n| \"Blake Griffin\" | \"Blake Griffin\" | 30  |\n+-----------------+-----------------+-----+\n\nnebula&gt; LOOKUP ON player WHERE WILDCARD(player.name, \"*ri*\") | YIELD count(*);\n+----------+\n| count(*) |\n+----------+\n| 3        |\n+----------+\n\nnebula&gt; LOOKUP ON player WHERE REGEXP(player.name, \"R.*\") YIELD player.name, player.age;\n+---------------------+---------------------+-----+\n| _vid                | name                | age |\n+---------------------+---------------------+-----+\n| \"Russell Westbrook\" | \"Russell Westbrook\" | 30  |\n+---------------------+---------------------+-----+\n\nnebula&gt; LOOKUP ON player WHERE REGEXP(player.name, \".*\");\n+---------------------+\n| _vid                |\n+---------------------+\n| \"Danny Green\"       |\n| \"David West\"        |\n| \"Russell Westbrook\" |\n+---------------------+\n...\n\nnebula&gt; LOOKUP ON player WHERE FUZZY(player.name, \"Tim Dunncan\", AUTO, OR) YIELD player.name;\n+--------------+--------------+\n| _vid         | name         |\n+--------------+--------------+\n| \"Tim Duncan\" | \"Tim Duncan\" |\n+--------------+--------------+\n\n// This example drops the full-text index.\nnebula&gt; DROP FULLTEXT INDEX nebula_index_1;\n</code></pre>"},{"location":"3.ngql-guide/16.subgraph-and-path/1.get-subgraph/","title":"GET SUBGRAPH","text":"<p>The <code>GET SUBGRAPH</code> statement retrieves information of vertices and edges reachable from the source vertices of the specified edge types and returns information of the subgraph.</p>"},{"location":"3.ngql-guide/16.subgraph-and-path/1.get-subgraph/#syntax","title":"Syntax","text":"<pre><code>GET SUBGRAPH [WITH PROP] [&lt;step_count&gt; STEPS] FROM {&lt;vid&gt;, &lt;vid&gt;...}\n[{IN | OUT | BOTH} &lt;edge_type&gt;, &lt;edge_type&gt;...]\n[YIELD [VERTICES AS &lt;vertex_alias&gt;] [,EDGES AS &lt;edge_alias&gt;]];\n</code></pre> <ul> <li><code>WITH PROP</code> shows the properties. If not specified, the properties will be hidden.</li> </ul> <ul> <li><code>step_count</code> specifies the number of hops from the source vertices and returns the subgraph from 0 to <code>step_count</code> hops. It must be a non-negative integer. Its default value is 1.</li> </ul> <ul> <li><code>vid</code> specifies the vertex IDs.</li> </ul> <ul> <li><code>edge_type</code> specifies the edge type. You can use <code>IN</code>, <code>OUT</code>, and <code>BOTH</code> to specify the traversal direction of the edge type. The default is <code>BOTH</code>.</li> </ul> <ul> <li><code>YIELD</code> defines the output that needs to be returned. You can return only vertexes or edges. The alias must be set. When you do not use <code>YIELD</code> to define the output result, <code>_vertices</code> and <code>_edges</code> are returned by default.</li> </ul> <p>Note</p> <p>The path type of <code>GET SUBGRAPH</code> is <code>trail</code>. Only vertices can be repeatedly visited in graph traversal. For more information, see Path.</p>"},{"location":"3.ngql-guide/16.subgraph-and-path/1.get-subgraph/#examples","title":"Examples","text":"<p>The following graph is used as the sample.</p> <p></p> <p>Insert the test data:</p> <pre><code>nebula&gt; CREATE SPACE IF NOT EXISTS subgraph(partition_num=15, replica_factor=1, vid_type=fixed_string(30));\nnebula&gt; USE subgraph;\nnebula&gt; CREATE TAG IF NOT EXISTS player(name string, age int);\nnebula&gt; CREATE TAG IF NOT EXISTS team(name string);\nnebula&gt; CREATE EDGE IF NOT EXISTS follow(degree int);\nnebula&gt; CREATE EDGE IF NOT EXISTS serve(start_year int, end_year int);\nnebula&gt; INSERT VERTEX player(name, age) VALUES \"player100\":(\"Tim Duncan\", 42);\nnebula&gt; INSERT VERTEX player(name, age) VALUES \"player101\":(\"Tony Parker\", 36);\nnebula&gt; INSERT VERTEX player(name, age) VALUES \"player102\":(\"LaMarcus Aldridge\", 33);\nnebula&gt; INSERT VERTEX team(name) VALUES \"team203\":(\"Trail Blazers\"), \"team204\":(\"Spurs\");\nnebula&gt; INSERT EDGE follow(degree) VALUES \"player101\" -&gt; \"player100\":(95);\nnebula&gt; INSERT EDGE follow(degree) VALUES \"player101\" -&gt; \"player102\":(90);\nnebula&gt; INSERT EDGE follow(degree) VALUES \"player102\" -&gt; \"player100\":(75);\nnebula&gt; INSERT EDGE serve(start_year, end_year) VALUES \"player101\" -&gt; \"team204\":(1999, 2018),\"player102\" -&gt; \"team203\":(2006,  2015);\n</code></pre> <ul> <li>This example goes one step from the vertex <code>player101</code> over all edge types and gets the subgraph.<pre><code>nebula&gt; GET SUBGRAPH 1 STEPS FROM \"player101\" YIELD VERTICES AS nodes, EDGES AS relationships;\n+-------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n| nodes                                                                   | relationships                                                                                                               |\n+-------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n| [(\"player101\" :player{})]                                               | [[:serve \"player101\"-&gt;\"team204\" @0 {}], [:follow \"player101\"-&gt;\"player100\" @0 {}], [:follow \"player101\"-&gt;\"player102\" @0 {}]] |\n| [(\"team204\" :team{}), (\"player100\" :player{}), (\"player102\" :player{})] | [[:follow \"player102\"-&gt;\"player100\" @0 {}]]                                                                                  |\n+-------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>The returned subgraph is as follows.</p> <p></p> </li> </ul> <ul> <li>This example goes one step from the vertex <code>player101</code> over incoming <code>follow</code> edges and gets the subgraph.<pre><code>nebula&gt; GET SUBGRAPH 1 STEPS FROM \"player101\" IN follow YIELD VERTICES AS nodes, EDGES AS relationships;\n+---------------------------+---------------+\n| nodes                     | relationships |\n+---------------------------+---------------+\n| [(\"player101\" :player{})] | []            |\n| []                        | []            |\n+---------------------------+---------------+\n</code></pre> <p>There is no incoming <code>follow</code> edge to <code>player101</code>, so only the vertex <code>player101</code> is returned.</p> </li> </ul> <ul> <li>This example goes one step from the vertex <code>player101</code> over outgoing <code>serve</code> edges, gets the subgraph, and shows the property of the edge.<pre><code>nebula&gt; GET SUBGRAPH WITH PROP 1 STEPS FROM \"player101\" OUT serve YIELD VERTICES AS nodes, EDGES AS relationships;\n+-------------------------------------------------------+-------------------------------------------------------------------------+\n| nodes                                                 | relationships                                                           |\n+-------------------------------------------------------+-------------------------------------------------------------------------+\n| [(\"player101\" :player{age: 36, name: \"Tony Parker\"})] | [[:serve \"player101\"-&gt;\"team204\" @0 {end_year: 2018, start_year: 1999}]] |\n| [(\"team204\" :team{name: \"Spurs\"})]                    | []                                                                      |\n+-------------------------------------------------------+-------------------------------------------------------------------------+\n</code></pre> <p>The returned subgraph is as follows.</p> <p></p> </li> </ul>"},{"location":"3.ngql-guide/16.subgraph-and-path/1.get-subgraph/#faq","title":"FAQ","text":""},{"location":"3.ngql-guide/16.subgraph-and-path/1.get-subgraph/#why_is_the_number_of_hops_in_the_returned_result_greater_than_step_count","title":"Why is the number of hops in the returned result greater than <code>step_count</code>?","text":"<p>To show the completeness of the subgraph, an additional hop is made on all vertices that meet the conditions. The following graph is used as the sample.</p> <p></p> <ul> <li>The returned paths of <code>GET SUBGRAPH 1 STEPS FROM \"A\";</code> are <code>A-&gt;B</code>, <code>B-&gt;A</code>, and <code>A-&gt;C</code>. To show the completeness of the subgraph, an additional hop is made on all vertices that meet the conditions, namely <code>B-&gt;C</code>.</li> </ul> <ul> <li>The returned path of <code>GET SUBGRAPH 1 STEPS FROM \"A\" IN follow;</code> is <code>B-&gt;A</code>. To show the completeness of the subgraph, an additional hop is made on all vertices that meet the conditions, namely <code>A-&gt;B</code>.</li> </ul> <p>If you only query paths or vertices that meet the conditions, we suggest you use MATCH or GO. The example is as follows.</p> <pre><code>nebula&gt; match p= (v:player) -- (v2) where id(v)==\"A\" return p;\n\nnebula&gt; go 1 steps from \"A\" over follow;\n</code></pre>"},{"location":"3.ngql-guide/16.subgraph-and-path/1.get-subgraph/#why_is_the_number_of_hops_in_the_returned_result_lower_than_step_count","title":"Why is the number of hops in the returned result lower than <code>step_count</code>?","text":"<p>The query stops when there is not enough subgraph data and will not return the null value.</p> <pre><code>nebula&gt; GET SUBGRAPH 100 STEPS FROM \"player101\" OUT follow YIELD VERTICES AS nodes, EDGES AS relationships;\n+----------------------------------------------------+--------------------------------------------------------------------------------------+\n| nodes                                              | relationships                                                                        |\n+----------------------------------------------------+--------------------------------------------------------------------------------------+\n| [(\"player101\" :player{})]                          | [[:follow \"player101\"-&gt;\"player100\" @0 {}], [:follow \"player101\"-&gt;\"player102\" @0 {}]] |\n| [(\"player100\" :player{}), (\"player102\" :player{})] | [[:follow \"player102\"-&gt;\"player100\" @0 {}]]                                           |\n+----------------------------------------------------+--------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/16.subgraph-and-path/2.find-path/","title":"FIND PATH","text":"<p>The <code>FIND PATH</code> statement finds the paths between the selected source vertices and destination vertices.</p>"},{"location":"3.ngql-guide/16.subgraph-and-path/2.find-path/#syntax","title":"Syntax","text":"<pre><code>FIND { SHORTEST | ALL | NOLOOP } PATH [WITH PROP] FROM &lt;vertex_id_list&gt; TO &lt;vertex_id_list&gt;\nOVER &lt;edge_type_list&gt; [REVERSELY | BIDIRECT] [&lt;WHERE clause&gt;] [UPTO &lt;N&gt; STEPS] [| ORDER BY $-.path] [| LIMIT &lt;M&gt;];\n\n&lt;vertex_id_list&gt; ::=\n    [vertex_id [, vertex_id] ...]\n</code></pre> <ul> <li><code>SHORTEST</code> finds the shortest path.</li> </ul> <ul> <li><code>ALL</code> finds all the paths.</li> </ul> <ul> <li><code>NOLOOP</code> finds the paths without circles.</li> </ul> <ul> <li><code>WITH PROP</code> shows properties of vertices and edges. If not specified, properties will be hidden.</li> </ul> <ul> <li><code>&lt;vertex_id_list&gt;</code> is a list of vertex IDs separated with commas (,). It supports <code>$-</code> and <code>$var</code>.</li> </ul> <ul> <li><code>&lt;edge_type_list&gt;</code> is a list of edge types separated with commas (,). <code>*</code> is all edge types.</li> </ul> <ul> <li><code>REVERSELY | BIDIRECT</code> specifies the direction. <code>REVERSELY</code> is reverse graph traversal while <code>BIDIRECT</code> is bidirectional graph traversal.</li> </ul> <ul> <li><code>&lt;WHERE clause&gt;</code> filters properties of edges.</li> </ul> <ul> <li><code>&lt;N&gt;</code> is the maximum hop number of the path. The default value is <code>5</code>.</li> </ul> <ul> <li><code>&lt;M&gt;</code> specifies the maximum number of rows to return.</li> </ul> <p>Note</p> <p>The path type of <code>FIND PATH</code> is <code>trail</code>. Only vertices can be repeatedly visited in graph traversal. For more information, see Path.</p>"},{"location":"3.ngql-guide/16.subgraph-and-path/2.find-path/#limitations","title":"Limitations","text":"<ul> <li>When a list of source and/or destination vertex IDs are specified, the paths between any source vertices and the destination vertices will be returned.</li> </ul> <ul> <li>There can be cycles when searching all paths.</li> </ul> <ul> <li><code>FIND PATH</code> only supports filtering properties of edges with <code>WHERE</code> clauses. Filtering properties of vertices and functions are not supported for now.</li> </ul> <ul> <li><code>FIND PATH</code> is a single-thread procedure, so it uses much memory.</li> </ul>"},{"location":"3.ngql-guide/16.subgraph-and-path/2.find-path/#examples","title":"Examples","text":"<p>A returned path is like <code>(&lt;vertex_id&gt;)-[:&lt;edge_type_name&gt;@&lt;rank&gt;]-&gt;(&lt;vertex_id)</code>.</p> <pre><code>nebula&gt; FIND SHORTEST PATH FROM \"player102\" TO \"team204\" OVER *;\n+--------------------------------------------+\n| path                                       |\n+--------------------------------------------+\n| &lt;(\"player102\")-[:serve@0 {}]-&gt;(\"team204\")&gt; |\n+--------------------------------------------+\n</code></pre> <pre><code>nebula&gt; FIND SHORTEST PATH WITH PROP FROM \"team204\" TO \"player100\" OVER * REVERSELY;\n+--------------------------------------------------------------------------------------------------------------------------------------+\n| path                                                                                                                                 |\n+--------------------------------------------------------------------------------------------------------------------------------------+\n| &lt;(\"team204\" :team{name: \"Spurs\"})&lt;-[:serve@0 {end_year: 2016, start_year: 1997}]-(\"player100\" :player{age: 42, name: \"Tim Duncan\"})&gt; |\n+--------------------------------------------------------------------------------------------------------------------------------------+\n</code></pre> <pre><code>nebula&gt; FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree &gt;=0;\n+------------------------------------------------------------------------------+\n| path                                                                         |\n+------------------------------------------------------------------------------+\n| &lt;(\"player100\")-[:serve@0 {}]-&gt;(\"team204\")&gt;                                   |\n| &lt;(\"player100\")-[:follow@0 {}]-&gt;(\"player125\")-[:serve@0 {}]-&gt;(\"team204\")&gt;     |\n| &lt;(\"player100\")-[:follow@0 {}]-&gt;(\"player101\")-[:serve@0 {}]-&gt;(\"team204\")&gt;     |\n|...                                                                           |\n+------------------------------------------------------------------------------+\n</code></pre> <pre><code>nebula&gt; FIND NOLOOP PATH FROM \"player100\" TO \"team204\" OVER *;\n+--------------------------------------------------------------------------------------------------------+\n| path                                                                                                   |\n+--------------------------------------------------------------------------------------------------------+\n| &lt;(\"player100\")-[:serve@0 {}]-&gt;(\"team204\")&gt;                                                             |\n| &lt;(\"player100\")-[:follow@0 {}]-&gt;(\"player125\")-[:serve@0 {}]-&gt;(\"team204\")&gt;                               |\n| &lt;(\"player100\")-[:follow@0 {}]-&gt;(\"player101\")-[:serve@0 {}]-&gt;(\"team204\")&gt;                               |\n| &lt;(\"player100\")-[:follow@0 {}]-&gt;(\"player101\")-[:follow@0 {}]-&gt;(\"player125\")-[:serve@0 {}]-&gt;(\"team204\")&gt; |\n| &lt;(\"player100\")-[:follow@0 {}]-&gt;(\"player101\")-[:follow@0 {}]-&gt;(\"player102\")-[:serve@0 {}]-&gt;(\"team204\")&gt; |\n+--------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/16.subgraph-and-path/2.find-path/#faq","title":"FAQ","text":""},{"location":"3.ngql-guide/16.subgraph-and-path/2.find-path/#does_it_support_the_where_clause_to_achieve_conditional_filtering_during_graph_traversal","title":"Does it support the WHERE clause to achieve conditional filtering during graph traversal?","text":"<p><code>FIND PATH</code> only supports filtering properties of edges with <code>WHERE</code> clauses, such as <code>FIND ALL PATH FROM \"player100\" TO \"team204\" OVER * WHERE follow.degree is EMPTY or follow.degree &gt;=0;</code>.</p> <p>Filtering properties of vertices is not supported for now.</p>"},{"location":"3.ngql-guide/17.query-tuning-statements/1.explain-and-profile/","title":"EXPLAIN and PROFILE","text":"<p><code>EXPLAIN</code> helps output the execution plan of an nGQL statement without executing the statement.</p> <p><code>PROFILE</code> executes the statement, then outputs the execution plan as well as the execution profile. You can optimize the queries for better performance according to the execution plan and profile.</p>"},{"location":"3.ngql-guide/17.query-tuning-statements/1.explain-and-profile/#execution_plan","title":"Execution Plan","text":"<p>The execution plan is determined by the execution planner in the NebulaGraph query engine.</p> <p>The execution planner processes the parsed nGQL statements into <code>actions</code>. An <code>action</code> is the smallest unit that can be executed. A typical <code>action</code> fetches all neighbors of a given vertex, gets the properties of an edge, and filters vertices or edges based on the given conditions. Each <code>action</code> is assigned to an <code>operator</code> that performs the action.</p> <p>For example, a <code>SHOW TAGS</code> statement is processed into two <code>actions</code> and assigned to a <code>Start operator</code> and a <code>ShowTags operator</code>, while a more complex <code>GO</code> statement may be processed into more than 10 <code>actions</code> and assigned to 10 operators.</p>"},{"location":"3.ngql-guide/17.query-tuning-statements/1.explain-and-profile/#syntax","title":"Syntax","text":"<ul> <li><code>EXPLAIN</code><pre><code>EXPLAIN [format=\"row\" | \"dot\"] &lt;your_nGQL_statement&gt;;\n</code></pre> </li> </ul> <ul> <li><code>PROFILE</code><pre><code>PROFILE [format=\"row\" | \"dot\"] &lt;your_nGQL_statement&gt;;\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/17.query-tuning-statements/1.explain-and-profile/#output_formats","title":"Output formats","text":"<p>The output of an <code>EXPLAIN</code> or a <code>PROFILE</code> statement has two formats, the default <code>row</code> format and the <code>dot</code> format. You can use the <code>format</code> option to modify the output format. Omitting the <code>format</code> option indicates using the default <code>row</code> format.</p>"},{"location":"3.ngql-guide/17.query-tuning-statements/1.explain-and-profile/#the_row_format","title":"The <code>row</code> format","text":"<p>The <code>row</code> format outputs the return message in a table as follows.</p> <ul> <li><code>EXPLAIN</code><pre><code>nebula&gt; EXPLAIN format=\"row\" SHOW TAGS;\nExecution succeeded (time spent 327/892 us)\n\nExecution Plan\n\n-----+----------+--------------+----------------+----------------------------------------------------------------------\n| id | name     | dependencies | profiling data | operator info                                                       |\n-----+----------+--------------+----------------+----------------------------------------------------------------------\n|  1 | ShowTags | 0            |                | outputVar: [{\"colNames\":[],\"name\":\"__ShowTags_1\",\"type\":\"DATASET\"}] |\n|    |          |              |                | inputVar:                                                           |\n-----+----------+--------------+----------------+----------------------------------------------------------------------\n|  0 | Start    |              |                | outputVar: [{\"colNames\":[],\"name\":\"__Start_0\",\"type\":\"DATASET\"}]    |\n-----+----------+--------------+----------------+----------------------------------------------------------------------\n</code></pre> </li> </ul> <ul> <li><code>PROFILE</code><pre><code>nebula&gt; PROFILE format=\"row\" SHOW TAGS;\n+--------+\n| Name   |\n+--------+\n| player |\n+--------+\n| team   |\n+--------+\nGot 2 rows (time spent 2038/2728 us)\n\nExecution Plan\n\n-----+----------+--------------+----------------------------------------------------+----------------------------------------------------------------------\n| id | name     | dependencies | profiling data                                     | operator info                                                       |\n-----+----------+--------------+----------------------------------------------------+----------------------------------------------------------------------\n|  1 | ShowTags | 0            | ver: 0, rows: 1, execTime: 42us, totalTime: 1177us | outputVar: [{\"colNames\":[],\"name\":\"__ShowTags_1\",\"type\":\"DATASET\"}] |\n|    |          |              |                                                    | inputVar:                                                           |\n-----+----------+--------------+----------------------------------------------------+----------------------------------------------------------------------\n|  0 | Start    |              | ver: 0, rows: 0, execTime: 1us, totalTime: 57us    | outputVar: [{\"colNames\":[],\"name\":\"__Start_0\",\"type\":\"DATASET\"}]    |\n-----+----------+--------------+----------------------------------------------------+----------------------------------------------------------------------\n</code></pre> </li> </ul> <p>The descriptions are as follows.</p> Parameter Description <code>id</code> The ID of the <code>operator</code>. <code>name</code> The name of the <code>operator</code>. <code>dependencies</code> The ID of the <code>operator</code> that the current <code>operator</code> depends on. <code>profiling data</code> The content of the execution profile. <code>ver</code> is the version of the <code>operator</code>. <code>rows</code> shows the number of rows to be output by the <code>operator</code>. <code>execTime</code> shows the execution time of <code>action</code>. <code>totalTime</code> is the sum of the execution time, the system scheduling time, and the queueing time. <code>operator info</code> The detailed information of the <code>operator</code>."},{"location":"3.ngql-guide/17.query-tuning-statements/1.explain-and-profile/#the_dot_format","title":"The <code>dot</code> format","text":"<p>You can use the <code>format=\"dot\"</code> option to output the return message in the <code>dot</code> language, and then use Graphviz to generate a graph of the plan.</p> <p>Note</p> <p>Graphviz is open source graph visualization software. Graphviz provides an online tool for previewing DOT language files and exporting them to other formats such as SVG or JSON. For more information, see Graphviz Online.</p> <pre><code>nebula&gt; EXPLAIN format=\"dot\" SHOW TAGS;\nExecution succeeded (time spent 161/665 us)\nExecution Plan\n---------------------------------------------------------------------------------------------------------------------------------------------  -------------\n  plan\n---------------------------------------------------------------------------------------------------------------------------------------------  -------------\n  digraph exec_plan {\n      rankdir=LR;\n      \"ShowTags_0\"[label=\"ShowTags_0|outputVar: \\[\\{\\\"colNames\\\":\\[\\],\\\"name\\\":\\\"__ShowTags_0\\\",\\\"type\\\":\\\"DATASET\\\"\\}\\]\\l|inputVar:\\l\",   shape=Mrecord];\n      \"Start_2\"-&gt;\"ShowTags_0\";\n      \"Start_2\"[label=\"Start_2|outputVar: \\[\\{\\\"colNames\\\":\\[\\],\\\"name\\\":\\\"__Start_2\\\",\\\"type\\\":\\\"DATASET\\\"\\}\\]\\l|inputVar: \\l\",   shape=Mrecord];\n  }\n---------------------------------------------------------------------------------------------------------------------------------------------  -------------\n</code></pre> <p>The Graphviz graph transformed from the above DOT statement is as follows.</p> <p></p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/2.balance-syntax/","title":"BALANCE syntax","text":"<p>The <code>BALANCE</code> statements support the load balancing operations of the NebulaGraph Storage services. For more information about storage load balancing and examples for using the <code>BALANCE</code> statements, see Storage load balance.</p> <p>The <code>BALANCE</code> statements are listed as follows.</p> Syntax Description <code>BALANCE DATA</code> Starts a task to balance the distribution of storage partitions in a NebulaGraph cluster or a Group. It returns the task ID (<code>balance_id</code>). <code>BALANCE DATA &lt;balance_id&gt;</code> Shows the status of the <code>BALANCE DATA</code> task. <code>BALANCE DATA STOP</code> Stops the <code>BALANCE DATA</code> task. <code>BALANCE DATA REMOVE &lt;host_list&gt;</code> Scales in the NebulaGraph cluster and detaches specific storage hosts. <code>BALANCE LEADER</code> Balances the distribution of storage raft leaders in a NebulaGraph cluster or a Group."},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/","title":"Job manager and the JOB statements","text":"<p>The long-term tasks run by the Storage Service are called jobs, such as <code>COMPACT</code>, <code>FLUSH</code>, and <code>STATS</code>. These jobs can be time-consuming if the data amount in the graph space is large. The job manager helps you run, show, stop, and recover jobs.</p> <p>Note</p> <p>All job management commands can be executed only after selecting a graph space.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#submit_job_compact","title":"SUBMIT JOB COMPACT","text":"<p>The <code>SUBMIT JOB COMPACT</code> statement triggers the long-term RocksDB <code>compact</code> operation.</p> <p>For more information about <code>compact</code> configuration, see Storage Service configuration.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example","title":"Example","text":"<pre><code>nebula&gt; SUBMIT JOB COMPACT;\n+------------+\n| New Job Id |\n+------------+\n| 40         |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#submit_job_flush","title":"SUBMIT JOB FLUSH","text":"<p>The <code>SUBMIT JOB FLUSH</code> statement writes the RocksDB memfile in the memory to the hard disk.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example_1","title":"Example","text":"<pre><code>nebula&gt; SUBMIT JOB FLUSH;\n+------------+\n| New Job Id |\n+------------+\n| 96         |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#submit_job_stats","title":"SUBMIT JOB STATS","text":"<p>The <code>SUBMIT JOB STATS</code> statement starts a job that makes the statistics of the current graph space. Once this job succeeds, you can use the <code>SHOW STATS</code> statement to list the statistics. For more information, see SHOW STATS.</p> <p>Note</p> <p>If the data stored in the graph space changes, in order to get the latest statistics, you have to run <code>SUBMIT JOB STATS</code> again.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example_2","title":"Example","text":"<pre><code>nebula&gt; SUBMIT JOB STATS;\n+------------+\n| New Job Id |\n+------------+\n| 34         |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#show_job","title":"SHOW JOB","text":"<p>The Meta Service parses a <code>SUBMIT JOB</code> request into multiple tasks and assigns them to the nebula-storaged processes. The <code>SHOW JOB &lt;job_id&gt;</code> statement shows the information about a specific job and all its tasks in the current graph space.</p> <p><code>job_id</code> is returned when you run the <code>SUBMIT JOB</code> statement.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example_3","title":"Example","text":"<pre><code>nebula&gt; SHOW JOB 34;\n+----------------+-----------------+------------+----------------------------+----------------------------+\n| Job Id(TaskId) | Command(Dest)   | Status     | Start Time                 | Stop Time                  |\n+----------------+-----------------+------------+----------------------------+----------------------------+\n| 34             | \"STATS\"         | \"FINISHED\" | 2021-11-01T03:32:27.000000 | 2021-11-01T03:32:27.000000 |\n| 0              | \"192.168.8.111\" | \"FINISHED\" | 2021-11-01T03:32:27.000000 | 2021-11-01T03:32:41.000000 |\n+----------------+-----------------+------------+----------------------------+----------------------------+\n</code></pre> <p>The descriptions are as follows.</p> <p>| Parameter        | Description                                                                                                       | |------------------+-------------------------------------------------------------------------------------------------------------------| | <code>Job Id(TaskId)</code> | The first row shows the job ID and the other rows show the task IDs.                                              | | <code>Command(Dest)</code>  | The first row shows the command executed and the other rows show on which storaged processes the task is running. | | <code>Status</code>         | Shows the status of the job or task. For more information, see Job status.                         | | <code>Start Time</code>     | Shows a timestamp indicating the time when the job or task enters the <code>RUNNING</code> phase.                            | | <code>Stop Time</code>      | Shows a timestamp indicating the time when the job or task gets <code>FINISHED</code>, <code>FAILED</code>, or <code>STOPPED</code>.               |</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#job_status","title":"Job status","text":"<p>The descriptions are as follows.</p> <p>| Status   | Description                                                                                                        | |----------+--------------------------------------------------------------------------------------------------------------------| | QUEUE    | The job or task is waiting in a queue. The <code>Start Time</code> is empty in this phase.                                    | | RUNNING  | The job or task is running. The <code>Start Time</code> shows the beginning time of this phase.                               | | FINISHED | The job or task is successfully finished. The <code>Stop Time</code> shows the time when the job or task enters this phase.   | | FAILED   | The job or task has failed. The <code>Stop Time</code> shows the time when the job or task enters this phase.                 | | STOPPED  | The job or task is stopped without running. The <code>Stop Time</code> shows the time when the job or task enters this phase. | | REMOVED  | The job or task is removed.                                                                                        |</p> <p>The description of switching the status is described as follows.</p> <pre><code>Queue -- running -- finished -- removed\n     \\          \\                /\n      \\          \\ -- failed -- /\n       \\          \\            /\n        \\ ---------- stopped -/\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#show_jobs","title":"SHOW JOBS","text":"<p>The <code>SHOW JOBS</code> statement lists all the unexpired jobs in the current graph space.</p> <p>The default job expiration interval is one week. You can change it by modifying the <code>job_expired_secs</code> parameter of the Meta Service. For how to modify <code>job_expired_secs</code>, see Meta Service configuration.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example_4","title":"Example","text":"<pre><code>nebula&gt; SHOW JOBS;\n+--------+---------------------+------------+----------------------------+----------------------------+\n| Job Id | Command             | Status     | Start Time                 | Stop Time                  |\n+--------+---------------------+------------+----------------------------+----------------------------+\n| 34     | \"STATS\"             | \"FINISHED\" | 2021-11-01T03:32:27.000000 | 2021-11-01T03:32:27.000000 |\n| 33     | \"FLUSH\"             | \"FINISHED\" | 2021-11-01T03:32:15.000000 | 2021-11-01T03:32:15.000000 |\n| 32     | \"COMPACT\"           | \"FINISHED\" | 2021-11-01T03:32:06.000000 | 2021-11-01T03:32:06.000000 |\n| 31     | \"REBUILD_TAG_INDEX\" | \"FINISHED\" | 2021-10-29T05:39:16.000000 | 2021-10-29T05:39:17.000000 |\n| 10     | \"COMPACT\"           | \"FINISHED\" | 2021-10-26T02:27:05.000000 | 2021-10-26T02:27:05.000000 |\n+--------+---------------------+------------+----------------------------+----------------------------+\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#stop_job","title":"STOP JOB","text":"<p>The <code>STOP JOB</code> statement stops jobs that are not finished in the current graph space.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example_5","title":"Example","text":"<pre><code>nebula&gt; STOP JOB 22;\n+---------------+\n| Result        |\n+---------------+\n| \"Job stopped\" |\n+---------------+\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#recover_job","title":"RECOVER JOB","text":"<p>The <code>RECOVER JOB</code> statement re-executes the failed jobs in the current graph space and returns the number of recovered jobs.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#example_6","title":"Example","text":"<pre><code>nebula&gt; RECOVER JOB;\n+-------------------+\n| Recovered job num |\n+-------------------+\n| 5 job recovered   |\n+-------------------+\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#faq","title":"FAQ","text":""},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/4.job-statements/#how_to_troubleshoot_job_problems","title":"How to troubleshoot job problems?","text":"<p>The <code>SUBMIT JOB</code> operations use the HTTP port. Please check if the HTTP ports on the machines where the Storage Service is running are working well. You can use the following command to debug.</p> <pre><code>curl \"http://{storaged-ip}:19779/admin?space={space_name}&amp;op=compact\"\n</code></pre>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/6.kill-query/","title":"Kill queries","text":"<p><code>KILL QUERY</code> can terminate the query being executed, and is often used to terminate slow queries.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/6.kill-query/#syntax","title":"Syntax","text":"<pre><code>KILL QUERY (session=&lt;session_id&gt;, plan=&lt;plan_id&gt;);\n</code></pre> <ul> <li><code>session_id</code>: The ID of the session.</li> <li><code>plan_id</code>: The ID of the execution plan.</li> </ul> <p>The ID of the session and the ID of the execution plan can uniquely determine a query. Both can be obtained through the SHOW QUERIES statement.</p>"},{"location":"3.ngql-guide/18.operation-and-maintenance-statements/6.kill-query/#examples","title":"Examples","text":"<p>This example executes <code>KILL QUERY</code> in one session to terminate the query in another session.</p> <pre><code>nebula&gt; KILL QUERY(SESSION=1625553545984255,PLAN=163);\n</code></pre> <p>The query will be terminated and the following information will be returned.</p> <pre><code>[ERROR (-1005)]: Execution had been killed\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/1.numeric/","title":"Numeric types","text":"<p>nGQL supports both integer and floating-point number.</p>"},{"location":"3.ngql-guide/3.data-types/1.numeric/#integer","title":"Integer","text":"<p>Signed 64-bit integer (INT64), 32-bit integer (INT32), 16-bit integer (INT16), and 8-bit integer (INT8) are supported.</p> Type Declared keywords Range INT64 <code>INT64</code> or<code>INT</code> -9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807 INT32 <code>INT32</code> -2,147,483,648 ~ 2,147,483,647 INT16 <code>INT16</code> -32,768 ~ 32,767 INT8 <code>INT8</code> -128 ~ 127"},{"location":"3.ngql-guide/3.data-types/1.numeric/#floating-point_number","title":"Floating-point number","text":"<p>Both single-precision floating-point format (FLOAT) and double-precision floating-point format (DOUBLE) are supported.</p> Type Declared keywords Range Precision FLOAT <code>FLOAT</code> 3.4E +/- 38 6~7 bits DOUBLE <code>DOUBLE</code> 1.7E +/- 308 15~16 bits <p>Scientific notation is also supported, such as <code>1e2</code>, <code>1.1e2</code>, <code>.3e4</code>, <code>1.e4</code>, and <code>-1234E-10</code>.</p> <p>Note</p> <p>The data type of DECIMAL in MySQL is not supported.</p>"},{"location":"3.ngql-guide/3.data-types/1.numeric/#reading_and_writing_of_data_values","title":"Reading and writing of data values","text":"<p>When writing and reading different types of data, nGQL complies with the following rules:</p> Data type Set as VID Set as property Resulted data type INT64 Supported Supported INT64 INT32 Not supported Supported INT64 INT16 Not supported Supported INT64 INT8 Not supported Supported INT64 FLOAT Not supported Supported DOUBLE DOUBLE Not supported Supported DOUBLE <p>For example, nGQL does not support setting VID as INT8, but supports setting a certain property type of TAG or Edge type as INT8. When using the nGQL statement to read the property of INT8, the resulted type is INT64.</p> <p>Multiple formats are supported:</p> <ul> <li>Decimal, such as <code>123456</code>.</li> <li>Hexadecimal, such as <code>0x1e240</code>.</li> <li>Octal, such as <code>0361100</code>.</li> </ul> <p>However, NebulaGraph will parse the written non-decimal value into a decimal value and save it. The value read is decimal.</p> <p>For example, the type of the property <code>score</code> is <code>INT</code>. The value of <code>0xb</code> is assigned to it through the INSERT statement. If querying the property value with statements such as FETCH, you will get the result <code>11</code>, which is the decimal result of the hexadecimal <code>0xb</code>.</p>"},{"location":"3.ngql-guide/3.data-types/10.geography/","title":"Geography","text":"<p>Geography is a data type composed of latitude and longitude that represents geospatial information. NebulaGraph currently supports Point, LineString, and Polygon in Simple Features and some functions in SQL-MM 3, such as part of the core geo parsing, construction, formatting, conversion, predicates, and dimensions.</p>"},{"location":"3.ngql-guide/3.data-types/10.geography/#type_description","title":"Type description","text":"<p>A point is the basic data type of geography, which is determined by a latitude and a longitude. For example, <code>\"POINT(3 8)\"</code> means that the longitude is <code>3\u00b0</code> and the latitude is <code>8\u00b0</code>. Multiple points can form a linestring or a polygon.</p> Shape Example Description Point <code>\"POINT(3 8)\"</code> Specifies the data type as a point. LineString <code>\"LINESTRING(3 8, 4.7 73.23)\"</code> Specifies the data type as a linestring. Polygon <code>\"POLYGON((0 1, 1 2, 2 3, 0 1))\"</code> Specifies the data type as a polygon."},{"location":"3.ngql-guide/3.data-types/10.geography/#examples","title":"Examples","text":"<p>For functions about the geography data type, see Geography functions.</p> <pre><code>//Create a Tag to allow storing any geography data type.\nnebula&gt; CREATE TAG IF NOT EXISTS any_shape(geo geography);\n\n//Create a Tag to allow storing a point only.\nnebula&gt; CREATE TAG IF NOT EXISTS only_point(geo geography(point));\n\n//Create a Tag to allow storing a linestring only.\nnebula&gt; CREATE TAG IF NOT EXISTS only_linestring(geo geography(linestring));\n\n//Create a Tag to allow storing a polygon only.\nnebula&gt; CREATE TAG IF NOT EXISTS only_polygon(geo geography(polygon));\n\n//Create an Edge type to allow storing any geography data type.\nnebula&gt; CREATE EDGE IF NOT EXISTS any_shape_edge(geo geography);\n\n//Create a vertex to store the geography of a polygon.\nnebula&gt; INSERT VERTEX any_shape(geo) VALUES \"103\":(ST_GeogFromText(\"POLYGON((0 1, 1 2, 2 3, 0 1))\"));\n\n//Create an edge to store the geography of a polygon.\nnebula&gt; INSERT EDGE any_shape_edge(geo) VALUES \"201\"-&gt;\"302\":(ST_GeogFromText(\"POLYGON((0 1, 1 2, 2 3, 0 1))\"));\n\n//Query the geography of Vertex 103.\nnebula&gt; FETCH PROP ON any_shape \"103\" YIELD ST_ASText(any_shape.geo);\n+----------+---------------------------------+\n| VertexID | ST_ASText(any_shape.geo)        |\n+----------+---------------------------------+\n| \"103\"    | \"POLYGON((0 1, 1 2, 2 3, 0 1))\" |\n+----------+---------------------------------+\n\n//Query the geography of the edge which traverses from Vertex 201 to Vertex 302.\nnebula&gt; FETCH PROP ON any_shape_edge \"201\"-&gt;\"302\" YIELD ST_ASText(any_shape_edge.geo);\n+---------------------+---------------------+----------------------+---------------------------------+\n| any_shape_edge._src | any_shape_edge._dst | any_shape_edge._rank | ST_ASText(any_shape_edge.geo)   |\n+---------------------+---------------------+----------------------+---------------------------------+\n| \"201\"               | \"302\"               | 0                    | \"POLYGON((0 1, 1 2, 2 3, 0 1))\" |\n+---------------------+---------------------+----------------------+---------------------------------+\n\n//Create an index for the geography of the Tag any_shape and run LOOKUP.\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS any_shape_geo_index ON any_shape(geo);\nnebula&gt; REBUILD TAG INDEX any_shape_geo_index;\nnebula&gt; LOOKUP ON any_shape YIELD ST_ASText(any_shape.geo);\n+----------+-------------------------------------------------+\n| VertexID | ST_ASText(any_shape.geo)                        |\n+----------+-------------------------------------------------+\n| \"103\"    | \"POLYGON((0 1, 1 2, 2 3, 0 1))\"                 |\n+----------+-------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/2.boolean/","title":"Boolean","text":"<p>A boolean data type is declared with the <code>bool</code> keyword and can only take the values <code>true</code> or <code>false</code>.</p> <p>nGQL supports using boolean in the following ways:</p> <ul> <li>Define the data type of the property value as a boolean.</li> <li>Use boolean as judgment conditions in the <code>WHERE</code> clause.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/3.string/","title":"String","text":"<p>Fixed-length strings and variable-length strings are supported.</p>"},{"location":"3.ngql-guide/3.data-types/3.string/#declaration_and_literal_representation","title":"Declaration and literal representation","text":"<p>The string type is declared with the keywords of:</p> <ul> <li><code>STRING</code>: Variable-length strings.</li> <li><code>FIXED_STRING(&lt;length&gt;)</code>: Fixed-length strings. <code>&lt;length&gt;</code> is the length of the string, such as <code>FIXED_STRING(32)</code>.</li> </ul> <p>A string type is used to store a sequence of characters (text). The literal constant is a sequence of characters of any length surrounded by double or single quotes. For example, <code>\"Hello, Cooper\"</code> or <code>'Hello, Cooper'</code>.</p>"},{"location":"3.ngql-guide/3.data-types/3.string/#string_reading_and_writing","title":"String reading and writing","text":"<p>Nebula\u00a0Graph supports using string types in the following ways:</p> <ul> <li>Define the data type of VID as a fixed-length string.</li> <li>Set the variable-length string as the Schema name, including the names of the graph space, tag, edge type, and property.</li> <li>Define the data type of the property as a fixed-length or variable-length string.</li> </ul> <p>For example:</p> <ul> <li>Define the data type of the property as a fixed-length string<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS t1 (p1 FIXED_STRING(10)); \n</code></pre> </li> </ul> <ul> <li>Define the data type of the property as a variable-length string<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS t2 (p2 STRING); \n</code></pre> </li> </ul> <p>When the fixed-length string you try to write exceeds the length limit:</p> <ul> <li>If the fixed-length string is a property, the writing will succeed, and NebulaGraph will truncate the string and only store the part that meets the length limit.</li> <li>If the fixed-length string is a VID, the writing will fail and NebulaGraph will return an error.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/3.string/#escape_characters","title":"Escape characters","text":"<p>Line breaks are not allowed in a string. Escape characters are supported within strings, for example:</p> <ul> <li><code>\"\\n\\t\\r\\b\\f\"</code></li> </ul> <ul> <li><code>\"\\110ello world\"</code></li> </ul>"},{"location":"3.ngql-guide/3.data-types/3.string/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>There are some tiny differences between openCypher and Cypher, as well as nGQL. The following is what openCypher requires. Single quotes cannot be converted to double quotes.</p> <pre><code># File: Literals.feature\nFeature: Literals\n\nBackground:\n    Given any graph\n Scenario: Return a single-quoted string\n    When executing query:\n      \"\"\"\n      RETURN '' AS literal\n      \"\"\"\n    Then the result should be, in any order:\n      | literal |\n      | ''      |    # Note: it should return single-quotes as openCypher required.\n    And no side effects\n</code></pre> <p>While Cypher accepts both single quotes and double quotes as the return results. nGQL follows the Cypher way.</p> <pre><code>nebula &gt; YIELD '' AS quote1, \"\" AS quote2, \"'\" AS quote3, '\"' AS quote4\n+--------+--------+--------+--------+\n| quote1 | quote2 | quote3 | quote4 |\n+--------+--------+--------+--------+\n| \"\"     | \"\"     | \"'\"    | \"\"\"    |\n+--------+--------+--------+--------+\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/","title":"Date and time types","text":"<p>This topic will describe the <code>DATE</code>, <code>TIME</code>, <code>DATETIME</code>, and <code>TIMESTAMP</code> types.</p> <p>While inserting time-type property values, except for <code>TIMESTAMP</code>, NebulaGraph transforms them to a UTC time according to the time zone specified with the <code>timezone_name</code> parameter in the configuration files.</p> <p>Note</p> <p>To change the time zone, modify the <code>timezone_name</code> value in the configuration files of all NebulaGraph services.</p> <ul> <li><code>date()</code>, <code>time()</code>, <code>datetime()</code>, and <code>timestamp()</code> all accept empty parameters to return the current date, time, and datetime.</li> </ul> <ul> <li><code>date()</code>, <code>time()</code>, and <code>datetime()</code> all accept the property name to return a specific property value of itself. For example, <code>date().month</code> returns the current month, while <code>time(\"02:59:40\").minute</code> returns the minutes of the importing time.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/#opencypher_compatibility","title":"OpenCypher Compatibility","text":"<p>In nGQL:</p> <ul> <li>Year, month, day, hour, minute, and second are supported, while the millisecond is not supported.</li> </ul> <ul> <li><code>localdatetime()</code> and <code>duration()</code> are not supported.</li> </ul> <ul> <li>Most string time formats are not supported. The exceptions are <code>YYYY-MM-DDThh:mm:ss</code> and <code>YYYY-MM-DD hh:mm:ss</code>.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/#date","title":"DATE","text":"<p>The <code>DATE</code> type is used for values with a date part but no time part. Nebula\u00a0Graph retrieves and displays <code>DATE</code> values in the <code>YYYY-MM-DD</code> format. The supported range is <code>-32768-01-01</code> to <code>32767-12-31</code>.</p> <p>The properties of <code>date()</code> include <code>year</code>, <code>month</code>, and <code>day</code>.</p>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/#time","title":"TIME","text":"<p>The <code>TIME</code> type is used for values with a time part but no date part. Nebula\u00a0Graph retrieves and displays <code>TIME</code> values in <code>hh:mm:ss.msmsmsususus</code> format. The supported range is <code>00:00:00.000000</code> to <code>23:59:59.999999</code>.</p> <p>The properties of <code>time()</code> include <code>hour</code>, <code>minute</code>, and <code>second</code>.</p>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/#datetime","title":"DATETIME","text":"<p>The <code>DATETIME</code> type is used for values that contain both date and time parts. Nebula\u00a0Graph retrieves and displays <code>DATETIME</code> values in <code>YYYY-MM-DDThh:mm:ss.msmsmsususus</code> format. The supported range is <code>-32768-01-01T00:00:00.000000</code> to <code>32767-12-31T23:59:59.999999</code>.</p> <p>The properties of <code>datetime()</code> include <code>year</code>, <code>month</code>, <code>day</code>, <code>hour</code>, <code>minute</code>, and <code>second</code>.</p>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/#timestamp","title":"TIMESTAMP","text":"<p>The <code>TIMESTAMP</code> data type is used for values that contain both date and time parts. It has a range of <code>1970-01-01T00:00:01</code> UTC to <code>2262-04-11T23:47:16</code> UTC.</p> <p><code>TIMESTAMP</code> has the following features:</p> <ul> <li>Stored and displayed in the form of a timestamp, such as <code>1615974839</code>, which means <code>2021-03-17T17:53:59</code>.</li> </ul> <ul> <li>Supported <code>TIMESTAMP</code> querying methods: timestamp and <code>timestamp()</code> function.</li> </ul> <ul> <li>Supported <code>TIMESTAMP</code> inserting methods: timestamp, <code>timestamp()</code> function, and <code>now()</code> function.</li> </ul> <ul> <li> <p><code>timestamp()</code> function accepts empty parameters to get the timestamp of the current time zone and also accepts a string type parameter.</p> <pre><code># Return the current time.\nnebula&gt; RETURN timestamp();\n+-------------+\n| timestamp() |\n+-------------+\n| 1625469277  |\n+-------------+\n\n# Return the specified time.\nnebula&gt; RETURN timestamp(\"2021-07-05T06:18:43.984000\");\n+-----------------------------------------+\n| timestamp(\"2021-07-05T06:18:43.984000\") |\n+-----------------------------------------+\n| 1625465923                              |\n+-----------------------------------------+\n</code></pre> </li> </ul> <ul> <li>The underlying storage data type is int64.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/4.date-and-time/#examples","title":"Examples","text":"<ol> <li> <p>Create a tag named <code>date1</code> with three properties: <code>DATE</code>, <code>TIME</code>, and <code>DATETIME</code>.</p> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS date1(p1 date, p2 time, p3 datetime);\n</code></pre> </li> <li> <p>Insert a vertex named <code>test1</code>.</p> <pre><code>nebula&gt; INSERT VERTEX date1(p1, p2, p3) VALUES \"test1\":(date(\"2021-03-17\"), time(\"17:53:59\"), datetime(\"2021-03-17T17:53:59\"));\n</code></pre> </li> <li> <p>Return the content of the property <code>p1</code> on <code>test1</code>.</p> <pre><code>nebula&gt; CREATE TAG INDEX IF NOT EXISTS date1_index ON date1(p1);\nnebula&gt; REBUILD TAG INDEX date1_index;\nnebula&gt; MATCH (v:date1) RETURN v.p1;\n+------------+\n| v.p1       |\n+------------+\n| 2021-03-17 |\n+------------+\n</code></pre> </li> <li> <p>Create a tag named <code>school</code> with the property of <code>TIMESTAMP</code>.</p> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS school(name string , found_time timestamp);\n</code></pre> </li> <li> <p>Insert a vertex named <code>DUT</code> with a found-time timestamp of <code>\"1988-03-01T08:00:00\"</code>.</p> <pre><code># Insert as a timestamp. The corresponding timestamp of 1988-03-01T08:00:00 is 573177600, or 573206400 UTC.\nnebula&gt; INSERT VERTEX school(name, found_time) VALUES \"DUT\":(\"DUT\", 573206400);\n\n# Insert in the form of date and time.\nnebula&gt; INSERT VERTEX school(name, found_time) VALUES \"DUT\":(\"DUT\", timestamp(\"1988-03-01T08:00:00\"));\n</code></pre> </li> <li> <p>Insert a vertex named <code>dut</code> and store time with <code>now()</code> or <code>timestamp()</code> functions.</p> <pre><code># Use now() function to store time\nnebula&gt; INSERT VERTEX school(name, found_time) VALUES \"dut\":(\"dut\", now());\n\n# Use timestamp() function to store time\nnebula&gt; INSERT VERTEX school(name, found_time) VALUES \"dut\":(\"dut\", timestamp());\n</code></pre> </li> </ol> <p>You can also use <code>WITH</code> statement to set a specific date and time. For example:</p> <pre><code>nebula&gt; WITH time({hour: 12, minute: 31, second: 14, millisecond:111, microsecond: 222}) AS d RETURN d;\n+-----------------+\n| d               |\n+-----------------+\n| 12:31:14.111222 |\n+-----------------+\n\nnebula&gt; WITH date({year: 1984, month: 10, day: 11}) AS x RETURN x + 1;\n+------------+\n| (x+1)      |\n+------------+\n| 1984-10-12 |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/5.null/","title":"NULL","text":"<p>You can set the properties for vertices or edges to <code>NULL</code>. Also, you can set the <code>NOT NULL</code> constraint to make sure that the property values are <code>NOT NULL</code>. If not specified, the property is set to <code>NULL</code> by default.</p>"},{"location":"3.ngql-guide/3.data-types/5.null/#logical_operations_with_null","title":"Logical operations with NULL","text":"<p>Here is the truth table for <code>AND</code>, <code>OR</code>, <code>XOR</code>, and <code>NOT</code>.</p> a b a AND b a OR b a XOR b NOT a false false false false false true false null false null null true false true false true true true true false false true true false true null null true null false true true true true false false null false false null null null null null null null null null null true null true null null"},{"location":"3.ngql-guide/3.data-types/5.null/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>The comparisons and operations about NULL are different from openCypher. There may be changes later.</p>"},{"location":"3.ngql-guide/3.data-types/5.null/#comparisons_with_null","title":"Comparisons with NULL","text":"<p>The comparison operations with NULL are incompatible with openCypher.</p>"},{"location":"3.ngql-guide/3.data-types/5.null/#operations_and_return_with_null","title":"Operations and RETURN with NULL","text":"<p>The NULL operations and RETURN with NULL are incompatible with openCypher.</p>"},{"location":"3.ngql-guide/3.data-types/5.null/#examples","title":"Examples","text":""},{"location":"3.ngql-guide/3.data-types/5.null/#use_not_null","title":"Use NOT NULL","text":"<p>Create a tag named <code>player</code>. Specify the property <code>name</code> as <code>NOT NULL</code>.</p> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS player(name string NOT NULL, age int);\n</code></pre> <p>Use <code>SHOW</code> to create tag statements. The property <code>name</code> is <code>NOT NULL</code>. The property <code>age</code> is <code>NULL</code> by default.</p> <pre><code>nebula&gt; SHOW CREATE TAG player;\n+-----------+-----------------------------------+\n| Tag       | Create Tag                        |\n+-----------+-----------------------------------+\n| \"student\" | \"CREATE TAG `player` (            |\n|           |  `name` string NOT NULL,          |\n|           |  `age` int64 NULL                 |\n|           | ) ttl_duration = 0, ttl_col = \"\"\" |\n+-----------+-----------------------------------+\n</code></pre> <p>Insert the vertex <code>Kobe</code>. The property <code>age</code> can be <code>NULL</code>.</p> <pre><code>nebula&gt; INSERT VERTEX player(name, age) VALUES \"Kobe\":(\"Kobe\",null);\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/5.null/#use_not_null_and_set_the_default","title":"Use NOT NULL and set the default","text":"<p>Create a tag named <code>player</code>. Specify the property <code>age</code> as <code>NOT NULL</code>. The default value is <code>18</code>.</p> <pre><code>nebula&gt; CREATE TAG IF NOT EXISTS player(name string, age int NOT NULL DEFAULT 18);\n</code></pre> <p>Insert the vertex <code>Kobe</code>. Specify the property <code>name</code> only.</p> <pre><code>nebula&gt; INSERT VERTEX player(name) VALUES \"Kobe\":(\"Kobe\");\n</code></pre> <p>Query the vertex <code>Kobe</code>. The property <code>age</code> is <code>18</code> by default.</p> <pre><code>nebula&gt; FETCH PROP ON player \"Kobe\";\n+-----------------------------------------+\n| vertices_                               |\n+-----------------------------------------+\n| (\"Kobe\" :player{age: 18, name: \"Kobe\"}) |\n+-----------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/6.list/","title":"Lists","text":"<p>The list is a composite data type. A list is a sequence of values. Individual elements in a list can be accessed by their positions.</p> <p>A list starts with a left square bracket <code>[</code> and ends with a right square bracket <code>]</code>. A list contains zero, one, or more expressions. List elements are separated from each other with commas (<code>,</code>). Whitespace around elements is ignored in the list, thus line breaks, tab stops, and blanks can be used for formatting.</p>"},{"location":"3.ngql-guide/3.data-types/6.list/#list_operations","title":"List operations","text":"<p>You can use the preset list function to operate the list, or use the index to filter the elements in the list.</p>"},{"location":"3.ngql-guide/3.data-types/6.list/#index_syntax","title":"Index syntax","text":"<pre><code>[M]\n[M..N]\n[M..]\n[..N]\n</code></pre> <p>The index of nGQL supports queries from front to back, starting from 0. 0 means the first element, 1 means the second element, and so on. It also supports queries from back to front, starting from -1. -1 means the last element, -2 means the penultimate element, and so on.</p> <ul> <li>[M]: represents the element whose index is M.</li> <li>[M..N]: represents the elements whose indexes are <code>greater or equal to M but smaller than N</code>. Return empty when <code>N</code> is 0.</li> <li>[M..]: represents the elements whose indexes are <code>greater or equal to M</code>.</li> <li>[..N]: represents the elements whose indexes are <code>smaller than N</code>. Return empty when <code>N</code> is 0.</li> </ul> <p>Note</p> <ul> <li>Return empty if the index is out of bounds, while return normally if the index is within the bound.</li> <li>Return empty if <code>M</code>\u2265<code>N</code>.</li> <li>When querying a single element, if <code>M</code> is null, return <code>BAD_TYPE</code>. When conducting a range query, if <code>M</code> or <code>N</code> is null, return <code>null</code>.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/6.list/#examples","title":"Examples","text":"<pre><code># The following query returns the list [1,2,3].\nnebula&gt; RETURN [1, 2, 3] AS List;\n+-----------+\n| List      |\n+-----------+\n| [1, 2, 3] |\n+-----------+\n\n# The following query returns the element whose index is 3 in the list [1,2,3,4,5]. In a list, the index starts from 0, and thus the return element is 4.\nnebula&gt; RETURN range(1,5)[3];\n+---------------+\n| range(1,5)[3] |\n+---------------+\n| 4             |\n+---------------+\n\n# The following query returns the element whose index is -2 in the list [1,2,3,4,5]. The index of the last element in a list is -1, and thus the return element is 4.\nnebula&gt; RETURN range(1,5)[-2];\n+------------------+\n| range(1,5)[-(2)] |\n+------------------+\n| 4                |\n+------------------+\n\n# The following query returns the elements whose indexes are from 0 to 3 (not including 3) in the list [1,2,3,4,5].\nnebula&gt; RETURN range(1,5)[0..3];\n+------------------+\n| range(1,5)[0..3] |\n+------------------+\n| [1, 2, 3]        |\n+------------------+\n\n# The following query returns the elements whose indexes are greater than 2 in the list [1,2,3,4,5].\nnebula&gt; RETURN range(1,5)[3..] AS a;\n+--------+\n| a      |\n+--------+\n| [4, 5] |\n+--------+\n\n# The following query returns the elements whose indexes are smaller than 3.\nnebula&gt; WITH [1, 2, 3, 4, 5] AS list \\\n        RETURN list[..3] AS r;\n+-----------+\n| r         |\n+-----------+\n| [1, 2, 3] |\n+-----------+\n\n# The following query filters the elements whose indexes are greater than 2 in the list [1,2,3,4,5], calculate them respectively, and returns them.\nnebula&gt; RETURN [n IN range(1,5) WHERE n &gt; 2 | n + 10] AS a;\n+--------------+\n| a            |\n+--------------+\n| [13, 14, 15] |\n+--------------+\n\n# The following query returns the elements from the first to the penultimate (inclusive) in the list [1, 2, 3].\nnebula&gt; YIELD [1, 2, 3][0..-1] AS a;\n+--------+\n| a      |\n+--------+\n| [1, 2] |\n+--------+\n\n# The following query returns the elements from the first (exclusive) to the third backward in the list [1, 2, 3, 4, 5].\nnebula&gt; YIELD [1, 2, 3, 4, 5][-3..-1] AS a;\n+--------+\n| a      |\n+--------+\n| [3, 4] |\n+--------+\n\n# The following query sets the variables and returns the elements whose indexes are 1 and 2.\nnebula&gt; $var = YIELD 1 AS f, 3 AS t; \\\n        YIELD [1, 2, 3][$var.f..$var.t] AS a;\n+--------+\n| a      |\n+--------+\n| [2, 3] |\n+--------+\n\n# The following query returns empty because the index is out of bound. It will return normally when the index is within the bound.\nnebula&gt; RETURN [1, 2, 3, 4, 5] [0..10] AS a;\n+-----------------+\n| a               |\n+-----------------+\n| [1, 2, 3, 4, 5] |\n+-----------------+\n\nnebula&gt; RETURN [1, 2, 3] [-5..5] AS a;\n+-----------+\n| a         |\n+-----------+\n| [1, 2, 3] |\n+-----------+\n\n# The following query returns empty because there is a [0..0].\nnebula&gt; RETURN [1, 2, 3, 4, 5] [0..0] AS a;\n+----+\n| a  |\n+----+\n| [] |\n+----+\n\n# The following query returns empty because of M \u2265 N.\nnebula&gt; RETURN [1, 2, 3, 4, 5] [3..1] AS a;\n+----+\n| a  |\n+----+\n| [] |\n+----+\n\n# When conduct a range query, if `M` or `N` is null, return `null`.\nnebula&gt; WITH [1,2,3] AS list \\\n        RETURN list[0..null] as a;\n+----------+\n| a        |\n+----------+\n| __NULL__ |\n+----------+\n\n# The following query calculates the elements in the list [1,2,3,4,5] respectively and returns them without the list head.\nnebula&gt; RETURN tail([n IN range(1, 5) | 2 * n - 10]) AS a;\n+-----------------+\n| a               |\n+-----------------+\n| [-6, -4, -2, 0] |\n+-----------------+\n\n# The following query takes the elements in the list [1,2,3] as true and return.\nnebula&gt; RETURN [n IN range(1, 3) WHERE true | n] AS r;\n+-----------+\n| r         |\n+-----------+\n| [1, 2, 3] |\n+-----------+\n\n# The following query returns the length of the list [1,2,3].\nnebula&gt; RETURN size([1,2,3]);\n+---------------+\n| size([1,2,3]) |\n+---------------+\n| 3             |\n+---------------+\n\n# The following query calculates the elements in the list [92,90] and runs a conditional judgment in a where clause.\nnebula&gt; GO FROM \"player100\" OVER follow WHERE follow.degree NOT IN [x IN [92, 90] | x + $$.player.age] \\\n        YIELD dst(edge) AS id, properties(edge).degree AS degree;\n+-------------+--------+\n| id          | degree |\n+-------------+--------+\n| \"player101\" | 95     |\n| \"player102\" | 90     |\n+-------------+--------+\n\n# The following query takes the query result of the MATCH statement as the elements in a list. Then it calculates and returns them.\nnebula&gt; MATCH p = (n:player{name:\"Tim Duncan\"})-[:follow]-&gt;(m) \\\n        RETURN [n IN nodes(p) | n.age + 100] AS r;\n+------------+\n| r          |\n+------------+\n| [142, 136] |\n| [142, 133] |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/6.list/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>In openCypher, return <code>null</code> when querying a single out-of-bound element. However, in nGQL, return <code>OUT_OF_RANGE</code> when querying a single out-of-bound element.<pre><code>nebula&gt; RETURN range(0,5)[-12];\n+-------------------+\n| range(0,5)[-(12)] |\n+-------------------+\n| OUT_OF_RANGE      |\n+-------------------+\n</code></pre> </li> </ul> <ul> <li> <p>A composite data type (i.e., set, map, and list) CAN NOT be stored as properties for vertices or edges.</p> <p>It is recommended to modify the graph modeling method. The composite data type should be modeled as an adjacent edge of a vertex, rather than its property. Each adjacent edge can be dynamically added or deleted. The rank values of the adjacent edges can be used for sequencing.</p> </li> </ul> <ul> <li>Patterns are not supported in the list. For example, <code>[(src)-[]-&gt;(m) | m.name]</code>.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/7.set/","title":"Sets","text":"<p>The set is a composite data type.</p>"},{"location":"3.ngql-guide/3.data-types/7.set/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>A set is not a data type in openCypher. The behavior of a set in nGQL is not determined yet.</p>"},{"location":"3.ngql-guide/3.data-types/8.map/","title":"Maps","text":"<p>The map is a composite data type. Maps are unordered collections of key-value pairs. In maps, the key is a string. The value can have any data type. You can get the map element by using <code>map['key']</code>.</p>"},{"location":"3.ngql-guide/3.data-types/8.map/#literal_maps","title":"Literal maps","text":"<pre><code>nebula&gt; YIELD {key: 'Value', listKey: [{inner: 'Map1'}, {inner: 'Map2'}]};\n+-------------------------------------------------------------+\n| {key:Value,listKey:[{inner:Map1},{inner:Map2}]}             |\n+-------------------------------------------------------------+\n| {key: \"Value\", listKey: [{inner: \"Map1\"}, {inner: \"Map2\"}]} |\n+-------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/3.data-types/8.map/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>A composite data type (i.e. set, map, and list) CANNOT be stored as properties of vertices or edges.</li> </ul> <ul> <li>Map projection is not supported.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/9.type-conversion/","title":"Type Conversion/Type coercions","text":"<p>Converting an expression of a given type to another type is known as type conversion.</p>"},{"location":"3.ngql-guide/3.data-types/9.type-conversion/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<ul> <li>nGQL 1.0 adopts the <code>C</code>-style of type conversion (implicitly or explicitly): <code>(type_name)expression</code>. For example, the results of <code>YIELD (int)(TRUE)</code> is <code>1</code>. But it is error-prone to users who are not familiar with the C language.</li> </ul> <ul> <li>nGQL 2.0 chooses the openCypher way of type coercions.</li> </ul>"},{"location":"3.ngql-guide/3.data-types/9.type-conversion/#type_coercions_functions","title":"Type coercions functions","text":"Function Description toBoolean() Converts a string value to a boolean value. toFloat() Converts an integer or string value to a floating point number. toInteger() Converts a floating point or string value to an integer value. type() Returns the string representation of the relationship type."},{"location":"3.ngql-guide/3.data-types/9.type-conversion/#examples","title":"Examples","text":"<pre><code>nebula&gt; UNWIND [true, false, 'true', 'false', NULL] AS b \\\n        RETURN toBoolean(b) AS b;\n+----------+\n| b        |\n+----------+\n| true     |\n| false    |\n| true     |\n| false    |\n| __NULL__ |\n+----------+\n\nnebula&gt; RETURN toFloat(1), toFloat('1.3'), toFloat('1e3'), toFloat('not a number');\n+------------+----------------+----------------+-------------------------+\n| toFloat(1) | toFloat(\"1.3\") | toFloat(\"1e3\") | toFloat(\"not a number\") |\n+------------+----------------+----------------+-------------------------+\n| 1.0        | 1.3            | 1000.0         | __NULL__                |\n+------------+----------------+----------------+-------------------------+\n\nnebula&gt; RETURN toInteger(1), toInteger('1'), toInteger('1e3'), toInteger('not a number');\n+--------------+----------------+------------------+---------------------------+\n| toInteger(1) | toInteger(\"1\") | toInteger(\"1e3\") | toInteger(\"not a number\") |\n+--------------+----------------+------------------+---------------------------+\n| 1            | 1              | 1000             | __NULL__                  |\n+--------------+----------------+------------------+---------------------------+\n\nnebula&gt; MATCH (a:player)-[e]-() \\\n        RETURN type(e);\n+----------+\n| type(e)  |\n+----------+\n| \"follow\" |\n| \"follow\" |\n+----------+\n\nnebula&gt; MATCH (a:player {name: \"Tim Duncan\"}) \\\n        WHERE toInteger(right(id(a),3)) == 100 \\\n        RETURN a;\n+----------------------------------------------------+\n| a                                                  |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n\nnebula&gt; MATCH (n:player) \\\n        WITH n LIMIT toInteger(ceil(1.8)) \\\n        RETURN count(*) AS count;\n+-------+\n| count |\n+-------+\n| 2     |\n+-------+\n</code></pre>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/1.composite-queries/","title":"Composite queries (clause structure)","text":"<p>Composite queries put data from different queries together. They then use filters, group-bys, or sorting before returning the combined return results.</p> <p>Nebula\u00a0Graph supports three methods to run composite queries (or sub-queries):</p> <ul> <li>(openCypher) Clauses are chained together, and they feed intermediate result sets between each other.</li> </ul> <ul> <li>(Native nGQL) More than one query can be batched together, separated by semicolons (;). The result of the last query is returned as the result of the batch.</li> </ul> <ul> <li>(Native nGQL) Queries can be piped together by using the pipe (<code>|</code>). The result of the previous query can be used as the input of the next query.</li> </ul>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/1.composite-queries/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>In a composite query, do not put together openCypher and native nGQL clauses in one statement. For example, this statement is undefined: <code>MATCH ... | GO ... | YIELD ...</code>.</p> <ul> <li>If you are in the openCypher way (<code>MATCH</code>, <code>RETURN</code>, <code>WITH</code>, etc), do not introduce any pipe or semicolons to combine the sub-clauses.</li> </ul> <ul> <li>If you are in the native nGQL way (<code>FETCH</code>, <code>GO</code>, <code>LOOKUP</code>, etc), you must use pipe or semicolons to combine the sub-clauses.</li> </ul> <p>Undefined behavior</p> <p>Do not put together <code>native nGQL</code> and <code>openCypher compatible sentences</code> in one composite statement because this behavior is undefined.</p>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/1.composite-queries/#composite_queries_are_not_transactional_queries_as_in_sqlcypher","title":"Composite queries are not <code>transactional</code> queries (as in SQL/Cypher)","text":"<p>For example, a query is composed of three sub-queries: <code>A B C</code>, <code>A | B | C</code> or <code>A; B; C</code>. In that A is a read operation, B is a computation operation, and C is a write operation. If any part fails in the execution, the whole result will be undefined. There is no rollback. What is written depends on the query executor.</p> <p>Note</p> <p>OpenCypher has no requirement of <code>transaction</code>.</p>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/1.composite-queries/#examples","title":"Examples","text":"<ul> <li>OpenCypher compatibility statement<pre><code># Connect multiple queries with clauses.\nnebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})--() \\\n        WITH nodes(p) AS n \\\n        UNWIND n AS n1 \\\n        RETURN DISTINCT n1;\n</code></pre> </li> </ul> <ul> <li>Native nGQL (Semicolon queries)<pre><code># Only return edges.\nnebula&gt; SHOW TAGS; SHOW EDGES;\n\n# Insert multiple vertices.\nnebula&gt; INSERT VERTEX player(name, age) VALUES \"player100\":(\"Tim Duncan\", 42); \\\n        INSERT VERTEX player(name, age) VALUES \"player101\":(\"Tony Parker\", 36); \\\n        INSERT VERTEX player(name, age) VALUES \"player102\":(\"LaMarcus Aldridge\", 33);\n</code></pre> </li> </ul> <ul> <li>Native nGQL (Pipe queries)<pre><code># Connect multiple queries with pipes.\nnebula&gt; GO FROM \"player100\" OVER follow YIELD dst(edge) AS id | \\\n        GO FROM $-.id OVER serve YIELD properties($$).name AS Team, \\\n        properties($^).name AS Player;\n+-----------+-----------------+\n| Team      | Player          |\n+-----------+-----------------+\n| \"Spurs\"   | \"Tony Parker\"   |\n| \"Hornets\" | \"Tony Parker\"   |\n| \"Spurs\"   | \"Manu Ginobili\" |\n+-----------+-----------------+\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/2.user-defined-variables/","title":"User-defined variables","text":"<p>User-defined variables allow passing the result of one statement to another.</p>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/2.user-defined-variables/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>In openCypher, when you refer to the vertex, edge, or path of a variable, you need to name it first. For example:</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) RETURN v;\n+----------------------------------------------------+\n| v                                                  |\n+----------------------------------------------------+\n| (\"player100\" :player{name: \"Tim Duncan\", age: 42}) |\n+----------------------------------------------------+\n</code></pre> <p>The user-defined variable in the preceding query is <code>v</code>.</p>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/2.user-defined-variables/#native_ngql","title":"Native nGQL","text":"<p>User-defined variables are written as <code>$var_name</code>. The <code>var_name</code> consists of letters, numbers, or underline characters. Any other characters are not permitted.</p> <p>The user-defined variables are valid only at the current execution (namely, in this composite query). When the execution ends, the user-defined variables will be automatically expired. The user-defined variables in one statement CANNOT be used in any other clients, executions, or sessions.</p> <p>You can use user-defined variables in composite queries. Details about composite queries, see Composite queries.</p> <p>Note</p> <p>User-defined variables are case-sensitive.</p>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/2.user-defined-variables/#example","title":"Example","text":"<pre><code>nebula&gt; $var = GO FROM \"player100\" OVER follow YIELD dst(edge) AS id; \\\n        GO FROM $var.id OVER serve YIELD properties($$).name AS Team, \\\n        properties($^).name AS Player;\n+-----------+-----------------+\n| Team      | Player          |\n+-----------+-----------------+\n| \"Spurs\"   | \"Tony Parker\"   |\n| \"Hornets\" | \"Tony Parker\"   |\n| \"Spurs\"   | \"Manu Ginobili\" |\n+-----------+-----------------+\n</code></pre>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/","title":"Property reference","text":"<p>You can refer to the properties of a vertex or an edge in <code>WHERE</code> and <code>YIELD</code> syntax.</p> <p>Note</p> <p>This function applies to native nGQL only.</p>"},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#property_reference_for_vertex","title":"Property reference for vertex","text":""},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#for_source_vertex","title":"For source vertex","text":"<pre><code>$^.&lt;tag_name&gt;.&lt;prop_name&gt;\n</code></pre> Parameter Description <code>$^</code> is used to get the property of the source vertex. <code>tag_name</code> is the tag name of the vertex. <code>prop_name</code> specifies the property name."},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#for_destination_vertex","title":"For destination vertex","text":"<pre><code>$$.&lt;tag_name&gt;.&lt;prop_name&gt;\n</code></pre> Parameter Description <code>$$</code> is used to get the property of the destination vertex. <code>tag_name</code> is the tag name of the vertex. <code>prop_name</code> specifies the property name."},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#property_reference_for_edge","title":"Property reference for edge","text":""},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#for_user-defined_edge_property","title":"For user-defined edge property","text":"<pre><code>&lt;edge_type&gt;.&lt;prop_name&gt;\n</code></pre> Parameter Description <code>edge_type</code> is the edge type of the edge. <code>prop_name</code> specifies the property name of the edge type."},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#for_built-in_properties","title":"For built-in properties","text":"<p>Apart from the user-defined edge property, there are four built-in properties in each edge:</p> Parameter Description <code>_src</code> source vertex ID of the edge <code>_dst</code> destination vertex ID of the edge <code>_type</code> edge type <code>_rank</code> the rank value for the edge"},{"location":"3.ngql-guide/4.variable-and-composite-queries/3.property-reference/#examples","title":"Examples","text":"<p>The following query returns the <code>name</code> property of the <code>player</code> tag on the source vertex and the <code>age</code> property of the <code>player</code> tag on the destination vertex.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow YIELD $^.player.name AS startName, $$.player.age AS endAge;\n+--------------+--------+\n| startName    | endAge |\n+--------------+--------+\n| \"Tim Duncan\" | 36     |\n| \"Tim Duncan\" | 41     |\n+--------------+--------+\n</code></pre> <p>The following query returns the <code>degree</code> property of the edge type <code>follow</code>.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow YIELD follow.degree;\n+---------------+\n| follow.degree |\n+---------------+\n| 95            |\n| 95            |\n+---------------+\n</code></pre> <p>The following query returns the source vertex, the destination vertex, the edge type, and the edge rank value of the edge type <code>follow</code>.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow YIELD follow._src, follow._dst, follow._type, follow._rank;\n+-------------+-------------+--------------+--------------+\n| follow._src | follow._dst | follow._type | follow._rank |\n+-------------+-------------+--------------+--------------+\n| \"player100\" | \"player101\" | 17           | 0            |\n| \"player100\" | \"player125\" | 17           | 0            |\n+-------------+-------------+--------------+--------------+\n</code></pre> <p>Legacy version compatibility</p> <p>NebulaGraph 2.6.0 and later versions support the new Schema function. The statements in the above examples are written as follows in 2.6.0.</p> <pre><code>GO FROM \"player100\" OVER follow YIELD properties($^).name AS startName, properties($$).age AS endAge;\nGO FROM \"player100\" OVER follow YIELD properties(edge).degree;\nGO FROM \"player100\" OVER follow YIELD src(edge), dst(edge), type(edge), rank(edge);\n</code></pre> <p>In 2.6.0, NebulaGraph is still compatible with the old syntax.</p>"},{"location":"3.ngql-guide/5.operators/1.comparison/","title":"Comparison operators","text":"<p>NebulaGraph supports the following comparison operators.</p> Name Description <code>=</code> Assigns a value <code>+</code> Addition operator <code>-</code> Minus operator <code>*</code> Multiplication operator <code>/</code> Division operator <code>==</code> Equal operator <code>!=</code>, <code>&lt;&gt;</code> Not equal operator <code>&gt;</code> Greater than operator <code>&gt;=</code> Greater than or equal operator <code>&lt;</code> Less than operator <code>&lt;=</code> Less than or equal operator <code>%</code> Modulo operator <code>-</code> Changes the sign of the argument <code>IS NULL</code> NULL check <code>IS NOT NULL</code> Not NULL check <code>IS EMPTY</code> EMPTY check <code>IS NOT EMPTY</code> Not EMPTY check <p>The result of the comparison operation is <code>true</code> or <code>false</code>.</p> <p>Note</p> <ul> <li>Comparability between values of different types is often undefined. The result could be <code>NULL</code> or others.</li> </ul> <ul> <li><code>EMPTY</code> is currently used only for checking, and does not support functions or operations such as <code>GROUP BY</code>, <code>count()</code>, <code>sum()</code>, <code>max()</code>, <code>hash()</code>, <code>collect()</code>, <code>+</code> or <code>*</code>.</li> </ul>"},{"location":"3.ngql-guide/5.operators/1.comparison/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>The comparison operation of <code>NULL</code> is different from openCypher. The behavior may also change. <code>IS [NOT] NULL</code> is often used with <code>OPTIONAL MATCH</code> in openCypher. But <code>OPTIONAL MATCH</code> is not supported in nGQL.</li> </ul> <ul> <li>openCypher does not have <code>EMPTY</code>. Thus <code>EMPTY</code> is not supported in MATCH statements.</li> </ul>"},{"location":"3.ngql-guide/5.operators/1.comparison/#examples","title":"Examples","text":""},{"location":"3.ngql-guide/5.operators/1.comparison/#_1","title":"<code>==</code>","text":"<p>String comparisons are case-sensitive. Values of different types are not equal.</p> <p>Note</p> <p>The equal operator is <code>==</code> in nGQL, while in openCypher it is <code>=</code>.</p> <pre><code>nebula&gt; RETURN 'A' == 'a', toUpper('A') == toUpper('a'), toLower('A') == toLower('a');\n+------------+------------------------------+------------------------------+\n| (\"A\"==\"a\") | (toUpper(\"A\")==toUpper(\"a\")) | (toLower(\"A\")==toLower(\"a\")) |\n+------------+------------------------------+------------------------------+\n| false      | true                         | true                         |\n+------------+------------------------------+------------------------------+\n\nnebula&gt; RETURN '2' == 2, toInteger('2') == 2;\n+----------+---------------------+\n| (\"2\"==2) | (toInteger(\"2\")==2) |\n+----------+---------------------+\n| false    | true                |\n+----------+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#_2","title":"<code>&gt;</code>","text":"<pre><code>nebula&gt; RETURN 3 &gt; 2;\n+-------+\n| (3&gt;2) |\n+-------+\n| true  |\n+-------+\n\nnebula&gt; WITH 4 AS one, 3 AS two \\\n        RETURN one &gt; two AS result;\n+--------+\n| result |\n+--------+\n| true   |\n+--------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#_3","title":"<code>&gt;=</code>","text":"<pre><code>nebula&gt; RETURN 2 &gt;= \"2\", 2 &gt;= 2;\n+----------+--------+\n| (2&gt;=\"2\") | (2&gt;=2) |\n+----------+--------+\n| __NULL__ | true   |\n+----------+--------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#_4","title":"<code>&lt;</code>","text":"<pre><code>nebula&gt; YIELD 2.0 &lt; 1.9;\n+---------+\n| (2&lt;1.9) |\n+---------+\n| false   |\n+---------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#_5","title":"<code>&lt;=</code>","text":"<pre><code>nebula&gt; YIELD 0.11 &lt;= 0.11;\n+--------------+\n| (0.11&lt;=0.11) |\n+--------------+\n| true         |\n+--------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#_6","title":"<code>!=</code>","text":"<pre><code>nebula&gt; YIELD 1 != '1';\n+----------+\n| (1!=\"1\") |\n+----------+\n| true     |\n+----------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#is_not_null","title":"<code>IS [NOT] NULL</code>","text":"<pre><code>nebula&gt; RETURN null IS NULL AS value1, null == null AS value2, null != null AS value3;\n+--------+----------+----------+\n| value1 | value2   | value3   |\n+--------+----------+----------+\n| true   | __NULL__ | __NULL__ |\n+--------+----------+----------+\n\nnebula&gt; RETURN length(NULL), size(NULL), count(NULL), NULL IS NULL, NULL IS NOT NULL, sin(NULL), NULL + NULL, [1, NULL] IS NULL;\n+--------------+------------+-------------+--------------+------------------+-----------+-------------+------------------+\n| length(NULL) | size(NULL) | count(NULL) | NULL IS NULL | NULL IS NOT NULL | sin(NULL) | (NULL+NULL) | [1,NULL] IS NULL |\n+--------------+------------+-------------+--------------+------------------+-----------+-------------+------------------+\n| __NULL__     | __NULL__   | 0           | true         | false            | __NULL__  | __NULL__    | false            |\n+--------------+------------+-------------+--------------+------------------+-----------+-------------+------------------+\n\nnebula&gt; WITH {name: null} AS map \\\n        RETURN map.name IS NOT NULL;\n+----------------------+\n| map.name IS NOT NULL |\n+----------------------+\n| false                |\n+----------------------+\n\nnebula&gt; WITH {name: 'Mats', name2: 'Pontus'} AS map1, \\\n        {name: null} AS map2, {notName: 0, notName2: null } AS map3 \\\n        RETURN map1.name IS NULL, map2.name IS NOT NULL, map3.name IS NULL;\n+-------------------+-----------------------+-------------------+\n| map1.name IS NULL | map2.name IS NOT NULL | map3.name IS NULL |\n+-------------------+-----------------------+-------------------+\n| false             | false                 | true              |\n+-------------------+-----------------------+-------------------+\n\nnebula&gt; MATCH (n:player) \\\n        RETURN n.age IS NULL, n.name IS NOT NULL, n.empty IS NULL;\n+---------------+--------------------+-----------------+\n| n.age IS NULL | n.name IS NOT NULL | n.empty IS NULL |\n+---------------+--------------------+-----------------+\n| false         | true               | true            |\n| false         | true               | true            |\n| false         | true               | true            |\n+---------------+--------------------+-----------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/5.operators/1.comparison/#is_not_empty","title":"<code>IS [NOT] EMPTY</code>","text":"<pre><code>nebula&gt; RETURN null IS EMPTY;\n+---------------+\n| NULL IS EMPTY |\n+---------------+\n| false         |\n+---------------+\n\nnebula&gt; RETURN \"a\" IS NOT EMPTY;\n+------------------+\n| \"a\" IS NOT EMPTY |\n+------------------+\n| true             |\n+------------------+\n\nnebula&gt; GO FROM \"player100\" OVER * WHERE $$.player.name IS NOT EMPTY YIELD dst(edge);\n+-------------+\n| dst(EDGE)   |\n+-------------+\n| \"team204\"   |\n| \"player101\" |\n| \"player125\" |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/2.boolean/","title":"Boolean operators","text":"<p>NebulaGraph supports the following boolean operators.</p> Name Description AND Logical AND NOT Logical NOT OR Logical OR XOR Logical XOR <p>For the precedence of the operators, refer to Operator Precedence.</p> <p>For the logical operations with <code>NULL</code>, refer to NULL.</p>"},{"location":"3.ngql-guide/5.operators/2.boolean/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<ul> <li>In NebulaGraph 2.0, non-zero numbers cannot be converted to boolean values.</li> </ul>"},{"location":"3.ngql-guide/5.operators/4.pipe/","title":"Pipe operators","text":"<p>Multiple queries can be combined using pipe operators in nGQL.</p>"},{"location":"3.ngql-guide/5.operators/4.pipe/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>Pipe operators apply to native nGQL only.</p>"},{"location":"3.ngql-guide/5.operators/4.pipe/#syntax","title":"Syntax","text":"<p>One major difference between nGQL and SQL is how sub-queries are composed.</p> <ul> <li>In SQL, sub-queries are nested in the query statements.</li> </ul> <ul> <li>In nGQL, the shell style <code>PIPE (|)</code> is introduced into the sub-queries.</li> </ul>"},{"location":"3.ngql-guide/5.operators/4.pipe/#examples","title":"Examples","text":"<pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS dstid, properties($$).name AS Name | \\\n        GO FROM $-.dstid OVER follow;\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player100\" |\n| \"player102\" |\n| \"player125\" |\n| \"player100\" |\n+-------------+\n</code></pre> <p>If there is no <code>YIELD</code> clause to define the output, the destination vertex ID is returned by default. If a YIELD clause is applied, the output is defined by the YIELD clause.</p> <p>Users must define aliases in the <code>YIELD</code> clause for the reference operator <code>$-</code> to use, just like <code>$-.dstid</code> in the preceding example.</p>"},{"location":"3.ngql-guide/5.operators/4.pipe/#performance_tips","title":"Performance tips","text":"<p>In NebulaGraph, pipes will affect the performance. Take <code>A | B</code> as an example, the effects are as follows:</p> <ol> <li> <p>Pipe operators operate synchronously. That is, the data can enter the pipe clause as a whole after the execution of clause <code>A</code> before the pipe operator is completed.</p> </li> <li> <p>Pipe operators need to be serialized and deserialized, which is executed in a single thread.</p> </li> <li> <p>If <code>A</code> sends a large amount of data to <code>|</code>, the entire query request may be very slow. You can try to split this statement.</p> <ol> <li> <p>Send <code>A</code> from the application,</p> </li> <li> <p>Split the return results on the application,</p> </li> <li> <p>Send to multiple graphd processes concurrently,</p> </li> <li> <p>Every graphd process executes part of B.</p> </li> </ol> <p>This is usually much faster than executing a complete <code>A | B</code> with a single graphd process.</p> </li> </ol>"},{"location":"3.ngql-guide/5.operators/5.property-reference/","title":"Reference operators","text":"<p>NGQL provides reference operators to represent a property in a <code>WHERE</code> or <code>YIELD</code> clause, or the output of the statement before the pipe operator in a composite query.</p>"},{"location":"3.ngql-guide/5.operators/5.property-reference/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>Reference operators apply to native nGQL only.</p>"},{"location":"3.ngql-guide/5.operators/5.property-reference/#reference_operator_list","title":"Reference operator List","text":"Reference operator Description <code>$^</code> Refers to a source vertex property. For more information, see Property reference. <code>$$</code> Refers to a destination vertex property. For more information, see Property reference. <code>$-</code> Refers to the output of the statement before the pipe operator in a composite query. For more information, see Pipe."},{"location":"3.ngql-guide/5.operators/5.property-reference/#examples","title":"Examples","text":"<pre><code># The following example returns the age of the source vertex and the destination vertex.\nnebula&gt; GO FROM \"player100\" OVER follow YIELD properties($^).age AS SrcAge, properties($$).age AS DestAge;\n+--------+---------+\n| SrcAge | DestAge |\n+--------+---------+\n| 42     | 36      |\n| 42     | 41      |\n+--------+---------+\n\n# The following example returns the name and team of the players that player100 follows.\nnebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS id | \\\n        GO FROM $-.id OVER serve \\\n        YIELD $^.player.name AS Player, properties($$).name AS Team;\n+-----------------+-----------+\n| Player          | Team      |\n+-----------------+-----------+\n| \"Tony Parker\"   | \"Spurs\"   |\n| \"Tony Parker\"   | \"Hornets\" |\n| \"Manu Ginobili\" | \"Spurs\"   |\n+-----------------+-----------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/6.set/","title":"Set operators","text":"<p>This topic will describe the set operators, including <code>UNION</code>, <code>UNION ALL</code>, <code>INTERSECT</code>, and <code>MINUS</code>. To combine multiple queries, use these set operators.</p> <p>All set operators have equal precedence. If a nGQL statement contains multiple set operators, NebulaGraph will evaluate them from left to right unless parentheses explicitly specify another order.</p>"},{"location":"3.ngql-guide/5.operators/6.set/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>Set operators apply to native nGQL only.</p>"},{"location":"3.ngql-guide/5.operators/6.set/#union_union_distinct_and_union_all","title":"UNION, UNION DISTINCT, and UNION ALL","text":"<pre><code>&lt;left&gt; UNION [DISTINCT | ALL] &lt;right&gt; [ UNION [DISTINCT | ALL] &lt;right&gt; ...]\n</code></pre> <ul> <li>Operator <code>UNION DISTINCT</code> (or by short <code>UNION</code>) returns the union of two sets A and B without duplicated elements.</li> </ul> <ul> <li>Operator <code>UNION ALL</code> returns the union of two sets A and B with duplicated elements.</li> </ul> <ul> <li>The <code>&lt;left&gt;</code> and <code>&lt;right&gt;</code> must have the same number of columns and data types. Different data types are converted according to the Type Conversion.</li> </ul>"},{"location":"3.ngql-guide/5.operators/6.set/#examples","title":"Examples","text":"<pre><code># The following statement returns the union of two query results without duplicated elements.\nnebula&gt; GO FROM \"player102\" OVER follow \\\n        UNION \\\n        GO FROM \"player100\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player100\" |\n| \"player101\" |\n| \"player125\" |\n+-------------+\n\n# The following statement returns the union of two query results with duplicated elements.\nnebula&gt; GO FROM \"player102\" OVER follow \\\n        UNION ALL \\\n        GO FROM \"player100\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player100\" |\n| \"player101\" |\n| \"player101\" |\n| \"player125\" |\n+-------------+\n\n# UNION can also work with the YIELD statement. The DISTINCT keyword will check duplication by all the columns for every line, and remove duplicated lines if every column is the same.\nnebula&gt; GO FROM \"player102\" OVER follow \\\n        YIELD dst(edge) AS id, properties(edge).degree AS Degree, properties($$).age AS Age \\\n        UNION /* DISTINCT */ \\\n        GO FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS id, properties(edge).degree AS Degree, properties($$).age AS Age;\n+-------------+--------+-----+\n| id          | Degree | Age |\n+-------------+--------+-----+\n| \"player100\" | 75     | 42  |\n| \"player101\" | 75     | 36  |\n| \"player101\" | 95     | 36  |\n| \"player125\" | 95     | 41  |\n+-------------+--------+-----+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/6.set/#intersect","title":"INTERSECT","text":"<pre><code>&lt;left&gt; INTERSECT &lt;right&gt;\n</code></pre> <ul> <li>Operator <code>INTERSECT</code> returns the intersection of two sets A and B (denoted by A \u22c2 B).</li> </ul> <ul> <li>Similar to <code>UNION</code>, the <code>left</code> and <code>right</code> must have the same number of columns and data types. Different data types are converted according to the Type Conversion.</li> </ul>"},{"location":"3.ngql-guide/5.operators/6.set/#example","title":"Example","text":"<pre><code>nebula&gt; GO FROM \"player102\" OVER follow \\\n        YIELD dst(edge) AS id, properties(edge).degree AS Degree, properties($$).age AS Age \\\n        INTERSECT \\\n        GO FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS id, properties(edge).degree AS Degree, properties($$).age AS Age;\n+----+--------+-----+\n| id | Degree | Age |\n+----+--------+-----+\n+----+--------+-----+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/6.set/#minus","title":"MINUS","text":"<pre><code>&lt;left&gt; MINUS &lt;right&gt;\n</code></pre> <p>Operator <code>MINUS</code> returns the subtraction (or difference) of two sets A and B (denoted by <code>A-B</code>). Always pay attention to the order of <code>left</code> and <code>right</code>. The set <code>A-B</code> consists of elements that are in A but not in B.</p>"},{"location":"3.ngql-guide/5.operators/6.set/#example_1","title":"Example","text":"<pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        MINUS \\\n        GO FROM \"player102\" OVER follow;\n+-------------+\n| dst(edge)   |\n+-------------+\n| \"player125\" |\n+-------------+\n\nnebula&gt; GO FROM \"player102\" OVER follow \\\n        MINUS \\\n        GO FROM \"player100\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player100\" |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/6.set/#precedence_of_the_set_operators_and_pipe_operators","title":"Precedence of the set operators and pipe operators","text":"<p>Please note that when a query contains a pipe <code>|</code> and a set operator, the pipe takes precedence. Refer to Pipe for details. The query <code>GO FROM 1 UNION GO FROM 2 | GO FROM 3</code> is the same as the query <code>GO FROM 1 UNION (GO FROM 2 | GO FROM 3)</code>.</p>"},{"location":"3.ngql-guide/5.operators/6.set/#examples_1","title":"Examples","text":"<pre><code>nebula&gt; GO FROM \"player102\" OVER follow \\\n        YIELD dst(edge) AS play_dst  \\\n        UNION \\\n        GO FROM \"team200\" OVER serve REVERSELY \\\n        YIELD src(edge) AS play_src \\\n        | GO FROM $-.play_src OVER follow YIELD dst(edge) AS play_dst;\n\n+-------------+\n| play_dst    |\n+-------------+\n| \"player100\" |\n| \"player101\" |\n| \"player117\" |\n| \"player105\" |\n+-------------+\n</code></pre> <p>The above query executes the statements in the red bar first and then executes the statement in the green box.</p> <p>The parentheses can change the execution priority. For example:</p> <pre><code>nebula&gt; (GO FROM \"player102\" OVER follow \\\n        YIELD dst(edge) AS play_dst  \\\n        UNION \\\n        GO FROM \"team200\" OVER serve REVERSELY \\\n        YIELD src(edge) AS play_dst) \\\n        | GO FROM $-.play_dst OVER follow YIELD dst(edge) AS play_dst;\n</code></pre> <p>In the above query, the statements within the parentheses take precedence. That is, the <code>UNION</code> operation will be executed first, and its output will be executed as the input of the next operation with pipes.</p>"},{"location":"3.ngql-guide/5.operators/7.string/","title":"String operators","text":"<p>You can use the following string operators for concatenating, querying, and matching.</p> Name Description + Concatenates strings. CONTAINS Performs searchings in strings. (NOT) IN Checks whether a value is within a set of values. (NOT) STARTS WITH Performs matchings at the beginning of a string. (NOT) ENDS WITH Performs matchings at the end of a string. Regular expressions Perform string matchings using regular expressions. <p>Note</p> <p>All the string searchings or matchings are case-sensitive.</p>"},{"location":"3.ngql-guide/5.operators/7.string/#examples","title":"Examples","text":""},{"location":"3.ngql-guide/5.operators/7.string/#_1","title":"<code>+</code>","text":"<pre><code>nebula&gt; RETURN 'a' + 'b';\n+-----------+\n| (\"a\"+\"b\") |\n+-----------+\n| \"ab\"      |\n+-----------+\nnebula&gt; UNWIND 'a' AS a UNWIND 'b' AS b RETURN a + b;\n+-------+\n| (a+b) |\n+-------+\n| \"ab\"  |\n+-------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/7.string/#contains","title":"<code>CONTAINS</code>","text":"<p>The <code>CONTAINS</code> operator requires string types on both left and right sides.</p> <pre><code>nebula&gt; MATCH (s:player)-[e:serve]-&gt;(t:team) WHERE id(s) == \"player101\" \\\n        AND t.name CONTAINS \"ets\" RETURN s.name, e.start_year, e.end_year, t.name;\n+---------------+--------------+------------+-----------+\n| s.name        | e.start_year | e.end_year | t.name    |\n+---------------+--------------+------------+-----------+\n| \"Tony Parker\" | 2018         | 2019       | \"Hornets\" |\n+---------------+--------------+------------+-----------+\n\nnebula&gt; GO FROM \"player101\" OVER serve WHERE (STRING)properties(edge).start_year CONTAINS \"19\" AND \\\n        properties($^).name CONTAINS \"ny\" \\\n        YIELD properties($^).name, properties(edge).start_year, properties(edge).end_year, properties($$).name;\n+---------------------+-----------------------------+---------------------------+---------------------+\n| properties($^).name | properties(EDGE).start_year | properties(EDGE).end_year | properties($$).name |\n+---------------------+-----------------------------+---------------------------+---------------------+\n| \"Tony Parker\"       | 1999                        | 2018                      | \"Spurs\"             |\n+---------------------+-----------------------------+---------------------------+---------------------+\n\nnebula&gt; GO FROM \"player101\" OVER serve WHERE !(properties($$).name CONTAINS \"ets\") \\\n        YIELD properties($^).name, properties(edge).start_year, properties(edge).end_year, properties($$).name;\n+---------------------+-----------------------------+---------------------------+---------------------+\n| properties($^).name | properties(EDGE).start_year | properties(EDGE).end_year | properties($$).name |\n+---------------------+-----------------------------+---------------------------+---------------------+\n| \"Tony Parker\"       | 1999                        | 2018                      | \"Spurs\"             |\n+---------------------+-----------------------------+---------------------------+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/7.string/#not_in","title":"<code>(NOT) IN</code>","text":"<pre><code>nebula&gt; RETURN  1 IN [1,2,3], \"Yao\" NOT IN [\"Yi\", \"Tim\", \"Kobe\"], NULL IN [\"Yi\", \"Tim\", \"Kobe\"];\n+----------------+------------------------------------+-------------------------------+\n| (1 IN [1,2,3]) | (\"Yao\" NOT IN [\"Yi\",\"Tim\",\"Kobe\"]) | (NULL IN [\"Yi\",\"Tim\",\"Kobe\"]) |\n+----------------+------------------------------------+-------------------------------+\n| true           | true                               | __NULL__                      |\n+----------------+------------------------------------+-------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/7.string/#not_starts_with","title":"<code>(NOT) STARTS WITH</code>","text":"<pre><code>nebula&gt; RETURN 'apple' STARTS WITH 'app', 'apple' STARTS WITH 'a', 'apple' STARTS WITH toUpper('a');\n+-----------------------------+---------------------------+------------------------------------+\n| (\"apple\" STARTS WITH \"app\") | (\"apple\" STARTS WITH \"a\") | (\"apple\" STARTS WITH toUpper(\"a\")) |\n+-----------------------------+---------------------------+------------------------------------+\n| true                        | true                      | false                              |\n+-----------------------------+---------------------------+------------------------------------+\n\nnebula&gt; RETURN 'apple' STARTS WITH 'b','apple' NOT STARTS WITH 'app';\n+---------------------------+---------------------------------+\n| (\"apple\" STARTS WITH \"b\") | (\"apple\" NOT STARTS WITH \"app\") |\n+---------------------------+---------------------------------+\n| false                     | false                           |\n+---------------------------+---------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/7.string/#not_ends_with","title":"<code>(NOT) ENDS WITH</code>","text":"<pre><code>nebula&gt; RETURN 'apple' ENDS WITH 'app', 'apple' ENDS WITH 'e', 'apple' ENDS WITH 'E', 'apple' ENDS WITH 'b';\n+---------------------------+-------------------------+-------------------------+-------------------------+\n| (\"apple\" ENDS WITH \"app\") | (\"apple\" ENDS WITH \"e\") | (\"apple\" ENDS WITH \"E\") | (\"apple\" ENDS WITH \"b\") |\n+---------------------------+-------------------------+-------------------------+-------------------------+\n| false                     | true                    | false                   | false                   |\n+---------------------------+-------------------------+-------------------------+-------------------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/7.string/#regular_expressions","title":"Regular expressions","text":"<p>Note</p> <p>Regular expressions cannot work with native nGQL statements (<code>GO</code>, <code>FETCH</code>, <code>LOOKUP</code>, etc.). Use it in openCypher only (<code>MATCH</code>, <code>WHERE</code>, etc.).</p> <p>NebulaGraph supports filtering by using regular expressions. The regular expression syntax is inherited from <code>std::regex</code>. You can match on regular expressions by using <code>=~ 'regexp'</code>. For example:</p> <pre><code>nebula&gt; RETURN \"384748.39\" =~ \"\\\\d+(\\\\.\\\\d{2})?\";\n+--------------------------------+\n| (\"384748.39\"=~\"\\d+(\\.\\d{2})?\") |\n+--------------------------------+\n| true                           |\n+--------------------------------+\n\nnebula&gt; MATCH (v:player) WHERE v.name =~ 'Tony.*' RETURN v.name;\n+---------------+\n| v.name        |\n+---------------+\n| \"Tony Parker\" |\n+---------------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/8.list/","title":"List operators","text":"<p>NebulaGraph supports the following list operators:</p> List operator Description + Concatenates lists. IN Checks if an element exists in a list. [] Accesses an element(s) in a list using the index operator."},{"location":"3.ngql-guide/5.operators/8.list/#examples","title":"Examples","text":"<pre><code>nebula&gt; YIELD [1,2,3,4,5]+[6,7] AS myList;\n+-----------------------+\n| myList                |\n+-----------------------+\n| [1, 2, 3, 4, 5, 6, 7] |\n+-----------------------+\n\nnebula&gt; RETURN size([NULL, 1, 2]);\n+------------------+\n| size([NULL,1,2]) |\n+------------------+\n| 3                |\n+------------------+\n\nnebula&gt; RETURN NULL IN [NULL, 1];\n+--------------------+\n| (NULL IN [NULL,1]) |\n+--------------------+\n| __NULL__           |\n+--------------------+\n\nnebula&gt; WITH [2, 3, 4, 5] AS numberlist \\\n    UNWIND numberlist AS number \\\n    WITH number \\\n    WHERE number IN [2, 3, 8] \\\n    RETURN number;\n+--------+\n| number |\n+--------+\n| 2      |\n| 3      |\n+--------+\n\nnebula&gt; WITH ['Anne', 'John', 'Bill', 'Diane', 'Eve'] AS names RETURN names[1] AS result;\n+--------+\n| result |\n+--------+\n| \"John\" |\n+--------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/9.precedence/","title":"Operator precedence","text":"<p>The following list shows the precedence of nGQL operators in descending order. Operators that are shown together on a line have the same precedence.</p> <ul> <li><code>-</code> (negative number)</li> <li><code>!</code>, <code>NOT</code></li> <li><code>*</code>, <code>/</code>, <code>%</code></li> <li><code>-</code>, <code>+</code></li> <li><code>==</code>, <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>&lt;&gt;</code>, <code>!=</code></li> <li><code>AND</code></li> <li><code>OR</code>, <code>XOR</code></li> <li><code>=</code> (assignment)</li> </ul> <p>For operators that occur at the same precedence level within an expression, evaluation proceeds left to right, with the exception that assignments evaluate right to left.</p> <p>The precedence of operators determines the order of evaluation of terms in an expression. To modify this order and group terms explicitly, use parentheses.</p>"},{"location":"3.ngql-guide/5.operators/9.precedence/#examples","title":"Examples","text":"<pre><code>nebula&gt; RETURN 2+3*5;\n+-----------+\n| (2+(3*5)) |\n+-----------+\n| 17        |\n+-----------+\n\nnebula&gt; RETURN (2+3)*5;\n+-----------+\n| ((2+3)*5) |\n+-----------+\n| 25        |\n+-----------+\n</code></pre>"},{"location":"3.ngql-guide/5.operators/9.precedence/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>In openCypher, comparisons can be chained arbitrarily, e.g., <code>x &lt; y &lt;= z</code> is equivalent to <code>x &lt; y AND y &lt;= z</code> in openCypher.</p> <p>But in nGQL, <code>x &lt; y &lt;= z</code> is equivalent to <code>(x &lt; y) &lt;= z</code>. The result of <code>(x &lt; y)</code> is a boolean. Compare it with an integer <code>z</code>, and you will get the final result <code>NULL</code>.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/1.math/","title":"Built-in math functions","text":""},{"location":"3.ngql-guide/6.functions-and-expressions/1.math/#function_descriptions","title":"Function descriptions","text":"<p>NebulaGraph supports the following built-in math functions:</p> Function Description double abs(double x) Returns the absolute value of the argument. double floor(double x) Returns the largest integer value smaller than or equal to the argument. (Rounds down) double ceil(double x) Returns the smallest integer greater than or equal to the argument. (Rounds up) double round(double x) Returns the integer value nearest to the argument. Returns a number farther away from 0 if the argument is in the middle. double sqrt(double x) Returns the square root of the argument. double cbrt(double x) Returns the cubic root of the argument. double hypot(double x, double y) Returns the hypotenuse of a right-angled triangle. double pow(double x, double y) Returns the result of \\(x^y\\). double exp(double x) Returns the result of \\(e^x\\). double exp2(double x) Returns the result of \\(2^x\\). double log(double x) Returns the base-e logarithm of the argument. double log2(double x) Returns the base-2 logarithm of the argument. double log10(double x) Returns the base-10 logarithm of the argument. double sin(double x) Returns the sine of the argument. double asin(double x) Returns the inverse sine of the argument. double cos(double x) Returns the cosine of the argument. double acos(double x) Returns the inverse cosine of the argument. double tan(double x) Returns the tangent of the argument. double atan(double x) Returns the inverse tangent of the argument. double rand() Returns a random floating point number in the range from 0 (inclusive) to 1 (exclusive); i.e.[0,1). int rand32(int min, int max) Returns a random 32-bit integer in <code>[min, max)</code>.If you set only one argument, it is parsed as <code>max</code> and <code>min</code> is <code>0</code> by default.If you set no argument, the system returns a random signed 32-bit integer. int rand64(int min, int max) Returns a random 64-bit integer in <code>[min, max)</code>.If you set only one argument, it is parsed as <code>max</code> and <code>min</code> is <code>0</code> by default.If you set no argument, the system returns a random signed 64-bit integer. collect() Puts all the collected values into a list. avg() Returns the average value of the argument. count() Returns the number of records. max() Returns the maximum value. min() Returns the minimum value. std() Returns the population standard deviation. sum() Returns the sum value. bit_and() Bitwise AND. bit_or() Bitwise OR. bit_xor() Bitwise XOR. int size() Returns the number of elements in a list or a map. int range(int start, int end, int step) Returns a list of integers from <code>[start,end]</code> in the specified steps. <code>step</code> is 1 by default. int sign(double x) Returns the signum of the given number.If the number is 0, the system returns 0.If the number is negative, the system returns -1.If the number is positive, the system returns 1. double e() Returns the base of the natural logarithm, e (2.718281828459045). double pi() Returns the mathematical constant pi (3.141592653589793). double radians() Converts degrees to radians. <code>radians(180)</code> returns <code>3.141592653589793</code>. <p>Note</p> <p>If the argument is <code>NULL</code>, the output is undefined.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/1.math/#example","title":"Example","text":"<pre><code># The following statement supports aggregate functions.\nnebula&gt;  GO FROM \"player100\" OVER follow YIELD dst(edge) AS dst, properties($$).age AS age \\\n         | GROUP BY $-.dst \\\n         YIELD \\\n         $-.dst AS dst, \\\n         toInteger((sum($-.age)/count($-.age)))+avg(distinct $-.age+1)+1 AS statistics;\n+-------------+------------+\n| dst         | statistics |\n+-------------+------------+\n| \"player125\" | 84.0       |\n| \"player101\" | 74.0       |\n+-------------+------------+\nGot 2 rows (time spent 4739/5064 us)\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/10.collect/","title":"collect()","text":"<p>The <code>collect()</code> function returns a list containing the values returned by an expression. Using this function aggregates data by merging multiple records or values into a single list.</p> <p>The aggregate function <code>collect()</code> works like <code>GROUP BY</code> in SQL.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/10.collect/#examples","title":"Examples","text":"<pre><code>nebula&gt; UNWIND [1, 2, 1] AS a \\\n        RETURN a;\n+---+\n| a |\n+---+\n| 1 |\n| 2 |\n| 1 |\n+---+\n\nnebula&gt; UNWIND [1, 2, 1] AS a \\\n        RETURN collect(a);\n+------------+\n| collect(a) |\n+------------+\n| [1, 2, 1]  |\n+------------+\n\nnebula&gt; UNWIND [1, 2, 1] AS a \\\n        RETURN a, collect(a), size(collect(a));\n+---+------------+------------------+\n| a | collect(a) | size(COLLECT(a)) |\n+---+------------+------------------+\n| 2 | [2]        | 1                |\n| 1 | [1, 1]     | 2                |\n+---+------------+------------------+\n\n# The following examples sort the results in descending order, limit output rows to 3, and collect the output into a list.\u0153\nnebula&gt; UNWIND [\"c\", \"b\", \"a\", \"d\" ] AS p \\\n        WITH p AS q \\\n        ORDER BY q DESC LIMIT 3 \\\n        RETURN collect(q);\n+-----------------+\n| collect(q)      |\n+-----------------+\n| [\"d\", \"c\", \"b\"] |\n+-----------------+\n\nnebula&gt; WITH [1, 1, 2, 2] AS coll \\\n        UNWIND coll AS x \\\n        WITH DISTINCT x \\\n        RETURN collect(x) AS ss;\n+--------+\n| ss     |\n+--------+\n| [1, 2] |\n+--------+\n\nnebula&gt; MATCH (n:player) \\\n        RETURN collect(n.age);\n+---------------------------------------------------------------+\n| collect(n.age)                                                |\n+---------------------------------------------------------------+\n| [32, 32, 34, 29, 41, 40, 33, 25, 40, 37, ...\n...\n\n# The following example aggregates all the players' names by their ages.\nnebula&gt; MATCH (n:player) \\\n        RETURN n.age AS age, collect(n.name);\n+-----+--------------------------------------------------------------------------+\n| age | collect(n.name)                                                          |\n+-----+--------------------------------------------------------------------------+\n| 24  | [\"Giannis Antetokounmpo\"]                                                |\n| 20  | [\"Luka Doncic\"]                                                          |\n| 25  | [\"Joel Embiid\", \"Kyle Anderson\"]                                         |\n+-----+--------------------------------------------------------------------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/11.reduce/","title":"reduce() function","text":"<p>This topic will describe the <code>reduce</code> function.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/11.reduce/#opencypher_compatibility","title":"OpenCypher Compatibility","text":"<p>In openCypher, the <code>reduce()</code> function is not defined. nGQL will implement the <code>reduce()</code> function in the Cypher way.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/11.reduce/#syntax","title":"Syntax","text":"<p>The <code>reduce()</code> function applies an expression to each element in a list one by one, chains the result to the next iteration by taking it as the initial value, and returns the final result. This function iterates each element <code>e</code> in the given list, runs the expression on <code>e</code>, accumulates the result with the initial value, and store the new result in the accumulator as the initial value of the next iteration. It works like the fold or reduce method in functional languages such as Lisp and Scala.</p> <pre><code>reduce(&lt;accumulator&gt; = &lt;initial&gt;, &lt;variable&gt; IN &lt;list&gt; | &lt;expression&gt;)\n</code></pre> Parameter Description accumulator A variable that will hold the accumulated results as the list is iterated. initial An expression that runs once to give an initial value to the <code>accumulator</code>. variable A variable in the list that will be applied to the expression successively. list A list or a list of expressions. expression This expression will be run on each element in the list once and store the result value in the <code>accumulator</code>. <p>Note</p> <p>The type of the value returned depends on the parameters provided, along with the semantics of the expression.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/11.reduce/#examples","title":"Examples","text":"<pre><code>nebula&gt; RETURN reduce(totalNum = 10, n IN range(1, 3) | totalNum + n) AS r;\n+----+\n| r  |\n+----+\n| 16 |\n+----+\n\nnebula&gt; RETURN reduce(totalNum = -4 * 5, n IN [1, 2] | totalNum + n * 2) AS r;\n+-----+\n| r   |\n+-----+\n| -14 |\n+-----+\n\nnebula&gt; MATCH p = (n:player{name:\"LeBron James\"})&lt;-[:follow]-(m) \\\n        RETURN  nodes(p)[0].age AS src1,  nodes(p)[1].age AS dst2,  \\\n        reduce(totalAge = 100, n IN nodes(p) | totalAge + n.age) AS sum;\n+------+------+-----+\n| src1 | dst2 | sum |\n+------+------+-----+\n| 34   | 31   | 165 |\n| 34   | 29   | 163 |\n| 34   | 33   | 167 |\n| 34   | 26   | 160 |\n| 34   | 34   | 168 |\n| 34   | 37   | 171 |\n+------+------+-----+\n\nnebula&gt; LOOKUP ON player WHERE player.name == \"Tony Parker\" \\\n        |  GO FROM $-.VertexID over follow \\\n        WHERE follow.degree != reduce(totalNum = 5, n IN range(1, 3) | properties($$).age + totalNum + n) \\\n        YIELD properties($$).name AS id, properties($$).age AS age, properties(edge).degree AS degree;\n+---------------------+-----+--------+\n| id                  | age | degree |\n+---------------------+-----+--------+\n| \"Tim Duncan\"        | 42  | 95     |\n| \"LaMarcus Aldridge\" | 33  | 90     |\n| \"Manu Ginobili\"     | 41  | 95     |\n+---------------------+-----+--------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/","title":"hash function","text":"<p>The <code>hash()</code> function returns the hash value of the argument. The argument can be a number, a string, a list, a boolean, null, or an expression that evaluates to a value of the preceding data types.</p> <p>The source code of the <code>hash()</code> function (MurmurHash2), seed (<code>0xc70f6907UL</code>), and other parameters can be found in <code>MurmurHash2.h</code>.</p> <p>For Java, the hash function operates as follows.</p> <pre><code>MurmurHash2.hash64(\"to_be_hashed\".getBytes(),\"to_be_hashed\".getBytes().length, 0xc70f6907)\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<p>In nGQL 1.0, when nGQL does not support string VIDs, a common practice is to hash the strings first and then use the values as VIDs. But in nGQL 2.0, both string VIDs and integer VIDs are supported, so there is no need to use <code>hash()</code> to set VIDs.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#hash_a_number","title":"Hash a number","text":"<pre><code>nebula&gt; YIELD hash(-123);\n+--------------+\n| hash(-(123)) |\n+--------------+\n| -123         |\n+--------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#hash_a_string","title":"Hash a string","text":"<pre><code>nebula&gt; YIELD hash(\"to_be_hashed\");\n+----------------------+\n| hash(to_be_hashed)   |\n+----------------------+\n| -1098333533029391540 |\n+----------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#hash_a_list","title":"Hash a list","text":"<pre><code>nebula&gt; YIELD hash([1,2,3]);\n+----------------+\n| hash([1,2,3])  |\n+----------------+\n| 11093822460243 |\n+----------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#hash_a_boolean","title":"Hash a boolean","text":"<pre><code>nebula&gt; YIELD hash(true);\n+------------+\n| hash(true) |\n+------------+\n| 1          |\n+------------+\n\nnebula&gt; YIELD hash(false);\n+-------------+\n| hash(false) |\n+-------------+\n| 0           |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#hash_null","title":"Hash NULL","text":"<pre><code>nebula&gt; YIELD hash(NULL);\n+------------+\n| hash(NULL) |\n+------------+\n| -1         |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/12.hash/#hash_an_expression","title":"Hash an expression","text":"<pre><code>nebula&gt; YIELD hash(toLower(\"HELLO NEBULA\"));\n+-------------------------------+\n| hash(toLower(\"HELLO NEBULA\")) |\n+-------------------------------+\n| -8481157362655072082          |\n+-------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/","title":"concat function","text":"<p>The <code>concat()</code> and <code>concat_ws()</code> functions return strings concatenated by one or more strings.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/#concat_function_1","title":"concat() function","text":"<p>The <code>concat()</code> function requires at least two or more strings. All the parameters are concatenated into one string.</p> <ul> <li>If there is only one string, the string itself is returned.</li> </ul> <ul> <li>If any one of the strings is <code>NULL</code>, <code>NULL</code> is returned.</li> </ul>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/#syntax","title":"Syntax","text":"<pre><code>concat(string1,string2,...)\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/#examples","title":"Examples","text":"<pre><code>//This example concatenates 1, 2, and 3.\nnebula&gt; RETURN concat(\"1\",\"2\",\"3\") AS r;\n+-------+\n| r     |\n+-------+\n| \"123\" |\n+-------+\n\n//In this example, one of the string is NULL.\nnebula&gt; RETURN concat(\"1\",\"2\",NULL) AS r;\n+----------+\n| r        |\n+----------+\n| __NULL__ |\n+----------+\n\nnebula&gt; GO FROM \"player100\" over follow \\\nYIELD concat(src(edge), properties($^).age, properties($$).name, properties(edge).degree) AS A;\n+------------------------------+\n| A                            |\n+------------------------------+\n| \"player10042Tony Parker95\"   |\n| \"player10042Manu Ginobili95\" |\n+------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/#concat_ws_function","title":"concat_ws() function","text":"<p>The <code>concat_ws()</code> function connects two or more strings with a predefined separator.</p> <ul> <li>If the separator is <code>NULL</code>, the <code>concat_ws()</code> function returns <code>NULL</code>.</li> </ul> <ul> <li>If the separator is not <code>NULL</code> and there is only one string, the string itself is returned.</li> </ul> <ul> <li>If the separator is not <code>NULL</code> and there is a <code>NULL</code> in the strings, <code>NULL</code> is ignored during the concatenation.</li> </ul>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/#syntax_1","title":"Syntax","text":"<pre><code>concat_ws(separator,string1,string2,... )\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/13.concat/#examples_1","title":"Examples","text":"<pre><code>//This example concatenates a, b, and c with the separator +.\nnebula&gt; RETURN concat_ws(\"+\",\"a\",\"b\",\"c\") AS r;\n+---------+\n| r       |\n+---------+\n| \"a+b+c\" |\n+---------+\n\n//In this example, the separator is NULL.\nneubla&gt; RETURN concat_ws(NULL,\"a\",\"b\",\"c\") AS r;\n+----------+\n| r        |\n+----------+\n| __NULL__ |\n+----------+\n\n//In this example, the separator is + and there is a NULL in the strings.\nnebula&gt; RETURN concat_ws(\"+\",\"a\",NULL,\"b\",\"c\") AS r;\n+---------+\n| r       |\n+---------+\n| \"a+b+c\" |\n+---------+\n\n//In this example, the separator is + and there is only one string.\nnebula&gt; RETURN concat_ws(\"+\",\"a\") AS r;\n+-----+\n| r   |\n+-----+\n| \"a\" |\n+-----+\n\nnebula&gt; GO FROM \"player100\" over follow \\\nYIELD concat_ws(\" \",src(edge), properties($^).age, properties($$).name, properties(edge).degree) AS A;\n+---------------------------------+\n| A                               |\n+---------------------------------+\n| \"player100 42 Tony Parker 95\"   |\n| \"player100 42 Manu Ginobili 95\" |\n+---------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/14.geo/","title":"Geography functions","text":"<p>Geography functions are used to generate or perform operations on the value of the geography data type.</p> <p>For descriptions of the geography data types, see Geography.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/14.geo/#descriptions","title":"Descriptions","text":"Function Return Type Description ST_Point(longitude, latitude) <code>GEOGRAPHY</code> Creates the geography that contains a point. ST_GeogFromText(wkt_string) <code>GEOGRAPHY</code> Returns the geography corresponding to the input WKT string. ST_ASText(geography) <code>STRING</code> Returns the WKT string of the input geography. ST_Centroid(geography) <code>GEOGRAPHY</code> Returns the centroid of the input geography in the form of the single point geography. ST_ISValid(geography) <code>BOOL</code> Returns whether the input geography is valid. ST_Intersects(geography_1, geography_2) <code>BOOL</code> Returns whether geography_1 and geography_2 have intersections. ST_Covers(geography_1, geography_2) <code>BOOL</code> Returns whether geography_1 completely contains geography_2. If there is no point outside geography_1 in geography_2, return True. ST_CoveredBy(geography_1, geography_2) <code>BOOL</code> Returns whether geography_2 completely contains geography_1.If there is no point outside geography_2 in geography_1, return True. ST_DWithin(geography_1, geography_2, distance) <code>BOOL</code> If the distance between one point (at least) in geography_1 and one point in geography_2 is less than or equal to the distance specified by the distance parameter (measured by meters), return True. ST_Distance(geography_1, geography_2) <code>FLOAT</code> Returns the smallest possible distance (measured by meters) between two non-empty geographies. S2_CellIdFromPoint(point_geography) <code>INT</code> Returns the S2 Cell ID that covers the point geography. S2_CoveringCellIds(geography) <code>ARRAY&lt;INT64&gt;</code> Returns an array of S2 Cell IDs that cover the input geography."},{"location":"3.ngql-guide/6.functions-and-expressions/14.geo/#examples","title":"Examples","text":"<pre><code>nebula&gt; RETURN ST_ASText(ST_Point(1,1));\n+--------------------------+\n| ST_ASText(ST_Point(1,1)) |\n+--------------------------+\n| \"POINT(1 1)\"             |\n+--------------------------+\n\nnebula&gt; RETURN ST_ASText(ST_GeogFromText(\"POINT(3 8)\"));\n+------------------------------------------+\n| ST_ASText(ST_GeogFromText(\"POINT(3 8)\")) |\n+------------------------------------------+\n| \"POINT(3 8)\"                             |\n+------------------------------------------+\n\nnebula&gt; RETURN ST_ASTEXT(ST_Centroid(ST_GeogFromText(\"LineString(0 1,1 0)\")));\n+----------------------------------------------------------------+\n| ST_ASTEXT(ST_Centroid(ST_GeogFromText(\"LineString(0 1,1 0)\"))) |\n+----------------------------------------------------------------+\n| \"POINT(0.5000380800773782 0.5000190382261059)\"                 |\n+----------------------------------------------------------------+\n\nnebula&gt; RETURN ST_ISValid(ST_GeogFromText(\"POINT(3 8)\"));\n+-------------------------------------------+\n| ST_ISValid(ST_GeogFromText(\"POINT(3 8)\")) |\n+-------------------------------------------+\n| true                                      |\n+-------------------------------------------+\n\nnebula&gt; RETURN ST_Intersects(ST_GeogFromText(\"LineString(0 1,1 0)\"),ST_GeogFromText(\"LineString(0 0,1 1)\"));\n+----------------------------------------------------------------------------------------------+\n| ST_Intersects(ST_GeogFromText(\"LineString(0 1,1 0)\"),ST_GeogFromText(\"LineString(0 0,1 1)\")) |\n+----------------------------------------------------------------------------------------------+\n| true                                                                                         |\n+----------------------------------------------------------------------------------------------+\n\nnebula&gt; RETURN ST_Covers(ST_GeogFromText(\"POLYGON((0 0,10 0,10 10,0 10,0 0))\"),ST_Point(1,2));\n+--------------------------------------------------------------------------------+\n| ST_Covers(ST_GeogFromText(\"POLYGON((0 0,10 0,10 10,0 10,0 0))\"),ST_Point(1,2)) |\n+--------------------------------------------------------------------------------+\n| true                                                                           |\n+--------------------------------------------------------------------------------+\n\nnebula&gt; RETURN ST_CoveredBy(ST_Point(1,2),ST_GeogFromText(\"POLYGON((0 0,10 0,10 10,0 10,0 0))\"));\n+-----------------------------------------------------------------------------------+\n| ST_CoveredBy(ST_Point(1,2),ST_GeogFromText(\"POLYGON((0 0,10 0,10 10,0 10,0 0))\")) |\n+-----------------------------------------------------------------------------------+\n| true                                                                              |\n+-----------------------------------------------------------------------------------+\n\nnebula&gt; RETURN ST_dwithin(ST_GeogFromText(\"Point(0 0)\"),ST_GeogFromText(\"Point(10 10)\"),20000000000.0);\n+---------------------------------------------------------------------------------------+\n| ST_dwithin(ST_GeogFromText(\"Point(0 0)\"),ST_GeogFromText(\"Point(10 10)\"),20000000000) |\n+---------------------------------------------------------------------------------------+\n| true                                                                                  |\n+---------------------------------------------------------------------------------------+\n\nnebula&gt; RETURN ST_Distance(ST_GeogFromText(\"Point(0 0)\"),ST_GeogFromText(\"Point(10 10)\"));\n+----------------------------------------------------------------------------+\n| ST_Distance(ST_GeogFromText(\"Point(0 0)\"),ST_GeogFromText(\"Point(10 10)\")) |\n+----------------------------------------------------------------------------+\n| 1568523.0187677438                                                         |\n+----------------------------------------------------------------------------+\n\nnebula&gt; RETURN S2_CellIdFromPoint(ST_GeogFromText(\"Point(1 1)\"));\n+---------------------------------------------------+\n| S2_CellIdFromPoint(ST_GeogFromText(\"Point(1 1)\")) |\n+---------------------------------------------------+\n| 1153277837650709461                               |\n+---------------------------------------------------+\n\nnebula&gt; RETURN S2_CoveringCellIds(ST_GeogFromText(\"POLYGON((0 1, 1 2, 2 3, 0 1))\"));\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| S2_CoveringCellIds(ST_GeogFromText(\"POLYGON((0 1, 1 2, 2 3, 0 1))\"))                                                                                                     |\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| [1152391494368201343, 1153466862374223872, 1153554823304445952, 1153836298281156608, 1153959443583467520, 1154240918560178176, 1160503736791990272, 1160591697722212352] |\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/2.string/","title":"Built-in string functions","text":"<p>NebulaGraph supports the following built-in string functions:</p> <p>Note</p> <p>Like SQL, the position index of nGQL starts from <code>1</code>, while in C language it starts from <code>0</code>.</p> Function Description int strcasecmp(string a, string b) Compares string a and b without case sensitivity. When a = b, the return value is 0. When a &gt; b, the return value is greater than 0. When a &lt; b, the return value is less than 0. string lower(string a) Returns the argument in lowercase. string toLower(string a) The same as <code>lower()</code>. string upper(string a) Returns the argument in uppercase. string toUpper(string a) The same as <code>upper()</code>. int length(string a) Returns the length of the given string in bytes. string trim(string a) Removes leading and trailing spaces. string ltrim(string a) Removes leading spaces. string rtrim(string a) Removes trailing spaces. string left(string a, int count) Returns a substring consisting of <code>count</code> characters from the left side of string a. If string a is shorter than <code>count</code>, the system returns string a. string right(string a, int count) Returns a substring consisting of <code>count</code> characters from the right side of string a. If string a is shorter than <code>count</code>, the system returns string a. string lpad(string a, int size, string letters) Left-pads string a with string <code>letters</code> and returns a substring with the length of <code>size</code>. string rpad(string a, int size, string letters) Right-pads string a with string <code>letters</code> and returns a substring with the length of <code>size</code>. string substr(string a, int pos, int count) Returns a substring extracting <code>count</code> characters starting from the specified position <code>pos</code> of string a. string substring(string a, int pos, int count) The same as <code>substr()</code>. string reverse(string) Returns a string in reverse order. string replace(string a, string b, string c) Replaces string b in string a with string c. list split(string a, string b) Splits string a at string b and returns a list of strings. string toString() Takes in any data type and converts it into a string. int hash() Takes in any data type and encodes it into a hash value. <p>Note</p> <p>If the argument is <code>NULL</code>, the return is undefined.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/2.string/#explanations_for_the_return_of_substr_and_substring","title":"Explanations for the return of <code>substr()</code> and <code>substring()</code>","text":"<ul> <li>The position index starts from <code>0</code>.</li> </ul> <ul> <li>If <code>pos</code> is 0, the whole string is returned.</li> </ul> <ul> <li>If <code>pos</code> is greater than the maximum string index, an empty string is returned.</li> </ul> <ul> <li>If <code>pos</code> is a negative number, <code>BAD_DATA</code> is returned.</li> </ul> <ul> <li>If <code>count</code> is omitted, the function returns the substring starting at the position given by <code>pos</code> and extending to the end of the string.</li> </ul> <ul> <li>If <code>count</code> is 0, an empty string is returned.</li> </ul> <ul> <li>Using <code>NULL</code> as any of the argument of <code>substr()</code> will cause an issue.</li> </ul> <p>OpenCypher compatibility</p> <ul> <li>In openCypher, if <code>a</code> is <code>null</code>, <code>null</code> is returned.</li> <li>In openCypher, if <code>pos</code> is 0, the returned substring starts from the first character, and extend to <code>count</code> characters.</li> <li>In openCypher, if either <code>pos</code> or <code>count</code> is <code>null</code> or a negative integer, an issue is raised.</li> </ul>"},{"location":"3.ngql-guide/6.functions-and-expressions/3.date-and-time/","title":"Built-in date and time functions","text":"<p>NebulaGraph supports the following built-in date and time functions:</p> Function Description int now() Returns the current date and time of the system time zone. timestamp timestamp() Returns the current date and time of the system time zone. date date() Returns the current UTC date based on the current system. time time() Returns the current UTC time based on the current system. datetime datetime() Returns the current UTC date and time based on the current system. <p>The <code>date()</code>, <code>time()</code>, and <code>datetime()</code> functions accept three kind of parameters, namely empty, string, and map. The <code>timestamp()</code> function accepts two kind of parameters, namely empty and string.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/3.date-and-time/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>Time in openCypher is measured in milliseconds.</li> </ul> <ul> <li>Time in nGQL is measured in seconds. The milliseconds are displayed in <code>000</code>.</li> </ul>"},{"location":"3.ngql-guide/6.functions-and-expressions/3.date-and-time/#examples","title":"Examples","text":"<pre><code>&gt; RETURN now(), timestamp(), date(), time(), datetime();\n+------------+-------------+------------+-----------------+----------------------------+\n| now()      | timestamp() | date()     | time()          | datetime()                 |\n+------------+-------------+------------+-----------------+----------------------------+\n| 1625470028 | 1625470028  | 2021-07-05 | 07:27:07.944000 | 2021-07-05T07:27:07.944000 |\n+------------+-------------+------------+-----------------+----------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/4.schema/","title":"Schema functions","text":"<p>NebulaGraph supports the following schema functions.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/4.schema/#for_ngql_statements","title":"For nGQL statements","text":"<p>Note</p> <ul> <li>The following functions are only available in the YIELD clauses.</li> </ul> <ul> <li>The following functions are unavailable in the WHERE clauses.</li> </ul> Function Description id(vertex) Returns the ID of a vertex. The data type of the result is the same as the vertex ID. map properties(vertex) Returns the properties of a vertex. map properties(edge) Returns the properties of an edge. string type(edge) Returns the edge type of an edge. src(edge) Returns the source vertex ID of an edge. The data type of the result is the same as the vertex ID. dst(edge) Returns the destination vertex ID of an edge. The data type of the result is the same as the vertex ID. int rank(edge) Returns the rank value of an edge."},{"location":"3.ngql-guide/6.functions-and-expressions/4.schema/#for_statements_compatible_with_opencypher","title":"For statements compatible with openCypher","text":"Function Description id(&lt;vertex&gt;) Returns the ID of a vertex. The data type of the result is the same as the vertex ID. list tags(&lt;vertex&gt;) Returns the Tag of a vertex, which serves the same purpose as labels(). list labels(&lt;vertex&gt;) Returns the Tag of a vertex, which serves the same purpose as tags(). This function is used for compatibility with openCypher syntax. map properties(&lt;vertex_or_edge&gt;) Returns the properties of a vertex or an edge. string type(&lt;edge&gt;) Returns the edge type of an edge. src(&lt;edge&gt;) Returns the source vertex ID of an edge. The data type of the result is the same as the vertex ID. dst(&lt;edge&gt;) Returns the destination vertex ID of an edge. The data type of the result is the same as the vertex ID. vertex startNode(&lt;path&gt;) Visits an edge or a path and returns its source vertex ID. string endNode(&lt;path&gt;) Visits an edge or a path and returns its destination vertex ID. int rank(&lt;edge&gt;) Returns the rank value of an edge."},{"location":"3.ngql-guide/6.functions-and-expressions/4.schema/#examples","title":"Examples","text":"<pre><code>nebula&gt; GO FROM \"player100\" OVER follow REVERSELY \\\n        YIELD src(edge) AS destination;\n+-------------+\n| destination |\n+-------------+\n| \"player101\" |\n| \"player102\" |\n+-------------+\nnebula&gt; LOOKUP ON player WHERE player.age  &gt; 45 YIELD id(vertex);\n+-------------+-------------+\n| VertexID    | id(VERTEX)  |\n+-------------+-------------+\n| \"player144\" | \"player144\" |\n| \"player140\" | \"player140\" |\n+-------------+-------------+\n\nnebula&gt; MATCH (a:player) WHERE id(a) == \"player100\" \\\n        RETURN tags(a), labels(a), properties(a);\n+------------+------------+-------------------------------+\n| tags(a)    | labels(a)  | properties(a)                 |\n+------------+------------+-------------------------------+\n| [\"player\"] | [\"player\"] | {age: 42, name: \"Tim Duncan\"} |\n+------------+------------+-------------------------------+\n\nnebula&gt; MATCH p = (a :player {name : \"Tim Duncan\"})-[r:serve]-(t) \\\n        RETURN type(r), rank(r);\n+---------+---------+\n| type(r) | rank(r) |\n+---------+---------+\n| \"serve\" | 0       |\n+---------+---------+\n\nnebula&gt; MATCH p = (a :player {name : \"Tim Duncan\"})-[r:serve]-(t) \\\n        RETURN startNode(p), endNode(p);\n+----------------------------------------------------+----------------------------------+\n| startNode(p)                                       | endNode(p)                       |\n+----------------------------------------------------+----------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) | (\"team204\" :team{name: \"Spurs\"}) |\n+----------------------------------------------------+----------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/","title":"CASE expressions","text":"<p>The <code>CASE</code> expression uses conditions to filter the result of an nGQL query statement. It is usually used in the <code>YIELD</code> and <code>RETURN</code> clauses. nGQL provides two forms of <code>CASE</code> expressions just like openCypher: the simple form and the generic form.</p> <p>The <code>CASE</code> expression will traverse all the conditions. When the first condition is met, the <code>CASE</code> expression stops reading the conditions and returns the result. If no conditions are met, it returns the result in the <code>ELSE</code> clause. If there is no <code>ELSE</code> clause and no conditions are met, it returns <code>NULL</code>.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#the_simple_form_of_case_expressions","title":"The simple form of CASE expressions","text":""},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#syntax","title":"Syntax","text":"<pre><code>CASE &lt;comparer&gt;\nWHEN &lt;value&gt; THEN &lt;result&gt;\n[WHEN ...]\n[ELSE &lt;default&gt;]\nEND\n</code></pre> <p>Caution</p> <p>Always remember to end the <code>CASE</code> expression with an <code>END</code>.</p> <p>| Parameter  | Description                                                                                                 | |------------+-------------------------------------------------------------------------------------------------------------| | <code>comparer</code> | A value or a valid expression that outputs a value. This value is used to compare with the <code>value</code>.         | | <code>value</code>    | It will be compared with the <code>comparer</code>. If the <code>value</code> matches the <code>comparer</code>, then this condition is met. | | <code>result</code>   | The <code>result</code> is returned by the <code>CASE</code> expression if the <code>value</code> matches the <code>comparer</code>.                    | | <code>default</code>  | The <code>default</code> is returned by the <code>CASE</code> expression if no conditions are met.                                |</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#examples","title":"Examples","text":"<pre><code>nebula&gt; RETURN \\\n        CASE 2+3 \\\n        WHEN 4 THEN 0 \\\n        WHEN 5 THEN 1 \\\n        ELSE -1 \\\n        END \\\n        AS result;\n+--------+\n| result |\n+--------+\n| 1      |\n+--------+\n</code></pre> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD properties($$).name AS Name, \\\n        CASE properties($$).age &gt; 35 \\\n        WHEN true THEN \"Yes\" \\\n        WHEN false THEN \"No\" \\\n        ELSE \"Nah\" \\\n        END \\\n        AS Age_above_35;\n+-----------------+--------------+\n| Name            | Age_above_35 |\n+-----------------+--------------+\n| \"Tony Parker\"   | \"Yes\"        |\n| \"Manu Ginobili\" | \"Yes\"        |\n+-----------------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#the_generic_form_of_case_expressions","title":"The generic form of CASE expressions","text":""},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#syntax_1","title":"Syntax","text":"<pre><code>CASE\nWHEN &lt;condition&gt; THEN &lt;result&gt;\n[WHEN ...]\n[ELSE &lt;default&gt;]\nEND\n</code></pre> <p>| Parameter   | Description                                                                                 | |-------------+---------------------------------------------------------------------------------------------| | <code>condition</code> | If the <code>condition</code> is evaluated as true, the <code>result</code> is returned by the <code>CASE</code> expression. | | <code>result</code>    | The <code>result</code> is returned by the <code>CASE</code> expression if the <code>condition</code> is evaluated as true.  | | <code>default</code>   | The <code>default</code> is returned by the <code>CASE</code> expression if no conditions are met.                |</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#examples_1","title":"Examples","text":"<pre><code>nebula&gt; YIELD \\\n        CASE WHEN 4 &gt; 5 THEN 0 \\\n        WHEN 3+4==7 THEN 1 \\\n        ELSE 2 \\\n        END \\\n        AS result;\n+--------+\n| result |\n+--------+\n| 1      |\n+--------+\n</code></pre> <pre><code>nebula&gt; MATCH (v:player) WHERE v.age &gt; 30 \\\n        RETURN v.name AS Name,  \\\n        CASE \\\n        WHEN v.name STARTS WITH \"T\" THEN \"Yes\" \\\n        ELSE \"No\" \\\n        END \\\n        AS Starts_with_T;\n+---------------------+---------------+\n| Name                | Starts_with_T |\n+---------------------+---------------+\n| \"Tim\"               | \"Yes\"         |\n| \"LaMarcus Aldridge\" | \"No\"          |\n| \"Tony Parker\"       | \"Yes\"         |\n+---------------------+---------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/5.case-expressions/#differences_between_the_simple_form_and_the_generic_form","title":"Differences between the simple form and the generic form","text":"<p>To avoid the misuse of the simple form and the generic form, it is important to understand their differences. The following example can help explain them.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD properties($$).name AS Name, properties($$).age AS Age, \\\n        CASE properties($$).age \\\n        WHEN properties($$).age &gt; 35 THEN \"Yes\" \\\n        ELSE \"No\" \\\n        END \\\n        AS Age_above_35;\n+-----------------+-----+--------------+\n| Name            | Age | Age_above_35 |\n+-----------------+-----+--------------+\n| \"Tony Parker\"   | 36  | \"No\"         |\n| \"Manu Ginobili\" | 41  | \"No\"         |\n+-----------------+-----+--------------+\n</code></pre> <p>The preceding <code>GO</code> query is intended to output <code>Yes</code> when the player's age is above 35. However, in this example, when the player's age is 36, the actual output is not as expected: It is <code>No</code> instead of <code>Yes</code>.</p> <p>This is because the query uses the <code>CASE</code> expression in the simple form, and a comparison between the values of <code>$$.player.age</code> and <code>$$.player.age &gt; 35</code> is made. When the player age is 36:</p> <ul> <li>The value of <code>$$.player.age</code> is <code>36</code>. It is an integer.</li> </ul> <ul> <li><code>$$.player.age &gt; 35</code> is evaluated to be <code>true</code>. It is a boolean.</li> </ul> <p>The values of <code>$$.player.age</code> and <code>$$.player.age &gt; 35</code> do not match. Therefore, the condition is not met and <code>No</code> is returned.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/6.list/","title":"List functions","text":"<p>NebulaGraph supports the following list functions:</p> Function Description keys(expr) Returns a list containing the string representations for all the property names of vertices, edges, or maps. labels(vertex) Returns the list containing all the tags of a vertex. nodes(path) Returns the list containing all the vertices in a path. range(start, end [, step]) Returns the list containing all the fixed-length steps in <code>[start,end]</code>. <code>step</code> is 1 by default. relationships(path) Returns the list containing all the relationships in a path. reverse(list) Returns the list reversing the order of all elements in the original list. tail(list) Returns all the elements of the original list, excluding the first one. head(list) Returns the first element of a list. last(list) Returns the last element of a list. coalesce(list) Returns the first not null value in a list. reduce() See reduce() function. <p>Note</p> <p>If the argument is <code>NULL</code>, the output is undefined.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/6.list/#examples","title":"Examples","text":"<pre><code>nebula&gt; WITH [NULL, 4923, 'abc', 521, 487] AS ids \\\n        RETURN reverse(ids), tail(ids), head(ids), last(ids), coalesce(ids);\n+-----------------------------------+-------------------------+-----------+-----------+---------------+\n| reverse(ids)                      | tail(ids)               | head(ids) | last(ids) | coalesce(ids) |\n+-----------------------------------+-------------------------+-----------+-----------+---------------+\n| [487, 521, \"abc\", 4923, __NULL__] | [4923, \"abc\", 521, 487] | __NULL__  | 487       | 4923          |\n+-----------------------------------+-------------------------+-----------+-----------+---------------+\n\nnebula&gt; MATCH (a:player)-[r]-&gt;() \\\n        WHERE id(a) == \"player100\" \\\n        RETURN labels(a),  keys(r);\n+------------+----------------------------+\n| labels(a)  | keys(r)                    |\n+------------+----------------------------+\n| [\"player\"] | [\"degree\"]                 |\n| [\"player\"] | [\"degree\"]                 |\n| [\"player\"] | [\"end_year\", \"start_year\"] |\n+------------+----------------------------+\n\nnebula&gt; MATCH p = (a:player)-[]-&gt;(b)-[]-&gt;(c:team) \\\n        WHERE a.name == \"Tim Duncan\" AND c.name == \"Spurs\" \\\n        RETURN nodes(p);\n+-----------------------------------------------------------------------------------------------------------------------------------------------+\n| nodes(p)                                                                                                                                      |\n+-----------------------------------------------------------------------------------------------------------------------------------------------+\n| [(\"player100\" :player{age: 42, name: \"Tim Duncan\"}), (\"player101\" :player{age: 36, name: \"Tony Parker\"}), (\"team204\" :team{name: \"Spurs\"})]   |\n| [(\"player100\" :player{age: 42, name: \"Tim Duncan\"}), (\"player125\" :player{age: 41, name: \"Manu Ginobili\"}), (\"team204\" :team{name: \"Spurs\"})] |\n+-----------------------------------------------------------------------------------------------------------------------------------------------+\n\nnebula&gt; MATCH p = (a:player)-[]-&gt;(b)-[]-&gt;(c:team) WHERE a.name == \"Tim Duncan\" AND c.name == \"Spurs\" RETURN relationships(p);\n+-----------------------------------------------------------------------------------------------------------------------------+\n| relationships(p)                                                                                                            |\n+-----------------------------------------------------------------------------------------------------------------------------+\n| [[:follow \"player100\"-&gt;\"player101\" @0 {degree: 95}], [:serve \"player101\"-&gt;\"team204\" @0 {end_year: 2018, start_year: 1999}]] |\n| [[:follow \"player100\"-&gt;\"player125\" @0 {degree: 95}], [:serve \"player125\"-&gt;\"team204\" @0 {end_year: 2018, start_year: 2002}]] |\n+-----------------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/7.count/","title":"count() function","text":"<p>The <code>count()</code> function counts the number of the specified values or rows.</p> <ul> <li>(Native nGQL) You can use <code>count()</code> and <code>GROUP BY</code> together to group and count the number of specific values. Use <code>YIELD</code> to return.</li> </ul> <ul> <li>(OpenCypher style) You can use <code>count()</code> and <code>RETURN</code>. <code>GROUP BY</code> is not necessary.</li> </ul>"},{"location":"3.ngql-guide/6.functions-and-expressions/7.count/#syntax","title":"Syntax","text":"<pre><code>count({expr | *})\n</code></pre> <ul> <li>count(*) returns the number of rows (including NULL).</li> </ul> <ul> <li>count(expr) returns the number of non-NULL values that meet the expression.</li> </ul> <ul> <li><code>count()</code> and <code>size()</code> are different.</li> </ul>"},{"location":"3.ngql-guide/6.functions-and-expressions/7.count/#examples","title":"Examples","text":"<pre><code>nebula&gt; WITH [NULL, 1, 1, 2, 2] As a UNWIND a AS b \\\n        RETURN count(b), count(*), count(DISTINCT b);\n+----------+----------+-------------------+\n| count(b) | count(*) | count(distinct b) |\n+----------+----------+-------------------+\n| 4        | 5        | 2                 |\n+----------+----------+-------------------+\n</code></pre> <pre><code># The statement in the following example searches for the people whom `player101` follows and people who follow `player101`, i.e. a bidirectional query.\nnebula&gt; GO FROM \"player101\" OVER follow BIDIRECT \\\n        YIELD properties($$).name AS Name \\\n        | GROUP BY $-.Name YIELD $-.Name, count(*);\n+---------------------+----------+\n| $-.Name             | count(*) |\n+---------------------+----------+\n| \"LaMarcus Aldridge\" | 2        |\n| \"Tim Duncan\"        | 2        |\n| \"Marco Belinelli\"   | 1        |\n| \"Manu Ginobili\"     | 1        |\n| \"Boris Diaw\"        | 1        |\n| \"Dejounte Murray\"   | 1        |\n+---------------------+----------+\n</code></pre> <p>The preceding example retrieves two columns:</p> <ul> <li><code>$-.Name</code>: the names of the people.</li> </ul> <ul> <li><code>count(*)</code>: how many times the names show up.</li> </ul> <p>Because there are no duplicate names in the <code>basketballplayer</code> dataset, the number <code>2</code> in the column <code>count(*)</code> shows that the person in that row and <code>player101</code> have followed each other.</p> <pre><code># a: The statement in the following example retrieves the age distribution of the players in the dataset.\nnebula&gt; LOOKUP ON player \\\n        YIELD player.age As playerage \\\n        | GROUP BY $-.playerage \\\n        YIELD $-.playerage as age, count(*) AS number \\\n        | ORDER BY $-.number DESC, $-.age DESC;\n+-----+--------+\n| age | number |\n+-----+--------+\n| 34  | 4      |\n| 33  | 4      |\n| 30  | 4      |\n| 29  | 4      |\n| 38  | 3      |\n+-----+--------+\n...\n\n# b: The statement in the following example retrieves the age distribution of the players in the dataset.\nnebula&gt; MATCH (n:player) \\\n        RETURN n.age as age, count(*) as number \\\n        ORDER BY number DESC, age DESC;\n+-----+--------+\n| age | number |\n+-----+--------+\n| 34  | 4      |\n| 33  | 4      |\n| 30  | 4      |\n| 29  | 4      |\n| 38  | 3      |\n+-----+--------+\n...\n</code></pre> <pre><code># The statement in the following example counts the number of edges that Tim Duncan relates.\nnebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) -- (v2) \\\n        RETURN count(DISTINCT v2);\n+--------------------+\n| count(distinct v2) |\n+--------------------+\n| 11                 |\n+--------------------+\n\n# The statement in the following example counts the number of edges that Tim Duncan relates and returns two columns (no DISTINCT and DISTINCT) in multi-hop queries.\nnebula&gt; MATCH (n:player {name : \"Tim Duncan\"})-[]-&gt;(friend:player)-[]-&gt;(fof:player) \\\n        RETURN count(fof), count(DISTINCT fof);\n+------------+---------------------+\n| count(fof) | count(distinct fof) |\n+------------+---------------------+\n| 4          | 3                   |\n+------------+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/8.predicate/","title":"Predicate functions","text":"<p>Predicate functions return <code>true</code> or <code>false</code>. They are most commonly used in <code>WHERE</code> clauses.</p> <p>NebulaGraph supports the following predicate functions:</p> Functions Description exists() Returns <code>true</code> if the specified property exists in the vertex, edge or map. Otherwise, returns <code>false</code>. any() Returns <code>true</code> if the specified predicate holds for at least one element in the given list. Otherwise, returns <code>false</code>. all() Returns <code>true</code> if the specified predicate holds for all elements in the given list. Otherwise, returns <code>false</code>. none() Returns <code>true</code> if the specified predicate holds for no element in the given list. Otherwise, returns <code>false</code>. single() Returns <code>true</code> if the specified predicate holds for exactly one of the elements in the given list. Otherwise, returns <code>false</code>. <p>Note</p> <p>NULL is returned if the list is NULL or all of its elements are NULL.</p> <p>Compatibility</p> <p>In openCypher, only function <code>exists()</code> is defined and specified. The other functions are implement-dependent.</p>"},{"location":"3.ngql-guide/6.functions-and-expressions/8.predicate/#syntax","title":"Syntax","text":"<pre><code>&lt;predicate&gt;(&lt;variable&gt; IN &lt;list&gt; WHERE &lt;condition&gt;)\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/8.predicate/#examples","title":"Examples","text":"<pre><code>nebula&gt; RETURN any(n IN [1, 2, 3, 4, 5, NULL] \\\n        WHERE n &gt; 2) AS r;\n+------+\n| r    |\n+------+\n| true |\n+------+\n\nnebula&gt; RETURN single(n IN range(1, 5) \\\n        WHERE n == 3) AS r;\n+------+\n| r    |\n+------+\n| true |\n+------+\n\nnebula&gt; RETURN none(n IN range(1, 3) \\\n        WHERE n == 0) AS r;\n+------+\n| r    |\n+------+\n| true |\n+------+\n\nnebula&gt; WITH [1, 2, 3, 4, 5, NULL] AS a \\\n        RETURN any(n IN a WHERE n &gt; 2);\n+-------------------------+\n| any(n IN a WHERE (n&gt;2)) |\n+-------------------------+\n| true                    |\n+-------------------------+\n\nnebula&gt; MATCH p = (n:player{name:\"LeBron James\"})&lt;-[:follow]-(m) \\\n        RETURN nodes(p)[0].name AS n1, nodes(p)[1].name AS n2, \\\n        all(n IN nodes(p) WHERE n.name NOT STARTS WITH \"D\") AS b;\n+----------------+-------------------+-------+\n| n1             | n2                | b     |\n+----------------+-------------------+-------+\n| \"LeBron James\" | \"Danny Green\"     | false |\n| \"LeBron James\" | \"Dejounte Murray\" | false |\n| \"LeBron James\" | \"Chris Paul\"      | true  |\n| \"LeBron James\" | \"Kyrie Irving\"    | true  |\n| \"LeBron James\" | \"Carmelo Anthony\" | true  |\n| \"LeBron James\" | \"Dwyane Wade\"     | false |\n+----------------+-------------------+-------+\n\nnebula&gt; MATCH p = (n:player{name:\"LeBron James\"})-[:follow]-&gt;(m) \\\n        RETURN single(n IN nodes(p) WHERE n.age &gt; 40) AS b;\n+------+\n| b    |\n+------+\n| true |\n+------+\n\nnebula&gt; MATCH (n:player) \\\n        RETURN exists(n.id), n IS NOT NULL;\n+--------------+---------------+\n| exists(n.id) | n IS NOT NULL |\n+--------------+---------------+\n| false        | true          |\n+--------------+---------------+\n...\n\nnebula&gt; MATCH (n:player) \\\n        WHERE exists(n['name']) RETURN n;\n+-------------------------------------------------------------------------------------------------------------+\n| n                                                                                                           |\n+-------------------------------------------------------------------------------------------------------------+\n| (\"Grant Hill\" :player{age: 46, name: \"Grant Hill\"})                                                         |\n| (\"Marc Gasol\" :player{age: 34, name: \"Marc Gasol\"})                                                         |\n+-------------------------------------------------------------------------------------------------------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/6.functions-and-expressions/9.user-defined-functions/","title":"User-defined functions","text":""},{"location":"3.ngql-guide/6.functions-and-expressions/9.user-defined-functions/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>User-defined functions (UDF) and storage processes are not yet supported nor designed in NebulaGraph 2.6.2.</p>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/","title":"MATCH","text":"<p>The <code>MATCH</code> statement supports searching based on pattern matching.</p> <p>A <code>MATCH</code> statement defines a search pattern and uses it to match data stored in NebulaGraph and to retrieve them in the form defined in the <code>RETURN</code> clause.</p> <p>The examples in this topic use the basketballplayer dataset as the sample dataset.</p>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#syntax","title":"Syntax","text":"<p>The syntax of <code>MATCH</code> is relatively more flexible compared with that of other query statements such as <code>GO</code> or <code>LOOKUP</code>. But generally, it can be summarized as follows.</p> <pre><code>MATCH &lt;pattern&gt; [&lt;WHERE clause&gt;] RETURN &lt;output&gt;;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#the_workflow_of_match","title":"The workflow of MATCH","text":"<ol> <li> <p>The <code>MATCH</code> statement uses a native index to locate a source vertex or an edge. The source vertex or the edge can be in any position in the pattern. In other words, in a valid <code>MATCH</code> statement, there must be an indexed property, a tag, or an edge type. Or the VID of a specific vertex must be specified with the id() function in the <code>WHERE</code> clause. For how to create an index, see create native index.</p> </li> <li> <p>The <code>MATCH</code> statement searches through the pattern to match edges or vertices.</p> <p>Note</p> <p>The path type of the <code>MATCH</code> statement is <code>trail</code>. That is, only vertices can be repeatedly visited in the graph traversal. Edges cannot be repeatedly visited. For details, see path.</p> </li> <li> <p>The <code>MATCH</code> statement retrieves data according to the <code>RETURN</code> clause.</p> </li> </ol>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>For now, nGQL does not support traversing all vertices and edges with <code>MATCH</code>, such as <code>MATCH (v) RETURN v</code>. However, after the index of a certain tag is created, all corresponding vertices can be traversed, such as <code>MATCH (v:T1) RETURN v</code>.</li> </ul> <ul> <li>Graph pattern is not supported in the <code>WHERE</code> clause.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#using_patterns_in_match_statements","title":"Using patterns in MATCH statements","text":""},{"location":"3.ngql-guide/7.general-query-statements/2.match/#prerequisites","title":"Prerequisites","text":"<p>Make sure there is at least one index in the <code>MATCH</code> statement, or there is a specified VID. If you want to create an index, but there are already related vertices, edges, or properties, you must rebuild indexes after creating the index to make it valid.</p> <p>Caution</p> <p>Correct use of indexes can speed up queries, but indexes can dramatically reduce the write performance. The performance reduction can be as much as 90% or even more. DO NOT use indexes in production environments unless you are fully aware of their influences on your service.</p> <pre><code># The following example creates an index on both the name property of the tag player and the edge type follow.\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS name ON player(name(20));\nnebula&gt; CREATE EDGE INDEX IF NOT EXISTS follow_index on follow();\n\n# The following example rebuilds the index.\nnebula&gt; REBUILD TAG INDEX name;\n+------------+\n| New Job Id |\n+------------+\n| 121        |\n+------------+\n\nnebula&gt; REBUILD EDGE INDEX follow_index;\n+------------+\n| New Job Id |\n+------------+\n| 122        |\n+------------+\n\n\n# The following example makes sure the index is rebuilt successfully.\nnebula&gt; SHOW JOB 121;\n+----------------+---------------------+------------+----------------------------+----------------------------+\n| Job Id(TaskId) | Command(Dest)       | Status     | Start Time                 | Stop Time                  |\n+----------------+---------------------+------------+----------------------------+----------------------------+\n| 121            | \"REBUILD_TAG_INDEX\" | \"FINISHED\" | 2021-05-27T02:18:02.000000 | 2021-05-27T02:18:02.000000 |\n| 0              | \"storaged1\"         | \"FINISHED\" | 2021-05-27T02:18:02.000000 | 2021-05-27T02:18:02.000000 |\n| 1              | \"storaged0\"         | \"FINISHED\" | 2021-05-27T02:18:02.000000 | 2021-05-27T02:18:02.000000 |\n| 2              | \"storaged2\"         | \"FINISHED\" | 2021-05-27T02:18:02.000000 | 2021-05-27T02:18:02.000000 |\n+----------------+---------------------+------------+----------------------------+----------------------------+\n\nnebula&gt; SHOW JOB 122;\n+----------------+----------------------+------------+----------------------------+----------------------------+\n| Job Id(TaskId) | Command(Dest)        | Status     | Start Time                 | Stop Time                  |\n+----------------+----------------------+------------+----------------------------+----------------------------+\n| 122            | \"REBUILD_EDGE_INDEX\" | \"FINISHED\" | 2021-05-27T02:18:11.000000 | 2021-05-27T02:18:11.000000 |\n| 0              | \"storaged1\"          | \"FINISHED\" | 2021-05-27T02:18:11.000000 | 2021-05-27T02:18:21.000000 |\n| 1              | \"storaged0\"          | \"FINISHED\" | 2021-05-27T02:18:11.000000 | 2021-05-27T02:18:21.000000 |\n| 2              | \"storaged2\"          | \"FINISHED\" | 2021-05-27T02:18:11.000000 | 2021-05-27T02:18:21.000000 |\n+----------------+----------------------+------------+----------------------------+----------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_vertices","title":"Match vertices","text":"<p>You can use a user-defined variable in a pair of parentheses to represent a vertex in a pattern. For example: <code>(v)</code>.</p>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_tags","title":"Match tags","text":"<p>Note</p> <p>The prerequisite for matching a tag is that the tag itself has an index or a certain property of the tag has an index. Otherwise, you cannot execute the <code>MATCH</code> statement based on the tag.</p> <p>You can specify a tag with <code>:&lt;tag_name&gt;</code> after the vertex in a pattern.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        RETURN v;\n+---------------------------------------------------------------+\n| v                                                             |\n+---------------------------------------------------------------+\n| (\"player105\" :player{age: 31, name: \"Danny Green\"})           |\n| (\"player109\" :player{age: 34, name: \"Tiago Splitter\"})        |\n| (\"player111\" :player{age: 38, name: \"David West\"})            |\n...\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_vertex_properties","title":"Match vertex properties","text":"<p>Note</p> <p>The prerequisite for matching a vertex property is that the tag itself has an index of the corresponding property. Otherwise, you cannot execute the <code>MATCH</code> statement to match the property.</p> <p>You can specify a vertex property with <code>{&lt;prop_name&gt;: &lt;prop_value&gt;}</code> after the tag in a pattern.</p> <pre><code># The following example uses the name property to match a vertex.\nnebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN v;\n+----------------------------------------------------+\n| v                                                  |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n</code></pre> <p>The <code>WHERE</code> clause can do the same thing:</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.name == \"Tim Duncan\" \\\n        RETURN v;\n+----------------------------------------------------+\n| v                                                  |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n</code></pre> <p>OpenCypher compatibility</p> <p>In openCypher 9, <code>=</code> is the equality operator. However, in nGQL, <code>==</code> is the equality operator and <code>=</code> is the assignment operator (as in C++ or Java).</p>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_vids","title":"Match VIDs","text":"<p>You can use the VID to match a vertex. The <code>id()</code> function can retrieve the VID of a vertex.</p> <pre><code>nebula&gt; MATCH (v) \\\n        WHERE id(v) == 'player101' \\\n        RETURN v;\n+-----------------------------------------------------+\n| v                                                   |\n+-----------------------------------------------------+\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"}) |\n+-----------------------------------------------------+\n</code></pre> <p>To match multiple VIDs, use <code>WHERE id(v) IN [vid_list]</code>.</p> <pre><code>nebula&gt; MATCH (v:player { name: 'Tim Duncan' })--(v2) \\\n        WHERE id(v2) IN [\"player101\", \"player102\"] \\\n        RETURN v2;\n+-----------------------------------------------------------+\n| v2                                                        |\n+-----------------------------------------------------------+\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       |\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       |\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) |\n+-----------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_connected_vertices","title":"Match connected vertices","text":"<p>You can use the <code>--</code> symbol to represent edges of both directions and match vertices connected by these edges.</p> <p>Legacy version compatibility</p> <p>In nGQL 1.x, the <code>--</code> symbol is used for inline comments. Starting from nGQL 2.x, the <code>--</code> symbol represents an incoming or outgoing edge.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})--(v2) \\\n        RETURN v2.name AS Name;\n+---------------------+\n| Name                |\n+---------------------+\n| \"Spurs\"             |\n| \"Tony Parker\"       |\n| \"LaMarcus Aldridge\" |\n| \"Marco Belinelli\"   |\n...\n</code></pre> <p>You can add a <code>&gt;</code> or <code>&lt;</code> to the <code>--</code> symbol to specify the direction of an edge.</p> <p>In the following example, <code>--&gt;</code> represents an edge that starts from <code>v</code> and points to <code>v2</code>. To <code>v</code>, this is an outgoing edge, and to <code>v2</code> this is an incoming edge.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})--&gt;(v2) \\\n        RETURN v2.name AS Name;\n+-----------------+\n| Name            |\n+-----------------+\n| \"Spurs\"         |\n| \"Tony Parker\"   |\n| \"Manu Ginobili\" |\n+-----------------+\n</code></pre> <p>To extend the pattern, you can add more vertices and edges.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})--&gt;(v2)&lt;--(v3) \\\n        RETURN v3.name AS Name;\n+---------------------+\n| Name                |\n+---------------------+\n| \"Dejounte Murray\"   |\n| \"LaMarcus Aldridge\" |\n| \"Marco Belinelli\"   |\n...\n</code></pre> <p>If you do not need to refer to a vertex, you can omit the variable representing it in the parentheses.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})--&gt;()&lt;--(v3) \\\n        RETURN v3.name AS Name;\n+---------------------+\n| Name                |\n+---------------------+\n| \"Dejounte Murray\"   |\n| \"LaMarcus Aldridge\" |\n| \"Marco Belinelli\"   |\n...\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_paths","title":"Match paths","text":"<p>Connected vertices and edges form a path. You can use a user-defined variable to name a path as follows.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})--&gt;(v2) \\\n        RETURN p;\n+--------------------------------------------------------------------------------------------------------------------------------------+\n| p                                                                                                                                    |\n+--------------------------------------------------------------------------------------------------------------------------------------+\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:serve@0 {end_year: 2016, start_year: 1997}]-&gt;(\"team204\" :team{name: \"Spurs\"})&gt; |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})&gt;   |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player125\" :player{age: 41, name: \"Manu Ginobili\"})&gt; |\n+--------------------------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>OpenCypher compatibility</p> <p>In nGQL, the <code>@</code> symbol represents the rank of an edge, but openCypher has no such concept.</p>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_edges","title":"Match edges","text":"<p>Besides using <code>--</code>, <code>--&gt;</code>, or <code>&lt;--</code> to indicate a nameless edge, you can use a user-defined variable in a pair of square brackets to represent a named edge. For example: <code>-[e]-</code>.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[e]-(v2) \\\n        RETURN e;\n+-----------------------------------------------------------------------+\n| e                                                                     |\n+-----------------------------------------------------------------------+\n| [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}] |\n| [:follow \"player101\"-&gt;\"player100\" @0 {degree: 95}]                    |\n| [:follow \"player102\"-&gt;\"player100\" @0 {degree: 75}]                    |\n...\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_edge_types","title":"Match edge types","text":"<p>Just like vertices, you can specify edge types with <code>:&lt;edge_type&gt;</code> in a pattern. For example: <code>-[e:follow]-</code>.</p> <pre><code>nebula&gt; MATCH ()-[e:follow]-() \\\n        RETURN e;\n+-----------------------------------------------------+\n| e                                                   |\n+-----------------------------------------------------+\n| [:follow \"player104\"-&gt;\"player105\" @0 {degree: 60}]  |\n| [:follow \"player113\"-&gt;\"player105\" @0 {degree: 99}]  |\n| [:follow \"player105\"-&gt;\"player100\" @0 {degree: 70}]  |\n...\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_edge_type_properties","title":"Match edge type properties","text":"<p>Note</p> <p>The prerequisite for matching an edge type property is that the edge type itself has an index of the corresponding property. Otherwise, you cannot execute the <code>MATCH</code> statement to match the property.</p> <p>You can specify edge type properties with <code>{&lt;prop_name&gt;: &lt;prop_value&gt;}</code> in a pattern. For example: <code>[e:follow{likeness:95}]</code>.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[e:follow{degree:95}]-&gt;(v2) \\\n        RETURN e;\n+--------------------------------------------------------+\n| e                                                      |\n+--------------------------------------------------------+\n| [:follow \"player100\"-&gt;\"player101\" @0 {degree: 95}]     |\n| [:follow \"player100\"-&gt;\"player125\" @0 {degree: 95}]     |\n+--------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_multiple_edge_types","title":"Match multiple edge types","text":"<p>The <code>|</code> symbol can help matching multiple edge types. For example: <code>[e:follow|:serve]</code>. The English colon (:) before the first edge type cannot be omitted, but the English colon before the subsequent edge type can be omitted, such as <code>[e:follow|serve]</code>.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[e:follow|:serve]-&gt;(v2) \\\n        RETURN e;\n+---------------------------------------------------------------------------+\n| e                                                                         |\n+---------------------------------------------------------------------------+\n| [:follow \"player100\"-&gt;\"player101\" @0 {degree: 95}]                        |\n| [:follow \"player100\"-&gt;\"player125\" @0 {degree: 95}]                        |\n| [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}]     |\n+---------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_multiple_edges","title":"Match multiple edges","text":"<p>You can extend a pattern to match multiple edges in a path.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[]-&gt;(v2)&lt;-[e:serve]-(v3) \\\n        RETURN v2, v3;\n+----------------------------------+-----------------------------------------------------------+\n| v2                               | v3                                                        |\n+----------------------------------+-----------------------------------------------------------+\n| (\"team204\" :team{name: \"Spurs\"}) | (\"player104\" :player{age: 32, name: \"Marco Belinelli\"})   |\n| (\"team204\" :team{name: \"Spurs\"}) | (\"player101\" :player{age: 36, name: \"Tony Parker\"})       |\n| (\"team204\" :team{name: \"Spurs\"}) | (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) |\n...\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_fixed-length_paths","title":"Match fixed-length paths","text":"<p>You can use the <code>:&lt;edge_type&gt;*&lt;hop&gt;</code> pattern to match a fixed-length path. <code>hop</code> must be a non-negative integer.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*2]-&gt;(v2) \\\n        RETURN DISTINCT v2 AS Friends;\n+-----------------------------------------------------------+\n| Friends                                                   |\n+-----------------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"})        |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})     |\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) |\n+-----------------------------------------------------------+\n</code></pre> <p>If <code>hop</code> is 0, the pattern will match the source vertex of the path.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) -[*0]-&gt; (v2) \\\n        RETURN v2;\n+----------------------------------------------------+\n| v2                                                 |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n</code></pre> <p>Note</p> <p>When you conditionally filter on multi-hop edges, such as <code>-[e:follow*2]-&gt;</code>, note that the <code>e</code> is a list of edges instead of a single edge. </p> <p>For example, the following statement is correct from the syntax point of view which may not get your expected query result, because the <code>e</code> is a list without the <code>.degree</code> property. </p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*2]-&gt;(v2) \\\n        WHERE e.degree &gt; 1 \\\n        RETURN DISTINCT v2 AS Friends;\n</code></pre> <p>The correct statement is as follows:</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*2]-&gt;(v2) \\\n        WHERE ALL(e_ in e WHERE e_.degree &gt; 0) \\\n        RETURN DISTINCT v2 AS Friends;\n</code></pre> <p>Further, the following statement is for filtering the properties of the first-hop edge in multi-hop edges:</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*2]-&gt;(v2) \\\n        WHERE e[0].degree &gt; 98 \\\n        RETURN DISTINCT v2 AS Friends;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_variable-length_paths","title":"Match variable-length paths","text":"<p>You can use the <code>:&lt;edge_type&gt;*[minHop]..&lt;maxHop&gt;</code> pattern to match variable-length paths.</p> Parameter Description <code>minHop</code> Optional. It represents the minimum length of the path. <code>minHop</code> must be a non-negative integer. The default value is 1. <code>maxHop</code> Required. It represents the maximum length of the path. <code>maxHop</code> must be a non-negative integer. It has no default value. <p>OpenCypher compatibility</p> <p>In openCypher, <code>maxHop</code> is optional and defaults to infinity. When no bounds are given, <code>..</code> can be omitted. However, in nGQL, <code>maxHop</code> is required. And <code>..</code> cannot be omitted.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*1..3]-&gt;(v2) \\\n        RETURN v2 AS Friends;\n+-----------------------------------------------------------+\n| Friends                                                   |\n+-----------------------------------------------------------+\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})     |\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"})        |\n...\n</code></pre> <p>You can use the <code>DISTINCT</code> keyword to aggregate duplicate results.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*1..3]-&gt;(v2:player) \\\n        RETURN DISTINCT v2 AS Friends, count(v2);\n+-----------------------------------------------------------+-----------+\n| Friends                                                   | count(v2) |\n+-----------------------------------------------------------+-----------+\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) | 1         |\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"})        | 4         |\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       | 3         |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})     | 3         |\n+-----------------------------------------------------------+-----------+\n</code></pre> <p>If <code>minHop</code> is <code>0</code>, the pattern will match the source vertex of the path. Compared to the preceding statement, the following example uses <code>0</code> as the <code>minHop</code>. So in the following result set, <code>\"Tim Duncan\"</code> is counted one more time than it is in the preceding result set because it is the source vertex.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow*0..3]-&gt;(v2:player) \\\n        RETURN DISTINCT v2 AS Friends, count(v2);\n+-----------------------------------------------------------+-----------+\n| Friends                                                   | count(v2) |\n+-----------------------------------------------------------+-----------+\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) | 1         |\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"})        | 5         |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})     | 3         |\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       | 3         |\n+-----------------------------------------------------------+-----------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#match_variable-length_paths_with_multiple_edge_types","title":"Match variable-length paths with multiple edge types","text":"<p>You can specify multiple edge types in a fixed-length or variable-length pattern. In this case, <code>hop</code>, <code>minHop</code>, and <code>maxHop</code> take effect on all edge types.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e:follow|serve*2]-&gt;(v2) \\\n        RETURN DISTINCT v2;\n+-----------------------------------------------------------+\n| v2                                                        |\n+-----------------------------------------------------------+\n| (\"team204\" :team{name: \"Spurs\"})                          |\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"})        |\n| (\"team215\" :team{name: \"Hornets\"})                        |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})     |\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) |\n+-----------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#common_retrieving_operations","title":"Common retrieving operations","text":""},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_vertex_or_edge_information","title":"Retrieve vertex or edge information","text":"<p>Use <code>RETURN {&lt;vertex_name&gt; | &lt;edge_name&gt;}</code> to retrieve all the information of a vertex or an edge.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN v;\n+----------------------------------------------------+\n| v                                                  |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n\nnebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[e]-&gt;(v2) \\\n        RETURN e;\n+-----------------------------------------------------------------------+\n| e                                                                     |\n+-----------------------------------------------------------------------+\n| [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}] |\n| [:follow \"player100\"-&gt;\"player101\" @0 {degree: 95}]                    |\n| [:follow \"player100\"-&gt;\"player125\" @0 {degree: 95}]                    |\n+-----------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_vids","title":"Retrieve VIDs","text":"<p>Use the <code>id()</code> function to retrieve VIDs.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN id(v);\n+-------------+\n| id(v)       |\n+-------------+\n| \"player100\" |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_tags","title":"Retrieve tags","text":"<p>Use the <code>labels()</code> function to retrieve the list of tags on a vertex.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN labels(v);\n+------------+\n| labels(v)  |\n+------------+\n| [\"player\"] |\n+------------+\n</code></pre> <p>To retrieve the nth element in the <code>labels(v)</code> list, use <code>labels(v)[n-1]</code>. The following example shows how to use <code>labels(v)[0]</code> to retrieve the first tag in the list.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN labels(v)[0];\n+--------------+\n| labels(v)[0] |\n+--------------+\n| \"player\"     |\n+--------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_a_single_property_on_a_vertex_or_an_edge","title":"Retrieve a single property on a vertex or an edge","text":"<p>Use <code>RETURN {&lt;vertex_name&gt; | &lt;edge_name&gt;}.&lt;property&gt;</code> to retrieve a single property.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN v.age;\n+-------+\n| v.age |\n+-------+\n| 42    |\n+-------+\n</code></pre> <p>Use <code>AS</code> to specify an alias for a property.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN v.age AS Age;\n+-----+\n| Age |\n+-----+\n| 42  |\n+-----+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_all_properties_on_a_vertex_or_an_edge","title":"Retrieve all properties on a vertex or an edge","text":"<p>Use the <code>properties()</code> function to retrieve all properties on a vertex or an edge.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[]-&gt;(v2) \\\n        RETURN properties(v2);\n+----------------------------------+\n| properties(v2)                   |\n+----------------------------------+\n| {name: \"Spurs\"}                  |\n| {age: 36, name: \"Tony Parker\"}   |\n| {age: 41, name: \"Manu Ginobili\"} |\n+----------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_edge_types","title":"Retrieve edge types","text":"<p>Use the <code>type()</code> function to retrieve the matched edge types.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[e]-&gt;() \\\n        RETURN DISTINCT type(e);\n+----------+\n| type(e)  |\n+----------+\n| \"serve\"  |\n| \"follow\" |\n+----------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_paths","title":"Retrieve paths","text":"<p>Use <code>RETURN &lt;path_name&gt;</code> to retrieve all the information of the matched paths.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[*3]-&gt;() \\\n        RETURN p;\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| p                                                                                                                                                                                                                                                                                                              |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:follow@0 {degree: 90}]-&gt;(\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"})-[:serve@0 {end_year: 2019, start_year: 2015}]-&gt;(\"team204\" :team{name: \"Spurs\"})&gt;         |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:follow@0 {degree: 90}]-&gt;(\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"})-[:serve@0 {end_year: 2015, start_year: 2006}]-&gt;(\"team203\" :team{name: \"Trail Blazers\"})&gt; |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:follow@0 {degree: 90}]-&gt;(\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"})-[:follow@0 {degree: 75}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})&gt;           |\n+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_vertices_in_a_path","title":"Retrieve vertices in a path","text":"<p>Use the <code>nodes()</code> function to retrieve all vertices in a path.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[]-&gt;(v2) \\\n        RETURN nodes(p);\n+---------------------------------------------------------------------------------------------------------------------+\n| nodes(p)                                                                                                            |\n+---------------------------------------------------------------------------------------------------------------------+\n| [(\"player100\" :star{} :player{age: 42, name: \"Tim Duncan\"}), (\"player204\" :team{name: \"Spurs\"})]                    |\n| [(\"player100\" :star{} :player{age: 42, name: \"Tim Duncan\"}), (\"player101\" :player{name: \"Tony Parker\", age: 36})]   |\n| [(\"player100\" :star{} :player{age: 42, name: \"Tim Duncan\"}), (\"player125\" :player{name: \"Manu Ginobili\", age: 41})] |\n+---------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_edges_in_a_path","title":"Retrieve edges in a path","text":"<p>Use the <code>relationships()</code> function to retrieve all edges in a path.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[]-&gt;(v2) \\\n        RETURN relationships(p);\n+-------------------------------------------------------------------------+\n| relationships(p)                                                        |\n+-------------------------------------------------------------------------+\n| [[:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}]] |\n| [[:follow \"player100\"-&gt;\"player101\" @0 {degree: 95}]]                    |\n| [[:follow \"player100\"-&gt;\"player125\" @0 {degree: 95}]]                    |\n+-------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/2.match/#retrieve_path_length","title":"Retrieve path length","text":"<p>Use the <code>length()</code> function to retrieve the length of a path.</p> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})-[*..2]-&gt;(v2) \\\n        RETURN p AS Paths, length(p) AS Length;\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n| Paths                                                                                                                                                                                                                  | Length |\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:serve@0 {end_year: 2016, start_year: 1997}]-&gt;(\"team204\" :team{name: \"Spurs\"})&gt;                                                                                   | 1      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})&gt;                                                                                     | 1      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player125\" :player{age: 41, name: \"Manu Ginobili\"})&gt;                                                                                   | 1      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:serve@0 {end_year: 2018, start_year: 1999}]-&gt;(\"team204\" :team{name: \"Spurs\"})&gt;     | 2      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:serve@0 {end_year: 2019, start_year: 2018}]-&gt;(\"team215\" :team{name: \"Hornets\"})&gt;   | 2      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:follow@0 {degree: 95}]-&gt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})&gt;        | 2      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:follow@0 {degree: 90}]-&gt;(\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"})&gt; | 2      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player101\" :player{age: 36, name: \"Tony Parker\"})-[:follow@0 {degree: 95}]-&gt;(\"player125\" :player{age: 41, name: \"Manu Ginobili\"})&gt;     | 2      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player125\" :player{age: 41, name: \"Manu Ginobili\"})-[:serve@0 {end_year: 2018, start_year: 2002}]-&gt;(\"team204\" :team{name: \"Spurs\"})&gt;   | 2      |\n| &lt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})-[:follow@0 {degree: 95}]-&gt;(\"player125\" :player{age: 41, name: \"Manu Ginobili\"})-[:follow@0 {degree: 90}]-&gt;(\"player100\" :player{age: 42, name: \"Tim Duncan\"})&gt;      | 2      |\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n</code></pre> <p>Performance</p> <p>In NebulaGraph, the performance and resource usage of the <code>MATCH</code> statement have been optimized. But we still recommend to use <code>GO</code>, <code>LOOKUP</code>, <code>|</code>, and <code>FETCH</code> instead of <code>MATCH</code> when high performance is required.</p>"},{"location":"3.ngql-guide/7.general-query-statements/3.go/","title":"GO","text":"<p><code>GO</code> traverses in a graph with specified filters and returns results.</p>"},{"location":"3.ngql-guide/7.general-query-statements/3.go/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>This topic applies to native nGQL only.</p>"},{"location":"3.ngql-guide/7.general-query-statements/3.go/#syntax","title":"Syntax","text":"<pre><code>GO [[&lt;M&gt; TO] &lt;N&gt; STEPS ] FROM &lt;vertex_list&gt;\nOVER &lt;edge_type_list&gt; [{REVERSELY | BIDIRECT}]\n[ WHERE &lt;conditions&gt;\u00a0]\n[YIELD\u00a0[DISTINCT] &lt;return_list&gt;]\n[{SAMPLE &lt;sample_list&gt; | LIMIT &lt;limit_list&gt;}]\n[| GROUP BY {col_name | expr | position} YIELD &lt;col_name&gt;]\n[| ORDER BY &lt;expression&gt; [{ASC | DESC}]]\n[| LIMIT [&lt;offset&gt;,] &lt;number_rows&gt;];\n\n&lt;vertex_list&gt; ::=\n    &lt;vid&gt; [, &lt;vid&gt; ...]\n\n&lt;edge_type_list&gt; ::=\n   edge_type [, edge_type ...]\n   | *\n\n&lt;return_list&gt; ::=\n    &lt;col_name&gt; [AS &lt;col_alias&gt;] [, &lt;col_name&gt; [AS &lt;col_alias&gt;] ...]\n</code></pre> <ul> <li> <p><code>&lt;N&gt; STEPS</code>: specifies the hop number. If not specified, the default value for <code>N</code> is <code>one</code>. When <code>N</code> is <code>zero</code>, NebulaGraph does not traverse any edges and returns nothing.</p> <p>Note</p> <p>The path type of the <code>GO</code> statement is <code>walk</code>, which means both vertices and edges can be repeatedly visited in graph traversal. For more information, see Path.</p> </li> </ul> <ul> <li><code>M TO N STEPS</code>: traverses <code>from M to N</code> hops. When <code>M</code> is <code>zero</code>, the output is the same as that of <code>M</code> is <code>one</code>. That is, the output of <code>GO 0 TO 2</code> and <code>GO 1 TO 2</code> are the same.</li> </ul> <ul> <li><code>&lt;vertex_list&gt;</code>: represents a list of vertex IDs separated by commas, or a special place holder <code>$-.id</code>. For more information, see Pipe.</li> </ul> <ul> <li><code>&lt;edge_type_list&gt;</code>: represents a list of edge types which the traversal can go through.</li> </ul> <ul> <li><code>REVERSELY | BIDIRECT</code>: defines the direction of the query. By default, the <code>GO</code> statement searches for outgoing edges of <code>&lt;vertex_list&gt;</code>. If <code>REVERSELY</code> is set, <code>GO</code> searches for incoming edges. If <code>BIDIRECT</code> is set, <code>GO</code> searches for edges of both directions.</li> </ul> <ul> <li> <p><code>WHERE &lt;expression&gt;</code>: specifies the traversal filters. You can use the <code>WHERE</code> clause for the source vertices, the edges, and the destination vertices. You can use it together with <code>AND</code>, <code>OR</code>, <code>NOT</code>, and <code>XOR</code>. For more information, see WHERE.</p> <p>Note</p> <p>There are some restrictions for the <code>WHERE</code> clause when you traverse along with multiple edge types. For example, <code>WHERE edge1.prop1 &gt; edge2.prop2</code> is not supported.</p> </li> </ul> <ul> <li><code>YIELD [DISTINCT] &lt;return_list&gt;</code>: defines the output to be returned. It is recommended to use the Schema function to fill in <code>&lt;return_list&gt;</code>. <code>src(edge)</code>, <code>dst(edge)</code>, <code>type(edge) )</code>, <code>rank(edge)</code>, <code>properties(edge)</code>, <code>id(vertex)</code>, and <code>properties(vertex)</code> are currently supported, while nested functions are not. For more information, see YIELD. When not specified, the destination vertex ID of the edge will be returned by default.</li> </ul> <ul> <li><code>SAMPLE &lt;sample_list&gt;</code>: takes samples from the result set. For more information, see SAMPLE.</li> </ul> <ul> <li><code>LIMIT &lt;limit_list&gt;</code>: limits the number of outputs during the traversal process. For more information, see LIMIT.</li> </ul> <ul> <li><code>GROUP BY</code>: groups the output into subgroups based on the value of the specified property. For more information, see GROUP BY. After grouping, you need to use <code>YIELD</code> again to define the output that needs to be returned.</li> </ul> <ul> <li> <p><code>ORDER BY</code>: sorts outputs with specified orders. For more information, see ORDER BY.</p> <p>Note</p> <p>When the sorting method is not specified, the output orders can be different for the same query.</p> </li> </ul> <ul> <li><code>LIMIT  [&lt;offset&gt;,] &lt;number_rows&gt;]</code>: limits the number of rows of the output. For more information, see LIMIT.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/3.go/#examples","title":"Examples","text":"<pre><code># The following example returns the teams that player 102 serves.\nnebula&gt;\u00a0GO FROM \"player102\" OVER serve;\n+------------+\n| serve._dst |\n+------------+\n| \"team203\"  |\n| \"team204\"  |\n+------------+\n</code></pre> <pre><code># The following example returns the friends of player 102 with 2 hops.\nnebula&gt; GO 2 STEPS FROM \"player102\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\n...\n</code></pre> <pre><code># The following example adds a filter for the traversal.\nnebula&gt;\u00a0GO FROM \"player100\", \"player102\" OVER serve \\\n        WHERE serve.start_year &gt; 1995 \\\n        YIELD DISTINCT properties($$).name AS team_name, properties(edge).start_year AS start_year, properties($^).name AS player_name;\n\n+-----------------+------------+---------------------+\n| team_name       | start_year | player_name         |\n+-----------------+------------+---------------------+\n| \"Spurs\"         | 1997       | \"Tim Duncan\"        |\n| \"Trail Blazers\" | 2006       | \"LaMarcus Aldridge\" |\n| \"Spurs\"         | 2015       | \"LaMarcus Aldridge\" |\n+-----------------+------------+---------------------+\n</code></pre> <pre><code># The following example traverses along with multiple edge types. If there is no value for a property, the output is UNKNOWN_PROP.\nnebula&gt; GO FROM \"player100\" OVER follow, serve \\\n        YIELD properties(edge).degree, properties(edge).start_year;\n+-------------------------+-----------------------------+\n| properties(EDGE).degree | properties(EDGE).start_year |\n+-------------------------+-----------------------------+\n| 95                      | UNKNOWN_PROP                |\n| 95                      | UNKNOWN_PROP                |\n| UNKNOWN_PROP            | 1997                        |\n+-------------------------+-----------------------------+\n</code></pre> <pre><code># The following example returns the neighbor vertices in the incoming direction of player 100.\nnebula&gt; GO FROM \"player100\" OVER follow REVERSELY \\\n        YIELD src(edge) AS destination;\n+-------------+\n| destination |\n+-------------+\n| \"player101\" |\n| \"player102\" |\n+-------------+\n...\n\n# This MATCH query shares the same semantics with the preceding GO query.\nnebula&gt; MATCH (v)&lt;-[e:follow]- (v2) WHERE id(v) == 'player100' \\\n        RETURN id(v2) AS destination;\n+-------------+\n| destination |\n+-------------+\n| \"player101\" |\n| \"player102\" |\n+-------------+\n...\n</code></pre> <pre><code># The following example retrieves the friends of player 100 and the teams that they serve.\nnebula&gt; GO FROM \"player100\" OVER follow REVERSELY \\\n        YIELD src(edge) AS id | \\\n        GO FROM $-.id OVER serve \\\n        WHERE $^.player.age &gt; 20 \\\n        YIELD properties($^).name AS FriendOf, properties($$).name AS Team;\n+---------------------+-----------------+\n| FriendOf            | Team            |\n+---------------------+-----------------+\n| \"Boris Diaw\"        | \"Spurs\"         |\n| \"Boris Diaw\"        | \"Jazz\"          |\n| \"Boris Diaw\"        | \"Suns\"          |\n...\n\n# This MATCH query shares the same semantics with the preceding GO query.\nnebula&gt; MATCH (v)&lt;-[e:follow]- (v2)-[e2:serve]-&gt;(v3)  \\\n        WHERE id(v) == 'player100' \\\n        RETURN v2.name AS FriendOf, v3.name AS Team;\n+---------------------+-----------------+\n| FriendOf            | Team            |\n+---------------------+-----------------+\n| \"Boris Diaw\"        | \"Spurs\"         |\n| \"Boris Diaw\"        | \"Jazz\"          |\n| \"Boris Diaw\"        | \"Suns\"          |\n...\n</code></pre> <pre><code># The following example retrieves the friends of player 100 within 1 or 2 hops.\nnebula&gt; GO 1 TO 2 STEPS FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS destination;\n+-------------+\n| destination |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n...\n\n# This MATCH query shares the same semantics with the preceding GO query.\nnebula&gt; MATCH (v) -[e:follow*1..2]-&gt;(v2) \\\n        WHERE id(v) == \"player100\" \\\n        RETURN id(v2) AS destination;\n+-------------+\n| destination |\n+-------------+\n| \"player100\" |\n| \"player102\" |\n...\n</code></pre> <pre><code># The following example the outputs according to age.\nnebula&gt; GO 2 STEPS FROM \"player100\" OVER follow \\\n        YIELD src(edge) AS src, dst(edge) AS dst, properties($$).age AS age \\\n        | GROUP BY $-.dst \\\n        YIELD $-.dst AS dst, collect_set($-.src) AS src, collect($-.age) AS age;\n+-------------+----------------------------+----------+\n| dst         | src                        | age      |\n+-------------+----------------------------+----------+\n| \"player125\" | [\"player101\"]              | [41]     |\n| \"player100\" | [\"player125\", \"player101\"] | [42, 42] |\n| \"player102\" | [\"player101\"]              | [33]     |\n+-------------+----------------------------+----------+\n</code></pre> <pre><code># The following example groups the outputs and restricts the number of rows of the outputs.\nnebula&gt; $a = GO FROM \"player100\" OVER follow YIELD src(edge) AS src, dst(edge) AS dst; \\\n        GO 2 STEPS FROM $a.dst OVER follow \\\n        YIELD $a.src AS src, $a.dst, src(edge), dst(edge) \\\n        | ORDER BY $-.src | OFFSET 1 LIMIT 2;\n+-------------+-------------+-------------+-------------+\n| src         | $a.dst      | follow._src | follow._dst |\n+-------------+-------------+-------------+-------------+\n| \"player100\" | \"player125\" | \"player100\" | \"player101\" |\n| \"player100\" | \"player101\" | \"player100\" | \"player125\" |\n+-------------+-------------+-------------+-------------+\n</code></pre> <pre><code># The following example determines if $$.player.name IS NOT EMPTY.\nnebula&gt; GO FROM \"player100\" OVER follow WHERE $$.player.name IS NOT EMPTY YIELD dst(edge);\n+-------------+\n| follow._dst |\n+-------------+\n| \"player125\" |\n| \"player101\" |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/","title":"FETCH","text":"<p>The <code>FETCH</code> statement retrieves the properties of the specified vertices or edges.</p>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#opencypher_compatibility","title":"OpenCypher Compatibility","text":"<p>This topic applies to native nGQL only.</p>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_vertex_properties","title":"Fetch vertex properties","text":""},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#syntax","title":"Syntax","text":"<pre><code>FETCH PROP ON {&lt;tag_name&gt;[, tag_name ...] | *}\n&lt;vid&gt; [, vid ...]\n[YIELD &lt;return_list&gt; [AS &lt;alias&gt;]];\n</code></pre> Parameter Description <code>tag_name</code> The name of the tag. <code>*</code> Represents all the tags in the current graph space. <code>vid</code> The vertex ID. <code>YIELD</code> Define the output to be returned. The defined properties and <code>VertexID</code> are returned. For details, see <code>YIELD</code>. If there is no <code>YIELD</code> clause, <code>vertices_</code> is returned by default, which contains all the information about the vertex. <code>AS</code> Set an alias."},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_vertex_properties_by_one_tag","title":"Fetch vertex properties by one tag","text":"<p>Specify a tag in the <code>FETCH</code> statement to fetch the vertex properties by that tag.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player100\";\n+----------------------------------------------------+\n| vertices_                                          |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_specific_properties_of_a_vertex","title":"Fetch specific properties of a vertex","text":"<p>Use a <code>YIELD</code> clause to specify the properties to be returned.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player100\" \\\n        YIELD properties(vertex).name AS name;\n+-------------+--------------+\n| VertexID    | name         |\n+-------------+--------------+\n| \"player100\" | \"Tim Duncan\" |\n+-------------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_properties_of_multiple_vertices","title":"Fetch properties of multiple vertices","text":"<p>Specify multiple VIDs (vertex IDs) to fetch properties of multiple vertices. Separate the VIDs with commas.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player101\", \"player102\", \"player103\";\n+-----------------------------------------------------------+\n| vertices_                                                 |\n+-----------------------------------------------------------+\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       |\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) |\n| (\"player103\" :player{age: 32, name: \"Rudy Gay\"})          |\n+-----------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_vertex_properties_by_multiple_tags","title":"Fetch vertex properties by multiple tags","text":"<p>Specify multiple tags in the <code>FETCH</code> statement to fetch the vertex properties by the tags. Separate the tags with commas.</p> <pre><code># The following example creates a new tag t1.\nnebula&gt; CREATE TAG IF NOT EXISTS t1(a string, b int);\n\n# The following example attaches t1 to the vertex \"player100\".\nnebula&gt; INSERT VERTEX t1(a, b) VALUE \"player100\":(\"Hello\", 100);\n\n# The following example fetches the properties of vertex \"player100\" by the tags player and t1.\nnebula&gt; FETCH PROP ON player, t1 \"player100\";\n+----------------------------------------------------------------------------+\n| vertices_                                                                  |\n+----------------------------------------------------------------------------+\n| (\"player100\" :t1{a: \"Hello\", b: 100} :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------------------------------+\n</code></pre> <p>You can combine multiple tags with multiple VIDs in a <code>FETCH</code> statement.</p> <pre><code>nebula&gt; FETCH PROP ON player, t1 \"player100\", \"player103\";\n+----------------------------------------------------------------------------+\n| vertices_                                                                  |\n+----------------------------------------------------------------------------+\n| (\"player100\" :t1{a: \"Hello\", b: 100} :player{age: 42, name: \"Tim Duncan\"}) |\n| (\"player103\" :player{age: 32, name: \"Rudy Gay\"})                           |\n+----------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_vertex_properties_by_all_tags","title":"Fetch vertex properties by all tags","text":"<p>Set an asterisk symbol <code>*</code> to fetch properties by all tags in the current graph space.</p> <pre><code>nebula&gt; FETCH PROP ON * \"player100\", \"player106\", \"team200\";\n+----------------------------------------------------------------------------+\n| vertices_                                                                  |\n+----------------------------------------------------------------------------+\n| (\"player106\" :player{age: 25, name: \"Kyle Anderson\"})                      |\n| (\"team200\" :team{name: \"Warriors\"})                                        |\n| (\"player100\" :t1{a: \"Hello\", b: 100} :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_edge_properties","title":"Fetch edge properties","text":""},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#syntax_1","title":"Syntax","text":"<pre><code>FETCH PROP ON &lt;edge_type&gt; &lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;] [, &lt;src_vid&gt; -&gt; &lt;dst_vid&gt; ...]\n[YIELD &lt;output&gt;]\n</code></pre> Parameter Description <code>edge_type</code> The name of the edge type. <code>src_vid</code> The VID of the source vertex. It specifies the start of an edge. <code>dst_vid</code> The VID of the destination vertex. It specifies the end of an edge. <code>rank</code> The rank of the edge. It is optional and defaults to <code>0</code>. It distinguishes an edge from other edges with the same edge type, source vertex, destination vertex, and rank. <code>YIELD</code> Define the output to be returned. The defined properties, <code>SrcVertexID</code>, <code>DstVertexID</code>, and <code>rank</code> are returned. For details, see <code>YIELD</code>. If there is no <code>YIELD</code> clause, <code>edges_</code> is returned by default, which contains all the information about the edge."},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_all_properties_of_an_edge","title":"Fetch all properties of an edge","text":"<p>The following statement fetches all the properties of the <code>serve</code> edge that connects vertex <code>\"player100\"</code> and vertex <code>\"team204\"</code>.</p> <pre><code>nebula&gt; FETCH PROP ON serve \"player100\" -&gt; \"team204\";\n+-----------------------------------------------------------------------+\n| edges_                                                                |\n+-----------------------------------------------------------------------+\n| [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}] |\n+-----------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_specific_properties_of_an_edge","title":"Fetch specific properties of an edge","text":"<p>Use a <code>YIELD</code> clause to fetch specific properties of an edge.</p> <pre><code>nebula&gt; FETCH PROP ON serve \"player100\" -&gt; \"team204\"    \\\n        YIELD properties(edge).start_year;\n+-------------+------------+-------------+-----------------------------+\n| serve._src  | serve._dst | serve._rank | properties(EDGE).start_year |\n+-------------+------------+-------------+-----------------------------+\n| \"player100\" | \"team204\"  | 0           | 1997                        |\n+-------------+------------+-------------+-----------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_properties_of_multiple_edges","title":"Fetch properties of multiple edges","text":"<p>Specify multiple edge patterns (<code>&lt;src_vid&gt; -&gt; &lt;dst_vid&gt;[@&lt;rank&gt;]</code>) to fetch properties of multiple edges. Separate the edge patterns with commas.</p> <pre><code>nebula&gt; FETCH PROP ON serve \"player100\" -&gt; \"team204\", \"player133\" -&gt; \"team202\";\n+-----------------------------------------------------------------------+\n| edges_                                                                |\n+-----------------------------------------------------------------------+\n| [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}] |\n| [:serve \"player133\"-&gt;\"team202\" @0 {end_year: 2011, start_year: 2002}] |\n+-----------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#fetch_properties_based_on_edge_rank","title":"Fetch properties based on edge rank","text":"<p>If there are multiple edges with the same edge type, source vertex, and destination vertex, you can specify the rank to fetch the properties on the correct edge.</p> <pre><code># The following example inserts edges with different ranks and property values.\nnebula&gt; insert edge serve(start_year,end_year) \\\n        values \"player100\"-&gt;\"team204\"@1:(1998, 2017);\n\nnebula&gt; insert edge serve(start_year,end_year) \\\n        values \"player100\"-&gt;\"team204\"@2:(1990, 2018);\n\n# By default, the FETCH statement returns the edge whose rank is 0.\nnebula&gt; FETCH PROP ON serve \"player100\" -&gt; \"team204\";\n+-----------------------------------------------------------------------+\n| edges_                                                                |\n+-----------------------------------------------------------------------+\n| [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}] |\n+-----------------------------------------------------------------------+\n\n# To fetch on an edge whose rank is not 0, set its rank in the FETCH statement.\nnebula&gt; FETCH PROP ON serve \"player100\" -&gt; \"team204\"@1;\n+-----------------------------------------------------------------------+\n| edges_                                                                |\n+-----------------------------------------------------------------------+\n| [:serve \"player100\"-&gt;\"team204\" @1 {end_year: 2017, start_year: 1998}] |\n+-----------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/4.fetch/#use_fetch_in_composite_queries","title":"Use FETCH in composite queries","text":"<p>A common way to use <code>FETCH</code> is to combine it with native nGQL such as <code>GO</code>.</p> <p>The following statement returns the <code>degree</code> values of the <code>follow</code> edges that start from vertex <code>\"player101\"</code>.</p> <pre><code>nebula&gt; GO FROM \"player101\" OVER follow \\\n        YIELD src(edge) AS s, dst(edge) AS d \\\n        | FETCH PROP ON follow $-.s -&gt; $-.d \\\n        YIELD properties(edge).degree;\n+-------------+-------------+--------------+-------------------------+\n| follow._src | follow._dst | follow._rank | properties(EDGE).degree |\n+-------------+-------------+--------------+-------------------------+\n| \"player101\" | \"player100\" | 0            | 95                      |\n| \"player101\" | \"player102\" | 0            | 90                      |\n| \"player101\" | \"player125\" | 0            | 95                      |\n+-------------+-------------+--------------+-------------------------+\n</code></pre> <p>Or you can use user-defined variables to construct similar queries.</p> <pre><code>nebula&gt; $var = GO FROM \"player101\" OVER follow \\\n        YIELD src(edge) AS s, dst(edge) AS d; \\\n        FETCH PROP ON follow $var.s -&gt; $var.d \\\n        YIELD properties(edge).degree;\n+-------------+-------------+--------------+-------------------------+\n| follow._src | follow._dst | follow._rank | properties(EDGE).degree |\n+-------------+-------------+--------------+-------------------------+\n| \"player101\" | \"player100\" | 0            | 95                      |\n| \"player101\" | \"player102\" | 0            | 90                      |\n| \"player101\" | \"player125\" | 0            | 95                      |\n+-------------+-------------+--------------+-------------------------+\n</code></pre> <p>For more information about composite queries, see Composite queries (clause structure).</p>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/","title":"LOOKUP","text":"<p>The <code>LOOKUP</code> statement traverses data based on indexes. You can use <code>LOOKUP</code> for the following purposes:</p> <ul> <li>Search for the specific data based on conditions defined by the <code>WHERE</code> clause.</li> </ul> <ul> <li>List vertices with a tag: retrieve the VID of all vertices with a tag.</li> </ul> <ul> <li>List edges with an edge type: retrieve the source vertex IDs, destination vertex IDs, and ranks of all edges with an edge type.</li> </ul> <ul> <li>Count the number of vertices or edges with a tag or an edge type.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>This topic applies to native nGQL only.</p>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#precautions","title":"Precautions","text":"<ul> <li>Correct use of indexes can speed up queries, but indexes can dramatically reduce the write performance. The performance reduction can be 90% or even more. DO NOT use indexes in production environments unless you are fully aware of their influences on your service.</li> </ul> <ul> <li> <p>If the specified property is not indexed when using the <code>LOOKUP</code> statement, NebulaGraph randomly selects one of the available indexes.</p> <p>For example, the tag <code>player</code> has two properties, <code>name</code> and <code>age</code>. Both the tag <code>player</code> itself and the property <code>name</code> have indexes, but the property <code>age</code> has no indexes. When running <code>LOOKUP ON player WHERE player.age == 36 YIELD player.name;</code>, NebulaGraph randomly uses one of the indexes of the tag <code>player</code> and the property <code>name</code>.</p> <p>Legacy version compatibility</p> <p>In the previous releases, if the specified property is not indexed when using the <code>LOOKUP</code> statement, NebulaGraph reports an error and does not use other indexes.</p> </li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#prerequisites","title":"Prerequisites","text":"<p>Before using the <code>LOOKUP</code> statement, make sure that at least one index is created. If there are already related vertices, edges, or properties before an index is created, the user must rebuild the index after creating the index to make it valid.</p>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#syntax","title":"Syntax","text":"<pre><code>LOOKUP ON {&lt;vertex_tag&gt; | &lt;edge_type&gt;}\n[WHERE &lt;expression&gt; [AND &lt;expression&gt; ...]]\n[YIELD &lt;return_list&gt; [AS &lt;alias&gt;]];\n\n&lt;return_list&gt;\n    &lt;prop_name&gt; [AS &lt;col_alias&gt;] [, &lt;prop_name&gt; [AS &lt;prop_alias&gt;] ...];\n</code></pre> <ul> <li><code>WHERE &lt;expression&gt;</code>: filters data with specified conditions. Both <code>AND</code> and <code>OR</code> are supported between different expressions. For more information, see WHERE.</li> </ul> <ul> <li> <p><code>YIELD</code>: Define the output to be returned.</p> <ul> <li>When you <code>LOOKUP</code> a Tag, the defined properties and <code>VertexID</code> are returned. If there is no <code>YIELD</code> clause, <code>VertexID</code> is returned.</li> <li>When you <code>LOOKUP</code> an Edge type, the defined properties, <code>SrcVertexID</code>, <code>DstVertexID</code>, and <code>rank</code> are returned. If there is no <code>YIELD</code> clause, <code>SrcVertexID</code>, <code>DstVertexID</code>, and <code>rank</code> are returned.</li> </ul> </li> </ul> <ul> <li><code>AS</code>: Set an alias.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#limitations_of_using_where_in_lookup","title":"Limitations of using <code>WHERE</code> in <code>LOOKUP</code>","text":"<p>The <code>WHERE</code> clause in a <code>LOOKUP</code> statement does not support the following operations:</p> <ul> <li><code>$-</code> and <code>$^</code>.</li> <li>In relational expressions, operators are not supported to have field names on both sides, such as <code>tagName.prop1&gt; tagName.prop2</code>.</li> <li>Nested AliasProp expressions in operation expressions and function expressions are not supported.</li> <li>The <code>XOR</code> and <code>NOT</code> operations are not supported.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#retrieve_vertices","title":"Retrieve vertices","text":"<p>The following example returns vertices whose <code>name</code> is <code>Tony Parker</code> and the tag is <code>player</code>.</p> <pre><code>nebula&gt; CREATE TAG INDEX IF NOT EXISTS index_player ON player(name(30), age);\n\nnebula&gt; REBUILD TAG INDEX index_player;\n+------------+\n| New Job Id |\n+------------+\n| 15         |\n+------------+\n\nnebula&gt; LOOKUP ON player \\\n        WHERE player.name == \"Tony Parker\";\n+-------------+\n| VertexID    |\n+-------------+\n| \"player101\" |\n+-------------+\n\nnebula&gt; LOOKUP ON player \\\n        WHERE player.name == \"Tony Parker\" \\\n        YIELD properties(vertex).name AS name, properties(vertex).age AS age;\n+-------------+---------------+-----+\n| VertexID    | name          | age |\n+-------------+---------------+-----+\n| \"player101\" | \"Tony Parker\" | 36  |\n+-------------+---------------+-----+\n\nnebula&gt; LOOKUP ON player \\\n        WHERE player.age  &gt; 45;\n+-------------+\n| VertexID    |\n+-------------+\n| \"player140\" |\n| \"player144\" |\n+-------------+\n\nnebula&gt; LOOKUP ON player \\\n        WHERE player.name STARTS WITH \"B\" \\\n        AND player.age IN [22,30] \\\n        YIELD properties(vertex).name, properties(vertex).age;\n+-------------+-------------------------+------------------------+\n| VertexID    | properties(VERTEX).name | properties(VERTEX).age |\n+-------------+-------------------------+------------------------+\n| \"player134\" | \"Blake Griffin\"         | 30                     |\n| \"player149\" | \"Ben Simmons\"           | 22                     |\n+-------------+-------------------------+------------------------+\n\nnebula&gt; LOOKUP ON player \\\n        WHERE player.name == \"Kobe Bryant\"\\\n        YIELD properties(vertex).name AS name |\\\n        GO FROM $-.VertexID OVER serve \\\n        YIELD $-.name, properties(edge).start_year, properties(edge).end_year, properties($$).name;\n+---------------+-----------------------------+---------------------------+---------------------+\n| $-.name       | properties(EDGE).start_year | properties(EDGE).end_year | properties($$).name |\n+---------------+-----------------------------+---------------------------+---------------------+\n| \"Kobe Bryant\" | 1996                        | 2016                      | \"Lakers\"            |\n+---------------+-----------------------------+---------------------------+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#retrieve_edges","title":"Retrieve edges","text":"<p>The following example returns edges whose <code>degree</code> is <code>90</code> and the edge type is <code>follow</code>.</p> <pre><code>nebula&gt; CREATE EDGE INDEX IF NOT EXISTS index_follow ON follow(degree);\n\nnebula&gt; REBUILD EDGE INDEX index_follow;\n+------------+\n| New Job Id |\n+------------+\n| 62         |\n+------------+\n\nnebula&gt; LOOKUP ON follow \\\n        WHERE follow.degree == 90;\n+-------------+-------------+---------+\n| SrcVID      | DstVID      | Ranking |\n+-------------+-------------+---------+\n| \"player150\" | \"player143\" | 0       |\n| \"player150\" | \"player137\" | 0       |\n| \"player148\" | \"player136\" | 0       |\n...\n\nnebula&gt; LOOKUP ON follow \\\n        WHERE follow.degree == 90 \\\n        YIELD properties(edge).degree;\n+-------------+-------------+---------+-------------------------+\n| SrcVID      | DstVID      | Ranking | properties(EDGE).degree |\n+-------------+-------------+---------+-------------------------+\n| \"player150\" | \"player143\" | 0       | 90                      |\n| \"player150\" | \"player137\" | 0       | 90                      |\n| \"player148\" | \"player136\" | 0       | 90                      |\n...\n\nnebula&gt; LOOKUP ON follow \\\n        WHERE follow.degree == 60 \\\n        YIELD properties(edge).degree AS Degree |\\\n        GO FROM $-.DstVID OVER serve \\\n        YIELD $-.DstVID, properties(edge).start_year, properties(edge).end_year, properties($$).name;\n+-------------+------------------+----------------+--------------+\n| $-.DstVID   | serve.start_year | serve.end_year | $$.team.name |\n+-------------+------------------+----------------+--------------+\n| \"player105\" | 2010             | 2018           | \"Spurs\"      |\n| \"player105\" | 2009             | 2010           | \"Cavaliers\"  |\n| \"player105\" | 2018             | 2019           | \"Raptors\"    |\n+-------------+------------------+----------------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#list_vertices_or_edges_with_a_tag_or_an_edge_type","title":"List vertices or edges with a tag or an edge type","text":"<p>To list vertices or edges with a tag or an edge type, at least one index must exist on the tag, the edge type, or its property.</p> <p>For example, if there is a <code>player</code> tag with a <code>name</code> property and an <code>age</code> property, to retrieve the VID of all vertices tagged with <code>player</code>, there has to be an index on the <code>player</code> tag itself, the <code>name</code> property, or the <code>age</code> property.</p> <ul> <li>The following example shows how to retrieve the VID of all vertices tagged with <code>player</code>.<pre><code>nebula&gt; CREATE TAG IF NOT EXISTS player(name string,age int);\n\nnebula&gt; CREATE TAG INDEX IF NOT EXISTS player_index on player();\n\nnebula&gt; REBUILD TAG INDEX player_index;\n+------------+\n| New Job Id |\n+------------+\n| 66         |\n+------------+\n\nnebula&gt; INSERT VERTEX player(name,age) \\\n        VALUES \"player100\":(\"Tim Duncan\", 42), \"player101\":(\"Tony Parker\", 36);\n\nThe following statement retrieves the VID of all vertices with the tag `player`. It is similar to `MATCH (n:player) RETURN id(n) /*, n */`.\n\nnebula&gt; LOOKUP ON player;\n+-------------+\n|  VertexID   |\n+-------------+\n| \"player100\" |\n| \"player101\" |\n+-------------+\n</code></pre> </li> </ul> <ul> <li>The following example shows how to retrieve the source Vertex IDs, destination vertex IDs, and ranks of all edges of the <code>follow</code> edge type.<pre><code>nebula&gt; CREATE EDGE IF NOT EXISTS follow(degree int);\n\nnebula&gt; CREATE EDGE INDEX IF NOT EXISTS follow_index on follow();\n\nnebula&gt; REBUILD EDGE INDEX follow_index;\n+------------+\n| New Job Id |\n+------------+\n| 88         |\n+------------+\n\nnebula&gt; INSERT EDGE follow(degree) \\\n        VALUES \"player100\"-&gt;\"player101\":(95);\n\nThe following statement retrieves all edges with the edge type `follow`. It is similar to `MATCH (s)-[e:follow]-&gt;(d) RETURN id(s), rank(e), id(d) /*, type(e) */`.\n\nnebula)&gt; LOOKUP ON follow;\n+-------------+-------------+---------+\n| SrcVID      | DstVID      | Ranking |\n+-------------+-------------+---------+\n| \"player100\" | \"player101\" | 0       |\n+-------------+-------------+---------+\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/5.lookup/#count_the_numbers_of_vertices_or_edges","title":"Count the numbers of vertices or edges","text":"<p>The following example shows how to count the number of vertices tagged with <code>player</code> and edges of the <code>follow</code> edge type.</p> <pre><code>nebula&gt; LOOKUP ON player |\\\n        YIELD COUNT(*) AS Player_Number;\n+---------------+\n| Player_Number |\n+---------------+\n| 51            |\n+---------------+\n\nnebula&gt; LOOKUP ON follow | \\\n        YIELD COUNT(*) AS Follow_Number;\n+---------------+\n| Follow_Number |\n+---------------+\n| 81            |\n+---------------+\n</code></pre> <p>Note</p> <p>You can also use <code>SHOW STATS</code> to count the numbers of vertices or edges.</p>"},{"location":"3.ngql-guide/7.general-query-statements/7.unwind/","title":"UNWIND","text":"<p>The <code>UNWIND</code> statement splits a list into separated rows.</p> <p><code>UNWIND</code> can function as an individual statement or a clause in a statement.</p>"},{"location":"3.ngql-guide/7.general-query-statements/7.unwind/#syntax","title":"Syntax","text":"<pre><code>UNWIND &lt;list&gt; AS &lt;alias&gt; &lt;RETURN clause&gt;;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/7.unwind/#split_a_list","title":"Split a list","text":"<p>The following example splits the list <code>[1,2,3]</code> into three rows.</p> <pre><code>nebula&gt; UNWIND [1,2,3] AS n RETURN n;\n+---+\n| n |\n+---+\n| 1 |\n| 2 |\n| 3 |\n+---+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/7.unwind/#return_a_list_with_distinct_items","title":"Return a list with distinct items","text":"<p>Use <code>WITH DISTINCT</code> in the <code>UNWIND</code> statement to return a list with distinct items.</p>"},{"location":"3.ngql-guide/7.general-query-statements/7.unwind/#example_1","title":"Example 1","text":"<p>The following statement:</p> <ol> <li>Splits the list <code>[1,1,2,2,3,3]</code> into rows.</li> <li>Removes duplicated rows.</li> <li>Sorts the rows.</li> <li>Transforms the rows to a list.</li> </ol> <pre><code>nebula&gt; WITH [1,1,2,2,3,3] AS n \\\n        UNWIND n AS r \\\n        WITH DISTINCT r AS r \\\n        ORDER BY r \\\n        RETURN collect(r);\n+------------+\n| collect(r) |\n+------------+\n| [1, 2, 3]  |\n+------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/7.unwind/#example_2","title":"Example 2","text":"<p>The following statement:</p> <ol> <li>Outputs the vertices on the matched path into a list.</li> <li>Splits the list into rows.</li> <li>Removes duplicated rows.</li> <li>Transforms the rows to a list.</li> </ol> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})--(v2) \\\n        WITH nodes(p) AS n \\\n        UNWIND n AS r \\\n        WITH DISTINCT r AS r \\\n        RETURN collect(r);\n+----------------------------------------------------------------------------------------------------------------------+\n| collect(r)                                                                                                           |\n+----------------------------------------------------------------------------------------------------------------------+\n| [(\"player100\" :player{age: 42, name: \"Tim Duncan\"}), (\"player101\" :player{age: 36, name: \"Tony Parker\"}),\n(\"team204\" :team{name: \"Spurs\"}), (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}),\n(\"player125\" :player{age: 41, name: \"Manu Ginobili\"}), (\"player104\" :player{age: 32, name: \"Marco Belinelli\"}),\n(\"player144\" :player{age: 47, name: \"Shaquile O'Neal\"}), (\"player105\" :player{age: 31, name: \"Danny Green\"}),\n(\"player113\" :player{age: 29, name: \"Dejounte Murray\"}), (\"player107\" :player{age: 32, name: \"Aron Baynes\"}),\n(\"player109\" :player{age: 34, name: \"Tiago Splitter\"}), (\"player108\" :player{age: 36, name: \"Boris Diaw\"})] |\n+----------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/1.show-charset/","title":"SHOW CHARSET","text":"<p>The <code>SHOW CHARSET</code> statement shows the available character sets.</p> <p>Currently available types are <code>utf8</code> and <code>utf8mb4</code>. The default charset type is <code>utf8</code>. NebulaGraph extends the <code>uft8</code> to support four-byte characters. Therefore <code>utf8</code> and <code>utf8mb4</code> are equivalent.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/1.show-charset/#syntax","title":"Syntax","text":"<pre><code>SHOW CHARSET;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/1.show-charset/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW CHARSET;\n+---------+-----------------+-------------------+--------+\n| Charset | Description     | Default collation | Maxlen |\n+---------+-----------------+-------------------+--------+\n| \"utf8\"  | \"UTF-8 Unicode\" | \"utf8_bin\"        | 4      |\n+---------+-----------------+-------------------+--------+\n</code></pre> <p>| Parameter           | Description                                                  | |---------------------+--------------------------------------------------------------| | <code>Charset</code>           | The name of the character set.                               | | <code>Description</code>       | The description of the character set.                        | | <code>Default collation</code> | The default collation of the character set.                  | | <code>Maxlen</code>            | The maximum number of bytes required to store one character. |</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/10.show-roles/","title":"SHOW ROLES","text":"<p>The <code>SHOW ROLES</code> statement shows the roles that are assigned to a user account.</p> <p>The return message differs according to the role of the user who is running this statement:</p> <ul> <li>If the user is a <code>GOD</code> or <code>ADMIN</code> and is granted access to the specified graph space, NebulaGraph shows all roles in this graph space except for <code>GOD</code>.</li> </ul> <ul> <li>If the user is a <code>DBA</code>, <code>USER</code>, or <code>GUEST</code> and is granted access to the specified graph space, NebulaGraph shows the user's own role in this graph space.</li> </ul> <ul> <li>If the user does not have access to the specified graph space, NebulaGraph returns <code>PermissionError</code>.</li> </ul> <p>For more information about roles, see Roles and privileges.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/10.show-roles/#syntax","title":"Syntax","text":"<pre><code>SHOW ROLES IN &lt;space_name&gt;;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/10.show-roles/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW ROLES in basketballplayer;\n+---------+-----------+\n| Account | Role Type |\n+---------+-----------+\n| \"user1\" | \"ADMIN\"   |\n+---------+-----------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/11.show-snapshots/","title":"SHOW SNAPSHOTS","text":"<p>The <code>SHOW SNAPSHOTS</code> statement shows the information of all the snapshots.</p> <p>For how to create a snapshot and backup data, see Snapshot.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/11.show-snapshots/#role_requirement","title":"Role requirement","text":"<p>Only the <code>root</code> user who has the <code>GOD</code> role can use the <code>SHOW SNAPSHOTS</code> statement.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/11.show-snapshots/#syntax","title":"Syntax","text":"<pre><code>SHOW SNAPSHOTS;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/11.show-snapshots/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW SNAPSHOTS;\n+--------------------------------+---------+-----------------------------------------------------+\n| Name                           | Status  | Hosts                                               |\n+--------------------------------+---------+-----------------------------------------------------+\n| \"SNAPSHOT_2020_12_16_11_13_55\" | \"VALID\" | \"storaged0:9779, storaged1:9779, storaged2:9779\"    |\n| \"SNAPSHOT_2020_12_16_11_14_10\" | \"VALID\" | \"storaged0:9779, storaged1:9779, storaged2:9779\"    |\n+--------------------------------+---------+-----------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/12.show-spaces/","title":"SHOW SPACES","text":"<p>The <code>SHOW SPACES</code> statement shows existing graph spaces in NebulaGraph.</p> <p>For how to create a graph space, see CREATE SPACE.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/12.show-spaces/#syntax","title":"Syntax","text":"<pre><code>SHOW SPACES;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/12.show-spaces/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW SPACES;\n+---------------------+\n| Name                |\n+---------------------+\n| \"docs\"              |\n| \"basketballplayer\"  |\n+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/14.show-stats/","title":"SHOW STATS","text":"<p>The <code>SHOW STATS</code> statement shows the statistics of the graph space collected by the latest <code>STATS</code> job.</p> <p>The statistics include the following information:</p> <ul> <li>The number of vertices in the graph space</li> <li>The number of edges in the graph space</li> <li>The number of vertices of each tag</li> <li>The number of edges of each edge type</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/14.show-stats/#prerequisites","title":"Prerequisites","text":"<p>You have to run the <code>SUBMIT JOB STATS</code> statement in the graph space where you want to collect statistics. For more information, see SUBMIT JOB STATS.</p> <p>Caution</p> <p>The result of the <code>SHOW STATS</code> statement is based on the last executed <code>SUBMIT JOB STATS</code> statement. If you want to update the result, run <code>SUBMIT JOB STATS</code> again. Otherwise the statistics will be wrong.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/14.show-stats/#syntax","title":"Syntax","text":"<pre><code>SHOW STATS;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/14.show-stats/#examples","title":"Examples","text":"<pre><code># Choose a graph space.\nnebula&gt; USE basketballplayer;\n\n# Start SUBMIT JOB STATS.\nnebula&gt; SUBMIT JOB STATS;\n+------------+\n| New Job Id |\n+------------+\n| 98         |\n+------------+\n\n# Make sure the job executes successfully.\nnebula&gt; SHOW JOB 98;\n+----------------+---------------+------------+----------------------------+----------------------------+\n| Job Id(TaskId) | Command(Dest) | Status     | Start Time                 | Stop Time                  |\n+----------------+---------------+------------+----------------------------+----------------------------+\n| 98             | \"STATS\"       | \"FINISHED\" | 2021-11-01T09:33:21.000000 | 2021-11-01T09:33:21.000000 |\n| 0              | \"storaged2\"   | \"FINISHED\" | 2021-11-01T09:33:21.000000 | 2021-11-01T09:33:21.000000 |\n| 1              | \"storaged0\"   | \"FINISHED\" | 2021-11-01T09:33:21.000000 | 2021-11-01T09:33:21.000000 |\n| 2              | \"storaged1\"   | \"FINISHED\" | 2021-11-01T09:33:21.000000 | 2021-11-01T09:33:21.000000 |\n+----------------+---------------+------------+----------------------------+----------------------------+\n\n# Show the statistics of the graph space.\nnebula&gt; SHOW STATS;\n+---------+------------+-------+\n| Type    | Name       | Count |\n+---------+------------+-------+\n| \"Tag\"   | \"player\"   | 51    |\n| \"Tag\"   | \"team\"     | 30    |\n| \"Edge\"  | \"follow\"   | 81    |\n| \"Edge\"  | \"serve\"    | 152   |\n| \"Space\" | \"vertices\" | 81    |\n| \"Space\" | \"edges\"    | 233   |\n+---------+------------+-------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/15.show-tags-edges/","title":"SHOW TAGS/EDGES","text":"<p>The <code>SHOW TAGS</code> statement shows all the tags in the current graph space.</p> <p>The <code>SHOW EDGES</code> statement shows all the edge types in the current graph space.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/15.show-tags-edges/#syntax","title":"Syntax","text":"<pre><code>SHOW {TAGS | EDGES};\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/15.show-tags-edges/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW TAGS;\n+----------+\n| Name     |\n+----------+\n| \"player\" |\n| \"star\"   |\n| \"team\"   |\n+----------+\n\nnebula&gt; SHOW EDGES;\n+----------+\n| Name     |\n+----------+\n| \"follow\" |\n| \"serve\"  |\n+----------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/16.show-users/","title":"SHOW USERS","text":"<p>The <code>SHOW USERS</code> statement shows the user information.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/16.show-users/#role_requirement","title":"Role requirement","text":"<p>Only the <code>root</code> user who has the <code>GOD</code> role can use the <code>SHOW USERS</code> statement.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/16.show-users/#syntax","title":"Syntax","text":"<pre><code>SHOW USERS;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/16.show-users/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW USERS;\n+---------+\n| Account |\n+---------+\n| \"root\"  |\n| \"user1\" |\n+---------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/17.show-sessions/","title":"SHOW SESSIONS","text":"<p>The <code>SHOW SESSIONS</code> statement shows the information of all the sessions. It can also show a specified session with its ID.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/17.show-sessions/#precautions","title":"Precautions","text":"<p>When you log in to the database using Nebula Console, a session will be created. The client will execute the API <code>release</code> to release the session and clear the session information when you run <code>exit</code> after the operation ends.</p> <p>If you exit the database in unexpected ways with the <code>session_idle_timeout_secs</code> in nebula-graphd.conf undetermined, the session will not be released automatically.</p> <p>For those sessions that are not automatically released, you need to delete them manually (TODO: coding).</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/17.show-sessions/#syntax","title":"Syntax","text":"<pre><code>SHOW SESSIONS;\nSHOW SESSION &lt;Session_Id&gt;;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/17.show-sessions/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW SESSIONS;\n+------------------+----------+--------------------+----------------------------+----------------------------+------------------+----------+--------------------+\n| SessionId        | UserName | SpaceName          | CreateTime                 | UpdateTime                 | GraphAddr        | Timezone | ClientIp           |\n+------------------+----------+--------------------+----------------------------+----------------------------+------------------+----------+--------------------+\n| 1635128818397714 | \"root\"   | \"test\"             | 2021-10-25T02:26:58.397714 | 2021-10-25T08:31:31.846846 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1635254859271703 | \"root\"   | \"basketballplayer\" | 2021-10-26T13:27:39.271703 | 2021-10-26T13:51:38.277704 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1634871229727322 | \"root\"   | \"basketballplayer\" | 2021-10-22T02:53:49.727322 | 2021-10-22T02:53:56.564001 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1635750725840229 | \"root\"   | \"basketballplayer\" | 2021-11-01T07:12:05.840229 | 2021-11-01T09:42:36.883617 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1635299224732060 | \"root\"   | \"basketballplayer\" | 2021-10-27T01:47:04.732060 | 2021-10-27T09:04:31.741126 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1634628999765689 | \"root\"   | \"\"                 | 2021-10-19T07:36:39.765689 | 2021-10-19T07:36:39.768064 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1634886296595136 | \"root\"   | \"basketballplayer\" | 2021-10-22T07:04:56.595136 | 2021-10-22T09:48:20.299364 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1634629179882439 | \"root\"   | \"basketballplayer\" | 2021-10-19T07:39:39.882439 | 2021-10-19T09:34:52.153145 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1635246158961634 | \"root\"   | \"basketballplayer\" | 2021-10-26T11:02:38.961634 | 2021-10-26T11:02:51.250897 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n| 1634785346839017 | \"root\"   | \"basketballplayer\" | 2021-10-21T03:02:26.839017 | 2021-10-21T11:07:40.911329 | \"127.0.0.1:9669\" | 0        | \"::ffff:127.0.0.1\" |\n+------------------+----------+--------------------+----------------------------+----------------------------+------------------+----------+--------------------+\n\nnebula&gt; SHOW SESSION 1635254859271703;\n+--------------+----------------------------+\n| VariableName | Value                      |\n+--------------+----------------------------+\n| \"SessionID\"  | 1635254859271703           |\n| \"UserName\"   | \"root\"                     |\n| \"SpaceName\"  | \"basketballplayer\"         |\n| \"CreateTime\" | 2021-10-26T13:27:39.271703 |\n| \"UpdateTime\" | 2021-10-26T13:51:38.277704 |\n| \"GraphAddr\"  | \"127.0.0.1:9669\"           |\n| \"Timezone\"   | 0                          |\n| \"ClientIp\"   | \"::ffff:127.0.0.1\"         |\n+--------------+----------------------------+\n</code></pre> Parameter Description <code>SessionId</code> The session ID, namely the identifier of a session. <code>UserName</code> The username in a session. <code>SpaceName</code> The name of the graph space that the user uses currently. It is null (<code>\"\"</code>) when you first log in because there is no specified graph space. <code>CreateTime</code> The time when the session is created, namely the time when the user logs in. The time zone is specified by <code>timezone_name</code> in the configuration file. <code>UpdateTime</code> The system will update the time when there is an operation. The time zone is specified by <code>timezone_name</code> in the configuration file. <code>GraphAddr</code> The IP address and port of the Graph server that hosts the session. <code>Timezone</code> A reserved parameter that has no specified meaning for now. <code>ClientIp</code> The IP address of the client."},{"location":"3.ngql-guide/7.general-query-statements/6.show/18.show-queries/","title":"SHOW QUERIES","text":"<p>The <code>SHOW QUERIES</code> statement shows the information of working queries in the current session.</p> <p>Note</p> <p>To terminate queries, see Kill Query.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/18.show-queries/#precautions","title":"Precautions","text":"<ul> <li>The <code>SHOW QUERIES</code> statement gets the status of queries in the current session from the local cache with almost no latency.</li> </ul> <ul> <li>The <code>SHOW ALL QUERIES</code> statement gets the information of queries in all the sessions from the Meta Service. The information will be synchronized to the Meta Service according to the interval defined by <code>session_reclaim_interval_secs</code>. Therefore the information that you get from the client may belong to the last synchronization interval.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/18.show-queries/#syntax","title":"Syntax","text":"<pre><code>SHOW [ALL] QUERIES;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/18.show-queries/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW QUERIES;\n+------------------+-----------------+--------+----------------------+----------------------------+----------------+-----------+-----------------+\n| SessionID        | ExecutionPlanID | User   | Host                 | StartTime                  | DurationInUSec | Status    | Query           |\n+------------------+-----------------+--------+----------------------+----------------------------+----------------+-----------+-----------------+\n| 1625463842921750 | 46              | \"root\" | \"\"192.168.x.x\":9669\" | 2021-07-05T05:44:19.502903 | 0              | \"RUNNING\" | \"SHOW QUERIES;\" |\n+------------------+-----------------+--------+----------------------+----------------------------+----------------+-----------+-----------------+\n\nnebula&gt; SHOW ALL QUERIES;\n+------------------+-----------------+---------+----------------------+----------------------------+----------------+-----------+---------------------------------------------------------+\n| SessionID        | ExecutionPlanID | User    | Host                 | StartTime                  | DurationInUSec | Status    | Query                                                   |\n+------------------+-----------------+---------+----------------------+----------------------------+----------------+-----------+---------------------------------------------------------+\n| 1625456037718757 | 54              | \"user1\" | \"\"192.168.x.x\":9669\" | 2021-07-05T05:51:08.691318 | 1504502        | \"RUNNING\" | \"MATCH p=(v:player)-[*1..4]-(v2) RETURN v2 AS Friends;\" |\n+------------------+-----------------+---------+----------------------+----------------------------+----------------+-----------+---------------------------------------------------------+\n\n# The following statement returns the top 10 queries that have the longest duration.\nnebula&gt; SHOW ALL QUERIES | ORDER BY $-.DurationInUSec DESC | LIMIT 10;\n+------------------+-----------------+---------+----------------------+----------------------------+----------------+-----------+-------------------------------------------------------+\n| SessionID        | ExecutionPlanID | User    | Host                 | StartTime                  | DurationInUSec | Status    | Query                                                 |\n+------------------+-----------------+---------+----------------------+----------------------------+----------------+-----------+-------------------------------------------------------+\n| 1625471375320831 | 98              | \"user2\" | \"\"192.168.x.x\":9669\" | 2021-07-05T07:50:24.461779 | 2608176        | \"RUNNING\" | \"MATCH (v:player)-[*1..4]-(v2) RETURN v2 AS Friends;\" |\n| 1625456037718757 | 99              | \"user1\" | \"\"192.168.x.x\":9669\" | 2021-07-05T07:50:24.910616 | 2159333        | \"RUNNING\" | \"MATCH (v:player)-[*1..4]-(v2) RETURN v2 AS Friends;\" |\n+------------------+-----------------+---------+----------------------+----------------------------+----------------+-----------+-------------------------------------------------------+\n</code></pre> <p>The descriptions are as follows.</p> Parameter Description <code>SessionID</code> The session ID. <code>ExecutionPlanID</code> The ID of the execution plan. <code>User</code> The username that executes the query. <code>Host</code> The IP address and port of the Graph server that hosts the session. <code>StartTime</code> The time when the query starts. <code>DurationInUSec</code> The duration of the query. The unit is microsecond. <code>Status</code> The current status of the query. <code>Query</code> The query statement."},{"location":"3.ngql-guide/7.general-query-statements/6.show/19.show-meta-leader/","title":"SHOW META LEADER","text":"<p>The <code>SHOW META LEADER</code> statement shows the information of the leader in the current Meta cluster.</p> <p>For more information about the Meta service, see Meta service.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/19.show-meta-leader/#syntax","title":"Syntax","text":"<pre><code>SHOW META LEADER;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/19.show-meta-leader/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW META LEADER;\n+------------------+---------------------------+\n| Meta Leader      | secs from last heart beat |\n+------------------+---------------------------+\n| \"127.0.0.1:9559\" | 3                         |\n+------------------+---------------------------+\n</code></pre> Parameter Description <code>Meta Leader</code> Shows the information of the leader in the Meta cluster, including the IP address and port of the server where the leader is located. <code>secs from last heart beat</code> Indicates the time interval since the last heartbeat. This parameter is measured in seconds."},{"location":"3.ngql-guide/7.general-query-statements/6.show/2.show-collation/","title":"SHOW COLLATION","text":"<p>The <code>SHOW COLLATION</code> statement shows the collations supported by NebulaGraph.</p> <p>Currently available types are: <code>utf8_bin</code>, <code>utf8_general_ci</code>, <code>utf8mb4_bin</code>, and <code>utf8mb4_general_ci</code>.</p> <ul> <li>When the character set is <code>utf8</code>, the default collate is <code>utf8_bin</code>.</li> </ul> <ul> <li>When the character set is <code>utf8mb4</code>, the default collate is <code>utf8mb4_bin</code>.</li> </ul> <ul> <li>Both <code>utf8mb4_bin</code> and <code>utf8mb4_general_ci</code> are case-insensitive.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/2.show-collation/#syntax","title":"Syntax","text":"<pre><code>SHOW COLLATION;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/2.show-collation/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW COLLATION;\n+------------+---------+\n| Collation  | Charset |\n+------------+---------+\n| \"utf8_bin\" | \"utf8\"  |\n+------------+---------+\n</code></pre> Parameter Description <code>Collation</code> The name of the collation. <code>Charset</code> The name of the character set with which the collation is associated."},{"location":"3.ngql-guide/7.general-query-statements/6.show/4.show-create-space/","title":"SHOW CREATE SPACE","text":"<p>The <code>SHOW CREATE SPACE</code> statement shows the creating statement of the specified graph space.</p> <p>For details about the graph space information, see CREATE SPACE.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/4.show-create-space/#syntax","title":"Syntax","text":"<pre><code>SHOW CREATE SPACE &lt;space_name&gt;;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/4.show-create-space/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW CREATE SPACE basketballplayer;\n+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Space              | Create Space                                                                                                                                           |\n+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n| \"basketballplayer\" | \"CREATE SPACE `basketballplayer` (partition_num = 10, replica_factor = 1, charset = utf8, collate = utf8_bin, vid_type = FIXED_STRING(32)) ON default\" |\n+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/5.show-create-tag-edge/","title":"SHOW CREATE TAG/EDGE","text":"<p>The <code>SHOW CREATE TAG</code> statement shows the basic information of the specified tag. For details about the tag, see CREATE TAG.</p> <p>The <code>SHOW CREATE EDGE</code> statement shows the basic information of the specified edge type. For details about the edge type, see CREATE EDGE.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/5.show-create-tag-edge/#syntax","title":"Syntax","text":"<pre><code>SHOW CREATE {TAG &lt;tag_name&gt; | EDGE &lt;edge_name&gt;};\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/5.show-create-tag-edge/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW CREATE TAG player;\n+----------+-----------------------------------+\n| Tag      | Create Tag                        |\n+----------+-----------------------------------+\n| \"player\" | \"CREATE TAG `player` (            |\n|          |  `name` string NULL,              |\n|          |  `age` int64 NULL                 |\n|          | ) ttl_duration = 0, ttl_col = \"\"\" |\n+----------+-----------------------------------+\n\nnebula&gt; SHOW CREATE EDGE follow;\n+----------+-----------------------------------+\n| Edge     | Create Edge                       |\n+----------+-----------------------------------+\n| \"follow\" | \"CREATE EDGE `follow` (           |\n|          |  `degree` int64 NULL              |\n|          | ) ttl_duration = 0, ttl_col = \"\"\" |\n+----------+-----------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/6.show-hosts/","title":"SHOW HOSTS","text":"<p>The <code>SHOW HOSTS</code> statement shows the host and version information of Graph Service, Storage Service, and Meta Service.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/6.show-hosts/#syntax","title":"Syntax","text":"<pre><code>SHOW HOSTS [GRAPH | STORAGE | META];\n</code></pre> <p>Note</p> <ul> <li>If you return <code>SHOW HOSTS</code> without the service name, it will show the host information of the Storage Service, as well as the leader number, leader distribution, and partition distribution.</li> </ul> <ul> <li>For a NebulaGraph cluster installed with the source code, the version of the cluster will not be displayed in the output after executing the command <code>SHOW HOSTS (GRAPH | STORAGE | META)</code> with the service name.</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/6.show-hosts/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW HOSTS;\n+-------------+-------+----------+--------------+----------------------------------+------------------------------+\n| Host        | Port  | Status   | Leader count | Leader distribution              | Partition distribution       |\n+-------------+-------+----------+--------------+----------------------------------+------------------------------+\n| \"storaged0\" | 9779  | \"ONLINE\" | 8            | \"docs:5, basketballplayer:3\"     | \"docs:5, basketballplayer:3\" |\n| \"storaged1\" | 9779  | \"ONLINE\" | 9            | \"basketballplayer:4, docs:5\"     | \"docs:5, basketballplayer:4\" |\n| \"storaged2\" | 9779  | \"ONLINE\" | 8            | \"basketballplayer:3, docs:5\"     | \"docs:5, basketballplayer:3\" |\n+-------------+-------+----------+--------------+----------------------------------+------------------------------+\n\nnebula&gt; SHOW HOSTS GRAPH;\n+-----------+------+----------+---------+---------------+--------+\n| Host      | Port | Status   | Role    | Git Info Sha | Version |\n+-----------+------+----------+---------+--------------+---------+\n| \"graphd\"  | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\"    | \"2.6.0\" |\n| \"graphd1\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\"    | \"2.6.0\" |\n| \"graphd2\" | 9669 | \"ONLINE\" | \"GRAPH\" | \"3ba41bd\"    | \"2.6.0\" |\n+-----------+------+----------+---------+--------------+---------+\n\nnebula&gt; SHOW HOSTS STORAGE;\n+-------------+------+----------+-----------+--------------+---------+\n| Host        | Port | Status   | Role      | Git Info Sha | Version |\n+-------------+------+----------+-----------+--------------+---------+\n| \"storaged0\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\"    | \"2.6.0\" |\n| \"storaged1\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\"    | \"2.6.0\" |\n| \"storaged2\" | 9779 | \"ONLINE\" | \"STORAGE\" | \"3ba41bd\"    | \"2.6.0\" |\n+-------------+------+----------+-----------+--------------+---------+\n\nnebula&gt; SHOW HOSTS META;\n+----------+------+----------+--------+--------------+---------+\n| Host     | Port | Status   | Role   | Git Info Sha | Version |\n+----------+------+----------+--------+--------------+---------+\n| \"metad2\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\"    | \"2.6.0\" |\n| \"metad0\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\"    | \"2.6.0\" |\n| \"metad1\" | 9559 | \"ONLINE\" | \"META\" | \"3ba41bd\"    | \"2.6.0\" |\n+----------+------+----------+--------+--------------+---------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/7.show-index-status/","title":"SHOW INDEX STATUS","text":"<p>The <code>SHOW INDEX STATUS</code> statement shows the status of jobs that rebuild native indexes, which helps check whether a native index is successfully rebuilt or not.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/7.show-index-status/#syntax","title":"Syntax","text":"<pre><code>SHOW {TAG | EDGE} INDEX STATUS;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/7.show-index-status/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW TAG INDEX STATUS;\n+------------------------------------+--------------+\n| Name                               | Index Status |\n+------------------------------------+--------------+\n| \"date1_index\"                      | \"FINISHED\"   |\n| \"basketballplayer_all_tag_indexes\" | \"FINISHED\"   |\n| \"any_shape_geo_index\"              | \"FINISHED\"   |\n+------------------------------------+--------------+\n\nnebula&gt; SHOW EDGE INDEX STATUS;\n+----------------+--------------+\n| Name           | Index Status |\n+----------------+--------------+\n| \"follow_index\" | \"FINISHED\"   |\n+----------------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/7.show-index-status/#related_topics","title":"Related topics","text":"<ul> <li>Job manager and the JOB statements</li> <li>REBUILD NATIVE INDEX</li> </ul>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/8.show-indexes/","title":"SHOW INDEXES","text":"<p>The <code>SHOW INDEXES</code> statement shows the names of existing native indexes.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/8.show-indexes/#syntax","title":"Syntax","text":"<pre><code>SHOW {TAG | EDGE} INDEXES;\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/8.show-indexes/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW TAG INDEXES;\n+------------------+--------------+-----------------+\n| Index Name       | By Tag       | Columns         |\n+------------------+--------------+-----------------+\n| \"fix\"            | \"fix_string\" | [\"p1\"]          |\n| \"player_index_0\" | \"player\"     | [\"name\"]        |\n| \"player_index_1\" | \"player\"     | [\"name\", \"age\"] |\n| \"var\"            | \"var_string\" | [\"p1\"]          |\n+------------------+--------------+-----------------+\n\nnebula&gt; SHOW EDGE INDEXES;\n+----------------+----------+---------+\n| Index Name     | By Edge  | Columns |\n+----------------+----------+---------+\n| \"follow_index\" | \"follow\" | []      |\n+----------------+----------+---------+\n</code></pre> <p>Legacy version compatibility</p> <p>In NebulaGraph 2.0.1, <code>SHOW TAG/EDGE INDEXES</code> only returns <code>Names</code>.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/9.show-parts/","title":"SHOW PARTS","text":"<p>The <code>SHOW PARTS</code> statement shows the information of a specified partition or all partitions in a graph space.</p>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/9.show-parts/#syntax","title":"Syntax","text":"<pre><code>SHOW PARTS [&lt;part_id&gt;];\n</code></pre>"},{"location":"3.ngql-guide/7.general-query-statements/6.show/9.show-parts/#examples","title":"Examples","text":"<pre><code>nebula&gt; SHOW PARTS;\n+--------------+--------------------+--------------------+-------+\n| Partition ID | Leader             | Peers              | Losts |\n+--------------+--------------------+--------------------+-------+\n| 1            | \"192.168.2.1:9779\" | \"192.168.2.1:9779\" | \"\"    |\n| 2            | \"192.168.2.2:9779\" | \"192.168.2.2:9779\" | \"\"    |\n| 3            | \"192.168.2.3:9779\" | \"192.168.2.3:9779\" | \"\"    |\n| 4            | \"192.168.2.1:9779\" | \"192.168.2.1:9779\" | \"\"    |\n| 5            | \"192.168.2.2:9779\" | \"192.168.2.2:9779\" | \"\"    |\n| 6            | \"192.168.2.3:9779\" | \"192.168.2.3:9779\" | \"\"    |\n| 7            | \"192.168.2.1:9779\" | \"192.168.2.1:9779\" | \"\"    |\n| 8            | \"192.168.2.2:9779\" | \"192.168.2.2:9779\" | \"\"    |\n| 9            | \"192.168.2.3:9779\" | \"192.168.2.3:9779\" | \"\"    |\n| 10           | \"192.168.2.1:9779\" | \"192.168.2.1:9779\" | \"\"    |\n+--------------+--------------------+--------------------+-------+\n\nnebula&gt; SHOW PARTS 1;\n+--------------+--------------------+--------------------+-------+\n| Partition ID | Leader             | Peers              | Losts |\n+--------------+--------------------+--------------------+-------+\n| 1            | \"192.168.2.1:9779\" | \"192.168.2.1:9779\" | \"\"    |\n+--------------+--------------------+--------------------+-------+\n</code></pre> <p>The descriptions are as follows.</p> Parameter Description <code>Partition ID</code> The ID of the partition. <code>Leader</code> The IP address and the port of the leader. <code>Peers</code> The IP addresses and the ports of all the replicas. <code>Losts</code> The IP addresses and the ports of replicas at fault."},{"location":"3.ngql-guide/8.clauses-and-options/group-by/","title":"GROUP BY","text":"<p>The <code>GROUP BY</code> clause can be used to aggregate data.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/group-by/#opencypher_compatibility","title":"OpenCypher Compatibility","text":"<p>This topic applies to native nGQL only.</p> <p>You can also use the count() function to aggregate data.</p> <pre><code>nebula&gt;  MATCH (v:player)&lt;-[:follow]-(:player) RETURN v.name AS Name, count(*) as cnt ORDER BY cnt DESC;\n+----------------------+-----+\n| Name                 | cnt |\n+----------------------+-----+\n| \"Tim Duncan\"         | 10  |\n| \"LeBron James\"       | 6   |\n| \"Tony Parker\"        | 5   |\n| \"Chris Paul\"         | 4   |\n| \"Manu Ginobili\"      | 4   |\n+----------------------+-----+\n...\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/group-by/#syntax","title":"Syntax","text":"<p>The <code>GROUP BY</code> clause groups the rows with the same value. Then operations such as counting, sorting, and calculation can be applied.</p> <p>The <code>GROUP BY</code> clause works after the pipe symbol (|) and before a <code>YIELD</code> clause.</p> <pre><code>| GROUP BY &lt;var&gt; YIELD &lt;var&gt;, &lt;aggregation_function(var)&gt;\n</code></pre> <p>The <code>aggregation_function()</code> function supports <code>avg()</code>, <code>sum()</code>, <code>max()</code>, <code>min()</code>, <code>count()</code>, <code>collect()</code>, and <code>std()</code>.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/group-by/#examples","title":"Examples","text":"<p>The following statement finds all the vertices connected directly to vertex <code>\"player100\"</code>, groups the result set by player names, and counts how many times the name shows up in the result set.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow BIDIRECT \\\n        YIELD properties($$).name as Name \\\n        | GROUP BY $-.Name \\\n        YIELD $-.Name as Player, count(*) AS Name_Count;\n+---------------------+------------+\n| Player              | Name_Count |\n+---------------------+------------+\n| \"Shaquille O'Neal\"  | 1          |\n| \"Tiago Splitter\"    | 1          |\n| \"Manu Ginobili\"     | 2          |\n| \"Boris Diaw\"        | 1          |\n| \"LaMarcus Aldridge\" | 1          |\n| \"Tony Parker\"       | 2          |\n| \"Marco Belinelli\"   | 1          |\n| \"Dejounte Murray\"   | 1          |\n| \"Danny Green\"       | 1          |\n| \"Aron Baynes\"       | 1          |\n+---------------------+------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/group-by/#group_and_calculate_with_functions","title":"Group and calculate with functions","text":"<p>The following statement finds all the vertices connected directly to vertex <code>\"player100\"</code>, groups the result set by source vertices, and returns the sum of degree values.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD src(edge) AS player, properties(edge).degree AS degree \\\n        | GROUP BY $-.player \\\n        YIELD sum($-.degree);\n+----------------+\n| sum($-.degree) |\n+----------------+\n| 190            |\n+----------------+\n</code></pre> <p>For more information about the <code>sum()</code> function, see Built-in math functions.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/","title":"LIMIT AND SKIP","text":"<p>The <code>LIMIT</code> clause constrains the number of rows in the output. The usage of <code>LIMIT</code> in native nGQL statements and openCypher compatible statements is different.</p> <ul> <li>Native nGQL: Generally, a pipe <code>|</code> needs to be used before the <code>LIMIT</code> clause. The offset parameter can be set or omitted directly after the <code>LIMIT</code> statement.</li> </ul> <ul> <li>OpenCypher compatible statements: No pipes are permitted before the <code>LIMIT</code> clause. And you can use <code>SKIP</code> to indicate an offset.</li> </ul> <p>Note<p>When using <code>LIMIT</code> in either syntax above, it is important to use an <code>ORDER BY</code> clause that constrains the output into a unique order. Otherwise, you will get an unpredictable subset of the output.</p> </p> <p>Legacy version compatibility</p> <p>In NebulaGraph 2.6.0, <code>GO</code> statements support the new <code>LIMIT</code> syntax. Some operators related to <code>LIMIT</code> support computing pushdown.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#limit_in_native_ngql_statements","title":"LIMIT in native nGQL statements","text":"<p>In native nGQL, <code>LIMIT</code> has general syntax and exclusive syntax in <code>GO</code> statements.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#general_limit_syntax_in_native_ngql_statements","title":"General LIMIT syntax in native nGQL statements","text":"<p>In native nGQL,  the general <code>LIMIT</code> syntax works the same as in <code>SQL</code>. The <code>LIMIT</code> clause accepts one or two parameters. The values of both parameters must be non-negative integers and be used after a pipe. The syntax and description are as follows:</p> <pre><code>... | LIMIT [&lt;offset&gt;,] &lt;number_rows&gt;;\n</code></pre> Parameter Description <code>offset</code> The offset value. It defines the row from which to start returning. The offset starts from <code>0</code>. The default value is <code>0</code>, which returns from the first row. <code>number_rows</code> It constrains the total number of returned rows. <p>For example:</p> <pre><code># The following example returns the top 3 rows of data from the result.\nnebula&gt; LOOKUP ON player |\\\n        LIMIT 3;\n+-------------+\n| VertexID    |\n+-------------+\n| \"player100\" |\n| \"player101\" |\n| \"player102\" |\n+-------------+\n\n# The following example returns the 3 rows of data starting from the second row of the sorted output.\nnebula&gt; GO FROM \"player100\" OVER follow REVERSELY \\\n        YIELD properties($$).name AS Friend, properties($$).age AS Age \\\n        | ORDER BY $-.Age, $-.Friend \\\n        | LIMIT 1, 3;\n+-------------------+-----+\n| Friend            | Age |\n+-------------------+-----+\n| \"Danny Green\"     | 31  |\n| \"Aron Baynes\"     | 32  |\n| \"Marco Belinelli\" | 32  |\n+-------------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#limit_in_go_statements","title":"LIMIT in GO statements","text":"<p>In addition to the general syntax in the native nGQL, the <code>LIMIT</code> in the <code>GO</code> statement also supports limiting the number of output results based on edges.</p> <p>Syntax:</p> <pre><code>&lt;go_statement&gt; LIMIT &lt;limit_list&gt;;\n</code></pre> <p><code>limit_list</code> is a list. Elements in the list must be natural numbers, and the number of elements must be the same as the maximum number of <code>STEPS</code> in the <code>GO</code> statement. The following takes <code>GO 1 TO 3 STEPS FROM \"A\" OVER * LIMIT &lt;limit_list&gt;</code> as an example to introduce this usage of <code>LIMIT</code> in detail.</p> <ul> <li>The list <code>limit_list</code> must contain 3 natural numbers, such as <code>GO 1 TO 3 STEPS FROM \"A\" OVER * LIMIT [1,2,4]</code>.</li> <li><code>1</code> in <code>LIMIT [1,2,4]</code> means that the system automatically selects 1 edge to continue traversal in the first step. <code>2</code> means to select 2 edges to continue traversal in the second step. <code>4</code> indicates that 4 edges are selected to continue traversal in the third step.</li> <li>Because <code>GO 1 TO 3 STEPS</code> means to return all the traversal results from the first to third steps, all the red edges and their source and destination vertices in the figure below will be matched by this <code>GO</code> statement. And the yellow edges represent there is no path selected when the GO statement traverses. If it is not <code>GO 1 TO 3 STEPS</code> but <code>GO 3 STEPS</code>, it will only match the red edges of the third step and the vertices at both ends.</li> </ul> <p></p> <p>In the basketballplayer dataset, the example is as follows:</p> <pre><code>nebula&gt; GO 3 STEPS FROM \"player100\" \\\n        OVER * \\\n        YIELD properties($$).name AS NAME, properties($$).age AS Age \\\n        LIMIT [3,3,3];\n+-----------------+--------------+\n| NAME            | Age          |\n+-----------------+--------------+\n| \"Spurs\"         | UNKNOWN_PROP |\n| \"Tony Parker\"   | 36           |\n| \"Manu Ginobili\" | 41           |\n+-----------------+--------------+\n\nnebula&gt; GO 3 STEPS FROM \"player102\" \\\n        OVER * \\\n        LIMIT [rand32(5),rand32(5),rand32(5)];\n+------------+-------------+---------------------+\n| serve._dst | follow._dst | any_shape_edge._dst |\n+------------+-------------+---------------------+\n| \"team204\"  |             |                     |\n| \"team215\"  |             |                     |\n|            | \"player100\" |                     |\n+------------+-------------+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#limit_in_opencypher_compatible_statements","title":"LIMIT in openCypher compatible statements","text":"<p>In openCypher compatible statements such as <code>MATCH</code>, there is no need to use a pipe when <code>LIMIT</code> is used. The syntax and description are as follows:</p> <pre><code>... [SKIP &lt;offset&gt;] [LIMIT &lt;number_rows&gt;];\n</code></pre> Parameter Description <code>offset</code> The offset value. It defines the row from which to start returning. The offset starts from <code>0</code>. The default value is <code>0</code>, which returns from the first row. <code>number_rows</code> It constrains the total number of returned rows. <p>Both <code>offset</code> and <code>number_rows</code> accept expressions, but the result of the expression must be a non-negative integer.</p> <p>Note</p> <p>Fraction expressions composed of two integers are automatically floored to integers. For example, <code>8/6</code> is floored to 1.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#examples_of_limit","title":"Examples of LIMIT","text":"<p><code>LIMIT</code> can be used alone to return a specified number of results.</p> <pre><code>nebula&gt; MATCH (v:player) RETURN v.name AS Name, v.age AS Age \\\n        ORDER BY Age LIMIT 5;\n+-------------------------+-----+\n| Name                    | Age |\n+-------------------------+-----+\n| \"Luka Doncic\"           | 20  |\n| \"Ben Simmons\"           | 22  |\n| \"Kristaps Porzingis\"    | 23  |\n| \"Giannis Antetokounmpo\" | 24  |\n| \"Kyle Anderson\"         | 25  |\n+-------------------------+-----+\n\nnebula&gt; MATCH (v:player) RETURN v.name AS Name, v.age AS Age \\\n        ORDER BY Age LIMIT rand32(5);\n+-------------------------+-----+\n| Name                    | Age |\n+-------------------------+-----+\n| \"Luka Doncic\"           | 20  |\n| \"Ben Simmons\"           | 22  |\n| \"Kristaps Porzingis\"    | 23  |\n| \"Giannis Antetokounmpo\" | 24  |\n+-------------------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#examples_of_skip","title":"Examples of SKIP","text":"<p><code>SKIP</code> can be used alone to set the offset and return the data after the specified position.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) --&gt; (v2) \\\n        RETURN v2.name AS Name, v2.age AS Age \\\n        ORDER BY Age DESC SKIP 1;\n+-----------------+-----+\n| Name            | Age |\n+-----------------+-----+\n| \"Manu Ginobili\" | 41  |\n| \"Tony Parker\"   | 36  |\n+-----------------+-----+\n\nnebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) --&gt; (v2) \\\n        RETURN v2.name AS Name, v2.age AS Age \\\n        ORDER BY Age DESC SKIP 1+1;\n+---------------+-----+\n| Name          | Age |\n+---------------+-----+\n| \"Tony Parker\" | 36  |\n+---------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/limit/#example_of_skip_and_limit","title":"Example of SKIP and LIMIT","text":"<p><code>SKIP</code> and <code>LIMIT</code> can be used together to return the specified amount of data starting from the specified position.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) --&gt; (v2) \\\n        RETURN v2.name AS Name, v2.age AS Age \\\n        ORDER BY Age DESC SKIP 1 LIMIT 1;\n+-----------------+-----+\n| Name            | Age |\n+-----------------+-----+\n| \"Manu Ginobili\" | 41  |\n+-----------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/order-by/","title":"ORDER BY","text":"<p>The <code>ORDER BY</code> clause specifies the order of the rows in the output.</p> <ul> <li>Native nGQL: You must use a pipe (<code>|</code>) and an <code>ORDER BY</code> clause after <code>YIELD</code> clause.</li> </ul> <ul> <li>OpenCypher style: No pipes are permitted. The <code>ORDER BY</code> clause follows a <code>RETURN</code> clause.</li> </ul> <p>There are two order options:</p> <ul> <li><code>ASC</code>: Ascending. <code>ASC</code> is the default order.</li> <li><code>DESC</code>: Descending.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/order-by/#native_ngql_syntax","title":"Native nGQL Syntax","text":"<pre><code>&lt;YIELD clause&gt;\nORDER BY &lt;expression&gt; [ASC | DESC] [, &lt;expression&gt; [ASC | DESC] ...];\n</code></pre> <p>Compatibility</p> <p>In the native nGQL syntax, <code>$-.</code> must be used after <code>ORDER BY</code>. But it is not required in releases prior to 2.5.0.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/order-by/#examples","title":"Examples","text":"<pre><code>nebula&gt; FETCH PROP ON player \"player100\", \"player101\", \"player102\", \"player103\" \\\n        YIELD player.age AS age, player.name AS name \\\n        | ORDER BY $-.age ASC, $-.name DESC;\n+-------------+-----+---------------------+\n| VertexID    | age | name                |\n+-------------+-----+---------------------+\n| \"player103\" | 32  | \"Rudy Gay\"          |\n| \"player102\" | 33  | \"LaMarcus Aldridge\" |\n| \"player101\" | 36  | \"Tony Parker\"       |\n| \"player100\" | 42  | \"Tim Duncan\"        |\n+-------------+-----+---------------------+\n\nnebula&gt; $var = GO FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS dst; \\\n        ORDER BY $var.dst DESC;\n+-------------+\n| dst         |\n+-------------+\n| \"player125\" |\n| \"player101\" |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/order-by/#opencypher_syntax","title":"OpenCypher Syntax","text":"<pre><code>&lt;RETURN clause&gt;\nORDER BY &lt;expression&gt; [ASC | DESC] [, &lt;expression&gt; [ASC | DESC] ...];\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/order-by/#examples_1","title":"Examples","text":"<pre><code>nebula&gt; MATCH (v:player) RETURN v.name AS Name, v.age AS Age  \\\n        ORDER BY Name DESC;\n+-----------------+-----+\n| Name            | Age |\n+-----------------+-----+\n| \"Yao Ming\"      | 38  |\n| \"Vince Carter\"  | 42  |\n| \"Tracy McGrady\" | 39  |\n| \"Tony Parker\"   | 36  |\n| \"Tim Duncan\"    | 42  |\n+-----------------+-----+\n...\n\n# In the following example, nGQL sorts the rows by age first. If multiple people are of the same age, nGQL will then sort them by name.\nnebula&gt; MATCH (v:player) RETURN v.age AS Age, v.name AS Name  \\\n        ORDER BY Age DESC, Name ASC;\n+-----+-------------------+\n| Age | Name              |\n+-----+-------------------+\n| 47  | \"Shaquille O'Neal\" |\n| 46  | \"Grant Hill\"      |\n| 45  | \"Jason Kidd\"      |\n| 45  | \"Steve Nash\"      |\n+-----+-------------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/order-by/#order_of_null_values","title":"Order of NULL values","text":"<p>nGQL lists NULL values at the end of the output for ascending sorting, and at the start for descending sorting.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) --&gt; (v2) \\\n        RETURN v2.name AS Name, v2.age AS Age  \\\n        ORDER BY Age;\n+-----------------+--------------+\n| Name            | Age          |\n+-----------------+--------------+\n| \"Tony Parker\"   | 36           |\n| \"Manu Ginobili\" | 41           |\n| \"Spurs\"         | UNKNOWN_PROP |\n+-----------------+--------------+\n\nnebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) --&gt; (v2) \\\n        RETURN v2.name AS Name, v2.age AS Age  \\\n        ORDER BY Age DESC;\n+-----------------+--------------+\n| Name            | Age          |\n+-----------------+--------------+\n| \"Spurs\"         | UNKNOWN_PROP |\n| \"Manu Ginobili\" | 41           |\n| \"Tony Parker\"   | 36           |\n+-----------------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/","title":"RETURN","text":"<p>The <code>RETURN</code> clause defines the output of an nGQL query. To return multiple fields, separate them with commas.</p> <p><code>RETURN</code> can lead a clause or a statement:</p> <ul> <li>A <code>RETURN</code> clause can work in openCypher statements in nGQL, such as <code>MATCH</code> or <code>UNWIND</code>.</li> </ul> <ul> <li>A <code>RETURN</code> statement can work independently to output the result of an expression.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>This topic applies to the openCypher syntax in nGQL only. For native nGQL, use <code>YIELD</code>.</p> <p><code>RETURN</code> does not support the following openCypher features yet.</p> <ul> <li> <p>Return variables with uncommon characters, for example:</p> <pre><code>MATCH (`non-english_characters`:player) \\\nRETURN `non-english_characters`;\n</code></pre> </li> </ul> <ul> <li> <p>Set a pattern in the <code>RETURN</code> clause and return all elements that this pattern matches, for example:</p> <pre><code>MATCH (v:player) \\\nRETURN (v)-[e]-&gt;(v2);\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#legacy_version_compatibility","title":"Legacy version compatibility","text":"<ul> <li>In nGQL 1.x, <code>RETURN</code> works with native nGQL with the <code>RETURN &lt;var_ref&gt; IF &lt;var_ref&gt; IS NOT NULL</code> syntax.</li> </ul> <ul> <li>In nGQL 2.0, <code>RETURN</code> does not work with native nGQL.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#map_order_description","title":"Map order description","text":"<p>When <code>RETURN</code> returns the map data structure, the order of key-value pairs is undefined.</p> <pre><code>nebula&gt; RETURN {age: 32, name: \"Marco Belinelli\"};\n+------------------------------------+\n| {age:32,name:\"Marco Belinelli\"}    |\n+------------------------------------+\n| {age: 32, name: \"Marco Belinelli\"} |\n+------------------------------------+\n\nnebula&gt; RETURN {zage: 32, name: \"Marco Belinelli\"};\n+-------------------------------------+\n| {zage:32,name:\"Marco Belinelli\"}    |\n+-------------------------------------+\n| {name: \"Marco Belinelli\", zage: 32} |\n+-------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_vertices","title":"Return vertices","text":"<pre><code>nebula&gt; MATCH (v:player) \\\n        RETURN v;\n+---------------------------------------------------------------+\n| v                                                             |\n+---------------------------------------------------------------+\n| (\"player104\" :player{age: 32, name: \"Marco Belinelli\"})       |\n| (\"player107\" :player{age: 32, name: \"Aron Baynes\"})           |\n| (\"player116\" :player{age: 34, name: \"LeBron James\"})          |\n| (\"player120\" :player{age: 29, name: \"James Harden\"})          |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})         |\n+---------------------------------------------------------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_edges","title":"Return edges","text":"<pre><code>nebula&gt; MATCH (v:player)-[e]-&gt;() \\\n        RETURN e;\n+------------------------------------------------------------------------------+\n| e                                                                            |\n+------------------------------------------------------------------------------+\n| [:follow \"player104\"-&gt;\"player100\" @0 {degree: 55}]                           |\n| [:follow \"player104\"-&gt;\"player101\" @0 {degree: 50}]                           |\n| [:follow \"player104\"-&gt;\"player105\" @0 {degree: 60}]                           |\n| [:serve \"player104\"-&gt;\"team200\" @0 {end_year: 2009, start_year: 2007}]        |\n| [:serve \"player104\"-&gt;\"team208\" @0 {end_year: 2016, start_year: 2015}]        |\n+------------------------------------------------------------------------------+\n...\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_properties","title":"Return properties","text":"<p>To return a vertex or edge property, use the <code>{&lt;vertex_name&gt;|&lt;edge_name&gt;}.&lt;property&gt;</code> syntax.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        RETURN v.name, v.age \\\n        LIMIT 3;\n+-------------------+-------+\n| v.name            | v.age |\n+-------------------+-------+\n| \"Rajon Rondo\"     | 33    |\n| \"Rudy Gay\"        | 32    |\n| \"Dejounte Murray\" | 29    |\n+-------------------+-------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_all_elements","title":"Return all elements","text":"<p>To return all the elements that this pattern matches, use an asterisk (*).</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"}) \\\n        RETURN *;\n+----------------------------------------------------+\n| v                                                  |\n+----------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) |\n+----------------------------------------------------+\n\nnebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[e]-&gt;(v2) \\\n        RETURN *;\n+----------------------------------------------------+-----------------------------------------------------------------------+-------------------------------------------------------+\n| v                                                  | e                                                                     | v2                                                    |\n+----------------------------------------------------+-----------------------------------------------------------------------+-------------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) | [:follow \"player100\"-&gt;\"player101\" @0 {degree: 95}]                    | (\"player101\" :player{age: 36, name: \"Tony Parker\"})   |\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) | [:follow \"player100\"-&gt;\"player125\" @0 {degree: 95}]                    | (\"player125\" :player{age: 41, name: \"Manu Ginobili\"}) |\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"}) | [:serve \"player100\"-&gt;\"team204\" @0 {end_year: 2016, start_year: 1997}] | (\"team204\" :team{name: \"Spurs\"})                      |\n+----------------------------------------------------+-----------------------------------------------------------------------+-------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#rename_a_field","title":"Rename a field","text":"<p>Use the <code>AS &lt;alias&gt;</code> syntax to rename a field in the output.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[:serve]-&gt;(v2) \\\n        RETURN v2.name AS Team;\n+---------+\n| Team    |\n+---------+\n| \"Spurs\" |\n+---------+\n\nnebula&gt; RETURN \"Amber\" AS Name;\n+---------+\n| Name    |\n+---------+\n| \"Amber\" |\n+---------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_a_non-existing_property","title":"Return a non-existing property","text":"<p>If a property matched does not exist, <code>NULL</code> is returned.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tim Duncan\"})-[e]-&gt;(v2) \\\n        RETURN v2.name, type(e), v2.age;\n+-----------------+----------+--------------+\n| v2.name         | type(e)  | v2.age       |\n+-----------------+----------+--------------+\n| \"Tony Parker\"   | \"follow\" | 36           |\n| \"Manu Ginobili\" | \"follow\" | 41           |\n| \"Spurs\"         | \"serve\"  | UNKNOWN_PROP |\n+-----------------+----------+--------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_expression_results","title":"Return expression results","text":"<p>To return the results of expressions such as literals, functions, or predicates, set them in a <code>RETURN</code> clause.</p> <pre><code>nebula&gt; MATCH (v:player{name:\"Tony Parker\"})--&gt;(v2:player) \\\n        RETURN DISTINCT v2.name, \"Hello\"+\" graphs!\", v2.age &gt; 35;\n+---------------------+------------------+-------------+\n| v2.name             | (Hello+ graphs!) | (v2.age&gt;35) |\n+---------------------+------------------+-------------+\n| \"Tim Duncan\"        | \"Hello graphs!\"  | true        |\n| \"LaMarcus Aldridge\" | \"Hello graphs!\"  | false       |\n| \"Manu Ginobili\"     | \"Hello graphs!\"  | true        |\n+---------------------+------------------+-------------+\n\nnebula&gt; RETURN 1+1;\n+-------+\n| (1+1) |\n+-------+\n| 2     |\n+-------+\n\nnebula&gt; RETURN 3 &gt; 1;\n+-------+\n| (3&gt;1) |\n+-------+\n| true  |\n+-------+\n\nnebula&gt; RETURN 1+1, rand32(1, 5);\n+-------+-------------+\n| (1+1) | rand32(1,5) |\n+-------+-------------+\n| 2     | 1           |\n+-------+-------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/return/#return_unique_fields","title":"Return unique fields","text":"<p>Use <code>DISTINCT</code> to remove duplicate fields in the result set.</p> <pre><code># Before using DISTINCT.\nnebula&gt; MATCH (v:player{name:\"Tony Parker\"})--(v2:player) \\\n        RETURN v2.name, v2.age;\n+---------------------+--------+\n| v2.name             | v2.age |\n+---------------------+--------+\n| \"Tim Duncan\"        | 42     |\n| \"LaMarcus Aldridge\" | 33     |\n| \"Marco Belinelli\"   | 32     |\n| \"Boris Diaw\"        | 36     |\n| \"Dejounte Murray\"   | 29     |\n| \"Tim Duncan\"        | 42     |\n| \"LaMarcus Aldridge\" | 33     |\n| \"Manu Ginobili\"     | 41     |\n+---------------------+--------+\n\n# After using DISTINCT.\nnebula&gt; MATCH (v:player{name:\"Tony Parker\"})--(v2:player) \\\n        RETURN DISTINCT v2.name, v2.age;\n+---------------------+--------+\n| v2.name             | v2.age |\n+---------------------+--------+\n| \"Tim Duncan\"        | 42     |\n| \"LaMarcus Aldridge\" | 33     |\n| \"Marco Belinelli\"   | 32     |\n| \"Boris Diaw\"        | 36     |\n| \"Dejounte Murray\"   | 29     |\n| \"Manu Ginobili\"     | 41     |\n+---------------------+--------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/sample/","title":"SAMPLE","text":"<p>The <code>SAMPLE</code> clause takes samples evenly in the result set and returns the specified amount of data.</p> <p>Legacy version compatibility</p> <p><code>SAMPLE</code> is a new clause added in NebulaGraph 2.6.0.</p> <p><code>SAMPLE</code> can be used in <code>GO</code> statements only. The syntax is as follows:</p> <pre><code>&lt;go_statement&gt; SAMPLE &lt;sample_list&gt;;\n</code></pre> <p><code>sample_list</code> is a list. Elements in the list must be natural numbers, and the number of elements must be the same as the maximum number of <code>STEPS</code> in the <code>GO</code> statement. The following takes <code>GO 1 TO 3 STEPS FROM \"A\" OVER * SAMPLE &lt;sample_list&gt;</code> as an example to introduce this usage of <code>SAMPLE</code> in detail.</p> <ul> <li>The list <code>sample_list</code> must contain 3 natural numbers, such as <code>GO 1 TO 3 STEPS FROM \"A\" OVER * SAMPLE [1,2,4]</code>.</li> <li><code>1</code> in <code>SAMPLE [1,2,4]</code> means that the system automatically selects 1 edge to continue traversal in the first step. <code>2</code> means to select 2 edges to continue traversal in the second step. <code>4</code> indicates that 4 edges are selected to continue traversal in the third step. If there is no matched edge in a certain step or the number of matched edges is less than the specified number, the actual number will be returned.</li> <li>Because <code>GO 1 TO 3 STEPS</code> means to return all the traversal results from the first to third steps, all the red edges and their source and destination vertices in the figure below will be matched by this <code>GO</code> statement. And the yellow edges represent there is no path selected when the GO statement traverses. If it is not <code>GO 1 TO 3 STEPS</code> but <code>GO 3 STEPS</code>, it will only match the red edges of the third step and the vertices at both ends.</li> </ul> <p></p> <p>In the basketballplayer dataset, the example is as follows:</p> <pre><code>nebula&gt; GO 3 STEPS FROM \"player100\" \\\n        OVER * \\\n        YIELD properties($$).name AS NAME, properties($$).age AS Age \\\n        SAMPLE [1,2,3];\n+-----------------+--------------+\n| NAME            | Age          |\n+-----------------+--------------+\n| \"Spurs\"         | UNKNOWN_PROP |\n| \"Tony Parker\"   | 36           |\n| \"Manu Ginobili\" | 41           |\n+-----------------+--------------+\n\nnebula&gt; GO 1 TO 3 STEPS FROM \"player100\" \\\n        OVER * \\\n        YIELD properties($$).name AS NAME, properties($$).age AS Age \\\n        SAMPLE [2,2,2];\n+---------------------+-----+\n| NAME                | Age |\n+---------------------+-----+\n| \"Manu Ginobili\"     | 41  |\n| \"Tony Parker\"       | 36  |\n| \"Tim Duncan\"        | 42  |\n| \"LaMarcus Aldridge\" | 33  |\n| \"Tony Parker\"       | 36  |\n| \"Tim Duncan\"        | 42  |\n+---------------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/","title":"TTL","text":"<p>TTL (Time To Live) specifies a timeout for a property. Once timed out, the property expires.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#opencypher_compatibility","title":"OpenCypher Compatibility","text":"<p>This topic applies to native nGQL only.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#precautions","title":"Precautions","text":"<ul> <li>You CANNOT modify a property schema with TTL options on it.</li> </ul> <ul> <li>TTL options and indexes have coexistence issues.<p>+  TTL options and indexes CANNOT coexist on a tag or an edge type. If there is an index on a property, you cannot set TTL options on other properties.</p> <p>+ If there are TTL options on a tag, an edge type, or a property, you can still add an index on them.</p> </li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#data_expiration_and_deletion","title":"Data expiration and deletion","text":""},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#vertex_property_expiration","title":"Vertex property expiration","text":"<p>Vertex property expiration has the following impact.</p> <ul> <li>If a vertex has only one tag, once a property of the vertex expires, the vertex expires.</li> </ul> <ul> <li>If a vertex has multiple tags, once a property of the vertex expires, properties bound to the same tag with the expired property also expire, but the vertex does not expire and other properties of it remain untouched.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#edge_property_expiration","title":"Edge property expiration","text":"<p>Since an edge can have only one edge type, once an edge property expires, the edge expires.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#data_deletion","title":"Data deletion","text":"<p>The expired data are still stored on the disk, but queries will filter them out.</p> <p>NebulaGraph automatically deletes the expired data and reclaims the disk space during the next compaction.</p> <p>Note</p> <p>If TTL is disabled, the corresponding data deleted after the last compaction can be queried again.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#ttl_options","title":"TTL options","text":"<p>The native nGQL TTL feature has the following options.</p> Option Description <code>ttl_col</code> Specifies the property to set a timeout on. The data type of the property must be <code>int</code> or <code>timestamp</code>. <code>ttl_duration</code> Specifies the timeout adds-on value in seconds. The value must be a non-negative int64 number. A property expires if the sum of its value and the <code>ttl_duration</code> value is smaller than the current timestamp. If the <code>ttl_duration</code> value is <code>0</code>, the property never expires."},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#use_ttl_options","title":"Use TTL options","text":"<p>You must use the TTL options together to set a valid timeout on a property.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#set_a_timeout_if_a_tag_or_an_edge_type_exists","title":"Set a timeout if a tag or an edge type exists","text":"<p>If a tag or an edge type is already created, to set a timeout on a property bound to the tag or edge type, use <code>ALTER</code> to update the tag or edge type.</p> <pre><code># Create a tag.\nnebula&gt; CREATE TAG IF NOT EXISTS t1 (a timestamp);\n\n# Use ALTER to update the tag and set the TTL options.\nnebula&gt; ALTER TAG t1 ttl_col = \"a\", ttl_duration = 5;\n\n# Insert a vertex with tag t1. The vertex expires 5 seconds after the insertion.\nnebula&gt; INSERT VERTEX t1(a) values \"101\":(now());\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#set_a_timeout_when_creating_a_tag_or_an_edge_type","title":"Set a timeout when creating a tag or an edge type","text":"<p>Use TTL options in the <code>CREATE</code> statement to set a timeout when creating a tag or an edge type. For more information, see CREATE TAG and CREATE EDGE.</p> <pre><code># Create a tag and set the TTL options.\nnebula&gt; CREATE TAG IF NOT EXISTS t2(a int, b int, c string) ttl_duration= 100, ttl_col = \"a\";\n\n# Insert a vertex with tag t2. The timeout timestamp is 1612778164774 (1612778164674 + 100).\nnebula&gt; INSERT VERTEX t2(a, b, c) values \"102\":(1612778164674, 30, \"Hello\");\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/ttl-options/#remove_a_timeout","title":"Remove a timeout","text":"<p>To disable TTL and remove the timeout on a property, you can use the following approaches.</p> <ul> <li>Drop the property with the timeout.<pre><code>nebula&gt; ALTER TAG t1 DROP (a);\n</code></pre> </li> </ul> <ul> <li>Set <code>ttl_col</code> to an empty string.<pre><code>nebula&gt; ALTER TAG t1 ttl_col = \"\";\n</code></pre> </li> </ul> <ul> <li>Set <code>ttl_duration</code> to <code>0</code>. This operation keeps the TTL options and prevents the property from expiring and the property schema from being modified.<pre><code>nebula&gt; ALTER TAG t1 ttl_duration = 0;\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/where/","title":"WHERE","text":"<p>The <code>WHERE</code> clause filters the output by conditions.</p> <p>The <code>WHERE</code> clause usually works in the following queries:</p> <ul> <li>Native nGQL: such as <code>GO</code> and <code>LOOKUP</code>.</li> </ul> <ul> <li>OpenCypher syntax: such as <code>MATCH</code> and <code>WITH</code>.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<ul> <li>Using patterns in <code>WHERE</code> is not supported (TODO: planning), for example <code>WHERE (v)--&gt;(v2)</code>.</li> </ul> <ul> <li>Filtering on edge rank is a native nGQL feature. To retrieve the rank value in openCypher statements, use the rank() function, such as <code>MATCH (:player)-[e:follow]-&gt;() RETURN rank(e);</code>.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#basic_usage","title":"Basic usage","text":"<p>Note</p> <p>In the following examples, <code>$$</code> and <code>$^</code> are reference operators. For more information, see Operators.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#define_conditions_with_boolean_operators","title":"Define conditions with boolean operators","text":"<p>Use the boolean operators <code>NOT</code>, <code>AND</code>, <code>OR</code>, and <code>XOR</code> to define conditions in <code>WHERE</code> clauses. For the precedence of the operators, see Precedence.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.name == \"Tim Duncan\" \\\n        XOR (v.age &lt; 30 AND v.name == \"Yao Ming\") \\\n        OR NOT (v.name == \"Yao Ming\" OR v.name == \"Tim Duncan\") \\\n        RETURN v.name, v.age;\n+-------------------------+-------+\n| v.name                  | v.age |\n+-------------------------+-------+\n| \"Marco Belinelli\"       | 32    |\n| \"Aron Baynes\"           | 32    |\n| \"LeBron James\"          | 34    |\n| \"James Harden\"          | 29    |\n| \"Manu Ginobili\"         | 41    |\n+-------------------------+-------+\n...\n</code></pre> <pre><code>nebula&gt; GO FROM \"player100\" \\\n        OVER follow \\\n        WHERE follow.degree &gt; 90 \\\n        OR properties($$).age != 33 \\\n        AND properties($$).name != \"Tony Parker\" \\\n        YIELD properties($$);\n+----------------------------------+\n| properties($$)                   |\n+----------------------------------+\n| {age: 41, name: \"Manu Ginobili\"} |\n+----------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#filter_on_properties","title":"Filter on properties","text":"<p>Use vertex or edge properties to define conditions in <code>WHERE</code> clauses.</p> <ul> <li>Filter on a vertex property:<pre><code>nebula&gt; MATCH (v:player)-[e]-&gt;(v2) \\\n        WHERE v2.age &lt; 25 \\\n        RETURN v2.name, v2.age;\n+----------------------+--------+\n| v2.name              | v2.age |\n+----------------------+--------+\n| \"Luka Doncic\"        | 20     |\n| \"Kristaps Porzingis\" | 23     |\n| \"Ben Simmons\"        | 22     |\n+----------------------+--------+\n</code></pre> <pre><code>nebula&gt; GO FROM \"player100\" \\\n        OVER follow \\\n        WHERE $^.player.age &gt;= 42;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\n</code></pre> </li> </ul> <ul> <li>Filter on an edge property:<pre><code>nebula&gt; MATCH (v:player)-[e]-&gt;() \\\n        WHERE e.start_year &lt; 2000 \\\n        RETURN DISTINCT v.name, v.age;\n+--------------------+-------+\n| v.name             | v.age |\n+--------------------+-------+\n| \"Shaquille O'Neal\" | 47    |\n| \"Steve Nash\"       | 45    |\n| \"Ray Allen\"        | 43    |\n| \"Grant Hill\"       | 46    |\n| \"Tony Parker\"      | 36    |\n+--------------------+-------+\n...\n</code></pre> <pre><code>nebula&gt; GO FROM \"player100\" \\\n        OVER follow \\\n        WHERE follow.degree &gt; 90;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#filter_on_dynamically-calculated_properties","title":"Filter on dynamically-calculated properties","text":"<pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v[toLower(\"AGE\")] &lt; 21 \\\n        RETURN v.name, v.age;\n+---------------+-------+\n| v.name        | v.age |\n+---------------+-------+\n| \"Luka Doncic\" | 20    |\n+---------------+-------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#filter_on_existing_properties","title":"Filter on existing properties","text":"<pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE exists(v.age) \\\n        RETURN v.name, v.age;\n+-------------------------+-------+\n| v.name                  | v.age |\n+-------------------------+-------+\n| \"Boris Diaw\"            | 36    |\n| \"DeAndre Jordan\"        | 30    |\n+-------------------------+-------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#filter_on_edge_rank","title":"Filter on edge rank","text":"<p>In nGQL, if a group of edges has the same source vertex, destination vertex, and properties, the only thing that distinguishes them is the rank. Use rank conditions in <code>WHERE</code> clauses to filter such edges.</p> <pre><code># The following example creates test data.\nnebula&gt; CREATE SPACE IF NOT EXISTS test (vid_type=FIXED_STRING(30));\nnebula&gt; USE test;\nnebula&gt; CREATE EDGE IF NOT EXISTS e1(p1 int);\nnebula&gt; CREATE TAG IF NOT EXISTS person(p1 int);\nnebula&gt; INSERT VERTEX person(p1) VALUES \"1\":(1);\nnebula&gt; INSERT VERTEX person(p1) VALUES \"2\":(2);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@0:(10);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@1:(11);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@2:(12);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@3:(13);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@4:(14);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@5:(15);\nnebula&gt; INSERT EDGE e1(p1) VALUES \"1\"-&gt;\"2\"@6:(16);\n\n# The following example use rank to filter edges and retrieves edges with a rank greater than 2.\nnebula&gt; GO FROM \"1\" \\\n        OVER e1 \\\n        WHERE rank(edge) &gt; 2 \\\n        YIELD src(edge), dst(edge), rank(edge) AS Rank, properties(edge).p1 | \\\n        ORDER BY $-.Rank DESC;\n+-----------+-----------+------+---------------------+\n| src(EDGE) | dst(EDGE) | Rank | properties(EDGE).p1 |\n+-----------+-----------+------+---------------------+\n| \"1\"       | \"2\"       | 6    | 16                  |\n| \"1\"       | \"2\"       | 5    | 15                  |\n| \"1\"       | \"2\"       | 4    | 14                  |\n| \"1\"       | \"2\"       | 3    | 13                  |\n+-----------+-----------+------+---------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#filter_on_strings","title":"Filter on strings","text":"<p>Use <code>STARTS WITH</code>, <code>ENDS WITH</code>, or <code>CONTAINS</code> in <code>WHERE</code> clauses to match a specific part of a string. String matching is case-sensitive.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#starts_with","title":"<code>STARTS WITH</code>","text":"<p><code>STARTS WITH</code> will match the beginning of a string.</p> <p>The following example uses <code>STARTS WITH \"T\"</code> to retrieve the information of players whose name starts with <code>T</code>.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.name STARTS WITH \"T\" \\\n        RETURN v.name, v.age;\n+------------------+-------+\n| v.name           | v.age |\n+------------------+-------+\n| \"Tracy McGrady\"  | 39    |\n| \"Tony Parker\"    | 36    |\n| \"Tim Duncan\"     | 42    |\n| \"Tiago Splitter\" | 34    |\n+------------------+-------+\n</code></pre> <p>If you use <code>STARTS WITH \"t\"</code> in the preceding statement, an empty set is returned because no name in the dataset starts with the lowercase <code>t</code>.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.name STARTS WITH \"t\" \\\n        RETURN v.name, v.age;\nEmpty set (time spent 5080/6474 us)\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#ends_with","title":"<code>ENDS WITH</code>","text":"<p><code>ENDS WITH</code> will match the ending of a string.</p> <p>The following example uses <code>ENDS WITH \"r\"</code> to retrieve the information of players whose name ends with <code>r</code>.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.name ENDS WITH \"r\" \\\n        RETURN v.name, v.age;\n+------------------+-------+\n| v.name           | v.age |\n+------------------+-------+\n| \"Vince Carter\"   | 42    |\n| \"Tony Parker\"    | 36    |\n| \"Tiago Splitter\" | 34    |\n+------------------+-------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#contains","title":"<code>CONTAINS</code>","text":"<p><code>CONTAINS</code> will match a certain part of a string.</p> <p>The following example uses <code>CONTAINS \"Pa\"</code> to match the information of players whose name contains <code>Pa</code>.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.name CONTAINS \"Pa\" \\\n        RETURN v.name, v.age;\n+---------------+-------+\n| v.name        | v.age |\n+---------------+-------+\n| \"Paul George\" | 28    |\n| \"Tony Parker\" | 36    |\n| \"Paul Gasol\"  | 38    |\n| \"Chris Paul\"  | 33    |\n+---------------+-------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#negative_string_matching","title":"Negative string matching","text":"<p>You can use the boolean operator <code>NOT</code> to negate a string matching condition.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE NOT v.name ENDS WITH \"R\" \\\n        RETURN v.name, v.age;\n+-------------------------+-------+\n| v.name                  | v.age |\n+-------------------------+-------+\n| \"Rajon Rondo\"           | 33    |\n| \"Rudy Gay\"              | 32    |\n| \"Dejounte Murray\"       | 29    |\n| \"Chris Paul\"            | 33    |\n| \"Carmelo Anthony\"       | 34    |\n+-------------------------+-------+\n...\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#filter_on_lists","title":"Filter on lists","text":""},{"location":"3.ngql-guide/8.clauses-and-options/where/#match_values_in_a_list","title":"Match values in a list","text":"<p>Use the <code>IN</code> operator to check if a value is in a specific list.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.age IN range(20,25) \\\n        RETURN v.name, v.age;\n+-------------------------+-------+\n| v.name                  | v.age |\n+-------------------------+-------+\n| \"Ben Simmons\"           | 22    |\n| \"Kristaps Porzingis\"    | 23    |\n| \"Luka Doncic\"           | 20    |\n| \"Kyle Anderson\"         | 25    |\n| \"Giannis Antetokounmpo\" | 24    |\n| \"Joel Embiid\"           | 25    |\n+-------------------------+-------+\n\nnebula&gt; LOOKUP ON player \\\n        WHERE player.age IN [25,28]  \\\n        YIELD properties(vertex).name, properties(vertex).age;\n+-------------+-------------------------+------------------------+\n| VertexID    | properties(VERTEX).name | properties(VERTEX).age |\n+-------------+-------------------------+------------------------+\n| \"player106\" | \"Kyle Anderson\"         | 25                     |\n| \"player135\" | \"Damian Lillard\"        | 28                     |\n| \"player130\" | \"Joel Embiid\"           | 25                     |\n| \"player131\" | \"Paul George\"           | 28                     |\n| \"player123\" | \"Ricky Rubio\"           | 28                     |\n+-------------+-------------------------+------------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/where/#match_values_not_in_a_list","title":"Match values not in a list","text":"<p>Use <code>NOT</code> before <code>IN</code> to rule out the values in a list.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WHERE v.age NOT IN range(20,25) \\\n        RETURN v.name AS Name, v.age AS Age \\\n        ORDER BY Age;\n+---------------------+-----+\n| Name                | Age |\n+---------------------+-----+\n| \"Kyrie Irving\"      | 26  |\n| \"Cory Joseph\"       | 27  |\n| \"Damian Lillard\"    | 28  |\n| \"Paul George\"       | 28  |\n| \"Ricky Rubio\"       | 28  |\n+---------------------+-----+\n...\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/with/","title":"WITH","text":"<p>The <code>WITH</code> clause can retrieve the output from a query part, process it, and pass it to the next query part as the input.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>This topic applies to openCypher syntax only.</p> <p>Note</p> <p><code>WITH</code> has a similar function with the Pipe symbol in native nGQL, but they work in different ways. DO NOT use pipe symbols in the openCypher syntax or use <code>WITH</code> in native nGQL statements.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#combine_statements_and_form_a_composite_query","title":"Combine statements and form a composite query","text":"<p>Use a <code>WITH</code> clause to combine statements and transfer the output of a statement as the input of another statement.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#example_1","title":"Example 1","text":"<p>The following statement:</p> <ol> <li>Matches a path.</li> <li>Outputs all the vertices on the path to a list with the <code>nodes()</code> function.</li> <li>Unwinds the list into rows.</li> <li>Removes duplicated vertices and returns a set of distinct vertices.</li> </ol> <pre><code>nebula&gt; MATCH p=(v:player{name:\"Tim Duncan\"})--() \\\n        WITH nodes(p) AS n \\\n        UNWIND n AS n1 \\\n        RETURN DISTINCT n1;\n+-----------------------------------------------------------+\n| n1                                                        |\n+-----------------------------------------------------------+\n| (\"player100\" :player{age: 42, name: \"Tim Duncan\"})        |\n| (\"player101\" :player{age: 36, name: \"Tony Parker\"})       |\n| (\"team204\" :team{name: \"Spurs\"})                          |\n| (\"player102\" :player{age: 33, name: \"LaMarcus Aldridge\"}) |\n| (\"player125\" :player{age: 41, name: \"Manu Ginobili\"})     |\n| (\"player104\" :player{age: 32, name: \"Marco Belinelli\"})   |\n| (\"player144\" :player{age: 47, name: \"Shaquille O'Neal\"})  |\n| (\"player105\" :player{age: 31, name: \"Danny Green\"})       |\n| (\"player113\" :player{age: 29, name: \"Dejounte Murray\"})   |\n| (\"player107\" :player{age: 32, name: \"Aron Baynes\"})       |\n| (\"player109\" :player{age: 34, name: \"Tiago Splitter\"})    |\n| (\"player108\" :player{age: 36, name: \"Boris Diaw\"})        |\n+-----------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#example_2","title":"Example 2","text":"<p>The following statement:</p> <ol> <li>Matches the vertex with the VID <code>player100</code>.</li> <li>Outputs all the tags of the vertex into a list with the <code>labels()</code> function.</li> <li>Unwinds the list into rows.</li> <li>Returns the output.</li> </ol> <pre><code>nebula&gt; MATCH (v) \\\n        WHERE id(v)==\"player100\" \\\n        WITH labels(v) AS tags_unf \\\n        UNWIND tags_unf AS tags_f \\\n        RETURN tags_f;\n+----------+\n| tags_f   |\n+----------+\n| \"star\"   |\n| \"player\" |\n| \"person\" |\n+----------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#filter_composite_queries","title":"Filter composite queries","text":"<p><code>WITH</code> can work as a filter in the middle of a composite query.</p> <pre><code>nebula&gt; MATCH (v:player)--&gt;(v2:player) \\\n        WITH DISTINCT v2 AS v2, v2.age AS Age \\\n        ORDER BY Age \\\n        WHERE Age&lt;25 \\\n        RETURN v2.name AS Name, Age;\n+----------------------+-----+\n| Name                 | Age |\n+----------------------+-----+\n| \"Luka Doncic\"        | 20  |\n| \"Ben Simmons\"        | 22  |\n| \"Kristaps Porzingis\" | 23  |\n+----------------------+-----+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#process_the_output_before_using_collect","title":"Process the output before using collect()","text":"<p>Use a <code>WITH</code> clause to sort and limit the output before using <code>collect()</code> to transform the output into a list.</p> <pre><code>nebula&gt; MATCH (v:player) \\\n        WITH v.name AS Name \\\n        ORDER BY Name DESC \\\n        LIMIT 3 \\\n        RETURN collect(Name);\n+-----------------------------------------------+\n| collect(Name)                                 |\n+-----------------------------------------------+\n| [\"Yao Ming\", \"Vince Carter\", \"Tracy McGrady\"] |\n+-----------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/with/#use_with_return","title":"Use with RETURN","text":"<p>Set an alias using a <code>WITH</code> clause, and then output the result through a <code>RETURN</code> clause.</p> <pre><code>nebula&gt; WITH [1, 2, 3] AS list  RETURN 3 IN list AS r;\n+------+\n| r    |\n+------+\n| true |\n+------+\n\nnebula&gt; WITH 4 AS one, 3 AS two RETURN one &gt; two AS result;\n+--------+\n| result |\n+--------+\n| true   |\n+--------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/yield/","title":"YIELD","text":"<p><code>YIELD</code> defines the output of an nGQL query.</p> <p><code>YIELD</code> can lead a clause or a statement:</p> <ul> <li>A <code>YIELD</code> clause works in nGQL statements such as <code>GO</code>, <code>FETCH</code>, or <code>LOOKUP</code>.</li> </ul> <ul> <li>A <code>YIELD</code> statement works in a composite query or independently.</li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/yield/#opencypher_compatibility","title":"OpenCypher compatibility","text":"<p>This topic applies to native nGQL only. For the openCypher syntax, use <code>RETURN</code>.</p> <p><code>YIELD</code> has different functions in openCypher and nGQL.</p> <ul> <li> <p>In openCypher, <code>YIELD</code> is used in the <code>CALL[\u2026YIELD]</code> clause to specify the output of the procedure call.</p> <p>Note</p> <p>NGQL does not support <code>CALL[\u2026YIELD]</code> yet.</p> </li> </ul> <ul> <li>In nGQL, <code>YIELD</code> works like <code>RETURN</code> in openCypher.</li> </ul> <p>Note</p> <p>In the following examples, <code>$$</code> and <code>$-</code> are reference operators. For more information, see Operators.</p>"},{"location":"3.ngql-guide/8.clauses-and-options/yield/#yield_clauses","title":"YIELD clauses","text":""},{"location":"3.ngql-guide/8.clauses-and-options/yield/#syntax","title":"Syntax","text":"<pre><code>YIELD [DISTINCT] &lt;col&gt; [AS &lt;alias&gt;] [, &lt;col&gt; [AS &lt;alias&gt;] ...];\n</code></pre> Parameter Description <code>DISTINCT</code> Aggregates the output and makes the statement return a distinct result set. <code>col</code> A field to be returned. If no alias is set, <code>col</code> will be a column name in the output. <code>alias</code> An alias for <code>col</code>. It is set after the keyword <code>AS</code> and will be a column name in the output."},{"location":"3.ngql-guide/8.clauses-and-options/yield/#use_a_yield_clause_in_a_statement","title":"Use a YIELD clause in a statement","text":"<ul> <li>Use <code>YIELD</code> with <code>GO</code>:<pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD properties($$).name AS Friend, properties($$).age AS Age;\n+-----------------+-----+\n| Friend          | Age |\n+-----------------+-----+\n| \"Tony Parker\"   | 36  |\n| \"Manu Ginobili\" | 41  |\n+-----------------+-----+\n</code></pre> </li> </ul> <ul> <li>Use <code>YIELD</code> with <code>FETCH</code>:<pre><code>nebula&gt; FETCH PROP ON player \"player100\" \\\n        YIELD properties(vertex).name;\n+-------------+-------------------------+\n| VertexID    | properties(VERTEX).name |\n+-------------+-------------------------+\n| \"player100\" | UNKNOWN_PROP            |\n+-------------+-------------------------+\n</code></pre> </li> </ul> <ul> <li>Use <code>YIELD</code> with <code>LOOKUP</code>:<pre><code>nebula&gt; LOOKUP ON player WHERE player.name == \"Tony Parker\" \\\n        YIELD properties(vertex).name, properties(vertex).age;\n+-------------+-------------------------+------------------------+\n| VertexID    | properties(VERTEX).name | properties(VERTEX).age |\n+-------------+-------------------------+------------------------+\n| \"player101\" | \"Tony Parker\"           | 36                     |\n+-------------+-------------------------+------------------------+\n</code></pre> </li> </ul>"},{"location":"3.ngql-guide/8.clauses-and-options/yield/#yield_statements","title":"YIELD statements","text":""},{"location":"3.ngql-guide/8.clauses-and-options/yield/#syntax_1","title":"Syntax","text":"<pre><code>YIELD [DISTINCT] &lt;col&gt; [AS &lt;alias&gt;] [, &lt;col&gt; [AS &lt;alias&gt;] ...]\n[WHERE &lt;conditions&gt;];\n</code></pre> <p>| Parameter    | Description                                                                                             | |--------------+---------------------------------------------------------------------------------------------------------| | <code>DISTINCT</code>   | Aggregates the output and makes the statement return a distinct result set.                             | | <code>col</code>        | A field to be returned. If no alias is set, <code>col</code> will be a column name in the output.                  | | <code>alias</code>      | An alias for <code>col</code>. It is set after the keyword <code>AS</code> and will be a column name in the output.           | | <code>conditions</code> | Conditions set in a <code>WHERE</code> clause to filter the output. For more information, see <code>WHERE</code>. |</p>"},{"location":"3.ngql-guide/8.clauses-and-options/yield/#use_a_yield_statement_in_a_composite_query","title":"Use a YIELD statement in a composite query","text":"<p>In a composite query, a <code>YIELD</code> statement accepts, filters, and modifies the result set of the preceding statement, and then outputs it.</p> <p>The following query finds the players that \"player100\" follows and calculates their average age.</p> <pre><code>nebula&gt; GO FROM \"player100\" OVER follow \\\n        YIELD dst(edge) AS ID \\\n        | FETCH PROP ON player $-.ID \\\n        YIELD properties(vertex).age AS Age \\\n        | YIELD AVG($-.Age) as Avg_age, count(*)as Num_friends;\n+---------+-------------+\n| Avg_age | Num_friends |\n+---------+-------------+\n| 38.5    | 2           |\n+---------+-------------+\n</code></pre> <p>The following query finds the players that \"player101\" follows with the follow degrees greater than 90.</p> <pre><code>nebula&gt; $var1 = GO FROM \"player101\" OVER follow \\\n        YIELD properties(edge).degree AS Degree, dst(edge) as ID; \\\n        YIELD $var1.ID AS ID WHERE $var1.Degree &gt; 90;\n+-------------+\n| ID          |\n+-------------+\n| \"player100\" |\n| \"player125\" |\n+-------------+\n</code></pre>"},{"location":"3.ngql-guide/8.clauses-and-options/yield/#use_a_standalone_yield_statement","title":"Use a standalone YIELD statement","text":"<p>A <code>YIELD</code> statement can calculate a valid expression and output the result.</p> <pre><code>nebula&gt; YIELD rand32(1, 6);\n+-------------+\n| rand32(1,6) |\n+-------------+\n| 3           |\n+-------------+\n\nnebula&gt; YIELD \"Hel\" + \"\\tlo\" AS string1, \", World!\" AS string2;\n+-------------+------------+\n| string1     | string2    |\n+-------------+------------+\n| \"Hel    lo\" | \", World!\" |\n+-------------+------------+\n\nnebula&gt; YIELD hash(\"Tim\") % 100;\n+-----------------+\n| (hash(Tim)%100) |\n+-----------------+\n| 42              |\n+-----------------+\n\nnebula&gt; YIELD \\\n      CASE 2+3 \\\n      WHEN 4 THEN 0 \\\n      WHEN 5 THEN 1 \\\n      ELSE -1 \\\n      END \\\n      AS result;\n+--------+\n| result |\n+--------+\n| 1      |\n+--------+\n</code></pre>"},{"location":"3.ngql-guide/9.space-statements/1.create-space/","title":"CREATE SPACE","text":"<p>Graph spaces are used to store data in a physically isolated way in NebulaGraph, which is similar to the database concept in MySQL. The <code>CREATE SPACE</code> statement can create a new graph space or clone the schema of an existing graph space.</p>"},{"location":"3.ngql-guide/9.space-statements/1.create-space/#prerequisites","title":"Prerequisites","text":"<p>Only the God role can use the <code>CREATE SPACE</code> statement. For more information, see AUTHENTICATION.</p>"},{"location":"3.ngql-guide/9.space-statements/1.create-space/#syntax","title":"Syntax","text":""},{"location":"3.ngql-guide/9.space-statements/1.create-space/#create_graph_spaces","title":"Create graph spaces","text":"<pre><code>CREATE SPACE [IF NOT EXISTS] &lt;graph_space_name&gt; (\n    [partition_num = &lt;partition_number&gt;,]\n    [replica_factor = &lt;replica_number&gt;,]\n    vid_type = {FIXED_STRING(&lt;N&gt;) | INT[64]}\n    )\n    [ON &lt;group_name&gt;]\n    [COMMENT = '&lt;comment&gt;'];\n</code></pre> Parameter Description <code>IF NOT EXISTS</code> Detects if the related graph space exists. If it does not exist, a new one will be created. The graph space existence detection here only compares the graph space name (excluding properties). <code>&lt;graph_space_name&gt;</code> Uniquely identifies a graph space in a NebulaGraph instance. The name of the graph space is case-sensitive and allows letters, numbers, or underlines. Keywords and reserved words are not allowed. <code>partition_num</code> Specifies the number of partitions in each replica. The suggested number is five times the number of the hard disks in the cluster. For example, if you have 3 hard disks in the cluster, we recommend that you set 15 partitions. The default value is 100. <code>replica_factor</code> Specifies the number of replicas in the cluster. The suggested number is 3 in a production environment and 1 in a test environment. The replica number must be an odd number for the need of quorum-based voting. The default value is 1. <code>vid_type</code> A required parameter. Specifies the VID type in a graph space. Available values are <code>FIXED_STRING(N)</code> and <code>INT64</code>. <code>INT</code> equals to <code>INT64</code>. <code>FIXED_STRING(&lt;N&gt;)</code> specifies the VID as a string, while <code>INT64</code> specifies it as an integer. <code>N</code> represents the maximum length of the VIDs. If you set a VID that is longer than <code>N</code> characters, NebulaGraph throws an error. <code>ON &lt;group_name&gt;</code> Specifies the Group to which a space belongs. For more information, see Group&amp;Zone. <code>COMMENT</code> The remarks of the graph space. The maximum length is 256 bytes. By default, there is no comments on a space. <p>Caution</p> <p>If the replica number is set to one, you will not be able to load balance or scale out the NebulaGraph Storage Service with the BALANCE statement.</p> <p>Caution</p> <p>Restrictions on VID type change and VID length</p> <ol> <li> <p>In NebulaGraph 1.x, the VID type can only be <code>INT64</code> and does not support string. In NebulaGraph 2.x, the VID type can be both <code>INT64</code> and <code>FIXED_STRING(&lt;N&gt;)</code>. You should specify the VID type when creating a graph space and keep consistency when using the <code>INSERT</code> statement. Otherwise, NebulaGraph throws <code>Wrong vertex id type: 1001</code>.</p> </li> <li> <p>The length of the VID should not be longer than <code>N</code> characters. If it exceeds <code>N</code>, NebulaGraph throws <code>The VID must be a 64-bit integer or a string fitting space vertex id length limit.</code>.</p> </li> </ol> <p>Legacy version compatibility</p> <p>In the 2.x releases before 2.5.0, <code>vid_type</code> is not a required parameter and its default value is <code>FIXED_STRING(8)</code>.</p> <p>Note</p> <p><code>graph_space_name</code>, <code>partition_num</code>, <code>replica_factor</code>, <code>vid_type</code>, and <code>comment</code> cannot be modified once set. To modify them, drop the current working graph space with <code>DROP SPACE</code> and create a new one with <code>CREATE SPACE</code>.</p>"},{"location":"3.ngql-guide/9.space-statements/1.create-space/#clone_graph_spaces","title":"Clone graph spaces","text":"<pre><code>CREATE SPACE &lt;new_graph_space_name&gt; AS &lt;old_graph_space_name&gt;;\n</code></pre> Parameter Description <code>&lt;new_graph_space_name&gt;</code> The name of the graph space that is newly created. The name of the graph space is case-sensitive and allows letters, numbers, or underlines. Keywords and reserved words are not allowed. When a new graph space is created, the schema of the old graph space <code>&lt;old_graph_space_name&gt;</code> will be cloned, including its parameters (the number of partitions and replicas, etc.), Tag, Edge type, and native indexes. <code>&lt;old_graph_space_name&gt;</code> The name of the graph space that already exists."},{"location":"3.ngql-guide/9.space-statements/1.create-space/#examples","title":"Examples","text":"<pre><code># The following example creates a graph space with a specified VID type and the maximum length. Other fields still use the default values.\nnebula&gt; CREATE SPACE IF NOT EXISTS my_space_1 (vid_type=FIXED_STRING(30));\n\n# The following example creates a graph space with a specified partition number, replica number, and VID type.\nnebula&gt; CREATE SPACE IF NOT EXISTS my_space_2 (partition_num=15, replica_factor=1, vid_type=FIXED_STRING(30));\n\n#  The following example creates a graph space with a specified partition number, replica number, and VID type, and adds a comment on it.\nnebula&gt; CREATE SPACE IF NOT EXISTS my_space_3 (partition_num=15, replica_factor=1, vid_type=FIXED_STRING(30)) comment=\"Test the graph space\";\n\n# Clone a graph space.\nnebula&gt; CREATE SPACE IF NOT EXISTS my_space_4 as my_space_3;\nnebula&gt; SHOW CREATE SPACE my_space_4;\n+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Space        | Create Space                                                                                                                                                            |\n+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| \"my_space_4\" | \"CREATE SPACE `my_space_4` (partition_num = 15, replica_factor = 1, charset = utf8, collate = utf8_bin, vid_type = FIXED_STRING(30)) ON default comment = 'Test the graph space'\"  |\n+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/9.space-statements/1.create-space/#implementation_of_the_operation","title":"Implementation of the operation","text":"<p>Caution</p> <p>Trying to use a newly created graph space may fail because the creation is implemented asynchronously. To make sure the follow-up operations work as expected, Wait for two heartbeat cycles, i.e., 20 seconds. To change the heartbeat interval, modify the <code>heartbeat_interval_secs</code> parameter in the configuration files for all services. If the heartbeat interval is too short (i.e., less than 5 seconds), disconnection between peers may happen because of the misjudgment of machines in the distributed system.</p>"},{"location":"3.ngql-guide/9.space-statements/1.create-space/#check_partition_distribution","title":"Check partition distribution","text":"<p>On some large clusters, the partition distribution is possibly unbalanced because of the different startup times. You can run the following command to do a check of the machine distribution.</p> <pre><code>nebula&gt; SHOW HOSTS;\n+-------------+------+----------+--------------+--------------------------------+--------------------------------+\n| Host        | Port | Status   | Leader count | Leader distribution            | Partition distribution         |\n+-------------+------+----------+--------------+--------------------------------+--------------------------------+\n| \"storaged0\" | 9779 | \"ONLINE\" | 8            | \"basketballplayer:3, test:5\"   | \"basketballplayer:10, test:10\" |\n| \"storaged1\" | 9779 | \"ONLINE\" | 9            | \"basketballplayer:4, test:5\"   | \"basketballplayer:10, test:10\" |\n| \"storaged2\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"           | \"basketballplayer:10, test:10\" |\n| \"Total\"     |      |          | 20           | \"basketballplayer:10, test:10\" | \"basketballplayer:30, test:30\" |\n+-------------+------+----------+--------------+--------------------------------+--------------------------------+\n</code></pre> <p>To balance the request loads, use the following command.</p> <pre><code>nebula&gt; BALANCE LEADER;\nnebula&gt; SHOW HOSTS;\n+-------------+------+----------+--------------+--------------------------------+--------------------------------+\n| Host        | Port | Status   | Leader count | Leader distribution            | Partition distribution         |\n+-------------+------+----------+--------------+--------------------------------+--------------------------------+\n| \"storaged0\" | 9779 | \"ONLINE\" | 7            | \"basketballplayer:3, test:4\"   | \"basketballplayer:10, test:10\" |\n| \"storaged1\" | 9779 | \"ONLINE\" | 7            | \"basketballplayer:4, test:3\"   | \"basketballplayer:10, test:10\" |\n| \"storaged2\" | 9779 | \"ONLINE\" | 6            | \"basketballplayer:3, test:3\"   | \"basketballplayer:10, test:10\" |\n| \"Total\"     |      |          | 20           | \"basketballplayer:10, test:10\" | \"basketballplayer:30, test:30\" |\n+-------------+------+----------+--------------+--------------------------------+--------------------------------+\n</code></pre>"},{"location":"3.ngql-guide/9.space-statements/2.use-space/","title":"USE","text":"<p><code>USE</code> specifies a graph space as the current working graph space for subsequent queries.</p>"},{"location":"3.ngql-guide/9.space-statements/2.use-space/#prerequisites","title":"Prerequisites","text":"<p>Running the <code>USE</code> statement requires some privileges for the graph space. Otherwise, NebulaGraph throws an error.</p>"},{"location":"3.ngql-guide/9.space-statements/2.use-space/#syntax","title":"Syntax","text":"<pre><code>USE &lt;graph_space_name&gt;;\n</code></pre>"},{"location":"3.ngql-guide/9.space-statements/2.use-space/#examples","title":"Examples","text":"<pre><code># The following example creates two sample spaces.\nnebula&gt; CREATE SPACE IF NOT EXISTS space1 (vid_type=FIXED_STRING(30));\nnebula&gt; CREATE SPACE IF NOT EXISTS space2 (vid_type=FIXED_STRING(30));\n\n# The following example specifies space1 as the current working graph space.\nnebula&gt; USE space1;\n\n# The following example specifies space2 as the current working graph space. Hereafter, you cannot read any data from space1, because these vertices and edges being traversed have no relevance with space1.\nnebula&gt; USE space2;\n</code></pre> <p>Caution</p> <p>You cannot use two graph spaces in one statement.</p> <p>Different from Fabric Cypher, graph spaces in NebulaGraph are fully isolated from each other. Making a graph space as the working graph space prevents you from accessing other spaces. The only way to traverse in a new graph space is to switch by the <code>USE</code> statement. In Fabric Cypher, you can use two graph spaces in one statement (using the <code>USE + CALL</code> syntax). But in NebulaGraph, you can only use one graph space in one statement.</p>"},{"location":"3.ngql-guide/9.space-statements/3.show-spaces/","title":"SHOW SPACES","text":"<p><code>SHOW SPACES</code> lists all the graph spaces in the NebulaGraph examples.</p>"},{"location":"3.ngql-guide/9.space-statements/3.show-spaces/#syntax","title":"Syntax","text":"<pre><code>SHOW SPACES;\n</code></pre>"},{"location":"3.ngql-guide/9.space-statements/3.show-spaces/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW SPACES;\n+--------------------+\n| Name               |\n+--------------------+\n| \"cba\"              |\n| \"basketballplayer\" |\n+--------------------+\n</code></pre> <p>To create graph spaces, see CREATE SPACE.</p>"},{"location":"3.ngql-guide/9.space-statements/4.describe-space/","title":"DESCRIBE SPACE","text":"<p><code>DESCRIBE SPACE</code> returns the information about the specified graph space.</p>"},{"location":"3.ngql-guide/9.space-statements/4.describe-space/#syntax","title":"Syntax","text":"<p>You can use <code>DESC</code> instead of <code>DESCRIBE</code> for short.</p> <pre><code>DESC[RIBE] SPACE &lt;graph_space_name&gt;;\n</code></pre> <p>The <code>DESCRIBE SPACE</code> statement is different from the <code>SHOW SPACES</code> statement. For details about <code>SHOW SPACES</code>, see SHOW SPACES.</p>"},{"location":"3.ngql-guide/9.space-statements/4.describe-space/#example","title":"Example","text":"<pre><code>nebula&gt; DESCRIBE SPACE basketballplayer;\n+----+--------------------+------------------+----------------+---------+------------+--------------------+-------------+-----------+---------+\n| ID | Name               | Partition Number | Replica Factor | Charset | Collate    | Vid Type           | Atomic Edge | Group     | Comment |\n+----+--------------------+------------------+----------------+---------+------------+--------------------+-------------+-----------+---------+\n| 1  | \"basketballplayer\" | 10               | 1              | \"utf8\"  | \"utf8_bin\" | \"FIXED_STRING(32)\" | false       | \"default\" |         |\n+----+--------------------+------------------+----------------+---------+------------+--------------------+-------------+-----------+---------+\n</code></pre>"},{"location":"3.ngql-guide/9.space-statements/5.drop-space/","title":"DROP SPACE","text":"<p><code>DROP SPACE</code> deletes everything in the specified graph space.</p>"},{"location":"3.ngql-guide/9.space-statements/5.drop-space/#prerequisites","title":"Prerequisites","text":"<p>Only the God role can use the <code>DROP SPACE</code> statement. For more information, see AUTHENTICATION.</p>"},{"location":"3.ngql-guide/9.space-statements/5.drop-space/#syntax","title":"Syntax","text":"<pre><code>DROP SPACE [IF EXISTS] &lt;graph_space_name&gt;;\n</code></pre> <p>You can use the <code>IF EXISTS</code> keywords when dropping spaces. These keywords automatically detect if the related graph space exists. If it exists, it will be deleted. Otherwise, no graph space will be deleted.</p> <p>The <code>DROP SPACE</code> statement does not immediately remove all the files and directories from the disk. You can specify another graph space with the <code>USE</code> statement and <code>submit job compact</code>.</p> <p>Caution<p>BE CAUTIOUS about running the <code>DROP SPACE</code> statement.</p> </p>"},{"location":"4.deployment-and-installation/1.resource-preparations/","title":"Prepare resources for compiling, installing, and running NebulaGraph","text":"<p>This topic describes the requirements and suggestions for compiling and installing NebulaGraph, as well as how to estimate the resource you need to reserve for running a NebulaGraph cluster.</p>"},{"location":"4.deployment-and-installation/1.resource-preparations/#reading_guide","title":"Reading guide","text":"<p>If you are reading this topic with the questions listed below, click them to jump to their answers.</p> <ul> <li>What do I need to compile NebulaGraph?</li> </ul> <ul> <li>What do I need to run NebulaGraph in a test environment?</li> </ul> <ul> <li>What do I need to run NebulaGraph in a production environment?</li> </ul> <ul> <li>How much memory and disk space do I need to reserve for my NebulaGraph cluster?</li> </ul>"},{"location":"4.deployment-and-installation/1.resource-preparations/#requirements_for_compiling_the_nebulagraph_source_code","title":"Requirements for compiling the NebulaGraph source code","text":""},{"location":"4.deployment-and-installation/1.resource-preparations/#hardware_requirements_for_compiling_nebulagraph","title":"Hardware requirements for compiling NebulaGraph","text":"Item Requirement CPU architecture x86_64 Memory 4 GB Disk 10 GB, SSD"},{"location":"4.deployment-and-installation/1.resource-preparations/#supported_operating_systems_for_compiling_nebulagraph","title":"Supported operating systems for compiling NebulaGraph","text":"<p>For now, we can only compile NebulaGraph in the Linux system. We recommend that you use any Linux system with kernel version <code>2.6.32</code> or above.</p>"},{"location":"4.deployment-and-installation/1.resource-preparations/#software_requirements_for_compiling_nebulagraph","title":"Software requirements for compiling NebulaGraph","text":"<p>You must have the correct version of the software listed below to compile NebulaGraph. If they are not as required or you are not sure, follow the steps in Prepare software for compiling NebulaGraph to get them ready.</p> Software Version Note glibc 2.17 or above You can run <code>ldd --version</code> to check the glibc version. make Any stable version - m4 Any stable version - git Any stable version - wget Any stable version - unzip Any stable version - xz Any stable version - readline-devel Any stable version - ncurses-devel Any stable version - zlib-devel Any stable version - gcc 7.5.0 or above You can run <code>gcc -v</code> to check the gcc version. gcc-c++ Any stable version - cmake 3.9.0 or above You can run <code>cmake --version</code> to check the cmake version. gettext Any stable version - curl Any stable version - redhat-lsb-core Any stable version - libstdc++-static Any stable version Only needed in CentOS 8+, RedHat 8+, and Fedora systems. libasan Any stable version Only needed in CentOS 8+, RedHat 8+, and Fedora systems. bzip2 Any stable version - <p>Other third-party software will be automatically downloaded and installed to the <code>build</code> directory at the configure (cmake) stage.</p>"},{"location":"4.deployment-and-installation/1.resource-preparations/#prepare_software_for_compiling_nebulagraph","title":"Prepare software for compiling NebulaGraph","text":"<p>This section guides you through the downloading and installation of software required for compiling NebulaGraph.</p> <ol> <li> <p>Install dependencies.</p> <ul> <li>For CentOS, RedHat, and Fedora users, run the following commands.<pre><code>$ yum update\n$ yum install -y make \\\nm4 \\\ngit \\\nwget \\\nunzip \\\nxz \\\nreadline-devel \\\nncurses-devel \\\nzlib-devel \\\ngcc \\\ngcc-c++ \\\ncmake \\\ngettext \\\ncurl \\\nredhat-lsb-core \\\nbzip2\n  // For CentOS 8+, RedHat 8+, and Fedora, install libstdc++-static and libasan as well\n$ yum install -y libstdc++-static libasan\n</code></pre> </li> </ul> <ul> <li>For Debian and Ubuntu users, run the following commands.<pre><code>$ apt-get update\n$ apt-get install -y make \\\nm4 \\\ngit \\\nwget \\\nunzip \\\nxz-utils \\\ncurl \\\nlsb-core \\\nbuild-essential \\\nlibreadline-dev \\\nncurses-dev \\\ncmake \\\ngettext\n</code></pre> </li> </ul> </li> <li> <p>Check if the GCC and cmake on your host are in the right version. See Software requirements for compiling NebulaGraph for the required versions.</p> <pre><code>$ g++ --version\n$ cmake --version\n</code></pre> <p>If your GCC and CMake are in the right version, then you are all set. If they are not, follow the sub-steps as follows.</p> <ol> <li> <p>Clone the <code>nebula</code> repository to your host.</p> <pre><code>$ git clone -b v2.6.2 https://github.com/vesoft-inc/nebula-common.git\n</code></pre> <p>Users can use the <code>--branch</code> or <code>-b</code> option to specify the branch to be cloned. For example, for 2.6.2, run the following  command.</p> <pre><code>$ git clone --branch v2.6.2 https://github.com/vesoft-inc/nebula-common.git\n</code></pre> </li> <li> <p>Make <code>nebula</code> the current working directory.</p> <pre><code>$ cd nebula\n</code></pre> </li> <li> <p>Run the following commands to install and enable CMake and GCC.</p> <pre><code>// Install CMake.\n$ ./third-party/install-cmake.sh cmake-install\n\n// Enable CMake.\n$ source cmake-install/bin/enable-cmake.sh\n\n// Authorize the write privilege to the opt directory.\n$ sudo mkdir /opt/vesoft &amp;&amp; sudo chmod -R a+w /opt/vesoft\n\n// Install GCC. Installing GCC to the opt directory requires the write privilege. And users can change it to other locations.\n$ ./third-party/install-gcc.sh --prefix=/opt\n\n// Enable GCC.\n$ source /opt/vesoft/toolset/gcc/7.5.0/enable\n</code></pre> </li> </ol> </li> <li> <p>Execute the script <code>install-third-party.sh</code>.</p> <pre><code>$ ./third-party/install-third-party.sh\n</code></pre> </li> </ol>"},{"location":"4.deployment-and-installation/1.resource-preparations/#requirements_and_suggestions_for_installing_nebulagraph_in_test_environments","title":"Requirements and suggestions for installing NebulaGraph in test environments","text":""},{"location":"4.deployment-and-installation/1.resource-preparations/#hardware_requirements_for_test_environments","title":"Hardware requirements for test environments","text":"Item Requirement CPU architecture x86_64 Number of CPU core 4 Memory 8 GB Disk 100 GB, SSD"},{"location":"4.deployment-and-installation/1.resource-preparations/#supported_operating_systems_for_test_environments","title":"Supported operating systems for test environments","text":"<p>For now, we can only install NebulaGraph in the Linux system. To install NebulaGraph in a test environment, we recommend that you use any Linux system with kernel version <code>3.9</code> or above.</p>"},{"location":"4.deployment-and-installation/1.resource-preparations/#suggested_service_architecture_for_test_environments","title":"Suggested service architecture for test environments","text":"Process Suggested number metad (the metadata service process) 1 storaged (the storage service process) 1 or more graphd (the query engine service process) 1 or more <p>For example, for a single-machine test environment, you can deploy 1 metad, 1 storaged, and 1 graphd processes in the machine.</p> <p>For a more common test environment, such as a cluster of 3 machines (named as A, B, and C), you can deploy NebulaGraph as follows:</p> Machine name Number of metad Number of storaged Number of graphd A 1 1 1 B None 1 1 C None 1 1"},{"location":"4.deployment-and-installation/1.resource-preparations/#requirements_and_suggestions_for_installing_nebulagraph_in_production_environments","title":"Requirements and suggestions for installing NebulaGraph in production environments","text":""},{"location":"4.deployment-and-installation/1.resource-preparations/#hardware_requirements_for_production_environments","title":"Hardware requirements for production environments","text":"Item Requirement CPU architecture x86_64 Number of CPU core 48 Memory 96 GB Disk 2 * 900 GB, NVMe SSD"},{"location":"4.deployment-and-installation/1.resource-preparations/#supported_operating_systems_for_production_environments","title":"Supported operating systems for production environments","text":"<p>For now, we can only install NebulaGraph in the Linux system. To install NebulaGraph in a production environment, we recommend that you use any Linux system with kernel version 3.9 or above.</p> <p>Users can adjust some of the kernel parameters to better accommodate the need for running NebulaGraph. For more information, see kernel configuration.</p>"},{"location":"4.deployment-and-installation/1.resource-preparations/#suggested_service_architecture_for_production_environments","title":"Suggested service architecture for production environments","text":"<p>Danger</p> <p>DO NOT deploy a cluster across IDCs.</p> Process Suggested number metad (the metadata service process) 3 storaged (the storage service process) 3 or more graphd (the query engine service process) 3 or more <p>Each metad process automatically creates and maintains a replica of the metadata. Usually, you need to deploy three metad processes and only three.</p> <p>The number of storaged processes does not affect the number of graph space replicas.</p> <p>Users can deploy multiple processes on a single machine. For example, on a cluster of 5 machines (named as A, B, C, D, and E), you can deploy NebulaGraph as follows:</p> Machine name Number of metad Number of storaged Number of graphd A 1 1 1 B 1 1 1 C 1 1 1 D None 1 1 E None 1 1"},{"location":"4.deployment-and-installation/1.resource-preparations/#capacity_requirements_for_running_a_nebulagraph_cluster","title":"Capacity requirements for running a NebulaGraph cluster","text":"<p>Users can estimate the memory, disk space, and partition number needed for a NebulaGraph cluster of 3 replicas as follows.</p> Resource Unit How to estimate Description Disk space for a cluster Bytes <code>the_sum_of_edge_number_and_vertex_number</code> * <code>average_bytes_of_properties</code> * 6 * 120% - Memory for a cluster Bytes [<code>the_sum_of_edge_number_and_vertex_number</code> * 15 + <code>the_number_of_RocksDB_instances</code> * (<code>write_buffer_size</code> * <code>max_write_buffer_number</code> + <code>rocksdb_block_cache</code>)] * 120% <code>write_buffer_size</code> and <code>max_write_buffer_number</code> are RocksDB parameters. For more information, see MemTable. For details about <code>rocksdb_block_cache</code>, see Memory usage in RocksDB. Number of partitions for a graph space - <code>the_number_of_disks_in_the_cluster</code> * <code>disk_partition_num_multiplier</code> <code>disk_partition_num_multiplier</code> is an integer between 2 and 10 (both including). Its value depends on the disk performance. Use 2 for HDD. <ul> <li>Question 1: Why do we multiply the disk space and memory by 120%?<p>Answer: The extra 20% is for buffer.</p> </li> </ul> <ul> <li> <p>Question 2: How to get the number of RocksDB instances?</p> <p>Answer: Each directory in the <code>--data_path</code> item in the <code>etc/nebula-storaged.conf</code> file corresponds to a RocksDB instance. Count the number of directories to get the RocksDB instance number.</p> <p>Note</p> <p>Users can decrease the memory size occupied by the bloom filter by adding <code>--enable_partitioned_index_filter=true</code> in <code>etc/nebula-storaged.conf</code>. But it may decrease the read performance in some random-seek cases.</p> </li> </ul>"},{"location":"4.deployment-and-installation/1.resource-preparations/#faq","title":"FAQ","text":""},{"location":"4.deployment-and-installation/1.resource-preparations/#about_storage_devices","title":"About storage devices","text":"<p>NebulaGraph is designed and implemented for NVMe SSD. All default parameters are optimized for the SSD devices and require extremely high IOPS and low latency.</p> <ul> <li>Due to the poor IOPS capability and long random seek latency, HDD is not recommended. Users may encounter many problems when using HDD.</li> </ul> <ul> <li>Do not use remote storage devices, such as NAS or SAN. Do not connect an external virtual hard disk based on HDFS or Ceph.</li> </ul> <ul> <li>Do not use RAID.</li> </ul> <ul> <li>Use local SSD devices.</li> </ul>"},{"location":"4.deployment-and-installation/1.resource-preparations/#about_cpu_architecture","title":"About CPU architecture","text":"<p>Enterpriseonly</p> <p>Only NebulaGraph 2.6.2 Enterprise Edition can be run or compiled on ARM architectures (including Apple Mac M1 or Huawei Kunpeng). Contact inquiry@vesoft.com for business supports.</p>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/","title":"Uninstall NebulaGraph","text":"<p>This topic describes how to uninstall NebulaGraph.</p> <p>Caution</p> <p>Before re-installing NebulaGraph on a machine, follow this topic to completely uninstall the old NebulaGraph, in case the remaining data interferes with the new services, including inconsistencies between Meta services.</p>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#prerequisite","title":"Prerequisite","text":"<p>The NebulaGraph services should be stopped before the uninstallation. For more information, see Manage NebulaGraph services.</p>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#step_1_delete_data_files_of_the_storage_and_meta_services","title":"Step 1: Delete data files of the Storage and Meta Services","text":"<p>If you have modified the <code>data_path</code> in the configuration files for the Meta Service and Storage Service, the directories where NebulaGraph stores data may not be in the installation path of NebulaGraph. Check the configuration files to confirm the data paths, and then manually delete the directories to clear all data.</p> <p>Note</p> <p>For a NebulaGraph cluster, delete the data files of all Storage and Meta servers.</p> <ol> <li> <p>Check the Storage Service disk settings. For example:</p> <pre><code>########## Disk ##########\n# Root data path. Split by comma. e.g. --data_path=/disk1/path1/,/disk2/path2/\n# One path per Rocksdb instance.\n--data_path=/nebula/data/storage\n</code></pre> </li> <li> <p>Check the Metad Service configurations and find the corresponding metadata directories.</p> </li> <li> <p>Delete the data and the directories found in step 2.</p> </li> </ol>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#step_2_delete_the_installation_directories","title":"Step 2: Delete the installation directories","text":"<p>Note</p> <p>Delete all installation directories, including the <code>cluster.id</code> file in them.</p> <p>The default installation path is <code>/usr/local/nebula</code>, which is specified by <code>--prefix</code> while installing NebulaGraph.</p>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#uninstall_nebulagraph_deployed_with_source_code","title":"Uninstall NebulaGraph deployed with source code","text":"<p>Find the installation directories of NebulaGraph, and delete them all.</p>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#uninstall_nebulagraph_deployed_with_rpm_packages","title":"Uninstall NebulaGraph deployed with RPM packages","text":"<ol> <li> <p>Run the following command to get the NebulaGraph version.</p> <pre><code>$ rpm -qa | grep \"nebula\"\n</code></pre> <p>The return message is as follows.</p> <pre><code>nebula-graph-2.6.2-1.x86_64\n</code></pre> </li> <li> <p>Run the following command to uninstall NebulaGraph.</p> <pre><code>sudo rpm -e &lt;nebula_version&gt;\n</code></pre> <p>For example:</p> <pre><code>sudo rpm -e nebula-graph-2.6.2-1.x86_64\n</code></pre> </li> <li> <p>Delete the installation directories.</p> </li> </ol>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#uninstall_nebulagraph_deployed_with_deb_packages","title":"Uninstall NebulaGraph deployed with DEB packages","text":"<ol> <li> <p>Run the following command to get the NebulaGraph version.</p> <pre><code>$ dpkg -l | grep \"nebula\"\n</code></pre> <p>The return message is as follows.</p> <pre><code>ii  nebula-graph  2.6.2  amd64     Nebula Package built using CMake\n</code></pre> </li> <li> <p>Run the following command to uninstall NebulaGraph.</p> <pre><code>sudo dpkg -r &lt;nebula_version&gt;\n</code></pre> <p>For example:</p> <pre><code>sudo dpkg -r nebula-graph\n</code></pre> </li> <li> <p>Delete the installation directories.</p> </li> </ol>"},{"location":"4.deployment-and-installation/4.uninstall-nebula-graph/#uninstall_nebulagraph_deployed_with_docker_compose","title":"Uninstall NebulaGraph deployed with Docker Compose","text":"<ol> <li> <p>In the <code>nebula-docker-compose</code> directory, run the following command to stop the NebulaGraph services.</p> <pre><code>docker-compose down -v\n</code></pre> </li> <li> <p>Delete the <code>nebula-docker-compose</code> directory.</p> </li> </ol>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/","title":"Connect to NebulaGraph","text":"<p>NebulaGraph supports multiple types of clients, including a CLI client, a GUI client, and clients developed in popular programming languages. This topic provides an overview of NebulaGraph clients and basic instructions on how to use the native CLI client, Nebula Console.</p>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#nebulagraph_clients","title":"NebulaGraph clients","text":"<p>You can use supported clients or console to connect to NebulaGraph.</p>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#use_nebula_console_to_connect_to_nebulagraph","title":"Use Nebula Console to connect to NebulaGraph","text":""},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have started the NebulaGraph services. For how to start the services, see Start and Stop NebulaGraph.</li> <li>The machine you plan to run Nebula Console on has network access to the NebulaGraph services.</li> </ul>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#steps","title":"Steps","text":"<ol> <li> <p>On the nebula-console page, select a Nebula Console version and click Assets.</p> <p>Note</p> <p>We recommend that you select the latest release.</p> <p></p> </li> <li> <p>In the Assets area, find the correct binary file for the machine where you want to run Nebula Console and download the file to the machine.</p> <p></p> </li> <li> <p>(Optional) Rename the binary file to <code>nebula-console</code> for convenience.</p> <p>Note</p> <p>For Windows, rename the file to <code>nebula-console.exe</code>.</p> </li> <li> <p>On the machine to run Nebula Console, grant the execute permission of the nebula-console binary file to the user.</p> <p>Note</p> <p>For Windows, skip this step.</p> <pre><code>$ chmod 111 nebula-console\n</code></pre> </li> <li> <p>In the command line interface, change the working directory to the one where the nebula-console binary file is stored.</p> </li> <li> <p>Run the following command to connect to NebulaGraph.</p> <ul> <li>For Linux or macOS:</li> </ul> <pre><code>$ ./nebula-console -addr &lt;ip&gt; -port &lt;port&gt; -u &lt;username&gt; -p &lt;password&gt;\n[-t 120] [-e \"nGQL_statement\" | -f filename.nGQL]\n</code></pre> <ul> <li>For Windows:</li> </ul> <pre><code>&gt; nebula-console.exe -addr &lt;ip&gt; -port &lt;port&gt; -u &lt;username&gt; -p &lt;password&gt;\n[-t 120] [-e \"nGQL_statement\" | -f filename.nGQL]\n</code></pre> <p>The description of the parameters is as follows.</p> Option Description <code>-h</code> Shows the help menu. <code>-addr</code> Sets the IP address of the graphd service. The default address is 127.0.0.1. <code>-port</code> Sets the port number of the graphd service. The default port number is 9669. <code>-u/-user</code> Sets the username of your NebulaGraph account. Before enabling authentication, you can use any existing username. The default username is <code>root</code>. <code>-p/-password</code> Sets the password of your NebulaGraph account. Before enabling authentication, you can use any characters as the password. <code>-t/-timeout</code> Sets an integer-type timeout threshold of the connection. The unit is second. The default value is 120. <code>-e/-eval</code> Sets a string-type nGQL statement. The nGQL statement is executed once the connection succeeds. The connection stops after the result is returned. <code>-f/-file</code> Sets the path of an nGQL file. The nGQL statements in the file are executed once the connection succeeds. You'll get the return messages and the connection stops then. </li> </ol> <p>You can find more details in the Nebula Console Repository.</p>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#nebula_console_commands","title":"Nebula Console commands","text":"<p>Nebula Console can export CSV file, DOT file, and import too.</p> <p>Note</p> <p>The commands are case insensitive.</p>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#export_a_csv_file","title":"Export a CSV file","text":"<p>CSV files save the return result of a executed command.</p> <p>Note</p> <ul> <li>A CSV file will be saved in the working directory, i.e., what linux command <code>pwd</code> show;</li> </ul> <ul> <li>This command only works for the next query statement.</li> </ul> <p>The command to export a csv file.</p> <pre><code>nebula&gt; :CSV &lt;file_name.csv&gt;\n</code></pre>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#export_a_dot_file","title":"Export a DOT file","text":"<p>DOT files save the return result of a executed command, and the result information is different from CSV files.</p> <p>Note</p> <ul> <li>A DOT file will be saved in the working directory, i.e., what linux command <code>pwd</code> show;</li> </ul> <ul> <li>You can copy the contents of DOT file, and paste in GraphvizOnline, to visualize the excution plan;</li> </ul> <ul> <li>This command only works for the next query statement.</li> </ul> <p>The command to export a DOT file.</p> <pre><code>nebula&gt; :dot &lt;file_name.dot&gt;\n</code></pre> <p>For example,</p> <pre><code>nebula&gt; :dot a.dot\nnebula&gt; PROFILE FORMAT=\"dot\" GO FROM \"player100\" OVER follow;\n</code></pre>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#importing_a_testing_dataset","title":"Importing a testing dataset","text":"<p>The testing dataset is named <code>nba</code>. Details about schema and data can be seen by commands <code>SHOW</code>.</p> <p>Using the following command to import the testing dataset,</p> <pre><code>nebula&gt; :play nba\n</code></pre>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#run_a_command_multiple_times","title":"Run a command multiple times","text":"<p>Sometimes, you want to run a command multiple times. Run the following command.</p> <pre><code>nebula&gt; :repeat N\n</code></pre> <p>For example,</p> <pre><code>nebula&gt; :repeat 3\nnebula&gt; GO FROM \"player100\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 2602/3214 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 583/849 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 496/671 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\nExecuted 3 times, (total time spent 3681/4734 us), (average time spent 1227/1578 us)\n</code></pre>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#sleep_to_wait","title":"Sleep to wait","text":"<p>Sleep N seconds.</p> <p>It is usually used when altering schema. Since schema is altered in async way, and take effects in the next heartbeat cycle.</p> <pre><code>nebula&gt; :sleep N\n</code></pre>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#disconnect_nebula_console_from_nebulagraph","title":"Disconnect Nebula Console from NebulaGraph","text":"<p>You can use <code>:EXIT</code> or <code>:QUIT</code> to disconnect from NebulaGraph. For convenience, Nebula Console supports using these commands in lower case without the colon (\":\"), such as <code>quit</code>.</p> <pre><code>nebula&gt; :QUIT\n\nBye root!\n</code></pre>"},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#faq","title":"FAQ","text":""},{"location":"4.deployment-and-installation/connect-to-nebula-graph/#how_can_i_install_nebula_console_from_the_source_code","title":"How can I install Nebula Console from the source code","text":"<p>To download and compile the latest source code of Nebula Console, follow the instructions on the nebula console GitHub page.</p>"},{"location":"4.deployment-and-installation/deploy-license/","title":"Deploy license","text":"<p>NebulaGraph Enterprise Edition requires the user to deploy a license file before starting the Enterprise Edition. This topic describes how to deploy a license file for the Enterprise Edition.</p> <p>Enterpriseonly</p> <p>License is a software authorization certificate provided for users of the Enterprise Edition. Users of the Enterprise Edition can send email to <code>inquiry@vesoft.com</code> to apply for a license file.</p>"},{"location":"4.deployment-and-installation/deploy-license/#precautions","title":"Precautions","text":"<ul> <li>If the license file is not deployed, NebulaGraph Enterprise Edition cannot be started.</li> </ul> <ul> <li>Do not modify the license file, otherwise the license will become invalid.</li> </ul> <ul> <li>If the license is about to expire, send email to <code>inquiry@vesoft.com</code> to apply for renewal.</li> </ul> <ul> <li> <p>The transition period after the license expires is 7 days:</p> <ul> <li>If you start the Enterprise Edition within 3 days before the license expires or on the day the license expires, a log will be printed as a reminder.</li> </ul> <ul> <li>The license can still be used for 7 days after it expires.</li> </ul> <ul> <li>If the license has expired for 7 days, you will not be able to start the Enterprise Edition, and a log will be printed as a reminder.</li> </ul> </li> </ul>"},{"location":"4.deployment-and-installation/deploy-license/#license_description","title":"License description","text":"<p>You can use <code>cat</code> to view the content of the license file (<code>nebula.license</code>). The example is as follows:</p> <pre><code>----------License Content Start----------\n{\n\"vendor\": \"Vesoft_Inc\",\n  \"organization\": \"doc\",\n  \"issuedDate\": \"2021-11-07T16:00:00.000Z\",\n  \"expirationDate\": \"2021-11-30T15:59:59.000Z\",\n  \"product\": \"nebula_graph\",\n  \"version\": \"&gt;2.6.1\",\n  \"licenseType\": \"enterprise\"\n}\n----------License Content End----------\n\n----------License Key Start----------\ncofFcOxxxxxxxxxxxxxhnZgaxrQ==\n----------License Key End----------\n</code></pre> <p>The license file contains information such as <code>issuedDate</code> and <code>expirationDate</code>. The description is as follows.</p> Parameter Description <code>vendor</code> The supplier. <code>organization</code> The username. <code>issuedDate</code> The date that the license is issued. <code>expirationDate</code> The date that the license expires. <code>product</code> The product type. The product type of NebulaGraph is <code>nebula_graph</code>. <code>version</code> The version information. <code>licenseType</code> The license type, including <code>enterprise</code>, <code>samll_bussiness</code>, <code>pro</code>, and <code>individual</code>."},{"location":"4.deployment-and-installation/deploy-license/#steps","title":"Steps","text":"<ol> <li> <p>Send email to <code>inquiry@vesoft.com</code> to apply for the NebulaGraph Enterprise Edition package.</p> </li> <li> <p>Install NebulaGraph Enterprise Edition. The installation method is the same as the Community Edition. See Install NebulaGraph with RPM or DEB package.</p> </li> <li> <p>Send email to <code>inquiry@vesoft.com</code> to apply for the license file <code>nebula.license</code>.</p> </li> <li> <p>Upload the license file to all hosts that contain Meta services. The path is in the <code>share/resources/</code> of each Meta service installation directory.</p> <p>Note</p> <p>For the upload address of the license file for ecosystem tools, refer to the document of Ecosystem tools overview.</p> </li> </ol>"},{"location":"4.deployment-and-installation/manage-service/","title":"Manage NebulaGraph Service","text":"<p>You can use the <code>nebula.service</code> script to start, stop, restart, terminate, and check the NebulaGraph services. This topic takes starting, stopping and checking the NebulaGraph services for examples.</p> <p><code>nebula.service</code> is stored in the <code>/usr/local/nebula/</code> directory by default, which is also the default installation path of NebulaGraph. If you have customized the path, use the actual path in your environment.</p>"},{"location":"4.deployment-and-installation/manage-service/#syntax","title":"Syntax","text":"<pre><code>$ sudo /usr/local/nebula/scripts/nebula.service [-v] [-c &lt;config_file_path&gt;]\n&lt;start|stop|restart|status|kill&gt;\n&lt;metad|graphd|storaged|all&gt;\n</code></pre> Parameter Description <code>-v</code> Display detailed debugging information. <code>-c</code> Specify the configuration file path. The default path is <code>/usr/local/nebula/etc/</code>. <code>start</code> Start the target services. <code>stop</code> Stop the target services. <code>restart</code> Restart the target services. <code>kill</code> Terminate the target services. <code>status</code> Check the status of the target services. <code>metad</code> Set the Meta Service as the target service. <code>graphd</code> Set the Graph Service as the target service. <code>storaged</code> Set the Storage Service as the target service. <code>all</code> Set all the NebulaGraph services as the target services."},{"location":"4.deployment-and-installation/manage-service/#start_nebulagraph","title":"Start NebulaGraph","text":""},{"location":"4.deployment-and-installation/manage-service/#in_non-container_environment","title":"In non-container environment","text":"<p>Run the following command to start NebulaGraph.</p> <pre><code>$ sudo /usr/local/nebula/scripts/nebula.service start all\n[INFO] Starting nebula-metad...\n[INFO] Done\n[INFO] Starting nebula-graphd...\n[INFO] Done\n[INFO] Starting nebula-storaged...\n[INFO] Done\n</code></pre>"},{"location":"4.deployment-and-installation/manage-service/#in_docker_container_deployed_with_docker-compose","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to start NebulaGraph.</p> <pre><code>nebula-docker-compose]$ docker-compose up -d\nBuilding with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/\nCreating network \"nebula-docker-compose_nebula-net\" with the default driver\nCreating nebula-docker-compose_metad0_1 ... done\nCreating nebula-docker-compose_metad2_1 ... done\nCreating nebula-docker-compose_metad1_1 ... done\nCreating nebula-docker-compose_storaged2_1 ... done\nCreating nebula-docker-compose_graphd1_1   ... done\nCreating nebula-docker-compose_storaged1_1 ... done\nCreating nebula-docker-compose_storaged0_1 ... done\nCreating nebula-docker-compose_graphd2_1   ... done\nCreating nebula-docker-compose_graphd_1    ... done\n</code></pre>"},{"location":"4.deployment-and-installation/manage-service/#stop_nebulagraph","title":"Stop NebulaGraph","text":"<p>Danger</p> <p>Don't run <code>kill -9</code> to forcibly terminate the processes, otherwise, there is a low probability of data loss.</p>"},{"location":"4.deployment-and-installation/manage-service/#in_non-container_environment_1","title":"In non-container environment","text":"<p>Run the following command to stop NebulaGraph.</p> <pre><code>sudo /usr/local/nebula/scripts/nebula.service stop all\n[INFO] Stopping nebula-metad...\n[INFO] Done\n[INFO] Stopping nebula-graphd...\n[INFO] Done\n[INFO] Stopping nebula-storaged...\n[INFO] Done\n</code></pre>"},{"location":"4.deployment-and-installation/manage-service/#in_docker_container_deployed_with_docker-compose_1","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to stop NebulaGraph.</p> <pre><code>nebula-docker-compose]$ docker-compose down\nStopping nebula-docker-compose_graphd_1    ... done\nStopping nebula-docker-compose_graphd2_1   ... done\nStopping nebula-docker-compose_storaged0_1 ... done\nStopping nebula-docker-compose_storaged1_1 ... done\nStopping nebula-docker-compose_graphd1_1   ... done\nStopping nebula-docker-compose_storaged2_1 ... done\nStopping nebula-docker-compose_metad1_1    ... done\nStopping nebula-docker-compose_metad2_1    ... done\nStopping nebula-docker-compose_metad0_1    ... done\nRemoving nebula-docker-compose_graphd_1    ... done\nRemoving nebula-docker-compose_graphd2_1   ... done\nRemoving nebula-docker-compose_storaged0_1 ... done\nRemoving nebula-docker-compose_storaged1_1 ... done\nRemoving nebula-docker-compose_graphd1_1   ... done\nRemoving nebula-docker-compose_storaged2_1 ... done\nRemoving nebula-docker-compose_metad1_1    ... done\nRemoving nebula-docker-compose_metad2_1    ... done\nRemoving nebula-docker-compose_metad0_1    ... done\nRemoving network nebula-docker-compose_nebula-net\n</code></pre> <p>If you are using a development or nightly version for testing and have compatibility issues, try to run <code>docker-compose down -v</code> to DELETE all data stored in NebulaGraph and import data again.</p>"},{"location":"4.deployment-and-installation/manage-service/#check_the_service_status","title":"Check the service status","text":""},{"location":"4.deployment-and-installation/manage-service/#in_non-container_environment_2","title":"In non-container environment","text":"<p>Run the following command to check the service status of NebulaGraph.</p> <pre><code>$ sudo /usr/local/nebula/scripts/nebula.service status all\n</code></pre> <ul> <li>NebulaGraph is running normally if the following information is returned.</li> </ul> <pre><code>[INFO] nebula-metad(3ba41bd): Running as 26601, Listening on 9559\n[INFO] nebula-graphd(3ba41bd): Running as 26644, Listening on 9669\n[INFO] nebula-storaged(3ba41bd): Running as 26709, Listening on 9779\n</code></pre> <ul> <li>If the return information is similar to the following one, there is a problem.</li> </ul> <pre><code>[INFO] nebula-metad(de03025): Running as 25600, Listening on 9559\n[INFO] nebula-graphd(de03025): Exited\n[INFO] nebula-storaged(de03025): Running as 25646, Listening on 9779\n</code></pre> <p>The NebulaGraph services consist of the Meta Service, Graph Service, and Storage Service. The configuration files for all three services are stored in the <code>/usr/local/nebula/etc/</code> directory by default. You can check the configuration files according to the return information to troubleshoot problems.</p> <p>You may also go to the NebulaGraph community for help.</p>"},{"location":"4.deployment-and-installation/manage-service/#in_docker_container_deployed_with_docker-compose_2","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to check the service status of NebulaGraph.</p> <pre><code>[nebula-docker-compose]$ docker-compose ps\nCONTAINER ID   IMAGE                               COMMAND                  CREATED          STATUS                    PORTS                                                                                                  NAMES\n2a6c56c405f5   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:49230-&gt;9669/tcp, 0.0.0.0:49229-&gt;19669/tcp, 0.0.0.0:49228-&gt;19670/tcp                            nebula-docker-compose_graphd2_1\n7042e0a8e83d   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49227-&gt;9779/tcp, 0.0.0.0:49226-&gt;19779/tcp, 0.0.0.0:49225-&gt;19780/tcp   nebula-docker-compose_storaged2_1\n18e3ea63ad65   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49219-&gt;9779/tcp, 0.0.0.0:49218-&gt;19779/tcp, 0.0.0.0:49217-&gt;19780/tcp   nebula-docker-compose_storaged0_1\n4dcabfe8677a   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:49224-&gt;9669/tcp, 0.0.0.0:49223-&gt;19669/tcp, 0.0.0.0:49222-&gt;19670/tcp                            nebula-docker-compose_graphd1_1\na74054c6ae25   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:9669-&gt;9669/tcp, 0.0.0.0:49221-&gt;19669/tcp, 0.0.0.0:49220-&gt;19670/tcp                             nebula-docker-compose_graphd_1\n880025a3858c   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49216-&gt;9779/tcp, 0.0.0.0:49215-&gt;19779/tcp, 0.0.0.0:49214-&gt;19780/tcp   nebula-docker-compose_storaged1_1\n45736a32a23a   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49213-&gt;9559/tcp, 0.0.0.0:49212-&gt;19559/tcp, 0.0.0.0:49211-&gt;19560/tcp                  nebula-docker-compose_metad0_1\n3b2c90eb073e   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49207-&gt;9559/tcp, 0.0.0.0:49206-&gt;19559/tcp, 0.0.0.0:49205-&gt;19560/tcp                  nebula-docker-compose_metad2_1\n7bb31b7a5b3f   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49210-&gt;9559/tcp, 0.0.0.0:49209-&gt;19559/tcp, 0.0.0.0:49208-&gt;19560/tcp                  nebula-docker-compose_metad1_1\n</code></pre> <p>Use the <code>CONTAINER ID</code> to log in the container and troubleshoot.</p> <pre><code>nebula-docker-compose]$ docker exec -it 2a6c56c405f5 bash\n[root@2a6c56c405f5 nebula]#\n</code></pre>"},{"location":"4.deployment-and-installation/manage-service/#whats_next","title":"What's next","text":"<p>Connect to NebulaGraph</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/","title":"Install NebulaGraph by compiling the source code","text":"<p>Installing NebulaGraph from the source code allows you to customize the compiling and installation settings and test the latest features.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#prerequisites","title":"Prerequisites","text":"<ul> <li>Users have to prepare correct resources described in Prepare resources for compiling, installing, and running NebulaGraph.</li> </ul> <ul> <li>The host to be installed with NebulaGraph has access to the Internet.</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#installation_steps","title":"Installation steps","text":"<p>Note</p> <p>Starting with the NebulaGraph 2.6.2 release, the code repositories for Nebula-Graph, Nebula-Storage, and Nebula-Common have been merged into the Nebula code repository, so the compilation steps are different from those in previous releases.</p> <ol> <li> <p>Use Git to clone the source code of NebulaGraph to the host.</p> <ul> <li> <p>[Recommended] To install NebulaGraph 2.6.2, run the following command.</p> <pre><code>$ git clone --branch v2.6.2 https://github.com/vesoft-inc/nebula.git\n</code></pre> </li> </ul> <ul> <li> <p>To install the latest developing release, run the following command to clone the source code from the master branch.</p> <pre><code>$ git clone https://github.com/vesoft-inc/nebula.git\n</code></pre> </li> </ul> </li> <li> <p>Make the <code>nebula</code> directory the current working directory.</p> <pre><code>$ cd nebula\n</code></pre> </li> <li> <p>Create a <code>build</code> directory and make it the current working directory.</p> <pre><code>$ mkdir build &amp;&amp; cd build\n</code></pre> </li> <li> <p>Generate Makefile with CMake.</p> <p>Note</p> <p>The installation path is <code>/usr/local/nebula</code> by default. To customize it, add the <code>-DCMAKE_INSTALL_PREFIX=&lt;installation_path&gt;</code> CMake variable in the following command.</p> <p>For more information about CMake variables, see CMake variables.</p> <pre><code>$ cmake -DCMAKE_INSTALL_PREFIX=/usr/local/nebula -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release ..\n</code></pre> </li> <li> <p>Compile NebulaGraph.</p> <p>Note</p> <p>Check Prepare resources for compiling, installing, and running NebulaGraph.</p> <p>To speed up the compiling, use the <code>-j</code> option to set a concurrent number <code>N</code>. It should be \\(\\min(\\text{CPU}core number,\\frac{the_memory_size(GB)}{2})\\).</p> <pre><code>$ make -j{N} # E.g., make -j2\n</code></pre> </li> <li> <p>Install NebulaGraph.</p> <pre><code>$ sudo make install\n</code></pre> </li> <li> <p>The configuration files in the <code>etc/</code> directory (<code>/usr/local/nebula/etc</code> by default) are references. Users can create their own configuration files accordingly. If you want to use the scripts in the <code>script</code> directory to start, stop, restart, and kill the service, and check the service status, the configuration files have to be named as <code>nebula-graph.conf</code>, <code>nebula-metad.conf</code>, and <code>nebula-storaged.conf</code>.</p> </li> </ol>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#update_the_master_branch","title":"Update the master branch","text":"<p>The source code of the master branch changes frequently. If the corresponding NebulaGraph release is installed, update it in the following steps.</p> <ol> <li> <p>In the <code>nebula</code> directory, run <code>git pull upstream master</code> to update the source code.</p> </li> <li> <p>In the <code>nebula/build</code> directory, run <code>make -j{N}</code> and <code>make install</code> again.</p> </li> </ol>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#next_to_do","title":"Next to do","text":"<ul> <li>(Enterprise Edition)Deploy license</li> </ul> <ul> <li>Manage NebulaGraph services</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#cmake_variables","title":"CMake variables","text":""},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#usage_of_cmake_variables","title":"Usage of CMake variables","text":"<pre><code>$ cmake -D&lt;variable&gt;=&lt;value&gt; ...\n</code></pre> <p>The following CMake variables can be used at the configure (cmake) stage to adjust the compiling settings.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#cmake_install_prefix","title":"CMAKE_INSTALL_PREFIX","text":"<p><code>CMAKE_INSTALL_PREFIX</code> specifies the path where the service modules, scripts, configuration files are installed. The default path is <code>/usr/local/nebula</code>.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#enable_werror","title":"ENABLE_WERROR","text":"<p><code>ENABLE_WERROR</code> is <code>ON</code> by default and it makes all warnings into errors. You can set it to <code>OFF</code> if needed.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#enable_testing","title":"ENABLE_TESTING","text":"<p><code>ENABLE_TESTING</code> is <code>ON</code> by default and unit tests are built with the NebulaGraph services. If you just need the service modules, set it to <code>OFF</code>.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#enable_asan","title":"ENABLE_ASAN","text":"<p><code>ENABLE_ASAN</code> is <code>OFF</code> by default and the building of ASan (AddressSanitizer), a memory error detector, is disabled. To enable it, set <code>ENABLE_ASAN</code> to <code>ON</code>. This variable is intended for NebulaGraph developers.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#cmake_build_type","title":"CMAKE_BUILD_TYPE","text":"<p>NebulaGraph supports the following building types of <code>MAKE_BUILD_TYPE</code>:</p> <ul> <li> <p><code>Debug</code></p> <p>The default value of <code>CMAKE_BUILD_TYPE</code>. It indicates building NebulaGraph with the debug info but not the optimization options.</p> </li> </ul> <ul> <li> <p><code>Release</code></p> <p>It indicates building NebulaGraph with the optimization options but not the debug info.</p> </li> </ul> <ul> <li> <p><code>RelWithDebInfo</code></p> <p>It indicates building NebulaGraph with the optimization options and the debug info.</p> </li> </ul> <ul> <li> <p><code>MinSizeRel</code></p> <p>It indicates building NebulaGraph with the optimization options for controlling the code size but not the debug info.</p> </li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#cmake_c_compilercmake_cxx_compiler","title":"CMAKE_C_COMPILER/CMAKE_CXX_COMPILER","text":"<p>Usually, CMake locates and uses a C/C++ compiler installed in the host automatically. But if your compiler is not installed at the standard path, or if you want to use a different one, run the command as follows to specify the installation path of the target compiler:</p> <pre><code>$ cmake -DCMAKE_C_COMPILER=&lt;path_to_gcc/bin/gcc&gt; -DCMAKE_CXX_COMPILER=&lt;path_to_gcc/bin/g++&gt; ..\n$ cmake -DCMAKE_C_COMPILER=&lt;path_to_clang/bin/clang&gt; -DCMAKE_CXX_COMPILER=&lt;path_to_clang/bin/clang++&gt; ..\n</code></pre>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#enable_ccache","title":"ENABLE_CCACHE","text":"<p><code>ENABLE_CCACHE</code> is <code>ON</code> by default and Ccache (compiler cache) is used to speed up the compiling of NebulaGraph.</p> <p>To disable <code>ccache</code>, setting <code>ENABLE_CCACHE</code> to <code>OFF</code> is not enough. On some platforms, the <code>ccache</code> installation hooks up or precedes the compiler. In such a case, you have to set an environment variable <code>export CCACHE_DISABLE=true</code> or add a line <code>disable=true</code> in <code>~/.ccache/ccache.conf</code> as well. For more information, see the ccache official documentation.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#nebula_thirdparty_root","title":"NEBULA_THIRDPARTY_ROOT","text":"<p><code>NEBULA_THIRDPARTY_ROOT</code> specifies the path where the third party software is installed. By default it is <code>/opt/vesoft/third-party</code>.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/#examine_problems","title":"Examine problems","text":"<p>If the compiling fails, we suggest you:</p> <ol> <li> <p>Check whether the operating system release meets the requirements and whether the memory and hard disk space are sufficient.</p> </li> <li> <p>Check whether the third-party is installed correctly.</p> </li> <li> <p>Use <code>make -j1</code> to reduce the compiling concurrency.</p> </li> </ol>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/2.install-nebula-graph-by-rpm-or-deb/","title":"Install NebulaGraph with RPM or DEB package","text":"<p>RPM and DEB are common package formats on Linux systems. This topic shows how to quickly install NebulaGraph with the RPM or DEB package.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/2.install-nebula-graph-by-rpm-or-deb/#prerequisites","title":"Prerequisites","text":"<p>Prepare the right resources.</p> <p>Note</p> <p>The console is not complied or packaged with NebulaGraph server binaries. You can install nebula-console by yourself.</p> <p>Enterpriseonly</p> <p>For the Enterprise Edition, please send an email to inquiry@vesoft.com.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/2.install-nebula-graph-by-rpm-or-deb/#download_the_package_from_cloud_service","title":"Download the package from cloud service","text":"<ul> <li>Download the released version.<p>URL: </p> <pre><code>//Centos 6 \nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el6.x86_64.rpm\n\n//Centos 7\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el7.x86_64.rpm\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el8.x86_64.rpm\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1604.amd64.deb\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1804.amd64.deb\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu2004.amd64.deb\n</code></pre> <p>For example, download release package 2.6.2 for <code>Centos 7.5</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.rpm\nwget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.rpm.sha256sum.txt\n</code></pre> <p>download release package <code>2.6.2</code> for <code>Ubuntu 1804</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.ubuntu1804.amd64.deb\nwget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.ubuntu1804.amd64.deb.sha256sum.txt\n</code></pre> </li> </ul> <ul> <li> <p>Download the nightly version.</p> <p>Danger</p> <ul> <li>Nightly versions are usually used to test new features. Don't use it for production.</li> <li>Nightly versions may not be build successfully every night. And the names may change from day to day.</li> </ul> <p>URL: </p> <pre><code>//Centos 6 \nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el6.x86_64.rpm\n\n//Centos 7\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el7.x86_64.rpm\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el8.x86_64.rpm\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu1604.amd64.deb\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu1804.amd64.deb\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu2004.amd64.deb\n</code></pre> <p>For example, download the <code>Centos 7.5</code> package developed and built in <code>2021.03.28</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.el7.x86_64.rpm\nwget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.el7.x86_64.rpm.sha256sum.txt\n</code></pre> <p>For example, download the <code>Ubuntu 1804</code> package developed and built in <code>2021.03.28</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.ubuntu1804.amd64.deb\nwget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.ubuntu1804.amd64.deb.sha256sum.txt\n</code></pre> </li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/2.install-nebula-graph-by-rpm-or-deb/#install_nebulagraph","title":"Install NebulaGraph","text":"<ul> <li> <p>Use the following syntax to install with an RPM package.</p> <pre><code>$ sudo rpm -ivh --prefix=&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> <p>For example, to install an RPM package in the default path for the 2.6.2 version.</p> <pre><code>sudo rpm -ivh nebula-graph-2.6.2.el7.x86_64.rpm\n</code></pre> </li> </ul> <ul> <li> <p>Use the following syntax to install with a DEB package.</p> <pre><code>$ sudo dpkg -i --instdir==&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> <p>For example, to install a DEB package in the default path for the 2.6.2 version.</p> <pre><code>sudo dpkg -i nebula-graph-2.6.2.ubuntu1804.amd64.deb\n</code></pre> <p>Note</p> <p>The default installation path is <code>/usr/local/nebula/</code>.</p> </li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/2.install-nebula-graph-by-rpm-or-deb/#whats_next","title":"What's next","text":"<ul> <li>(Enterprise Edition)Deploy license</li> <li>start NebulaGraph </li> <li>connect to NebulaGraph</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/","title":"Deploy NebulaGraph with Docker Compose","text":"<p>Using Docker Compose can quickly deploy NebulaGraph services based on the prepared configuration file. It is only recommended to use this method when testing functions of NebulaGraph.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>You have installed the following applications on your host.</p> Application Recommended version Official installation reference Docker Latest Install Docker Engine Docker Compose Latest Install Docker Compose Git Latest Download Git </li> </ul> <ul> <li>If you are deploying NebulaGraph as a non-root user, grant the user with Docker-related privileges. For detailed instructions, see Manage Docker as a non-root user.</li> </ul> <ul> <li>You have started the Docker service on your host.</li> </ul> <ul> <li>If you have already deployed another version of NebulaGraph with Docker Compose on your host, to avoid compatibility issues, you need to delete the <code>nebula-docker-compose/data</code> directory.</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#how_to_deploy_and_connect_to_nebulagraph","title":"How to deploy and connect to NebulaGraph","text":"<ol> <li> <p>Clone the <code>2.6</code> branch of the <code>nebula-docker-compose</code> repository to your host with Git.</p> <p>Danger</p> <p>The <code>master</code> branch contains the untested code for the latest NebulaGraph development release. DO NOT use this release in a production environment.</p> <pre><code>$ git clone -b v2.6 https://github.com/vesoft-inc/nebula-docker-compose.git\n</code></pre> </li> <li> <p>Go to the <code>nebula-docker-compose</code> directory.</p> <pre><code>$ cd nebula-docker-compose/\n</code></pre> </li> <li> <p>Run the following command to start all the NebulaGraph services.</p> <p>Note</p> <p>Update the NebulaGraph images and Nebula Console images first if they are out of date.</p> <pre><code>[nebula-docker-compose]$ docker-compose up -d\nCreating nebula-docker-compose_metad0_1 ... done\nCreating nebula-docker-compose_metad2_1 ... done\nCreating nebula-docker-compose_metad1_1 ... done\nCreating nebula-docker-compose_graphd2_1   ... done\nCreating nebula-docker-compose_graphd_1    ... done\nCreating nebula-docker-compose_graphd1_1   ... done\nCreating nebula-docker-compose_storaged0_1 ... done\nCreating nebula-docker-compose_storaged2_1 ... done\nCreating nebula-docker-compose_storaged1_1 ... done\n</code></pre> <p>Note</p> <p>For more information of the preceding services, see NebulaGraph architecture.</p> </li> <li> <p>Connect to NebulaGraph.</p> <ol> <li> <p>Run the following command to start a new docker container with the Nebula Console image, and connect the container to the network where NebulaGraph is deployed (nebula-docker-compose_nebula-net).</p> <pre><code>$ docker run --rm -ti --network nebula-docker-compose_nebula-net --entrypoint=/bin/sh vesoft/nebula-console:v2.6.0\n</code></pre> <p>Note</p> <p>The local network may be different from the <code>nebula-docker-compose_nebula-net</code> in the above example. Use the following command.</p> <pre><code>$ docker network  ls\nNETWORK ID          NAME                               DRIVER              SCOPE\na74c312b1d16        bridge                             bridge              local\ndbfa82505f0e        host                               host                local\ned55ccf356ae        nebula-docker-compose_nebula-net   bridge              local\n93ba48b4b288        none                               null                local\n</code></pre> </li> <li> <p>Connect to NebulaGraph with Nebula Console.</p> <pre><code>docker&gt; nebula-console -u &lt;user_name&gt; -p &lt;password&gt; --address=graphd --port=9669\n</code></pre> <p>Note</p> <p>By default, the authentication is off, you can only log in with an existing username (the default is <code>root</code>) and any password. To turn it on, see Enable authentication.</p> </li> <li> <p>Run the <code>SHOW HOSTS</code> statement to check the status of the <code>nebula-storaged</code> processes.</p> <pre><code>nebula&gt; SHOW HOSTS;\n+-------------+------+----------+--------------+----------------------+------------------------+\n| Host        | Port | Status   | Leader count | Leader distribution  | Partition distribution |\n+-------------+------+----------+--------------+----------------------+------------------------+\n| \"storaged0\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"storaged1\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"storaged2\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"Total\"     |      |          | 0            |                      |                        |\n+-------------+------+----------+--------------+----------------------+------------------------+\n</code></pre> </li> </ol> </li> <li> <p>Run <code>exit</code> twice to switch back to your terminal (shell). You can run Step 4 to log in to NebulaGraph again.</p> </li> </ol>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#check_the_nebulagraph_service_status_and_ports","title":"Check the NebulaGraph service status and ports","text":"<p>Run <code>docker-compose ps</code> to list all the services of NebulaGraph and their status and ports.</p> <pre><code>$ docker-compose ps\nName                     Command                       State                                                   Ports\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------\nnebula-docker-compose_graphd1_1     ./bin/nebula-graphd --flag ...   Up (health: starting)   13000/tcp, 13002/tcp, 0.0.0.0:33295-&gt;19669/tcp, 0.0.0.0:33291-&gt;19670/tcp,\n                                                                                             3699/tcp, 0.0.0.0:33298-&gt;9669/tcp\nnebula-docker-compose_graphd2_1     ./bin/nebula-graphd --flag ...   Up (health: starting)   13000/tcp, 13002/tcp, 0.0.0.0:33285-&gt;19669/tcp, 0.0.0.0:33284-&gt;19670/tcp,\n                                                                                             3699/tcp, 0.0.0.0:33286-&gt;9669/tcp\nnebula-docker-compose_graphd_1      ./bin/nebula-graphd --flag ...   Up (health: starting)   13000/tcp, 13002/tcp, 0.0.0.0:33288-&gt;19669/tcp, 0.0.0.0:33287-&gt;19670/tcp,\n                                                                                             3699/tcp, 0.0.0.0:9669-&gt;9669/tcp\nnebula-docker-compose_metad0_1      ./bin/nebula-metad --flagf ...   Up (health: starting)   11000/tcp, 11002/tcp, 0.0.0.0:33276-&gt;19559/tcp, 0.0.0.0:33275-&gt;19560/tcp,\n                                                                                             45500/tcp, 45501/tcp, 0.0.0.0:33278-&gt;9559/tcp\nnebula-docker-compose_metad1_1      ./bin/nebula-metad --flagf ...   Up (health: starting)   11000/tcp, 11002/tcp, 0.0.0.0:33279-&gt;19559/tcp, 0.0.0.0:33277-&gt;19560/tcp,\n                                                                                             45500/tcp, 45501/tcp, 0.0.0.0:33281-&gt;9559/tcp\nnebula-docker-compose_metad2_1      ./bin/nebula-metad --flagf ...   Up (health: starting)   11000/tcp, 11002/tcp, 0.0.0.0:33282-&gt;19559/tcp, 0.0.0.0:33280-&gt;19560/tcp,\n                                                                                             45500/tcp, 45501/tcp, 0.0.0.0:33283-&gt;9559/tcp\nnebula-docker-compose_storaged0_1   ./bin/nebula-storaged --fl ...   Up (health: starting)   12000/tcp, 12002/tcp, 0.0.0.0:33290-&gt;19779/tcp, 0.0.0.0:33289-&gt;19780/tcp,\n                                                                                             44500/tcp, 44501/tcp, 0.0.0.0:33294-&gt;9779/tcp\nnebula-docker-compose_storaged1_1   ./bin/nebula-storaged --fl ...   Up (health: starting)   12000/tcp, 12002/tcp, 0.0.0.0:33296-&gt;19779/tcp, 0.0.0.0:33292-&gt;19780/tcp,\n                                                                                             44500/tcp, 44501/tcp, 0.0.0.0:33299-&gt;9779/tcp\nnebula-docker-compose_storaged2_1   ./bin/nebula-storaged --fl ...   Up (health: starting)   12000/tcp, 12002/tcp, 0.0.0.0:33297-&gt;19779/tcp, 0.0.0.0:33293-&gt;19780/tcp,\n                                                                                             44500/tcp, 44501/tcp, 0.0.0.0:33300-&gt;9779/tcp\n</code></pre> <p>NebulaGraph provides services to the clients through port <code>9669</code> by default. To use other ports, modify the <code>docker-compose.yaml</code> file in the <code>nebula-docker-compose</code> directory and restart the NebulaGraph services.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#check_the_service_data_and_logs","title":"Check the service data and logs","text":"<p>All the data and logs of NebulaGraph are stored persistently in the <code>nebula-docker-compose/data</code> and <code>nebula-docker-compose/logs</code> directories.</p> <p>The structure of the directories is as follows:</p> <pre><code>nebula-docker-compose/\n  |-- docker-compose.yaml\n  \u251c\u2500\u2500 data\n  \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta0\n  \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta1\n  \u2502\u00a0\u00a0 \u251c\u2500\u2500 meta2\n  \u2502\u00a0\u00a0 \u251c\u2500\u2500 storage0\n  \u2502\u00a0\u00a0 \u251c\u2500\u2500 storage1\n  \u2502\u00a0\u00a0 \u2514\u2500\u2500 storage2\n  \u2514\u2500\u2500 logs\n      \u251c\u2500\u2500 graph\n      \u251c\u2500\u2500 graph1\n      \u251c\u2500\u2500 graph2\n      \u251c\u2500\u2500 meta0\n      \u251c\u2500\u2500 meta1\n      \u251c\u2500\u2500 meta2\n      \u251c\u2500\u2500 storage0\n      \u251c\u2500\u2500 storage1\n      \u2514\u2500\u2500 storage2\n</code></pre>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#stop_the_nebulagraph_services","title":"Stop the NebulaGraph services","text":"<p>You can run the following command to stop the NebulaGraph services:</p> <pre><code>$ docker-compose down\n</code></pre> <p>The following information indicates you have successfully stopped the NebulaGraph services:</p> <pre><code>Stopping nebula-docker-compose_graphd2_1   ... done\nStopping nebula-docker-compose_graphd1_1   ... done\nStopping nebula-docker-compose_graphd_1    ... done\nStopping nebula-docker-compose_storaged1_1 ... done\nStopping nebula-docker-compose_storaged2_1 ... done\nStopping nebula-docker-compose_storaged0_1 ... done\nStopping nebula-docker-compose_metad0_1    ... done\nStopping nebula-docker-compose_metad1_1    ... done\nStopping nebula-docker-compose_metad2_1    ... done\nRemoving nebula-docker-compose_graphd2_1   ... done\nRemoving nebula-docker-compose_graphd1_1   ... done\nRemoving nebula-docker-compose_graphd_1    ... done\nRemoving nebula-docker-compose_storaged1_1 ... done\nRemoving nebula-docker-compose_storaged2_1 ... done\nRemoving nebula-docker-compose_storaged0_1 ... done\nRemoving nebula-docker-compose_metad0_1    ... done\nRemoving nebula-docker-compose_metad1_1    ... done\nRemoving nebula-docker-compose_metad2_1    ... done\nRemoving network nebula-docker-compose_nebula-net\n</code></pre> <p>Danger</p> <p>The parameter <code>-v</code> in the command <code>docker-compose down -v</code> will delete all your local NebulaGraph storage data. Try this command if you are using the nightly release and having some compatibility issues.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#modify_configurations","title":"Modify configurations","text":"<p>The configuration file of NebulaGraph deployed by Docker Compose is <code>nebula-docker-compose/docker-compose.yaml</code>. To make the new configuration take effect, modify the configuration in this file and restart the service.</p> <p>For more instructions, see Configurations.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#faq","title":"FAQ","text":""},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#how_to_fix_the_docker_mapping_to_external_ports","title":"How to fix the docker mapping to external ports?","text":"<p>To set the <code>ports</code> of corresponding services as fixed mapping, modify the <code>docker-compose.yaml</code> in the <code>nebula-docker-compose</code> directory. For example:</p> <pre><code>graphd:\n    image: vesoft/nebula-graphd:v2.6.2\n    ...\n    ports:\n      - 9669:9669\n      - 19669\n- 19670\n</code></pre> <p><code>9669:9669</code> indicates the internal port 9669 is uniformly mapped to external ports, while <code>19669</code> indicates the internal port 19669 is randomly mapped to external ports.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#how_to_upgrade_or_update_the_docker_images_of_nebulagraph_services","title":"How to upgrade or update the docker images of NebulaGraph services","text":"<ol> <li> <p>In the <code>nebula-docker-compose/docker-compose.yaml</code> file, change all the <code>image</code> values to the required image version.</p> </li> <li> <p>In the <code>nebula-docker-compose</code> directory, run <code>docker-compose pull</code> to update the images of the Graph Service, Storage Service, and Meta Service.</p> <p>Note</p> <p>Note that all the NebulaGraph services are stopped before running the command <code>docker-compose pull</code>.</p> </li> <li> <p>Run <code>docker-compose up -d</code> to start the NebulaGraph services again.</p> </li> <li> <p>After connecting to NebulaGraph with Nebula Console, run <code>SHOW HOSTS GRAPH</code>, <code>SHOW HOSTS STORAGE</code>, or <code>SHOW HOSTS META</code> to check the version of the responding service respectively.</p> </li> </ol>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#error_toomanyrequests_when_docker-compose_pull","title":"<code>ERROR: toomanyrequests</code> when <code>docker-compose pull</code>","text":"<p>You may meet the following error.</p> <p><code>ERROR: toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: https://www.docker.com/increase-rate-limit</code>.</p> <p>You have met the rate limit of Docker Hub. Learn more on Understanding Docker Hub Rate Limiting.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#how_to_update_the_nebula_console_client","title":"How to update the Nebula Console client","text":"<p>To update the Nebula Console client, run the following command.</p> <pre><code>docker pull vesoft/nebula-console:v2.6.0\n</code></pre>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#why_cant_i_connect_to_nebulagraph_via_port_3699_after_updating_the_nebula-docker-compose_repository_nebulagraph_200-rc","title":"Why can\u2019t I connect to NebulaGraph via port <code>3699</code> after updating the nebula-docker-compose repository (NebulaGraph 2.0.0-RC)?","text":"<p>In NebulaGraph 2.0.0-RC release, the default port is changed from <code>3699</code> to <code>9669</code>. Please use port <code>9669</code> to connect to NebulaGraph, or modify the port in <code>docker-compose.yaml</code>.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#why_cant_i_access_the_data_after_updating_the_nebula-docker-compose_repository_jan_4_2021","title":"Why can't I access the data after updating the nebula-docker-compose repository? (Jan 4, 2021)","text":"<p>If you have updated the nebula-docker-compose repository after Jan 4, 2021, and there are pre-existing data, modify the <code>docker-compose.yaml</code> file and change the port numbers to the previous ones before connecting to NebulaGraph.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#why_cant_i_access_the_data_after_updating_the_nebula-docker-compose_repository_jan_27_2021","title":"Why can't I access the data after updating the nebula-docker-compose repository? (Jan 27, 2021)","text":"<p>The data format has been modified on Jan 27, 2021, and is incompatible with the previous data. Run <code>docker-compose down -v</code> to delete all your local data.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/3.deploy-nebula-graph-with-docker-compose/#related_documents","title":"Related documents","text":"<ul> <li>Install and deploy NebulaGraph with the source code</li> <li>Install NebulaGraph by RPM or DEB</li> <li>Connect to NebulaGraph</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/4.install-nebula-graph-from-tar/","title":"Install NebulaGraph with the tar.gz file","text":"<p>You can install NebulaGraph by downloading the tar.gz file.</p> <p>Note</p> <p>NebulaGraph provides installing with the tar.gz file starting from version 2.6.0.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/4.install-nebula-graph-from-tar/#installation_steps","title":"Installation steps","text":"<ol> <li> <p>Download the NebulaGraph tar.gz file using the following address.</p> <p>Before downloading, you need to replace <code>&lt;release_version&gt;</code> with the version you want to download.</p> <pre><code>//Centos 7\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el7.x86_64.tar.gz\n//Checksum\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el7.x86_64.tar.gz.sha256sum.txt\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el8.x86_64.tar.gz\n//Checksum\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el8.x86_64.tar.gz.sha256sum.txt\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1604.amd64.tar.gz\n//Checksum\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1604.amd64.tar.gz.sha256sum.txt\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1804.amd64.tar.gz\n//Checksum\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1804.amd64.tar.gz.sha256sum.txt\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu2004.amd64.tar.gz\n//Checksum\nhttps://oss-cdn.nebula-graph.com.cn/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu2004.amd64.tar.gz.sha256sum.txt\n</code></pre> <p>For example, to download the NebulaGraph v2.6.2 tar.gz file for <code>CentOS 7.5</code>, run the following command:</p> <pre><code>wget https://oss-cdn.nebula-graph.com.cn/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.tar.gz\n</code></pre> </li> <li> <p>Decompress the tar.gz file to the NebulaGraph installation directory.</p> <pre><code>tar -xvzf &lt;tar.gz_file_name&gt; -C &lt;install_path&gt;\n</code></pre> <ul> <li><code>tar.gz_file_name</code> specifies the name of the tar.gz file.</li> <li><code>install_path</code> specifies the installation path.</li> </ul> <p>For example:</p> <pre><code>tar -xvzf nebula-graph-2.6.0.el7.x86_64.tar.gz -C /home/joe/nebula/install\n</code></pre> </li> <li> <p>Modify the name of the configuration file.</p> <p>Enter the decompressed directory, rename the files <code>nebula-graphd.conf.default</code>, <code>nebula-metad.conf.default</code>, and <code>nebula-storaged.conf.default</code> in the subdirectory <code>etc</code>, and delete <code>.default</code> to apply the default configuration of NebulaGraph. To modify the configuration, see Configurations.</p> </li> </ol> <p>So far, you have installed NebulaGraph successfully.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/4.install-nebula-graph-from-tar/#next_to_do","title":"Next to do","text":"<ul> <li>(Enterprise Edition)Deploy license</li> </ul> <ul> <li>Manage NebulaGraph services</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/","title":"Deploy a NebulaGraph cluster with RPM/DEB package on multiple servers","text":"<p>For now, NebulaGraph does not provide an official deployment tool. Users can deploy a NebulaGraph cluster with RPM or DEB package manually. This topic provides an example of deploying a NebulaGraph cluster on multiple servers (machines).</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#deployment","title":"Deployment","text":"Machine name IP address Number of graphd Number of storaged Number of metad A 192.168.10.111 1 1 1 B 192.168.10.112 1 1 1 C 192.168.10.113 1 1 1 D 192.168.10.114 1 1 None E 192.168.10.115 1 1 None"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#prerequisites","title":"Prerequisites","text":"<p>Prepare 5 machines for deploying the cluster.</p>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#manual_deployment_process","title":"Manual deployment process","text":""},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#step_1_install_nebulagraph","title":"Step 1: Install NebulaGraph","text":"<p>Install NebulaGraph on each machine in the cluster. Available approaches of installation are as follows.</p> <ul> <li>Install NebulaGraph with RPM or DEB package</li> </ul> <ul> <li>Install NebulaGraph by compiling the source code</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#step_2_modify_the_configurations","title":"Step 2: Modify the configurations","text":"<p>To deploy NebulaGraph according to your requirements, you have to modify the configuration files.</p> <p>All the configuration files for NebulaGraph, including <code>nebula-graphd.conf</code>, <code>nebula-metad.conf</code>, and <code>nebula-storaged.conf</code>, are stored in the <code>etc</code> directory in the installation path. You only need to modify the configuration for the corresponding service on the machines. The configurations that need to be modified for each machine are as follows.</p> Machine name The configuration to be modified A <code>nebula-graphd.conf</code>, <code>nebula-storaged.conf</code>, <code>nebula-metad.conf</code> B <code>nebula-graphd.conf</code>, <code>nebula-storaged.conf</code>, <code>nebula-metad.conf</code> C <code>nebula-graphd.conf</code>, <code>nebula-storaged.conf</code>, <code>nebula-metad.conf</code> D <code>nebula-graphd.conf</code>, <code>nebula-storaged.conf</code> E <code>nebula-graphd.conf</code>, <code>nebula-storaged.conf</code> <p>Users can refer to the content of the following configurations, which only show part of the cluster settings. The hidden content uses the default setting so that users can better understand the relationship between the servers in the NebulaGraph cluster.</p> <p>Note</p> <p>The main configuration to be modified is <code>meta_server_addrs</code>. All configurations need to fill in the IP addresses and ports of all Meta services. At the same time, <code>local_ip</code> needs to be modified as the network IP address of the machine itself. For detailed descriptions of the configuration parameters, see:</p> <ul> <li>Meta Service configurations</li> </ul> <ul> <li>Graph Service configurations</li> </ul> <ul> <li>Storage Service configurations</li> </ul> <ul> <li> <p>Deploy machine A</p> <ul> <li> <p><code>nebula-graphd.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server Addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-graphd process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.111\n# Network device to listen on\n--listen_netdev=any\n# Port to listen on\n--port=9669\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-storaged.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-storaged process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.111\n# Storage daemon listening port\n--port=9779\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-metad.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-metad process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.111\n# Meta daemon listening port\n--port=9559\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>Deploy machine B</p> <ul> <li> <p><code>nebula-graphd.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server Addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-graphd process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.112\n# Network device to listen on\n--listen_netdev=any\n# Port to listen on\n--port=9669\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-storaged.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-storaged process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.112\n# Storage daemon listening port\n--port=9779\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-metad.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-metad process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.112\n# Meta daemon listening port\n--port=9559\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>Deploy machine C</p> <ul> <li> <p><code>nebula-graphd.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server Addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-graphd process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.113\n# Network device to listen on\n--listen_netdev=any\n# Port to listen on\n--port=9669\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-storaged.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-storaged process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.113\n# Storage daemon listening port\n--port=9779\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-metad.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-metad process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.113\n# Meta daemon listening port\n--port=9559\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>Deploy machine D</p> <ul> <li> <p><code>nebula-graphd.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server Addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-graphd process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.114\n# Network device to listen on\n--listen_netdev=any\n# Port to listen on\n--port=9669\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-storaged.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-storaged process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.114\n# Storage daemon listening port\n--port=9779\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>Deploy machine E</p> <ul> <li> <p><code>nebula-graphd.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta Server Addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-graphd process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.115\n# Network device to listen on\n--listen_netdev=any\n# Port to listen on\n--port=9669\n</code></pre> </li> </ul> <ul> <li> <p><code>nebula-storaged.conf</code></p> <pre><code>########## networking ##########\n# Comma separated Meta server addresses\n--meta_server_addrs=192.168.10.111:9559,192.168.10.112:9559,192.168.10.113:9559\n# Local IP used to identify the nebula-storaged process.\n# Change it to an address other than loopback if the service is distributed or\n# will be accessed remotely.\n--local_ip=192.168.10.115\n# Storage daemon listening port\n--port=9779\n</code></pre> </li> </ul> </li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#step_3_start_the_cluster","title":"Step 3: Start the cluster","text":"<p>Start the corresponding service on each machine. Descriptions are as follows.</p> Machine name The process to be started A graphd, storaged, metad B graphd, storaged, metad C graphd, storaged, metad D graphd, storaged E graphd, storaged <p>The command to start the NebulaGraph services is as follows.</p> <pre><code>sudo /usr/local/nebula/scripts/nebula.service start &lt;metad|graphd|storaged|all&gt;\n</code></pre> <p>Note</p> <ul> <li>Make sure all the processes of services on each machine are started. Otherwise, you will fail to start NebulaGraph.</li> </ul> <ul> <li>When the graphd process, the storaged process, and the metad process are all started, you can use <code>all</code> instead.</li> </ul> <ul> <li><code>/usr/local/nebula</code> is the default installation path for NebulaGraph. Use the actual path if you have customized the path. For more information about how to start and stop the services, see Manage NebulaGraph services.</li> </ul>"},{"location":"4.deployment-and-installation/2.compile-and-install-nebula-graph/deploy-nebula-graph-cluster/#step_4_check_the_cluster_status","title":"Step 4: Check the cluster status","text":"<p>Install the native CLI client Nebula Console, then connect to any machine that has started the graphd process, and run <code>SHOW HOSTS</code> to check the cluster status. For example:</p> <pre><code>$ ./nebula-console --addr 192.168.10.111 --port 9669 -u root -p nebula\n\n2021/05/25 01:41:19 [INFO] connection pool is initialized successfully\nWelcome to NebulaGraph!\n\n&gt; SHOW HOSTS;\n+------------------+------+----------+--------------+----------------------+------------------------+\n| Host             | Port | Status   | Leader count | Leader distribution  | Partition distribution |\n+------------------+------+----------+--------------+----------------------+------------------------+\n| \"192.168.10.111\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"192.168.10.112\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"192.168.10.113\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"192.168.10.114\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"192.168.10.115\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\" | \"No valid partition\"   |\n| \"Total\"          |      |          | 0            |                      |                        |\n+------------------+------+----------+--------------+----------------------+------------------------+\n</code></pre>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-from-200-to-latest/","title":"Upgrade NebulaGraph v2.0.x to v2.6.2","text":"<p>To upgrade NebulaGraph v2.0.x to v2.6.2, you only need to use the RPM/DEB package of v2.6.2 for the upgrade, or compile it and then reinstall.</p> <p>Note</p> <p>NebulaGraph v2.0.x refers to v2.0.0-GA and v2.0.1 releases. If your NebulaGraph version is too low (v2.0.0-RC, v2.0.0-beta, v1.x), see Upgrade NebulaGraph to v2.6.2.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-from-200-to-latest/#upgrade_steps_with_rpmdeb_packages","title":"Upgrade steps with RPM/DEB packages","text":"<ol> <li> <p>Download the RPM/DEB package.</p> </li> <li> <p>Stop all NebulaGraph services. For details, see Manage NebulaGraph Service. It is recommended to back up the configuration file before updating.</p> </li> <li> <p>Execute the following command to upgrade:</p> <ul> <li>RPM package<pre><code>$ sudo rpm -Uvh &lt;package_name&gt;\n</code></pre> <p>If you specify the path during installation, you also need to specify the path during upgrade.</p> <pre><code>$ sudo rpm -Uvh --prefix=&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> </li> </ul> <ul> <li>DEB package<pre><code>$ sudo dpkg -i &lt;package_name&gt;\n</code></pre> </li> </ul> </li> <li> <p>Start the required services on each server. For details, see Manage NebulaGraph Service.</p> </li> </ol>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-from-200-to-latest/#upgrade_steps_by_compiling_the_new_source_code","title":"Upgrade steps by compiling the new source code","text":"<ol> <li> <p>Back up the old version of the configuration file. The configuration file is saved in the <code>etc</code> directory of the NebulaGraph installation path.</p> </li> <li> <p>Update the repository and compile the source code. For details, see Install NebulaGraph by compiling the source code.</p> <p>Note</p> <p>When compiling, set the installation path, which is the same as the installation path of the old version.</p> </li> </ol>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-from-200-to-latest/#upgrade_steps_by_deploying_docker_compose","title":"Upgrade steps by deploying Docker Compose","text":"<ol> <li> <p>Modify the file <code>docker-compose.yaml</code> in the directory <code>nebula-docker-compose</code>, and modify all versions after <code>image</code> to <code>v2.6.2</code>.</p> </li> <li> <p>Execute the command <code>docker-compose pull</code> in the directory <code>nebula-docker-compose</code> to update the images of all services.</p> </li> <li> <p>Execute the command <code>docker-compose down</code> to stop the NebulaGraph service.</p> </li> <li> <p>Execute the command <code>docker-compose up -d</code> to start the NebulaGraph service.</p> </li> </ol>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/","title":"Upgrade NebulaGraph to v2.6.2","text":"<p>The legacy versions of NebulaGraph refer to the versions lower than NebulaGraph v2.0.0-GA. This topic describes how to upgrade NebulaGraph to v2.6.2.</p> <p>Note</p> <p>To upgrade NebulaGraph v2.0.0-GA or later versions to v2.6.2, see NebulaGraph v2.0.x to v2.6.2.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#limitations","title":"Limitations","text":"<ul> <li>Rolling Upgrade is not supported. You must stop the NebulaGraph services before the upgrade.</li> </ul> <ul> <li>There is no upgrade script. You have to manually upgrade each server in the cluster.</li> </ul> <ul> <li>This topic does not apply to scenarios where NebulaGraph is deployed with Docker, including Docker Swarm, Docker Compose, and K8s.</li> </ul> <ul> <li>You must upgrade the old NebulaGraph services on the same machines they are deployed. DO NOT change the IP addresses, configuration files of the machines, and DO NOT change the cluster topology.</li> </ul> <ul> <li>The hard disk space of each machine should be three times as much as the space taken by the original data directories.</li> </ul> <ul> <li>Known issues that could cause data loss are listed on GitHub known issues. The issues are all related to altering schema or default values.</li> </ul> <ul> <li>To connect to NebulaGraph 2.0.0, you must upgrade all the NebulaGraph clients. The communication protocols of the old versions and the latest versions are not compatible.</li> </ul> <ul> <li>The upgrade takes about 30 minutes in this test environment.</li> </ul> <ul> <li>DO NOT use soft links to switch the data directories.</li> </ul> <ul> <li>You must have the sudo privileges to complete the steps in this topic.</li> </ul>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#installation_paths","title":"Installation paths","text":""},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#old_installation_path","title":"Old installation path","text":"<p>By default, old versions of NebulaGraph are installed in <code>/usr/local/nebula/</code>, hereinafter referred to as <code>${nebula-old}</code>. The default configuration file path is <code>${nebula-old}/etc/</code>.</p> <ul> <li>Storaged data path is defined by the <code>--data_path</code> option in the <code>${nebula-old}/etc/nebula-storaged.conf</code> file. The default path is <code>data/storage</code>.</li> </ul> <ul> <li>Metad data path is defined by the <code>--data_path</code> option in the <code>${nebula-old}/etc/nebula-metad.conf</code> file. The default path is <code>data/meta</code>.</li> </ul> <p>Note</p> <p>The actual paths in your environment may be different from those described in this topic. You can run the Linux command <code>ps -ef | grep nebula</code> to locate them.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#new_installation_path","title":"New installation path","text":"<p><code>${nebula-new}</code> represents the installation path of the new NebulaGraph version, such as <code>/usr/local/nebula-new/</code>.</p> <pre><code># mkdir -p ${nebula-new}\n</code></pre>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#upgrade_steps","title":"Upgrade steps","text":"<ol> <li> <p>Stop all client connections. You can run the following commands on each Graph server to turn off the Graph Service and avoid dirty write.</p> <pre><code># ${nebula-old}/scripts/nebula.service stop graphd\n[INFO] Stopping nebula-graphd...\n[INFO] Done\n</code></pre> </li> <li> <p>Run the following commands to stop all services of the old version NebulaGraph.</p> <pre><code># ${nebula-old}/scripts/nebula.service stop all\n[INFO] Stopping nebula-metad...\n[INFO] Done\n[INFO] Stopping nebula-graphd...\n[INFO] Done\n[INFO] Stopping nebula-storaged...\n[INFO] Done\n</code></pre> <p>The <code>storaged</code> process needs about 1 minute to flush data. Wait 1 minute and then run <code>ps -ef | grep nebula</code> to check and make sure that all the NebulaGraph services are stopped.</p> <p>Note</p> <p>If the services are not fully stopped in 20 minutes, stop upgrading and go to the NebulaGraph community for help.</p> </li> <li> <p>Install the new version of NebulaGraph on each machine.</p> <ol> <li> <p>Install the new binary file.</p> <ul> <li> <p>To install with RPM/DEB packages, download the installation package of the corresponding operating system from release page.</p> <pre><code># sudo rpm --force -i --prefix=${nebula-new}  ${nebula-package-name.rpm} # for centos/redhat\n# sudo dpkg -i --instdir==${nebula-new} ${nebula-package-name.deb} # for ubuntu\n</code></pre> <p>For detailed steps, see Install NebulaGraph with RPM or DEB package.</p> </li> </ul> <ul> <li> <p>To install with the source code, follow the substeps. For detailed steps, see Install NebulaGraph by compiling the source code. Some key commands are as follows.</p> <ul> <li> <p>Clone the source code.</p> <pre><code># git clone --branch v2.6.2 https://github.com/vesoft-inc/nebula-graph.git\n</code></pre> </li> </ul> <ul> <li> <p>Configure CMake.</p> <pre><code># cmake -DCMAKE_INSTALL_PREFIX=${nebula-new} -DENABLE_TESTING=OFF -DCMAKE_BUILD_TYPE=Release .. \n</code></pre> </li> </ul> </li> </ul> </li> <li> <p>Copy the configuration files from the old path to the new path.</p> <pre><code># cp -rf ${nebula-old}/etc ${nebula-new}/\n</code></pre> </li> </ol> </li> <li> <p>Follow the substeps to prepare the Meta servers (usually 3 of them in a cluster).</p> <ul> <li> <p>Locate the old Meta data path and copy the data files to the new path.</p> <p>Find the  <code>--data_path</code> option in <code>${nebula-old}/etc/nebula-metad.conf</code>. The default value is <code>data/meta</code>.</p> <ul> <li> <p>If the legacy versions has not changed the <code>--data_path</code> item, run the following command to copy the meta data to the new directory.</p> <pre><code># mkdir -p ${nebula-new}/data/meta/\n# cp -r ${nebula-old}/data/meta/* ${nebula-new}/data/meta/\n</code></pre> </li> </ul> <ul> <li>If the legacy versions change the default metad directory, copy it according to the actual directory.</li> </ul> </li> </ul> <ul> <li> <p>Modify the new Meta configuration files.</p> <ul> <li> <p>Edit the new metad configuration file.</p> <pre><code># vim ${nebula-new}/nebula-metad.conf\n</code></pre> </li> </ul> <ul> <li> <p>[Optional]Add the following parameters in the Meta configuration files if you need them.</p> <p><code>--null_type=false</code>: Disables the support for using <code>NULL</code>.The default value is <code>true</code>. When set to <code>false</code>, you must specify a default value when altering tags or edge types, otherwise, data reading fails.</p> <p><code>--string_index_limit=32</code>: Specifies the index length for string values as 32. The default length is 64.</p> </li> </ul> <p>Note</p> <p>You must make sure that this step is applied on every Meta server.</p> </li> </ul> </li> <li> <p>Prepare the Storage configuration files on each Storage server.</p> <ul> <li>[Optional]If the old Storage data path is not the default setting <code>--data_path=data/storage</code>, modify it.<p><pre><code># vim ${nebula-new}/nebula-storaged.conf\n</code></pre>   Change the value of <code>--data_path</code> as the new data path.</p> </li> </ul> <ul> <li>Create the new Storage data directories.<pre><code># mkdir -p ${nebula-new}/data/storage/\n</code></pre> </li> </ul> <p>If the <code>--data_path</code> default value has been modified, create the Storage data directories according to the modification.</p> </li> <li> <p>Start the new Meta Service.</p> <ul> <li>Run the following command on each Meta server.<pre><code># ${nebula-new}/scripts/nebula.service start metad\n[INFO] Starting nebula-metad...\n[INFO] Done\n</code></pre> </li> </ul> <ul> <li>Check if every nebula-metad process is started normally.<pre><code># ps -ef |grep nebula-metad\n</code></pre> </li> </ul> <ul> <li>Check if there is any error information in the Meta logs in <code>${nebula-new}/logs</code>.</li> </ul> <p>Note</p> <p>If any nebula-metad process cannot start normally, stop upgrading, start the NebulaGraph services from the old directories, and take the error logs to the NebulaGraph community for help.</p> </li> <li> <p>Run the following commands to upgrade the Storage data format.</p> <pre><code># ${nebula-new}/bin/db_upgrader  \\\n--src_db_path=&lt;old_storage_directory_path&gt; \\\n--dst_db_path=&lt;new_storage_directory_path&gt;  \\\n--upgrade_meta_server=&lt;meta_server_ip1&gt;:&lt;port1&gt;[,&lt;meta_server_ip2&gt;:&lt;port2&gt;,...] \\\n--upgrade_version=&lt;old_nebula_version&gt; \\\n</code></pre> <p>The parameters are described as follows.</p> <ul> <li><code>--src_db_path</code>: Specifies the absolute path of the OLD Storage data directories. Separate multiple paths with commas, without spaces.</li> </ul> <ul> <li><code>--dst_db_path</code>: Specifies the absolute path of the NEW Storage data directories. Separate multiple paths with commas, without spaces. The paths must correspond to the paths set in <code>--src_db_path</code> one by one.</li> </ul> <ul> <li><code>--upgrade_meta_server</code>: Specifies the addresses of the new Meta servers that you started in step 6.</li> </ul> <ul> <li><code>--upgrade_version</code>: If the old NebulaGraph version is v1.2.0, set the parameter value to <code>1</code>. If the old version is v2.0.0-RC1, set the value to <code>2</code>. Do not set the value to other numbers.</li> </ul> <p>Danger</p> <p>Do not mix up the order of <code>--src_db_path</code> and <code>--dst_db_path</code>. Otherwise, the old data will be damaged during the upgrade.</p> <p>For example, upgrade from v1.2.x:</p> <pre><code># /usr/local/nebula_new/bin/db_upgrader \\\n--src_db_path=/usr/local/nebula/data/storage/data1/,/usr/local/nebula/data/storage/data2/ \\\n--dst_db_path=/usr/local/nebula_new/data/storage/data1/,/usr/local/nebula_new/data/storage/data2/\\\n--upgrade_meta_server=192.168.*.14:45500,192.168.*.15:45500,192.168.*.16:45500 \\\n--upgrade_version=1\n</code></pre> <p>For example, upgrade from v2.0.0-RC1:</p> <pre><code># /usr/local/nebula_new/bin/db_upgrader \\\n--src_db_path=/usr/local/nebula/data/storage/ \\\n--dst_db_path=/usr/local/nebula_new/data/storage/ \\\n--upgrade_meta_server=192.168.*.14:9559,192.168.*.15:9559,192.168.*.16:9559 \\\n--upgrade_version=2\n</code></pre> <p>Note</p> <ul> <li>If anything goes wrong, Stop upgrading, stop all the Meta servers, and start the NebulaGraph services from the old directories.</li> <li>Make sure that all the Storage servers have finished the upgrade. </li> </ul> </li> <li> <p>Start the new Storage Service on each Storage server.</p> <pre><code># ${nebula-new}/scripts/nebula.service start storaged\n# ${nebula-new}/scripts/nebula.service status storaged\n</code></pre> <p>Note</p> <p>If this step goes wrong on any server, Take the logs in <code>${nebula-new}/logs/</code> to the NebulaGraph community for help. Stop upgrading. Stop all the Meta servers and Storage servers. Start the NebulaGraph services from the old directories.</p> </li> <li> <p>Start the new Graph Service on each Graph server.</p> <pre><code># ${nebula-new}/scripts/nebula.service start graphd\n# ${nebula-new}/scripts/nebula.service status graphd\n</code></pre> <p>Note</p> <p>If this step goes wrong on any server, take the logs in <code>${nebula-new}/logs/</code> to the NebulaGraph community for help. Stop upgrading. Stop all the Meta servers, Storage servers, and Graph servers. Start the NebulaGraph services from the old directories.</p> </li> <li> <p>Connect to NebulaGraph with the new versions of Nebula Console. Verify if the NebulaGraph services are available and if the data can be accessed normally. Make sure that the command parameters, including the IP address and port of the Graph Service, are the same as the old one.</p> <pre><code>nebula&gt; SHOW HOSTS;\nnebula&gt; SHOW SPACES;\nnebula&gt; USE &lt;space_name&gt;\nnebula&gt; SHOW PARTS;\nnebula&gt; SUBMIT JOB STATS;\nnebula&gt; SHOW STATS;\n</code></pre> <p>Note</p> <p>The old releases of Nebula Console may have compatibility issues.</p> </li> <li> <p>Upgrade other NebulaGraph clients.</p> <p>You must upgrade all other clients to corresponding NebulaGraph v2.6.2. The clients include but are not limited to Python, Java, go, C++, Flink-connector, Algorithm, Exchange, Spark-connector, and Nebula Bench. Find the v2.6.2 branch for each client.</p> <p>Note</p> <p>Communication protocols of v2.6.2 are not compatible with that of the old releases. To upgrade the clients, compile the v2.6.2 source code of the clients or download corresponding binaries.</p> <p>Tip for maintenance: The data path after the upgrade is <code>${nebula-new}/</code>. Modify relative paths for hard disk monitor systems, log, or ELK, etc.</p> </li> </ol>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#upgrade_failure_and_rollback","title":"Upgrade failure and rollback","text":"<p>If the upgrade fails, stop all NebulaGraph services of the new version, and start the services of the old version.</p> <p>All NebulaGraph clients in use must be switched to the old version.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#appendix_1_test_environment","title":"Appendix 1: Test Environment","text":"<p>The test environment for this topic is as follows:</p> <ul> <li>Machine specifications: 32 CPU cores, 62 GB memory, and SSD.</li> </ul> <ul> <li>Data size: 100 GB of NebulaGraph 1.2.0 LDBC test data, with 1 graph space, 24 partitions, and 92 GB of data directory size.</li> </ul> <ul> <li>Concurrent configuration: <code>--max_concurrent=5</code>, <code>--max_concurrent_parts=24</code>, and <code>--write_batch_num=100</code>.</li> </ul> <p>The upgrade cost 21 minutes in all, including 13 minutes of compaction. The descriptions are as follows.</p> Parameter Default value <code>--max_concurrent</code> 5 <code>--max_concurrent_parts</code> 10 <code>--write_batch_num</code> 100"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#appendix_2_nebulagraph_v200_code_address_and_commit_id","title":"Appendix 2: NebulaGraph V2.0.0 code address and commit ID","text":"Code address Commit ID graphd 91639db storaged and metad 761f22b common b2512aa"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#faq","title":"FAQ","text":""},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#can_i_write_through_the_client_during_the_upgrade","title":"Can I write through the client during the upgrade?","text":"<p>A: No. The state of the data written during this process is undefined.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#can_i_upgrade_other_old_versions_except_for_v12x_and_v200-rc_to_v262","title":"Can I upgrade other old versions except for v1.2.x and v2.0.0-RC to v2.6.2?","text":"<p>A: Upgrading from other old versions is not tested. Theoretically, versions between v1.0.0 and v1.2.0 could adopt the upgrade approach for v1.2.x. v2.0.0-RC nightly versions cannot apply the solutions in this topic.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#how_to_upgrade_if_a_machine_has_only_the_graph_service_but_not_the_storage_service","title":"How to upgrade if a machine has only the Graph Service, but not the Storage Service?","text":"<p>A: Upgrade the Graph Service with the corresponding binary or rpm package.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#how_to_resolve_the_error_permission_denied","title":"How to resolve the error <code>Permission denied</code>?","text":"<p>A: Try again with the sudo privileges.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#is_there_any_change_in_gflags","title":"Is there any change in gflags?","text":"<p>A: Yes. For more information, see github issues.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#what_are_the_differences_between_deleting_data_then_installing_the_new_version_and_upgrading_according_to_this_topic","title":"What are the differences between deleting data then installing the new version and upgrading according to this topic?","text":"<p>A: The default configurations for v2.x and v1.x are different, including the ports used. The upgrade solution keeps the old configurations, and the delete-and-install solution uses the new configurations.</p>"},{"location":"4.deployment-and-installation/3.upgrade-nebula-graph/upgrade-nebula-graph-to-latest/#is_there_a_tool_or_solution_for_verifying_data_consistency_after_the_upgrade","title":"Is there a tool or solution for verifying data consistency after the upgrade?","text":"<p>A: No.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/1.text-based-index-restrictions/","title":"Full-text index restrictions","text":"<p>Caution</p> <p>This topic introduces the restrictions for full-text indexes. Please read the restrictions very carefully before using the full-text indexes.</p> <p>For now, full-text search has the following limitations:</p> <ol> <li> <p>Currently, full-text search supports <code>LOOKUP</code> statements only.</p> </li> <li> <p>The maximum indexing string length is 256 bytes. The part of data that exceeds 256 bytes will not be indexed.</p> </li> <li> <p>If there is a full-text index on the tag/edge type, the tag/edge type cannot be deleted or modified.</p> </li> <li> <p>One tag/edge type can only have one full-text index.</p> </li> <li> <p>The type of properties must be <code>string</code>.</p> </li> <li> <p>Full-text index can not be applied to search multiple tags/edge types.</p> </li> <li> <p>Sorting for the returned results of the full-text search is not supported. Data is returned in the order of data insertion.</p> </li> <li> <p>Full-text index can not search properties with value <code>NULL</code>.</p> </li> <li> <p>Altering Elasticsearch indexes is not supported at this time.</p> </li> <li> <p>The pipe operator is not supported.</p> </li> <li> <p><code>WHERE</code> clauses supports full-text search only working on single terms.</p> </li> <li> <p>Full-text indexes are not deleted together with the graph space.</p> </li> <li> <p>Make sure that you start the Elasticsearch cluster and Nebula\u00a0Graph at the same time. If not, the data writing on the Elasticsearch cluster can be incomplete.</p> </li> <li> <p>Do not contain <code>'</code> or <code>\\</code> in the vertex or edge values. If not, an error will be caused in the Elasticsearch cluster storage.</p> </li> <li> <p>It may take a while for Elasticsearch to create indexes. If Nebula\u00a0Graph warns no index is found, wait for the index to take effect (however, the waiting time is unknown and there is no code to check).</p> </li> <li> <p>NebulaGraph clusters deployed with K8s do not support the full-text search feature.</p> </li> </ol>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/","title":"Deploy full-text index","text":"<p>Nebula\u00a0Graph full-text indexes are powered by Elasticsearch. This means that you can use Elasticsearch full-text query language to retrieve what you want. Full-text indexes are managed through built-in procedures. They can be created only for variable <code>STRING</code> and <code>FIXED_STRING</code> properties when the listener cluster and the Elasticsearch cluster are deployed.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#precaution","title":"Precaution","text":"<p>Before you start using the full-text index, please make sure that you know the restrictions.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#deploy_elasticsearch_cluster","title":"Deploy Elasticsearch cluster","text":"<p>To deploy an Elasticsearch cluster, see Kubernetes Elasticsearch deployment or Elasticsearch installation.</p> <p>When the Elasticsearch cluster is started, add the template file for the Nebula\u00a0Graph full-text index. For more information on index templates, see Elasticsearch Document.</p> <p>Take the following sample template for example:</p> <pre><code>{\n\"template\": \"nebula*\",\n\"settings\": {\n\"index\": {\n\"number_of_shards\": 3,\n\"number_of_replicas\": 1\n}\n},\n\"mappings\": {\n\"properties\" : {\n\"tag_id\" : { \"type\" : \"long\" },\n\"column_id\" : { \"type\" : \"text\" },\n\"value\" :{ \"type\" : \"keyword\"}\n}\n}\n}\n</code></pre> <p>Make sure that you specify the following fields in strict accordance with the preceding template format:</p> <pre><code>\"template\": \"nebula*\"\n\"tag_id\" : { \"type\" : \"long\" },\n\"column_id\" : { \"type\" : \"text\" },\n\"value\" :{ \"type\" : \"keyword\"}\n</code></pre> <p>Caution</p> <p>When creating a full-text index, start the index name with <code>nebula</code>.</p> <p>For example:</p> <pre><code>curl -H \"Content-Type: application/json; charset=utf-8\" -XPUT http://127.0.0.1:9200/_template/nebula_index_template -d '\n{\n \"template\": \"nebula*\",\n  \"settings\": {\n    \"index\": {\n      \"number_of_shards\": 3,\n      \"number_of_replicas\": 1\n    }\n  },\n  \"mappings\": {\n    \"properties\" : {\n            \"tag_id\" : { \"type\" : \"long\" },\n            \"column_id\" : { \"type\" : \"text\" },\n            \"value\" :{ \"type\" : \"keyword\"}\n        }\n  }\n}'\n</code></pre> <p>You can configure the Elasticsearch to meet your business needs. To customize the Elasticsearch, see Elasticsearch Document.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#sign_in_to_the_text_search_clients","title":"Sign in to the text search clients","text":"<p>When the Elasticsearch cluster is deployed, use the <code>SIGN IN</code> statement to sign in to the Elasticsearch clients. Multiple <code>elastic_ip:port</code> pairs are separated with commas. You must use the IPs and the port number in the configuration file for the Elasticsearch.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#syntax","title":"Syntax","text":"<pre><code>SIGN IN TEXT SERVICE [(&lt;elastic_ip:port&gt; [,\"&lt;username&gt;\", \"&lt;password&gt;\"]), (&lt;elastic_ip:port&gt;), ...];\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#example","title":"Example","text":"<pre><code>nebula&gt; SIGN IN TEXT SERVICE (127.0.0.1:9200);\n</code></pre> <p>Note</p> <p>Elasticsearch does not have a username or password by default. If you configured a username and password, you need to specify them in the <code>SIGN IN</code> statement.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#show_text_search_clients","title":"Show text search clients","text":"<p>The <code>SHOW TEXT SEARCH CLIENTS</code> statement can list the text search clients.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#syntax_1","title":"Syntax","text":"<pre><code>SHOW TEXT SEARCH CLIENTS;\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#example_1","title":"Example","text":"<pre><code>nebula&gt; SHOW TEXT SEARCH CLIENTS;\n+-------------+------+\n| Host        | Port |\n+-------------+------+\n| \"127.0.0.1\" | 9200 |\n| \"127.0.0.1\" | 9200 |\n| \"127.0.0.1\" | 9200 |\n+-------------+------+\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#sign_out_to_the_text_search_clients","title":"Sign out to the text search clients","text":"<p>The <code>SIGN OUT TEXT SERVICE</code> statement can sign out all the text search clients.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#syntax_2","title":"Syntax","text":"<pre><code>SIGN OUT TEXT SERVICE;\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/2.deploy-es/#example_2","title":"Example","text":"<pre><code>nebula&gt; SIGN OUT TEXT SERVICE;\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/","title":"Deploy Raft Listener for Nebula Storage service","text":"<p>Full-text index data is written to the Elasticsearch cluster asynchronously. The Raft Listener (Listener for short) is a separate process that fetches data from the Storage Service and writes them into the Elasticsearch cluster.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have read and fully understood the restrictions for using full-text indexes.</li> </ul> <ul> <li>You have deployed a NebulaGraph cluster.</li> </ul> <ul> <li>You have deploy a Elasticsearch cluster.</li> </ul> <ul> <li>You have prepared at least one extra Storage Server. To use the full-text search, you must run one or more Storage Server as the Raft Listener.</li> </ul>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#precautions","title":"Precautions","text":"<ul> <li>The Storage Service that you want to run as the Listener must have the same or later release with all the other Nebula\u00a0Graph services in the cluster.</li> </ul> <ul> <li>For now, you can only add all Listeners to a graph space once and for all. Trying to add a new Listener to a graph space that already has a Listener will fail. To add all Listeners, set them in one statement.</li> </ul>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#deployment_process","title":"Deployment process","text":""},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#step_1_install_the_storage_service","title":"Step 1: Install the Storage service","text":"<p>The Listener process and the storaged process use the same binary file. However, their configuration files and using ports are different. You can install NebulaGraph on all servers that need to deploy a Listener, but only the Storage service can be used. For details, see Install NebulaGraph by RPM or DEB Package.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#step_2_prepare_the_configuration_file_for_the_listener","title":"Step 2: Prepare the configuration file for the Listener","text":"<p>You have to prepare a corresponding configuration file on the machine that you want to deploy a Listener. The file must be named as <code>nebula-storaged-listener.conf</code> and stored in the <code>etc</code> directory. A template is provided for your reference. Note that the file suffix <code>.production</code> should be removed.</p> <p>Most configurations are the same as the configurations of Storage Service. This topic only introduces the differences.</p> Name Default value Description <code>daemonize</code> <code>true</code> When set to <code>true</code>, the process is a daemon process. <code>pid_file</code> <code>pids_listener/nebula-storaged.pid</code> The file that records the process ID. <code>meta_server_addrs</code> - IP addresses and ports of all Meta services. Multiple Meta services are separated by commas. <code>local_ip</code> - The local IP address of the Listener service. <code>port</code> - The listening port of the RPC daemon of the Listener service. <code>heartbeat_interval_secs</code> <code>10</code> The heartbeat interval of the Meta service. The unit is second (s). <code>listener_path</code> <code>data/listener</code> The WAL directory of the Listener. Only one directory is allowed. <code>data_path</code> <code>data</code> For compatibility reasons, this parameter can be ignored. Fill in the default value <code>data</code>. <code>part_man_type</code> <code>memory</code> The type of the part manager. Optional values \u200b\u200bare <code>memory</code> and <code>meta</code>. <code>rocksdb_batch_size</code> <code>4096</code> The default reserved bytes for batch operations. <code>rocksdb_block_cache</code> <code>4</code> The default block cache size of BlockBasedTable. The unit is Megabyte (MB). <code>engine_type</code> <code>rocksdb</code> The type of the Storage engine, such as <code>rocksdb</code>, <code>memory</code>, etc. <code>part_type</code> <code>simple</code> The type of the part, such as <code>simple</code>, <code>consensus</code>, etc. <p>Note</p> <p>Use real IP addresses in the configuration file instead of domain names or loopback IP addresses such as <code>127.0.0.1</code>.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#step_3_start_listeners","title":"Step 3: Start Listeners","text":"<p>Run the following command to start the Listener.</p> <pre><code>./bin/nebula-storaged --flagfile &lt;listener_config_path&gt;/nebula-storaged-listener.conf\n</code></pre> <p><code>${listener_config_path}</code> is the path where you store the Listener configuration file.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#step_4_add_listeners_to_nebulagraph","title":"Step 4: Add Listeners to NebulaGraph","text":"<p>Connect to NebulaGraph and run <code>USE &lt;space&gt;</code> to enter the graph space that you want to create full-text indexes for. Then run the following statement to add a Listener into NebulaGraph.</p> <pre><code>ADD LISTENER ELASTICSEARCH &lt;listener_ip:port&gt; [,&lt;listener_ip:port&gt;, ...]\n</code></pre> <p>Warning</p> <p>You must use real IPs for a Listener.</p> <p>Add all Listeners in one statement completely.</p> <pre><code>nebula&gt; ADD LISTENER ELASTICSEARCH 192.168.8.5:9789,192.168.8.6:9789;\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#show_listeners","title":"Show Listeners","text":"<p>Run the <code>SHOW LISTENER</code> statement to list all Listeners.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#example","title":"Example","text":"<pre><code>nebula&gt; SHOW LISTENER;\n+--------+-----------------+-----------------------+----------+\n| PartId | Type            | Host                  | Status   |\n+--------+-----------------+-----------------------+----------+\n| 1      | \"ELASTICSEARCH\" | \"[192.168.8.5:46780]\" | \"ONLINE\" |\n| 2      | \"ELASTICSEARCH\" | \"[192.168.8.5:46780]\" | \"ONLINE\" |\n| 3      | \"ELASTICSEARCH\" | \"[192.168.8.5:46780]\" | \"ONLINE\" |\n+--------+-----------------+-----------------------+----------+\n</code></pre>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#remove_listeners","title":"Remove Listeners","text":"<p>Run the <code>REMOVE LISTENER ELASTICSEARCH</code> statement to remove all Listeners in a graph space.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#example_1","title":"Example","text":"<pre><code>nebula&gt; REMOVE LISTENER ELASTICSEARCH;\n</code></pre> <p>Danger</p> <p>After the Listener is deleted, it cannot be added again. Therefore, the synchronization to the ES cluster cannot be continued and the text index data will be incomplete. If needed, you can only recreate the graph space.</p>"},{"location":"4.deployment-and-installation/6.deploy-text-based-index/3.deploy-listener/#next","title":"Next","text":"<p>After deploying the Elasticsearch cluster and the Listener, full-text indexes are created automatically on the Elasticsearch cluster. Users can do full-text search now. For more information, see Full-Text search.</p>"},{"location":"5.configurations-and-logs/1.configurations/1.configurations/","title":"Configurations","text":"<p>NebulaGraph builds the configurations based on the gflags repository. Most configurations are flags. When the NebulaGraph service starts, it will get the configuration information from Configuration files by default. Configurations that are not in the file apply the default values.</p> <p>Note</p> <ul> <li>Because there are many configurations and they may change as NebulaGraph develops, this topic will not introduce all configurations. To get detailed descriptions of configurations, follow the instructions below.</li> <li>It is not recommended to modify the configurations that are not introduced in this topic, unless you are familiar with the source code and fully understand the function of configurations.</li> </ul> <p>Legacy version compatibility</p> <p>In the topic of 1.x, we provide a method of using the <code>CONFIGS</code> command to modify the configurations in the cache. However, using this method in a production environment can easily cause inconsistencies of configurations between clusters and the local. Therefore, this method will no longer be introduced in the topic of 2.x.</p>"},{"location":"5.configurations-and-logs/1.configurations/1.configurations/#get_the_configuration_list_and_descriptions","title":"Get the configuration list and descriptions","text":"<p>Use the following command to get all the configuration information of the service corresponding to the binary file:</p> <pre><code>&lt;binary&gt; --help\n</code></pre> <p>For example:</p> <pre><code># Get the help information from Meta\n$ /usr/local/nebula/bin/nebula-metad  --help\n\n# Get the help information from Graph\n$ /usr/local/nebula/bin/nebula-graphd --help\n\n# Get the help information from Storage\n$ /usr/local/nebula/bin/nebula-storaged --help\n</code></pre> <p>The above examples use the default storage path <code>/usr/local/nebula/bin/</code>. If you modify the installation path of NebulaGraph, use the actual path to query the configurations.</p>"},{"location":"5.configurations-and-logs/1.configurations/1.configurations/#get_configurations","title":"Get configurations","text":"<p>Use the <code>curl</code> command to get the value of the running configurations.</p> <p>Legacy version compatibility</p> <p>The <code>curl</code> commands and parameters in NebulaGraph v2.x. are different from NebulaGraph v1.x.</p> <p>For example:</p> <pre><code># Get the running configurations from Meta\ncurl 127.0.0.1:19559/flags\n\n# Get the running configurations from Graph\ncurl 127.0.0.1:19669/flags\n\n# Get the running configurations from Storage\ncurl 127.0.0.1:19779/flags\n</code></pre> <p>Note</p> <p>In an actual environment, use the real host IP address instead of <code>127.0.0.1</code> in the above example.</p>"},{"location":"5.configurations-and-logs/1.configurations/1.configurations/#configuration_files","title":"Configuration files","text":"<p>NebulaGraph provides two initial configuration files for each service, <code>&lt;service_name&gt;.conf.default</code> and <code>&lt;service_name&gt;.conf.production</code>. Users can use them in different scenarios conveniently. The default path is <code>/usr/local/nebula/etc/</code>.</p> <p>The configuration values in the initial configuration file are for reference only and can be adjusted according to actual needs. To use the initial configuration file, choose one of the above two files and delete the suffix <code>.default</code> or <code>.production</code> to make it valid.</p> <p>Caution</p> <p>To ensure the availability of services, the configurations of the same service must be consistent, except for the local IP address <code>local_ip</code>. For example, three Storage servers are deployed in one NebulaGraph cluster. The configurations of the three Storage servers need to be the same, except for the IP address.</p> <p>The initial configuration files corresponding to each service are as follows.</p> NebulaGraph service Initial configuration file Description Meta <code>nebula-metad.conf.default</code> and <code>nebula-metad.conf.production</code> Meta service configuration Graph <code>nebula-graphd.conf.default</code> and <code>nebula-graphd.conf.production</code> Graph service configuration Storage <code>nebula-storaged.conf.default</code> and <code>nebula-storaged.conf.production</code> Storage service configuration <p>Each initial configuration file of all services contains <code>local_config</code>. The default value is <code>true</code>, which means that the NebulaGraph service will get configurations from its configuration files and start it.</p> <p>Caution</p> <p>It is not recommended to modify the value of <code>local_config</code> to <code>false</code>. If modified, the NebulaGraph service will first read the cached configurations, which may cause configuration inconsistencies between clusters and cause unknown risks.</p>"},{"location":"5.configurations-and-logs/1.configurations/1.configurations/#modify_configurations","title":"Modify configurations","text":"<p>By default, each NebulaGraph service gets configurations from its configuration files. Users can modify configurations and make them valid according to the following steps:</p> <ol> <li> <p>Use a text editor to modify the configuration files of the target service and save the modification.</p> </li> <li> <p>Choose an appropriate time to restart all NebulaGraph services to make the modifications valid.</p> </li> </ol>"},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/","title":"Meta Service configuration","text":"<p>NebulaGraph provides two initial configuration files for the Meta Service, <code>nebula-metad.conf.default</code> and <code>nebula-metad.conf.production</code>. Users can use them in different scenarios conveniently. The default file path is <code>/usr/local/nebula/etc/</code>.</p> <p>Caution</p> <ul> <li>It is not recommended to modify the value of <code>local_config</code> to <code>false</code>. If modified, the NebulaGraph service will first read the cached configurations, which may cause configuration inconsistencies between clusters and cause unknown risks.</li> <li>It is not recommended to modify the configurations that are not introduced in this topic, unless you are familiar with the source code and fully understand the function of configurations.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#how_to_use_the_configuration_files","title":"How to use the configuration files","text":"<p>To use the initial configuration file, choose one of the above two files and delete the suffix <code>.default</code> or <code>.production</code> from the initial configuration file for the Meta Service to apply the configurations defined in it.</p>"},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#about_parameter_values","title":"About parameter values","text":"<p>If a parameter is not set in the configuration file, NebulaGraph uses the default value. Not all parameters are predefined. And the predefined parameters in the two initial configuration files are different. This topic uses the parameters in <code>nebula-metad.conf.default</code>.</p> <p>For all parameters and their current values, see Configurations.</p>"},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#basics_configurations","title":"Basics configurations","text":"Name Predefined value Description <code>daemonize</code> <code>true</code> When set to <code>true</code>, the process is a daemon process. <code>pid_file</code> <code>pids/nebula-metad.pid</code> The file that records the process ID. <code>timezone_name</code> - Specifies the NebulaGraph time zone. This parameter is not predefined in the initial configuration files. You can manually set it if you need it. The system default value is <code>UTC+00:00:00</code>. For the format of the parameter value, see Specifying the Time Zone with TZ. For example, <code>--timezone_name=UTC+08:00</code> represents the GMT+8 time zone. <code>local_config</code> <code>true</code> When set to <code>true</code>, the process gets configurations from the configuration files. <code>minimum_reserved_bytes</code> - Specifies the minimum remaining space of each data storage path. When the value is lower than this standard, the cluster metadata operation may fail. This configuration is measured in bytes. The default value is <code>1073741824</code>, namely, 1GB. <p>Note</p> <ul> <li>While inserting property values of time types, NebulaGraph transforms time types (except TIMESTAMP) to the corresponding UTC according to the time zone specified by <code>timezone_name</code>. The time-type values returned by nGQL queries are all UTC time.</li> <li><code>timezone_name</code> is only used to transform the data stored in NebulaGraph. Other time-related data of the NebulaGraph processes still uses the default time zone of the host, such as the log printing time.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#logging_configurations","title":"Logging configurations","text":"Name Predefined value Description <code>log_dir</code> <code>logs</code> The directory that stores the Meta Service log. It is recommended to put logs on a different hard disk from the data. <code>minloglevel</code> <code>0</code> Specifies the minimum level of the log. That is, no logs below this level will be printed. Optional values are <code>0</code> (INFO), <code>1</code> (WARNING), <code>2</code> (ERROR), <code>3</code> (FATAL). It is recommended to set it to <code>0</code> during debugging and <code>1</code> in a production environment. If it is set to <code>4</code>, NebulaGraph will not print any logs. <code>v</code> <code>0</code> Specifies the detailed level of the log. The larger the value, the more detailed the log is. Optional values are <code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>. <code>logbufsecs</code> <code>0</code> Specifies the maximum time to buffer the logs. If there is a timeout, it will output the buffered log to the log file. <code>0</code> means real-time output. This configuration is measured in seconds. <code>redirect_stdout</code> <code>true</code> When set to <code>true</code>, the process redirects the<code>stdout</code> and <code>stderr</code> to separate output files. <code>stdout_log_file</code> <code>metad-stdout.log</code> Specifies the filename for the <code>stdout</code> log. <code>stderr_log_file</code> <code>metad-stderr.log</code> Specifies the filename for the <code>stderr</code> log. <code>stderrthreshold</code> <code>2</code> Specifies the <code>minloglevel</code> to be copied to the <code>stderr</code> log."},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#networking_configurations","title":"Networking configurations","text":"Name Predefined value Description <code>meta_server_addrs</code> <code>127.0.0.1:9559</code> Specifies the IP addresses and ports of all Meta Services.  Multiple addresses are separated with commas. <code>local_ip</code> <code>127.0.0.1</code> Specifies the local IP for the Meta Service. The local IP address is used to identify the nebula-metad process. If it is a distributed cluster or requires remote access, modify it to the corresponding address. <code>port</code> <code>9559</code> Specifies RPC daemon listening port of the Meta service. The external port for the Meta Service is predefined to <code>9559</code>. The internal port is predefined to <code>port + 1</code>, i.e., <code>9560</code>. Nebula\u00a0Graph uses the internal port for multi-replica interactions. <code>ws_ip</code> <code>0.0.0.0</code> Specifies the IP address for the HTTP service. <code>ws_http_port</code> <code>19559</code> Specifies the port for the HTTP service. <code>ws_h2_port</code> <code>19560</code> Specifies the port for the HTTP2 service. <code>ws_storage_http_port</code> <code>19779</code> Specifies the Storage service listening port used by the HTTP protocol. It must be consistent with the <code>ws_http_port</code> in the Storage service configuration file. <code>heartbeat_interval_secs</code> <code>10</code> Specifies the default heartbeat interval. Make sure the <code>heartbeat_interval_secs</code> values for all services are the same, otherwise NebulaGraph CANNOT work normally. This configuration is measured in seconds. <p>Caution</p> <p>The real IP address must be used in the configuration file. Otherwise, <code>127.0.0.1/0.0.0.0</code> cannot be parsed correctly in some cases.</p>"},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#storage_configurations","title":"Storage configurations","text":"Name Predefined Value Description <code>data_path</code> <code>data/meta</code> The storage path for Meta data."},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#misc_configurations","title":"Misc configurations","text":"Name Predefined Value Description <code>default_parts_num</code> <code>100</code> Specifies the default partition number when creating a new graph space. <code>default_replica_factor</code> <code>1</code> Specifies the default replica number when creating a new graph space."},{"location":"5.configurations-and-logs/1.configurations/2.meta-config/#rocksdb_options_configurations","title":"RocksDB options configurations","text":"Name Predefined Value Description <code>rocksdb_wal_sync</code> <code>true</code> Enables or disables RocksDB WAL synchronization. Available values are <code>true</code> (enable) and <code>false</code> (disable)."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/","title":"Graph Service configuration","text":"<p>NebulaGraph provides two initial configuration files for the Graph Service, <code>nebula-graphd.conf.default</code> and <code>nebula-graphd.conf.production</code>. Users can use them in different scenarios conveniently. The default file path is <code>/usr/local/nebula/etc/</code>.</p> <p>Caution</p> <ul> <li>It is not recommended to modify the value of <code>local_config</code> to <code>false</code>. If modified, the NebulaGraph service will first read the cached configurations, which may cause configuration inconsistencies between clusters and cause unknown risks.</li> <li>It is not recommended to modify the configurations that are not introduced in this topic, unless you are familiar with the source code and fully understand the function of configurations.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#how_to_use_the_configuration_files","title":"How to use the configuration files","text":"<p>To use the initial configuration file, choose one of the above two files and delete the suffix <code>.default</code> or <code>.production</code> from the initial configuration file for the Meta Service to apply the configurations defined in it.</p>"},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#about_parameter_values","title":"About parameter values","text":"<p>If a parameter is not set in the configuration file, NebulaGraph uses the default value. Not all parameters are predefined. And the predefined parameters in the two initial configuration files are different. This topic uses the parameters in <code>nebula-metad.conf.default</code>.</p> <p>For all parameters and their current values, see Configurations.</p>"},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#basics_configurations","title":"Basics configurations","text":"Name Predefined value Description <code>daemonize</code> <code>true</code> When set to <code>true</code>, the process is a daemon process. <code>pid_file</code> <code>pids/nebula-graphd.pid</code> The file that records the process ID. <code>enable_optimizer</code> <code>true</code> When set to <code>true</code>, the optimizer is enabled. <code>timezone_name</code> - Specifies the NebulaGraph time zone. This parameter is not predefined in the initial configuration files. The system default value is <code>UTC+00:00:00</code>. For the format of the parameter value, see Specifying the Time Zone with TZ. For example\uff0c <code>--timezone_name=UTC+08:00</code> represents the GMT+8 time zone. <code>local_config</code> <code>true</code> When set to <code>true</code>, the process gets configurations from the configuration files. <p>Note</p> <ul> <li>While inserting property values of time types, NebulaGraph transforms time types (except TIMESTAMP) to the corresponding UTC according to the time zone specified by <code>timezone_name</code>. The time-type values returned by nGQL queries are all UTC time.</li> <li><code>timezone_name</code> is only used to transform the data stored in NebulaGraph. Other time-related data of the NebulaGraph processes still uses the default time zone of the host, such as the log printing time.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#logging_configurations","title":"Logging configurations","text":"Name Predefined value Description <code>log_dir</code> <code>logs</code> The directory that stores the Meta Service log. It is recommended to put logs on a different hard disk from the data. <code>minloglevel</code> <code>0</code> Specifies the minimum level of the log. That is, no logs below this level will be printed. Optional values are <code>0</code> (INFO), <code>1</code> (WARNING), <code>2</code> (ERROR), <code>3</code> (FATAL). It is recommended to set it to <code>0</code> during debugging and <code>1</code> in a production environment. If it is set to <code>4</code>, NebulaGraph will not print any logs. <code>v</code> <code>0</code> Specifies the detailed level of the log. The larger the value, the more detailed the log is. Optional values are <code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>. <code>logbufsecs</code> <code>0</code> Specifies the maximum time to buffer the logs. If there is a timeout, it will output the buffered log to the log file. <code>0</code> means real-time output. This configuration is measured in seconds. <code>redirect_stdout</code> <code>true</code> When set to <code>true</code>, the process redirects the<code>stdout</code> and <code>stderr</code> to separate output files. <code>stdout_log_file</code> <code>graphd-stdout.log</code> Specifies the filename for the <code>stdout</code> log. <code>stderr_log_file</code> <code>graphd-stderr.log</code> Specifies the filename for the <code>stderr</code> log. <code>stderrthreshold</code> <code>2</code> Specifies the <code>minloglevel</code> to be copied to the <code>stderr</code> log."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#query_configurations","title":"Query configurations","text":"Name Predefined value Description <code>accept_partial_success</code> <code>false</code> When set to <code>false</code>, the process treats partial success as an error. This configuration only applies to read-only requests. Write requests always treat partial success as an error. <code>session_reclaim_interval_secs</code> <code>10</code> Specifies the interval that the Session information is sent to the Meta service. This configuration is measured in seconds. <code>max_allowed_query_size</code> <code>4194304</code> Specifies the maximum length of queries. Unit: bytes. The default value is <code>4194304</code>, namely 4MB."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#networking_configurations","title":"Networking configurations","text":"Name Predefined value Description <code>meta_server_addrs</code> <code>127.0.0.1:9559</code> Specifies the IP addresses and ports of all Meta Services.  Multiple addresses are separated with commas. <code>local_ip</code> <code>127.0.0.1</code> Specifies the local IP for the Graph Service. The local IP address is used to identify the nebula-graphd process. If it is a distributed cluster or requires remote access, modify it to the corresponding address. <code>listen_netdev</code> <code>any</code> Specifies the listening network device. <code>port</code> <code>9669</code> Specifies RPC daemon listening port of the Graph service. <code>reuse_port</code> <code>false</code> When set to <code>false</code>, the <code>SO_REUSEPORT</code> is closed. <code>listen_backlog</code> <code>1024</code> Specifies the maximum length of the connection queue for socket monitoring. This configuration must be modified together with the <code>net.core.somaxconn</code>. <code>client_idle_timeout_secs</code> <code>0</code> Specifies the time to expire an idle connection. <code>0</code> means that the connection will never expire. This configuration is measured in seconds. <code>session_idle_timeout_secs</code> <code>0</code> Specifies the time to expire an idle session. <code>0</code> means that the session will never expire. This configuration is measured in seconds. <code>num_accept_threads</code> <code>1</code> Specifies the number of threads that accept incoming connections. <code>num_netio_threads</code> <code>0</code> Specifies the number of networking IO threads. <code>0</code> is the number of CPU cores. <code>num_worker_threads</code> <code>0</code> Specifies the number of threads that execute queries. <code>0</code> is the number of CPU cores. <code>ws_ip</code> <code>0.0.0.0</code> Specifies the IP address for the HTTP service. <code>ws_http_port</code> <code>19669</code> Specifies the port for the HTTP service. <code>ws_h2_port</code> <code>19670</code> Specifies the port for the HTTP2 service. <code>heartbeat_interval_secs</code> <code>10</code> Specifies the default heartbeat interval. Make sure the <code>heartbeat_interval_secs</code> values for all services are the same, otherwise NebulaGraph CANNOT work normally. This configuration is measured in seconds. <code>storage_client_timeout_ms</code> - Specifies the RPC connection timeout threshold between the Graph Service and the Storage Service. This parameter is not predefined in the initial configuration files. You can manually set it if you need it. The system default value is <code>60000</code>ms. <code>ws_meta_http_port</code> <code>19559</code> Specifies the Meta service listening port used by the HTTP protocol. It must be consistent with the <code>ws_http_port</code> in the Meta service configuration file. <p>Caution</p> <p>The real IP address must be used in the configuration file. Otherwise, <code>127.0.0.1/0.0.0.0</code> cannot be parsed correctly in some cases.</p>"},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#charset_and_collate_configurations","title":"Charset and collate configurations","text":"Name Predefined value Description <code>default_charset</code> <code>utf8</code> Specifies the default charset when creating a new graph space. <code>default_collate</code> <code>utf8_bin</code> Specifies the default collate when creating a new graph space."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#authorization_configurations","title":"Authorization configurations","text":"Name Predefined value Description <code>enable_authorize</code> <code>false</code> When set to <code>false</code>, the system authentication is not enabled. For more information, see Authentication. <code>auth_type</code> <code>password</code> Specifies the login method. Available values are <code>password</code>, <code>ldap</code>, and <code>cloud</code>."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#memory_configurations","title":"Memory configurations","text":"Name Predefined value Description <code>system_memory_high_watermark_ratio</code> - Specifies the trigger threshold of the high-level memory alarm mechanism. The default value is <code>0.8</code>. If the system memory usage is higher than this value, an alarm mechanism will be triggered, and NebulaGraph will stop querying. This parameter is not predefined in the initial configuration files."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#experimental_configurations","title":"Experimental configurations","text":"Name Predefined value Description <code>enable_experimental_feature</code> <code>false</code> Specifies the experimental feature. Optional values are <code>true</code> and <code>false</code>. For currently supported experimental features, see below."},{"location":"5.configurations-and-logs/1.configurations/3.graph-config/#experimental_features","title":"Experimental features","text":"Name Description TOSS The TOSS (Transaction on Storage Side) function is used to ensure the final consistency of the <code>INSERT</code>, <code>UPDATE</code>, or <code>UPSERT</code> operations on edges (because one edge logically corresponds to two key-value pairs on the hard disk). The <code>DELETE</code> operation is not currently supported. After the TOSS function is enabled, the time delay of related operations will be increased by about one time."},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/","title":"Storage Service configurations","text":"<p>NebulaGraph provides two initial configuration files for the Storage Service, <code>nebula-storaged.conf.default</code> and <code>nebula-storaged.conf.production</code>. Users can use them in different scenarios conveniently. The default file path is <code>/usr/local/nebula/etc/</code>.</p> <p>Caution</p> <ul> <li>It is not recommended to modify the value of <code>local_config</code> to <code>false</code>. If modified, the NebulaGraph service will first read the cached configurations, which may cause configuration inconsistencies between clusters and cause unknown risks.</li> <li>It is not recommended to modify the configurations that are not introduced in this topic, unless you are familiar with the source code and fully understand the function of configurations.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#how_to_use_the_configuration_files","title":"How to use the configuration files","text":"<p>To use the initial configuration file, choose one of the above two files and delete the suffix <code>.default</code> or <code>.production</code> from the initial configuration file for the Meta Service to apply the configurations defined in it.</p>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#about_parameter_values","title":"About parameter values","text":"<p>If a parameter is not set in the configuration file, NebulaGraph uses the default value. Not all parameters are predefined. And the predefined parameters in the two initial configuration files are different. This topic uses the parameters in <code>nebula-metad.conf.default</code>. For parameters that are not included in <code>nebula-metad.conf.default</code>, see <code>nebula-storaged.conf.production</code>.</p> <p>Note</p> <p>The configurations of the Raft Listener and the Storage service are different. For details, see Deploy Raft listener.</p> <p>For all parameters and their current values, see Configurations.</p>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#basics_configurations","title":"Basics configurations","text":"Name Predefined value Description <code>daemonize</code> <code>true</code> When set to <code>true</code>, the process is a daemon process. <code>pid_file</code> <code>pids/nebula-storaged.pid</code> The file that records the process ID. <code>timezone_name</code> - Specifies the NebulaGraph time zone. This parameter is not predefined in the initial configuration files. The system default value is <code>UTC+00:00:00</code>. For the format of the parameter value, see Specifying the Time Zone with TZ. For example, <code>--timezone_name=UTC+08:00</code> represents the GMT+8 time zone. <code>local_config</code> <code>true</code> When set to <code>true</code>, the process gets configurations from the configuration files. <p>Note</p> <ul> <li>While inserting property values of time types, NebulaGraph transforms time types (except TIMESTAMP) to the corresponding UTC according to the time zone specified by <code>timezone_name</code>. The time-type values returned by nGQL queries are all UTC.</li> <li><code>timezone_name</code> is only used to transform the data stored in NebulaGraph. Other time-related data of the NebulaGraph processes still uses the default time zone of the host, such as the log printing time.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#logging_configurations","title":"Logging configurations","text":"Name Predefined value Description <code>log_dir</code> <code>logs</code> The directory that stores the Meta Service log. It is recommended to put logs on a different hard disk from the data. <code>minloglevel</code> <code>0</code> Specifies the minimum level of the log. That is, no logs below this level will be printed. Optional values are <code>0</code> (INFO), <code>1</code> (WARNING), <code>2</code> (ERROR), <code>3</code> (FATAL). It is recommended to set it to <code>0</code> during debugging and <code>1</code> in a production environment. If it is set to <code>4</code>, NebulaGraph will not print any logs. <code>v</code> <code>0</code> Specifies the detailed level of the log. The larger the value, the more detailed the log is. Optional values are <code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>. <code>logbufsecs</code> <code>0</code> Specifies the maximum time to buffer the logs. If there is a timeout, it will output the buffered log to the log file. <code>0</code> means real-time output. This configuration is measured in seconds. <code>redirect_stdout</code> <code>true</code> When set to <code>true</code>, the process redirects the<code>stdout</code> and <code>stderr</code> to separate output files. <code>stdout_log_file</code> <code>graphd-stdout.log</code> Specifies the filename for the <code>stdout</code> log. <code>stderr_log_file</code> <code>graphd-stderr.log</code> Specifies the filename for the <code>stderr</code> log. <code>stderrthreshold</code> <code>2</code> Specifies the <code>minloglevel</code> to be copied to the <code>stderr</code> log."},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#networking_configurations","title":"Networking configurations","text":"Name Predefined value Description <code>meta_server_addrs</code> <code>127.0.0.1:9559</code> Specifies the IP addresses and ports of all Meta Services.  Multiple addresses are separated with commas. <code>local_ip</code> <code>127.0.0.1</code> Specifies the local IP for the Storage Service. The local IP address is used to identify the nebula-storaged process. If it is a distributed cluster or requires remote access, modify it to the corresponding address. <code>port</code> <code>9779</code> Specifies RPC daemon listening port of the Storage service. The external port for the Meta Service is predefined to <code>9779</code>. The internal port is predefined to <code>9777</code>, <code>9778</code>, and <code>9780</code>. Nebula\u00a0Graph uses the internal port for multi-replica interactions. <code>ws_ip</code> <code>0.0.0.0</code> Specifies the IP address for the HTTP service. <code>ws_http_port</code> <code>19779</code> Specifies the port for the HTTP service. <code>ws_h2_port</code> <code>19780</code> Specifies the port for the HTTP2 service. <code>heartbeat_interval_secs</code> <code>10</code> Specifies the default heartbeat interval. Make sure the <code>heartbeat_interval_secs</code> values for all services are the same, otherwise NebulaGraph CANNOT work normally. This configuration is measured in seconds. <p>Caution</p> <p>The real IP address must be used in the configuration file. Otherwise, <code>127.0.0.1/0.0.0.0</code> cannot be parsed correctly in some cases.</p>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#raft_configurations","title":"Raft configurations","text":"Name Predefined value Description <code>raft_heartbeat_interval_secs</code> <code>30</code> Specifies the time to expire the Raft election. The configuration is measured in seconds. <code>raft_rpc_timeout_ms</code> <code>500</code> Specifies the time to expire the Raft RPC. The configuration is measured in milliseconds. <code>wal_ttl</code> <code>14400</code> Specifies the lifetime of the RAFT WAL. The configuration is measured in seconds."},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#disk_configurations","title":"Disk configurations","text":"Name Predefined value Description <code>data_path</code> <code>data/storage</code> Specifies the data storage path. Multiple paths are separated with commas. One RocksDB example corresponds to one path. <code>minimum_reserved_bytes</code> <code>268435456</code> Specifies the minimum remaining space of each data storage path. When the value is lower than this standard, the cluster data writing may fail. This configuration is measured in bytes. The default value is <code>1073741824</code>, namely, 1GB. <code>rocksdb_batch_size</code> <code>4096</code> Specifies the block cache for a batch operation. The configuration is measured in bytes. <code>rocksdb_block_cache</code> <code>4</code> Specifies the block cache for BlockBasedTable. The configuration is measured in megabytes. <code>engine_type</code> <code>rocksdb</code> Specifies the engine type. <code>rocksdb_compression</code> <code>lz4</code> Specifies the compression algorithm for RocksDB. Optional values are <code>no</code>, <code>snappy</code>, <code>lz4</code>, <code>lz4hc</code>, <code>zlib</code>, <code>bzip2</code>, and <code>zstd</code>. <code>rocksdb_compression_per_level</code> \\ Specifies the compression algorithm for each level. <code>enable_rocksdb_statistics</code> <code>false</code> When set to <code>false</code>, RocksDB statistics is disabled. <code>rocksdb_stats_level</code> <code>kExceptHistogramOrTimers</code> Specifies the stats level for RocksDB. Optional values are <code>kExceptHistogramOrTimers</code>, <code>kExceptTimers</code>, <code>kExceptDetailedTimers</code>, <code>kExceptTimeForMutex</code>, and <code>kAll</code>. <code>enable_rocksdb_prefix_filtering</code> <code>true</code> When set to <code>true</code>, the prefix bloom filter for RocksDB is enabled. Enabling prefix bloom filter makes the graph traversal faster but occupies more memory. <code>enable_rocksdb_whole_key_filtering</code> <code>false</code> When set to <code>true</code>, the whole key bloom filter for RocksDB is enabled. <code>rocksdb_filtering_prefix_length</code> <code>12</code> Specifies the prefix length for each key. Optional values are <code>12</code> and <code>16</code>. The configuration is measured in bytes. <code>enable_partitioned_index_filter</code> - When set to <code>true</code>, it reduces the amount of memory used by the bloom filter. But in some random-seek situations, it may reduce the read performance."},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#misc_configurations","title":"misc configurations","text":"<p>Caution</p> <p>The configuration <code>snapshot</code> in the following table is different from the snapshot in NebulaGraph. The <code>snapshot</code> here refers to the stock data on the leader when synchronizing Raft.</p> Name Predefined value Description <code>snapshot_part_rate_limit</code> <code>8388608</code> The rate limit when the Raft leader synchronizes the stock data with other members of the Raft group. Unit: bytes/s. <code>snapshot_batch_size</code> <code>1048576</code> The amount of data sent in each batch when the Raft leader synchronizes the stock data with other members of the Raft group. Unit: bytes. <code>rebuild_index_part_rate_limit</code> <code>4194304</code> The rate limit when the Raft leader synchronizes the index data rate with other members of the Raft group during the index rebuilding process. Unit: bytes/s. <code>rebuild_index_batch_size</code> <code>1048576</code> The amount of data sent in each batch when the Raft leader synchronizes the index data with other members of the Raft group during the index rebuilding process. Unit: bytes."},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#rocksdb_options","title":"RocksDB options","text":"Name Predefined value Description <code>rocksdb_db_options</code> <code>{}</code> Specifies the RocksDB database options. <code>rocksdb_column_family_options</code> <code>{\"write_buffer_size\":\"67108864\",</code><code>\"max_write_buffer_number\":\"4\",</code><code>\"max_bytes_for_level_base\":\"268435456\"}</code> Specifies the RocksDB column family options. <code>rocksdb_block_based_table_options</code> <code>{\"block_size\":\"8192\"}</code> Specifies the RocksDB block based table options. <p>The format of the RocksDB option is <code>{\"&lt;option_name&gt;\":\"&lt;option_value&gt;\"}</code>. Multiple options are separated with commas.</p> <p>Supported options of <code>rocksdb_db_options</code> and <code>rocksdb_column_family_options</code> are listed as follows.</p> <ul> <li><code>rocksdb_db_options</code><pre><code>max_total_wal_size\ndelete_obsolete_files_period_micros\nmax_background_jobs\nstats_dump_period_sec\ncompaction_readahead_size\nwritable_file_max_buffer_size\nbytes_per_sync\nwal_bytes_per_sync\ndelayed_write_rate\navoid_flush_during_shutdown\nmax_open_files\nstats_persist_period_sec\nstats_history_buffer_size\nstrict_bytes_per_sync\nenable_rocksdb_prefix_filtering\nenable_rocksdb_whole_key_filtering\nrocksdb_filtering_prefix_length\nnum_compaction_threads\nrate_limit\n</code></pre> </li> </ul> <ul> <li><code>rocksdb_column_family_options</code><pre><code>write_buffer_size\nmax_write_buffer_number\nlevel0_file_num_compaction_trigger\nlevel0_slowdown_writes_trigger\nlevel0_stop_writes_trigger\ntarget_file_size_base\ntarget_file_size_multiplier\nmax_bytes_for_level_base\nmax_bytes_for_level_multiplier\ndisable_auto_compactions \n</code></pre> </li> </ul> <p>For more information, see RocksDB official documentation.</p>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#for_super-large_vertices","title":"For super-Large vertices","text":"<p>When the query starting from each vertex gets an edge, truncate it directly to avoid too many neighboring edges on the super-large vertex, because a single query occupies too much hard disk and memory. Or you can truncate a certain number of edges specified in the <code>Max_edge_returned_per_vertex</code> parameter. Excess edges will not be returned. This parameter applies to all spaces.</p> Property name Default value Description max_edge_returned_per_vertex 2147483647 Specifies the maximum number of edges returned for each dense vertex. Excess edges are truncated and not returned. This parameter is not predefined in the configuration files. <p>Compatibility</p> <p>The reservoir sampling algorithm in NebulaGraph 1.x is no longer supported in NebulaGraph 2.6.2.</p>"},{"location":"5.configurations-and-logs/1.configurations/4.storage-config/#storage_configurations_for_large_dataset","title":"Storage configurations for large dataset","text":"<p>When you have a large dataset (in the RocksDB directory) and your memory is tight, we suggest that you set the <code>enable_partitioned_index_filter</code> parameter to <code>true</code>. The performance is affected because RocksDB indexes are cached.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/","title":"Kernel configurations","text":"<p>This topic introduces the Kernel configurations in Nebula\u00a0Graph.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#resource_control","title":"Resource control","text":""},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#ulimit_precautions","title":"ulimit precautions","text":"<p>The <code>ulimit</code> command specifies the resource threshold for the current shell session. The precautions are as follows:</p> <ul> <li>The changes made by <code>ulimit</code> only take effect for the current session or child process.</li> </ul> <ul> <li>The resource threshold (soft threshold) cannot exceed the hard threshold.</li> </ul> <ul> <li>Common users cannot use commands to adjust the hard threshold, even with <code>sudo</code>.</li> </ul> <ul> <li>To modify the system level or adjust the hard threshold, edit the file <code>/etc/security/limits.conf</code>. This method requires re-login to take effect.</li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#ulimit_-c","title":"ulimit -c","text":"<p><code>ulimit -c</code> limits the size of the core dumps. We recommend that you set it to <code>unlimited</code>. The command is:</p> <pre><code>ulimit -c unlimited\n</code></pre>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#ulimit_-n","title":"ulimit -n","text":"<p><code>ulimit -n</code> limits the number of open files. We recommend that you set it to more than 100,000. For example:</p> <pre><code>ulimit -n 130000\n</code></pre>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#memory","title":"Memory","text":""},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#vmswappiness","title":"vm.swappiness","text":"<p><code>vm.swappiness</code> specifies the percentage of the available memory before starting swap. The greater the value, the more likely the swap occurs. We recommend that you set it to 0. When set to 0, the page cache is removed first. Note that when <code>vm.swappiness</code> is 0, it does not mean that there is no swap.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#vmmin_free_kbytes","title":"vm.min_free_kbytes","text":"<p><code>vm.min_free_kbytes</code> specifies the minimum number of kilobytes available kept by Linux VM. If you have a large system memory, we recommend that you increase this value. For example, if your physical memory 128GB, set it to 5GB. If the value is not big enough, the system cannot apply for enough continuous physical memory.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#vmmax_map_count","title":"vm.max_map_count","text":"<p><code>vm.max_map_count</code> limits the maximum number of vma (virtual memory area) for a process. The default value is <code>65530</code>. It is enough for most applications. If your memory application fails because the memory consumption is large, increase the <code>vm.max_map_count</code> value.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#vmdirty_","title":"vm.dirty_*","text":"<p>These values control the dirty data cache for the system. For write-intensive scenarios, you can make adjustments based on your needs (throughput priority or delay priority). We recommend that you use the system default value.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#transparent_huge_page","title":"Transparent huge page","text":"<p>For better delay performance, you must disable the transparent huge pages (THP). The command is:</p> <pre><code>root# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\nroot# echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag\nroot# swapoff -a &amp;&amp; swapon -a\n</code></pre>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#networking","title":"Networking","text":""},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#netipv4tcp_slow_start_after_idle","title":"net.ipv4.tcp_slow_start_after_idle","text":"<p>The default value of <code>net.ipv4.tcp_slow_start_after_idle</code> is <code>1</code>. If set, the congestion window is timed out after an idle period. We recommend that you set it to <code>0</code>, especially for long fat scenarios (high latency and large bandwidth).</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#netcoresomaxconn","title":"net.core.somaxconn","text":"<p><code>net.core.somaxconn</code> specifies the maximum number of connection queues listened by the socket. The default value is <code>128</code>. For scenarios with a large number of burst connections, we recommend that you set it to greater than <code>1024</code>.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#netipv4tcp_max_syn_backlog","title":"net.ipv4.tcp_max_syn_backlog","text":"<p><code>net.ipv4.tcp_max_syn_backlog</code> specifies the maximum number of TCP connections in the SYN_RECV (semi-connected) state. The setting rule for this parameter is the same as that of <code>net.core.somaxconn</code>.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#netcorenetdev_max_backlog","title":"net.core.netdev_max_backlog","text":"<p><code>net.core.netdev_max_backlog</code> specifies the maximum number of packets. The default value is <code>1000</code>. We recommend that you increase it to greater than <code>10,000</code>, especially for 10G network adapters.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#netipv4tcp_keepalive_","title":"net.ipv4.tcp_keepalive_*","text":"<p>These values keep parameters alive for TCP connections. For applications that use a 4-layer transparent load balancer, if the idle connection is disconnected unexpectedly, decrease the values of <code>tcp_keepalive_time</code> and <code>tcp_keepalive_intvl</code>.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#netipv4tcp_rmemwmem","title":"net.ipv4.tcp_rmem/wmem","text":"<p><code>net.ipv4.tcp_wmem/rmem</code> specifies the minimum, default, and maximum size of the buffer pool sent/received by the TCP socket. For long fat links, we recommend that you increase the default value to <code>bandwidth (GB) * RTT (ms)</code>.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#scheduler","title":"scheduler","text":"<p>For SSD devices, we recommend that you set <code>scheduler</code> to <code>noop</code> or <code>none</code>. The path is <code>/sys/block/DEV_NAME/queue/scheduler</code>.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#other_parameters","title":"Other parameters","text":""},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#kernelcore_pattern","title":"kernel.core_pattern","text":"<p>we recommend that you set it to <code>core</code> and set <code>kernel.core_uses_pid</code> to <code>1</code>.</p>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#modify_parameters","title":"Modify parameters","text":""},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#sysctl","title":"sysctl","text":"<ul> <li> <p><code>sysctl &lt;conf_name&gt;</code></p> <p>Checks the current parameter value.</p> </li> </ul> <ul> <li> <p><code>sysctl -w &lt;conf_name&gt;=&lt;value&gt;</code></p> <p>Modifies the parameter value. The modification takes effect immediately. The original value is restored after restarting.</p> </li> </ul> <ul> <li> <p><code>sysctl -p [&lt;file_path&gt;]</code> </p> <p>Loads Linux parameter values \u200b\u200bfrom the specified configuration file. The default path is <code>/etc/sysctl.conf</code>.</p> </li> </ul>"},{"location":"5.configurations-and-logs/1.configurations/6.kernel-config/#prlimit","title":"prlimit","text":"<p>The <code>prlimit</code> command gets and sets process resource limits. You can modify the hard threshold by using it and the <code>sudo</code> command. For example, <code>prlimit --nofile = 130000 --pid = $$</code> adjusts the maximum number of open files permitted by the current process to <code>14000</code>. And the modification takes effect immediately. Note that this command is only available in RedHat 7u or higher versions.</p>"},{"location":"5.configurations-and-logs/2.log-management/logs/","title":"Logs","text":"<p>NebulaGraph uses glog to print logs, uses gflags to control the severity level of the log, and provides an HTTP interface to dynamically change the log level at runtime to facilitate tracking.</p>"},{"location":"5.configurations-and-logs/2.log-management/logs/#log_directory","title":"Log directory","text":"<p>The default log directory is <code>/usr/local/nebula/logs/</code>.</p> <p>If the log directory is deleted while NebulaGraph is running, the log would not continue to be printed. However, this operation will not affect the services. To recover the logs, restart the services.</p>"},{"location":"5.configurations-and-logs/2.log-management/logs/#parameter_descriptions","title":"Parameter descriptions","text":"<ul> <li><code>minloglevel</code>: Specifies the minimum level of the log. That is, no logs below this level will be printed. Optional values are <code>0</code> (INFO), <code>1</code> (WARNING), <code>2</code> (ERROR), <code>3</code> (FATAL). It is recommended to set it to <code>0</code> during debugging and <code>1</code> in a production environment. If it is set to <code>4</code>, NebulaGraph will not print any logs.</li> </ul> <ul> <li><code>v</code>: Specifies the detailed level of the log. The larger the value, the more detailed the log is. Optional values are <code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>.</li> </ul> <p>The default severity level for the metad, graphd, and storaged logs can be found in their respective configuration files. The default path is <code>/usr/local/nebula/etc/</code>.</p>"},{"location":"5.configurations-and-logs/2.log-management/logs/#check_the_severity_level","title":"Check the severity level","text":"<p>Check all the flag values (log values included) of the current gflags with the following command.</p> <pre><code>$ curl &lt;ws_ip&gt;:&lt;ws_port&gt;/flags\n</code></pre> Parameter Description <code>ws_ip</code> The IP address for the HTTP service, which can be found in the configuration files above. The default value is <code>127.0.0.1</code>. <code>ws_port</code> The port for the HTTP service, which can be found in the configuration files above. The default values are <code>19559</code>(Meta), <code>19669</code>(Graph), and <code>19779</code>(Storage) respectively. <p>Examples are as follows:</p> <ul> <li>Check the current <code>minloglevel</code> in the Meta service:<pre><code>$ curl 127.0.0.1:19559/flags | grep 'minloglevel'\n</code></pre> </li> </ul> <ul> <li>Check the current <code>v</code> in the Storage service:<pre><code>$ curl 127.0.0.1:19779/flags | grep -w 'v'\n</code></pre> </li> </ul>"},{"location":"5.configurations-and-logs/2.log-management/logs/#change_the_severity_level","title":"Change the severity level","text":"<p>Change the severity level of the log with the following command.</p> <pre><code>$ curl -X PUT -H \"Content-Type: application/json\" -d '{\"&lt;key&gt;\":&lt;value&gt;[,\"&lt;key&gt;\":&lt;value&gt;]}' \"&lt;ws_ip&gt;:&lt;ws_port&gt;/flags\"\n</code></pre> Parameter Description <code>key</code> The type of the log to be changed. For optional values, see Parameter descriptions. <code>value</code> The level of the log. For optional values, see Parameter descriptions. <code>ws_ip</code> The IP address for the HTTP service, which can be found in the configuration files above. The default value is <code>127.0.0.1</code>. <code>ws_port</code> The port for the HTTP service, which can be found in the configuration files above. The default values are <code>19559</code>(Meta), <code>19669</code>(Graph), and <code>19779</code>(Storage) respectively. <p>Examples are as follows:</p> <pre><code>$ curl -X PUT -H \"Content-Type: application/json\" -d '{\"minloglevel\":0,\"v\":3}' \"127.0.0.1:19779/flags\" # storaged\n$ curl -X PUT -H \"Content-Type: application/json\" -d '{\"minloglevel\":0,\"v\":3}' \"127.0.0.1:19669/flags\" # graphd\n$ curl -X PUT -H \"Content-Type: application/json\" -d '{\"minloglevel\":0,\"v\":3}' \"127.0.0.1:19559/flags\" # metad\n</code></pre> <p>If the log level is changed while NebulaGraph is running, it will be restored to the level set in the configuration file after restarting the service. To permanently modify it, see Configuration files.</p>"},{"location":"5.configurations-and-logs/2.log-management/logs/#rocksdb_logs","title":"RocksDB logs","text":"<p>RocksDB logs are usually used to debug RocksDB parameters and stored in <code>/usr/local/nebula/data/storage/nebula/$id/data/LOG</code>. <code>$id</code> is the ID of the example.</p>"},{"location":"6.monitor-and-metrics/1.query-performance-metrics/","title":"Query NebulaGraph metrics","text":"<p>NebulaGraph supports querying the monitoring metrics through HTTP ports.</p>"},{"location":"6.monitor-and-metrics/1.query-performance-metrics/#metrics","title":"Metrics","text":"<p>Each metric of NebulaGraph consists of three fields: name, type, and time range. The fields are separated by periods, for example, <code>num_queries.sum.600</code>. Different NebulaGraph services (Graph, Storage, or Meta) support different metrics. The detailed description is as follows.</p> Field Example Description Metric name <code>num_queries</code> Indicates the function of the metric. Metric type <code>sum</code> Indicates how the metrics are collected. Supported types are SUM, COUNT, AVG, RATE, and the P-th sample quantiles such as P75, P95, P99, and P99.9. Time range <code>600</code> The time range in seconds for the metric collection. Supported values are 5, 60, 600, and 3600, representing the last 5 seconds, 1 minute, 10 minutes, and 1 hour."},{"location":"6.monitor-and-metrics/1.query-performance-metrics/#query_metrics_over_http","title":"Query metrics over HTTP","text":""},{"location":"6.monitor-and-metrics/1.query-performance-metrics/#syntax","title":"Syntax","text":"<pre><code>curl -G \"http://&lt;ip&gt;:&lt;port&gt;/stats?stats=&lt;metric_name_list&gt; [&amp;format=json]\"\n</code></pre> Parameter Description <code>ip</code> The IP address of the server. You can find it in the configuration file in the installation directory. <code>port</code> The HTTP port of the server. You can find it in the configuration file in the installation directory. The default ports are 19559 (Meta), 19669 (Graph), and 19779 (Storage). <code>metric_name_list</code> The metrics names. Multiple metrics are separated by commas (,). <code>&amp;format=json</code> Optional. Returns the result in the JSON format. <p>Note</p> <p>If NebulaGraph is deployed with Docker Compose, run <code>docker-compose ps</code> to check the ports that are mapped from the service ports inside of the container and then query through them.</p>"},{"location":"6.monitor-and-metrics/1.query-performance-metrics/#examples","title":"Examples","text":"<ul> <li> <p>Query a single metric</p> <p>Query the query number in the last 10 minutes in the Graph Service.</p> <pre><code>$ curl -G \"http://192.168.8.40:19669/stats?stats=num_queries.sum.600\"\nnum_queries.sum.600=400\n</code></pre> </li> </ul> <ul> <li> <p>Query multiple metrics</p> <p>Query the following metrics together:</p> <ul> <li>The average heartbeat latency in the last 1 minute.</li> </ul> <ul> <li> <p>The average latency of the slowest 1% heartbeats, i.e., the P99 heartbeats, in the last 10 minutes.</p> <pre><code>$ curl -G \"http://192.168.8.40:19559/stats?stats=heartbeat_latency_us.avg.60,heartbeat_latency_us.p99.600\"\nheartbeat_latency_us.avg.60=281\nheartbeat_latency_us.p99.600=985\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p>Return a JSON result.</p> <p>Query the number of new vertices in the Storage Service in the last 10 minutes and return the result in the JSON format.</p> <pre><code>$ curl -G \"http://192.168.8.40:19779/stats?stats=num_add_vertices.sum.600&amp;format=json\"\n[{\"value\":1,\"name\":\"num_add_vertices.sum.600\"}]\n</code></pre> </li> </ul> <ul> <li> <p>Query all metrics in a service.</p> <p>If no metric is specified in the query, NebulaGraph returns all metrics in the service.</p> <pre><code>$ curl -G \"http://192.168.8.40:19559/stats\"\nheartbeat_latency_us.avg.5=304\nheartbeat_latency_us.avg.60=308\nheartbeat_latency_us.avg.600=299\nheartbeat_latency_us.avg.3600=285\nheartbeat_latency_us.p75.5=652\nheartbeat_latency_us.p75.60=669\nheartbeat_latency_us.p75.600=651\nheartbeat_latency_us.p75.3600=642\nheartbeat_latency_us.p95.5=930\nheartbeat_latency_us.p95.60=963\nheartbeat_latency_us.p95.600=933\nheartbeat_latency_us.p95.3600=929\nheartbeat_latency_us.p99.5=986\nheartbeat_latency_us.p99.60=1409\nheartbeat_latency_us.p99.600=989\nheartbeat_latency_us.p99.3600=986\nnum_heartbeats.rate.5=0\nnum_heartbeats.rate.60=0\nnum_heartbeats.rate.600=0\nnum_heartbeats.rate.3600=0\nnum_heartbeats.sum.5=2\nnum_heartbeats.sum.60=40\nnum_heartbeats.sum.600=394\nnum_heartbeats.sum.3600=2364\n</code></pre> </li> </ul>"},{"location":"6.monitor-and-metrics/2.rocksdb-statistics/","title":"RocksDB statistics","text":"<p>NebulaGraph uses RocksDB as the underlying storage. This topic describes how to collect and show the RocksDB statistics of NebulaGraph.</p>"},{"location":"6.monitor-and-metrics/2.rocksdb-statistics/#enable_rocksdb","title":"Enable RocksDB","text":"<p>By default, the function of RocksDB statistics is disabled. To enable RocksDB statistics, you need to:</p> <ol> <li> <p>Modify the <code>--enable_rocksdb_statistics</code> parameter as <code>true</code> in the <code>nebula-storaged.conf</code> file. The default path of the configuration file is <code>/use/local/nebula/etc</code>.</p> </li> <li> <p>Restart the service to make the modification valid.</p> </li> </ol>"},{"location":"6.monitor-and-metrics/2.rocksdb-statistics/#get_rocksdb_statistics","title":"Get RocksDB statistics","text":"<p>Users can use the built-in HTTP service in the storage service to get the following types of statistics. Results in the JSON format are supported.</p> <ul> <li>All RocksDB statistics.</li> <li>Specified RocksDB statistics.</li> </ul>"},{"location":"6.monitor-and-metrics/2.rocksdb-statistics/#examples","title":"Examples","text":"<p>Use the following command to get all RocksDB statistics: <pre><code>curl -L \"http://${storage_ip}:${port}/rocksdb_stats\"\n</code></pre></p> <p>For example: <pre><code>curl -L \"http://172.28.2.1:19779/rocksdb_stats\"\n\nrocksdb.blobdb.blob.file.bytes.read=0\nrocksdb.blobdb.blob.file.bytes.written=0\nrocksdb.blobdb.blob.file.bytes.synced=0\n...\n</code></pre></p> <p>Use the following command to get specified RocksDB statistics: <pre><code>curl -L \"http://${storage_ip}:${port}/rocksdb_stats?stats=${stats_name}\"\n</code></pre></p> <p>For example, use the following command to get the information of <code>rocksdb.bytes.read</code> and <code>rocksdb.block.cache.add</code>. <pre><code>curl -L \"http://172.28.2.1:19779/rocksdb_stats?stats=rocksdb.bytes.read,rocksdb.block.cache.add\"\n\nrocksdb.block.cache.add=14\nrocksdb.bytes.read=1632\n</code></pre></p> <p>Use the following command to get specified RocksDB statistics in the JSON format: <pre><code>curl -L \"http://${storage_ip}:${port}/rocksdb_stats?stats=${stats_name}&amp;format=json\"\n</code></pre></p> <p>For example, use the following command to get the information of <code>rocksdb.bytes.read</code> and <code>rocksdb.block.cache.add</code> and return the results in the JSON format. <pre><code>curl -L \"http://172.28.2.1:19779/rocksdb_stats?stats=rocksdb.bytes.read,rocksdb.block.cache.add&amp;format=json\"\n\n[\n{\n\"rocksdb.block.cache.add\": 1\n},\n  {\n\"rocksdb.bytes.read\": 160\n}\n]\n</code></pre></p>"},{"location":"7.data-security/3.manage-snapshot/","title":"Backup and restore data with snapshots","text":"<p>NebulaGraph supports using snapshots to back up and restore data. When data loss or misoperation occurs, the data will be restored through the snapshot.</p>"},{"location":"7.data-security/3.manage-snapshot/#prerequisites","title":"Prerequisites","text":"<p>NebulaGraph authentication is disabled by default. In this case, all users can use the snapshot feature.</p> <p>If authentication is enabled, only the GOD role user can use the snapshot feature. For more information about roles, see Roles and privileges.</p>"},{"location":"7.data-security/3.manage-snapshot/#precautions","title":"Precautions","text":"<ul> <li>To prevent data loss, create a snapshot as soon as the system structure changes, for example, after operations such as <code>ADD HOST</code>, <code>DROP HOST</code>, <code>CREATE SPACE</code>, <code>DROP SPACE</code>, and <code>BALANCE</code> are performed.</li> </ul> <ul> <li>NebulaGraph cannot automatically delete the invalid files created by a failed snapshot task. You have to manually delete them by using <code>DROP SNAPSHOT</code>.</li> </ul> <ul> <li>Customizing the storage path for snapshots is not supported for now. The default path is <code>/usr/local/nebula/data</code>.</li> </ul>"},{"location":"7.data-security/3.manage-snapshot/#snapshot_form_and_path","title":"Snapshot form and path","text":"<p>NebulaGraph snapshots are stored in the form of directories with names like <code>SNAPSHOT_2021_03_09_08_43_12</code>. The suffix <code>2021_03_09_08_43_12</code> is generated automatically based on the creation time (UTC).</p> <p>When a snapshot is created, snapshot directories will be automatically created in the <code>checkpoints</code> directory on the leader Meta server and each Storage server.</p> <p>To fast locate the path where the snapshots are stored, you can use the Linux command <code>find</code>. For example:</p> <pre><code>$ find |grep 'SNAPSHOT_2021_03_09_08_43_12'\n./data/meta2/nebula/0/checkpoints/SNAPSHOT_2021_03_09_08_43_12\n./data/meta2/nebula/0/checkpoints/SNAPSHOT_2021_03_09_08_43_12/data\n./data/meta2/nebula/0/checkpoints/SNAPSHOT_2021_03_09_08_43_12/data/000081.sst\n...\n</code></pre>"},{"location":"7.data-security/3.manage-snapshot/#create_snapshots","title":"Create snapshots","text":"<p>Run <code>CREATE SNAPSHOT</code> to create a snapshot for all the graph spaces based on the current time for NebulaGraph. Creating a snapshot for a specific graph space is not supported yet.</p> <p>Note</p> <p>If the creation fails, delete the snapshot and try again.</p> <pre><code>nebula&gt; CREATE SNAPSHOT;\n</code></pre>"},{"location":"7.data-security/3.manage-snapshot/#view_snapshots","title":"View snapshots","text":"<p>To view all existing snapshots, run <code>SHOW SNAPSHOTS</code>.</p> <pre><code>nebula&gt; SHOW SNAPSHOTS;\n+--------------------------------+---------+------------------+\n| Name                           | Status  | Hosts            |\n+--------------------------------+---------+------------------+\n| \"SNAPSHOT_2021_03_09_08_43_12\" | \"VALID\" | \"127.0.0.1:9779\" |\n| \"SNAPSHOT_2021_03_09_09_10_52\" | \"VALID\" | \"127.0.0.1:9779\" |\n+--------------------------------+---------+------------------+\n</code></pre> <p>The parameters in the return information are described as follows.</p> <p>| Parameter | Description                                                                                                                                                             | |-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | <code>Name</code>    | The name of the snapshot directory. The prefix <code>SNAPSHOT</code> indicates that the file is a snapshot file, and the suffix indicates the time the snapshot was created (UTC). | | <code>Status</code>  | The status of the snapshot. <code>VALID</code> indicates that the creation succeeded, while <code>INVALID</code> indicates that it failed.                                                    | | <code>Hosts</code>   | IP addresses and ports of all Storage servers at the time the snapshot was created.                                                                                     |</p>"},{"location":"7.data-security/3.manage-snapshot/#delete_snapshots","title":"Delete snapshots","text":"<p>To delete a snapshot with the given name, run <code>DROP SNAPSHOT</code>.</p> <pre><code>DROP SNAPSHOT &lt;snapshot_name&gt;;\n</code></pre> <p>Example:</p> <pre><code>nebula&gt; DROP SNAPSHOT SNAPSHOT_2021_03_09_08_43_12;\nnebula&gt; SHOW SNAPSHOTS;\n+--------------------------------+---------+------------------+\n| Name                           | Status  | Hosts            |\n+--------------------------------+---------+------------------+\n| \"SNAPSHOT_2021_03_09_09_10_52\" | \"VALID\" | \"127.0.0.1:9779\" |\n+--------------------------------+---------+------------------+\n</code></pre>"},{"location":"7.data-security/3.manage-snapshot/#restore_data_with_snapshots","title":"Restore data with snapshots","text":"<p>Currently, there is no command to restore data with snapshots. You need to manually copy the snapshot file to the corresponding folder, or you can make it by using a shell script. The logic implements as follows:</p> <ol> <li> <p>After the snapshot is created, the <code>checkpoints</code> directory is generated in the installation directory of the leader Meta server and all Storage servers, and saves the created snapshot. Taking this topic as an example, when there are two graph spaces, the snapshots created are saved in <code>/usr/local/nebula/data/meta/nebula/0/checkpoints</code>, <code>/usr/local/nebula/data/storage/ nebula/3/checkpoints</code> and <code>/usr/local/nebula/data/storage/nebula/4/checkpoints</code>.</p> <pre><code>$ ls /usr/local/nebula/data/meta/nebula/0/checkpoints/\nSNAPSHOT_2021_03_09_09_10_52\n$ ls /usr/local/nebula/data/storage/nebula/3/checkpoints/\nSNAPSHOT_2021_03_09_09_10_52\n$ ls /usr/local/nebula/data/storage/nebula/4/checkpoints/\nSNAPSHOT_2021_03_09_09_10_52\n</code></pre> </li> <li> <p>To restore the lost data through snapshots, you can take a snapshot at an appropriate time, copy the folders <code>data</code> and <code>wal</code> in the corresponding snapshot directory to its parent directory (at the same level with <code>checkpoints</code>) to overwrite the previous <code>data</code> and <code>wal</code>, and then restart the cluster.</p> <p>Caution</p> <p>The data and wal directories of all Meta servers should be overwritten at the same time. Otherwise, the new leader Meta server will use the latest Meta data after a cluster is restarted. </p> </li> </ol>"},{"location":"7.data-security/4.ssl/","title":"SSL encryption","text":"<p>NebulaGraph supports data transmission with SSL encryption between clients, the Graph service, the Meta service, and the Storage service. This topic describes how to enable SSL encryption.</p>"},{"location":"7.data-security/4.ssl/#precaution","title":"Precaution","text":"<p>Enabling SSL encryption will slightly affect the performance, such as causing operation latency.</p>"},{"location":"7.data-security/4.ssl/#parameters","title":"Parameters","text":"Parameter Default value Description <code>cert_path</code> - The path to the PEM certification. <code>key_path</code> - The path to the key certification. <code>password_path</code> - The path to the password file certification. <code>ca_path</code> - The path to the trusted CA file. <code>enable_ssl</code> <code>false</code> Whether to enable SSL encryption. <code>enable_graph_ssl</code> <code>false</code> Whether to enable SSL encryption in the Graph service only. <code>enable_meta_ssl</code> <code>false</code> Whether to enable SSL encryption in the Meta service only."},{"location":"7.data-security/4.ssl/#certificate_modes","title":"Certificate modes","text":"<p>To use SSL encryption, SSL certificates are required. NebulaGraph supports two certificate modes.</p> <ul> <li> <p>Self-signed certificate mode</p> <p>In this mode, users need to make the signed certificate by themselves and set <code>cert_path</code>, <code>key_path</code>, and <code>password_path</code> in the corresponding file according to encryption policies.</p> </li> </ul> <ul> <li> <p>CA-signed certificate mode</p> <p>In this mode, users need to apply for the signed certificate from a certificate authority and set <code>cert_path</code>, <code>key_path</code>, and <code>password_path</code> in the corresponding file according to encryption policies.</p> </li> </ul>"},{"location":"7.data-security/4.ssl/#encryption_policies","title":"Encryption policies","text":"<p>NebulaGraph supports three encryption policies. For details, see Usage explanation.</p> <ul> <li> <p>Encrypt the data transmission between clients, the Graph service, the Meta service, and the Storage service.</p> <p>Add <code>enable_ssl = true</code> to the configuration files of <code>nebula-graphd.conf</code>, <code>nebula-metad.conf</code>, and <code>nebula-storaged.conf</code>.</p> </li> </ul> <ul> <li> <p>Encrypt the data transmission between clients and the Graph service.</p> <p>This policy applies to the case that the clusters are set in the same server room. Only the port of the Graph service is open to the outside because other services can communicate over the internal network without encryption. Add <code>enable_graph_ssl = true</code> to the configuration file of <code>nebula-graphd.conf</code>.</p> </li> </ul> <ul> <li> <p>Encrypt the data transmission related to the Meta service in the cluster.</p> <p>This policy applies to transporting classified information to the Meta service. Add <code>enable_meta_ssl = true</code> to the configuration files of <code>nebula-graphd.conf</code>, <code>nebula-metad.conf</code>, and <code>nebula-storaged.conf</code>.</p> </li> </ul>"},{"location":"7.data-security/4.ssl/#steps","title":"Steps","text":"<ol> <li> <p>Ensure the certificate mode and the encryption policy.</p> </li> <li> <p>Add the certificate configuration and the policy configuration in corresponding files.</p> <p>For example, the three configuration files need to be set as follows when using a self-signed certificate and encrypt data transmission between clients, the Graph service, the Meta service, and the Storage service.</p> <pre><code>--cert_path=xxxxxx\n--key_path=xxxxx\n--password_path=xxxxxx\n--enable_ssl=true\n</code></pre> </li> <li> <p>Set the SSL and the trusted CA in clients. For code examples, see nebula-test-run.py.</p> </li> </ol>"},{"location":"7.data-security/5.zone/","title":"Group&amp;Zone","text":"<p>The Group&amp;Zone feature groups the nodes where Storage services are located (also called Storage nodes) to isolate resources.</p>"},{"location":"7.data-security/5.zone/#background","title":"Background","text":"<p>Storage nodes can be added into a Zone, and multiple Zones form a Group. If you specify a Group when creating a space, the space will be created and stored on the Storage nodes within the Group. Data partitions and replicas are stored evenly in each Zone as shown below.</p> <p></p> <p>Suppose that 8 Storage nodes are divided into 4 Zones, with each one having 2 Storage nodes, and then add Zone1, Zone2, and Zone3 into Group1, add Zone3 and Zone4 into Group2.</p> <p>After specifying Group1 when you create a space called S1, data partitions and replicas will be stored evenly on the nodes in Zone1, Zone2, and Zone3, and will not be stored on the node in Zone4.</p> <p>After specifying Group2 when you create another space called S2, data partitions and replicas will be stored evenly on the nodes in Zone3 and Zone4, and will not be stored on the nodes in Zone1 and Zone2.</p> <p>The above example briefly introduces the zone feature. Users can isolate resources by balanced planning of Zones and Groups.</p>"},{"location":"7.data-security/5.zone/#scenarios","title":"Scenarios","text":"<ul> <li>Create a space on specified Storage nodes to isolate resources.</li> </ul> <ul> <li>Perform rolling upgrade of a cluster which requires stopping one or more nodes before the cluster is upgraded, and then restart the nodes until all services on the nodes in the cluster are updated to the latest version.</li> </ul>"},{"location":"7.data-security/5.zone/#precautions","title":"Precautions","text":"<ul> <li>A Zone is a collection of Storage nodes, and each Storage node can only be added into one Zone.</li> </ul> <ul> <li>Replicas can be restored in a Zone, and only one replica of the same partition can exist in a Zone.</li> </ul> <ul> <li>Many Zones can form a Group for easy management and resource isolation.</li> </ul> <ul> <li>A Zone can be added into multiple Groups.</li> </ul> <ul> <li>If you specify a Group when creating a space, replicas in the space will be distributed evenly in each Zone within the Group.</li> </ul> <ul> <li>You can create multiple spaces using a Group\uff0cbut note that the number of Zones in the Group needs to be greater than or equal to the number of replicas (<code>replica_factor</code>) specified when creating a space.</li> </ul>"},{"location":"7.data-security/5.zone/#syntax","title":"Syntax","text":""},{"location":"7.data-security/5.zone/#add_zone","title":"ADD ZONE","text":"<p>Create a Zone and add Storage nodes into the Zone.</p> <pre><code>ADD ZONE &lt;zone_name&gt; &lt;host1&gt;:&lt;port1&gt; [,&lt;host2&gt;:&lt;port2&gt;...];\n</code></pre> <p>For example:</p> <pre><code>nebula&gt; ADD ZONE zone1 192.168.8.111:9779, 192.168.8.129:9779;\n</code></pre>"},{"location":"7.data-security/5.zone/#add_hostinto_zone","title":"ADD HOST...INTO ZONE","text":"<p>Add a Storage node into a created Zone.</p> <p>Note</p> <p>Use the BALANCE command to implement load balance after the Storage node is added into a created Zone.</p> <pre><code>ADD HOST &lt;host1&gt;:&lt;port1&gt; INTO ZONE &lt;zone_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#drop_hostfrom_zone","title":"DROP HOST...FROM ZONE","text":"<p>Delete a Storage node from a Zone.</p> <p>Note</p> <p>You cannot delete a Storage node that is being used in a Group directly until the related space is deleted.</p> <pre><code>DROP HOST &lt;host1&gt;:&lt;port1&gt; FROM ZONE &lt;zone_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#show_zones","title":"SHOW ZONES","text":"<p>View all Zones.</p> <pre><code>SHOW ZONES;\n</code></pre>"},{"location":"7.data-security/5.zone/#describe_zone","title":"DESCRIBE ZONE","text":"<p>View a specified Zone.</p> <pre><code>DESCRIBE ZONE &lt;zone_name&gt;;\nDESC ZONE &lt;zone_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#drop_zone","title":"DROP ZONE","text":"<p>Delete a Zone.</p> <p>Note</p> <p>You cannot delete a Zone that has been added into a Group until the Zone is removed from the Group or the Group to which the Zone belongs is deleted.</p> <pre><code>DROP ZONE &lt;zone_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#add_group","title":"ADD GROUP","text":"<p>Create a Group and add one or more Zones into the Group.</p> <pre><code>ADD GROUP &lt;group_name&gt; &lt;zone_name&gt; [,&lt;zone_name&gt;...];\n</code></pre> <p>For example:</p> <pre><code>nebula&gt; ADD GROUP group1 zone1,zone2;\n</code></pre>"},{"location":"7.data-security/5.zone/#add_zoneinto_group","title":"ADD ZONE...INTO GROUP","text":"<p>Add a Zone into a created Group.</p> <p>Note</p> <p>Use the BALANCE command to implement load balance after the Zone is added into a created Group.</p> <pre><code>ADD ZONE &lt;zone_name&gt; INTO GROUP &lt;group_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#drop_zonefrom_group","title":"DROP ZONE...FROM GROUP","text":"<p>Delete a Zone from a GROUP.</p> <p>Note</p> <p>You cannot delete a Zone that is being used in a Group directly until the related space is deleted.</p> <pre><code>DROP ZONE &lt;zone_name&gt; FROM GROUP &lt;group_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#show_groups","title":"SHOW GROUPS","text":"<p>View all Groups.</p> <pre><code>SHOW GROUPS;\n</code></pre>"},{"location":"7.data-security/5.zone/#describe_group","title":"DESCRIBE GROUP","text":"<p>View a specified Group.</p> <pre><code>DESCRIBE GROUP &lt;group_name&gt;;\nDESC GROUP &lt;group_name&gt;;\n</code></pre>"},{"location":"7.data-security/5.zone/#drop_group","title":"DROP GROUP","text":"<p>Delete a Group.</p> <p>Note</p> <p>You cannot delete a Group that is being used directly until the related space is deleted.</p> <pre><code>DROP GROUP &lt;group_name&gt;;\n</code></pre>"},{"location":"7.data-security/1.authentication/1.authentication/","title":"Authentication","text":"<p>NebulaGraph replies on local authentication or LDAP authentication to implement access control.</p> <p>NebulaGraph creates a session when a client connects to it. The session stores information about the connection, including the user information. If the authentication system is enabled, the session will be mapped to corresponding users.</p> <p>Note</p> <p>By default, the authentication is disabled and NebulaGraph allows connections with the username <code>root</code> and any password.</p> <p>NebulaGraph supports local authentication and LDAP authentication.</p>"},{"location":"7.data-security/1.authentication/1.authentication/#local_authentication","title":"Local authentication","text":"<p>Local authentication indicates that usernames and passwords are stored locally on the server, with the passwords encrypted. Users will be authenticated when trying to visit NebulaGraph.</p>"},{"location":"7.data-security/1.authentication/1.authentication/#enable_local_authentication","title":"Enable local authentication","text":"<ol> <li> <p>Modify the <code>nebula-graphd.conf</code> file (<code>/usr/local/nebula/etc/</code> is the default path), set <code>--enable_authorize=true</code> and save the modification.</p> </li> <li> <p>Restart the NebulaGraph services. For how to restart, see Manage NebulaGraph services.</p> </li> </ol> <p>Note</p> <p>You can use the username <code>root</code> and password <code>nebula</code> to log into NebulaGraph after enabling local authentication. This account has the build-in God role. For more information about roles, see Roles and privileges.</p>"},{"location":"7.data-security/1.authentication/1.authentication/#ldap_authentication","title":"LDAP authentication","text":"<p>Lightweight Directory Access Protocol (LDAP) is a lightweight client-server protocol for accessing directories and building a centralized account management system. LDAP authentication and local authentication can be enabled at the same time, but LDAP authentication has a higher priority. If the local authentication server and the LDAP server both have the information of user <code>Amber</code>, NebulaGraph reads from the LDAP server first.</p>"},{"location":"7.data-security/1.authentication/1.authentication/#enable_ldap_authentication","title":"Enable LDAP authentication","text":"<p>Enterpriseonly</p> <p>LDAP authentication is an Enterprise-only feature. For how to enable LDAP, see Authenticate with an LDAP server (TODO: doc).</p>"},{"location":"7.data-security/1.authentication/2.management-user/","title":"User management","text":"<p>User management is an indispensable part of NebulaGraph access control. This topic describes how to manage users and roles.</p> <p>After enabling authentication, only valid users can connect to NebulaGraph and access the resources according to the user roles.</p> <p>Note</p> <ul> <li>By default, the authentication is disabled. NebulaGraph allows connections with the username <code>root</code> and any password.</li> <li>Once the role of a user is modified, the user has to re-login to make the new role takes effect.</li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#create_user","title":"CREATE USER","text":"<p>The <code>root</code> user with the GOD role can run <code>CREATE USER</code> to create a new user.</p> <ul> <li> <p>Syntax</p> <pre><code>CREATE USER [IF NOT EXISTS] &lt;user_name&gt; [WITH PASSWORD '&lt;password&gt;'];\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; CREATE USER user1 WITH PASSWORD 'nebula';\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#grant_role","title":"GRANT ROLE","text":"<p>Users with the GOD role or the ADMIN role can run <code>GRANT ROLE</code> to assign a built-in role in a graph space to a user. For more information about NebulaGraph built-in roles, see Roles and privileges.</p> <ul> <li> <p>Syntax</p> <pre><code>GRANT ROLE &lt;role_type&gt; ON &lt;space_name&gt; TO &lt;user_name&gt;;\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; GRANT ROLE USER ON basketballplayer TO user1;\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#revoke_role","title":"REVOKE ROLE","text":"<p>Users with the GOD role or the ADMIN role can run <code>REVOKE ROLE</code> to revoke the built-in role of a user in a graph space. For more information about NebulaGraph built-in roles, see Roles and privileges.</p> <ul> <li> <p>Syntax</p> <pre><code>REVOKE ROLE &lt;role_type&gt; ON &lt;space_name&gt; FROM &lt;user_name&gt;;\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; REVOKE ROLE USER ON basketballplayer FROM user1;\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#show_roles","title":"SHOW ROLES","text":"<p>Users can run <code>SHOW ROLES</code> to list the roles in a graph space.</p> <ul> <li> <p>Syntax</p> <pre><code>SHOW ROLES IN &lt;space_name&gt;;\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; SHOW ROLES IN basketballplayer;\n+---------+-----------+\n| Account | Role Type |\n+---------+-----------+\n| \"user1\" | \"ADMIN\"   |\n+---------+-----------+\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#change_password","title":"CHANGE PASSWORD","text":"<p>Users can run <code>CHANGE PASSWORD</code> to set a new password for a user. The old password is needed when setting a new one.</p> <ul> <li> <p>Syntax</p> <pre><code>CHANGE PASSWORD &lt;user_name&gt; FROM '&lt;old_password&gt;' TO '&lt;new_password&gt;';\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; CHANGE PASSWORD user1 FROM 'nebula' TO 'nebula123';\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#alter_user","title":"ALTER USER","text":"<p>The <code>root</code> user with the GOD role can run <code>ALTER USER</code> to set a new password for a user. The old password is not needed when setting a new one.</p> <ul> <li> <p>Syntax</p> <pre><code>ALTER USER &lt;user_name&gt; WITH PASSWORD '&lt;password&gt;';\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; ALTER USER user1 WITH PASSWORD 'nebula';\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#drop_user","title":"DROP USER","text":"<p>The <code>root</code> user with the GOD role can run <code>DROP USER</code> to remove a user.</p> <p>Note</p> <p>Removing a user does not close the current session of the user, and the user role still takes effect in the session until the session is closed.</p> <ul> <li> <p>Syntax</p> <pre><code>DROP USER [IF EXISTS] &lt;user_name&gt;;\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; DROP USER user1;\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/2.management-user/#show_users","title":"SHOW USERS","text":"<p>The <code>root</code> user with the GOD role can run <code>SHOW USERS</code> to list all the users.</p> <ul> <li> <p>Syntax</p> <pre><code>SHOW USERS;\n</code></pre> </li> </ul> <ul> <li> <p>Example</p> <pre><code>nebula&gt; SHOW USERS;\n+-----------+\n| Account   |\n+-----------+\n| \"test1\"   |\n| \"test2\"   |\n| \"test3\"   |\n+-----------+\n</code></pre> </li> </ul>"},{"location":"7.data-security/1.authentication/3.role-list/","title":"Roles and privileges","text":"<p>A role is a collection of privileges. You can assign a role to a user for access control.</p>"},{"location":"7.data-security/1.authentication/3.role-list/#built-in_roles","title":"Built-in roles","text":"<p>NebulaGraph does not support custom roles, but it has multiple built-in roles:</p> <ul> <li> <p>GOD</p> <ul> <li>GOD is the original role with all privileges not limited to graph spaces. It is similar to <code>root</code> in Linux and <code>administrator</code> in Windows.</li> </ul> <ul> <li>When the Meta Service is initialized, the one and only GOD role user <code>root</code> is automatically created with the password <code>nebula</code>.</li> </ul> <p>Caution</p> <p>Modify the password for <code>root</code> timely for security.</p> <ul> <li>One cluster can only have one user with the GOD role. This user can manage all graph spaces in a cluster.</li> </ul> <ul> <li>Manual authorization of the God role is not supported. Only the <code>root</code> user with the default God role can be used.</li> </ul> </li> </ul> <ul> <li> <p>ADMIN</p> <ul> <li>An ADMIN role can read and write both the Schema and the data in a specific graph space.</li> </ul> <ul> <li> <p>An ADMIN role of a graph space can grant DBA, USER, and GUEST roles in the graph space to other users.</p> <p>Note</p> <p>Only roles lower than ADMIN can be authorized to other users.</p> </li> </ul> </li> </ul> <ul> <li> <p>DBA</p> <ul> <li>A DBA role can read and write both the Schema and the data in a specific graph space.</li> </ul> <ul> <li>A DBA role of a graph space CANNOT grant roles to other users.</li> </ul> </li> </ul> <ul> <li> <p>USER</p> <ul> <li>A USER role can read and write data in a specific graph space.</li> </ul> <ul> <li>The Schema information is read-only to the USER roles in a graph space.</li> </ul> </li> </ul> <ul> <li>GUEST<ul> <li>A GUEST role can only read the Schema and the data in a specific graph space.</li> </ul> </li> </ul> <p>Note</p> <ul> <li>NebulaGraph does not support custom roles. Users can only use the default built-in roles.</li> <li>A user can have only one role in a graph space. For authenticated users, see User management.</li> </ul>"},{"location":"7.data-security/1.authentication/3.role-list/#role_privileges_and_allowed_ngql","title":"Role privileges and allowed nGQL","text":"<p>The privileges of roles and the nGQL statements that each role can use are listed as follows.</p> Privilege God Admin DBA User Guest Allowed nGQL Read space Y Y Y Y Y <code>USE</code>, <code>DESCRIBE SPACE</code> Write space Y <code>CREATE SPACE</code>, <code>DROP SPACE</code>, <code>CREATE SNAPSHOT</code>, <code>DROP SNAPSHOT</code>, <code>BALANCE DATA</code>, <code>BALANCE DATA STOP</code>, <code>BALANCE DATA REMOVE</code>, <code>BALANCE LEADER</code>, <code>ADMIN</code>, <code>CONFIG</code>, <code>INGEST</code>, <code>DOWNLOAD</code>, <code>BUILD TAG INDEX</code>, <code>BUILD EDGE INDEX</code> Read schema Y Y Y Y Y <code>DESCRIBE TAG</code>, <code>DESCRIBE EDGE</code>, <code>DESCRIBE TAG INDEX</code>, <code>DESCRIBE EDGE INDEX</code> Write schema Y Y Y <code>CREATE TAG</code>, <code>ALTER TAG</code>, <code>CREATE EDGE</code>, <code>ALTER EDGE</code>, <code>DROP TAG</code>, <code>DELETE TAG</code>, <code>DROP EDGE</code>, <code>CREATE TAG INDEX</code>, <code>CREATE EDGE INDEX</code>, <code>DROP TAG INDEX</code>, <code>DROP EDGE INDEX</code> Write user Y <code>CREATE USER</code>, <code>DROP USER</code>, <code>ALTER USER</code> Write role Y Y <code>GRANT</code>, <code>REVOKE</code> Read data Y Y Y Y Y <code>GO</code>, <code>SET</code>, <code>PIPE</code>, <code>MATCH</code>, <code>ASSIGNMENT</code>, <code>LOOKUP</code>, <code>YIELD</code>, <code>ORDER BY</code>, <code>FETCH VERTICES</code>, <code>Find</code>, <code>FETCH EDGES</code>, <code>FIND PATH</code>, <code>LIMIT</code>, <code>GROUP BY</code>, <code>RETURN</code> Write data Y Y Y Y <code>INSERT VERTEX</code>, <code>UPDATE VERTEX</code>, <code>INSERT EDGE</code>, <code>UPDATE EDGE</code>, <code>DELETE VERTEX</code>, <code>DELETE EDGES</code>, <code>DELETE TAG</code> Show operations Y Y Y Y Y <code>SHOW</code>, <code>CHANGE PASSWORD</code> Job Y Y Y Y <code>SUBMIT JOB COMPACT</code>\u3001<code>SUBMIT JOB FLUSH</code>\u3001<code>SUBMIT JOB STATS</code>\u3001<code>STOP JOB</code>\u3001<code>RECOVER JOB</code> <p>Caution</p> <ul> <li>The results of <code>SHOW</code> operations are limited to the role of a user. For example, all users can run <code>SHOW SPACES</code>, but the results only include the graph spaces that the users have privileges.</li> <li>Only the GOD role can run <code>SHOW USERS</code> and <code>SHOW SNAPSHOTS</code>.</li> </ul>"},{"location":"7.data-security/1.authentication/4.ldap/","title":"OpenLDAP authentication","text":"<p>This topic introduces how to connect NebulaGraph to the OpenLDAP server and use the DN (Distinguished Name) and password defined in OpenLDAP for authentication.</p> <p>Enterpriseonly</p> <p>This feature is supported by the Enterprise Edition only.</p>"},{"location":"7.data-security/1.authentication/4.ldap/#authentication_method","title":"Authentication method","text":"<p>After the OpenLDAP authentication is enabled and users log into NebulaGraph with the account and password, NebulaGraph checks whether the login account exists in the Meta service. If the account exists, NebulaGraph finds the corresponding DN in OpenLDAP according to the authentication method and verifies the password.</p> <p>OpenLDAP supports two authentication methods: simple bind authentication (SimpleBindAuth) and search bind authentication (SearchBindAuth).</p>"},{"location":"7.data-security/1.authentication/4.ldap/#simplebindauth","title":"SimpleBindAuth","text":"<p>Simple bind authentication splices the login account and the configuration information of Graph services into a DN that can be recognized by OpenLDAP, and then authenticates on OpenLDAP based on the DN and password.</p>"},{"location":"7.data-security/1.authentication/4.ldap/#searchbindauth","title":"SearchBindAuth","text":"<p>Search bind authentication reads the Graph service configuration information and queries whether the <code>uid</code> in the configuration matches the login account. If they match, search bind authentication reads the DN, and then uses the DN and password to verify on OpenLDAP.</p>"},{"location":"7.data-security/1.authentication/4.ldap/#prerequisites","title":"Prerequisites","text":"<ul> <li>OpenLDAP is installed.</li> </ul> <ul> <li>The account and password are imported on OpenLDAP.</li> </ul> <ul> <li>The server where OpenLDAP is located has opened the corresponding authentication port.</li> </ul>"},{"location":"7.data-security/1.authentication/4.ldap/#procedures","title":"Procedures","text":"<p>Take the existing account <code>test2</code> and password <code>passwdtest2</code> on OpenLDAP as an example.</p> <ol> <li> <p>Connect to NebulaGraph, create and authorize the shadow account <code>test2</code> corresponding to OpenLDAP.</p> <pre><code>nebula&gt; CREATE USER test2 WITH PASSWORD '';\nnebula&gt; GRANT ROLE ADMIN ON basketballplayer TO test2;\n</code></pre> <p>!!! note</p> <pre><code>  When creating an account in NebulaGraph, the password can be set arbitrarily.\n</code></pre> </li> <li> <p>Edit the configuration file <code>nebula-graphd.conf</code> (The default path is<code>/usr/local/nebula/etc/</code>):</p> <ul> <li> <p>SimpleBindAuth (Recommended)</p> <pre><code># Whether to get the configuration information from the configuration file.\n--local_config=true\n# Whether to enable authentication.\n--enable_authorize=true\n# Authentication methods include password, ldap, and cloud.\n--auth_type=ldap\n# The address of the OpenLDAP server.\n--ldap_server=192.168.8.211\n# The port of the OpenLDAP server.\n--ldap_port=389\n# The name of the Schema in OpenLDAP.\n--ldap_scheme=ldap\n# The prefix of DN.\n--ldap_prefix=uid=\n# The suffix of DN.\n--ldap_suffix=,ou=it,dc=sys,dc=com\n</code></pre> </li> </ul> <ul> <li> <p>SearchBindAuth</p> <pre><code># Whether to get the configuration information from the configuration file.\n--local_config=true\n# Whether to enable authentication.\n--enable_authorize=true\n# Authentication methods include password, ldap, and cloud.\n--auth_type=ldap\n# The address of the OpenLDAP server.\n--ldap_server=192.168.8.211\n# The port of the OpenLDAP server.\n--ldap_port=389\n# The name of the Schema in OpenLDAP.\n--ldap_scheme=ldap\n# The DN that binds the target.\n--ldap_basedn=ou=it,dc=sys,dc=com\n</code></pre> </li> </ul> </li> <li> <p>Restart NebulaGraph services to make the new configuration valid.</p> </li> <li> <p>Run the login test.</p> <pre><code>$ ./nebula-console --addr 127.0.0.1 --port 9669 -u test2 -p passwdtest2\n2021/09/08 03:49:39 [INFO] connection pool is initialized successfully\n\nWelcome to NebulaGraph!\n</code></pre> <p>!!! note</p> <pre><code>  After using OpenLDAP for authentication, local users (including `root`) cannot log in normally.\n</code></pre> </li> </ol>"},{"location":"8.service-tuning/2.graph-modeling/","title":"Graph data modeling suggestions","text":"<p>This topic provides general suggestions for modeling data in NebulaGraph.</p> <p>Note</p> <p>The following suggestions may not apply to some special scenarios. In these cases, find help in the NebulaGraph community.</p>"},{"location":"8.service-tuning/2.graph-modeling/#model_for_performance","title":"Model for performance","text":"<p>There is no perfect method to model in Nebula\u00a0Graph. Graph modeling depends on the questions that you want to know from the data. Your data drives your graph model. Graph data modeling is intuitive and convenient. Create your data model based on your business model. Test your model and gradually optimize it to fit your business. To get better performance, you can change or re-design your model multiple times.</p>"},{"location":"8.service-tuning/2.graph-modeling/#design_and_evaluate_the_most_important_queries","title":"Design and evaluate the most important queries","text":"<p>Usually, various types of queries are validated in test scenarios to assess the overall capabilities of the system. However, in most production scenarios, there are not many types of frequently used queries. You can optimize the data model based on key queries selected according to the Pareto (80/20) principle.</p>"},{"location":"8.service-tuning/2.graph-modeling/#no_predefined_bonds_between_tags_and_edge_types","title":"No predefined bonds between Tags and Edge types","text":"<p>Define the bonds between Tags and Edge types in the application, not NebulaGraph. There are no statements that could get the bonds between Tags and Edge types.</p>"},{"location":"8.service-tuning/2.graph-modeling/#tagsedge_types_predefine_a_set_of_properties","title":"Tags/Edge types predefine a set of properties","text":"<p>While creating Tags or Edge types, you need to define a set of properties. Properties are part of the NebulaGraph Schema.</p>"},{"location":"8.service-tuning/2.graph-modeling/#control_changes_in_the_business_model_and_the_data_model","title":"Control changes in the business model and the data model","text":"<p>Changes here refer to changes in business models and data models (meta-information), not changes in the data itself.</p> <p>Some graph databases are designed to be Schema-free, so their data modeling, including the modeling of the graph topology and properties, can be very flexible. Properties can be re-modeled to graph topology, and vice versa. Such systems are often specifically optimized for graph topology access.</p> <p>NebulaGraph 2.6.2 is a strong-Schema (row storage) system, which means that the business model should not change frequently. For example, the property Schema should not change. It is similar to avoiding <code>ALTER TABLE</code> in MySQL.</p> <p>On the contrary, vertices and their edges can be added or deleted at low costs. Thus, the easy-to-change part of the business model should be transformed to vertices or edges, rather than properties.</p> <p>For example, in a business model, people have relatively fixed properties such as age, gender, and name. But their contact, place of visit, trade account, and login device are often changing. The former is suitable for modeling as properties and the latter as vertices or edges.</p>"},{"location":"8.service-tuning/2.graph-modeling/#breadth-first_traversal_over_depth-first_traversal","title":"Breadth-first traversal over depth-first traversal","text":"<ul> <li>NebulaGraph has lower performance for depth-first traversal based on the Graph topology, and better performance for breadth-first traversal and obtaining properties. For example, if model A contains properties \"name\", \"age\", and \"eye color\", it is recommended to create a tag <code>person</code> and add properties <code>name</code>, <code>age</code>, and <code>eye_color</code> to it. If you create a tag <code>eye_color</code> and an edge type <code>has</code>, and then create an edge to represent the eye color owned by the person, the traversal performance will not be high.</li> </ul> <ul> <li>The performance of finding an edge by an edge property is close to that of finding a vertex by a vertex property. For some databases, it is recommended to re-model edge properties as those of the intermediate vertices. For example, model the pattern <code>(src)-[edge {P1, P2}]-&gt;(dst)</code> as <code>(src)-[edge1]-&gt;(i_node {P1, P2})-[edge2]-&gt;(dst)</code>. With NebulaGraph 2.6.2, you can use <code>(src)-[edge {P1, P2}]-&gt;(dst)</code> directly to decrease the depth of the traversal and increase the performance.</li> </ul>"},{"location":"8.service-tuning/2.graph-modeling/#edge_directions","title":"Edge directions","text":"<p>To query in the opposite direction of an edge, use the following syntax:</p> <p><code>(dst)&lt;-[edge]-(src)</code> or <code>GO FROM dst REVERSELY</code>.</p> <p>If you do not care about the directions or want to query against both directions, use the following syntax:</p> <p><code>(src)-[edge]-(dst)</code> or <code>GO FROM src BIDIRECT</code>.</p> <p>Therefore, there is no need to insert the same edge redundantly in the reversed direction.</p>"},{"location":"8.service-tuning/2.graph-modeling/#set_tag_properties_appropriately","title":"Set tag properties appropriately","text":"<p>Put a group of properties that are on the same level into the same tag. Different groups represent different concepts.</p>"},{"location":"8.service-tuning/2.graph-modeling/#use_indexes_correctly","title":"Use indexes correctly","text":"<p>Using property indexes helps find VIDs through properties, but can lead to performance reduction by 90% or even more. Only use an index when you need to find vertices or edges through their properties.</p>"},{"location":"8.service-tuning/2.graph-modeling/#design_vids_appropriately","title":"Design VIDs appropriately","text":"<p>See VID.</p>"},{"location":"8.service-tuning/2.graph-modeling/#long_texts","title":"Long texts","text":"<p>Do not use long texts to create edge properties. Edge properties are stored twice and long texts lead to greater write amplification. For how edges properties are stored, see Storage architecture. It is recommended to store long texts in HBase or Elasticsearch and store its address in NebulaGraph.</p>"},{"location":"8.service-tuning/2.graph-modeling/#dynamic_graphs_sequence_graphs_are_not_supported","title":"Dynamic graphs (sequence graphs) are not supported","text":"<p>In some scenarios, graphs need to have the time information to describe how the structure of the entire graph changes over time.1</p> <p>The Rank field on Edges in NebulaGraph 2.6.2 can be used to store time in int64, but no field on vertices can do this because if you store the time information as property values, it will be covered by new insertion. Thus NebulaGraph does not support sequence graphs.</p> <p></p> <ol> <li> <p>https://blog.twitter.com/engineering/en_us/topics/insights/2021/temporal-graph-networks\u00a0\u21a9</p> </li> </ol>"},{"location":"8.service-tuning/3.system-design/","title":"System design suggestions","text":""},{"location":"8.service-tuning/3.system-design/#qps_or_low-latency_first","title":"QPS or low-latency first","text":"<ul> <li>NebulaGraph 2.6.2 is good at handling small requests with high concurrency. In such scenarios, the whole graph is huge, containing maybe trillions of vertices or edges, but the subgraphs accessed by each request are not large (containing millions of vertices or edges), and the latency of a single request is low. The concurrent number of such requests, i.e., the QPS, can be huge.</li> </ul> <ul> <li>On the other hand, in interactive analysis scenarios, the request concurrency is usually not high, but the subgraphs accessed by each request are large, with thousands of millions of vertices or edges. To lower the latency of big requests in such scenarios, you can split big requests into multiple small requests in the application, and concurrently send them to multiple graphd processes. This can decrease the memory used by each graphd process as well. Besides, you can use Nebula Algorithm for such scenarios.</li> </ul>"},{"location":"8.service-tuning/3.system-design/#horizontal_or_vertical_scaling","title":"Horizontal or vertical scaling","text":"<p>NebulaGraph 2.6.2 supports horizontal scaling.</p> <ul> <li>The horizontal scaling of the Storaged process:<p>- Increasing the number of machines deployed with the Storaged process can increase the overall capability of the cluster linearly, including increasing the overall QPS and reducing latency.</p> <p>- However, the number of partitions is fixed when creating a graph space. The service capability of a single partition is determined by a single server. The operations depending on a single partition include fetching properties of a single vertex (<code>FETCH</code>), a breadth-first traversal from a single vertex (<code>GO</code>), etc.</p> </li> </ul> <ul> <li>The horizontal scaling of the Graphd process:<p>- Each request from the client is handled by one and only one Graphd process, with no other Graphd processes participating in the processing of the request.</p> <p>- Therefore, increasing the number of machines deployed with the Graphd process can increase the overall QPS of the cluster, but cannot lower the latency of a single request.</p> </li> </ul> <ul> <li>Metad does not support horizontal scaling.</li> </ul> <p>Vertical scaling usually has higher hardware costs, but relatively simple operations. NebulaGraph 2.6.2 can also be scaled vertically.</p>"},{"location":"8.service-tuning/3.system-design/#data_transmission_and_optimization","title":"Data transmission and optimization","text":"<ul> <li>Read/write balance. NebulaGraph fits into OLTP scenarios with balanced read/write, i.e., concurrent write and read. It is not suitable for OLAP scenarios that usually need to write once and read many times.</li> <li>Select different write methods. For large batches of data writing, use SST files. For small batches of data writing, use <code>INSERT</code>.</li> <li>Run <code>COMPACTION</code> and <code>BALANCE</code> jobs to optimize data format and storage distribution at the right time.</li> <li>NebulaGraph 2.6.2 does not support transactions and isolation in the relational database and is closer to NoSQL.</li> </ul>"},{"location":"8.service-tuning/3.system-design/#query_preheating_and_data_preheating","title":"Query preheating and data preheating","text":"<p>Preheat on the application side:</p> <ul> <li>The Grapd process does not support pre-compiling queries and generating corresponding query plans, nor can it cache previous query results.</li> <li>The Storagd process does not support preheating data. Only the LSM-Tree and BloomFilter of RocksDB are loaded into memory at startup.</li> <li>Once accessed, vertices and edges are cached respectively in two types of LRU cache of the Storage Service.</li> </ul>"},{"location":"8.service-tuning/4.plan/","title":"Execution plan","text":"<p>NebulaGraph 2.6.2 applies rule-based execution plans. Users cannot change execution plans, pre-compile queries (and corresponding plan cache), or accelerate queries by specifying indexes.</p> <p>To view the execution plan and executive summary, see EXPLAIN and PROFILE.</p>"},{"location":"8.service-tuning/compaction/","title":"Compaction","text":"<p>This topic gives some information about compaction.</p> <p>In NebulaGraph, <code>Compaction</code> is the most important background process and has an important effect on performance.</p> <p><code>Compaction</code> reads the data that is written on the hard disk, then re-organizes the data structure and the indexes, and then writes back to the hard disk. The read performance can increase by times after compaction. Thus, to get high read performance, trigger <code>compaction</code> (full <code>compaction</code>) manually when writing a large amount of data into Nebula\u00a0Graph.</p> <p>Note</p> <p>Note that <code>compaction</code> leads to long-time hard disk IO. We suggest that users do compaction during off-peak hours (for example, early morning).</p> <p>NebulaGraph has two types of <code>compaction</code>: automatic <code>compaction</code> and full <code>compaction</code>.</p>"},{"location":"8.service-tuning/compaction/#automatic_compaction","title":"Automatic <code>compaction</code>","text":"<p>Automatic <code>compaction</code> is automatically triggered when the system reads data, writes data, or the system restarts. The read performance can increase in a short time. Automatic <code>compaction</code> is enabled by default. But once triggered during peak hours, it can cause unexpected IO occupancy that has an unwanted effect on the performance.</p>"},{"location":"8.service-tuning/compaction/#full_compaction","title":"Full <code>compaction</code>","text":"<p>Full <code>compaction</code> enables large-scale background operations for a graph space such as merging files, deleting the data expired by TTL. This operation needs to be initiated manually. Use the following statements to enable full <code>compaction</code>:</p> <p>Note</p> <p>We recommend you to do the full compaction during off-peak hours because full compaction has a lot of IO operations.</p> <pre><code>nebula&gt; USE &lt;your_graph_space&gt;;\nnebula&gt; SUBMIT JOB COMPACT;\n</code></pre> <p>The preceding statement returns the job ID. To show the <code>compaction</code> progress, use the following statement:</p> <pre><code>nebula&gt; SHOW JOB &lt;job_id&gt;;\n</code></pre>"},{"location":"8.service-tuning/compaction/#operation_suggestions","title":"Operation suggestions","text":"<p>These are some operation suggestions to keep Nebula\u00a0Graph performing well.</p> <ul> <li>After data import is done, run <code>SUBMIT JOB COMPACT</code>.</li> </ul> <ul> <li>Run <code>SUBMIT JOB COMPACT</code> periodically during off-peak hours (e.g. early morning).</li> </ul> <ul> <li>To control the read and write traffic limitation for <code>compactions</code>, set the following parameter in the <code>nebula-storaged.conf</code> configuration file.<pre><code># Limit the read/write rate to 20MB/s.\n--rocksdb_rate_limit=20 (in MB/s)\n</code></pre> </li> </ul>"},{"location":"8.service-tuning/compaction/#faq","title":"FAQ","text":""},{"location":"8.service-tuning/compaction/#where_are_the_logs_related_to_compaction_stored","title":"\"Where are the logs related to <code>Compaction</code> stored?\"","text":"<p>By default, the logs are stored under the <code>LOG</code> file in the <code>/usr/local/nebula/data/storage/nebula/{1}/data/</code> directory, or similar to <code>LOG.old.1625797988509303</code>. You can find the following content.</p> <pre><code>** Compaction Stats [default] **\nLevel    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop\n----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  L0      2/0    2.46 KB   0.5      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      0.0      0.53              0.51         2    0.264       0      0\n Sum      2/0    2.46 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      0.0      0.53              0.51         2    0.264       0      0\n Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0\n</code></pre> <p>If the number of <code>L0</code> files is large, the read performance will be greatly affected and compaction can be triggered.</p>"},{"location":"8.service-tuning/compaction/#can_i_do_full_compactions_for_multiple_graph_spaces_at_the_same_time","title":"\"Can I do full <code>compactions</code> for multiple graph spaces at the same time?\"","text":"<p>Yes, you can. But the IO is much larger at this time and the efficiency may be affected.</p>"},{"location":"8.service-tuning/compaction/#how_much_time_does_it_take_for_full_compactions","title":"\"How much time does it take for full <code>compactions</code>?\"","text":"<p>When <code>rate_limit</code> is set to <code>20</code>, you can estimate the full compaction time by dividing the hard disk usage by the <code>rate_limit</code>. If you do not set the <code>rate_limit</code> value, the empirical value is around 50 MB/s.</p>"},{"location":"8.service-tuning/compaction/#can_i_modify_--rocksdb_rate_limit_dynamically","title":"\"Can I modify <code>--rocksdb_rate_limit</code> dynamically?\"","text":"<p>No, you cannot.</p>"},{"location":"8.service-tuning/compaction/#can_i_stop_a_full_compaction_after_it_starts","title":"\"Can I stop a full <code>compaction</code> after it starts?\"","text":"<p>No, you cannot. When you start a full compaction, you have to wait till it is done. This is the limitation of RocksDB.</p>"},{"location":"8.service-tuning/load-balance/","title":"Storage load balance","text":"<p>You can use the <code>BALANCE</code> statement to balance the distribution of partitions and Raft leaders, or remove redundant Storage servers.</p>"},{"location":"8.service-tuning/load-balance/#balance_partition_distribution","title":"Balance partition distribution","text":"<p><code>BALANCE DATA</code> starts a task to equally distribute the storage partitions in a NebulaGraph cluster. A group of subtasks will be created and implemented to migrate data and balance the partition distribution.</p> <p>Danger</p> <p>DO NOT stop any machine in the cluster or change its IP address until all the subtasks finish. Otherwise, the follow-up subtasks fail.</p>"},{"location":"8.service-tuning/load-balance/#examples","title":"Examples","text":"<p>After you add new storage hosts into the cluster, no partition is deployed on the new hosts.</p> <ol> <li> <p>Run <code>SHOW HOSTS</code> to check the partition distribution.</p> <pre><code>nebual&gt; SHOW HOSTS;\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n| Host        | Port | Status   | Leader count | Leader distribution               | Partition distribution |\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n| \"storaged0\" | 9779 | \"ONLINE\" | 4            | \"basketballplayer:4\"              | \"basketballplayer:15\"  |\n| \"storaged1\" | 9779 | \"ONLINE\" | 8            | \"basketballplayer:8\"              | \"basketballplayer:15\"  |\n| \"storaged2\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:15\"  |\n| \"storaged3\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\"              | \"No valid partition\"   |\n| \"storaged4\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\"              | \"No valid partition\"   |\n| \"Total\"     |      |          | 15           | \"basketballplayer:15\"             | \"basketballplayer:45\"  |\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n</code></pre> </li> <li> <p>Run <code>BALANCE DATA</code> to start balancing the storage partitions. If the partitions are already balanced, <code>BALANCE DATA</code> fails.</p> <pre><code>nebula&gt; BALANCE DATA;\n+------------+\n| ID         |\n+------------+\n| 1614237867 |\n+------------+\n</code></pre> </li> <li> <p>A BALANCE task ID is returned after running <code>BALANCE DATA</code>. Run <code>BALANCE DATA &lt;balance_id&gt;</code> to check the status of the <code>BALANCE</code> task.</p> <pre><code>nebula&gt; BALANCE DATA 1614237867;\n+--------------------------------------------------------------+-------------------+\n| balanceId, spaceId:partId, src-&gt;dst                          | status            |\n+--------------------------------------------------------------+-------------------+\n| \"[1614237867, 11:1, storaged1:9779-&gt;storaged3:9779]\"         | \"SUCCEEDED\"       |\n| \"[1614237867, 11:1, storaged2:9779-&gt;storaged4:9779]\"         | \"SUCCEEDED\"       |\n| \"[1614237867, 11:2, storaged1:9779-&gt;storaged3:9779]\"         | \"SUCCEEDED\"       |\n...\n| \"Total:22, Succeeded:22, Failed:0, In Progress:0, Invalid:0\" | 100               |\n+--------------------------------------------------------------+-------------------+\n</code></pre> </li> <li> <p>When all the subtasks succeed, the load balancing process finishes. Run <code>SHOW HOSTS</code> again to make sure the partition distribution is balanced.</p> <p>Note</p> <p><code>BALANCE DATA</code> does not balance the leader distribution. For more information, see Balance leader distribution.</p> <pre><code>nebula&gt; SHOW HOSTS;\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n| Host        | Port | Status   | Leader count | Leader distribution               | Partition distribution |\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n| \"storaged0\" | 9779 | \"ONLINE\" | 4            | \"basketballplayer:4\"              | \"basketballplayer:9\"   |\n| \"storaged1\" | 9779 | \"ONLINE\" | 8            | \"basketballplayer:8\"              | \"basketballplayer:9\"   |\n| \"storaged2\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:9\"   |\n| \"storaged3\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\"              | \"basketballplayer:9\"   |\n| \"storaged4\" | 9779 | \"ONLINE\" | 0            | \"No valid partition\"              | \"basketballplayer:9\"   |\n| \"Total\"     |      |          | 15           | \"basketballplayer:15\"             | \"basketballplayer:45\"  |\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n</code></pre> </li> </ol> <p>If any subtask fails, run <code>BALANCE DATA</code> again to restart the balancing. If redoing load balancing does not solve the problem, ask for help in the NebulaGraph community.</p>"},{"location":"8.service-tuning/load-balance/#stop_data_balancing","title":"Stop data balancing","text":"<p>To stop a balance task, run <code>BALANCE DATA STOP</code>.</p> <ul> <li>If no balance task is running, an error is returned.</li> </ul> <ul> <li>If a balance task is running, the task ID (<code>balance_id</code>) is returned.</li> </ul> <p><code>BALANCE DATA STOP</code> does not stop the running subtasks but cancels all follow-up subtasks. To check the status of the stopped balance task, run <code>BALANCE DATA &lt;balance_id&gt;</code>.</p> <p>Once all the subtasks are finished or stopped, you can run <code>BALANCE DATA</code> again to balance the partitions again.</p> <ul> <li>If any subtask of the preceding balance task fails, NebulaGraph restarts the preceding balance task.</li> </ul> <ul> <li>If no subtask of the preceding balance task fails, NebulaGraph starts a new balance task.</li> </ul>"},{"location":"8.service-tuning/load-balance/#reset_a_balance_task","title":"RESET a balance task","text":"<p>If a balance task fails to be restarted after being stopped, run <code>BALANCE DATA RESET PLAN</code> to reset the task. After that, run <code>BALANCE DATA</code> again to start a new balance task.</p>"},{"location":"8.service-tuning/load-balance/#remove_storage_servers","title":"Remove storage servers","text":"<p>To remove specified storage servers and scale in the Storage Service, run <code>BALANCE DATA REMOVE &lt;host_list&gt;</code>.</p>"},{"location":"8.service-tuning/load-balance/#example","title":"Example","text":"<p>To remove the following storage server,</p> Server name IP address Port storage3 192.168.0.8 9779 storage4 192.168.0.9 9779 <p>Run the following command:</p> <pre><code>BALANCE DATA REMOVE 192.168.0.8:9779,192.168.0.9:9779;\n</code></pre> <p>NebulaGraph will start a balance task, migrate the storage partitions in storage3 and storage4, and then remove them from the cluster.</p> <p>Note</p> <p>The state of the removed server will change to <code>OFFLINE</code>. This record will be deleted after one day. To retain it, you can change the meta configuration <code>removed_threshold_sec</code>.</p>"},{"location":"8.service-tuning/load-balance/#balance_leader_distribution","title":"Balance leader distribution","text":"<p><code>BALANCE DATA</code> only balances the partition distribution. If the raft leader distribution is not balanced, some of the leaders may overload. To balance the raft leaders, run <code>BALANCE LEADER</code>.</p>"},{"location":"8.service-tuning/load-balance/#example_1","title":"Example","text":"<pre><code>nebula&gt; BALANCE LEADER;\n</code></pre> <p>Run <code>SHOW HOSTS</code> to check the balance result.</p> <pre><code>nebula&gt; SHOW HOSTS;\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n| Host        | Port | Status   | Leader count | Leader distribution               | Partition distribution |\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n| \"storaged0\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:9\"   |\n| \"storaged1\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:9\"   |\n| \"storaged2\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:9\"   |\n| \"storaged3\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:9\"   |\n| \"storaged4\" | 9779 | \"ONLINE\" | 3            | \"basketballplayer:3\"              | \"basketballplayer:9\"   |\n| \"Total\"     |      |          | 15           | \"basketballplayer:15\"             | \"basketballplayer:45\"  |\n+-------------+------+----------+--------------+-----------------------------------+------------------------+\n</code></pre> <p>Caution</p> <p>In NebulaGraph 2.6.2, switching leaders will cause a large number of short-term request errors (Storage Error <code>E_RPC_FAILURE</code>). For solutions, see FAQ.</p>"},{"location":"8.service-tuning/practice/","title":"Best practices","text":"<p>NebulaGraph is used in a variety of industries. This topic presents a few best practices for using NebulaGraph. For more best practices, see Blog.</p>"},{"location":"8.service-tuning/practice/#scenarios","title":"Scenarios","text":"<ul> <li>Use cases</li> </ul> <ul> <li>User review</li> </ul> <ul> <li>Performance</li> </ul>"},{"location":"8.service-tuning/practice/#kernel","title":"Kernel","text":"<ul> <li>NebulaGraph Source Code Explained: Variable-Length Pattern Matching</li> </ul> <ul> <li>Adding a Test Case for NebulaGraph</li> </ul> <ul> <li>BDD-Based Integration Testing Framework for NebulaGraph: Part \u2160</li> </ul> <ul> <li>BDD-Based Integration Testing Framework for NebulaGraph: Part II</li> </ul> <ul> <li>Understanding Subgraph in NebulaGraph 2.0</li> </ul> <ul> <li>Full-Text Indexing in NebulaGraph 2.0</li> </ul>"},{"location":"8.service-tuning/practice/#ecosystem_tool","title":"Ecosystem tool","text":"<ul> <li>Validating Import Performance of Nebula Importer</li> </ul> <ul> <li>Ecosystem Tools: NebulaGraph Dashboard for Monitoring</li> </ul> <ul> <li>Visualizing Graph Data with Nebula Explorer</li> </ul>"},{"location":"8.service-tuning/super-node/","title":"Processing super vertices","text":""},{"location":"8.service-tuning/super-node/#principle_introduction","title":"Principle introduction","text":"<p>In graph theory, a super vertex, also known as a dense vertex, is a vertex with an extremely high number of adjacent edges. The edges can be outgoing or incoming.</p> <p>Super vertices are very common because of the power-law distribution. For example, popular leaders in social networks (Internet celebrities), top stocks in the stock market, Big Four in the banking system, hubs in transportation networks, websites with high clicking rates on the Internet, and best sellers in E-commerce.</p> <p>In NebulaGraph 2.6.2, a <code>vertex</code> and its <code>properties</code> form a <code>key-value pair</code>, with its <code>VID</code> and other meta information as the <code>key</code>. Its <code>Out-Edge Key-Value</code> and <code>In-Edge Key-Value</code> are stored in the same partition in the form of LSM-trees in hard disks and caches.</p> <p>Therefore, <code>directed traversals from this vertex</code> and <code>directed traversals ending at this vertex</code> both involve either <code>a large number of sequential IO scans</code> (ideally, after Compaction or a large number of <code>random IO</code> (frequent writes to <code>the vertex</code> and its <code>ingoing and outgoing edges</code>).</p> <p>As a rule of thumb, a vertex is considered dense when the number of its edges exceeds 10,000. Some special cases require additional consideration\u3002</p> <p>Note</p> <p>In NebulaGraph 2.6.2, there is not any data structure to store the out/in degree for each vertex. Therefore, there is no direct method to know whether it is a super vertex or not. You can try to use Spark to count the degrees periodically. </p>"},{"location":"8.service-tuning/super-node/#indexes_for_duplicate_properties","title":"Indexes for duplicate properties","text":"<p>In a property graph, there is another class of cases similar to super vertices: a property has a very high duplication rate, i.e., many vertices with the same <code>tag</code> but different <code>VIDs</code> have identical property and property values.</p> <p>Property indexes in NebulaGraph 2.6.2 are designed to reuse the functionality of RocksDB in the Storage Service, in which case indexes are modeled as <code>keys with the same prefix</code>. If the lookup of a property fails to hit the cache, it is processed as a random seek and a sequential prefix scan on the hard disk to find the corresponding VID. After that, the graph is usually traversed from this vertex, so that another random read and sequential scan for the corresponding key-value of this vertex will be triggered. The higher the duplication rate, the larger the scan range.</p> <p>For more information about property indexes, see How indexing works in NebulaGraph.</p> <p>Usually, special design and processing are required when the number of duplicate property values exceeds 10,000.</p>"},{"location":"8.service-tuning/super-node/#suggested_solutions","title":"Suggested solutions","text":""},{"location":"8.service-tuning/super-node/#solutions_at_the_database_end","title":"Solutions at the database end","text":"<ol> <li>Truncation: Only return a certain number (a threshold) of edges, and do not return other edges exceeding this threshold.</li> <li>Compact: Reorganize the order of data in RocksDB to reduce random reads and increase sequential reads.</li> </ol>"},{"location":"8.service-tuning/super-node/#solutions_at_the_application_end","title":"Solutions at the application end","text":"<p>Break up some of the super vertices according to their business significance:</p> <ul> <li> <p>Delete multiple edges and merge them into one.</p> <p>For example, in the transfer scenario <code>(Account_A)-[TRANSFER]-&gt;(Account_B)</code>, each transfer record is modeled as an edge between account A and account B, then there may be tens of thousands of transfer records between <code>(Account_A)</code> and <code>(Account_B)</code>.</p> <p>In such scenarios, merge obsolete transfer details on a daily, weekly, or monthly basis. That is, batch-delete old edges and replace them with a small number of edges representing <code>monthly total</code> and <code>times</code>. And keep the transfer details of the latest month.</p> </li> </ul> <ul> <li> <p>Split an edge into multiple edges of different types.</p> <p>For example, in the <code>(Airport)&lt;-[DEPART]-(Flight)</code> scenario, the departure of each flight is modeled as an edge between a flight and an airport. Departures from a big airport might be enormous.</p> <p>According to different airlines, divide the <code>DEPART</code> edge type into finer edge types, such as <code>DEPART_CEAIR</code>, <code>DEPART_CSAIR</code>, etc. Specify the departing airline in queries (graph traversal).</p> </li> </ul> <ul> <li> <p>Split vertices.</p> <p>For example, in the loan network <code>(person)-[BORROW]-&gt;(bank)</code>, large bank A will have a very large number of loans and borrowers.</p> <p>In such scenarios, you can split the large vertex A into connected sub-vertices A1, A2, and A3.</p> <pre><code>(Person1)-[BORROW]-&gt;(BankA1), (Person2)-[BORROW]-&gt;(BankA2), (Person2)-[BORROW]-&gt;(BankA3);\n(BankA1)-[BELONGS_TO]-&gt;(BankA), (BankA2)-[BELONGS_TO]-&gt;(BankA), (BankA3)-[BELONGS_TO]-&gt;(BankA).\n</code></pre> <p>A1, A2, and A3 can either be three real branches of bank A, such as Beijing branch, Shanghai branch, and Zhejiang branch, or three virtual branches set up according to certain rules, such as <code>A1: 1-1000, A2: 1001-10000 and A3: 10000+</code> according to the number of loans. In this way, any operation on A is converted into three separate operations on A1, A2, and A3.</p> </li> </ul>"},{"location":"nebula-dashboard/1.what-is-dashboard/","title":"What is Nebula Dashboard Community Edition","text":"<p>Nebula Dashboard Community Edition (Dashboard for short) is a visualization tool that monitors the status of machines and services in NebulaGraph clusters. This topic introduces Dashboard Community Edition. For details of Dashboard Enterprise Edition, refer to What is Nebula Dashboard Enterprise Edition.</p> <p>Enterpriseonly</p> <p>Dashboard Enterprise Edition adds features such as visual cluster creation, batch import of clusters, fast scaling, etc. For more information, see Pricing.</p>"},{"location":"nebula-dashboard/1.what-is-dashboard/#features","title":"Features","text":"<p>Dashboard monitors:</p> <ul> <li>The status of all the machines in clusters, including CPU, memory, load, disk, and network.</li> </ul> <ul> <li>The information of all the services in clusters, including the IP addresses, versions, and monitoring metrics (such as the number of queries, the latency of queries, the latency of heartbeats, and so on).</li> </ul> <ul> <li>The information of clusters, including the information of services, partitions, configurations, and long-term tasks.</li> </ul> <ul> <li>Features of the enterprise package (TODO: planning)</li> </ul>"},{"location":"nebula-dashboard/1.what-is-dashboard/#scenarios","title":"Scenarios","text":"<p>You can use Dashboard in one of the following scenarios:</p> <ul> <li>You want to monitor key metrics conveniently and quickly, and present multiple key information of the business to ensure the business operates normally.</li> </ul> <ul> <li>You want to monitor clusters from multiple dimensions (such as the time, aggregate rules, and metrics).</li> </ul> <ul> <li>After a failure occurs, you need to review it and confirm its occurrence time and unexpected phenomena.</li> </ul>"},{"location":"nebula-dashboard/1.what-is-dashboard/#precautions","title":"Precautions","text":"<ul> <li>The monitoring data will be updated per 7 seconds by default.</li> </ul> <ul> <li>The monitoring data will be retained for 14 days by default, that is, only the monitoring data within the last 14 days can be queried.</li> </ul> <p>Note</p> <p>The monitoring service is supported by Prometheus. The update frequency and retention intervals can be modified. For details, see Prometheus.</p>"},{"location":"nebula-dashboard/1.what-is-dashboard/#version_compatibility","title":"Version compatibility","text":"<p>The version correspondence between NebulaGraph and Dashboard Community Edition is as follows.</p> NebulaGraph version Dashboard version 2.0.1~2.5.1 1.0.2 2.0.1~2.5.1 1.0.1"},{"location":"nebula-dashboard/1.what-is-dashboard/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/","title":"Deploy Dashboard","text":"<p>The deployment of Dashboard involves five services. This topic will describe how to deploy Dashboard in detail. To download and compile the latest source code of Nebula Dashboard, follow the instructions on the nebula dashboard GitHub page.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#prerequisites","title":"Prerequisites","text":"<p>Before you deploy Dashboard, you must confirm that:</p> <ul> <li>The NebulaGraph services are deployed and started. For more information, see NebulaGraph Database Manual.</li> </ul> <ul> <li> <p>Before the installation starts, the following ports are not occupied.</p> <ul> <li>9200</li> </ul> <ul> <li>9100</li> </ul> <ul> <li>9090</li> </ul> <ul> <li>8090</li> </ul> <ul> <li>7003</li> </ul> </li> </ul> <ul> <li>The Linux distribution is CentOS, installed with Node.js of version above v10.12.0 and Go of version above 1.13.</li> </ul>"},{"location":"nebula-dashboard/2.deploy-dashboard/#download_dashboard","title":"Download Dashboard","text":"<p>Download the tar package as needed, and it is recommended to select the latest version.</p> Dashboard package NebulaGraph version nebula-graph-dashboard-1.0.2.x86_64.tar.gz v2.6.2"},{"location":"nebula-dashboard/2.deploy-dashboard/#service","title":"Service","text":"<p>Run <code>tar -xvf 1.0.2.tar.gz</code> to decompress the installation package. There are 5 services in the <code>nebula-graph-dashboard</code>. The descriptions are as follows.</p> <p>|Name|Description||Port| |:---|:---|:---| |node-exporter | Collects the source information of machines in the cluster, including the CPU, memory, load, disk, and network. |9100| |nebula-stats-exporter | Collects the performance metrics in the cluster, including the IP addresses, versions, and monitoring metrics (such as the number of queries, the latency of queries, the latency of heartbeats, and so on). |9200| |prometheus | The time series database that stores monitoring data. |9090| |nebula-http-gateway | Provides HTTP ports for cluster services to execute nGQL statements to interact with the NebulaGraph database. |8090| |nebula-graph-dashboard| Provides the Dashboard service. Note that its name is the same as its superordinate. The following <code>nebula-graph-dashboard</code> refers to this service. |7003|</p> <p>The above five services should be deployed as follows.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#procedure","title":"Procedure","text":""},{"location":"nebula-dashboard/2.deploy-dashboard/#deploy_node-exporter","title":"Deploy <code>node-exporter</code>","text":"<p>Note</p> <p>You need to deploy the <code>node-exporter</code> service on each machine in the cluster.</p> <p>To start the service, run the following statement in <code>node-exporter</code>:</p> <pre><code>$ nohup ./node-exporter --web.listen-address=\":9100\" &amp;\n</code></pre> <p>After the service is started, you can enter <code>&lt;IP&gt;:9100</code> in the browser to check whether the service is started normally.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#deploy_nebula-stats-exporter","title":"Deploy <code>nebula-stats-exporter</code>","text":"<p>Note</p> <p>You only need to deploy the <code>nebula-stats-exporter</code> service on the machine where the <code>nebula-graph-dashboard</code> service is installed.</p> <ol> <li> <p>Modify the <code>config.yaml</code> file in <code>nebula-stats-exporter</code> to deploy the HTTP ports of all the services. The example is as follows:</p> <pre><code>version: v0.0.4\nclusters:\n  - name: nebula\n    instances:\n      - name: metad0\n        endpointIP: 192.168.8.157\n        endpointPort: 19559\ncomponentType: metad\n      - name: metad1\n        endpointIP: 192.168.8.155\n        endpointPort: 19559\ncomponentType: metad\n      - name: metad2\n        endpointIP: 192.168.8.154\n        endpointPort: 19559\ncomponentType: metad\n      - name: graphd0\n        endpointIP: 192.168.8.157\n        endpointPort: 19669\ncomponentType: graphd\n      - name: graphd1\n        endpointIP: 192.168.8.155\n        endpointPort: 19669\ncomponentType: graphd\n      - name: graphd2\n        endpointIP: 192.168.8.154\n        endpointPort: 19669\ncomponentType: graphd\n      - name: storaged0\n        endpointIP: 192.168.8.157\n        endpointPort: 19779\ncomponentType: storaged\n      - name: storaged1\n        endpointIP: 192.168.8.155\n        endpointPort: 19779\ncomponentType: storaged\n      - name: storaged2\n        endpointIP: 192.168.8.154\n        endpointPort: 19779\ncomponentType: storaged\n</code></pre> </li> <li> <p>Run the following statement to start the service:</p> <pre><code>$ nohup  ./nebula-stats-exporter --listen-address=\":9200\" --bare-metal --bare-metal-config=./config.yaml &amp;\n</code></pre> </li> </ol> <p>After the service is started, you can enter <code>&lt;IP&gt;:9200</code> in the browser to check whether the service is started normally.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#deploy_prometheus","title":"Deploy <code>prometheus</code>","text":"<p>Note</p> <p>You only need to deploy the <code>prometheus</code> service on the machine where the <code>nebula-graph-dashboard</code> service is installed.</p> <ol> <li> <p>Modify the <code>prometheus.yaml</code> file in <code>prometheus</code> to deploy the IP addresses and ports of the <code>node-exporter</code> service and the <code>nebula-stats-exporter</code>. The example is as follows:</p> <pre><code>global:\n  scrape_interval:     5s\n  evaluation_interval: 5s\nscrape_configs:\n  - job_name: 'nebula-stats-exporter'\nstatic_configs:\n      - targets: [\n'192.168.xx.100:9200',  # nebula-stats-exporter \u670d\u52a1\u7684 IP \u5730\u5740\u548c\u7aef\u53e3\u3002\n]\n- job_name: 'node-exporter'\nstatic_configs:\n      - targets: [\n'192.168.xx.100:9100',  # node-exporter \u670d\u52a1\u7684 IP \u5730\u5740\u548c\u7aef\u53e3\u3002\n'192.168.xx.101:9100'\n]\n</code></pre> <ul> <li>scrape_interval: The interval for collecting the monitoring data, which is 1 minute by default.</li> </ul> <ul> <li>evaluation_interval: The interval for running alarm rules, which is 1 minute by default.</li> </ul> </li> <li> <p>Run the following statement to start the service.</p> <pre><code>$ nohup ./prometheus --config.file=./prometheus.yaml &amp;\n</code></pre> </li> </ol> <p>After the service is started, you can enter <code>&lt;IP&gt;:9090</code> in the browser to check whether the service is started normally.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#deploy_nebula-http-gateway","title":"Deploy <code>nebula-http-gateway</code>","text":"<p>Note</p> <p>You only need to deploy the <code>nebula-http-gateway</code> service on the machine where the <code>nebula-graph-dashboard</code> service is installed.</p> <p>To start the service, run the following statement in <code>nebula-http-gateway</code>:</p> <pre><code>$ nohup ./nebula-httpd &amp;\n</code></pre> <p>After the service is started, you can enter <code>&lt;IP&gt;:8090</code> in the browser to check whether the service is started normally.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#how_to_deploy_the_nebula-graph-dashboard_service","title":"How to deploy the <code>nebula-graph-dashboard</code> service","text":"<ol> <li> <p>Modify the <code>custom.json</code> file in <code>nebula-graph-dashboard/static/</code> to deploy the IP address and port of the Graph Service. The example is as follows:</p> <pre><code>{\n\"connection\": {\n\"ip\": \"192.168.xx.4\",\n        \"port\": 9669\n},\n    \"alias\": {\n\"ip:port\": \"instance1\"\n},\n    \"chartBaseLine\": {\n\n}\n}\n...\n</code></pre> </li> <li> <p>To start the service, run the following statement in <code>nebula-graph-dashboard</code>:</p> <pre><code>$ npm run start\n</code></pre> </li> </ol> <p>After the service is started, you can enter <code>&lt;IP&gt;:7003</code> in the browser to check whether the service is started normally.</p>"},{"location":"nebula-dashboard/2.deploy-dashboard/#stop_dashboard","title":"Stop Dashboard","text":"<p>You can enter <code>kill &lt;pid&gt;</code> to stop Dashboard. The examples are as follows:</p> <pre><code>$ kill $(lsof -t -i :9100) # stop the node-exporter service\n$ kill $(lsof -t -i :9200) # stop the nebula-stats-exporter service\n$ kill $(lsof -t -i :9090) # stop the prometheus service\n$ kill $(lsof -t -i :8090) # stop the nebula-http-gateway service\n$ cd nebula-graph-dashboard\n$ npm run stop # stop the nebula-graph-dashboard service\n</code></pre>"},{"location":"nebula-dashboard/3.connect-dashboard/","title":"Connect Dashboard","text":"<p>After Dashboard is deployed, you can log in and use Dashboard on the browser.</p>"},{"location":"nebula-dashboard/3.connect-dashboard/#prerequisites","title":"Prerequisites","text":"<ul> <li>The Dashboard services are started. For more information, see Deploy Dashboard.</li> </ul> <ul> <li>We recommend you to use the Chrome browser of the version above 58. Otherwise, there may be compatibility issues.</li> </ul>"},{"location":"nebula-dashboard/3.connect-dashboard/#procedures","title":"Procedures","text":"<ol> <li> <p>Confirm the IP address of the machine where the <code>nebula-graph-dashboard</code> service is installed. Enter <code>&lt;IP&gt;:7003</code> in the browser to open the login page.</p> </li> <li> <p>Enter the username and the passwords of the NebulaGraph database and click the login button.</p> <ul> <li>If authentication is enabled, you can log in with the created accounts.</li> </ul> <ul> <li>If authentication is not enabled, you can only log in using <code>root</code> as the username and random characters as the password.</li> </ul> <p>To enable authentication, see Authentication.</p> <p></p> </li> </ol>"},{"location":"nebula-dashboard/4.use-dashboard/","title":"Dashboard","text":"<p>Nebula Dashboard consists of three parts: Machine, Service, and Management. This topic will describe them in detail.</p>"},{"location":"nebula-dashboard/4.use-dashboard/#overview","title":"Overview","text":""},{"location":"nebula-dashboard/4.use-dashboard/#machine","title":"Machine","text":"<p>Machine consists of the following parts:</p> <ul> <li> <p>Overview</p> <p>You can check the fluctuations of CPU, Memory, Load, Disk, Network In, and Network Out in the past 24 hours.</p> <p>For details of certain monitoring metrics, you can click the  symbol in the upper right corner, or click the monitoring metrics on the left.</p> </li> </ul> <ul> <li> <p>CPU, Memory, Load, Disk, Network</p> <p>It shows the detailed monitoring data of the machine from the above dimensions.</p> <ul> <li>By default, you can check the monitoring data up to 14 days before. The alternative can be 1 hour, 6 hours, 12 hours, 1 day, 3 days, 7 days, or 14 days in the past.</li> </ul> <ul> <li>You can choose the machine and monitoring metrics that you want to check. For more information, see monitor parameter.</li> </ul> <ul> <li>You can set a base line as a reference.</li> </ul> <p></p> </li> </ul>"},{"location":"nebula-dashboard/4.use-dashboard/#service","title":"Service","text":"<p>Service consists of the following parts:</p> <ul> <li> <p>Overview</p> <p>You can check the fluctuations of monitoring metrics of various services in the past 24 hours. You can also switch to the Version page to view the IP addresses and versions of all services.</p> <p>For details of certain monitoring metrics, you can click the  symbol in the upper right corner, or click the services on the left.</p> <p>Note</p> <p>The overview page of the current Community Edition only supports setting two monitoring metrics for each service. You can adjust it by clicking the Set up button.</p> </li> </ul> <ul> <li> <p>Graph, Meta, Storage</p> <p>It shows the detailed monitoring data of the above services.</p> <ul> <li>By default, you can check the monitoring data up to 14 days before. The alternative can be 1 hour, 6 hours, 12 hours, 1 day, 3 days, 7 days, or 14 days in the past.</li> </ul> <ul> <li>You can choose the machine that you want to check the monitoring data, monitoring metrics, metric methods, and period. For more information, see monitor parameter.</li> </ul> <ul> <li>You can set a base line as a reference.</li> </ul> <ul> <li>You can check the status of the current service.</li> </ul> <p></p> </li> </ul>"},{"location":"nebula-dashboard/4.use-dashboard/#management","title":"Management","text":"<p>Note</p> <p><code>Non-root</code> users can view the service information and the partition information with spatial permissions, but cannot view the configuration and long-term tasks.</p> <p>Management consists of the following parts:</p> <ul> <li> <p>Service Info</p> <p>It shows the basic information of the Storage Service, including the information of the host, the commit ID of versions, the number of leaders, the distribution of partitions, and the distribution of leaders.</p> </li> </ul> <ul> <li> <p>Partition Info</p> <p>You can check the information of partitions in different graph spaces. The descriptions are as follows.</p> Parameter Description <code>Partition ID</code> The ID of the partition. <code>Leader</code> The IP address and the port of the leader. <code>Peers</code> The IP addresses and the ports of all the replicas. <code>Losts</code> The IP addresses and the ports of replicas at fault. </li> </ul> <ul> <li> <p>Config</p> <p>It shows the configuration of each service. Dashboard does not support online modification of configurations for now. For details, see configurations.</p> </li> </ul> <ul> <li> <p>Long-term Task</p> <p>It shows the information of all jobs. Dashboard does not support online management of jobs for now. For details, see job statements.</p> </li> </ul>"},{"location":"nebula-dashboard/4.use-dashboard/#others","title":"Others","text":"<p>In the lower left corner of the page, you can:</p> <ul> <li>Sign out</li> </ul> <ul> <li>Switch between Chinese and English</li> </ul> <ul> <li>View the current Dashboard release</li> </ul> <ul> <li>View the user manual and forum</li> </ul> <ul> <li>Fold the sidebar</li> </ul>"},{"location":"nebula-dashboard/6.monitor-parameter/","title":"Metrics","text":"<p>This topic will describe the monitoring metrics in Nebula Dashboard.</p>"},{"location":"nebula-dashboard/6.monitor-parameter/#machine","title":"Machine","text":"<p>Note</p> <ul> <li>All the machine metrics listed below are for the Linux operating system.</li> <li>The default unit in Disk and Network is byte. The unit will change with the data magnitude as the page displays. For example, when the flow is less than 1 KB/s, the unit will be Bytes/s.</li> <li>For versions of Dashboard Community Edition greater than v1.0.2, the memory occupied by Buff and Cache will not be counted in the memory usage.</li> </ul>"},{"location":"nebula-dashboard/6.monitor-parameter/#cpu","title":"CPU","text":"Parameter Description <code>cpu_utilization</code> The percentage of used CPU. <code>cpu_idle</code> The percentage of idled CPU. <code>cpu_wait</code> The percentage of CPU waiting for IO operations. <code>cpu_user</code> The percentage of CPU used by users. <code>cpu_system</code> The percentage of CPU used by the system."},{"location":"nebula-dashboard/6.monitor-parameter/#memory","title":"Memory","text":"Parameter Description <code>memory_utilization</code> The percentage of used memory. <code>memory_used</code> The memory space used (including caches). <code>memory_actual_used</code> The memory space used (not including caches). <code>memory_free</code> The memory space available."},{"location":"nebula-dashboard/6.monitor-parameter/#load","title":"Load","text":"Parameter Description <code>load_1m</code> The average load of the system in the last 1 minute. <code>load_5m</code> The average load of the system in the last 5 minutes. <code>load_15m</code> The average load of the system in the last 15 minutes."},{"location":"nebula-dashboard/6.monitor-parameter/#disk","title":"Disk","text":"Parameter Description <code>disk_used</code> The disk space used. <code>disk_free</code> The disk space available. <code>disk_readbytes</code> The number of bytes that the system reads in the disk per second. <code>disk_writebytes</code> The number of bytes that the system writes in the disk per second. <code>disk_readiops</code> The number of read queries that the disk receives per second. <code>disk_writeiops</code> The number of write queries that the disk receives per second. <code>inode_utilization</code> The percentage of used inode."},{"location":"nebula-dashboard/6.monitor-parameter/#network","title":"Network","text":"Parameter Description <code>network_in_rate</code> The number of bytes that the network card receives per second. <code>network_out_rate</code> The number of bytes that the network card sends out per second. <code>network_in_errs</code> The number of wrong bytes that the network card receives per second. <code>network_out_errs</code> The number of wrong bytes that the network card sends out per second. <code>network_in_packets</code> The number of data packages that the network card receives per second. <code>network_out_packets</code> The number of data packages that the network card sends out per second."},{"location":"nebula-dashboard/6.monitor-parameter/#service","title":"Service","text":""},{"location":"nebula-dashboard/6.monitor-parameter/#period","title":"Period","text":"<p>The period is the time range of counting metrics. It currently supports 5 seconds, 60 seconds, 600 seconds, and 3600 seconds, which respectively represent the last 5 seconds, the last 1 minute, the last 10 minutes, and the last 1 hour.</p>"},{"location":"nebula-dashboard/6.monitor-parameter/#metric_methods","title":"Metric methods","text":"Parameter Description <code>rate</code> The average rate of operations per second in a period. <code>sum</code> The sum of operations in the period. <code>avg</code> The average latency in the cycle. <code>P75</code> The 75th percentile latency. <code>P95</code> The 95th percentile latency. <code>P99</code> The 99th percentile latency. <code>P999</code> The 99.9th percentile latency."},{"location":"nebula-dashboard/6.monitor-parameter/#graph","title":"Graph","text":"Parameter Description <code>num_queries</code> The number of queries. <code>num_slow_queries</code> The number of slow queries. <code>query_latency_us</code> The average latency of queries. <code>slow_query_latency_us</code> The average latency of slow queries. <code>num_query_errors</code> The number of queries in error."},{"location":"nebula-dashboard/6.monitor-parameter/#meta","title":"Meta","text":"Parameter Description <code>heartbeat_latency_us</code> The latency of heartbeats. <code>num_heartbeats</code> The number of heartbeats."},{"location":"nebula-dashboard/6.monitor-parameter/#storage","title":"Storage","text":"Parameter Description <code>add_edges_latency_us</code> The average latency of adding edges. <code>add_vertices_latency_us</code> The average latency of adding vertices. <code>delete_edges_latency_us</code> The average latency of deleting edges. <code>delete_vertices_latency_us</code> The average latency of deleting vertices. <code>forward_tranx_latency_us</code> The average latency of transmitting. <code>get_neighbors_latency_us</code> The average latency of querying neighbors."},{"location":"nebula-dashboard-ent/1.what-is-dashboard-ent/","title":"What is Nebula Dashboard Enterprise Edition","text":"<p>Nebula Dashboard Enterprise Edition (Dashboard for short) is a visualization tool that monitors and manages the status of machines and services in NebulaGraph clusters. This topic introduces Dashboard Enterprise Edition. For more information, see What is Nebula Dashboard Community Edition.</p>"},{"location":"nebula-dashboard-ent/1.what-is-dashboard-ent/#features","title":"Features","text":"<ul> <li>Create a NebulaGraph cluster of a specified version, import nodes in batches, scale out NebulaGraph services with one click</li> </ul> <ul> <li>Import clusters, balance data, scale out or in on the visualization interface.</li> </ul> <ul> <li>Manage clusters, and view the operation log of clusters within the last 14 days.</li> </ul> <ul> <li>Start, stop, and restart services on the visualization interface.</li> </ul> <ul> <li>Update the configuration of Storage services and Graph services in clusters quickly.</li> </ul> <ul> <li>Monitor the information of all the services in clusters, including the IP address, version, and monitoring metrics (such as the number of queries, the latency of queries, and the latency of heartbeats).</li> </ul> <ul> <li>Monitor the status of all the machines in clusters, including CPU, memory, load, disk, and network.</li> </ul> <ul> <li>Monitor the information of clusters, including the information of services, partitions, configurations, and long-term tasks.</li> </ul>"},{"location":"nebula-dashboard-ent/1.what-is-dashboard-ent/#scenarios","title":"Scenarios","text":"<ul> <li>You want a visualized operation and maintenance monitoring platform for large-scale clusters.</li> </ul> <ul> <li>You want to monitor key metrics conveniently and quickly, and present multiple key information of the business to ensure that the business can be operated normally.</li> </ul> <ul> <li>You want to monitor clusters from multiple dimensions (such as the time, aggregate rules, and metrics).</li> </ul> <ul> <li>You want to review the failure after it occurs, confirm when it happened, and view its associated phenomena.</li> </ul>"},{"location":"nebula-dashboard-ent/1.what-is-dashboard-ent/#precautions","title":"Precautions","text":"<ul> <li>The monitoring data will be updated per 7 seconds by default.</li> </ul> <ul> <li>The monitoring data will be retained for 14 days by default, that is, only the monitoring data within the last 14 days can be queried.</li> </ul> <ul> <li>The version of NebulaGraph must be 2.0.1 or later.</li> </ul> <ul> <li>It is recommend to use the latest version of Chrome to access Dashboard.</li> </ul> <ul> <li>It is recommend to use the official installation package to create or import clusters.</li> </ul> <p>Note</p> <p>The monitoring feature is supported by Prometheus. The update frequency and retention intervals can be modified. For details, see Prometheus.</p>"},{"location":"nebula-dashboard-ent/1.what-is-dashboard-ent/#version_compatibility","title":"Version compatibility","text":"<p>The version correspondence between NebulaGraph and Dashboard Enterprise Edition is as follows.</p> NebulaGraph version Dashboard version 2.0.1~2.6.1 1.0.2 2.0.1~2.6.1 1.0.1 2.0.1~2.6.1 1.0.0"},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/","title":"Deploy Dashboard","text":"<p>This topic will introduce how to install and deploy Dashboard in detail.</p>"},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/#prerequisites","title":"Prerequisites","text":"<p>Before deploying Dashboard, you must do a check of these:</p> <ul> <li>Select and download Dashboard of the correct version. For information about the version correspondence between Dashboard and NebulaGraph, see Version compatibility.</li> </ul> <ul> <li>The environment of MySQL is ready and a database named as <code>dashboard</code> is created.</li> <li> <p>Before the installation starts, the following ports are not occupied.</p> Port Description 7005 The port through which Dashboard provides the web service. 8090 The port of the nebula-http-gateway service. 9090 The port of the prometheus service. 9200 The port of the nebula-stats-exporter service. </li> </ul> <ul> <li> <p>The license is ready.</p> <p>Enterpriseonly</p> <p>The license is only available in the Enterprise Edition. To obtain the license, send email to inquiry@vesoft.com.</p> </li> </ul>"},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/#install_and_start","title":"Install and start","text":"<ol> <li> <p>Select and download the tar package according to your needs. It is recommended to select the latest version.</p> <p>Enterpriseonly</p> <p>For features of Dashboard Enterprise Edition, see Pricing.</p> </li> <li> <p>Use <code>tar -xzvf</code> to decompress the tar package.</p> <pre><code>$ tar -xzvf nebula-dashboard-ent-&lt;version&gt;.linux-amd64.tar.gz </code></pre> <p>For example:</p> <pre><code>$ tar -xzvf nebula-dashboard-ent-1.0.0.linux-amd64.tar.gz </code></pre> </li> <li> <p>Edit <code>vim config/config.yaml</code> to modify the configuration.</p> <pre><code># Information about the database\ndatabase:\n  dialect: mysql # The type of database used, which currently only supports MySql\nhost: 192.168.8.157 # The IP address of the connected MySql database\nport: 3306 # The port of the connected MySql database\nusername: root # The username to log in MySql\npassword: nebula # The password to log in MySql\nname: dashboard # The name of the corresponding database\nautoMigrate: true # Auto database tables creation, the default value of which is true\n# Information about the exporter port\nexporter:\n  nodePort: 9100 # The port of the node-exporter service\nnebulaPort: 9200 # The port of the nebula-stats-exporter service\n# Information of services\nproxy:\n  gateway:\n    target: \"127.0.0.1:8090\" # The IP address and port of the gateway service\nprometheus:\n    target: \"127.0.0.1:9090\" # The IP address and port of the prometheus service\n</code></pre> </li> <li> <p>Copy the license file to the <code>nebula-dashboard-ent</code> directory.</p> <pre><code>$ cp -r &lt;license&gt; &lt;dashboard_path&gt;\n</code></pre> <p>For example:</p> <pre><code>$ cp -r nebula.license /usr/local/nebula-dashboard-ent\n</code></pre> </li> <li> <p>Start Dashboard.</p> <p>You can use the following command to start the Dashboard with one click.</p> <pre><code>$ cd scripts\n$ sudo ./dashboard.service start all\n</code></pre> <p>Or execute the following commands to start prometheus, webserver, exporter and gateway services to start Dashboard.</p> <pre><code>$ cd scripts\n$ sudo ./dashboard.service start prometheus # Start prometheus service\n$ sudo ./dashboard.service start webserver # Start webserver service\n$ sudo ./dashboard.service start exporter # Start exporter service\n$ sudo ./dashboard.service start gateway # Start gateway service\n</code></pre> </li> </ol>"},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/#manage_dashboard_service","title":"Manage Dashboard Service","text":"<p>You can use the <code>dashboard.service</code> script to start, stop, and check the Dashboard services.</p>"},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/#syntax","title":"Syntax","text":"<pre><code>$ sudo &lt;dashboard_path&gt;/dashboard/scripts/dashboard.service\n[-v] [-h]\n&lt;start|stop|status&gt;  &lt;prometheus|webserver|exporter|gateway|all&gt;\n</code></pre> Parameter Description <code>dashboard_path</code> Dashboard installation path. <code>-v</code> Display detailed debugging information. <code>-h</code> Display help information. <code>start</code> Start the target services. <code>stop</code> Stop the target services. <code>status</code> Check the status of the target services. <code>prometheus</code> Set the prometheus Service as the target service. <code>webserver</code> Set the webserver Service as the target service. <code>exporter</code> Set the exporter Service as the target service. <code>gateway</code> Set the gateway Service as the target service. <code>all</code> Set all the Dashboard services as the target services."},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/#examples","title":"Examples","text":"<p>Dashboard is installed in the current directory, and you can use the following commands to manage services.</p> <pre><code>$ sudo /dashboard/scripts/dashboard.service start all #start all Dashboard service \n$ sudo /dashboard/scripts/dashboard.service stop all #stop all Dashboard service \n$ sudo /dashboard/scripts/dashboard.service status all #check all Dashboard service \n</code></pre>"},{"location":"nebula-dashboard-ent/2.deploy-connect-dashboard-ent/#next_to_do","title":"Next to do","text":"<p>After Dashboard is successfully started, you can enter <code>http://&lt;ip_address&gt;:7005</code> in the address bar of a browser.</p> <p>If the following login interface is shown in the browser, then you have successfully deployed and started Dashboard. You can log into Dashboard as a GOD user with the default username <code>nebula</code> and password <code>nebula</code>. You can modify the password in System Settings. And you also can use the GOD account to create a new account with the permission ADMIN on the Account Management to log into the Dashboard.</p> <p></p>"},{"location":"nebula-dashboard-ent/5.account-management/","title":"Authority management","text":"<p>By default, you can log in with the GOD role (<code>nebula</code> as the default username and <code>nebula</code> as the default password). And the ADMIN account can be created or deleted on the authority management page.</p> <p></p> <p>You cannot perform operations on other accounts using the ADMIN account you created except for viewing the username, the role, and the creation time.</p> <p></p>"},{"location":"nebula-dashboard-ent/6.system-settings/","title":"System settings","text":"<p>This topic introduces the system settings that may be applied when using Dashboard.</p>"},{"location":"nebula-dashboard-ent/6.system-settings/#interface_settings","title":"Interface settings","text":"<p>On the Interface settings page, you can:</p> <ul> <li>Change the title, upload the logo, and upload the cover.</li> <li>Switch the interface language, which supports English and Chinese for now.</li> <li>Enable or disable the tip settings.</li> </ul> <p></p>"},{"location":"nebula-dashboard-ent/6.system-settings/#help","title":"Help","text":"<p>On the Help page, you can jump to Dashboard Docs, NebulaGraph Docs, NebulaGraph Website, or NebulaGraph Forum.</p> <p></p>"},{"location":"nebula-dashboard-ent/6.system-settings/#user_information","title":"User information","text":"<p>On the User information page, you can change your password or log out.</p> <p></p>"},{"location":"nebula-dashboard-ent/7.monitor-parameter/","title":"Metrics","text":"<p>This topic will describe the monitoring metrics in Nebula Dashboard.</p>"},{"location":"nebula-dashboard-ent/7.monitor-parameter/#machine","title":"Machine","text":"<p>Note</p> <ul> <li>All the machine metrics listed below are for the Linux operating system.</li> <li>The default unit for Disk and Network is byte. The unit changes with the data magnitude as the page displays. For example, when the flow is less than 1 KB/s, the unit is Bytes/s.</li> <li>For all versions of Dashboard Enterprise Edition, the memory occupied by Buff and Cache will not be counted in the memory usage.</li> </ul>"},{"location":"nebula-dashboard-ent/7.monitor-parameter/#cpu","title":"CPU","text":"Parameter Description <code>cpu_utilization</code> The percentage of used CPU. <code>cpu_idle</code> The percentage of idled CPU. <code>cpu_wait</code> The percentage of CPU waiting for IO operations. <code>cpu_user</code> The percentage of CPU used by users. <code>cpu_system</code> The percentage of CPU used by the system."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#memory","title":"Memory","text":"Parameter Description <code>memory_utilization</code> The percentage of used memory. <code>memory_used</code> The memory space used (including caches). <code>memory_actual_used</code> The memory space used (not including caches). <code>memory_free</code> The memory space available."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#load","title":"Load","text":"Parameter Description <code>load_1m</code> The average load of the system in the last 1 minute. <code>load_5m</code> The average load of the system in the last 5 minutes. <code>load_15m</code> The average load of the system in the last 15 minutes."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#disk","title":"Disk","text":"Parameter Description <code>disk_used</code> The disk space used. <code>disk_free</code> The disk space available. <code>disk_readbytes</code> The number of bytes that the system reads in the disk per second. <code>disk_writebytes</code> The number of bytes that the system writes in the disk per second. <code>disk_readiops</code> The number of read queries that the disk receives per second. <code>disk_writeiops</code> The number of write queries that the disk receives per second. <code>inode_utilization</code> The percentage of used inode."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#network","title":"Network","text":"Parameter Description <code>network_in_rate</code> The number of bytes that the network card receives per second. <code>network_out_rate</code> The number of bytes that the network card sends out per second. <code>network_in_errs</code> The number of wrong bytes that the network card receives per second. <code>network_out_errs</code> The number of wrong bytes that the network card sends out per second. <code>network_in_packets</code> The number of data packages that the network card receives per second. <code>network_out_packets</code> The number of data packages that the network card sends out per second."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#service","title":"Service","text":""},{"location":"nebula-dashboard-ent/7.monitor-parameter/#period","title":"Period","text":"<p>The period is the time range of counting metrics. It currently supports 5 seconds, 60 seconds, 600 seconds, and 3600 seconds, which respectively represent the last 5 seconds, the last 1 minute, the last 10 minutes, and the last 1 hour.</p>"},{"location":"nebula-dashboard-ent/7.monitor-parameter/#metric_methods","title":"Metric methods","text":"Parameter Description <code>rate</code> The average rate of operations per second in a period. <code>sum</code> The sum of operations in the period. <code>avg</code> The average latency in the cycle. <code>P75</code> The 75th percentile latency. <code>P95</code> The 95th percentile latency. <code>P99</code> The 99th percentile latency. <code>P999</code> The 99.9th percentile latency."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#graph","title":"Graph","text":"Parameter Description <code>num_queries</code> The number of queries. <code>num_slow_queries</code> The number of slow queries. <code>query_latency_us</code> The average latency of queries. <code>slow_query_latency_us</code> The average latency of slow queries. <code>num_query_errors</code> The number of queries in error."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#meta","title":"Meta","text":"Parameter Description <code>heartbeat_latency_us</code> The latency of heartbeats. <code>num_heartbeats</code> The number of heartbeats."},{"location":"nebula-dashboard-ent/7.monitor-parameter/#storage","title":"Storage","text":"Parameter Description <code>add_edges_latency_us</code> The average latency of adding edges. <code>add_vertices_latency_us</code> The average latency of adding vertices. <code>delete_edges_latency_us</code> The average latency of deleting edges. <code>delete_vertices_latency_us</code> The average latency of deleting vertices. <code>get_neighbors_latency_us</code> The average latency of querying neighbors."},{"location":"nebula-dashboard-ent/8.faq/","title":"FAQ","text":"<p>This topic lists the frequently asked questions for using Nebula Dashboard. You can use the search box in the help center or the search function of the browser to match the questions you are looking for.</p>"},{"location":"nebula-dashboard-ent/8.faq/#what_are_cluster_node_and_service","title":"\"What are Cluster, Node, and Service?\"","text":"<ul> <li>Cluster: refers to a group of systems composed of nodes where multiple NebulaGraph services are located.</li> </ul> <ul> <li>Node: refers to the physical or virtual machine hosting NebulaGraph services.</li> </ul> <ul> <li>Service: refers to Nebula services, including Metad, Storaged, and Graphd services.</li> </ul>"},{"location":"nebula-dashboard-ent/8.faq/#what_is_the_cluster_status","title":"\"What is the cluster status?\"","text":"<p>The status of a cluster is as follows:</p> <ul> <li>installing: The cluster is being created. The process will take about 3 to 10 minutes.</li> <li>healthy: All services in the cluster are healthy.</li> <li>unhealthy: There is an unhealthy service in the cluster service.</li> </ul>"},{"location":"nebula-dashboard-ent/8.faq/#why_authorizing_nodes","title":"\"Why authorizing nodes?\"","text":"<p>Managing clusters requires the SSH information of the corresponding node. Therefore, you need to have at least an SSH account and the corresponding password with executable permissions before performing operations on Dashboard.</p>"},{"location":"nebula-dashboard-ent/8.faq/#what_is_scaling","title":"\"What is scaling?\"","text":"<p>NebulaGraph is a distributed graph database that supports dynamic scaling services at runtime. Therefore, you can dynamically scale Storaged and Graphd services through Dashboard. The Metad service cannot be scaled.</p>"},{"location":"nebula-dashboard-ent/8.faq/#why_cannot_operate_on_the_metad_service","title":"\"Why cannot operate on the Metad service?\"","text":"<p>The Metad service stores the metadata of the NebulaGraph database. Once the Metad service fails to function, the entire cluster may break down. Besides, the amount of data processed by the Metad service is not much, so it is not recommended to scale the Metad service. And we directly disabled operating on the Metad service in Dashboard to prevent the cluster from being unavailable due to the misoperation of users.</p>"},{"location":"nebula-dashboard-ent/8.faq/#what_impact_will_the_scaling_have_on_the_data","title":"\"What impact will the scaling have on the data?\"","text":"<ul> <li>Scale out the Storaged service: Dashboard will create and start the Storaged service on the specified machine, which will not affect the existing data. You can choose to perform <code>Balance Data</code> on the <code>Service information</code> page or <code>Balance Leader</code> on the <code>Leader</code> page according to your own needs.</li> </ul> <ul> <li>Scale in the Storaged service: Dashboard will automatically execute <code>Balance Data Remove</code> to ensure that the service is stopped after the data partition on the specified service is successfully migrated.</li> </ul> <ul> <li>Scaling the Graphd service will not affect the data.</li> </ul>"},{"location":"nebula-dashboard-ent/8.faq/#why_dashboard_enterprise_edition_cannot_be_started","title":"\"Why Dashboard Enterprise Edition cannot be started?\"","text":"<ul> <li>Make sure that the license file is copied to the Dashboard directory and <code>sudo ./dashboard.service start all</code> is executed.</li> </ul> <ul> <li>Make sure that the license is not expired.</li> </ul> <p>You can also execute <code>cat logs/webserver.log</code> in the Dashboard directory to view the startup information of each module. If the above conditions are met but Dashboard still cannot be started, go to NebulaGraph Official Forum for consultation.</p>"},{"location":"nebula-dashboard-ent/8.faq/#can_i_add_the_nebulagraph_installation_package_manually","title":"\"Can I add the NebulaGraph installation package manually?\"","text":"<p>You can add the installation package manually in Dashboard. To download the system and RPM/DEB package you need, see How to download NebulaGraph and add the package to <code>dashboard/download/nebula-graph</code>. And you can select the added package for deployment when creating and scaling out a cluster.</p>"},{"location":"nebula-dashboard-ent/3.create-import-dashboard/1.create-cluster/","title":"Create clusters","text":"<p>This topic introduces how to create clusters using Dashboard.</p>"},{"location":"nebula-dashboard-ent/3.create-import-dashboard/1.create-cluster/#steps","title":"Steps","text":"<p>You can create a cluster following these steps:</p> <ol> <li>In the Cluster management page, click Create cluster.</li> <li> <p>In the Create cluster page, fill in the following:</p> <ul> <li>Enter the Cluster name, 15 characters at most. In this example, the cluster name is <code>test_foesa</code>.</li> <li>Choose the NebulaGraph version to install. In this example, the version is <code>v2.6.1</code>.</li> <li> <p>Add nodes. The information of each node is required.</p> <ol> <li>Enter the IP information of each host. In this example, it is <code>192.168.8.144</code>.</li> <li>Enter the SSH information. In this example, the SSH port is <code>22</code>, the SSH user is <code>vesoft</code>, and the SSH password is <code>nebula</code>.</li> <li>Choose the NebulaGraph package. In this example, the package is <code>nebula-graph-2.6.1.el7.x86_64rpm</code>.</li> <li>(Optional) Enter the node name to make a note on the node. In this example, the note is <code>Node_1</code>.</li> </ol> <p></p> </li> </ul> <ul> <li> <p>Import nodes in batches. The information of each node is required. To import nodes in batches, you need to choose the installation package and click download the CSV template. Fill in the template and upload it. Ensure that the node is correct, otherwise upload failure may happen.</p> <p></p> </li> </ul> </li> <li> <p>Select the node and add the service you need in the upper right corner. To create a cluster, you need to add 3 types of services to the node. If not familiar with the NebulaGraph architecture, click Auto add service.</p> <p></p> </li> <li> <p>(Optional) Edit the port of the meta service, the graph service, the storage service, HTTP, and HTTP2, and click OK to save.</p> </li> <li> <p>Click Create cluster. Make sure the configuration is correct and there is no conflict between nodes, click Confirm.</p> <p></p> </li> <li> <p>If a cluster with the status of <code>installing</code> appears in the list on the cluster management page, you need to wait for 3 to 10 minutes until the status changes to <code>healthy</code>, that is, the cluster is created successfully. If the service status is <code>unhealthy</code>, it means that there is an abnormal service in the cluster, click Detail for more information.</p> <p></p> </li> </ol>"},{"location":"nebula-dashboard-ent/3.create-import-dashboard/1.create-cluster/#next_to_do","title":"Next to do","text":"<p>After the cluster is successfully created, you can operate the cluster. For details, see Overview.</p>"},{"location":"nebula-dashboard-ent/3.create-import-dashboard/2.import-cluster/","title":"Import clusters","text":"<p>This topic introduces how to import clusters using Dashboard. The current version only supports importing clusters deployed by the official DEB or RPM packages and clusters created by Dashboard. Currently, importing clusters deployed by Docker and Kubernetes is not supported.</p>"},{"location":"nebula-dashboard-ent/3.create-import-dashboard/2.import-cluster/#steps","title":"Steps","text":"<p>Caution</p> <p>In the same cluster, the service versions need to be unified. Importing NebulaGraph examples from different versions in the same cluster is not supported.</p> <ol> <li> <p>In the configuration file of each service, change the IP in <code>&lt;meta|graph|storage&gt;_server_addrs</code> and <code>local_ip</code> to the server's IP, and then start NebulaGraph.</p> <p>For details, see Configurations and Manage NebulaGraph services.</p> </li> <li> <p>In the Cluster management page, click Import cluster.</p> </li> <li> <p>In the Import cluster page, enter the information of Connect to NebulaGraph.</p> <ul> <li>Graphd Host: :n. In this example, the IP is <code>192.168.8.157:9669</code>. <li>Username: The account to connect to NebulaGraph. In this example, the username is <code>vesoft</code>.</li> <li>Password: The password to connect to NebulaGraph. In this example, the password is <code>nebula</code>.</li> <p>Note</p> <p>By default, authentication is disabled in NebulaGraph. Therefore, you can use <code>root</code> as the username and any password to connect to NebulaGraph.   When authentication is enabled in NebulaGraph, you need to use the specified username and password to connect to NebulaGraph. For details of authentication,see NebulaGraph manual.</p> <p></p> <li> <p>In the Connect to NebulaGraph page, fill in the following:</p> <ul> <li>Enter the cluster name, 15 characters at most. In this example, the cluster name is <code>create_1027</code>.</li> <li>Authorize the node. The SSH username and password of each node are required.</li> <li> <p>Batch authorization requires uploading the CSV file. Edit the authentication information of each node according to the downloaded CSV file. Ensure that the node information is correct, otherwise upload failure may happen.</p> <p></p> </li> </ul> <ul> <li> <p>If the node status on the page becomes authorized, the node authentication is successful.</p> <p></p> </li> </ul> </li> <li> <p>Ensure that all nodes are authorized successfully. Click Import cluster.</p> </li>"},{"location":"nebula-dashboard-ent/3.create-import-dashboard/2.import-cluster/#next_to_do","title":"Next to do","text":"<p>After the cluster is successfully imported, you can operate the cluster. For details, see Overview.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/","title":"Cluster overview","text":"<p>This topic introduces the Overview page of Dashboard. You can click Detail on the right of the cluster management page to check the overview of a specified cluster.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/#overview","title":"Overview","text":"<p>The Overview page has five parts:</p> <ul> <li>Cluster survey</li> <li>Information</li> <li>Node</li> <li>Status list</li> <li>Service</li> </ul>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/#cluster_survey","title":"Cluster survey","text":"<p>In this part, you can view the number of nodes as well as the number of running and abnormal services of Graphd, Storaged, and Metad. In this example, there is 1 abnormal service in the Graphd service. You can click the View button to quickly check the abnormal service.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/#information","title":"Information","text":"<p>In this part, you can view the information of Cluster name, Creation time, Creator, and Version.</p> <p>Note</p> <p>The version here is the NebulaGraph version installed by the user, not the Dashboard version.</p> <p>Caution</p> <p>If the version of NebulaGraph imported by the user is before v2.5.0 or the version is unknown, v2.0.1 will be shown by default.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/#node","title":"Node","text":"<ul> <li>You can view the information of node monitoring quickly and change the displayed information. By default, the CPU information will be shown.</li> <li>You can click  on the page to insert a base line.</li> <li>You can click  to jump to the detailed node monitoring page.</li> </ul>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/#status_list","title":"Status list","text":"<p>This part uses pie charts to visually display the running status of nodes.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/1.overview/#service","title":"Service","text":"<ul> <li>By default, the information of <code>query_latency_us</code> and <code>slow_query_latency_us</code> will be shown.</li> </ul> <ul> <li>You can click  Set up to insert a base line.</li> </ul> <ul> <li>You can click  View to jump to the detailed service monitoring page.</li> </ul>"},{"location":"nebula-dashboard-ent/4.cluster-operator/2.monitor/","title":"Cluster monitoring","text":"<p>This topic introduces node monitoring and service monitoring of Dashboard.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/2.monitor/#node","title":"Node","text":"<p>On this page, you can view the variation of CPU, Memory, Load, Disk, and Network In/Out quickly.</p> <ul> <li>To set a base line, click the  button.</li> <li>To view the detailed monitoring information, click the  button. In this example, select <code>Load</code> for details. The figure is as follows.     <ul> <li>By default, you can view the monitoring data of the latest 1 hour, 6 hours, 12 hours, 1 day, 3 days, 7days, or 14 days.</li> <li>You can select the machine and monitoring metrics that you want to view. For details of monitoring metrics, see Monitor parameter.</li> <li>You can set a base line as a reference standard.</li> </ul> </li> </ul>"},{"location":"nebula-dashboard-ent/4.cluster-operator/2.monitor/#service","title":"Service","text":"<p>On this page, you can view the information of Graph, Meta, and Storage services quickly. In the upper right corner, the number of normal services and abnormal services will be displayed.</p> <p>Note</p> <p>In the current Service page of the Enterprise Edition, only two monitoring metrics can be set for each service, which can be adjusted by clicking the Set up button.</p> <ul> <li>To view the detailed monitoring information, click the  button. In this example, select <code>Graph</code> for details. The figure is as follows.    <ul> <li>By default, you can view the monitoring data of the latest 1 hour, 6 hours, 12 hours, 1 day, 3 days, 7days, or 14 days.</li> <li>You can select the machine and monitoring metrics that you want to view. For details of monitoring metrics, see Monitor parameter.</li> <li>You can set a base line as a reference standard.</li> <li>You can view the status of the current service.</li> </ul> </li> </ul>"},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/","title":"Cluster information","text":"<p>This topic introduces the cluster information of Dashboard. The cluster information has the following six parts:</p> <ul> <li>Version</li> <li>Leader</li> <li>Partition</li> <li>Service information</li> <li>Partition information</li> <li>Long-term task</li> </ul> <p>Before viewing the cluster information, you need to select any online Graph service address, enter the account to log in to NebulaGraph (not the Dashboard login account), and the corresponding password.</p> <p>For multi-machine deployment, you can choose any online Graph service address.</p> <p>Caution</p> <p>You need to ensure that NebulaGraph services have been deployed and started. For more information, see NebulaGraph installation and deployment.</p> <p></p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/#version","title":"Version","text":"<p>On this page, all services and corresponding Nebula versions will be shown.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/#leader","title":"Leader","text":"<p>On this page, the number of Leaders and the Leader distribution will be shown. You can click the Balance Leader button in the upper right corner to distribute Leaders evenly and quickly in the NebulaGraph cluster.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/#partition","title":"Partition","text":"<p>On this page, you can select the specified graph space and view its distribution of Partitions.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/#service_information","title":"Service information","text":"<p>On this page, the information of Storage services will be shown. You can click the Balance Date button in the upper right corner to start the task to distribute all partitions in the cluster evenly. The parameter description is as follows:</p> Parameter Description <code>Host</code> The IP address of the host. <code>Port</code> The port of the host. <code>Status</code> The host status. <code>Git Info Sha</code> The commit ID of the current version. <code>Leader Count</code> The number of Leaders. <code>Partition Distribution</code> The distribution of partitions. <code>Leader Distribution</code> The distribution of Leaders."},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/#partition_information","title":"Partition information","text":"<p>On this page, the information of partitions will be shown. Before viewing the partition information, you need to select a graph space in the upper left corner. You can also enter the partition ID into the input box in the upper right corner to filter the shown data. The parameter description is as follows:</p> Parameter Description <code>Partition ID</code> The ID of the partition. <code>Leader</code> The IP address and port of the leader. <code>Peers</code> The IP addresses and ports of all the replicas. <code>Losts</code> The IP addresses and ports of replicas at fault."},{"location":"nebula-dashboard-ent/4.cluster-operator/3.cluster-information/#long-term_task","title":"Long-term task","text":"<p>On this page, the information of all jobs will be shown. Before viewing the job information, you need to select a graph space in the upper left corner. Online managing jobs is not supported. For more information, see Job statements. The parameter description is as follows:</p> Parameter Description <code>Job ID</code> Shows the Job ID. <code>Command</code> Shows the command type. <code>Status</code> Shows the status of the job or task. For more information, see Job statements. <code>Start Time</code> Shows a timestamp indicating the time when the job or task starts RUNNING. <code>Stop Time</code> Shows a timestamp indicating the time when the job or task gets <code>FINISHED</code>, <code>FAILED</code>, or<code>STOPPED</code>."},{"location":"nebula-dashboard-ent/4.cluster-operator/4.manage/","title":"Cluster operation","text":"<p>This topic introduces the cluster operation of Dashboard. The cluster operation has the following four parts:</p> <ul> <li>Node</li> <li>Service</li> <li>Scale</li> <li>Update config</li> </ul>"},{"location":"nebula-dashboard-ent/4.cluster-operator/4.manage/#node","title":"Node","text":"<p>On this page, the information of all nodes will be shown, including the cluster name, Host(SSH_User), CPU (Core), etc.</p> <ul> <li>To add a node quickly, click Add node and enter the following information, the Host, SSH port, SSH user, SSH password, and select a NebulaGraph package.</li> </ul> <ul> <li> <p>Click the  button to view the process name, service type, status, runtime directory of the corresponding node.</p> <ul> <li>Click Node monitoring to jump to the detailed node monitoring page. For more information, see Cluster monitoring.</li> </ul> <ul> <li>Click Edit node to modify the SSH port, SSH user, and SSH password.</li> </ul> <ul> <li>If a node has no service, you can delete the node.</li> </ul> </li> </ul> <p></p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/4.manage/#service","title":"Service","text":"<ul> <li>On this page, you can select the service type, service status, and Host to filter the shown data, quickly select one or multiple services, and start/stop/restart the service with one click.</li> </ul> <ul> <li>Click the  icon to quickly view the Service monitoring.</li> </ul> <p>Danger</p> <p>If you click Stop/Restart, the running task will be stopped instantly, which may cause data inconsistency. It is recommended to perform this operation during the low peak period of the business.</p> <p></p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/4.manage/#scale","title":"Scale","text":"<ul> <li>On this page, you can add node and import node in batches quickly, and add Graph services and Storage services to the existing nodes.</li> <li>Click the Reset button to restore to the initial state.</li> </ul> <p>Caution</p> <p>Currently, you can dynamically scale Storaged and Graphd services through Dashboard. The Metad service cannot be scaled. When scaling a cluster, it is recommended to back up data in advance so that data can be rolled back when scaling fails. For more information, see FAQ.</p> <p>In this example, storage services with nodes <code>192.168.8.143</code> and <code>192.168.8.167</code> are added, and Graph services with node <code>192.168.8.169</code> are deleted. If the box is dotted and the service name is greyed, it means the service is removed. If the box is solid, it means the service is newly added.</p> <p>In the services below, green indicates services that will be added soon, and red indicates services that will be removed. You can modify the port, HTTP port, and HTTP2 port of the newly added service.</p> <p></p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/4.manage/#update_config","title":"Update config","text":"<p>On this page, you can modify configuration files of Storage and Graph services. For more information, see Storage service configuration and Graph service configuration. Updating configuration files is a batch operation, and each Storage/Graph configuration file will be modified.</p> <ul> <li>After clicking Save, the configuration will take effect after the next service restart.</li> </ul> <ul> <li> <p>Click Save and restart to directly restart the service to make the configuration take effect immediately.</p> <p>Danger</p> <p>If you click Save and Restart, the running task will be stopped and the cluster will be restarted instantly, which may cause data inconsistency. It is recommended to perform this operation during the low peak period of the business.</p> </li> </ul> <p></p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/5.operation-record/","title":"Operation record","text":"<p>This topic shows how to use the operation record feature in Nebula Dashboard.</p> <p></p> <p>On the Operation record page, you can check the operation records of the latest 1 hour, 6 hours, 1 day, 3 days, 7days, or 14 days. You can also view who runs what operation on which cluster at what time.</p>"},{"location":"nebula-dashboard-ent/4.cluster-operator/6.settings/","title":"Other settings","text":"<p>The following shows other settings in Nebula Dashboard.</p> <ul> <li>Information: shows the cluster name, the creation time, and the creator.</li> </ul> <ul> <li> <p>Unbind: Unbind a cluster and remove its information from the platform. The unbound cluster info will be removed and no operations will be done on cluster services or Nebula data.</p> <p>Note</p> <p>To unbind a cluster, enter the cluster name first.</p> <p></p> </li> </ul> <ul> <li> <p>Delete: Delete a cluster and remove its information from the platform. Deleting the cluster will stop its service and unbind the cluster info, but retain its Nebula data. Be cautious when you delete a cluster.</p> <p>Note</p> <p>To delete a cluster, enter the cluster name first</p> <p></p> </li> </ul>"},{"location":"nebula-exchange/ex-ug-FAQ/","title":"Exchange FAQ","text":""},{"location":"nebula-exchange/ex-ug-FAQ/#compilation","title":"Compilation","text":""},{"location":"nebula-exchange/ex-ug-FAQ/#some_packages_not_in_central_repository_failed_to_download_error_could_not_resolve_dependencies_for_project_xxx","title":"Some packages not in central repository failed to download, error: <code>Could not resolve dependencies for project xxx</code>","text":"<p>Please check the <code>mirror</code> part of Maven installation directory <code>libexec/conf/settings.xml</code>:</p> <pre><code>&lt;mirror&gt;\n    &lt;id&gt;alimaven&lt;/id&gt;\n    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n    &lt;name&gt;aliyun maven&lt;/name&gt;\n    &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt;\n&lt;/mirror&gt;\n</code></pre> <p>Check whether the value of <code>mirrorOf</code> is configured to <code>*</code>. If it is, change it to <code>central</code> or <code>*,!SparkPackagesRepo,!bintray-streamnative-maven</code>.</p> <p>Reason: There are two dependency packages in Exchange's <code>pom.xml</code> that are not in Maven's central repository. <code>pom.xml</code> configures the repository address for these two dependencies. If the <code>mirrorOf</code> value for the mirror address configured in Maven is <code>*</code>, all dependencies will be downloaded from the Central repository, causing the download to fail.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#execution","title":"Execution","text":""},{"location":"nebula-exchange/ex-ug-FAQ/#how_to_submit_in_yarn-cluster_mode","title":"How to submit in Yarn-Cluster mode?","text":"<p>To submit a task in Yarn-Cluster mode, run the following command:</p> <pre><code>$SPARK_HOME/bin/spark-submit --class com.vesoft.nebula.exchange.Exchange \\\n--master yarn-cluster \\\n--files application.conf \\\n--conf spark.driver.extraClassPath=./ \\\n--conf spark.executor.extraClassPath=./ \\\nnebula-exchange-2.0.0.jar \\\n-c application.conf\n</code></pre>"},{"location":"nebula-exchange/ex-ug-FAQ/#error_method_name_xxx_not_found","title":"Error: <code>method name xxx not found</code>","text":"<p>Generally, the port configuration is incorrect. Check the port configuration of the Meta service, Graph service, and Storage service.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#error_nosuchmethod_methodnotfound_exception_in_thread_main_javalangnosuchmethoderror_etc","title":"Error: NoSuchMethod, MethodNotFound (<code>Exception in thread \"main\" java.lang.NoSuchMethodError</code>, etc)","text":"<p>Most errors are caused by JAR package conflicts or version conflicts. Check whether the version of the error reporting service is the same as that used in Exchange, especially Spark, Scala, and Hive.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#when_exchange_imports_hive_data_error_exception_in_thread_main_orgapachesparksqlanalysisexception_table_or_view_not_found","title":"When Exchange imports Hive data, error: <code>Exception in thread \"main\" org.apache.spark.sql.AnalysisException: Table or view not found</code>","text":"<p>Check whether the <code>-h</code> parameter is omitted in the command for submitting the Exchange task and whether the table and database are correct, and run the user-configured exec statement in spark-SQL to verify the correctness of the exec statement.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#run_error_comfacebookthriftprotocoltprotocolexception_expected_protocol_id_xxx","title":"Run error: <code>com.facebook.thrift.protocol.TProtocolException: Expected protocol id xxx</code>","text":"<p>Check that the NebulaGraph service port is configured correctly.</p> <ul> <li>For source, RPM, or DEB installations, configure the port number corresponding to <code>--port</code> in the configuration file for each service.</li> </ul> <ul> <li>For docker installation, configure the docker mapped port number as follows:<p>Execute <code>docker-compose ps</code> in the <code>nebula-docker-compose</code> directory, for example:</p> <pre><code>$ docker-compose ps\n              Name                             Command                  State                                                         Ports\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nnebula-docker-compose_graphd_1      /usr/local/nebula/bin/nebu ...   Up (healthy)   0.0.0.0:33205-&gt;19669/tcp, 0.0.0.0:33204-&gt;19670/tcp, 0.0.0.0:9669-&gt;9669/tcp\nnebula-docker-compose_metad0_1      ./bin/nebula-metad --flagf ...   Up (healthy)   0.0.0.0:33165-&gt;19559/tcp, 0.0.0.0:33162-&gt;19560/tcp, 0.0.0.0:33167-&gt;9559/tcp, 9560/tcp\nnebula-docker-compose_metad1_1      ./bin/nebula-metad --flagf ...   Up (healthy)   0.0.0.0:33166-&gt;19559/tcp, 0.0.0.0:33163-&gt;19560/tcp, 0.0.0.0:33168-&gt;9559/tcp, 9560/tcp\nnebula-docker-compose_metad2_1      ./bin/nebula-metad --flagf ...   Up (healthy)   0.0.0.0:33161-&gt;19559/tcp, 0.0.0.0:33160-&gt;19560/tcp, 0.0.0.0:33164-&gt;9559/tcp, 9560/tcp\nnebula-docker-compose_storaged0_1   ./bin/nebula-storaged --fl ...   Up (healthy)   0.0.0.0:33180-&gt;19779/tcp, 0.0.0.0:33178-&gt;19780/tcp, 9777/tcp, 9778/tcp, 0.0.0.0:33183-&gt;9779/tcp, 9780/tcp\nnebula-docker-compose_storaged1_1   ./bin/nebula-storaged --fl ...   Up (healthy)   0.0.0.0:33175-&gt;19779/tcp, 0.0.0.0:33172-&gt;19780/tcp, 9777/tcp, 9778/tcp, 0.0.0.0:33177-&gt;9779/tcp, 9780/tcp\nnebula-docker-compose_storaged2_1   ./bin/nebula-storaged --fl ...   Up (healthy)   0.0.0.0:33184-&gt;19779/tcp, 0.0.0.0:33181-&gt;19780/tcp, 9777/tcp, 9778/tcp, 0.0.0.0:33185-&gt;9779/tcp, 9780/tcp\n</code></pre> <p>Check the <code>Ports</code> column to find the docker mapped port number, for example:</p> <p>- The port number available for Graph service is 9669.</p> <p>- The port number for Meta service are 33167, 33168, 33164.</p> <p>- The port number for Storage service are 33183, 33177, 33185.</p> </li> </ul>"},{"location":"nebula-exchange/ex-ug-FAQ/#error_exception_in_thread_main_comfacebookthriftprotocoltprotocolexception_the_field_code_has_been_assigned_the_invalid_value_-4","title":"Error: <code>Exception in thread \"main\" com.facebook.thrift.protocol.TProtocolException: The field 'code' has been assigned the invalid value -4</code>","text":"<p>Check whether the version of Exchange is the same as that of NebulaGraph. For more information, see Limitations.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#how_to_correct_the_messy_code_when_importing_hive_data_into_nebulagraph","title":"How to correct the messy code when importing Hive data into NebulaGraph?","text":"<p>It may happen if the property value of the data in Hive contains Chinese characters. The solution is to add the following options before the JAR package path in the import command:</p> <pre><code>--conf spark.driver.extraJavaOptions=-Dfile.encoding=utf-8\n--conf spark.executor.extraJavaOptions=-Dfile.encoding=utf-8\n</code></pre> <p>Namely:</p> <pre><code>&lt;spark_install_path&gt;/bin/spark-submit --master \"local\" \\\n--conf spark.driver.extraJavaOptions=-Dfile.encoding=utf-8 \\\n--conf spark.executor.extraJavaOptions=-Dfile.encoding=utf-8 \\\n--class com.vesoft.nebula.exchange.Exchange \\\n&lt;nebula-exchange-2.x.y.jar_path&gt; -c &lt;application.conf_path&gt;\n</code></pre> <p>In YARN, use the following command:</p> <pre><code>&lt;spark_install_path&gt;/bin/spark-submit \\\n--class com.vesoft.nebula.exchange.Exchange \\\n--master yarn-cluster \\\n--files &lt;application.conf_path&gt; \\\n--conf spark.driver.extraClassPath=./ \\\n--conf spark.executor.extraClassPath=./ \\\n--conf spark.driver.extraJavaOptions=-Dfile.encoding=utf-8 \\\n--conf spark.executor.extraJavaOptions=-Dfile.encoding=utf-8 \\\n&lt;nebula-exchange-2.x.y.jar_path&gt; \\\n-c application.conf\n</code></pre>"},{"location":"nebula-exchange/ex-ug-FAQ/#configuration","title":"Configuration","text":""},{"location":"nebula-exchange/ex-ug-FAQ/#which_configuration_fields_will_affect_import_performance","title":"Which configuration fields will affect import performance?","text":"<ul> <li>batch: The number of data contained in each nGQL statement sent to the NebulaGraph service.</li> </ul> <ul> <li>partition: The number of Spark data partitions, indicating the number of concurrent data imports.</li> </ul> <ul> <li>nebula.rate: Get a token from the token bucket before sending a request to NebulaGraph.<p>- limit: Represents the size of the token bucket.</p> <p>- timeout: Represents the timeout period for obtaining the token.</p> </li> </ul> <p>The values of these four parameters can be adjusted appropriately according to the machine performance. If the leader of the Storage service changes during the import process, you can adjust the values of these four parameters to reduce the import speed.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#others","title":"Others","text":""},{"location":"nebula-exchange/ex-ug-FAQ/#which_versions_of_nebulagraph_are_supported_by_exchange","title":"Which versions of NebulaGraph are supported by Exchange?","text":"<p>See Limitations.</p>"},{"location":"nebula-exchange/ex-ug-FAQ/#what_is_the_relationship_between_exchange_and_spark_writer","title":"What is the relationship between Exchange and Spark Writer?","text":"<p>Exchange is the Spark application developed based on Spark Writer. Both are suitable for bulk migration of cluster data to NebulaGraph in a distributed environment, but later maintenance work will be focused on Exchange. Compared with Spark Writer, Exchange has the following improvements:</p> <ul> <li>It supports more abundant data sources, such as MySQL, Neo4j, Hive, HBase, Kafka, Pulsar, etc.</li> </ul> <ul> <li>It fixed some problems of Spark Writer. For example, when Spark reads data from HDFS, the default source data is String, which may be different from the NebulaGraph's Schema. So Exchange adds automatic data type matching and type conversion. When the data type in the NebulaGraph's Schema is non-String (e.g. double), Exchange converts the source data of String type to the corresponding type.</li> </ul>"},{"location":"nebula-exchange/ex-ug-compile/","title":"Get Exchange","text":"<p>This topic introduces how to get the JAR file of Nebula Exchange.</p>"},{"location":"nebula-exchange/ex-ug-compile/#download_the_jar_file_directly","title":"Download the JAR file directly","text":"<p>The JAR file of Exchange Community Edition can be downloaded directly.</p> <p>To download Exchange Enterprise Edition, get NebulaGraph Enterprise Edition Package first.</p>"},{"location":"nebula-exchange/ex-ug-compile/#get_the_jar_file_by_compiling_the_source_code","title":"Get the JAR file by compiling the source code","text":"<p>You can get the JAR file of Exchange Community Edition by compiling the source code. The following introduces how to compile the source code of Exchange.</p> <p>Enterpriseonly</p> <p>You can get Exchange Enterprise Edition in NebulaGraph Enterprise Edition Package only.</p>"},{"location":"nebula-exchange/ex-ug-compile/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Maven.</li> </ul> <ul> <li>Download pulsar-spark-connector_2.11, and unzip it to <code>io/streamnative/connectors</code> directory of the local Maven library.</li> </ul>"},{"location":"nebula-exchange/ex-ug-compile/#steps","title":"Steps","text":"<ol> <li> <p>Clone the repository <code>nebula-exchange</code> in the <code>/</code> directory.</p> <pre><code>git clone -b v2.6 https://github.com/vesoft-inc/nebula-exchange.git\n</code></pre> </li> <li> <p>Switch to the directory <code>nebula-exchange</code>.</p> <pre><code>cd nebula-exchange/nebula-exchange\n</code></pre> </li> <li> <p>Package Nebula Exchange.</p> <pre><code>mvn clean package -Dmaven.test.skip=true -Dgpg.skip -Dmaven.javadoc.skip=true\n</code></pre> </li> </ol> <p>After the compilation is successful, you can view a directory structure similar to the following in the current directory.</p> <pre><code>.\n\u251c\u2500\u2500 README-CN.md\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pom.xml\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 main\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 test\n\u2514\u2500\u2500 target\n    \u251c\u2500\u2500 classes\n    \u251c\u2500\u2500 classes.timestamp\n    \u251c\u2500\u2500 maven-archiver\n    \u251c\u2500\u2500 nebula-exchange-2.x.y-javadoc.jar\n    \u251c\u2500\u2500 nebula-exchange-2.x.y-sources.jar\n    \u251c\u2500\u2500 nebula-exchange-2.x.y.jar\n    \u251c\u2500\u2500 original-nebula-exchange-2.x.y.jar\n    \u2514\u2500\u2500 site\n</code></pre> <p>In the <code>target</code> directory, users can find the <code>exchange-2.x.y.jar</code> file.</p> <p>Note</p> <p>The JAR file version changes with the release of the Nebula Java Client. Users can view the latest version on the Releases page.</p> <p>When migrating data, you can refer to configuration file <code>target/classes/application.conf</code>.</p>"},{"location":"nebula-exchange/ex-ug-compile/#failed_to_download_the_dependency_package","title":"Failed to download the dependency package","text":"<p>If downloading dependencies fails when compiling:</p> <ul> <li>Check the network settings and ensure that the network is normal.</li> </ul> <ul> <li> <p>Modify the <code>mirror</code> part of Maven installation directory <code>libexec/conf/settings.xml</code>:</p> <pre><code>&lt;mirror&gt;\n &lt;id&gt;alimaven&lt;/id&gt;\n &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n &lt;name&gt;aliyun maven&lt;/name&gt;\n &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt;\n&lt;/mirror&gt;\n</code></pre> </li> </ul>"},{"location":"nebula-exchange/about-exchange/ex-ug-limitations/","title":"Limitations","text":"<p>This topic describes some of the limitations of using Exchange 2.x.</p>"},{"location":"nebula-exchange/about-exchange/ex-ug-limitations/#version_compatibility","title":"Version compatibility","text":"<p>The correspondence between the Nebula Exchange release (the JAR version) and the NebulaGraph core release is as follows.</p> Exchange client NebulaGraph 2.5-SNAPSHOT nightly 2.6.1 2.6.0, 2.6.2 2.5.1 2.5.0, 2.5.1 2.5.0 2.5.0, 2.5.1 2.1.0 2.0.0, 2.0.1 2.0.1 2.0.0, 2.0.1 2.0.0 2.0.0, 2.0.1 <p>JAR packages are available in two ways: compile them yourself or download them from the Maven repository.</p> <p>If you are using NebulaGraph 1.x, use Nebula Exchange 1.x.</p>"},{"location":"nebula-exchange/about-exchange/ex-ug-limitations/#environment","title":"Environment","text":"<p>Exchange 2.x supports the following operating systems:</p> <ul> <li>CentOS 7</li> <li>macOS</li> </ul>"},{"location":"nebula-exchange/about-exchange/ex-ug-limitations/#software_dependencies","title":"Software dependencies","text":"<p>To ensure the healthy operation of Exchange, ensure that the following software has been installed on the machine:</p> <ul> <li>Apache Spark: 2.4.x</li> </ul> <ul> <li>Java: 1.8</li> </ul> <ul> <li>Scala: 2.10.7, 2.11.12, or 2.12.10</li> </ul> <p>Hadoop Distributed File System (HDFS) needs to be deployed in the following scenarios:</p> <ul> <li>Migrate HDFS data</li> <li>Generate SST files</li> </ul>"},{"location":"nebula-exchange/about-exchange/ex-ug-what-is-exchange/","title":"What is Nebula Exchange","text":"<p>Nebula Exchange (Exchange) is an Apache Spark\u2122 application for bulk migration of cluster data to NebulaGraph in a distributed environment, supporting batch and streaming data migration in a variety of formats.</p> <p>Exchange consists of Reader, Processor, and Writer. After Reader reads data from different sources and returns a DataFrame, the Processor iterates through each row of the DataFrame and obtains the corresponding value based on the mapping between <code>fields</code> in the configuration file. After iterating through the number of rows in the specified batch, Writer writes the captured data to the NebulaGraph at once. The following figure illustrates the process by which Exchange completes the data conversion and migration.</p> <p></p>"},{"location":"nebula-exchange/about-exchange/ex-ug-what-is-exchange/#editions","title":"Editions","text":"<p>Exchange has two editions, the Community Edition and the Enterprise Edition. The Community Edition is open source developed on GitHub. The Enterprise Edition supports not only the functions of the Community Edition but also adds additional features. For details, see Comparisons.</p>"},{"location":"nebula-exchange/about-exchange/ex-ug-what-is-exchange/#scenarios","title":"Scenarios","text":"<p>Exchange applies to the following scenarios:</p> <ul> <li>Streaming data from Kafka and Pulsar platforms, such as log files, online shopping data, activities of game players, information on social websites, financial transactions or geospatial services, and telemetry data from connected devices or instruments in the data center, are required to be converted into the vertex or edge data of the property graph and import them into the NebulaGraph database.</li> </ul> <ul> <li>Batch data, such as data from a time period, needs to be read from a relational database (such as MySQL) or a distributed file system (such as HDFS), converted into vertex or edge data for a property graph, and imported into the NebulaGraph database.</li> </ul> <ul> <li>A large volume of data needs to be generated into SST files that NebulaGraph can recognize and then imported into the NebulaGraph database.</li> </ul> <ul> <li> <p>The data saved in NebulaGraph needs to be exported.</p> <p>Enterpriseonly</p> <p>Exporting the data saved in NebulaGraph is supported by Exchange Enterprise Edition only.</p> </li> </ul>"},{"location":"nebula-exchange/about-exchange/ex-ug-what-is-exchange/#advantages","title":"Advantages","text":"<p>Exchange has the following advantages:</p> <ul> <li>High adaptability: It supports importing data into the NebulaGraph database in a variety of formats or from a variety of sources, making it easy to migrate data.</li> </ul> <ul> <li>SST import: It supports converting data from different sources into SST files for data import.</li> </ul> <ul> <li>SSL encryption: It supports establishing the SSL encryption between Exchange and NebulaGraph to ensure data security.</li> </ul> <ul> <li> <p>Resumable data import: It supports resumable data import to save time and improve data import efficiency.</p> <p>Note</p> <p>Resumable data import is currently supported when migrating Neo4j data only.</p> </li> </ul> <ul> <li>Asynchronous operation: An insert statement is generated in the source data and sent to the Graph service. Then the insert operation is performed.</li> </ul> <ul> <li>Great flexibility: It supports importing multiple Tags and Edge types at the same time. Different Tags and Edge types can be from different data sources or in different formats.</li> </ul> <ul> <li>Statistics: It uses the accumulator in Apache Spark\u2122 to count the number of successful and failed insert operations.</li> </ul> <ul> <li>Easy to use: It adopts the Human-Optimized Config Object Notation (HOCON) configuration file format and has an object-oriented style, which is easy to understand and operate.</li> </ul>"},{"location":"nebula-exchange/about-exchange/ex-ug-what-is-exchange/#data_source","title":"Data source","text":"<p>Exchange 2.6.1 supports converting data from the following formats or sources into vertexes and edges that NebulaGraph can recognize, and then importing them into NebulaGraph in the form of nGQL statements:</p> <ul> <li>Data stored in HDFS or locally:<ul> <li>Apache Parquet</li> <li>Apache ORC</li> <li>JSON</li> <li>CSV</li> </ul> </li> </ul> <ul> <li>Apache HBase\u2122</li> </ul> <ul> <li> <p>Data repository:</p> <ul> <li>Hive</li> <li>MaxCompute</li> </ul> </li> </ul> <ul> <li>Graph database: Neo4j (Client version 2.4.5-M1)</li> </ul> <ul> <li>Relational database: MySQL</li> </ul> <ul> <li>Column database: ClickHouse</li> </ul> <ul> <li>Stream processing software platform: Apache Kafka\u00ae</li> </ul> <ul> <li>Publish/Subscribe messaging platform: Apache Pulsar 2.4.5</li> </ul> <p>In addition to importing data as nGQL statements, Exchange supports generating SST files for data sources and then importing SST files via Console.</p> <p>In addition, Exchange Enterprise Edition also supports exporting data to a CSV file using NebulaGraph as data sources.</p>"},{"location":"nebula-exchange/about-exchange/ex-ug-what-is-exchange/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-exchange/parameter-reference/ex-ug-para-import-command/","title":"Options for import","text":"<p>After editing the configuration file, run the following commands to import specified source data into the NebulaGraph database.</p> <ul> <li> <p>First import</p> <pre><code>&lt;spark_install_path&gt;/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.x.y.jar_path&gt; -c &lt;application.conf_path&gt; </code></pre> </li> </ul> <ul> <li> <p>Import the reload file</p> <p>If some data fails to be imported during the first import, the failed data will be stored in the reload file. Use the parameter <code>-r</code> to import the reload file.</p> <pre><code>&lt;spark_install_path&gt;/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.x.y.jar_path&gt; -c &lt;application.conf_path&gt; -r \"&lt;reload_file_path&gt;\" </code></pre> </li> </ul> <p>Note</p> <p>The version number of a JAR file is subject to the name of the JAR file that is actually compiled.</p> <p>Note</p> <p>If users use the yarn-cluster mode to submit a job, see the following command:</p> <pre><code>$SPARK_HOME/bin/spark-submit     --master yarn-cluster \\\n--class com.vesoft.nebula.exchange.Exchange \\\n--files application.conf \\\n--conf spark.driver.extraClassPath=./ \\\n--conf spark.executor.extraClassPath=./ \\\nnebula-exchange-2.6.1.jar \\\n-c application.conf\n</code></pre> <p>The following table lists command parameters.</p> Parameter Required Default value Description <code>--class</code> Yes - Specify the main class of the driver. <code>--master</code> Yes - Specify the URL of the master process in a Spark cluster. For more information, see master-urls. <code>-c</code>\u00a0 / <code>--config</code> Yes - Specify the path of the configuration file. <code>-h</code>\u00a0 / <code>--hive</code> No <code>false</code> Indicate support for importing Hive data. <code>-D</code>\u00a0 / <code>--dry</code> No <code>false</code> Check whether the format of the configuration file meets the requirements, but it does not check whether the configuration items of <code>tags</code> and <code>edges</code> are correct. This parameter cannot be added when users import data. <code>-r</code> / <code>--reload</code> No - Specify the path of the reload file that needs to be reloaded. <p>For more Spark parameter configurations, see Spark Configuration.</p>"},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/","title":"Parameters in the configuration file","text":"<p>This topic describes how to configure the file <code>application.conf</code> when users use Nebula Exchange.</p> <p>Before configuring the <code>application.conf</code> file, it is recommended to copy the file name <code>application.conf</code> and then edit the file name according to the file type of a data source. For example, change the file name to <code>csv_application.conf</code> if the file type of the data source is CSV.</p> <p>The <code>application.conf</code> file contains the following content types:</p> <ul> <li>Spark configurations</li> </ul> <ul> <li>Hive configurations (optional)</li> </ul> <ul> <li>NebulaGraph configurations</li> </ul> <ul> <li>Vertex configurations</li> </ul> <ul> <li>Edge configurations</li> </ul>"},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#spark_configurations","title":"Spark configurations","text":"<p>This topic lists only some Spark parameters. For more information, see Spark Configuration.</p> Parameter Type Default value Required Description <code>spark.app.name</code> string - No The drive name in Spark. <code>spark.driver.cores</code> int <code>1</code> No The number of CPU cores used by a driver, only applicable to a cluster mode. <code>spark.driver.maxResultSize</code> string <code>1G</code> No The total size limit (in bytes) of the serialized results of all partitions in a single Spark operation (such as collect). The minimum value is 1M, and 0 means unlimited. <code>spark.executor.memory</code> string <code>1G</code> No The amount of memory used by a Spark driver which can be specified in units, such as 512M or 1G. <code>spark.cores.max</code> int <code>16</code> No The maximum number of CPU cores of applications requested across clusters (rather than from each node) when a driver runs in a coarse-grained sharing mode on a standalone cluster or a Mesos cluster. The default value is <code>spark.deploy.defaultCores</code> on a Spark standalone cluster manager or the value of the <code>infinite</code> parameter (all available cores) on Mesos."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#hive_configurations_optional","title":"Hive configurations (optional)","text":"<p>Users only need to configure parameters for connecting to Hive if Spark and Hive are deployed in different clusters. Otherwise, please ignore the following configurations.</p> Parameter Type Default value Required Description <code>hive.warehouse</code> string - Yes The warehouse path in HDFS. Enclose the path in double quotes and start with <code>hdfs://</code>. <code>hive.connectionURL</code> string - Yes The URL of a JDBC connection. For example, <code>\"jdbc:mysql://127.0.0.1:3306/hive_spark?characterEncoding=UTF-8\"</code>. <code>hive.connectionDriverName</code> string <code>\"com.mysql.jdbc.Driver\"</code> Yes The driver name. <code>hive.connectionUserName</code> list[string] - Yes The username for connections. <code>hive.connectionPassword</code> list[string] - Yes The account password."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#nebulagraph_configurations","title":"NebulaGraph configurations","text":"Parameter Type Default value Required Description <code>nebula.address.graph</code> list[string] <code>[\"127.0.0.1:9669\"]</code> Yes The addresses of all Graph services, including IPs and ports, separated by commas (,). Example: <code>[\"ip1:port1\",\"ip2:port2\",\"ip3:port3\"]</code>. <code>nebula.address.meta</code> list[string] <code>[\"127.0.0.1:9559\"]</code> Yes The addresses of all Meta services, including IPs and ports, separated by commas (,). Example: <code>[\"ip1:port1\",\"ip2:port2\",\"ip3:port3\"]</code>. <code>nebula.user</code> string - Yes The username with write permissions for NebulaGraph. <code>nebula.pswd</code> string - Yes The account password. <code>nebula.space</code> string - Yes The name of the graph space where data needs to be imported. <code>nebula.ssl.enable.graph</code> bool <code>false</code> Yes Enables the SSL encryption between Exchange and Graph services. If the value is <code>true</code>, the SSL encryption is enabled and the following SSL parameters take effect. If Exchange is run on a multi-machine cluster, you need to store the corresponding files in the same path on each machine when setting the following SSL-related paths. <code>nebula.ssl.sign</code> string <code>ca</code> Yes Specifies the SSL sign. Optional values are <code>ca</code> and <code>self</code>. <code>nebula.ssl.ca.param.caCrtFilePath</code> string Specifies the storage path of the CA certificate. It takes effect when the value of <code>nebula.ssl.sign</code> is <code>ca</code>. <code>nebula.ssl.ca.param.crtFilePath</code> string <code>\"/path/crtFilePath\"</code> Yes Specifies the storage path of the CRT certificate. It takes effect when the value of <code>nebula.ssl.sign</code> is <code>ca</code>. <code>nebula.ssl.ca.param.keyFilePath</code> string <code>\"/path/keyFilePath\"</code> Yes Specifies the storage path of the key file. It takes effect when the value of <code>nebula.ssl.sign</code> is <code>ca</code>. <code>nebula.ssl.self.param.crtFilePath</code> string <code>\"/path/crtFilePath\"</code> Yes Specifies the storage path of the CRT certificate. It takes effect when the value of <code>nebula.ssl.sign</code> is <code>self</code>. <code>nebula.ssl.self.param.keyFilePath</code> string <code>\"/path/keyFilePath\"</code> Yes Specifies the storage path of the key file. It takes effect when the value of <code>nebula.ssl.sign</code> is <code>self</code>. <code>nebula.ssl.self.param.password</code> string <code>\"nebula\"</code> Yes Specifies the storage path of the password. It takes effect when the value of <code>nebula.ssl.sign</code> is <code>self</code>. <code>nebula.path.local</code> string <code>\"/tmp\"</code> No The local SST file path which needs to be set when users import SST files. <code>nebula.path.remote</code> string <code>\"/sst\"</code> No The remote SST file path which needs to be set when users import SST files. <code>nebula.path.hdfs.namenode</code> string <code>\"hdfs://name_node:9000\"</code> No The NameNode path which needs to be set when users import SST files. <code>nebula.connection.timeout</code> int <code>3000</code> No The timeout set for Thrift connections. Unit: ms. <code>nebula.connection.retry</code> int <code>3</code> No Retries set for Thrift connections. <code>nebula.execution.retry</code> int <code>3</code> No Retries set for executing nGQL statements. <code>nebula.error.max</code> int <code>32</code> No The maximum number of failures during the import process. When the number of failures reaches the maximum, the Spark job submitted will stop automatically . <code>nebula.error.output</code> string <code>/tmp/errors</code> No The path to output error logs. Failed nGQL statement executions are saved in the error log. <code>nebula.rate.limit</code> int <code>1024</code> No The limit on the number of tokens in the token bucket when importing data. <code>nebula.rate.timeout</code> int <code>1000</code> No The timeout period for getting tokens from a token bucket. Unit: milliseconds."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#vertex_configurations","title":"Vertex configurations","text":"<p>For different data sources, the vertex configurations are different. There are many general parameters and some specific parameters. General parameters and specific parameters of different data sources need to be configured when users configure vertices.</p>"},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#general_parameters","title":"General parameters","text":"Parameter Type Default value Required Description <code>tags.name</code> string - Yes The tag name defined in NebulaGraph. <code>tags.type.source</code> string - Yes Specify a data source. For example, <code>csv</code>. <code>tags.type.sink</code> string <code>client</code> Yes Specify an import method. Optional values are <code>client</code> and <code>SST</code>. <code>tags.fields</code> list[string] - Yes The header or column name of the column corresponding to properties. If there is a header or a column name, please use that name directly. If a CSV file does not have a header, use the form of <code>[_c0, _c1, _c2]</code> to represent the first column, the second column, the third column, and so on. <code>tags.nebula.fields</code> list[string] - Yes Property names defined in NebulaGraph, the order of which must correspond to <code>tags.fields</code>. For example, <code>[_c1, _c2]</code> corresponds to <code>[name, age]</code>, which means that values in the second column are the values of the property <code>name</code>, and values in the third column are the values of the property <code>age</code>. <code>tags.vertex.field</code> string - Yes The column of vertex IDs. For example, when a CSV file has no header, users can use <code>_c0</code> to indicate values in the first column are vertex IDs. <code>tags.batch</code> int <code>256</code> Yes The maximum number of vertices written into NebulaGraph in a single batch. <code>tags.partition</code> int <code>32</code> Yes The number of Spark partitions."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_parquetjsonorc_data_sources","title":"Specific parameters of Parquet/JSON/ORC data sources","text":"Parameter Type Default value Required Description <code>tags.path</code> string - Yes The path of vertex data files in HDFS. Enclose the path in double quotes and start with <code>hdfs://</code>."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_csv_data_sources","title":"Specific parameters of CSV data sources","text":"Parameter Type Default value Required Description <code>tags.path</code> string - Yes The path of vertex data files in HDFS. Enclose the path in double quotes and start with <code>hdfs://</code>. <code>tags.separator</code> string <code>,</code> Yes The separator. The default value is a comma (,). <code>tags.header</code> bool <code>true</code> Yes Whether the file has a header."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_hive_data_sources","title":"Specific parameters of Hive data sources","text":"Parameter Type Default value Required Description <code>tags.exec</code> string - Yes The statement to query data sources. For example, <code>select name,age from mooc.users</code>."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_maxcompute_data_sources","title":"Specific parameters of MaxCompute data sources","text":"Parameter Type Default value Required Description <code>tags.table</code> string - Yes The table name of the MaxCompute. <code>tags.project</code> string - Yes The project name of the MaxCompute. <code>tags.odpsUrl</code> string - Yes The odpsUrl of the MaxCompute service. For more information about odpsUrl, see Endpoints. <code>tags.tunnelUrl</code> string - Yes The tunnelUrl of the MaxCompute service. For more information about tunnelUrl, see Endpoints. <code>tags.accessKeyId</code> string - Yes The accessKeyId of the MaxCompute service. <code>tags.accessKeySecret</code> string - Yes The accessKeySecret of the MaxCompute service. <code>tags.partitionSpec</code> string - No Partition descriptions of MaxCompute tables. <code>tags.sentence</code> string - No Statements to query data sources. The table name in the SQL statement is the same as the value of the table above."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_neo4j_data_sources","title":"Specific parameters of Neo4j data sources","text":"Parameter Type Default value Required Description <code>tags.exec</code> string - Yes Statements to query data sources. For example: <code>match (n:label) return n.neo4j-field-0</code>. <code>tags.server</code> string <code>\"bolt://127.0.0.1:7687\"</code> Yes The server address of Neo4j. <code>tags.user</code> string - Yes The Neo4j username with read permissions. <code>tags.password</code> string - Yes The account password. <code>tags.database</code> string - Yes The name of the database where source data is saved in Neo4j. <code>tags.check_point_path</code> string <code>/tmp/test</code> No The directory set to import progress information, which is used for resuming transfers. If not set, the resuming transfer is disabled."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_mysql_data_sources","title":"Specific parameters of MySQL data sources","text":"Parameter Type Default value Required Description <code>tags.host</code> string - Yes The MySQL server address. <code>tags.port</code> string - Yes The MySQL server port. <code>tags.database</code> string - Yes The database name. <code>tags.table</code> string - Yes The name of a table used as a data source. <code>tags.user</code> string - Yes The MySQL username with read permissions. <code>tags.password</code> string - Yes The account password. <code>tags.sentence</code> string - Yes Statements to query data sources. For example: <code>\"select teamid, name from basketball.team order by teamid;\"</code>."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_clickhouse_data_sources","title":"Specific parameters of ClickHouse data sources","text":"Parameter Type Default value Required Description <code>tags.url</code> string - Yes The JDBC URL of ClickHouse. <code>tags.user</code> string - Yes The ClickHouse username with read permissions. <code>tags.password</code> string - Yes The account password. <code>tags.numPartition</code> string - Yes The number of ClickHouse partitions. <code>tags.sentence</code> string - Yes Statements to query data sources."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_hbase_data_sources","title":"Specific parameters of Hbase data sources","text":"Parameter Type Default value Required Description <code>tags.host</code> string <code>127.0.0.1</code> Yes The Hbase server address. <code>tags.port</code> string <code>2181</code> Yes The Hbase server port. <code>tags.table</code> string - Yes The name of a table used as a data source. <code>tags.columnFamily</code> string - Yes The column family to which a table belongs."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_pulsar_data_sources","title":"Specific parameters of Pulsar data sources","text":"Parameter Type Default value Required Description <code>tags.service</code> string <code>\"pulsar://localhost:6650\"</code> Yes The Pulsar server address. <code>tags.admin</code> string <code>\"http://localhost:8081\"</code> Yes The admin URL used to connect pulsar. <code>tags.options.&lt;topic\\|topics\\| topicsPattern&gt;</code> string - Yes Options offered by Pulsar, which can be configured by choosing one from <code>topic</code>, <code>topics</code>, and <code>topicsPattern</code>. <code>tags.interval.seconds</code> int <code>10</code> Yes The interval for reading messages. Unit: seconds."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_kafka_data_sources","title":"Specific parameters of Kafka data sources","text":"Parameter Type Default value Required Description <code>tags.service</code> string - Yes The Kafka server address. <code>tags.topic</code> string - Yes The message type. <code>tags.interval.seconds</code> int <code>10</code> Yes The interval for reading messages. Unit: seconds."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_sst_data_sources","title":"Specific parameters of SST data sources","text":"Parameter Type Default value Required Description <code>tags.path</code> string - Yes The path of the source file specified to generate SST files."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_nebulagraph","title":"Specific parameters of NebulaGraph","text":"<p>Enterpriseonly</p> <p>Specific parameters of NebulaGraph are used for exporting NebulaGraph data, which is supported by Exchange Enterprise Edition only.</p> Parameter Data type Default value Required Description <code>tags.path</code> string <code>\"hdfs://namenode:9000/path/vertex\"</code> Yes Specifies the storage path of the CSV file. You need to set a new path and Exchange will automatically create the path you set. If you store the data to the HDFS server, the path format is the same as the default value, such as <code>\"hdfs://192.168.8.177:9000/vertex/player\"</code>. If you store the data to the local, the path format is <code>\"file:///path/vertex\"</code>, such as <code>\"file:///home/nebula/vertex/player\"</code>. If there are multiple Tags, different directories must be set for each Tag. <code>tags.noField</code> bool <code>false</code> Yes If the value is <code>true</code>, only VIDs will be exported, not the property data. If the value is <code>false</code>, VIDs and the property data will be exported. <code>tags.return.fields</code> list <code>[]</code> Yes Specifies the properties to be exported. For example, to export the <code>name</code> and <code>age</code>, you need to set the parameter value to <code>[\"name\",\"age\"]</code>. This parameter only takes effect when the value of <code>tags.noField</code> is <code>false</code>."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#edge_configurations","title":"Edge configurations","text":"<p>For different data sources, configurations of edges are also different. There are general parameters and some specific parameters. General parameters and specific parameters of different data sources need to be configured when users configure edges.</p> <p>For the specific parameters of different data sources for edge configurations, please refer to the introduction of specific parameters of different data sources above, and pay attention to distinguishing tags and edges.</p>"},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#general_parameters_1","title":"General parameters","text":"Parameter Type Default value Required Description <code>edges.name</code> string - Yes The edge type name defined in NebulaGraph. <code>edges.type.source</code> string - Yes The data source of edges. For example, <code>csv</code>. <code>edges.type.sink</code> string <code>client</code> Yes The method specified to import data. Optional values are <code>client</code> and <code>SST</code>. <code>edges.fields</code> list[string] - Yes The header or column name of the column corresponding to properties. If there is a header or column name, please use that name directly. If a CSV file does not have a header, use the form of <code>[_c0, _c1, _c2]</code> to represent the first column, the second column, the third column, and so on. <code>edges.nebula.fields</code> list[string] - Yes Edge names defined in NebulaGraph, the order of which must correspond to <code>edges.fields</code>. For example, <code>[_c2, _c3]</code> corresponds to <code>[start_year, end_year]</code>, which means that values in the third column are the values of the start year, and values in the fourth column are the values of the end year. <code>edges.source.field</code> string - Yes The column of source vertices of edges. For example, <code>_c0</code> indicates a value in the first column that is used as the source vertex of an edge. <code>edges.target.field</code> string - Yes The column of destination vertices of edges. For example, <code>_c0</code> indicates a value in the first column that is used as the destination vertex of an edge. <code>edges.ranking</code> int - No The column of rank values. If not specified, all rank values are <code>0</code> by default. <code>edges.batch</code> int <code>256</code> Yes The maximum number of edges written into NebulaGraph in a single batch. <code>edges.partition</code> int <code>32</code> Yes The number of Spark partitions."},{"location":"nebula-exchange/parameter-reference/ex-ug-parameter/#specific_parameters_of_nebulagraph_1","title":"Specific parameters of NebulaGraph","text":"Parameter Type Default value Required Description <code>edges.path</code> string <code>\"hdfs://namenode:9000/path/edge\"</code> Yes Specifies the storage path of the CSV file. You need to set a new path and Exchange will automatically create the path you set. If you store the data to the HDFS server, the path format is the same as the default value, such as <code>\"hdfs://192.168.8.177:9000/edge/follow\"</code>. If you store the data to the local, the path format is <code>\"file:///path/edge\"</code>, such as <code>\"file:///home/nebula/edge/follow\"</code>. If there are multiple Edges, different directories must be set for each Edge. <code>edges.noField</code> bool <code>false</code> Yes If the value is <code>true</code>, source vertex IDs, destination vertex IDs, and ranks will be exported, not the property data. If the vaue is <code>false</code>, ranks, source vertex IDs, destination vertex IDs, ranks, and the property data will be exported. <code>edges.return.fields</code> list <code>[]</code> Yes Specifies the properties to be exported. For example, to export <code>start_year</code> and <code>end_year</code>, you need to set the parameter value to <code>[\"start_year\",\"end_year\"]</code>. This parameter only takes effect when the value of <code>edges.noField</code> is <code>false</code>."},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/","title":"Export data from NebulaGraph","text":"<p>This topic uses an example to illustrate how to use Exchange to export data from NebulaGraph to a CSV file.</p> <p>Enterpriseonly</p> <p>Only Exchange Enterprise Edition supports exporting data from NebulaGraph to a CSV file.</p> <p>Note</p> <p>SSL encryption is not supported when exporting data from NebulaGraph.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/#preparation","title":"Preparation","text":"<p>This example is completed on a virtual machine equipped with Linux. The hardware and software you need to prepare before exporting data are as follows.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/#hardware","title":"Hardware","text":"Type Information CPU 4 Intel(R) Xeon(R) Platinum 8260 CPU @ 2.30GHz Memory 16G Hard disk 50G"},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/#system","title":"System","text":"<p>CentOS 7.9.2009</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/#software","title":"Software","text":"Name Version JDK 1.8.0 Hadoop 2.10.1 Scala 2.12.11 Spark 2.4.7 NebulaGraph 2.6.2"},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/#dataset","title":"Dataset","text":"<p>As the data source, NebulaGraph stores the basketballplayer dataset in this example, the Schema elements of which are shown as follows.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge type <code>follow</code> <code>degree int</code> Edge type <code>serve</code> <code>start_year int, end_year int</code>"},{"location":"nebula-exchange/use-exchange/ex-ug-export-from-nebula/#steps","title":"Steps","text":"<ol> <li> <p>Get the JAR file of Exchange Enterprise Edition from the NebulaGraph Enterprise Edition Package.</p> </li> <li> <p>Modify the configuration file.</p> <p>Exchange Enterprise Edition provides the configuration template <code>export_application.conf</code> for exporting NebulaGraph data. For details, see Exchange parameters. The core content of the configuration file used in this example is as follows:</p> <pre><code>...\n\n  # Processing tags\n  # There are tag config examples for different dataSources.\n  tags: [\n    # export NebulaGraph tag data to csv, only support export to CSV for now.\n    {\n      name: player\n      type: {\n        source: Nebula\n        sink: CSV\n      }\n      # the path to save the NebulaGrpah data, make sure the path doesn't exist.\n      path:\"hdfs://192.168.8.177:9000/vertex/player\"\n      # if no need to export any properties when export NebulaGraph tag data\n      # if noField is configured true, just export vertexId\n      noField:false\n      # define properties to export from NebulaGraph tag data\n      # if return.fields is configured as empty list, then export all properties\n      return.fields:[]\n      # nebula space partition number\n      partition:10\n    }\n\n...\n\n  ]\n\n  # Processing edges\n  # There are edge config examples for different dataSources.\n  edges: [\n    # export NebulaGraph tag data to csv, only support export to CSV for now.\n    {\n      name: follow\n      type: {\n        source: Nebula\n        sink: CSV\n      }\n      # the path to save the NebulaGrpah data, make sure the path doesn't exist.\n      path:\"hdfs://192.168.8.177:9000/edge/follow\"\n      # if no need to export any properties when export NebulaGraph edge data\n      # if noField is configured true, just export src,dst,rank\n      noField:false\n      # define properties to export from NebulaGraph edge data\n      # if return.fields is configured as empty list, then export all properties\n      return.fields:[]\n      # nebula space partition number\n      partition:10\n    }\n\n...\n\n  ]\n}\n</code></pre> </li> <li> <p>Export data from NebulaGraph with the following command.</p> <pre><code>&lt;spark_install_path&gt;/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange nebula-exchange-x.y.z.jar_path&gt; -c &lt;export_application.conf_path&gt;\n</code></pre> <p>The command used in this example is as follows.</p> <pre><code>$ ./spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange \\\n~/exchange-ent/nebula-exchange-ent-2.6.1.jar -c ~/exchange-ent/export_application.conf\n</code></pre> </li> <li> <p>Check the exported data.</p> <ol> <li> <p>Check whether the CSV file is successfully generated under the target path.</p> <pre><code>$ hadoop fs -ls /vertex/player\nFound 11 items\n-rw-r--r--   3 nebula supergroup          0 2021-11-05 07:36 /vertex/player/_SUCCESS\n-rw-r--r--   3 nebula supergroup        160 2021-11-05 07:36 /vertex/player/    part-00000-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        163 2021-11-05 07:36 /vertex/player/    part-00001-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        172 2021-11-05 07:36 /vertex/player/    part-00002-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        172 2021-11-05 07:36 /vertex/player/    part-00003-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        144 2021-11-05 07:36 /vertex/player/    part-00004-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        173 2021-11-05 07:36 /vertex/player/    part-00005-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        160 2021-11-05 07:36 /vertex/player/    part-00006-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        148 2021-11-05 07:36 /vertex/player/    part-00007-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        125 2021-11-05 07:36 /vertex/player/    part-00008-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n-rw-r--r--   3 nebula supergroup        119 2021-11-05 07:36 /vertex/player/    part-00009-17293020-ba2e-4243-b834-34495c0536b3-c000.csv\n</code></pre> </li> <li> <p>Check the contents of the CSV file to ensure that the data export is successful.</p> </li> </ol> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/","title":"Import data from ClickHouse","text":"<p>This topic provides an example of how to use Exchange to import data stored on ClickHouse into NebulaGraph.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>ClickHouse: docker deployment yandex/clickhouse-server tag: latest(2021.07.01)</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>The Hadoop service has been installed and started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#step_2_modify_configuration_files","title":"Step 2: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set ClickHouse data source configuration. In this example, the copied file is called <code>clickhouse_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n# NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      name: player\n      type: {\n        # Specify the data source file format to ClickHouse.\n        source: clickhouse\n        # Specify how to import the data of vertexes into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # JDBC URL of ClickHouse\n      url:\"jdbc:clickhouse://192.168.*.*:8123/basketballplayer\"\n\n      user:\"user\"\n      password:\"123456\"\n\n      # The number of ClickHouse partitions\n      numPartition:\"5\"\n\n      sentence:\"select * from player\"\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [name,age]\n      nebula.fields: [name,age]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      vertex: {\n        field:playerid\n        # policy:hash\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag Team.\n    {\n      name: team\n      type: {\n        source: clickhouse\n        sink: client\n      }\n      url:\"jdbc:clickhouse://192.168.*.*:8123/basketballplayer\"\n      user:\"user\"\n      password:\"123456\"\n      numPartition:\"5\"\n      sentence:\"select * from team\"\n      fields: [name]\n      nebula.fields: [name]\n      vertex: {\n        field:teamid\n      }\n      batch: 256\n      partition: 32\n    }\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type: {\n        # Specify the data source file format to ClickHouse.\n        source: clickhouse\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # JDBC URL of ClickHouse\n      url:\"jdbc:clickhouse://192.168.*.*:8123/basketballplayer\"\n\n      user:\"user\"\n      password:\"123456\"\n\n      # The number of ClickHouse partitions.\n      numPartition:\"5\"\n\n      sentence:\"select * from follow\"\n\n      # Specify the column names in the follow table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [degree]\n      nebula.fields: [degree]\n\n      # In source, use a column in the follow table as the source of the edge's source vertexes.\n      source: {\n        field:src_player\n      }\n\n      # In target, use a column in the follow table as the source of the edge's destination vertexes.\n      target: {\n        field:dst_player\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      name: serve\n      type: {\n        source: clickhouse\n        sink: client\n      }\n      url:\"jdbc:clickhouse://192.168.*.*:8123/basketballplayer\"\n      user:\"user\"\n      password:\"123456\"\n      numPartition:\"5\"\n      sentence:\"select * from serve\"\n      fields: [start_year,end_year]\n      nebula.fields: [start_year,end_year]\n      source: {\n        field:playerid\n      }\n      target: {\n        field:teamid\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      batch: 256\n      partition: 32\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#step_3_import_data_into_nebulagraph","title":"Step 3: Import data into NebulaGraph","text":"<p>Run the following command to import ClickHouse data into NebulaGraph. For descriptions of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;clickhouse_application.conf_path&gt;\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/clickhouse_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#step_4_optional_validate_data","title":"Step 4: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the SHOW STATS command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-clickhouse/#step_5_optional_rebuild_indexes_in_nebulagraph","title":"Step 5: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/","title":"Import data from CSV files","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in HDFS or local CSV files.</p> <p>To import a local CSV file to NebulaGraph, see Nebula Importer.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>If files are stored in HDFS, ensure that the Hadoop service is running normally.</li> </ul> <ul> <li>If files are stored locally and NebulaGraph is a cluster architecture, you need to place the files in the same directory locally on each machine in the cluster.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#step_2_process_csv_files","title":"Step 2: Process CSV files","text":"<p>Confirm the following information:</p> <ol> <li> <p>Process CSV files to meet Schema requirements.</p> <p>Note</p> <p>Exchange supports uploading CSV files with or without headers.</p> </li> <li> <p>Obtain the CSV file storage path.</p> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#step_3_modify_configuration_files","title":"Step 3: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set CSV data source configuration. In this example, the copied file is called <code>csv_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    executor: {\n        memory:1G\n    }\n\n    cores {\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example: \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example: \"file:///tmp/xx.csv\".\n      path: \"hdfs://192.168.*.*:9000/data/vertex_player.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has headers, use the actual column names.\n      fields: [_c1, _c2]\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [age, name]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      # The value of vertex must be the same as the column names in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:_c0\n        # policy:hash\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag Team.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: team\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example: \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example: \"file:///tmp/xx.csv\".\n      path: \"hdfs://192.168.*.*:9000/data/vertex_team.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has headers, use the actual column names.\n      fields: [_c1]\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      # The value of vertex must be the same as the column names in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:_c0\n        # policy:hash\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n\n    # If more vertexes need to be added, refer to the previous configuration to add them.\n  ]\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # Specify the Edge Type name defined in NebulaGraph.\n      name: follow\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example: \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example: \"file:///tmp/xx.csv\".\n      path: \"hdfs://192.168.*.*:9000/data/edge_follow.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has headers, use the actual column names.\n      fields: [_c2]\n\n      # Specify the column names in the edge table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [degree]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The value of vertex must be the same as the column names in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: _c0\n      }\n      target: {\n        field: _c1\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # Specify a column as the source of the rank (optional).\n\n      #ranking: rank\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      # Specify the Edge Type name defined in NebulaGraph.\n      name: serve\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example: \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example: \"file:///tmp/xx.csv\".\n      path: \"hdfs://192.168.*.*:9000/data/edge_serve.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has headers, use the actual column names.\n      fields: [_c2,_c3]\n\n      # Specify the column names in the edge table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [start_year, end_year]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The value of vertex must be the same as the column names in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: _c0\n      }\n      target: {\n        field: _c1\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # Specify a column as the source of the rank (optional).\n      #ranking: _c5\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n  ]\n    # If more edges need to be added, refer to the previous configuration to add them.\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#step_4_import_data_into_nebulagraph","title":"Step 4: Import data into NebulaGraph","text":"<p>Run the following command to import CSV data into NebulaGraph. For descriptions of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;csv_application.conf_path&gt; </code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/csv_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#step_5_optional_validate_data","title":"Step 5: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-csv/#step_6_optional_rebuild_indexes_in_nebulagraph","title":"Step 6: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/","title":"Import data from HBase","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in HBase.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p> <p>In this example, the data set has been stored in HBase. All vertexes and edges are stored in the <code>player</code>, <code>team</code>, <code>follow</code>, and <code>serve</code> tables. The following are some of the data for each table.</p> <pre><code>hbase(main):002:0&gt; scan \"player\"\nROW                                COLUMN+CELL\nplayer100                         column=cf:age, timestamp=1618881347530, value=42\nplayer100                         column=cf:name, timestamp=1618881354604, value=Tim Duncan\nplayer101                         column=cf:age, timestamp=1618881369124, value=36\nplayer101                         column=cf:name, timestamp=1618881379102, value=Tony Parker\nplayer102                         column=cf:age, timestamp=1618881386987, value=33\nplayer102                         column=cf:name, timestamp=1618881393370, value=LaMarcus Aldridge\nplayer103                         column=cf:age, timestamp=1618881402002, value=32\nplayer103                         column=cf:name, timestamp=1618881407882, value=Rudy Gay\n...\n\nhbase(main):003:0&gt; scan \"team\"\nROW                                COLUMN+CELL\nteam200                           column=cf:name, timestamp=1618881445563, value=Warriors\nteam201                           column=cf:name, timestamp=1618881453636, value=Nuggets\n...\n\nhbase(main):004:0&gt; scan \"follow\"\nROW                                COLUMN+CELL\nplayer100                         column=cf:degree, timestamp=1618881804853, value=95\nplayer100                         column=cf:dst_player, timestamp=1618881791522, value=player101\nplayer101                         column=cf:degree, timestamp=1618881824685, value=90\nplayer101                         column=cf:dst_player, timestamp=1618881816042, value=player102\n...\n\nhbase(main):005:0&gt; scan \"serve\"\nROW                                COLUMN+CELL\nplayer100                         column=cf:end_year, timestamp=1618881899333, value=2016\nplayer100                         column=cf:start_year, timestamp=1618881890117, value=1997\nplayer100                         column=cf:teamid, timestamp=1618881875739, value=team204\n...\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>HBase: 2.2.7</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>The Hadoop service has been installed and started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#step_2_modify_configuration_files","title":"Step 2: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set HBase data source configuration. In this example, the copied file is called <code>hbase_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertexes\n  tags: [\n    # Set information about Tag player.\n    # If you want to set RowKey as the data source, enter rowkey and the actual column name of the column family.\n    {\n      # The Tag name in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to HBase.\n        source: hbase\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n      host:192.168.*.*\n      port:2181\n      table:\"player\"\n      columnFamily:\"cf\"\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [age,name]\n      nebula.fields: [age,name]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      # For example, if rowkey is the source of the VID, enter rowkey.\n      vertex:{\n          field:rowkey\n      }\n\n\n      # Number of pieces of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # Number of Spark partitions\n      partition: 32\n    }\n    # Set Tag Team information.\n    {\n      name: team\n      type: {\n        source: hbase\n        sink: client\n      }\n      host:192.168.*.*\n      port:2181\n      table:\"team\"\n      columnFamily:\"cf\"\n      fields: [name]\n      nebula.fields: [name]\n      vertex:{\n          field:rowkey\n      }\n      batch: 256\n      partition: 32\n    }\n\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type: {\n        # Specify the data source file format to HBase.\n        source: hbase\n\n        # Specify how to import the Edge type data into NebulaGraph.\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      host:192.168.*.*\n      port:2181\n      table:\"follow\"\n      columnFamily:\"cf\"\n\n      # Specify the column names in the follow table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [degree]\n      nebula.fields: [degree]\n\n      # In source, use a column in the follow table as the source of the edge's source vertex.\n      # In target, use a column in the follow table as the source of the edge's destination vertex.\n      source:{\n          field:rowkey\n      }\n\n\n      target:{\n          field:dst_player\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      name: serve\n      type: {\n        source: hbase\n        sink: client\n      }\n      host:192.168.*.*\n      port:2181\n      table:\"serve\"\n      columnFamily:\"cf\"\n\n      fields: [start_year,end_year]\n      nebula.fields: [start_year,end_year]\n      source:{\n          field:rowkey\n      }\n\n      target:{\n          field:teamid\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      batch: 256\n      partition: 32\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#step_3_import_data_into_nebulagraph","title":"Step 3: Import data into NebulaGraph","text":"<p>Run the following command to import HBase data into NebulaGraph. For descriptions of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;hbase_application.conf_path&gt;\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/hbase_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#step_4_optional_validate_data","title":"Step 4: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the SHOW STATS command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hbase/#step_5_optional_rebuild_indexes_in_nebulagraph","title":"Step 5: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/","title":"Import data from Hive","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in Hive.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p> <p>In this example, the data set has been stored in Hive. All vertexes and edges are stored in the <code>player</code>, <code>team</code>, <code>follow</code>, and <code>serve</code> tables. The following are some of the data for each table.</p> <pre><code>scala&gt; spark.sql(\"describe basketball.player\").show\n+--------+---------+-------+\n|col_name|data_type|comment|\n+--------+---------+-------+\n|playerid|   string|   null|\n|     age|   bigint|   null|\n|    name|   string|   null|\n+--------+---------+-------+\n\nscala&gt; spark.sql(\"describe basketball.team\").show\n+----------+---------+-------+\n|  col_name|data_type|comment|\n+----------+---------+-------+\n|    teamid|   string|   null|\n|      name|   string|   null|\n+----------+---------+-------+\n\nscala&gt; spark.sql(\"describe basketball.follow\").show\n+----------+---------+-------+\n|  col_name|data_type|comment|\n+----------+---------+-------+\n|src_player|   string|   null|\n|dst_player|   string|   null|\n|    degree|   bigint|   null|\n+----------+---------+-------+\n\nscala&gt; spark.sql(\"describe basketball.serve\").show\n+----------+---------+-------+\n|  col_name|data_type|comment|\n+----------+---------+-------+\n|  playerid|   string|   null|\n|    teamid|   string|   null|\n|start_year|   bigint|   null|\n|  end_year|   bigint|   null|\n+----------+---------+-------+\n</code></pre> <p>Note</p> <p>The Hive data type <code>bigint</code> corresponds to the NebulaGraph <code>int</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>Hive: 2.3.7, Hive Metastore database is MySQL 8.0.22</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>Hadoop has been installed and started, and the Hive Metastore database (MySQL in this example) has been started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#step_2_use_spark_sql_to_confirm_hive_sql_statements","title":"Step 2: Use Spark SQL to confirm Hive SQL statements","text":"<p>After the Spark-shell environment is started, run the following statements to ensure that Spark can read data in Hive.</p> <pre><code>scala&gt; sql(\"select playerid, age, name from basketball.player\").show\nscala&gt; sql(\"select teamid, name from basketball.team\").show\nscala&gt; sql(\"select src_player, dst_player, degree from basketball.follow\").show\nscala&gt; sql(\"select playerid, teamid, start_year, end_year from basketball.serve\").show\n</code></pre> <p>The following is the result read from the table <code>basketball.player</code>.</p> <pre><code>+---------+----+-----------------+\n| playerid| age|             name|\n+---------+----+-----------------+\n|player100|  42|       Tim Duncan|\n|player101|  36|      Tony Parker|\n|player102|  33|LaMarcus Aldridge|\n|player103|  32|         Rudy Gay|\n|player104|  32|  Marco Belinelli|\n+---------+----+-----------------+\n...\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#step_3_modify_configuration_file","title":"Step 3: Modify configuration file","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set Hive data source configuration. In this example, the copied file is called <code>hive_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n  # If Spark and Hive are deployed in different clusters, you need to configure the parameters for connecting to Hive. Otherwise, skip these configurations.\n  #hive: {\n  #  waredir: \"hdfs://NAMENODE_IP:9000/apps/svr/hive-xxx/warehouse/\"\n  #  connectionURL: \"jdbc:mysql://your_ip:3306/hive_spark?characterEncoding=UTF-8\"\n  #  connectionDriverName: \"com.mysql.jdbc.Driver\"\n  #  connectionUserName: \"user\"\n  #  connectionPassword: \"password\"\n  #}\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # The Tag name in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to Hive.\n        source: hive\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Set the SQL statement to read the data of player table in basketball database.\n      exec: \"select playerid, age, name from basketball.player\"\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [age,name]\n      nebula.fields: [age,name]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      vertex:{\n        field:playerid\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n    # Set the information about the Tag Team.\n    {\n      name: team\n      type: {\n        source: hive\n        sink: client\n      }\n      exec: \"select teamid, name from basketball.team\"\n      fields: [name]\n      nebula.fields: [name]\n      vertex: {\n        field: teamid\n      }\n      batch: 256\n      partition: 32\n    }\n\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type: {\n        # Specify the data source file format to Hive.\n        source: hive\n\n        # Specify how to import the Edge type data into NebulaGraph.\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Set the SQL statement to read the data of follow table in the basketball database.\n      exec: \"select src_player, dst_player, degree from basketball.follow\"\n\n      # Specify the column names in the follow table in Fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [degree]\n      nebula.fields: [degree]\n\n      # In source, use a column in the follow table as the source of the edge's starting vertex.\n      # In target, use a column in the follow table as the source of the edge's destination vertex.\n      source: {\n        field: src_player\n      }\n\n      target: {\n        field: dst_player\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      name: serve\n      type: {\n        source: hive\n        sink: client\n      }\n      exec: \"select playerid, teamid, start_year, end_year from basketball.serve\"\n      fields: [start_year,end_year]\n      nebula.fields: [start_year,end_year]\n      source: {\n        field: playerid\n      }\n      target: {\n        field: teamid\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      batch: 256\n      partition: 32\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#step_4_import_data_into_nebulagraph","title":"Step 4: Import data into NebulaGraph","text":"<p>Run the following command to import Hive data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;hive_application.conf_path&gt; -h\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/hive_application.conf -h\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#step_5_optional_validate_data","title":"Step 5: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the SHOW STATS command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-hive/#step_6_optional_rebuild_indexes_in_nebulagraph","title":"Step 6: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/","title":"Import data from JSON files","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in HDFS or local JSON files.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example. Some sample data are as follows:</p> <ul> <li> <p>player</p> <pre><code>{\"id\":\"player100\",\"age\":42,\"name\":\"Tim Duncan\"}\n{\"id\":\"player101\",\"age\":36,\"name\":\"Tony Parker\"}\n{\"id\":\"player102\",\"age\":33,\"name\":\"LaMarcus Aldridge\"}\n{\"id\":\"player103\",\"age\":32,\"name\":\"Rudy Gay\"}\n...\n</code></pre> </li> </ul> <ul> <li> <p>team</p> <pre><code>{\"id\":\"team200\",\"name\":\"Warriors\"}\n{\"id\":\"team201\",\"name\":\"Nuggets\"}\n...\n</code></pre> </li> </ul> <ul> <li> <p>follow</p> <pre><code>{\"src\":\"player100\",\"dst\":\"player101\",\"degree\":95}\n{\"src\":\"player101\",\"dst\":\"player102\",\"degree\":90}\n...\n</code></pre> </li> </ul> <ul> <li> <p>serve</p> <pre><code>{\"src\":\"player100\",\"dst\":\"team204\",\"start_year\":\"1997\",\"end_year\":\"2016\"}\n{\"src\":\"player101\",\"dst\":\"team204\",\"start_year\":\"1999\",\"end_year\":\"2018\"}\n...\n</code></pre> </li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>If files are stored in HDFS, ensure that the Hadoop service is running properly.</li> </ul> <ul> <li>If files are stored locally and NebulaGraph is a cluster architecture, you need to place the files in the same directory locally on each machine in the cluster.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#step_2_process_json_files","title":"Step 2: Process JSON files","text":"<p>Confirm the following information:</p> <ol> <li> <p>Process JSON files to meet Schema requirements.</p> </li> <li> <p>Obtain the JSON file storage path.</p> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#step_3_modify_configuration_files","title":"Step 3: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set JSON data source configuration. In this example, the copied file is called <code>json_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    executor: {\n        memory:1G\n    }\n\n    cores {\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to JSON.\n        source: json\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the JSON file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.json\".\n      path: \"hdfs://192.168.*.*:9000/data/vertex_player.json\"\n\n      # Specify the key name in the JSON file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [age,name]\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [age, name]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      # The value of vertex must be the same as that in the JSON file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:id\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag Team.\n{\n      # Specify the Tag name defined in NebulaGraph.\n      name: team\n      type: {\n        # Specify the data source file format to JSON.\n        source: json\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the JSON file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.json\".\n      path: \"hdfs://192.168.*.*:9000/data/vertex_team.json\"\n\n      # Specify the key name in the JSON file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [name]\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [name]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      # The value of vertex must be the same as that in the JSON file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:id\n      }\n\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n\n    # If more vertexes need to be added, refer to the previous configuration to add them.\n  ]\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # Specify the Edge Type name defined in NebulaGraph.\n      name: follow\n      type: {\n        # Specify the data source file format to JSON.\n        source: json\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the JSON file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.json\".\n      path: \"hdfs://192.168.*.*:9000/data/edge_follow.json\"\n\n      # Specify the key name in the JSON file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [degree]\n\n      # Specify the column names in the edge table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [degree]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The value of vertex must be the same as that in the JSON file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      # Specify the Edge type name defined in NebulaGraph.\n      name: serve\n      type: {\n        # Specify the data source file format to JSON.\n        source: json\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the JSON file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.json\".\n      path: \"hdfs://192.168.*.*:9000/data/edge_serve.json\"\n\n      # Specify the key name in the JSON file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [start_year,end_year]\n\n      # Specify the column names in the edge table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [start_year, end_year]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The value of vertex must be the same as that in the JSON file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: _c5\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n  ]\n  # If more edges need to be added, refer to the previous configuration to add them.\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#step_4_import_data_into_nebulagraph","title":"Step 4: Import data into NebulaGraph","text":"<p>Run the following command to import JSON data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;json_application.conf_path&gt; </code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-echange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/json_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#step_5_optional_validate_data","title":"Step 5: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-json/#step_6_optional_rebuild_indexes_in_nebulagraph","title":"Step 6: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/","title":"Import data from Kafka","text":"<p>This topic provides a simple guide to importing Data stored on Kafka into NebulaGraph using Exchange.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>The Kafka service has been installed and started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#step_2_modify_configuration_files","title":"Step 2: Modify configuration files","text":"<p>Note</p> <p>If some data is stored in Kafka's value field, you need to modify the source code, get the value from Kafka, parse the value through the from_JSON function, and return it as a Dataframe.</p> <p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set Kafka data source configuration. In this example, the copied file is called <code>kafka_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n\n      # The corresponding Tag name in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to Kafka.\n        source: kafka\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n      # Kafka server address.\n      service: \"127.0.0.1:9092\"\n      # Message category.\n      topic: \"topic_name1\"\n\n      # Kafka data has a fixed domain name: key, value, topic, partition, offset, timestamp, timestampType.\n      # If multiple fields need to be specified after Spark reads as DataFrame, separate them with commas.\n      # Specify the field name in fields. For example, use key for name in Nebula and value for age in Nebula, as shown in the following.\n      fields: [key,value]\n      nebula.fields: [name,age]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      # The key is the same as the value above, indicating that key is used as both VID and property name.\n      vertex:{\n          field:key\n      }\n\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 10\n\n      # The number of Spark partitions.\n      partition: 10\n      # The interval for message reading. Unit: second.\n      interval.seconds: 10\n    }\n    # Set the information about the Tag Team.\n    {\n      name: team\n      type: {\n        source: kafka\n        sink: client\n      }\n      service: \"127.0.0.1:9092\"\n      topic: \"topic_name2\"\n      fields: [key]\n      nebula.fields: [name]\n      vertex:{\n          field:key\n      }\n      batch: 10\n      partition: 10\n      interval.seconds: 10\n    }\n\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type: {\n        # Specify the data source file format to Kafka.\n        source: kafka\n\n        # Specify how to import the Edge type data into NebulaGraph.\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Kafka server address.\n      service: \"127.0.0.1:9092\"\n      # Message category.\n      topic: \"topic_name3\"\n\n      # Kafka data has a fixed domain name: key, value, topic, partition, offset, timestamp, timestampType.\n      # If multiple fields need to be specified after Spark reads as DataFrame, separate them with commas.\n      # Specify the field name in fields. For example, use key for degree in Nebula, as shown in the following.\n      fields: [key]\n      nebula.fields: [degree]\n\n      # In source, use a column in the topic as the source of the edge's source vertex.\n      # In target, use a column in the topic as the source of the edge's destination vertex.\n      source:{\n          field:timestamp\n      }\n\n\n      target:{\n          field:offset\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 10\n\n      # The number of Spark partitions.\n      partition: 10\n\n      # The interval for message reading. Unit: second.\n      interval.seconds: 10\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      name: serve\n      type: {\n        source: kafka\n        sink: client\n      }\n      service: \"127.0.0.1:9092\"\n      topic: \"topic_name4\"\n\n      fields: [timestamp,offset]\n      nebula.fields: [start_year,end_year]\n      source:{\n          field:key\n      }\n\n      target:{\n          field:value\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      batch: 10\n      partition: 10\n      interval.seconds: 10\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#step_3_import_data_into_nebulagraph","title":"Step 3: Import data into NebulaGraph","text":"<p>Run the following command to import Kafka data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;kafka_application.conf_path&gt;\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/kafka_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#step_4_optional_validate_data","title":"Step 4: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the SHOW STATS command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-kafka/#step_5_optional_rebuild_indexes_in_nebulagraph","title":"Step 5: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/","title":"Import data from MaxCompute","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in MaxCompute.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>MaxCompute: Alibaba Cloud official version</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>The Hadoop service has been installed and started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#step_2_modify_configuration_files","title":"Step 2: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set MaxCompute data source configuration. In this example, the copied file is called <code>maxcompute_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      name: player\n      type: {\n        # Specify the data source file format to MaxCompute.\n        source: maxcompute\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Table name of MaxCompute.\n      table:player\n\n      # Project name of MaxCompute.\n      project:project\n\n      # OdpsUrl and tunnelUrl for the MaxCompute service.\n      # The address is https://help.aliyun.com/document_detail/34951.html.\n      odpsUrl:\"http://service.cn-hangzhou.maxcompute.aliyun.com/api\"\n      tunnelUrl:\"http://dt.cn-hangzhou.maxcompute.aliyun.com\"\n\n      # AccessKeyId and accessKeySecret of the MaxCompute service.\n      accessKeyId:xxx\n      accessKeySecret:xxx\n\n      # Partition description of the MaxCompute table. This configuration is optional.\n      partitionSpec:\"dt='partition1'\"\n\n      # Ensure that the table name in the SQL statement is the same as the value of the table above. This configuration is optional.\n      sentence:\"select id, name, age, playerid from player where id &lt; 10\"\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields:[name, age]\n      nebula.fields:[name, age]\n\n      # Specify a column of data in the table as the source of vertex VID in the NebulaGraph.\n      vertex:{\n        field: playerid\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag Team.\n    {\n      name: team\n      type: {\n        source: maxcompute\n        sink: client\n      }\n      table:team\n      project:project\n      odpsUrl:\"http://service.cn-hangzhou.maxcompute.aliyun.com/api\"\n      tunnelUrl:\"http://dt.cn-hangzhou.maxcompute.aliyun.com\"\n      accessKeyId:xxx\n      accessKeySecret:xxx\n      partitionSpec:\"dt='partition1'\"\n      sentence:\"select id, name, teamid from team where id &lt; 10\"\n      fields:[name]\n      nebula.fields:[name]\n      vertex:{\n        field: teamid\n      }\n      batch: 256\n      partition: 32\n    }\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type:{\n        # Specify the data source file format to MaxCompute.\n        source:maxcompute\n\n        # Specify how to import the Edge type data into NebulaGraph.\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink:client\n      }\n\n      # Table name of MaxCompute.\n      table:follow\n\n      # Project name of MaxCompute.\n      project:project\n\n      # OdpsUrl and tunnelUrl for MaxCompute service.\n      # The address is https://help.aliyun.com/document_detail/34951.html.\n      odpsUrl:\"http://service.cn-hangzhou.maxcompute.aliyun.com/api\"\n      tunnelUrl:\"http://dt.cn-hangzhou.maxcompute.aliyun.com\"\n\n      # AccessKeyId and accessKeySecret of the MaxCompute service.\n      accessKeyId:xxx\n      accessKeySecret:xxx\n\n      # Partition description of the MaxCompute table. This configuration is optional.\n      partitionSpec:\"dt='partition1'\"\n\n      # Ensure that the table name in the SQL statement is the same as the value of the table above. This configuration is optional.\n      sentence:\"select * from follow\"\n\n      # Specify the column names in the follow table in Fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields:[degree]\n      nebula.fields:[degree]\n\n      # In source, use a column in the follow table as the source of the edge's source vertex.\n      source:{\n        field: src_player\n      }\n\n      # In target, use a column in the follow table as the source of the edge's destination vertex.\n      target:{\n        field: dst_player\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of Spark partitions.\n      partition:10\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch:10\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      name: serve\n      type:{\n        source:maxcompute\n        sink:client\n      }\n      table:serve\n      project:project\n      odpsUrl:\"http://service.cn-hangzhou.maxcompute.aliyun.com/api\"\n      tunnelUrl:\"http://dt.cn-hangzhou.maxcompute.aliyun.com\"\n      accessKeyId:xxx\n      accessKeySecret:xxx\n      partitionSpec:\"dt='partition1'\"\n      sentence:\"select * from serve\"\n      fields:[start_year,end_year]\n      nebula.fields:[start_year,end_year]\n      source:{\n        field: playerid\n      }\n      target:{\n        field: teamid\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      partition:10\n      batch:10\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#step_3_import_data_into_nebulagraph","title":"Step 3: Import data into NebulaGraph","text":"<p>Run the following command to import MaxCompute data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;maxcompute_application.conf_path&gt;\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/maxcompute_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#step_4_optional_validate_data","title":"Step 4: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-maxcompute/#step_5_optional_rebuild_indexes_in_nebulagraph","title":"Step 5: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/","title":"Import data from MySQL","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in MySQL.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p> <p>In this example, the data set has been stored in MySQL. All vertexes and edges are stored in the <code>player</code>, <code>team</code>, <code>follow</code>, and <code>serve</code> tables. The following are some of the data for each table.</p> <pre><code>mysql&gt; desc player;\n+----------+-------------+------+-----+---------+-------+\n| Field    | Type        | Null | Key | Default | Extra |\n+----------+-------------+------+-----+---------+-------+\n| playerid | varchar(30) | YES  |     | NULL    |       |\n| age      | int         | YES  |     | NULL    |       |\n| name     | varchar(30) | YES  |     | NULL    |       |\n+----------+-------------+------+-----+---------+-------+\n\nmysql&gt; desc team;\n+--------+-------------+------+-----+---------+-------+\n| Field  | Type        | Null | Key | Default | Extra |\n+--------+-------------+------+-----+---------+-------+\n| teamid | varchar(30) | YES  |     | NULL    |       |\n| name   | varchar(30) | YES  |     | NULL    |       |\n+--------+-------------+------+-----+---------+-------+\n\nmysql&gt; desc follow;\n+------------+-------------+------+-----+---------+-------+\n| Field      | Type        | Null | Key | Default | Extra |\n+------------+-------------+------+-----+---------+-------+\n| src_player | varchar(30) | YES  |     | NULL    |       |\n| dst_player | varchar(30) | YES  |     | NULL    |       |\n| degree     | int         | YES  |     | NULL    |       |\n+------------+-------------+------+-----+---------+-------+\n\nmysql&gt; desc serve;\n+------------+-------------+------+-----+---------+-------+\n| Field      | Type        | Null | Key | Default | Extra |\n+------------+-------------+------+-----+---------+-------+\n| playerid   | varchar(30) | YES  |     | NULL    |       |\n| teamid     | varchar(30) | YES  |     | NULL    |       |\n| start_year | int         | YES  |     | NULL    |       |\n| end_year   | int         | YES  |     | NULL    |       |\n+------------+-------------+------+-----+---------+-------+\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>MySQL: 8.0.23</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>The Hadoop service has been installed and started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#step_2_modify_configuration_files","title":"Step 2: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set MySQL data source configuration. In this case, the copied file is called <code>mysql_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # The Tag name in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to MySQL.\n        source: mysql\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      host:192.168.*.*\n      port:3306\n      database:\"basketball\"\n      table:\"player\"\n      user:\"test\"\n      password:\"123456\"\n      sentence:\"select playerid, age, name from basketball.player order by playerid;\"\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [age,name]\n      nebula.fields: [age,name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      vertex: {\n        field:playerid\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n    # Set the information about the Tag Team.\n    {\n      name: team\n      type: {\n        source: mysql\n        sink: client\n      }\n\n      host:192.168.*.*\n      port:3306\n      database:\"basketball\"\n      table:\"team\"\n      user:\"test\"\n      password:\"123456\"\n      sentence:\"select teamid, name from basketball.team order by teamid;\"\n\n      fields: [name]\n      nebula.fields: [name]\n      vertex: {\n        field: teamid\n      }\n      batch: 256\n      partition: 32\n    }\n\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type: {\n        # Specify the data source file format to MySQL.\n        source: mysql\n\n        # Specify how to import the Edge type data into NebulaGraph.\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      host:192.168.*.*\n      port:3306\n      database:\"basketball\"\n      table:\"follow\"\n      user:\"test\"\n      password:\"123456\"\n      sentence:\"select src_player,dst_player,degree from basketball.follow order by src_player;\"\n\n      # Specify the column names in the follow table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [degree]\n      nebula.fields: [degree]\n\n      # In source, use a column in the follow table as the source of the edge's source vertex.\n      # In target, use a column in the follow table as the source of the edge's destination vertex.\n      source: {\n        field: src_player\n      }\n\n      target: {\n        field: dst_player\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      name: serve\n      type: {\n        source: mysql\n        sink: client\n      }\n\n      host:192.168.*.*\n      port:3306\n      database:\"basketball\"\n      table:\"serve\"\n      user:\"test\"\n      password:\"123456\"\n      sentence:\"select playerid,teamid,start_year,end_year from basketball.serve order by playerid;\"\n      fields: [start_year,end_year]\n      nebula.fields: [start_year,end_year]\n      source: {\n        field: playerid\n      }\n      target: {\n        field: teamid\n      }\n      batch: 256\n      partition: 32\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#step_3_import_data_into_nebulagraph","title":"Step 3: Import data into NebulaGraph","text":"<p>Run the following command to import MySQL data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;mysql_application.conf_path&gt;\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/mysql_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#step_4_optional_validate_data","title":"Step 4: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the SHOW STATS command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-mysql/#step_5_optional_rebuild_indexes_in_nebulagraph","title":"Step 5: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/","title":"Import data from Neo4j","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in Neo4j.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#implementation_method","title":"Implementation method","text":"<p>Exchange uses Neo4j Driver 4.0.1 to read Neo4j data. Before batch export, you need to write Cypher statements that are automatically executed based on labels and relationship types and the number of Spark partitions in the configuration file to improve data export performance.</p> <p>When Exchange reads Neo4j data, it needs to do the following:</p> <ol> <li> <p>The Reader in Exchange replaces the statement following the Cypher <code>RETURN</code> statement in the <code>exec</code> part of the configuration file with <code>COUNT(*)</code>, and executes this statement to get the total amount of data, then calculates the starting offset and size of each partition based on the number of Spark partitions.</p> </li> <li> <p>(Optional) If the user has configured the <code>check_point_path</code> directory, Reader reads the files in the directory. In the transferring state, Reader calculates the offset and size that each Spark partition should have.</p> </li> <li> <p>In each Spark partition, the Reader in Exchange adds different <code>SKIP</code> and <code>LIMIT</code> statements to the Cypher statement and calls the Neo4j Driver for parallel execution to distribute data to different Spark partitions.</p> </li> <li> <p>The Reader finally processes the returned data into a DataFrame.</p> </li> </ol> <p>At this point, Exchange has finished exporting the Neo4j data. The data is then written in parallel to the NebulaGraph database.</p> <p>The whole process is illustrated below.</p> <p></p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li> <p>Hardware specifications:</p> <ul> <li>CPU\uff1aIntel(R) Xeon(R) CPU E5-2697 v3 @ 2.60GHz</li> </ul> <ul> <li>CPU cores: 14</li> </ul> <ul> <li>Memory: 251 GB</li> </ul> </li> </ul> <ul> <li>Spark: Stand-alone, 2.4.6 pre-build for Hadoop 2.7</li> </ul> <ul> <li>Neo4j: 3.5.20 Community Edition</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with NebulaGraph write permission.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#step_2_configuring_source_data","title":"Step 2: Configuring source data","text":"<p>To speed up the export of Neo4j data, create indexes for the corresponding properties in the Neo4j database. For more information, refer to the Neo4j manual.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#step_3_modify_configuration_files","title":"Step 3: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set Neo4j data source configuration. In this example, the copied file is called <code>neo4j_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n\n    executor: {\n        memory:1G\n    }\n\n    cores:{\n      max: 16\n    }\n  }\n\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    user: root\n    pswd: nebula\n    space: basketballplayer\n\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n\n    execution {\n      retry: 3\n    }\n\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n\n  # Processing vertexes\n  tags: [\n\n\n    # Set the information about the Tag player\n    {\n      name: player\n      type: {\n        source: neo4j\n        sink: client\n      }\n      server: \"bolt://192.168.*.*:7687\"\n      user: neo4j\n      password:neo4j\n      database:neo4j\n      exec: \"match (n:player) return n.id as id, n.age as age, n.name as name\"\n      fields: [age,name]\n      nebula.fields: [age,name]\n      vertex: {\n        field:id\n      }\n      partition: 10\n      batch: 1000\n      check_point_path: /tmp/test\n   }\n  # Set the information about the Tag Team\n  {\n      name: team\n      type: {\n        source: neo4j\n        sink: client\n      }\n      server: \"bolt://192.168.*.*:7687\"\n      user: neo4j\n      password:neo4j\n      database:neo4j\n      exec: \"match (n:team) return n.id as id,n.name as name\"\n      fields: [name]\n      nebula.fields: [name]\n      vertex: {\n        field:id\n      }\n      partition: 10\n      batch: 1000\n      check_point_path: /tmp/test\n   }\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow\n    {\n      name: follow\n      type: {\n        source: neo4j\n        sink: client\n      }\n      server: \"bolt://192.168.*.*:7687\"\n      user: neo4j\n      password:neo4j\n      database:neo4j\n      exec: \"match (a:player)-[r:follow]-&gt;(b:player) return a.id as src, b.id as dst, r.degree as degree  order by id(r)\"\n      fields: [degree]\n      nebula.fields: [degree]\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n      #ranking: rank\n      partition: 10\n      batch: 1000\n      check_point_path: /tmp/test\n    }\n   # Set the information about the Edge Type serve\n   {\n      name: serve\n      type: {\n        source: neo4j\n        sink: client\n      }\n      server: \"bolt://192.168.*.*:7687\"\n      user: neo4j\n      password:neo4j\n      database:neo4j\n      exec: \"match (a:player)-[r:serve]-&gt;(b:team) return a.id as src, b.id as dst, r.start_year as start_year, r.end_year as end_year  order by id(r)\"\n      fields: [start_year,end_year]\n      nebula.fields: [start_year,end_year]\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n      #ranking: rank\n      partition: 10\n      batch: 1000\n      check_point_path: /tmp/test\n    }\n   ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#exec_configuration","title":"Exec configuration","text":"<p>When configuring either the <code>tags.exec</code> or <code>edges.exec</code> parameters, you need to fill in the Cypher query. To prevent loss of data during import, it is strongly recommended to include <code>ORDER BY</code> clause in Cypher queries. Meanwhile, in order to improve data import efficiency, it is better to select indexed properties for ordering. If there is no index, users can also observe the default order and select the appropriate properties for ordering to improve efficiency. If the pattern of the default order cannot be found, users can order them by the ID of the vertex or relationship and set the <code>partition</code> to a small value to reduce the ordering pressure of Neo4j.</p> <p>Note</p> <p>Using the <code>ORDER BY</code> clause lengthens the data import time.</p> <p>Exchange needs to execute different <code>SKIP</code> and <code>LIMIT</code> Cypher statements on different Spark partitions, so <code>SKIP</code> and <code>LIMIT</code> clauses cannot be included in the Cypher statements corresponding to <code>tags.exec</code> and <code>edges.exec</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#tagsvertex_or_edgesvertex_configuration","title":"tags.vertex or edges.vertex configuration","text":"<p>NebulaGraph uses ID as the unique primary key when creating vertexes and edges, overwriting the data in that primary key if it already exists. So, if a Neo4j property value is given as the NebulaGraph'S ID and the value is duplicated in Neo4j, duplicate IDs will be generated. One and only one of their corresponding data will be stored in the NebulaGraph, and the others will be overwritten. Because the data import process is concurrently writing data to NebulaGraph, the final saved data is not guaranteed to be the latest data in Neo4j.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#check_point_path_configuration","title":"check_point_path configuration","text":"<p>If breakpoint transfers are enabled, to avoid data loss, the state of the database should not change between the breakpoint and the transfer. For example, data cannot be added or deleted, and the <code>partition</code> quantity configuration should not be changed.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#step_4_import_data_into_nebulagraph","title":"Step 4: Import data into NebulaGraph","text":"<p>Run the following command to import Neo4j data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;neo4j_application.conf_path&gt; </code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/neo4j_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#step_5_optional_validate_data","title":"Step 5: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-neo4j/#step_6_optional_rebuild_indexes_in_nebulagraph","title":"Step 6: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/","title":"Import data from ORC files","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in HDFS or local ORC files.</p> <p>To import a local ORC file to NebulaGraph, see Nebula Importer.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>If files are stored in HDFS, ensure that the Hadoop service is running properly.</li> </ul> <ul> <li>If files are stored locally and NebulaGraph is a cluster architecture, you need to place the files in the same directory locally on each machine in the cluster.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#step_2_process_orc_files","title":"Step 2: Process ORC files","text":"<p>Confirm the following information:</p> <ol> <li> <p>Process ORC files to meet Schema requirements.</p> </li> <li> <p>Obtain the ORC file storage path.</p> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#step_3_modify_configuration_files","title":"Step 3: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set ORC data source configuration. In this example, the copied file is called <code>orc_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    executor: {\n        memory:1G\n    }\n\n    cores {\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      name: player\n      type: {\n        # Specify the data source file format to ORC.\n        source: orc\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the ORC file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.orc\".\n      path: \"hdfs://192.168.*.*:9000/data/vertex_player.orc\"\n\n      # Specify the key name in the ORC file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [age,name]\n\n      # Specify the property names defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [age, name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      # The value of vertex must be consistent with the field in the ORC file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:id\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag team.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: team\n      type: {\n        # Specify the data source file format to ORC.\n        source: orc\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the ORC file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.orc\".\n      path: \"hdfs://192.168.*.*:9000/data/vertex_team.orc\"\n\n      # Specify the key name in the ORC file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [name]\n\n      # Specify the property names defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      # The value of vertex must be consistent with the field in the ORC file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:id\n      }\n\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n\n\n    # If more vertexes need to be added, refer to the previous configuration to add them.\n  ]\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # Specify the Edge Type name defined in NebulaGraph.\n      name: follow\n      type: {\n        # Specify the data source file format to ORC.\n        source: orc\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the ORC file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.orc\".\n      path: \"hdfs://192.168.*.*:9000/data/edge_follow.orc\"\n\n      # Specify the key name in the ORC file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [degree]\n\n      # Specify the property names defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [degree]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The value of vertex must be consistent with the field in the ORC file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge type serve.\n    {\n      # Specify the Edge type name defined in NebulaGraph.\n      name: serve\n      type: {\n        # Specify the data source file format to ORC.\n        source: orc\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the ORC file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.orc\".\n      path: \"hdfs://192.168.*.*:9000/data/edge_serve.orc\"\n\n      # Specify the key name in the ORC file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [start_year,end_year]\n\n      # Specify the property names defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [start_year, end_year]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The value of vertex must be consistent with the field in the ORC file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: _c5\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n  # If more edges need to be added, refer to the previous configuration to add them.\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#step_4_import_data_into_nebulagraph","title":"Step 4: Import data into NebulaGraph","text":"<p>Run the following command to import ORC data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;orc_application.conf_path&gt; </code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/orc_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#step_5_optional_validate_data","title":"Step 5: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-orc/#step_6_optional_rebuild_indexes_in_nebulagraph","title":"Step 6: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/","title":"Import data from Parquet files","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in HDFS or local Parquet files.</p> <p>To import a local Parquet file to NebulaGraph, see Nebula Importer.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>If files are stored in HDFS, ensure that the Hadoop service is running properly.</li> </ul> <ul> <li>If files are stored locally and NebulaGraph is a cluster architecture, you need to place the files in the same directory locally on each machine in the cluster.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space.\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer.\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player.\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team.\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow.\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve.\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#step_2_process_parquet_files","title":"Step 2: Process Parquet files","text":"<p>Confirm the following information:</p> <ol> <li> <p>Process Parquet files to meet Schema requirements.</p> </li> <li> <p>Obtain the Parquet file storage path.</p> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#step_3_modify_configuration_files","title":"Step 3: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set Parquet data source configuration. In this example, the copied file is called <code>parquet_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    executor: {\n        memory:1G\n    }\n\n    cores {\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n\n  # Processing vertexes\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to Parquet.\n        source: parquet\n\n        # Specifies how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the Parquet file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.parquet\".\n      path: \"hdfs://192.168.*.13:9000/data/vertex_player.parquet\"\n\n      # Specify the key name in the Parquet file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [age,name]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [age, name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      # The value of vertex must be consistent with the field in the Parquet file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:id\n      }\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag team.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: team\n      type: {\n        # Specify the data source file format to Parquet.\n        source: parquet\n\n        # Specifies how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the Parquet file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.parquet\".\n      path: \"hdfs://192.168.11.13:9000/data/vertex_team.parquet\"\n\n      # Specify the key name in the Parquet file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [name]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      # The value of vertex must be consistent with the field in the Parquet file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:id\n      }\n\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n\n    # If more vertexes need to be added, refer to the previous configuration to add them.\n  ]\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # Specify the Edge Type name defined in NebulaGraph.\n      name: follow\n      type: {\n        # Specify the data source file format to Parquet.\n        source: parquet\n\n        # Specifies how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the Parquet file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.parquet\".\n      path: \"hdfs://192.168.11.13:9000/data/edge_follow.parquet\"\n\n      # Specify the key name in the Parquet file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [degree]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [degree]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The values of vertex must be consistent with the fields in the Parquet file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge type serve.\n    {\n      # Specify the Edge type name defined in NebulaGraph.\n      name: serve\n      type: {\n        # Specify the data source file format to Parquet.\n        source: parquet\n\n        # Specifies how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # Specify the path to the Parquet file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx\".\n      # If the file is stored locally, use double quotation marks to enclose the file path, starting with file://. For example, \"file:///tmp/xx.parquet\".\n      path: \"hdfs://192.168.11.13:9000/data/edge_serve.parquet\"\n\n      # Specify the key name in the Parquet file in fields, and its corresponding value will serve as the data source for the properties specified in the NebulaGraph.\n      # If multiple values need to be specified, separate them with commas.\n      fields: [start_year,end_year]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [start_year, end_year]\n\n      # Specify a column as the source for the source and destination vertexes.\n      # The values of vertex must be consistent with the fields in the Parquet file.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: src\n      }\n      target: {\n        field: dst\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: _c5\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n  ]\n  # If more edges need to be added, refer to the previous configuration to add them.\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#step_4_import_data_into_nebulagraph","title":"Step 4: Import data into NebulaGraph","text":"<p>Run the following command to import Parquet data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;parquet_application.conf_path&gt; </code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/parquet_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#step_5_optional_validate_data","title":"Step 5: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-parquet/#step_6_optional_rebuild_indexes_in_nebulagraph","title":"Step 6: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/","title":"Import data from Pulsar","text":"<p>This topic provides an example of how to use Exchange to import NebulaGraph data stored in Pulsar.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>NebulaGraph: 2.6.2. Deploy NebulaGraph with Docker Compose.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>Learn about the Schema created in NebulaGraph, including names and properties of Tags and Edge types, and more.</li> </ul> <ul> <li>The Pulsar service has been installed and started.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#step_2_modify_configuration_files","title":"Step 2: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set Pulsar data source configuration. In this example, the copied file is called <code>pulsar_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.6.1\n    }\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n    cores {\n      max: 16\n    }\n  }\n\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      # Specify the IP addresses and ports for Graph and all Meta services.\n      # If there are multiple addresses, the format is \"ip1:port\",\"ip2:port\",\"ip3:port\".\n      # Addresses are separated by commas.\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n\n    # The account entered must have write permission for the NebulaGraph space.\n    user: root\n    pswd: nebula\n\n    # Fill in the name of the graph space you want to write data to in the NebulaGraph.\n    space: basketballplayer\n    connection {\n      timeout: 3000\n      retry: 3\n    }\n    execution {\n      retry: 3\n    }\n    error: {\n      max: 32\n      output: /tmp/errors\n    }\n    rate: {\n      limit: 1024\n      timeout: 1000\n    }\n  }\n  # Processing vertices\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # The corresponding Tag name in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to Pulsar.\n        source: pulsar\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n      # The address of the Pulsar server.\n      service: \"pulsar://127.0.0.1:6650\"\n      # admin.url of pulsar.\n      admin: \"http://127.0.0.1:8081\"\n      # The Pulsar option can be configured from topic, topics or topicsPattern.\n      options: {\n        topics: \"topic1,topic2\"\n      }\n\n      # Specify the column names in the player table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [age,name]\n      nebula.fields: [age,name]\n\n      # Specify a column of data in the table as the source of VIDs in the NebulaGraph.\n      vertex:{\n          field:playerid\n      }\n\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 10\n\n      # The number of Spark partitions.\n      partition: 10\n      # The interval for message reading. Unit: second.\n      interval.seconds: 10\n    }\n    # Set the information about the Tag Team.\n    {\n      name: team\n      type: {\n        source: pulsar\n        sink: client\n      }\n      service: \"pulsar://127.0.0.1:6650\"\n      admin: \"http://127.0.0.1:8081\"\n      options: {\n        topics: \"topic1,topic2\"\n      }\n      fields: [name]\n      nebula.fields: [name]\n      vertex:{\n          field:teamid\n      }\n      batch: 10\n      partition: 10\n      interval.seconds: 10\n    }\n\n  ]\n\n  # Processing edges\n  edges: [\n    # Set the information about Edge Type follow\n    {\n      # The corresponding Edge Type name in NebulaGraph.\n      name: follow\n\n      type: {\n        # Specify the data source file format to Pulsar.\n        source: pulsar\n\n        # Specify how to import the Edge type data into NebulaGraph.\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: client\n      }\n\n      # The address of the Pulsar server.\n      service: \"pulsar://127.0.0.1:6650\"\n      # admin.url of pulsar.\n      admin: \"http://127.0.0.1:8081\"\n      # The Pulsar option can be configured from topic, topics or topicsPattern.\n      options: {\n        topics: \"topic1,topic2\"\n      }\n\n      # Specify the column names in the follow table in fields, and their corresponding values are specified as properties in the NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      # If multiple column names need to be specified, separate them by commas.\n      fields: [degree]\n      nebula.fields: [degree]\n\n      # In source, use a column in the follow table as the source of the edge's source vertex.\n      # In target, use a column in the follow table as the source of the edge's destination vertex.\n      source:{\n          field:src_player\n      }\n\n      target:{\n          field:dst_player\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 10\n\n      # The number of Spark partitions.\n      partition: 10\n\n      # The interval for message reading. Unit: second.\n      interval.seconds: 10\n    }\n\n    # Set the information about the Edge Type serve\n    {\n      name: serve\n      type: {\n        source: Pulsar\n        sink: client\n      }\n      service: \"pulsar://127.0.0.1:6650\"\n      admin: \"http://127.0.0.1:8081\"\n      options: {\n        topics: \"topic1,topic2\"\n      }\n\n      fields: [start_year,end_year]\n      nebula.fields: [start_year,end_year]\n      source:{\n          field:playerid\n      }\n\n      target:{\n          field:teamid\n      }\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: rank\n\n      batch: 10\n      partition: 10\n      interval.seconds: 10\n    }\n  ]\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#step_3_import_data_into_nebulagraph","title":"Step 3: Import data into NebulaGraph","text":"<p>Run the following command to import Pulsar data into NebulaGraph. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;pulsar_application.conf_path&gt;\n</code></pre> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/pulsar_application.conf\n</code></pre> <p>You can search for <code>batchSuccess.&lt;tag_name/edge_name&gt;</code> in the command output to check the number of successes. For example, <code>batchSuccess.follow: 300</code>.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#step_4_optional_validate_data","title":"Step 4: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-pulsar/#step_5_optional_rebuild_indexes_in_nebulagraph","title":"Step 5: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/","title":"Import data from SST files","text":"<p>This topic provides an example of how to generate the data from the data source into an SST (Sorted String Table) file and save it on HDFS, and then import it into NebulaGraph. The sample data source is a CSV file.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#precautions","title":"Precautions","text":"<ul> <li>The SST file can be imported only in Linux.</li> </ul> <ul> <li>The default value of the property is not supported.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#background_information","title":"Background information","text":"<p>Exchange supports two data import modes:</p> <ul> <li>Import the data from the data source directly into NebulaGraph as nGQL statements.</li> </ul> <ul> <li>Generate the SST file from the data source, and use Console to import the SST file into NebulaGraph.</li> </ul> <p>The following describes the scenarios, implementation methods, prerequisites, and steps for generating an SST file and importing data.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#scenarios","title":"Scenarios","text":"<ul> <li> <p>Suitable for online services, because the generation almost does not affect services (just reads the Schema), and the import speed is fast.</p> <p>Caution</p> <p>Although the import speed is fast, write operations in the corresponding space are blocked during the import period (about 10 seconds). Therefore, you are advised to import data in off-peak hours.</p> </li> </ul> <ul> <li>Suitable for scenarios with a large amount of data from data sources for its fast import speed.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#implementation_methods","title":"Implementation methods","text":"<p>The underlying code in NebulaGraph uses RocksDB as the key-value storage engine. RocksDB is a storage engine based on the hard disk, providing a series of APIs for creating and importing SST files to help quickly import massive data.</p> <p>The SST file is an internal file containing an arbitrarily long set of ordered key-value pairs for efficient storage of large amounts of key-value data. The entire process of generating SST files is mainly done by Exchange Reader, sstProcessor, and sstWriter. The whole data processing steps are as follows:</p> <ol> <li> <p>Reader reads data from the data source.</p> </li> <li> <p>sstProcessor generates the SST file from the NebulaGraph's Schema information and uploads it to the HDFS. For details about the format of the SST file, see Data Storage Format.</p> </li> <li> <p>sstWriter opens a file and inserts data. When generating SST files, keys must be written in sequence.</p> </li> <li> <p>After the SST file is generated, RocksDB imports the SST file into NebulaGraph using the <code>IngestExternalFile()</code> method. For example:</p> <pre><code>IngestExternalFileOptions ifo;\n# Import two SST files\nStatus s = db_-&gt;IngestExternalFile({\"/home/usr/file1.sst\", \"/home/usr/file2.sst\"}, ifo);\nif (!s.ok()) {\n  printf(\"Error while adding file %s and %s, Error %s\\n\",\n         file_path1.c_str(), file_path2.c_str(), s.ToString().c_str());\n  return 1;\n}\n</code></pre> <p>When the <code>IngestExternalFile()</code> method is called, RocksDB copies the file to the data directory by default and blocks the RocksDB write operation. If the key range in the SST file overwrites the Memtable key range, flush the Memtable to the hard disk. After placing the SST file in an optimal location in the LSM tree, assign a global serial number to the file and turn on the write operation.</p> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#data_set","title":"Data set","text":"<p>This topic takes the basketballplayer dataset as an example.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#environment","title":"Environment","text":"<p>This example is done on MacOS. Here is the environment configuration information:</p> <ul> <li>Hardware specifications:<ul> <li>CPU: 1.7 GHz Quad-Core Intel Core i7</li> <li>Memory: 16 GB</li> </ul> </li> </ul> <ul> <li>Spark: 2.4.7, stand-alone</li> </ul> <ul> <li>Hadoop: 2.9.2, pseudo-distributed deployment</li> </ul> <ul> <li>NebulaGraph: 2.6.2.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#prerequisites","title":"Prerequisites","text":"<p>Before importing data, you need to confirm the following information:</p> <ul> <li> <p>NebulaGraph has been installed and deployed with the following information:</p> <ul> <li>IP addresses and ports of Graph and Meta services.</li> </ul> <ul> <li>The user name and password with write permission to NebulaGraph.</li> </ul> <ul> <li><code>--ws_storage_http_port</code> in the Meta service configuration file is the same as <code>--ws_http_port</code> in the Storage service configuration file. For example, <code>19779</code>.</li> </ul> <ul> <li><code>--ws_meta_http_port</code> in the Graph service configuration file is the same as <code>--ws_http_port</code> in the Meta service configuration file. For example, <code>19559</code>.</li> </ul> <ul> <li>The information about the Schema, including names and properties of Tags and Edge types, and more.</li> </ul> </li> </ul> <ul> <li>Exchange has been compiled, or download the compiled <code>.jar</code> file directly.</li> </ul> <ul> <li>Spark has been installed.</li> </ul> <ul> <li>JDK 1.8 or the later version has been installed and the environment variable <code>JAVA_HOME</code> has been configured.</li> </ul> <ul> <li> <p>The Hadoop service has been installed and started.</p> <p>Note</p> <ul> <li>To generate SST files of other data sources, see documents of the corresponding data source and check the prerequisites.</li> </ul> <ul> <li>To generate SST files only, users do not need to install the Hadoop service on the machine where the Storage service is deployed.</li> </ul> <ul> <li>To delete the SST file after the ingest (data import) operation, add the configuration <code>-- move_Files =true</code> to the Storage Service configuration file.</li> </ul> </li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#steps","title":"Steps","text":""},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_1_create_the_schema_in_nebulagraph","title":"Step 1: Create the Schema in NebulaGraph","text":"<p>Analyze the data to create a Schema in NebulaGraph by following these steps:</p> <ol> <li> <p>Identify the Schema elements. The Schema elements in the NebulaGraph are shown in the following table.</p> Element Name Property Tag <code>player</code> <code>name string, age int</code> Tag <code>team</code> <code>name string</code> Edge Type <code>follow</code> <code>degree int</code> Edge Type <code>serve</code> <code>start_year int, end_year int</code> </li> <li> <p>Create a graph space basketballplayer in the NebulaGraph and create a Schema as shown below.</p> <pre><code>## Create a graph space\nnebula&gt; CREATE SPACE basketballplayer \\\n        (partition_num = 10, \\\n        replica_factor = 1, \\\n        vid_type = FIXED_STRING(30));\n\n## Use the graph space basketballplayer\nnebula&gt; USE basketballplayer;\n\n## Create the Tag player\nnebula&gt; CREATE TAG player(name string, age int);\n\n## Create the Tag team\nnebula&gt; CREATE TAG team(name string);\n\n## Create the Edge type follow\nnebula&gt; CREATE EDGE follow(degree int);\n\n## Create the Edge type serve\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>For more information, see Quick start workflow.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_2_process_csv_files","title":"Step 2: Process CSV files","text":"<p>Confirm the following information:</p> <ol> <li> <p>Process CSV files to meet Schema requirements.</p> <p>Note</p> <p>Exchange supports uploading CSV files with or without headers.</p> </li> <li> <p>Obtain the CSV file storage path.</p> </li> </ol>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_3_modify_configuration_files","title":"Step 3: Modify configuration files","text":"<p>After Exchange is compiled, copy the conf file <code>target/classes/application.conf</code> to set SST data source configuration. In this example, the copied file is called <code>sst_application.conf</code>. For details on each configuration item, see Parameters in the configuration file.</p> <pre><code>{\n  # Spark configuration\n  spark: {\n    app: {\n      name: Nebula Exchange 2.0\n    }\n\n    master:local\n\n    driver: {\n      cores: 1\n      maxResultSize: 1G\n    }\n\n    executor: {\n        memory:1G\n    }\n\n    cores:{\n      max: 16\n    }\n  }\n\n  # NebulaGraph configuration\n  nebula: {\n    address:{\n      graph:[\"127.0.0.1:9669\"]\n      meta:[\"127.0.0.1:9559\"]\n    }\n    user: root\n    pswd: nebula\n    space: basketballplayer\n\n    # SST file configuration\n    path:{\n        # The local directory that temporarily stores generated SST files\n        local:\"/tmp\"\n\n        # The path for storing the SST file in the HDFS\n        remote:\"/sst\"\n\n        # The NameNode address of HDFS\n        hdfs.namenode: \"hdfs://*.*.*.*:9000\"\n    }\n\n    # The connection parameters of clients\n    connection {\n      # The timeout duration of socket connection and execution. Unit: milliseconds.\n      timeout: 30000\n    }\n\n    error: {\n      # The maximum number of failures that will exit the application.\n      max: 32\n      # Failed import jobs are logged in the output path.\n      output: /tmp/errors\n    }\n\n    # Use Google's RateLimiter to limit requests to NebulaGraph.\n    rate: {\n      # Steady throughput of RateLimiter.\n      limit: 1024\n\n      # Get the allowed timeout duration from RateLimiter. Unit: milliseconds.\n      timeout: 1000\n    }\n  }\n\n\n  # Processing vertices\n  tags: [\n    # Set the information about the Tag player.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: player\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: sst\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx.csv\".\n      path: \"hdfs://*.*.*.*:9000/dataset/vertex_player.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has a header, use the actual column name.\n      fields: [_c1, _c2]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [age, name]\n\n      # Specify a column of data in the table as the source of VIDs in NebulaGraph.\n      # The value of vertex must be consistent with the column name in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:_c0\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Tag Team.\n    {\n      # Specify the Tag name defined in NebulaGraph.\n      name: team\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: sst\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx.csv\".\n      path: \"hdfs://*.*.*.*:9000/dataset/vertex_team.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has a header, use the actual column name.\n      fields: [_c1]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [name]\n\n      # Specify a column of data in the table as the source of VIDs in NebulaGraph.\n      # The value of vertex must be consistent with the column name in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      vertex: {\n        field:_c0\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n\n\n    # If more vertices need to be added, refer to the previous configuration to add them.\n  ]\n  # Processing edges\n  edges: [\n    # Set the information about the Edge Type follow.\n    {\n      # The Edge Type name defined in NebulaGraph.\n      name: follow\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: sst\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx.csv\".\n      path: \"hdfs://*.*.*.*:9000/dataset/edge_follow.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has a header, use the actual column name.\n      fields: [_c2]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [degree]\n\n      # Specify a column as the source for the source and destination vertices.\n      # The value of vertex must be consistent with the column name in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: _c0\n      }\n      target: {\n        field: _c1\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # (Optional) Specify a column as the source of the rank.\n\n      #ranking: rank\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n    # Set the information about the Edge Type serve.\n    {\n      # Specify the Edge type name defined in NebulaGraph.\n      name: serve\n      type: {\n        # Specify the data source file format to CSV.\n        source: csv\n\n        # Specify how to import the data into NebulaGraph: Client or SST.\n        sink: sst\n      }\n\n      # Specify the path to the CSV file.\n      # If the file is stored in HDFS, use double quotation marks to enclose the file path, starting with hdfs://. For example, \"hdfs://ip:port/xx/xx.csv\".\n      path: \"hdfs://*.*.*.*:9000/dataset/edge_serve.csv\"\n\n      # If the CSV file does not have a header, use [_c0, _c1, _c2, ..., _cn] to represent its header and indicate the columns as the source of the property values.\n      # If the CSV file has a header, use the actual column name.\n      fields: [_c2,_c3]\n\n      # Specify the property name defined in NebulaGraph.\n      # The sequence of fields and nebula.fields must correspond to each other.\n      nebula.fields: [start_year, end_year]\n\n      # Specify a column as the source for the source and destination vertices.\n      # The value of vertex must be consistent with the column name in the above fields or csv.fields.\n      # Currently, NebulaGraph 2.6.2 supports only strings or integers of VID.\n      source: {\n        field: _c0\n      }\n      target: {\n        field: _c1\n      }\n\n      # The delimiter specified. The default value is comma.\n      separator: \",\"\n\n      # (Optional) Specify a column as the source of the rank.\n      #ranking: _c5\n\n      # If the CSV file has a header, set the header to true.\n      # If the CSV file does not have a header, set the header to false. The default value is false.\n      header: false\n\n      # The number of data written to NebulaGraph in a single batch.\n      batch: 256\n\n      # The number of Spark partitions.\n      partition: 32\n    }\n\n  ]\n  # If more edges need to be added, refer to the previous configuration to add them.\n}\n</code></pre>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_4_generate_the_sst_file","title":"Step 4: Generate the SST file","text":"<p>Run the following command to generate the SST file from the CSV source file. For a description of the parameters, see Options for import.</p> <pre><code>${SPARK_HOME}/bin/spark-submit --master \"local\" --conf spark.sql.shuffle.partition=&lt;shuffle_concurrency&gt; --class com.vesoft.nebula.exchange.Exchange &lt;nebula-exchange-2.6.1.jar_path&gt; -c &lt;sst_application.conf_path&gt; </code></pre> <p>Note</p> <p>When generating SST files, the shuffle operation of Spark will be involved. Note that the configuration of <code>spark.sql.shuffle.partition</code> should be added when you submit the command.</p> <p>Note</p> <p>JAR packages are available in two ways: compiled them yourself, or download the compiled <code>.jar</code> file directly.</p> <p>For example:</p> <pre><code>${SPARK_HOME}/bin/spark-submit  --master \"local\" --conf spark.sql.shuffle.partition=200 --class com.vesoft.nebula.exchange.Exchange  /root/nebula-exchange/nebula-exchange/target/nebula-exchange-2.6.1.jar  -c /root/nebula-exchange/nebula-exchange/target/classes/sst_application.conf\n</code></pre> <p>After the task is complete, you can view the generated SST file in the <code>/sst</code> directory (specified by the <code>nebula.path.remote</code> parameter) on HDFS.</p> <p>Note</p> <p>If you modify the Schema, such as rebuilding the graph space, modifying the Tag, or modifying the Edge type, you need to regenerate the SST file because the SST file verifies the space ID, Tag ID, and Edge ID.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_5_import_the_sst_file","title":"Step 5: Import the SST file","text":"<p>Note</p> <p>Confirm the following information before importing:</p> <ul> <li>Confirm that the Hadoop service has been deployed on all the machines where the Storage service is deployed, and configure <code>HADOOP_HOME</code> and <code>JAVA_HOME</code>.</li> </ul> <ul> <li>The <code>--ws_storage_http_port</code> in the Meta service configuration file (add it manually if it does not exist) is the same as the <code>--ws_http_port</code> in the Storage service configuration file. For example, both are <code>19779</code>.</li> </ul> <ul> <li>The <code>--ws_meta_http_port</code> in the Graph service configuration file (add it manually if it does not exist) is the same as the <code>--ws_http_port</code> in the Meta service configuration file. For example, both are <code>19559</code>.</li> </ul> <p>Connect to the NebulaGraph database using the client tool and import the SST file as follows:</p> <ol> <li> <p>Run the following command to select the graph space you created earlier.</p> <pre><code>nebula&gt; USE basketballplayer;\n</code></pre> </li> <li> <p>Run the following command to download the SST file:</p> <pre><code>nebula&gt; DOWNLOAD HDFS \"hdfs://&lt;hadoop_address&gt;:&lt;hadoop_port&gt;/&lt;sst_file_path&gt;\";\n</code></pre> <p>For example:</p> <pre><code>nebula&gt; DOWNLOAD HDFS \"hdfs://*.*.*.*:9000/sst\";\n</code></pre> </li> <li> <p>Run the following command to import the SST file:</p> <pre><code>nebula&gt; INGEST;\n</code></pre> </li> </ol> <p>Note</p> <ul> <li>To download the SST file again, delete the <code>download</code> folder in the space ID in the <code>data/storage/nebula</code> directory in the NebulaGraph installation path, and then download the SST file again. If the space has multiple copies, the <code>download</code> folder needs to be deleted on all machines where the copies are saved.</li> </ul> <ul> <li>If there is a problem with the import and re-importing is required, re-execute <code>INGEST;</code>.</li> </ul>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_6_optional_validate_data","title":"Step 6: (optional) Validate data","text":"<p>Users can verify that data has been imported by executing a query in the NebulaGraph client (for example, NebulaGraph Studio). For example:</p> <pre><code>GO FROM \"player100\" OVER follow;\n</code></pre> <p>Users can also run the <code>SHOW STATS</code> command to view statistics.</p>"},{"location":"nebula-exchange/use-exchange/ex-ug-import-from-sst/#step_7_optional_rebuild_indexes_in_nebulagraph","title":"Step 7: (optional) Rebuild indexes in NebulaGraph","text":"<p>With the data imported, users can recreate and rebuild indexes in NebulaGraph. For details, see Index overview.</p>"},{"location":"nebula-explorer/about-explorer/ex-ug-what-is-explorer/","title":"What is Nebula Explorer","text":"<p>Nebula Explorer (Explorer in short) is a browser-based visualization tool. It is used with the NebulaGraph core to visualize interaction with graph data. Even if there is no experience in graph database, you can quickly become a graph exploration expert.</p> <p></p> <p>Enterpriseonly</p> <p>Explorer is only available in the enterprise version.</p> <p>Note</p> <p>You can also try some functions online in Explorer.</p>"},{"location":"nebula-explorer/about-explorer/ex-ug-what-is-explorer/#scenarios","title":"Scenarios","text":"<p>You can use Explorer in one of these scenarios:</p> <ul> <li>You need to quickly find neighbor relationships from complex relationships, analyze suspicious targets, and display graph data in a visual manner.</li> <li>For large-scale data sets, the data needs to be filtered, analyzed, and explored in a visual manner.</li> </ul>"},{"location":"nebula-explorer/about-explorer/ex-ug-what-is-explorer/#features","title":"Features","text":"<p>Explorer has these features:</p> <ul> <li>Easy to use and user-friendly: Explorer can be deployed in simple steps. And use simple visual interaction, no need to conceive nGQL sentences, easy to realize graph exploration.</li> </ul> <ul> <li>Flexible: Explorer supports querying data through VID, Tag, Subgraph.</li> </ul> <ul> <li>Multiple operations: Explorer supports operations such as expanding operations on multiple vertexes, querying the common neighbors of multiple vertexes, and querying the path between the start vertex and the end vertex.</li> </ul> <ul> <li>Various display: Explorer supports modifying the color and icon of the vertex in the canvas to highlight key nodes. You can also freely choose the data display mode in <code>dagre</code>, <code>force</code>, and <code>circular</code>.</li> </ul>"},{"location":"nebula-explorer/about-explorer/ex-ug-what-is-explorer/#authentication","title":"Authentication","text":"<p>Authentication is not enabled in NebulaGraph by default. Users can log into Studio with the <code>root</code> account and any password.</p> <p>When NebulaGraph enables authentication, users can only sign into Studio with the specified account. For more information, see Authentication.</p>"},{"location":"nebula-explorer/deploy-connect/ex-ug-connect/","title":"Connect to NebulaGraph","text":"<p>After successfully launching Explorer, you need to configure to connect to NebulaGraph. This topic describes how Explorer connects to the NebulaGraph database.</p>"},{"location":"nebula-explorer/deploy-connect/ex-ug-connect/#prerequisites","title":"Prerequisites","text":"<p>Before connecting to the NebulaGraph database, you need to confirm the following information:</p> <ul> <li>The NebulaGraph services and Explorer are started. For more information, see Deploy Explorer.</li> </ul> <ul> <li>You have the local IP address and the port used by the Graph service of NebulaGraph. The default port is <code>9669</code>.</li> </ul> <ul> <li> <p>You have a NebulaGraph account and its password.</p> <p>Note</p> <p>If authentication is enabled in NebulaGraph and different role-based accounts are created, you must use the assigned account to connect to NebulaGraph. If authentication is disabled, you can use the <code>root</code> and any password to connect to NebulaGraph. For more information, see NebulaGraph Database Manual.</p> </li> </ul>"},{"location":"nebula-explorer/deploy-connect/ex-ug-connect/#procedure","title":"Procedure","text":"<p>To connect Explorer to NebulaGraph, follow these steps:</p> <ol> <li> <p>On the Config Server page of Explorer, configure these fields:</p> <ul> <li> <p>Host: Enter the IP address and the port of the Graph service of NebulaGraph. The valid format is <code>IP:port</code>. The default port is <code>9669</code>.  </p> <p>Note</p> <p>When NebulaGraph and Explorer are deployed on the same machine, you must enter the IP address of the machine, but not <code>127.0.0.1</code> or <code>localhost</code>, in the Host field.</p> </li> </ul> <ul> <li> <p>Username and Password: Fill in the log in account according to the authentication settings of NebulaGraph.</p> <ul> <li>If authentication is not enabled, you can use <code>root</code> and any password as the username and its password.</li> </ul> <ul> <li>If authentication is enabled and no account information has been created, you can only log in as GOD role and use <code>root</code> and <code>nebula</code> as the username and its password.</li> </ul> <ul> <li>If authentication is enabled and different users are created and assigned roles, users in different roles log in with their accounts and passwords.</li> </ul> </li> </ul> <p></p> </li> <li> <p>After the configuration, click the Login button.</p> <p>If you can see the interface as shown in the below, it means you have successfully connected to the NebulaGraph database.</p> <p></p> </li> </ol> <p>One session continues for up to 30 minutes. If you do not operate Explorer within 30 minutes, the active session will time out and you must connect to NebulaGraph again.</p>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/","title":"Deploy Explorer","text":"<p>This topic describes how to deploy Explorer locally by RPM and tar packages.</p>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#nebulagraph_version","title":"NebulaGraph version","text":"<p>Note</p> <p>Explorer is released separately, not synchronized with NebulaGraph. And the version naming of Explorer is different from that of NebulaGraph. The version correspondence between NebulaGraph and Explorer is as follows.</p> NebulaGraph version Explorer version 2.5.x 2.0.0 2.6.x 2.1.0"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#rpm-based_explorer","title":"RPM-based Explorer","text":""},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#prerequisites","title":"Prerequisites","text":"<p>Before you deploy Explorer, you must do a check of these:</p> <ul> <li>The NebulaGraph services are deployed and started. For more information, see NebulaGraph Database Manual.</li> </ul> <ul> <li> <p>Before the installation starts, the following ports are not occupied.</p> Port Description 7002 Web service provided by Explorer <p>Caution</p> <p>By default, Explorer uses the port <code>7002</code>. You can modify the <code>httpport</code> in the <code>conf/app.conf</code> file in the installation directory and restart the service.</p> </li> </ul> <ul> <li>The Linux distribution is CentOS.</li> <li>GO of version above 1.13 is installed.</li> </ul>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#install","title":"Install","text":"<ol> <li> <p>Select and download the RPM package according to your needs. It is recommended to select the latest version. Common links are as follows:</p> <p>Enterpriseonly</p> <p>Explorer is only available in the enterprise version. Click Pricing to see more.</p> </li> <li> <p>Use <code>sudo rpm -i &lt;rpm&gt;</code> to install RPM package.</p> <p>For example, use the following command to install Explorer. The default installation path is <code>/usr/local/nebula-explorer</code>.</p> <pre><code>$ sudo rpm -i nebula-explorer-&lt;version&gt;.x86_64.rpm\n</code></pre> <p>You can also install it to the specified path using the following command:  <pre><code>$ sudo rpm -i nebula-explorer-xxx.rpm --prefix=&lt;path&gt; </code></pre></p> </li> <li> <p>Copy the license to the installation path.</p> <pre><code>$ cp -r &lt;license&gt; &lt;explorer_path&gt;\n</code></pre> <p>For example:  <pre><code>$ cp -r nebula.license /usr/local/nebula-explorer\n</code></pre></p> <p>Enterpriseonly</p> <p>License is only available in the Enterprise Edition. For more information, send email to inquiry@vesoft.com.</p> </li> <li> <p>After adding the license, you need to stop and restart the service using the following command.</p> <pre><code>$ systemctl stop nebula-explorer #Stop the service\n$ systemctl start nebula-explorer #Start the service\n</code></pre> </li> </ol>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#start_and_stop","title":"Start and stop","text":"<p>You can use SystemCTL to start and stop the service.</p> <pre><code>$ systemctl status nebula-explorer #Check the status\n$ systemctl stop nebula-explorer #Stop the service\n$ systemctl start nebula-explorer #Start the service\n</code></pre> <p>You can also start or stop the service manually using the following command in the installation directory.</p> <pre><code>$ cd ./scripts/rpm\n$ bash ./start.sh #Start the service\n$ bash ./stop.sh #Stop the service\n</code></pre>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#uninstall","title":"Uninstall","text":"<p>You can uninstall Explorer using the following command:</p> <pre><code>$ sudo rpm -e nebula-graph-explorer-&lt;version&gt;.x86_64\n</code></pre>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#tar-based_explorer","title":"tar-based Explorer","text":""},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#prerequisites_1","title":"Prerequisites","text":"<p>Before deploying Explorer, you must check the following information:</p> <ul> <li>The NebulaGraph services are deployed and started. For more information, see NebulaGraph Database Manual.</li> </ul> <ul> <li> <p>Before the installation starts, the following ports are not occupied.</p> Port Description 7002 Web service provided by Explorer <p>Caution</p> <p>By default, Explorer uses the port <code>7002</code>. You can modify the <code>httpport</code> in the <code>conf/app.conf</code> file in the installation directory and restart the service.</p> </li> </ul> <ul> <li>The Linux distribution is CentOS.</li> <li>GO of version above 1.13 is installed.</li> </ul>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#install_and_deploy","title":"Install and deploy","text":"<ol> <li> <p>Select and download the tar package according to your needs. It is recommended to select the latest version. Common links are as follows:</p> <p>Enterpriseonly</p> <p>Explorer is only available in the Enterprise Edition. Click Pricing to see more.</p> </li> <li> <p>Use <code>tar -xvf</code> to decompress the tar package.</p> <pre><code>$ tar -xvf nebula-graph-explorer-&lt;version&gt;.tar.gz\n</code></pre> </li> <li> <p>Copy the license to the <code>nebula-explorer</code> directory.</p> <pre><code>$ cp -r &lt;license&gt; &lt;explorer_path&gt;\n</code></pre> <p>For example:  <pre><code>$ cp -r nebula.license /usr/local/nebula-explorer\n</code></pre></p> <p>Enterpriseonly</p> <p>License is only available in the Enterprise Edition. For more information, send email to inquiry@vesoft.com.</p> </li> <li> <p>Enter the <code>nebula-explorer</code> folder to start Explorer.</p> <pre><code>$ cd nebula-explorer\n$ ./nebula-httpd &amp;\n</code></pre> </li> </ol>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#stop_service","title":"Stop Service","text":"<p>You can use <code>kill pid</code> to stop the service.</p> <pre><code>$ kill $(lsof -t -i :7002)\n</code></pre>"},{"location":"nebula-explorer/deploy-connect/ex-ug-deploy/#next_to_do","title":"Next to do","text":"<p>When Explorer is started, use <code>http://&lt;ip_address&gt;:7002</code> to get access to Explorer.</p> <p>Seeing the following login interface, Explorer is successfully connected to NebulaGraph.</p> <p></p> <p>After entering the Explorer login interface, you need to connect to NebulaGraph. For more information, refer to Connecting to the NebulaGraph.</p>"},{"location":"nebula-explorer/deploy-connect/ex-ug-reset-connection/","title":"Clear connection","text":"<p>When Explorer is still connected to a NebulaGraph database, in the toolbar, select Settings  &gt; clear connect, as shown in the below:</p> <p></p> <p>After that, if the configuration database page is displayed on the browser, it means that Explorer has successfully disconnected from the NebulaGraph.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/","title":"Canvas operation","text":"<p>This topic describes operation in canvas.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/#display_vertexes_and_edges","title":"Display vertexes and edges","text":"<p>Move the mouse to the vertex or edge to view in detail. The following shows the detailed information of the vertex with <code>VID 107</code>:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/#batch_selection","title":"Batch selection","text":"<p>Explorer supports batch selection and views the data of multiple vertexes and edges. The detailed data can be opened and viewed in the vertexes and edges overview at the lower-left corner of the canvas. It also supports exporting CSV files of selected vertexes or edges.</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/#frame_selection","title":"Frame selection","text":"<p>After clicking the  icon, hold down the left button to drag and select multiple vertexes and edges. Examples are as follows:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/#click_to_select_multiple_vertexes_and_edges","title":"Click to select multiple vertexes and edges","text":"<p>Click the  icon or hold down Shift, click and select multiple vertexes and edges with the mouse, and click the blank space to cancel the selection. Examples are as follows:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/#quick_operation","title":"Quick operation","text":"<p>You can select one or more vertexes and edges, and right-click in the blank area to expand the vertexes, search the path between two vertexes, and show or hide their property on the canvas. The number of vertexes and edges you choose will affect the operations that can be performed. For more information, see Graph Exploration Expansion.</p> <p></p> <p>Click Fit Selection to move the selected data to the center of the canvas for users to view.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-canvas/#vertex_filter","title":"Vertex Filter","text":"<p>You can filter the vertexes displayed on the canvas. In this example, select the vertexes with the Tag <code>player</code> and the property <code>age</code> greater than or equal to 35, and click the <code>Apply Filter</code> button.</p> <p>Note</p> <p>Each set of filter conditions aims at the data with this Tag. If the conditions are met, the corresponding vertex will be automatically selected. If the conditions are not met, the corresponding vertex will turn gray. The data status of other Tags will not be affected.</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-graph-exploration/","title":"Graph exploration and expansion","text":"<p>Graph exploration and expansion is divided into the following four parts:</p> <ul> <li>Expand</li> <li>Common neighbor</li> <li>Search path</li> <li>Inspect property</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-graph-exploration/#expand","title":"Expand","text":"<p>In the sidebar, click the  icon to open the Expand window. You can double-click a vertex to expand directly. You can also select multiple vertexes in the canvas, modify the edge type in the operation bar, select the inflow and outflow of the edge, modify the color of the vertex, specify the number of expansion steps and custom filter conditions.</p> <p>Note</p> <p>After the configuration in the panel is modified, the current configuration will be saved, and the current configuration will be expanded when double-clicking or right-clicking to quickly expand.</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-graph-exploration/#common_neighbor","title":"Common neighbor","text":"<p>In the sidebar, click the  icon to open the Common Neighbor window. You can select two or more vertexes on the canvas and query their common neighbors. When the selected vertexes have no common neighbor, the default returns There is no data.</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-graph-exploration/#search_path","title":"Search path","text":"<p>In the sidebar, click the findpath icon to open the Search path window. You can select two vertexes in the canvas. By default, the first vertex selected is the starting point, and the second vertex is the ending point. You can customize the type and direction of the edge, specify the number of expansion steps, and choose to query the following three paths: <code>All path</code>, <code>Shortest path</code> and <code>Noloop path</code>.</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-graph-exploration/#inspect_property","title":"Inspect property","text":"<p>In the sidebar, click the  icon to open the Inspect property window. You can choose to show or hide the property of vertexes or edges in the canvas. After clicking confirm, the property will be displayed on the canvas only when the zoom ratio is greater than 100%, and automatically hidden when the zoom ratio is less than 100%.</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/","title":"Page Overview","text":"<p>This topic describes Explorer main page.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#overview","title":"Overview","text":"<p> The main page of Explorer is divided into five parts:</p> <ul> <li>Tab bar</li> <li>Sidebar</li> <li>Canvas</li> <li>Minimap</li> <li>Relationship list</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#tab_bar","title":"Tab bar","text":"<ul> <li>Export: Export a CSV or PNG file of the current view.</li> </ul> <ul> <li>Create: Support creating multiple canvases. Only up to 10 canvases can be opened.</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#sidebar","title":"Sidebar","text":"<p>The sidebar consists of five parts. You can click the buttons to explore the graph, modify the content of the vertexes on the canvas, etc.</p> <ul> <li>Start query: Before exploring, the user needs to query the vertexes and display them in the canvas.</li> </ul> <ul> <li>Canvas operation: Including frame selection of vertexes in the canvas, dragging the canvas, and selecting multiple vertexes and edges.</li> </ul> <ul> <li>Graph exploration and expansion: Including functions such as vertexes expansion, finding common neighbors of multiple vertexes, finding the path of two vertexes, and inspecting the property.</li> </ul> <ul> <li>Hide and undo: Hide the data displayed in the canvas and undo the previous operation.</li> </ul> <ul> <li>Settings and help: Switch graph space, find help, modify settings, etc.</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#start_query","title":"Start query","text":"<ul> <li>Start: Click the  icon to query the data and display it on the page through VID, Tag and sub-graph.</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#canvas_operation","title":"Canvas operation","text":"<ul> <li>Frame selection mode: Click the  icon to support frame selection of vertexes and edges in the canvas.</li> <li>Click to select multiple vertexes and edges: Click the  icon, you can easily click the vertexes and edges in the canvas, and click the blank space to cancel the selection.</li> <li>Move the canvas: Click the  icon to drag the position of the canvas.</li> <li>Vertex Filter: Click the  icon to filter the vertexes displayed on the canvas.</li> </ul> <p>For more information, see Canvas Operation.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#graph_exploration_and_expansion","title":"Graph exploration and expansion","text":"<ul> <li>Expand: Click the  icon, select the vertexes on the page and perform custom expansion, including direction, steps, filter conditions, etc.</li> <li>Common neighbor: Click the  icon, select at least two vertexes on the page and view their common neighbors.</li> <li>Search path: Click the  icon to query the path of <code>all paths</code>, <code>Shortest path</code> or <code>Noloop path</code> between the start vertex and the end vertex.</li> <li>Inspect property: Click the  icon to choose whether to display the property values of vertexes or edges in the canvas.</li> </ul> <p>For more information, see Graph exploration and expansion.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#hide_and_undo","title":"Hide and undo","text":"<ul> <li>Dismiss: Click the  icon to hide the selected vertexes and edges in the canvas.</li> <li>Dismiss others: Click the  icon to hide all unselected vertexes and edges in the canvas.</li> <li>Undo: Click the  icon to undo the operation in the previous step.</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#settings_and_help","title":"Settings and help","text":"<ul> <li>Switch graph space: Click the  icon to switch the current graph space.</li> <li>Help: Click the  icon to see more information.</li> <li>Setting: Click the  icon to view usernames and shortcut keys, modify language settings, clear Explorer connect, etc.</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#canvas","title":"Canvas","text":"<p>The canvas is mainly divided into:</p> <ul> <li>Canvas: Display the data queried by VID, Tag or subgraph.</li> </ul> <ul> <li> <p>Vertexes and Edges overview: It is hidden by default and only displayed when the vertex and edge are selected on the current canvas. Click on the icon in the following, and the user can open the menu to view the detailed data of the selected vertexes and edges in the current canvas.</p> <p></p> </li> </ul> <p>For more information, see canvas operation.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#minimap","title":"Minimap","text":"<p>You can use the button on the minimap to switch the graph mode, display the vertexes in the canvas in full screen, collapse the minimap, zoom in or zoom out the canvass, etc. At the same time, the percentage of the graph in the canvas to the total graph is displayed in the lower-left corner of the minimap.</p> <ul> <li> <p>Switch mode: You can switch the display mode of the graph in the canvas.</p> icon mode force dagre circular </li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-page-overview/#relationship_list","title":"Relationship list","text":"<p>Click the  icon on the right, you can open the menu, view the number of tags and edges in the canvas, search for tags and edges, and also support modifying the color and icon of the vertex.</p>"},{"location":"nebula-explorer/operation-guide/ex-ug-query-exploration/","title":"Start query","text":"<p>In Explorer, you can choose the following query methods to display data:</p> <ul> <li>VID</li> <li>Tag</li> <li>Subgraph</li> </ul>"},{"location":"nebula-explorer/operation-guide/ex-ug-query-exploration/#query_by_vid","title":"Query by VID","text":"<p>You can query data by entering the VIDs or other data for VID generation, and a row only supports one data. It also supports random import of data and file import of data. After confirming the addition, the data will be displayed in the canvas. An example is given below:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-query-exploration/#query_by_tag","title":"Query by Tag","text":"<p>The required values are Tag and Index. You can limit the number of output results and filter the results. The following query 10 players whose age is greater than 30 years old and not equal to 40 years old, examples are as follows:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-query-exploration/#query_by_subgraph","title":"Query by Subgraph","text":"<p>The required value is VID. You can view the subgraph of one or more vertexes, and you can specify the number of steps, edge types, and the direction of inflow and outflow of the subgraph. The following is an example of an incoming edge with a VID value of 101, the number of steps of 4, and edge types of <code>server</code> and <code>like</code>:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-relationship-list/","title":"Relationship list","text":"<p>You can select vertexes and edges in the relationship list. Select 8 points where Tag is <code>player</code>, and select 5 edges where Edge is <code>serve</code>. An example is as follows:</p> <p></p> <p>At the same time, you can modify the color and icon of the Tag to make the key nodes more prominent.</p> <p>By default, VID with identical tags have the same color, and it is also allowed to manually modify the color of a vertex or a group of vertexes with identical tags. For example, if the vertex label is <code>player</code>, modify the color of one of the vertexes, and you can click to view it in the relationship list. The example is as follows:</p> <p></p>"},{"location":"nebula-explorer/operation-guide/ex-ug-shortcuts/","title":"Shortcuts","text":"<p>This document lists the shortcuts supported in Explorer.</p> Operation Description Shift + 'Enter' Expand Shift + '-' Zoom out Shift + '+' Zoom in Shift + 'l' Display Shift + 'z' Undo Selected + Shift + 'del' Delete"},{"location":"nebula-importer/config-with-header/","title":"Configuration with Header","text":"<p>For a CSV file with header, you need to set <code>withHeader</code> to <code>true</code> in the configuration file, indicating that the first behavior in the CSV file is the header. The header content has special meanings.</p> <p>Caution</p> <p>If the CSV file contains headers, the Importer will parse the Schema of each row of data according to the headers and ignore the vertex or edge settings in the YAML file.</p>"},{"location":"nebula-importer/config-with-header/#sample_files","title":"Sample files","text":"<p>The following is an example of a CSV file with header:</p> <ul> <li> <p>sample of vertex</p> <p>Example data for <code>student_with_header.csv</code>:</p> <pre><code>:VID(string),student.name:string,student.age:int,student.gender:string\nstudent100,Monica,16,female\nstudent101,Mike,18,male\nstudent102,Jane,17,female\n</code></pre> <p>The first column is the vertex ID, followed by the properties <code>name</code>, <code>age</code>, and <code>gender</code>.</p> </li> </ul> <ul> <li> <p>sample of edge</p> <p>Example data for <code>follow_with_header.csv</code>:</p> <pre><code>:SRC_VID(string),:DST_VID(string),:RANK,follow.degree:double\nstudent100,student101,0,92.5\nstudent101,student100,1,85.6\nstudent101,student102,2,93.2\nstudent100,student102,1,96.2\n</code></pre> <p>The first two columns are the start vertex ID and destination vertex ID, respectively. The third column is rank, and the fourth column is property <code>degree</code>.</p> </li> </ul>"},{"location":"nebula-importer/config-with-header/#header_format_description","title":"Header format description","text":"<p>The header defines the start vertex, the destination vertex, the rank, and some special functions by keywords as follows:</p> <ul> <li><code>:VID</code>(mandatory): Vertex ID. Need to use <code>:VID(type)</code> form to set data type, for example <code>:VID(string)</code> or <code>:VID(int)</code>.</li> </ul> <ul> <li><code>:SRC_VID</code>(mandatory): The start vertex ID of the edge. The data type needs to be set in the form <code>:SRC_VID(type)</code>.</li> </ul> <ul> <li><code>:DST_VID</code>(mandatory): The destination vertex ID of the edge. The data type needs to be set in the form <code>:DST_VID(type)</code>.</li> </ul> <ul> <li><code>:RANK</code>(optional): The rank value of the edge.</li> </ul> <ul> <li><code>:IGNORE</code>(optional): Ignore this column when inserting data.</li> </ul> <ul> <li> <p><code>:LABEL</code>(optional): Insert (+) or delete (-) the row. Must be column 1. For example:</p> <pre><code>:LABEL,\n+,\n-,\n</code></pre> </li> </ul> <p>Note</p> <p>All columns except the <code>:LABEL</code> column can be sorted in any order, so for larger CSV files, the user has the flexibility to set the header to select the desired column.</p> <p>For Tag or Edge type properties, the format is <code>&lt;tag_name/edge_name&gt;.&lt;prop_name&gt;:&lt;prop_type&gt;</code>, described as follows:</p> <ul> <li><code>&lt;tag_name/edge_name&gt;</code>: Tag or Edge type name.</li> </ul> <ul> <li><code>&lt;prop_name&gt;</code>: property name.</li> </ul> <ul> <li><code>&lt;prop_type&gt;</code>: property type. Support <code>bool</code>, <code>int</code>, <code>float</code>, <code>double</code>, <code>timestamp</code> and <code>string</code>, default <code>string</code>.</li> </ul> <p>Such as <code>student.name:string</code>, <code>follow.degree:double</code>.</p>"},{"location":"nebula-importer/config-with-header/#sample_configuration","title":"Sample configuration","text":"<pre><code># Connected to the NebulaGraph version, set to v2 when connected to 2.x.\nversion: v2\n\ndescription: example\n\n# Whether to delete temporarily generated logs and error data files.\nremoveTempFiles: false\n\nclientSettings:\n\n# Retry times of nGQL statement execution failures.\nretry: 3\n\n# Number of NebulaGraph client concurrency.\nconcurrency: 10 # Cache queue size per NebulaGraph client.\nchannelBufferSize: 128\n\n# Specifies the NebulaGraph space to import the data into.\nspace: student\n\n# Connection information.\nconnection:\nuser: root\npassword: nebula\naddress: 192.168.*.13:9669\n\npostStart:\n# Configure some of the operations to perform after connecting to the NebulaGraph server, and before inserting data.\ncommands: |\nDROP SPACE IF EXISTS student;\nCREATE SPACE IF NOT EXISTS student(partition_num=5, replica_factor=1, vid_type=FIXED_STRING(20));\nUSE student;\nCREATE TAG student(name string, age int,gender string);\nCREATE EDGE follow(degree int);\n\n# The interval between the execution of the above command and the execution of the insert data command.\nafterPeriod: 15s\n\npreStop:\n# Configure some of the actions you performed before disconnecting from the NebulaGraph server.\ncommands: |\n\n# Path of the error log file.\nlogPath: ./err/test.log\n\n# CSV file Settings.\nfiles:\n\n# Path for storing data files. If a relative path is used, the path is merged with the current configuration file directory. The first data file in this example is vertex data.\n- path: ./student_with_header.csv\n\n# Insert the failed data file storage path, so that data can be written later.\nfailDataPath: ./err/studenterr.csv\n\n# The number of statements inserting data in a batch.\nbatchSize: 10\n\n# Limit on the number of rows of read data.\nlimit: 10\n\n# Whether to insert rows in the file in order. If the value is set to false, the import rate decreases due to data skew.\ninOrder: true\n\n# File type. Currently, only CSV files are supported.\ntype: csv\n\ncsv:\n# Whether there is a header.\nwithHeader: true\n\n# Whether there is a LABEL.\nwithLabel: false\n\n# Specifies the delimiter for the CSV file. A string delimiter that supports only one character.\ndelimiter: \",\"\n\nschema:\n# Schema type. Possible values are vertex and edge.\ntype: vertex\n\n# The second data file in this example is edge data.\n- path: ./follow_with_header.csv\nfailDataPath: ./err/followerr.csv\nbatchSize: 10\nlimit: 10\ninOrder: true\ntype: csv\ncsv:\nwithHeader: true\nwithLabel: false\nschema:\n# The type of Schema is edge.\ntype: edge\nedge:\n# Edge type name.\nname: follow\n\n# Whether to include rank.\nwithRanking: true\n</code></pre> <p>Note</p> <p>The data type of the vertex ID must be the same as the data type of the statement in <code>clientSettings.postStart.commands</code> that creates the graph space.</p>"},{"location":"nebula-importer/config-without-header/","title":"Configuration without Header","text":"<p>For CSV files without header, you need to set <code>withHeader</code> to <code>false</code> in the configuration file, indicating that the CSV file contains only data (excluding the header of the first row). You may also need to set the data type and corresponding columns.</p>"},{"location":"nebula-importer/config-without-header/#sample_files","title":"Sample files","text":"<p>The following is an example of a CSV file without header:</p> <ul> <li> <p>sample of vertex</p> <p>Example data for <code>student_without_header.csv</code>:</p> <pre><code>student100,Monica,16,female\nstudent101,Mike,18,male\nstudent102,Jane,17,female\n</code></pre> <p>The first column is the vertex ID, followed by the properties <code>name</code>, <code>age</code>, and <code>gender</code>.</p> </li> </ul> <ul> <li> <p>sample of edge</p> <p>Example data for <code>follow_without_header.csv</code>:</p> <pre><code>student100,student101,0,92.5\nstudent101,student100,1,85.6\nstudent101,student102,2,93.2\nstudent100,student102,1,96.2\n</code></pre> <p>The first two columns are the start vertex ID and destination vertex ID, respectively. The third column is rank, and the fourth column is property <code>degree</code>.</p> </li> </ul>"},{"location":"nebula-importer/config-without-header/#sample_configuration","title":"Sample configuration","text":"<pre><code># Connected to the NebulaGraph version, set to v2 when connected to 2.x.\nversion: v2\n\ndescription: example\n\n# Whether to delete temporarily generated logs and error data files.\nremoveTempFiles: false\n\nclientSettings:\n\n# Retry times of nGQL statement execution failures.\nretry: 3\n\n# Number of NebulaGraph client concurrency.\nconcurrency: 10 # Cache queue size per NebulaGraph client.\nchannelBufferSize: 128\n\n# Specifies the NebulaGraph space to import the data into.\nspace: student\n\n# Connection information.\nconnection:\nuser: root\npassword: nebula\naddress: 192.168.*.13:9669\n\npostStart:\n# Configure some of the operations to perform after connecting to the NebulaGraph server, and before inserting data.\ncommands: |\nDROP SPACE IF EXISTS student;\nCREATE SPACE IF NOT EXISTS student(partition_num=5, replica_factor=1, vid_type=FIXED_STRING(20));\nUSE student;\nCREATE TAG student(name string, age int,gender string);\nCREATE EDGE follow(degree int);\n\n# The interval between the execution of the above command and the execution of the insert data command.\nafterPeriod: 15s\n\npreStop:\n# Configure some of the actions you performed before disconnecting from the NebulaGraph server.\ncommands: |\n\n# Path of the error log file.\nlogPath: ./err/test.log\n\n# CSV file Settings.\nfiles:\n\n# Path for storing data files. If a relative path is used, the path is merged with the current configuration file directory. The first data file in this example is vertex data.\n- path: ./student_without_header.csv\n\n# Insert the failed data file storage path, so that data can be written later.\nfailDataPath: ./err/studenterr.csv\n\n# The number of statements inserting data in a batch.\nbatchSize: 10\n\n# Limit on the number of rows of read data.\nlimit: 10\n\n# Whether to insert rows in the file in order. If the value is set to false, the import rate decreases due to data skew.\ninOrder: true\n\n# File type. Currently, only CSV files are supported.\ntype: csv\n\ncsv:\n# Whether there is a header.\nwithHeader: false\n\n# Whether there is a LABEL.\nwithLabel: false\n\n# Specifies the delimiter for the CSV file. A string delimiter that supports only one character.\ndelimiter: \",\"\n\nschema:\n# Schema type. Possible values are vertex and edge.\ntype: vertex\n\nvertex:\n\n# Vertex ID Settings.\nvid:\n# The vertex ID corresponds to the column number in the CSV file. Columns in the CSV file are numbered from 0.\nindex: 0\n\n# The data type of the vertex ID. The optional values are int and string, corresponding to INT64 and FIXED_STRING in the NebulaGraph, respectively.\ntype: string\n\n# Tag Settings.\n# Tag name.\n- name: student\n\n# property Settings in the Tag.\nprops:\n# property name.\n- name: name\n\n# Property data type.\ntype: string\n\n# Property corresponds to the sequence number of the column in the CSV file.\nindex: 1\n\n- name: age\ntype: int\nindex: 2\n- name: gender\ntype: string\nindex: 3\n\n# The second data file in this example is edge data.\n- path: ./follow_without_header.csv\nfailDataPath: ./err/followerr.csv\nbatchSize: 10\nlimit: 10\ninOrder: true\ntype: csv\ncsv:\nwithHeader: false\nwithLabel: false\nschema:\n# The type of Schema is edge.\ntype: edge\nedge:\n# Edge type name.\nname: follow\n\n# Whether to include rank.\nwithRanking: true\n\n# Start vertex ID setting.\nsrcVID:\n# Data type.\ntype: string\n\n# The start vertex ID corresponds to the sequence number of a column in the CSV file.\nindex: 0\n\n# Destination vertex ID.\ndstVID:\ntype: string\nindex: 1\n\n# rank setting.\nrank:\n# Rank Indicates the rank number of a column in the CSV file. If index is not set, be sure to set the rank value in the third column. Subsequent columns set each property in turn.\nindex: 2\n\n# Edge Type property Settings.\nprops:\n# property name.\n- name: degree\n\n# Data type.\ntype: double\n\n# Property corresponds to the sequence number of the column in the CSV file.\nindex: 3\n</code></pre> <p>Note</p> <ul> <li>The sequence numbers of the columns in the CSV file start from 0, that is, the sequence numbers of the first column are 0, and the sequence numbers of the second column are 1.</li> </ul> <ul> <li>The data type of the vertex ID must be the same as the data type of the statement in <code>clientSettings.postStart.commands</code> that creates the graph space.</li> </ul> <ul> <li> <p>If the index field is not specified, the CSV file must comply with the following rules:</p> <ul> <li>In the vertex data file, the first column must be the vertex ID, followed by the properties, and must correspond to the order in the configuration file.</li> </ul> <ul> <li>In the side data file, the first column must be the start vertex ID, the second column must be the destination vertex ID, if <code>withRanking</code> is <code>true</code>, the third column must be the rank value, and the following columns must be properties, and must correspond to the order in the configuration file.</li> </ul> </li> </ul>"},{"location":"nebula-importer/use-importer/","title":"Nebula Importer","text":"<p>Nebula Importer (Importer) is a standalone import tool for CSV files with NebulaGraph. Importer can read the local CSV file and then import the data into the NebulaGraph database.</p>"},{"location":"nebula-importer/use-importer/#scenario","title":"Scenario","text":"<p>Importer is used to import the contents of a local CSV file into the NebulaGraph.</p>"},{"location":"nebula-importer/use-importer/#advantage","title":"Advantage","text":"<ul> <li>Lightweight and fast: no complex environment can be used, fast data import.</li> </ul> <ul> <li>Flexible filtering: You can flexibly filter CSV data through configuration files.</li> </ul>"},{"location":"nebula-importer/use-importer/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-importer/use-importer/#prerequisites","title":"Prerequisites","text":"<p>Before using Nebula Importer, make sure:</p> <ul> <li> <p>NebulaGraph service has been deployed. There are currently three deployment modes:</p> <ul> <li>Deploy NebulaGraph with Docker Compose</li> </ul> <ul> <li>Install NebulaGraph with RPM or DEB package</li> </ul> <ul> <li>Install NebulaGraph by compiling the source code</li> </ul> </li> </ul> <ul> <li>Schema is created in NebulaGraph, including space, Tag and Edge type, or set by parameter <code>clientSettings.postStart.commands</code>.</li> </ul> <ul> <li>Golang environment has been deployed on the machine running the Importer. For details, see Build Go environment.</li> </ul>"},{"location":"nebula-importer/use-importer/#steps","title":"Steps","text":"<p>Configure the YAML file and prepare the CSV file to be imported to use the tool to batch write data to NebulaGraph.</p>"},{"location":"nebula-importer/use-importer/#download_binary_package_and_run","title":"Download binary package and run","text":"<ol> <li> <p>Download the binary package directly and add execute permission to it.</p> </li> <li> <p>Start the service.</p> <pre><code>$ ./&lt;binary_package_name&gt; --config &lt;yaml_config_file_path&gt;\n</code></pre> </li> </ol>"},{"location":"nebula-importer/use-importer/#source_code_compile_and_run","title":"Source code compile and run","text":"<ol> <li> <p>Clone repository.</p> <pre><code>$ git clone -b v2.6.0 https://github.com/vesoft-inc/nebula-importer.git\n</code></pre> <p>Note</p> <p>Use the correct branch.   NebulaGraph 1.x and 2.x have different RPC protocols, so:</p> <ul> <li>The Nebula Importer V1 branch can only connect to NebulaGraph 1.x.</li> <li>The Nebula Importer Master branch and v2 branch can connect to NebulaGraph 2.x.</li> </ul> </li> <li> <p>Access the directory <code>nebula-importer</code>.</p> <pre><code>$ cd nebula-importer\n</code></pre> </li> <li> <p>Compile the source code.</p> <pre><code>$ make build\n</code></pre> </li> <li> <p>Start the service.</p> <pre><code>$ ./nebula-importer --config &lt;yaml_config_file_path&gt;\n</code></pre> <p>Note</p> <p>For details about the YAML configuration file, see configuration file description at the end of topic.</p> </li> </ol>"},{"location":"nebula-importer/use-importer/#no_network_compilation_mode","title":"No network compilation mode","text":"<p>If the server cannot be connected to the Internet, it is recommended to upload the source code and various dependency packages to the corresponding server for compilation on the machine that can be connected to the Internet. The operation steps are as follows:</p> <ol> <li> <p>Clone repository.</p> <pre><code>$ git clone -b 2.6.0 https://github.com/vesoft-inc/nebula-importer.git\n</code></pre> </li> <li> <p>Use the following command to download and package the dependent source code.</p> <pre><code>$ cd nebula-importer\n$ go mod vendor\n$ cd .. &amp;&amp; tar -zcvf nebula-importer.tar.gz nebula-importer\n</code></pre> </li> <li> <p>Upload the compressed package to a server that cannot be connected to the Internet.</p> </li> <li> <p>Unzip and compile.</p> <pre><code>$ tar -zxvf nebula-importer.tar.gz \n$ cd nebula-importer\n$ go build -mod vendor cmd/importer.go\n</code></pre> </li> </ol>"},{"location":"nebula-importer/use-importer/#run_in_docker_mode","title":"Run in Docker mode","text":"<p>Instead of installing the Go locale locally, you can use Docker to pull the image of the Nebula Importer and mount the local configuration file and CSV data file into the container. The command is as follows:</p> <pre><code>$ docker run --rm -ti \\\n--network=host \\\n-v &lt;config_file&gt;:&lt;config_file&gt; \\\n-v &lt;csv_data_dir&gt;:&lt;csv_data_dir&gt; \\\nvesoft/nebula-importer:&lt;version&gt;\n    --config &lt;config_file&gt;\n</code></pre> <ul> <li><code>&lt;config_file&gt;</code>: The absolute path to the local YAML configuration file.</li> <li><code>&lt;csv_data_dir&gt;</code>: The absolute path to the local CSV data file.</li> <li><code>&lt;version&gt;</code>: NebulaGraph 2.x Please fill in 'v2'.</li> </ul> <p>Note</p> <p>A relative path is recommended. If you use a local absolute path, check that the path maps to the path in the Docker.</p>"},{"location":"nebula-importer/use-importer/#configuration_file_description","title":"Configuration File Description","text":"<p>Nebula Importer uses configuration(<code>nebula-importer/examples/v2/example.yaml</code>) files to describe information about the files to be imported, the NebulaGraph server, and more. You can refer to the example configuration file: Configuration without Header/Configuration with Header. This section describes the fields in the configuration file by category.</p> <p>Note</p> <p>If users download a binary package, create the configuration file manually.</p>"},{"location":"nebula-importer/use-importer/#basic_configuration","title":"Basic configuration","text":"<p>The example configuration is as follows:</p> <pre><code>version: v2\ndescription: example\nremoveTempFiles: false\n</code></pre> Parameter Default value Required Description <code>version</code> v2 Yes Target version of NebulaGraph. <code>description</code> example No Description of the configuration file. <code>removeTempFiles</code> false No Whether to delete temporarily generated logs and error data files."},{"location":"nebula-importer/use-importer/#client_configuration","title":"Client configuration","text":"<p>The client configuration stores the configurations associated with NebulaGraph.</p> <p>The example configuration is as follows:</p> <pre><code>clientSettings:\nretry: 3\nconcurrency: 10\nchannelBufferSize: 128\nspace: test\nconnection:\nuser: user\npassword: password\naddress: 192.168.*.13:9669,192.168.*.14:9669\npostStart:\ncommands: |\nUPDATE CONFIGS storage:wal_ttl=3600;\nUPDATE CONFIGS storage:rocksdb_column_family_options = { disable_auto_compactions = true };\nafterPeriod: 8s\npreStop:\ncommands: |\nUPDATE CONFIGS storage:wal_ttl=86400;\nUPDATE CONFIGS storage:rocksdb_column_family_options = { disable_auto_compactions = false };\n</code></pre> Parameter Default value Required Description <code>clientSettings.retry</code> 3 No Retry times of nGQL statement execution failures. <code>clientSettings.concurrency</code> 10 No Number of NebulaGraph client concurrency. <code>clientSettings.channelBufferSize</code> 128 No Cache queue size per NebulaGraph client. <code>clientSettings.space</code> - Yes Specifies the NebulaGraph space to import the data into. Do not import multiple spaces at the same time to avoid performance impact. <code>clientSettings.connection.user</code> - Yes NebulaGraph user name. <code>clientSettings.connection.password</code> - Yes The password for the NebulaGraph user name. <code>clientSettings.connection.address</code> - Yes Addresses and ports for all Graph services. <code>clientSettings.postStart.commands</code> - No Configure some of the operations to perform after connecting to the NebulaGraph server, and before inserting data. <code>clientSettings.postStart.afterPeriod</code> - No The interval, between executing the above <code>commands</code> and executing the insert data command, such as <code>8s</code>. <code>clientSettings.preStop.commands</code> - No Configure some of the actions you performed before disconnecting from the NebulaGraph server."},{"location":"nebula-importer/use-importer/#file_configuration","title":"File configuration","text":"<p>File configuration Stores the configuration of data files and logs, and details about the Schema.</p>"},{"location":"nebula-importer/use-importer/#file_and_log_configuration","title":"File and log configuration","text":"<p>The example configuration is as follows:</p> <pre><code>logPath: ./err/test.log\nfiles:\n- path: ./student_without_header.csv\nfailDataPath: ./err/studenterr.csv\nbatchSize: 128\nlimit: 10\ninOrder: false\ntype: csv\ncsv:\nwithHeader: false\nwithLabel: false\ndelimiter: \",\"\n</code></pre> Parameter Default value Required Description <code>logPath</code> - No Path for exporting log information, such as errors during import. <code>files.path</code> - Yes Path for storing data files. If a relative path is used, the path is merged with the current configuration file directory. You can use an asterisk (*) for fuzzy matching to import multiple files with similar names, but the files need to be the same structure. <code>files.failDataPath</code> - Yes Insert the failed data file storage path, so that data can be written later. <code>files.batchSize</code> 128 No The number of statements inserting data in a batch. <code>files.limit</code> - No Limit on the number of rows of read data. <code>files.inOrder</code> - No Whether to insert rows in the file in order. If the value is set to <code>false</code>, the import rate decreases due to data skew. <code>files.type</code> - Yes The file type. <code>files.csv.withHeader</code> <code>false</code> Yes Whether there is a header. <code>files.csv.withLabel</code> <code>false</code> Yes Whether there is a  label. <code>files.csv.delimiter</code> <code>\",\"</code> Yes Specifies the delimiter for the CSV file. A string delimiter that supports only one character."},{"location":"nebula-importer/use-importer/#schema_configuration","title":"Schema configuration","text":"<p>Schema configuration describes the Meta information of the current data file. Schema types are vertex and edge. Multiple vertexes or edges can be configured at the same time.</p> <ul> <li>vertex configuration</li> </ul> <p>The example configuration is as follows:</p> <pre><code>schema:\ntype: vertex\nvertex:\nvid:\ntype: string\nindex: 0\ntags:\n- name: student\nprops:\n- name: name\ntype: string\nindex: 1\n- name: age\ntype: int\nindex: 2\n- name: gender\ntype: string\nindex: 3\n</code></pre> Parameter Default value Required Description <code>files.schema.type</code> - Yes Schema type. Possible values are <code>vertex</code> and <code>edge</code>. <code>files.schema.vertex.vid.type</code> - No The data type of the vertex ID. Possible values are <code>int</code> and <code>string</code>. <code>files.schema.vertex.vid.index</code> - No The vertex ID corresponds to the column number in the CSV file. <code>files.schema.vertex.tags.name</code> - Yes Tag name. <code>files.schema.vertex.tags.props.name</code> - Yes Tag property name, which must match the Tag property in the NebulaGraph. <code>files.schema.vertex.tags.props.type</code> - Yes Property data type, supporting <code>bool</code>, <code>int</code>, <code>float</code>, <code>double</code>, <code>timestamp</code> and <code>string</code>. <code>files.schema.vertex.tags.props.index</code> - No Property corresponds to the sequence number of the column in the CSV file. <p>Note</p> <p>The sequence numbers of the columns in the CSV file start from 0, that is, the sequence numbers of the first column are 0, and the sequence numbers of the second column are 1.</p> <ul> <li>edge configuration</li> </ul> <p>The example configuration is as follows:</p> <pre><code>schema:\ntype: edge\nedge:\nname: follow\nwithRanking: true\nsrcVID:\ntype: string\nindex: 0\ndstVID:\ntype: string\nindex: 1\nrank:\nindex: 2\nprops:\n- name: degree\ntype: double\nindex: 3\n</code></pre> Parameter Default value Required Description <code>files.schema.type</code> - Yes Schema type. Possible values are <code>vertex</code> and <code>edge</code>. <code>files.schema.edge.name</code> - Yes Edge type name. <code>files.schema.edge.srcVID.type</code> - No \u8fb9\u7684\u8d77\u59cb\u70b9ID\u7684\u6570\u636e\u7c7b\u578b. <code>files.schema.edge.srcVID.index</code> - No The data type of the starting vertex ID of the edge. <code>files.schema.edge.dstVID.type</code> - No The data type of the destination vertex ID of the edge. <code>files.schema.edge.dstVID.index</code> - No The destination vertex ID of the edge corresponds to the column number in the CSV file. <code>files.schema.edge.rank.index</code> - No The rank value of the edge corresponds to the column number in the CSV file. <code>files.schema.edge.props.name</code> - Yes The Edge Type property name must match the Edge Type property in the NebulaGraph. <code>files.schema.edge.props.type</code> - Yes Property data type, supporting <code>bool</code>, <code>int</code>, <code>float</code>, <code>double</code>, <code>timestamp</code> and <code>string</code>. <code>files.schema.edge.props.index</code> - No Property corresponds to the sequence number of the column in the CSV file."},{"location":"nebula-importer/use-importer/#about_the_csv_file_header","title":"About the CSV file header","text":"<p>According to whether the CSV file has a header or not, the Importer needs to make different Settings on the configuration file. For relevant examples and explanations, please refer to:</p> <ul> <li>Configuration without Header</li> </ul> <ul> <li>Configuration with Header</li> </ul>"},{"location":"nebula-operator/1.introduction-to-nebula-operator/","title":"What is Nebula Operator","text":""},{"location":"nebula-operator/1.introduction-to-nebula-operator/#concept_of_nebula_operator","title":"Concept of Nebula Operator","text":"<p>Nebula Operator is a tool to automate the deployment, operation, and maintenance of NebulaGraph clusters on Kubernetes. Building upon the excellent scalability mechanism of Kubernetes, NebulaGraph introduced its operation and maintenance knowledge into the Kubernetes system, which makes NebulaGraph a real cloud-native graph database.</p>"},{"location":"nebula-operator/1.introduction-to-nebula-operator/#how_it_works","title":"How it works","text":"<p>For resource types that do not exist within Kubernetes\uff0cyou can register them by adding custom API objects. The common way is to use the CustomResourceDefinition.</p> <p>Nebula Operator abstracts the deployment management of NebulaGraph clusters as a CRD. By combining multiple built-in API objects including StatefulSet, Service, and ConfigMap, the routine management and maintenance of a NebulaGraph cluster are coded as a control loop in the Kubernetes system. When a CR instance is submitted, Nebula Operator drives database clusters to the final state according to the control process.</p>"},{"location":"nebula-operator/1.introduction-to-nebula-operator/#features_of_nebula_operator","title":"Features of Nebula Operator","text":"<p>The following features are already available in Nebula Operator:</p> <ul> <li>Deploy and uninstall clusters: Nebula Operator simplifies the process of deploying and uninstalling clusters for users. Nebula Operator allows you to quickly create, update, or delete a NebulaGraph cluster by simply providing the corresponding CR file. For more information, see Deploy NebulaGraph Clusters with Kubectl or Deploy NebulaGraph Clusters with Helm.</li> </ul> <ul> <li>Scale clusters: Nebula Operator calls NebulaGraph's native scaling interfaces in a control loop to implement the scaling logic. You can simply perform scaling operations with YAML configurations and ensure the stability of data. For more information, see Scale clusters with Kubectl or Scale clusters with Helm.</li> </ul> <ul> <li>Cluster Upgrade: Nebula Operator supports cluster upgrading from version 2.5.x to version 2.6.x.</li> </ul> <ul> <li>Self-Healing: Nebula Operator calls interfaces provided by NebulaGraph clusters to dynamically sense cluster service status. Once an exception is detected, Nebula Operator performs fault tolerance. For more information, see Self-Healing.</li> </ul> <ul> <li>Balance Scheduling: Based on the scheduler extension interface, the scheduler provided by Nebula Operator evenly distributes Pods in a NebulaGraph cluster across all nodes.</li> </ul>"},{"location":"nebula-operator/1.introduction-to-nebula-operator/#limitations","title":"Limitations","text":""},{"location":"nebula-operator/1.introduction-to-nebula-operator/#version_limitations","title":"Version limitations","text":"<p>Nebula Operator does not support the v1.x version of NebulaGraph. Nebula Operator version and the corresponding NebulaGraph version are as follows:</p> Nebula Operator version NebulaGraph version 0.9.0 2.5.x ~ 2.6.x 0.8.0 2.5.x"},{"location":"nebula-operator/1.introduction-to-nebula-operator/#feature_limitations","title":"Feature limitations","text":"<p>Nebula Operator currently only supports manual scaling of NebulaGraph clusters, and does not support automatic scaling of NebulaGraph clusters.</p>"},{"location":"nebula-operator/1.introduction-to-nebula-operator/#release_note","title":"Release note","text":"<p>Release</p>"},{"location":"nebula-operator/2.deploy-nebula-operator/","title":"Deploy Nebula Operator","text":"<p>You can deploy Nebula Operator with Helm.</p>"},{"location":"nebula-operator/2.deploy-nebula-operator/#background","title":"Background","text":"<p>Nebula Operator automates the management of NebulaGraph clusters, and eliminates the need for you to install, scale, upgrade, and uninstall NebulaGraph clusters, which lightens the burden on managing different application versions.</p>"},{"location":"nebula-operator/2.deploy-nebula-operator/#prerequisites","title":"Prerequisites","text":""},{"location":"nebula-operator/2.deploy-nebula-operator/#install_software","title":"Install software","text":"<p>Before installing Nebula Operator, you need to install the following software and ensure the correct version of the software:</p> Software Requirement Kubernetes &gt;= 1.16 Helm &gt;= 3.2.0 CoreDNS &gt;= 1.6.0 CertManager &gt;= 1.2.0 OpenKruise &gt;= 0.8.0 <p>If using a role-based access control policy, you need to enable RBAC (optional).</p>"},{"location":"nebula-operator/2.deploy-nebula-operator/#description_of_software","title":"Description of software","text":"<p>Note</p> <p>The following software used by Nebula Operator is from the third party. Nebula Operator is not responsible for any problems that may arise during the software installation.</p> <ul> <li> <p>CoreDNS</p> <p>CoreDNS is a flexible and scalable DNS server that is installed for Pods in NebulaGraph clusters.</p> <p>Components in a NebulaGraph cluster communicate with each other via DNS resolutions for domain names, like <code>x.default.svc.cluster.local</code>.</p> </li> </ul> <ul> <li> <p>cert-manager</p> <p>Note</p> <p>If you have set the value of the Nebula Operator configuration item <code>admissionWebhook.create</code> to <code>false</code>, there is no need to install cert-manager. For details about Nebula Operator configuration items, see the Customize Helm charts section in Install Nebula Operator below.</p> <p>cert-manager is a tool that automates the management of certificates. It leverages extensions of the Kubernetes API and uses the Webhook server to provide dynamic access control to cert-manager resources. For more information about installation, see cert-manager installation documentation.</p> <p>cert-manager is used to validate the numeric value of replicas for each component in a NebulaGraph cluster. If you run it in a production environment and care about the high availability of NebulaGraph clusters, it is recommended to set the value of <code>admissionWebhook.create</code> to <code>true</code> before installing cert-manager.</p> </li> </ul> <ul> <li> <p>OpenKruise</p> <p>OpenKruise is a full set of standard extensions for Kubernetes. It works well with original Kubernetes and provides more powerful and efficient features for managing Pods, sidecar containers, and even container images in clusters. OpenKruise is required to enable advanced features for StatefulSets when Nebula Operator starts. For information about installation, see openkruise installation documentation.</p> </li> </ul>"},{"location":"nebula-operator/2.deploy-nebula-operator/#steps","title":"Steps","text":""},{"location":"nebula-operator/2.deploy-nebula-operator/#install_nebula_operator","title":"Install Nebula Operator","text":"<ol> <li> <p>Add the Nebula Operator chart repository to Helm.</p> <pre><code>helm repo add nebula-operator https://vesoft-inc.github.io/nebula-operator/charts\n</code></pre> </li> <li> <p>Update information of available charts locally from chart repositories.</p> <pre><code>helm repo update\n</code></pre> <p>For more information about <code>helm repo</code>, see Helm Repo.</p> </li> <li> <p>Install Nebula Operator.</p> <pre><code>helm install nebula-operator nebula-operator/nebula-operator --namespace=&lt;namespace_name&gt; --version=${chart_version}\n</code></pre> <p>For example, the command to install Nebula Operator of version 0.9.0 is as follows.</p> <pre><code>helm install nebula-operator nebula-operator/nebula-operator --namespace=nebula-operator-system --version=0.9.0\n</code></pre> <ul> <li><code>nebula-operator-system</code> is a user-created namespace name. If you have not created this namespace, run <code>kubectl create namespace nebula-operator-system</code> to create one. You can also use a different name.</li> </ul> <ul> <li><code>0.9.0</code> is the version of the Nebula Operator chart. It can be unspecified when there is only one chart version in the Nebula Operator chart repository. Run <code>helm search repo -l nebula-operator</code> to see chart versions.</li> </ul> <p>You can customize the configuration items of the Nebula Operator chart before running the installation command. For more information, see Customize Helm charts below.</p> </li> </ol>"},{"location":"nebula-operator/2.deploy-nebula-operator/#customize_helm_charts","title":"Customize Helm charts","text":"<p>Run <code>helm show values [CHART] [flags]</code> to see configurable options.</p> <p>For example:</p> <pre><code>[k8s@master ~]$ helm show values nebula-operator/nebula-operator\nimage:\nnebulaOperator:\nimage: vesoft/nebula-operator:v0.9.0\nimagePullPolicy: Always\nkubeRBACProxy:\nimage: gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0\nimagePullPolicy: Always\nkubeScheduler:\nimage: k8s.gcr.io/kube-scheduler:v1.18.8\nimagePullPolicy: Always\n\nimagePullSecrets: []\nkubernetesClusterDomain: \"\"\n\ncontrollerManager:\ncreate: true\nreplicas: 2\nenv: []\nresources:\nlimits:\ncpu: 200m\nmemory: 200Mi\nrequests:\ncpu: 100m\nmemory: 100Mi\n\nadmissionWebhook:\ncreate: true\n\nscheduler:\ncreate: true\nschedulerName: nebula-scheduler\nreplicas: 2\nenv: []\nresources:\nlimits:\ncpu: 200m\nmemory: 20Mi\nrequests:\ncpu: 100m\nmemory: 100Mi\n</code></pre> <p>Part of the above parameters are described as follows:</p> Parameter Default value Description <code>image.nebulaOperator.image</code> <code>vesoft/nebula-operator:v0.9.0</code> The image of Nebula Operator, version of which is 0.9.0. <code>image.nebulaOperator.imagePullPolicy</code> <code>IfNotPresent</code> The image pull policy in Kubernetes. <code>imagePullSecrets</code> - The image pull secret in Kubernetes. <code>kubernetesClusterDomain</code> <code>cluster.local</code> The cluster domain. <code>controllerManager.create</code> <code>true</code> Whether to enable the controller-manager component. <code>controllerManager.replicas</code> <code>2</code> The numeric value of controller-manager replicas. <code>admissionWebhook.create</code> <code>true</code> Whether to enable Admission Webhook. <code>shceduler.create</code> <code>true</code> Whether to enable Scheduler. <code>shceduler.schedulerName</code> <code>nebula-scheduler</code> The Scheduler name. <code>shceduler.replicas</code> <code>2</code> The numeric value of nebula-scheduler replicas. <p>You can run <code>helm install [NAME] [CHART] [flags]</code> to specify chart configurations when installing a chart. For more information, see Customizing the Chart Before Installing.</p> <p>The following example shows how to specify the Nebula Operator's AdmissionWebhook mechanism to be turned off when you install Nebula Operator (AdmissionWebhook is enabled by default):</p> <pre><code>helm install nebula-operator nebula-operator/nebula-operator --namespace=&lt;nebula-operator-system&gt; --set admissionWebhook.create=false\n</code></pre> <p>For more information about <code>helm install</code>, see Helm Install.</p>"},{"location":"nebula-operator/2.deploy-nebula-operator/#update_nebula_operator","title":"Update Nebula Operator","text":"<p>After installing Nebula Operator, you can update it by modifying the parameter values in the <code>${HOME}/nebula-operator/charts/nebula-operator/values.yaml</code> file.</p> <ol> <li> <p>Clone the Nebula Operator repository to your local server.</p> <pre><code>git clone https://github.com/vesoft-inc/nebula-operator.git\n</code></pre> </li> <li> <p>Modify the parameter values in <code>${HOME}/nebula-operator/charts/nebula-operator/values.yaml</code>.</p> </li> <li> <p>Run the following command to update Nebula Operator.</p> <pre><code>helm upgrade nebula-operator nebula-operator/nebula-operator --namespace=&lt;namespace_name&gt; -f ${HOME}/nebula-operator/charts/nebula-operator/values.yaml\n</code></pre> <p><code>&lt;namespace_name&gt;</code> is a user-created namespace name. Pods related to the nebula-operator repository are in this namespace.</p> </li> </ol>"},{"location":"nebula-operator/2.deploy-nebula-operator/#upgrade_nebula_operator","title":"Upgrade Nebula Operator","text":"<p>Legacy version compatibility</p> <p>Starting from Nebula Operator 0.9.0, logs and data are stored separately. Managing a NebulaGraph 2.5.x cluster with Nebula Operator 0.9.0 or later versions can cause compatibility issues. You can backup the data of the NebulaGraph 2.5.x cluster and then create a 2.6.x cluster with Operator.</p> <ol> <li> <p>Update the information of available charts locally from chart repositories.</p> <pre><code>helm repo update\n</code></pre> </li> <li> <p>Upgrade Operator.</p> <pre><code>helm upgrade nebula-operator nebula-operator/nebula-operator --namespace=&lt;namespace_name&gt; --version=0.9.0\n</code></pre> <p>For example:</p> <pre><code>helm upgrade nebula-operator nebula-operator/nebula-operator --namespace=nebula-operator-system --version=0.9.0\n</code></pre> <p>Output:</p> <pre><code>Release \"nebula-operator\" has been upgraded. Happy Helming!\nNAME: nebula-operator\nLAST DEPLOYED: Tue Nov 16 02:21:08 2021\nNAMESPACE: nebula-operator-system\nSTATUS: deployed\nREVISION: 3\nTEST SUITE: None\nNOTES:\nNebula Operator installed!\n</code></pre> </li> <li> <p>Pull the latest CRD configuration file.</p> <p>Note</p> <p>You need to upgrade the corresponding CRD configurations after Nebula Operator is upgraded. Otherwise, the creation of NebulaGraph clusters will fail. For information about the CRD configurations, see apps.nebula-graph.io_nebulaclusters.yaml.</p> <pre><code>helm pull nebula-operator/nebula-operator\n</code></pre> </li> <li> <p>Upgrade the CRD configuration file.</p> <pre><code>kubectl apply -f &lt;crd_file_name&gt;.yaml\n</code></pre> <p>For example:</p> <pre><code>kubectl apply -f config/crd/bases/apps.nebula-graph.io_nebulaclusters.yaml\n</code></pre> <p>Output:</p> <pre><code>customresourcedefinition.apiextensions.k8s.io/nebulaclusters.apps.nebula-graph.io created\n</code></pre> </li> </ol>"},{"location":"nebula-operator/2.deploy-nebula-operator/#uninstall_nebula_operator","title":"Uninstall Nebula Operator","text":"<ol> <li> <p>Uninstall the Nebula Operator chart.</p> <pre><code>helm uninstall nebula-operator --namespace=&lt;nebula-operator-system&gt;\n</code></pre> </li> <li> <p>Delete CRD.</p> <pre><code>kubectl delete crd nebulaclusters.apps.nebula-graph.io\n</code></pre> </li> </ol>"},{"location":"nebula-operator/2.deploy-nebula-operator/#whats_next","title":"What's next","text":"<p>Automate the deployment of NebulaGraph clusters with Nebula Operator. For more information, see Deploy NebulaGraph Clusters with Kubectl or Deploy NebulaGraph Clusters with Helm.</p>"},{"location":"nebula-operator/4.connect-to-nebula-graph-service/","title":"Connect to NebulaGraph databases with Nebular Operator","text":"<p>After creating a NebulaGraph cluster with Nebula Operator on Kubernetes, you can connect to NebulaGraph databases from within the cluster and outside the cluster.</p>"},{"location":"nebula-operator/4.connect-to-nebula-graph-service/#prerequisites","title":"Prerequisites","text":"<p>Create a NebulaGraph cluster with Nebula Operator on Kubernetes. For more information, see Deploy NebulaGraph clusters with Kubectl or Deploy NebulaGraph clusters with Helm.</p>"},{"location":"nebula-operator/4.connect-to-nebula-graph-service/#connect_to_nebulagraph_databases_from_within_a_nebulagraph_cluster","title":"Connect to NebulaGraph databases from within a NebulaGraph cluster","text":"<p>When a NebulaGraph cluster is created, Nebula Operator automatically creates a Service named <code>&lt;cluster-name&gt;-graphd-svc</code> with the type <code>ClusterIP</code> under the same namespace. With the IP of the Service and the port number of the NebulaGraph database, you can connect to the NebulaGraph database.</p> <ol> <li> <p>Run the following command to check the IP of the Service:</p> <pre><code>$ kubectl get service -l app.kubernetes.io/cluster=&lt;nebula&gt;  #&lt;nebula&gt; is a variable value. Replace it with the desired name.\nNAME                       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                          AGE\nnebula-graphd-svc          ClusterIP   10.98.213.34   &lt;none&gt;        9669/TCP,19669/TCP,19670/TCP                     23h\nnebula-metad-headless      ClusterIP   None           &lt;none&gt;        9559/TCP,19559/TCP,19560/TCP                     23h\nnebula-storaged-headless   ClusterIP   None           &lt;none&gt;        9779/TCP,19779/TCP,19780/TCP,9778/TCP            23h\n</code></pre> <p>Services of the <code>ClusterIP</code> type only can be accessed by other applications in a cluster. For more information, see ClusterIP.</p> </li> <li> <p>Run the following command to connect to the NebulaGraph database using the IP of the <code>&lt;cluster-name&gt;-graphd-svc</code> Service above:</p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- &lt;nebula_console_name&gt; -addr &lt;cluster_ip&gt;  -port &lt;service_port&gt; -u &lt;username&gt; -p &lt;password&gt;\n</code></pre> <p>For example:</p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- nebula-console -addr 10.98.213.34  -port 9669 -u root -p vesoft\n\n- `--image`: The image for the tool Nebula Console used to connect to NebulaGraph databases.\n- `&lt;nebula-console&gt;`: The custom Pod name.\n- `-addr`: The IP of the `ClusterIP` Service, used to connect to Graphd services.\n- `-port`: The port to connect to Graphd services, the default port of which is 9669.\n- `-u`: The username of your NebulaGraph account. Before enabling authentication, you can use any existing username. The default username is root.\n- `-p`: The password of your NebulaGraph account. Before enabling authentication, you can use any characters as the password.\n\nA successful connection to the database is indicated if the following is returned:\n\n```bash\nIf you don't see a command prompt, try pressing enter.\n\n(root@nebula) [(none)]&gt;\n</code></pre> </li> </ol> <p>You can also connect to NebulaGraph databases with Fully Qualified Domain Name (FQDN). The domain format is <code>&lt;cluster-name&gt;-graphd.&lt;cluster-namespace&gt;.svc.&lt;CLUSTER_DOMAIN&gt;</code>:</p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- &lt;nebula_console_name&gt; -addr &lt;cluster_name&gt;-graphd-svc.default.svc.cluster.local -port &lt;service_port&gt; -u &lt;username&gt; -p &lt;password&gt;\n</code></pre> <p>The default value of <code>CLUSTER_DOMAIN</code> is <code>cluster.local</code>.</p>"},{"location":"nebula-operator/4.connect-to-nebula-graph-service/#connect_to_nebulagraph_databases_from_outside_a_nebulagraph_cluster_via_nodeport","title":"Connect to NebulaGraph databases from outside a NebulaGraph cluster via <code>NodePort</code>","text":"<p>You can create a Service of type <code>NodePort</code> to connect to NebulaGraph databases from outside a NebulaGraph cluster with a node IP and an exposed node port. You can also use load balancing software provided by cloud providers (such as Azure, AWS, etc.) and set the Service of type <code>LoadBalancer</code>.</p> <p>The Service of type <code>NodePort</code> forwards the front-end requests via the label selector <code>spec.selector</code> to Graphd pods with labels <code>app.kubernetes.io/cluster: &lt;cluster-name&gt;</code> and <code>app.kubernetes.io/component: graphd</code>.</p> <p>Steps:</p> <ol> <li> <p>Create a YAML file named <code>graphd-nodeport-service.yaml</code>. The file contents are as follows:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\nlabels:\napp.kubernetes.io/cluster: nebula\napp.kubernetes.io/component: graphd\napp.kubernetes.io/managed-by: nebula-operator\napp.kubernetes.io/name: nebula-graph\nname: nebula-graphd-svc-nodeport\nnamespace: default\nspec:\nexternalTrafficPolicy: Local\nports:\n- name: thrift\nport: 9669\nprotocol: TCP\ntargetPort: 9669\n- name: http\nport: 19669\nprotocol: TCP\ntargetPort: 19669\nselector:\napp.kubernetes.io/cluster: nebula\napp.kubernetes.io/component: graphd\napp.kubernetes.io/managed-by: nebula-operator\napp.kubernetes.io/name: nebula-graph\ntype: NodePort\n</code></pre> <ul> <li>NebulaGraph uses port <code>9669</code> by default. <code>19669</code> is the port of the Graph service in a NebulaGraph cluster.</li> <li>The value of <code>targetPort</code> is the port mapped to the database Pods, which can be customized.</li> </ul> </li> <li> <p>Run the following command to create a NodePort Service.</p> <pre><code>kubectl create -f graphd-nodeport-service.yaml\n</code></pre> </li> <li> <p>Check the port mapped on all of your cluster nodes.</p> <pre><code>kubectl get services\n</code></pre> <p>Output:</p> <pre><code>NAME                           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                          AGE\nnebula-graphd-svc              ClusterIP   10.98.213.34   &lt;none&gt;        9669/TCP,19669/TCP,19670/TCP                     23h\nnebula-graphd-svc-nodeport     NodePort    10.107.153.129 &lt;none&gt;        9669:32236/TCP,19669:31674/TCP,19670:31057/TCP   24h\nnebula-metad-headless          ClusterIP   None           &lt;none&gt;        9559/TCP,19559/TCP,19560/TCP                     23h\nnebula-storaged-headless       ClusterIP   None           &lt;none&gt;        9779/TCP,19779/TCP,19780/TCP,9778/TCP            23h\n</code></pre> <p>As you see, the mapped port of NebulaGraph databases on all cluster nodes is <code>32236</code>.</p> </li> <li> <p>Connect to NebulaGraph databases with your node IP and the node port above.</p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- &lt;nebula_console_name&gt; -addr &lt;node_ip&gt; -port &lt;node_port&gt; -u &lt;username&gt; -p &lt;password&gt;\n</code></pre> <p>For example:</p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- nebula-console2 -addr 192.168.8.24 -port 32236 -u root -p vesoft\nIf you don't see a command prompt, try pressing enter.\n\n(root@nebula) [(none)]&gt;\n</code></pre> <ul> <li><code>--image</code>: The image for the tool Nebula Console used to connect to NebulaGraph databases.</li> <li><code>&lt;nebula-console&gt;</code>: The custom Pod name. The above example uses <code>nebula-console2</code>.</li> <li><code>-addr</code>: The IP of any node in a NebulaGraph cluster. The above example uses <code>192.168.8.24</code>.</li> <li><code>-port</code>: The mapped port of NebulaGraph databases on all cluster nodes. The above example uses <code>32236</code>.</li> <li><code>-u</code>: The username of your NebulaGraph account. Before enabling authentication, you can use any existing username. The default username is root.</li> <li><code>-p</code>: The password of your NebulaGraph account. Before enabling authentication, you can use any characters as the password.</li> </ul> </li> </ol>"},{"location":"nebula-operator/4.connect-to-nebula-graph-service/#connect_to_nebulagraph_databases_from_outside_a_nebulagraph_cluster_via_ingress","title":"Connect to NebulaGraph databases from outside a NebulaGraph cluster via Ingress","text":"<p>Nginx Ingress is an implementation of Kubernetes Ingress. Nginx Ingress watches the Ingress resource of a Kubernetes cluster and generates the Ingress rules into Nginx configurations that enable Nginx to forward 7 layers of traffic.</p> <p>You can use Nginx Ingress to connect to a NebulaGraph cluster from outside the cluster using a combination of the HostNetwork and DaemonSet pattern.</p> <p>As HostNetwork is used, the Nginx Ingress pod cannot be scheduled to the same node. To avoid listening port conflicts, some nodes can be selected and labeled as edge nodes in advance, which are specially used for the Nginx Ingress deployment. Nginx Ingress is then deployed on these nodes in a DaemonSet mode.</p> <p>Ingress does not support TCP or UDP services. For this reason, the nginx-ingress-controller pod uses the flags <code>--tcp-services-configmap</code> and <code>--udp-services-configmap</code> to point to an existing ConfigMap where the key refers to the external port to be used and the value refers to the format of the service to be exposed. The format of the value is <code>&lt;namespace/service_name&gt;:&lt;service_port&gt;</code>.</p> <p>For example, the configurations of the ConfigMap named as <code>tcp-services</code> is as follows:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: tcp-services\nnamespace: nginx-ingress\ndata:\n# update \n9769: \"default/nebula-graphd-svc:9669\"\n</code></pre> <p>Steps are as follows.</p> <ol> <li> <p>Create a file named <code>nginx-ingress-daemonset-hostnetwork.yaml</code>. </p> <p>Click on nginx-ingress-daemonset-hostnetwork.yaml to view the complete content of the example YAML file.</p> <p>Note</p> <p>The resource objects in the YAML file above use the namespace <code>nginx-ingress</code>. You can run <code>kubectl create namespace nginx-ingress</code> to create this namespace, or you can customize the namespace.</p> </li> <li> <p>Label a node where the DaemonSet named <code>nginx-ingress-controller</code> in the above YAML file (The node used in this example is named <code>worker2</code> with an IP of <code>192.168.8.160</code>) runs.</p> <pre><code>kubectl label node worker2 nginx-ingress=true\n</code></pre> </li> <li> <p>Run the following command to enable Nginx Ingress in the cluster you created. </p> <pre><code>kubectl create -f nginx-ingress-daemonset-hostnetwork.yaml\n</code></pre> <p>Output:</p> <pre><code>configmap/nginx-ingress-controller created\nconfigmap/tcp-services created\nserviceaccount/nginx-ingress created\nserviceaccount/nginx-ingress-backend created\nclusterrole.rbac.authorization.k8s.io/nginx-ingress created\nclusterrolebinding.rbac.authorization.k8s.io/nginx-ingress created\nrole.rbac.authorization.k8s.io/nginx-ingress created\nrolebinding.rbac.authorization.k8s.io/nginx-ingress created\nservice/nginx-ingress-controller-metrics created\nservice/nginx-ingress-default-backend created\nservice/nginx-ingress-proxy-tcp created\ndaemonset.apps/nginx-ingress-controller created\n</code></pre> <p>Since the network type that is configured in Nginx Ingress is <code>hostNetwork</code>, after successfully deploying Nginx Ingress, with the IP (<code>192.168.8.160</code>) of the node where Nginx Ingress is deployed and with the external port (<code>9769</code>) you define, you can access NebulaGraph. </p> </li> <li> <p>Use the IP address and the port configured in the preceding steps. You can connect to NebulaGraph with Nebula Console. </p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- &lt;nebula_console_name&gt; -addr &lt;host_ip&gt; -port &lt;external_port&gt; -u &lt;username&gt; -p &lt;password&gt;\n</code></pre> <p>Output:</p> <pre><code>kubectl run -ti --image vesoft/nebula-console:v2.6.0 --restart=Never -- nebula-console -addr 192.168.8.160 -port 9769 -u root -p vesoft\n</code></pre> <ul> <li><code>--image</code>: The image for the tool Nebula Console used to connect to NebulaGraph databases.</li> <li><code>&lt;nebula-console&gt;</code> The custom Pod name. The above example uses <code>nebula-console</code>.</li> <li><code>-addr</code>: The IP of the node where Nginx Ingress is deployed. The above example uses <code>192.168.8.160</code>.</li> <li><code>-port</code>: The port used for external network access. The above example uses <code>9769</code>.</li> <li><code>-u</code>: The username of your NebulaGraph account. Before enabling authentication, you can use any existing username. The default username is root.</li> <li><code>-p</code>: The password of your NebulaGraph account. Before enabling authentication, you can use any characters as the password.</li> </ul> <p>A successful connection to the database is indicated if the following is returned:</p> <pre><code>If you don't see a command prompt, try pressing enter.\n(root@nebula) [(none)]&gt;\n</code></pre> </li> </ol>"},{"location":"nebula-operator/5.operator-failover/","title":"Self-healing","text":"<p>Nebula Operator calls the interface provided by NebulaGraph clusters to dynamically sense cluster service status. Once an exception is detected (for example, a component in a NebulaGraph cluster stops running), Nebula Operator automatically performs fault tolerance. This topic shows how Nebular Operator performs self-healing by simulating cluster failure of deleting one Storage service Pod in a NebulaGraph cluster.</p>"},{"location":"nebula-operator/5.operator-failover/#prerequisites","title":"Prerequisites","text":"<p>Install Nebula Operator</p>"},{"location":"nebula-operator/5.operator-failover/#steps","title":"Steps","text":"<ol> <li> <p>Create a NebulaGraph cluster. For more information, see Deploy NebulaGraph clusters with Kubectl or Deploy NebulaGraph clusters with Helm.</p> </li> <li> <p>Delete the Pod named <code>&lt;cluster_name&gt;-storaged-2</code> after all pods are in the <code>Running</code> status.</p> <p><pre><code>kubectl delete pod &lt;cluster-name&gt;-storaged-2 --now\n</code></pre> <code>&lt;cluster_name&gt;</code> is the name of your NebulaGraph cluster.</p> </li> <li> <p>Nebula Operator automates the creation of the Pod named <code>&lt;cluster-name&gt;-storaged-2</code> to perform self-healing.</p> <p>Run the <code>kubectl get pods</code> command to check the status of the Pod <code>&lt;cluster-name&gt;-storaged-2</code>.</p> <pre><code>...\nnebula-cluster-storaged-1        1/1     Running             0          5d23h\nnebula-cluster-storaged-2        0/1     ContainerCreating   0          1s\n...\n</code></pre> <p><pre><code>...\nnebula-cluster-storaged-1        1/1     Running     0          5d23h\nnebula-cluster-storaged-2        1/1     Running     0          4m2s\n...\n</code></pre> When the status of <code>&lt;cluster-name&gt;-storaged-2</code> is changed from <code>ContainerCreating</code> to <code>Running</code>, the self-healing is performed successfully.</p> </li> </ol>"},{"location":"nebula-operator/6.get-started-with-operator/","title":"Overview of using Nebula Operator","text":"<p>To use Nebula Operator to connect to NebulaGraph databases, see steps as follows:</p> <ol> <li>Install Nebula Operator.</li> <li> <p>Create a NebulaGraph cluster.</p> <p>For more information, see Deploy NebulaGraph clusters with Kubectl or Deploy NebulaGraph clusters with Helm.</p> </li> <li> <p>Connect to a NebulaGraph database.</p> </li> </ol>"},{"location":"nebula-operator/7.operator-faq/","title":"FAQ","text":""},{"location":"nebula-operator/7.operator-faq/#does_nebula_operator_support_the_v1x_version_of_nebulagraph","title":"Does Nebula Operator support the v1.x version of NebulaGraph?","text":"<p>No, because the v1.x version of NebulaGraph does not support DNS, and Nebula Operator requires the use of DNS.</p>"},{"location":"nebula-operator/7.operator-faq/#does_nebula_operator_support_the_rolling_upgrade_feature_for_nebulagraph_clusters","title":"Does Nebula Operator support the rolling upgrade feature for NebulaGraph clusters?","text":"<p>Nebula Operator currently supports cluster upgrading from version 2.5.x to version 2.6.x.</p>"},{"location":"nebula-operator/7.operator-faq/#is_cluster_stability_guaranteed_if_using_local_storage","title":"Is cluster stability guaranteed if using local storage?","text":"<p>There is no guarantee. Using local storage means that the Pod is bound to a specific node, and Nebula Operator does not currently support failover in the event of a failure of the bound node.</p>"},{"location":"nebula-operator/7.operator-faq/#how_to_ensure_the_stability_of_a_cluster_when_scaling_the_cluster","title":"How to ensure the stability of a cluster when scaling the cluster?","text":"<p>It is suggested to back up data in advance so that you can roll back data in case of failure.</p>"},{"location":"nebula-operator/9.upgrade-nebula-cluster/","title":"Upgrade NebulaGraph clusters created with Nebula Operator","text":"<p>This topic introduces how to upgrade a NebulaGraph cluster created with Nebula Operator.</p>"},{"location":"nebula-operator/9.upgrade-nebula-cluster/#limits","title":"Limits","text":"<ul> <li>Only NebulaGraph clusters created with Nebula Operator are supported.</li> </ul> <ul> <li>Only upgrading NebulaGraph from 2.5.x to 2.6.x is supported.</li> </ul> <ul> <li>Upgrading clusters created via Nebula Operator of version 0.8.0 is not supported.</li> </ul>"},{"location":"nebula-operator/9.upgrade-nebula-cluster/#upgrade_a_nebulagraph_cluster_with_kubectl","title":"Upgrade a NebulaGraph cluster with Kubectl","text":""},{"location":"nebula-operator/9.upgrade-nebula-cluster/#prerequisites","title":"Prerequisites","text":"<p>You have created a NebulaGraph cluster with Kubectl. For details, see Create a NebulaGraph cluster with Kubectl.</p> <p>The version of the NebulaGraph cluster to be upgraded in this topic is <code>2.5.1</code>, and its YAML file name is <code>apps_v1alpha1_nebulacluster.yaml</code>.</p>"},{"location":"nebula-operator/9.upgrade-nebula-cluster/#steps","title":"Steps","text":"<ol> <li> <p>Check the image version of the services in the cluster.</p> <pre><code>kubectl get pods -l app.kubernetes.io/cluster=nebula  -o jsonpath=\"{.items[*].spec.containers[*].image}\" |tr -s '[[:space:]]' '\\n' |sort |uniq -c\n</code></pre> <p>Output:</p> <pre><code>      1 vesoft/nebula-graphd:v2.5.1\n      1 vesoft/nebula-metad:v2.5.1\n      3 vesoft/nebula-storaged:v2.5.1  </code></pre> </li> <li> <p>Edit the <code>apps_v1alpha1_nebulacluster.yaml</code> file by changing the values of all the <code>version</code> parameters from v2.5.1 to v2.6.2.</p> <p>The modified YAML file reads as follows:</p> <pre><code>apiVersion: apps.nebula-graph.io/v1alpha1\nkind: NebulaCluster\nmetadata:\nname: nebula\nspec:\ngraphd:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 1\nimage: vesoft/nebula-graphd\nversion: v2.6.2 //Change the value from v2.5.1 to v2.6.2.\nservice:\ntype: NodePort\nexternalTrafficPolicy: Local\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nmetad:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 1\nimage: vesoft/nebula-metad\nversion: v2.6.2 //Change the value from v2.5.1 to v2.6.2.\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nstoraged:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 3\nimage: vesoft/nebula-storaged\nversion: v2.6.2 //Change the value from v2.5.1 to v2.6.2.\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nreference:\nname: statefulsets.apps\nversion: v1\nschedulerName: default-scheduler\nimagePullPolicy: Always\n</code></pre> </li> <li> <p>Run the following command to apply the version update to the cluster CR.</p> <pre><code>kubectl apply -f apps_v1alpha1_nebulacluster.yaml\n</code></pre> </li> <li> <p>After waiting for about 2 minutes, run the following command to see if the image versions of the services in the cluster have been changed to v2.6.2.</p> <pre><code>kubectl get pods -l app.kubernetes.io/cluster=nebula  -o jsonpath=\"{.items[*].spec.containers[*].image}\" |tr -s '[[:space:]]' '\\n' |sort |uniq -c\n</code></pre> <p>Output:</p> <pre><code>      1 vesoft/nebula-graphd:v2.6.2\n      1 vesoft/nebula-metad:v2.6.2\n      3 vesoft/nebula-storaged:v2.6.2  </code></pre> </li> </ol>"},{"location":"nebula-operator/9.upgrade-nebula-cluster/#upgrade_a_nebulagraph_cluster_with_helm","title":"Upgrade a NebulaGraph cluster with Helm","text":""},{"location":"nebula-operator/9.upgrade-nebula-cluster/#prerequisites_1","title":"Prerequisites","text":"<p>You have created a NebulaGraph cluster with Helm. For details, see Create a NebulaGraph cluster with Helm.</p>"},{"location":"nebula-operator/9.upgrade-nebula-cluster/#steps_1","title":"Steps","text":"<ol> <li> <p>Update the information of available charts locally from chart repositories.</p> <pre><code>helm repo update\n</code></pre> </li> <li> <p>Set environment variables to your desired values.</p> <pre><code>export NEBULA_CLUSTER_NAME=nebula         # The desired NebulaGraph cluster name.\nexport NEBULA_CLUSTER_NAMESPACE=nebula    # The desired namespace where your NebulaGraph cluster locates.\n</code></pre> </li> <li> <p>Upgrade a NebulaGraph cluster.</p> <p>For example, upgrade a cluster to v2.6.2.</p> <pre><code>helm upgrade \"${NEBULA_CLUSTER_NAME}\" nebula-operator/nebula-cluster \\\n--namespace=\"${NEBULA_CLUSTER_NAMESPACE}\" \\\n--set nameOverride=${NEBULA_CLUSTER_NAME} \\\n--set nebula.version=v2.6.2\n</code></pre> <p>The value of <code>--set nebula.version</code> specifies the version of the cluster you want to upgrade to.</p> </li> <li> <p>Run the following command to check the status and version of the upgraded cluster.</p> <p>Check cluster status:</p> <pre><code>$ kubectl -n \"${NEBULA_CLUSTER_NAMESPACE}\" get pod -l \"app.kubernetes.io/cluster=${NEBULA_CLUSTER_NAME}\"\nNAME                READY   STATUS    RESTARTS   AGE\nnebula-graphd-0     1/1     Running   0          2m\nnebula-graphd-1     1/1     Running   0          2m\nnebula-metad-0      1/1     Running   0          2m\nnebula-metad-1      1/1     Running   0          2m\nnebula-metad-2      1/1     Running   0          2m\nnebula-storaged-0   1/1     Running   0          2m\nnebula-storaged-1   1/1     Running   0          2m\nnebula-storaged-2   1/1     Running   0          2m\n</code></pre> <p>Check cluster version:</p> <pre><code>$ kubectl get pods -l app.kubernetes.io/cluster=nebula  -o jsonpath=\"{.items[*].spec.containers[*].image}\" |tr -s '[[:space:]]' '\\n' |sort |uniq -c\n      1 vesoft/nebula-graphd:v2.6.2\n      1 vesoft/nebula-metad:v2.6.2\n      3 vesoft/nebula-storaged:v2.6.2\n</code></pre> </li> </ol>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/","title":"Deploy NebulaGraph clusters with Kubectl","text":""},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#prerequisites","title":"Prerequisites","text":"<p>Install Nebula Operator</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#create_clusters","title":"Create clusters","text":"<p>The following example shows how to create a NebulaGraph cluster by creating a cluster named <code>nebula</code>.</p> <ol> <li> <p>Create a file named <code>apps_v1alpha1_nebulacluster.yaml</code>.</p> <p>The file contents are as follows:</p> <pre><code>apiVersion: apps.nebula-graph.io/v1alpha1\nkind: NebulaCluster\nmetadata:\nname: nebula\nspec:\ngraphd:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 1\nimage: vesoft/nebula-graphd\nversion: v2.6.2\nservice:\ntype: NodePort\nexternalTrafficPolicy: Local\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nmetad:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 1\nimage: vesoft/nebula-metad\nversion: v2.6.2\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nstoraged:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 3\nimage: vesoft/nebula-storaged\nversion: v2.6.2\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nreference:\nname: statefulsets.apps\nversion: v1\nschedulerName: default-scheduler\nimagePullPolicy: Always\n</code></pre> <p>The parameters in the file are described as follows:</p> Parameter Default value Description <code>metadata.name</code> - The name of the created NebulaGraph cluster. <code>spec.graphd.replicas</code> <code>1</code> The numeric value of replicas of the Graphd service. <code>spec.graphd.images</code> <code>vesoft/nebula-graphd</code> The container image of the Graphd service. <code>spec.graphd.version</code> <code>v2.6.2</code> The version of the Graphd service. <code>spec.graphd.service</code> - The Service configurations for the Graphd service. <code>spec.graphd.logVolumeClaim.storageClassName</code> - The log disk storage configurations for the Graphd service. <code>spec.metad.replicas</code> <code>1</code> The numeric value of replicas of the Metad service. <code>spec.metad.images</code> <code>vesoft/nebula-metad</code> The container image of the Metad service. <code>spec.metad.version</code> <code>v2.6.2</code> The version of the Metad service. <code>spec.metad.dataVolumeClaim.storageClassName</code> - The data disk storage configurations for the Metad service. <code>spec.metad.logVolumeClaim.storageClassName</code> - The log disk storage configurations for the Metad service. <code>spec.storaged.replicas</code> <code>3</code> The numeric value of replicas of the Storaged service. <code>spec.storaged.images</code> <code>vesoft/nebula-storaged</code> The container image of the Storaged service. <code>spec.storaged.version</code> <code>v2.6.2</code> The version of the Storaged service. <code>spec.storaged.dataVolumeClaim.storageClassName</code> - The data disk storage configurations for the Storaged service. <code>spec.storaged.logVolumeClaim.storageClassName</code> - The log disk storage configurations for the Storaged service. <code>spec.reference.name</code> - The name of the dependent controller. <code>spec.schedulerName</code> - The scheduler name. <code>spec.imagePullPolicy</code> The image policy to pull the NebulaGraph image. For details, see Image pull policy. The image pull policy in Kubernetes. </li> <li> <p>Create a NebulaGraph cluster.</p> <pre><code>kubectl create -f apps_v1alpha1_nebulacluster.yaml\n</code></pre> <p>Output:</p> <pre><code>nebulacluster.apps.nebula-graph.io/nebula created\n</code></pre> </li> <li> <p>Check the status of the NebulaGraph cluster.</p> <pre><code>kubectl get nebulaclusters.apps.nebula-graph.io nebula\n</code></pre> <p>Output:</p> <pre><code>NAME     GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE\nnebula   1                1              1               1             3                  3                86s\n</code></pre> </li> </ol>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#scaling_clusters","title":"Scaling clusters","text":"<p>You can modify the value of <code>replicas</code> in <code>apps_v1alpha1_nebulacluster.yaml</code> to scale a NebulaGraph cluster.</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#scale_out_clusters","title":"Scale out clusters","text":"<p>The following shows how to scale out a NebulaGraph cluster by changing the number of Storage services to 5:</p> <ol> <li> <p>Change the value of the <code>storaged.replicas</code> from <code>3</code> to <code>5</code> in <code>apps_v1alpha1_nebulacluster.yaml</code>.</p> <pre><code>  storaged:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 5\nimage: vesoft/nebula-storaged\nversion: v2.6.2\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nreference:\nname: statefulsets.apps\nversion: v1\nschedulerName: default-scheduler\n</code></pre> </li> <li> <p>Run the following command to update the NebulaGraph cluster CR.</p> <pre><code>kubectl apply -f apps_v1alpha1_nebulacluster.yaml\n</code></pre> </li> <li> <p>Check the number of Storage services.</p> <pre><code>kubectl  get pods -l app.kubernetes.io/cluster=nebula\n</code></pre> <p>Output:</p> <pre><code>NAME                READY   STATUS    RESTARTS   AGE\nnebula-graphd-0     1/1     Running   0          2m\nnebula-metad-0      1/1     Running   0          2m\nnebula-storaged-0   1/1     Running   0          2m\nnebula-storaged-1   1/1     Running   0          2m\nnebula-storaged-2   1/1     Running   0          2m\nnebula-storaged-3   1/1     Running   0          5m\nnebula-storaged-4   1/1     Running   0          5m\n</code></pre> <p>As you can see above, the number of Storage services is scaled up to 5.</p> </li> </ol>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#scale_in_clusters","title":"Scale in clusters","text":"<p>The principle of scaling in a cluster is the same as scaling out a cluster. You scale in a cluster if the numeric value of the <code>replicas</code> in <code>apps_v1alpha1_nebulacluster.yaml</code> is changed smaller than the current number. For more information, see the Scale out clusters section above.</p> <p>Caution</p> <p>Nebula Operator currently only supports scaling Graph and Storage services and does not support scale Meta services.</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#delete_clusters","title":"Delete clusters","text":"<p>Run the following command to delete a NebulaGraph cluster with Kubectl:</p> <pre><code>kubectl delete -f apps_v1alpha1_nebulacluster.yaml\n</code></pre>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.1create-cluster-with-kubectl/#whats_next","title":"What's next","text":"<p>Connect to NebulaGraph databases</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/","title":"Deploy NebulaGraph clusters with Helm","text":""},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/#prerequisite","title":"Prerequisite","text":"<p>Install Nebula Operator</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/#create_clusters","title":"Create clusters","text":"<ol> <li> <p>Add the Nebula Operator chart repository to Helm\uff08If you have already added the chart, skip the 1-2 steps and start from step 3).</p> <pre><code>helm repo add nebula-operator https://vesoft-inc.github.io/nebula-operator/charts\n</code></pre> </li> <li> <p>Update information of available charts locally from chart repositories.</p> <pre><code>helm repo update\n</code></pre> </li> <li> <p>Set environment variables to your desired values.</p> <pre><code>export NEBULA_CLUSTER_NAME=nebula         # The desired NebulaGraph cluster name.\nexport NEBULA_CLUSTER_NAMESPACE=nebula    # The desired namespace where your NebulaGraph cluster locates.\nexport STORAGE_CLASS_NAME=gp2             # The desired StorageClass name in your NebulaGraph cluster.\n</code></pre> </li> <li> <p>Create a namespace for your NebulaGraph cluster\uff08If you have created one, skip this step\uff09.</p> <pre><code>kubectl create namespace \"${NEBULA_CLUSTER_NAMESPACE}\"\n</code></pre> </li> <li> <p>Apply the variables to the Helm chart to create a NebulaGraph cluster.</p> <pre><code>helm install \"${NEBULA_CLUSTER_NAME}\" nebula-operator/nebula-cluster \\\n--namespace=\"${NEBULA_CLUSTER_NAMESPACE}\" \\\n--set nameOverride=${NEBULA_CLUSTER_NAME} \\\n--set nebula.storageClassName=\"${STORAGE_CLASS_NAME}\"\n</code></pre> </li> <li> <p>Check the status of the NebulaGraph cluster you created.</p> <pre><code>kubectl -n \"${NEBULA_CLUSTER_NAMESPACE}\" get pod -l \"app.kubernetes.io/cluster=${NEBULA_CLUSTER_NAME}\"\n</code></pre> <p>Output:</p> <pre><code>NAME                READY   STATUS    RESTARTS   AGE\nnebula-graphd-0     1/1     Running   0          5m34s\nnebula-graphd-1     1/1     Running   0          5m34s\nnebula-metad-0      1/1     Running   0          5m34s\nnebula-metad-1      1/1     Running   0          5m34s\nnebula-metad-2      1/1     Running   0          5m34s\nnebula-storaged-0   1/1     Running   0          5m34s\nnebula-storaged-1   1/1     Running   0          5m34s\nnebula-storaged-2   1/1     Running   0          5m34s\n</code></pre> </li> </ol>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/#scaling_clusters","title":"Scaling clusters","text":"<p>You can scale a NebulaGraph cluster by defining the value of the <code>replicas</code> corresponding to the different services in the cluster.</p> <p>For example, run the following command to scale out a NebulaGraph cluster by changing the number of Storage services from 2 (the original value) to 5:  </p> <pre><code>helm upgrade \"${NEBULA_CLUSTER_NAME}\" nebula-operator/nebula-cluster \\\n--namespace=\"${NEBULA_CLUSTER_NAMESPACE}\" \\\n--set nameOverride=${NEBULA_CLUSTER_NAME} \\\n--set nebula.storageClassName=\"${STORAGE_CLASS_NAME}\" \\\n--set nebula.storaged.replicas=5\n</code></pre> <p>Similarly, you can scale in a NebulaGraph cluster by setting the value of the <code>replicas</code> corresponding to the different services in the cluster smaller than the original value.</p> <p>Caution</p> <p>Nebula Operator currently only supports scaling Graph and Storage services and does not support scale Meta services.</p> <p>You can click on nebula-cluster/values.yaml to see more configurable parameters of the nebula-cluster chart. For more information about the descriptions of configurable parameters, see Configuration parameters of the nebula-cluster Helm chart below.</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/#delete_clusters","title":"Delete clusters","text":"<p>Run the following command to delete a NebulaGraph cluster with Helm:</p> <pre><code>helm uninstall \"${NEBULA_CLUSTER_NAME}\" --namespace=\"${NEBULA_CLUSTER_NAMESPACE}\"\n</code></pre>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/#whats_next","title":"What's next","text":"<p>Connect to NebulaGraph Databases</p>"},{"location":"nebula-operator/3.deploy-nebula-graph-cluster/3.2create-cluster-with-helm/#configuration_parameters_of_the_nebula-cluster_helm_chart","title":"Configuration parameters of the nebula-cluster Helm chart","text":"Parameter Default value Description <code>nameOverride</code> <code>nil</code> Replaces the name of the chart in the <code>Chart.yaml</code> file. <code>nebula.version</code> <code>v2.6.2</code> The version of NebulaGraph. <code>nebula.imagePullPolicy</code> <code>IfNotPresent</code> The NebulaGraph image pull policy. For details, see Image pull policy. <code>nebula.storageClassName</code> <code>nil</code> The StorageClass name. StorageClass is the default persistent volume type. <code>nebula.schedulerName</code> <code>default-scheduler</code> The scheduler name of a NebulaGraph cluster. <code>nebula.reference</code> <code>{\"name\": \"statefulsets.apps\", \"version\": \"v1\"}</code> The workload referenced for a NebulaGraph cluster. <code>nebula.graphd.image</code> <code>vesoft/nebula-graphd</code> The image name for a Graphd service. Uses the value of <code>nebula.version</code> as its version. <code>nebula.graphd.replicas</code> <code>2</code> The number of the Graphd service. <code>nebula.graphd.env</code> <code>[]</code> The environment variables for the Graphd service. <code>nebula.graphd.resources</code> <code>{\"resources\":{\"requests\":{\"cpu\":\"500m\",\"memory\":\"500Mi\"},\"limits\":{\"cpu\":\"1\",\"memory\":\"1Gi\"}}}</code> The resource configurations for the Graphd service. <code>nebula.graphd.logStorage</code> <code>500Mi</code> The log disk storage capacity for the Graphd service. <code>nebula.graphd.podLabels</code> <code>{}</code> Labels for the Graphd pod in a NebulaGraph cluster. <code>nebula.graphd.podAnnotations</code> <code>{}</code> Pod annotations for the Graphd pod in a NebulaGraph cluster. <code>nebula.graphd.nodeSelector</code> <code>{}</code> Labels for the Graphd pod to be scheduled to the specified node. <code>nebula.graphd.tolerations</code> <code>{}</code> Tolerations for the Graphd pod. <code>nebula.graphd.affinity</code> <code>{}</code> Affinity for the Graphd pod. <code>nebula.graphd.readinessProbe</code> <code>{}</code> ReadinessProbe for the Graphd pod. <code>nebula.graphd.sidecarContainers</code> <code>{}</code> Sidecar containers for the Graphd pod. <code>nebula.graphd.sidecarVolumes</code> <code>{}</code> Sidecar volumes for the Graphd pod. <code>nebula.metad.image</code> <code>vesoft/nebula-metad</code> The image name for a Metad service. Uses the value of <code>nebula.version</code> as its version. <code>nebula.metad.replicas</code> <code>3</code> The number of the Metad service. <code>nebula.metad.env</code> <code>[]</code> The environment variables for the Metad service. <code>nebula.metad.resources</code> <code>{\"resources\":{\"requests\":{\"cpu\":\"500m\",\"memory\":\"500Mi\"},\"limits\":{\"cpu\":\"1\",\"memory\":\"1Gi\"}}}</code> The resource configurations for the Metad service. <code>nebula.metad.logStorage</code> <code>500Mi</code> The log disk capacity for the Metad service. <code>nebula.metad.dataStorage</code> <code>1Gi</code> The data disk capacity for the Metad service. <code>nebula.metad.podLabels</code> <code>{}</code> Labels for the Metad pod in a NebulaGraph cluster. <code>nebula.metad.podAnnotations</code> <code>{}</code> Pod annotations for the Metad pod in a NebulaGraph cluster. <code>nebula.metad.nodeSelector</code> <code>{}</code> Labels for the Metad pod to be scheduled to the specified node. <code>nebula.metad.tolerations</code> <code>{}</code> Tolerations for the Metad pod. <code>nebula.metad.affinity</code> <code>{}</code> Affinity for the Metad pod. <code>nebula.metad.readinessProbe</code> <code>{}</code> ReadinessProbe for the Metad pod. <code>nebula.metad.sidecarContainers</code> <code>{}</code> Sidecar containers for the Metad pod. <code>nebula.metad.sidecarVolumes</code> <code>{}</code> Sidecar volumes for the Metad pod. <code>nebula.storaged.image</code> <code>vesoft/nebula-storaged</code> The image name for a Storaged service. Uses the value of <code>nebula.version</code> as its version. <code>nebula.storaged.replicas</code> <code>3</code> The number of Storaged services. <code>nebula.storaged.env</code> <code>[]</code> The environment variables for Storaged services. <code>nebula.storaged.resources</code> <code>{\"resources\":{\"requests\":{\"cpu\":\"500m\",\"memory\":\"500Mi\"},\"limits\":{\"cpu\":\"1\",\"memory\":\"1Gi\"}}}</code> The resource configurations for Storagedss services. <code>nebula.storaged.logStorage</code> <code>500Mi</code> The log disk capacity for the Metad service. <code>nebula.storaged.dataStorage</code> <code>1Gi</code> The data disk capacity for the Metad service. <code>nebula.storaged.podLabels</code> <code>{}</code> Labels for the Metad pod in a NebulaGraph cluster. <code>nebula.storaged.podAnnotations</code> <code>{}</code> Pod annotations for the Metad pod in a NebulaGraph cluster. <code>nebula.storaged.nodeSelector</code> <code>{}</code> Labels for the Metad pod to be scheduled to the specified node. <code>nebula.storaged.tolerations</code> <code>{}</code> Tolerations for the Metad pod. <code>nebula.storaged.affinity</code> <code>{}</code> Affinity for the Metad pod. <code>nebula.storaged.readinessProbe</code> <code>{}</code> ReadinessProbe for the Metad pod. <code>nebula.storaged.sidecarContainers</code> <code>{}</code> Sidecar containers for the Metad pod. <code>nebula.storaged.sidecarVolumes</code> <code>{}</code> Sidecar volumes for the Metad pod. <code>imagePullSecrets</code> <code>[]</code> The Secret to pull the NebulaGraph cluster image."},{"location":"nebula-operator/8.custom-cluster-configurations/8.1.custom-conf-parameter/","title":"Customize configuration parameters for a NebulaGraph cluster","text":"<p>Meta, Storage, and Graph services in a Nebula Cluster have their configurations, which are defined as <code>config</code> in the YAML file of the CR instance (NebulaGraph cluster) you created. The settings in <code>config</code> are mapped and loaded into the ConfigMap of the corresponding service in Kubernetes.</p> <p>Note</p> <p>It is not available to customize configuration parameters for Nebula Clusters deployed with Helm.</p> <p>The structure of <code>config</code> is as follows.</p> <pre><code>Config map[string]string `json:\"config,omitempty\"`\n</code></pre>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.1.custom-conf-parameter/#prerequisites","title":"Prerequisites","text":"<p>You have created a NebulaGraph cluster. For how to create a cluster with Kubectl, see Create a cluster with Kubectl. </p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.1.custom-conf-parameter/#steps","title":"Steps","text":"<p>The following example uses a cluster named <code>nebula</code> to show how to set <code>config</code> for the Graph service in a NebulaGraph cluster.</p> <ol> <li> <p>Run the following command to access the edit page of the <code>nebula</code> cluster.</p> <pre><code>kubectl edit nebulaclusters.apps.nebula-graph.io nebula\n</code></pre> </li> <li> <p>Add <code>enable_authorize</code> and <code>auth_type</code> under <code>spec.graphd.config</code>.</p> <pre><code>apiVersion: apps.nebula-graph.io/v1alpha1\nkind: NebulaCluster\nmetadata:\nname: nebula\nnamespace: default\nspec:\ngraphd:\nresources:\nrequests:\ncpu: \"500m\"\nmemory: \"500Mi\"\nlimits:\ncpu: \"1\"\nmemory: \"1Gi\"\nreplicas: 1\nimage: vesoft/nebula-graphd\nversion: v2.6.2\nstorageClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: gp2\nconfig: // Custom configuration parameters for the Graph service in a cluster.\n\"enable_authorize\": \"true\"\n\"auth_type\": \"password\"\n...\n</code></pre> </li> </ol> <p>After customizing the parameters <code>enable_authorize</code> and <code>auth_type</code>, the configurations in the corresponding ConfigMap (<code>nebula-graphd</code>) of the Graph service will be overwritten.</p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.1.custom-conf-parameter/#learn_more","title":"Learn more","text":"<p>For more information on the configuration parameters of Meta, Storage, and Graph services, see Configurations.</p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.2.pv-reclaim/","title":"Reclaim PVs","text":"<p>Nebula Operator uses PVs (Persistent Volumes) and PVCs (Persistent Volume Claims) to store persistent data. If you accidentally deletes a NebulaGraph cluster, PV and PVC objects and the relevant data will be retained to ensure data security.</p> <p>You can define whether to reclaim PVs or not in the configuration file of the cluster's CR instance with the parameter <code>enablePVReclaim</code>.</p> <p>If you need to release a graph space and retain the relevant data, update your nebula cluster by setting the parameter <code>enablePVReclaim</code> to <code>true</code>.</p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.2.pv-reclaim/#prerequisites","title":"Prerequisites","text":"<p>You have created a cluster. For how to create a cluster with Kubectl, see Create a cluster with Kubectl. </p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.2.pv-reclaim/#steps","title":"Steps","text":"<p>The following example uses a cluster named <code>nebula</code> to show how to set <code>enablePVReclaim</code>:</p> <ol> <li> <p>Run the following command to access the edit page of the <code>nebula</code> cluster.</p> <pre><code>kubectl edit nebulaclusters.apps.nebula-graph.io nebula\n</code></pre> </li> <li> <p>Add <code>enablePVReclaim</code> and set its value to <code>true</code> under <code>spec</code>.</p> <pre><code>apiVersion: apps.nebula-graph.io/v1alpha1\nkind: NebulaCluster\nmetadata:\nname: nebula\nspec:\nenablePVReclaim: true  //Set its value to true.\ngraphd:\nimage: vesoft/nebula-graphd\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nreplicas: 1\nresources:\nlimits:\ncpu: \"1\"\nmemory: 1Gi\nrequests:\ncpu: 500m\nmemory: 500Mi\nversion: v2.6.2\nimagePullPolicy: IfNotPresent\nmetad:\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nimage: vesoft/nebula-metad\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nreplicas: 1\nresources:\nlimits:\ncpu: \"1\"\nmemory: 1Gi\nrequests:\ncpu: 500m\nmemory: 500Mi\nversion: v2.6.2\nnodeSelector:\nnebula: cloud\nreference:\nname: statefulsets.apps\nversion: v1\nschedulerName: default-scheduler\nstoraged:\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nimage: vesoft/nebula-storaged\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nreplicas: 3\nresources:\nlimits:\ncpu: \"1\"\nmemory: 1Gi\nrequests:\ncpu: 500m\nmemory: 500Mi\nversion: v2.6.2\n...    </code></pre> </li> </ol>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.3.balance-data-when-scaling-storage/","title":"Balance storage data after scaling out","text":"<p>After the Storage service is scaled out, you can decide whether to balance the data in the Storage service. </p> <p>The scaling out of the NebulaGraph's Storage service is divided into two stages. In the first stage, the status of all pods is changed to <code>Ready</code>. In the second stage, the commands of <code>BALANCE DATA</code>\u548c<code>BALANCE LEADER</code> are executed to balance data. These two stages decouple the scaling out process of the controller replica from the balancing data process, so that you can choose to perform the data balancing operation during low traffic period. The decoupling of the scaling out process from the balancing process can effectively reduce the impact on online services during data migration.</p> <p>You can define whether to balance data automatically or not with the parameter <code>enableAutoBalance</code> in the configuration file of the CR instance of the cluster you created.</p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.3.balance-data-when-scaling-storage/#prerequisites","title":"Prerequisites","text":"<p>You have created a NebulaGraph cluster. For how to create a cluster with Kubectl, see Create a cluster with Kubectl. </p>"},{"location":"nebula-operator/8.custom-cluster-configurations/8.3.balance-data-when-scaling-storage/#steps","title":"Steps","text":"<p>The following example uses a cluster named <code>nebula</code> to show how to set <code>enableAutoBalance</code>.</p> <ol> <li> <p>Run the following command to access the edit page of the <code>nebula</code> cluster.</p> <pre><code>kubectl edit nebulaclusters.apps.nebula-graph.io nebula\n</code></pre> </li> <li> <p>Add <code>enableAutoBalance</code> and set its value to <code>true</code> under <code>spec.storaged</code>.</p> <pre><code>apiVersion: apps.nebula-graph.io/v1alpha1\nkind: NebulaCluster\nmetadata:\nname: nebula\nspec:\ngraphd:\nimage: vesoft/nebula-graphd\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nreplicas: 1\nresources:\nlimits:\ncpu: \"1\"\nmemory: 1Gi\nrequests:\ncpu: 500m\nmemory: 500Mi\nversion: v2.6.2\nimagePullPolicy: IfNotPresent\nmetad:\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nimage: vesoft/nebula-metad\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nreplicas: 1\nresources:\nlimits:\ncpu: \"1\"\nmemory: 1Gi\nrequests:\ncpu: 500m\nmemory: 500Mi\nversion: v2.6.2\nnodeSelector:\nnebula: cloud\nreference:\nname: statefulsets.apps\nversion: v1\nschedulerName: default-scheduler\nstoraged:\nenableAutoBalance: true   //Set its value to true which means storage data will be balanced after the Storage service is scaled out.\ndataVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nimage: vesoft/nebula-storaged\nlogVolumeClaim:\nresources:\nrequests:\nstorage: 2Gi\nstorageClassName: fast-disks\nreplicas: 3\nresources:\nlimits:\ncpu: \"1\"\nmemory: 1Gi\nrequests:\ncpu: 500m\nmemory: 500Mi\nversion: v2.6.2\n...    </code></pre> <ul> <li>When the value of <code>enableAutoBalance</code> is set to <code>true</code>, the Storage data will be automatically balanced after the Storage service is scaled out.</li> </ul> <ul> <li>When the value of <code>enableAutoBalance</code> is set to <code>false</code>, the Storage data will not be automatically balanced after the Storage service is scaled out.</li> </ul> <ul> <li>When the <code>enableAutoBalance</code> parameter is not set, the system will not automatically balance Storage data by default after the Storage service is scaled out. </li> </ul> </li> </ol>"},{"location":"nebula-studio/about-studio/st-ug-check-updates/","title":"Check updates","text":"<p>Studio is in development. Users can view the latest releases features through Changelog.</p> <p>To view the Changelog, on the upper-right corner of the page, click the version and then New version.</p> <p></p>"},{"location":"nebula-studio/about-studio/st-ug-limitations/","title":"Limitations","text":"<p>This topic introduces the limitations of Studio.</p>"},{"location":"nebula-studio/about-studio/st-ug-limitations/#nebulagraph_versions","title":"NebulaGraph versions","text":"<p>Note</p> <p>The Studio version is released independently of the NebulaGraph core. The correspondence between the versions of Studio and the NebulaGraph core, as shown in the table below.</p> NebulaGraph version Studio version 1.x 1.x 2.0 &amp; 2.0.1 2.x 2.5.0 &amp; 2.5.1 3.0.0 2.6.0 3.1.0 2.6.1 3.1.0"},{"location":"nebula-studio/about-studio/st-ug-limitations/#architecture","title":"Architecture","text":"<p>For now, Docker-based and RPM-based Studio v3.x supports x86_64 architecture only.</p>"},{"location":"nebula-studio/about-studio/st-ug-limitations/#upload_data","title":"Upload data","text":"<p>Only CSV files without headers can be uploaded, but no limitations are applied to the size and store period for a single file. The maximum data volume depends on the storage capacity of your machine.</p>"},{"location":"nebula-studio/about-studio/st-ug-limitations/#data_backup","title":"Data backup","text":"<p>For now, you can export the queried results in the CSV format on the Console page and export data in the CSV format on the Explore page. No other backup methods are available.</p>"},{"location":"nebula-studio/about-studio/st-ug-limitations/#ngql_statements","title":"nGQL statements","text":"<p>On the Console page of Docker-based and RPM-based Studio v3.x, all the nGQL syntaxes except these are supported:</p> <ul> <li><code>USE &lt;space_name&gt;</code>: You cannot run such a statement on the Console page to choose a graph space. As an alternative, you can click a graph space name in the drop-down list of Current Graph Space.</li> <li>You cannot use line breaks (\\). As an alternative, you can use the Enter key to split a line.</li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-limitations/#browser","title":"Browser","text":"<p>We recommend that you use Chrome to get access to Studio.</p>"},{"location":"nebula-studio/about-studio/st-ug-release-note/","title":"Change Log","text":""},{"location":"nebula-studio/about-studio/st-ug-release-note/#v311_20220525","title":"v3.1.1 (2022.05.25)","text":"<ul> <li>Fix:<ul> <li>Fix gateway crash.</li> </ul> </li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-release-note/#v310_20211029","title":"v3.1.0 (2021.10.29)","text":"<ul> <li>Feature enhancements:<ul> <li>Compatible with NebulaGraph v2.6.0.</li> <li>Added the use of Helm to deploy and start Studio in the Kubernetes cluster.</li> <li>Added GEO.</li> <li>Explorer<ul> <li>Added the function of modifying the vertex icon.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Fix:<ul> <li>Schema<ul> <li>Fix the problem that some operations of the tag/edge/property named after keywords will report errors.</li> <li>Fix the problem of incomplete data types by adding date/time/datetime/int32/int16/int8.</li> </ul> </li> </ul> </li> </ul> <ul> <li>Compatibility:<ul> <li>Remove Studio's dependency on nebula-importer and use http-gateway to be compatible with related functions.</li> </ul> </li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-release-note/#v300_20210813","title":"v3.0.0 (2021.08.13)","text":"<ul> <li> <p>Feature enhancements:</p> <ul> <li>Compatible with NebulaGraph v2.5.0.</li> <li>Supported adding <code>COMMENT</code> in Space, Tag, Edge Type, Index while configuration Schema.</li> </ul> </li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-shortcuts/","title":"Shortcuts","text":"<p>This topic lists the shortcuts supported in Studio.</p> Description Operation Run nGQL statements in Console Shift + Enter Select multiple vertices in Schema Shift + Left-click Zoom out graph in Schema Shift + \u2018-\u2019 Zoom in graph in Schema Shift + \u2018+\u2019 Show graph in Schema Shift + \u2018l\u2019 Rollback in Schema Shift + \u2018z\u2019 Delete map in Schema Selected + Shift + 'del' Expand a vertex in Schema Double Left-click or Shift + Enter"},{"location":"nebula-studio/about-studio/st-ug-terms/","title":"Explanations of terms","text":"<p>This topic provides explanations of terms you may need to know when using Studio.</p> <ul> <li>NebulaGraph Studio: Referred to as Studio in this manual. Studio is a browser-based visualization tool to manage NebulaGraph. It provides you with a graphical user interface to manipulate graph schemas, import data, explore graph data, and run nGQL statements to retrieve data.</li> </ul> <ul> <li>NebulaGraph: NebulaGraph is a distributed, scalable, and lightning-fast graph database. It is the optimal solution in the world capable of hosting graphs with dozens of billions of vertices (nodes) and trillions of edges (relationships) with millisecond latency. For details, refer to NebulaGraph User Manual.</li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-what-is-graph-studio/","title":"What is NebulaGraph Studio","text":"<p>NebulaGraph Studio (Studio in short) is a browser-based visualization tool to manage NebulaGraph. It provides you with a graphical user interface to manipulate graph schemas, import data, explore graph data, and run nGQL statements to retrieve data. With Studio, you can quickly become a graph exploration expert from scratch. Users can view the latest source code in the NebulaGraph GitHub repository, see nebula-studio for details.</p>"},{"location":"nebula-studio/about-studio/st-ug-what-is-graph-studio/#released_versions","title":"Released versions","text":"<p>You can deploy Studio using the following methods:</p> <ul> <li>Docker-based. You can deploy Studio with Docker and connect it to NebulaGraph. For more information, see Docker-based Studio.</li> <li>RPM-based. You can deploy Studio with RPM and connect it to NebulaGraph. For more information, see RPM-based Studio.</li> <li>Tar-based. You can deploy Studio with tar and connect it to NebulaGraph. For more information, see tar-based Studio.</li> <li>Helm-based. You can deploy Studio with Helm in the Kubernetes cluster and connect it to NebulaGraph. For more information, see Helm-based Studio.</li> </ul> <p>The functions of the above four deployment methods are the same and may be restricted when using Studio. For more information, see Limitations.</p>"},{"location":"nebula-studio/about-studio/st-ug-what-is-graph-studio/#features","title":"Features","text":"<p>Studio provides these features:</p> <ul> <li> <p>Graphical user interface (GUI) makes NebulaGraph management more user-friendly:</p> <ul> <li>On the Schema page, you can manage schemas with a graphical user interface. It helps you quickly get started with NebulaGraph.</li> </ul> <ul> <li>On the Console page, you can run nGQL statements and read the results in a human-friendly way.</li> </ul> <ul> <li>On the Import page, you can operate batch import of vertex and edge data with clicks, and view a real-time import log.</li> </ul> </li> </ul> <ul> <li>On the Explore page, you can explore the graph data. It helps you dig the relationships among data and improves the efficiency of data analysis.</li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-what-is-graph-studio/#scenarios","title":"Scenarios","text":"<p>You can use Studio in one of these scenarios:</p> <ul> <li>You have a dataset, and you want to explore and analyze data in a visualized way. You can use Docker Compose to deploy NebulaGraph and then use Studio to explore or analyze data in a visualized way.  </li> </ul> <ul> <li>You have deployed NebulaGraph and imported a dataset. You want to use a GUI to run nGQL statements or explore and analyze graph data in a visualized way.  </li> </ul> <ul> <li>You are a beginner of nGQL (NebulaGraph Query Language) and you prefer to use a GUI rather than a command-line interface (CLI) to learn the language.  </li> </ul>"},{"location":"nebula-studio/about-studio/st-ug-what-is-graph-studio/#authentication","title":"Authentication","text":"<p>Authentication is not enabled in NebulaGraph by default. Users can log into Studio with the <code>root</code> account and any password.</p> <p>When NebulaGraph enables authentication, users can only sign into Studio with the specified account. For more information, see Authentication.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-connect/","title":"Connect to NebulaGraph","text":"<p>After successfully launching Studio, you need to configure to connect to NebulaGraph. This topic describes how Studio connects to the NebulaGraph database.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-connect/#prerequisites","title":"Prerequisites","text":"<p>Before connecting to the NebulaGraph database, you need to confirm the following information:</p> <ul> <li>The NebulaGraph services and Studio are started. For more information, see Deploy Studio.</li> </ul> <ul> <li> <p>You have the local IP address and the port used by the Graph service of NebulaGraph. The default port is <code>9669</code>.  </p> <p>Note</p> <p>Run <code>ifconfig</code> or <code>ipconfig</code> on the machine to get the IP address.</p> </li> </ul> <ul> <li> <p>You have a NebulaGraph account and its password.</p> <p>Note</p> <p>If authentication is enabled in NebulaGraph and different role-based accounts are created, you must use the assigned account to connect to NebulaGraph. If authentication is disabled, you can use the <code>root</code> and any password to connect to NebulaGraph. For more information, see NebulaGraph Database Manual.</p> </li> </ul>"},{"location":"nebula-studio/deploy-connect/st-ug-connect/#procedure","title":"Procedure","text":"<p>To connect Studio to NebulaGraph, follow these steps:</p> <ol> <li> <p>On the Config Server page of Studio, configure these fields:</p> <ul> <li> <p>Host: Enter the IP address and the port of the Graph service of NebulaGraph. The valid format is <code>IP:port</code>. The default port is <code>9669</code>.  </p> <p>Note</p> <p>When NebulaGraph and Studio are deployed on the same machine, you must enter the IP address of the machine, but not <code>127.0.0.1</code> or <code>localhost</code>, in the Host field.</p> </li> </ul> <ul> <li> <p>Username and Password: Fill in the log in account according to the authentication settings of NebulaGraph.</p> <ul> <li>If authentication is not enabled, you can use <code>root</code> and any password as the username and its password.</li> </ul> <ul> <li>If authentication is enabled and no account information has been created, you can only log in as GOD role and use <code>root</code> and <code>nebula</code> as the username and its password.</li> </ul> <ul> <li>If authentication is enabled and different users are created and assigned roles, users in different roles log in with their accounts and passwords.</li> </ul> </li> </ul> <p></p> </li> <li> <p>After the configuration, click the Connect button.</p> <p>If you can see the Explore page, Studio is successfully connected to NebulaGraph.</p> <p></p> </li> </ol> <p>One session continues for up to 30 minutes. If you do not operate Studio within 30 minutes, the active session will time out and you must connect to NebulaGraph again.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-connect/#next_to_do","title":"Next to do","text":"<p>When Studio is successfully connected to NebulaGraph, you can do these operations:</p> <ul> <li>If your account has GOD or ADMIN privilege, you can create a schema on the Console page or on the Schema page.</li> </ul> <ul> <li>If your account has GOD, ADMIN, DBA, or USER privilege, you can batch import data on the Import page or insert data with nGQL statements on the Console page.</li> </ul> <ul> <li>If your account has GOD, ADMIN, DBA, USER, or GUEST privilege, you can retrieve data with nGQL statements on the Console page or explore and analyze data on the Explore page.</li> </ul>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy-by-helm/","title":"Deploy Studio with Helm","text":"<p>This topic describes how to deploy Studio with Helm.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy-by-helm/#prerequisites","title":"Prerequisites","text":"<p>Before installing Studio, you need to install the following software and ensure the correct version of the software:</p> Software Requirement Kubernetes &gt;= 1.14 Helm &gt;= 3.2.0"},{"location":"nebula-studio/deploy-connect/st-ug-deploy-by-helm/#install","title":"Install","text":"<ol> <li> <p>Use Git to clone the source code of Studio to the host.</p> <pre><code>$ git clone https://github.com/vesoft-inc/nebula-studio.git\n</code></pre> </li> <li> <p>Make the <code>nebula-studio</code> directory the current working directory.    <code>bash     $ cd nebula-studio</code></p> </li> <li> <p>Assume using release name:<code>my-studio</code>, installed Studio in Helm Chart.     <pre><code>$ helm upgrade --install my-studio --set service.type=NodePort --set service.port=30070 deployment/helm\n</code></pre></p> </li> <li> <p>When Studio is started, use <code>http://address-of-node:30070/</code> to get access to Studio.</p> <p>If you can see the Config Server page on the browser, Studio is started successfully.</p> <p></p> </li> </ol>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy-by-helm/#uninstall","title":"Uninstall","text":"<pre><code> $ helm uninstall my-studio\n</code></pre>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy-by-helm/#next_to_do","title":"Next to do","text":"<p>On the Config Server page, connect Docker-based Studio to NebulaGraph. For more information, see Connect to NebulaGraph.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy-by-helm/#configuration","title":"Configuration","text":"Parameter Default value Description replicaCount 0 The number of replicas for Deployment. image.httpGateway.name vesoft/nebula-http-gateway The image name of nebula-http-gateway. image.nebulaStudio.name vesoft/nebula-graph-studio The image name of nebula-graph-studio. image.nginx.name nginx The image name of nginx. image.httpGateway.version v2.1.1 The image version of nebula-http-gateway. image.nebulaStudio.version v3.1.0 The image version of nebula-graph-studio. image.nginx.version alpine The image version of nginx. service.type ClusterIP The service type, which should be one of 'NodePort', 'ClusterIP', and 'LoadBalancer'. service.port 7001 The expose port for nebula-graph-studio's web. resources.httpGateway {} The resource limits/requests for nebula-http-gateway. resources.nebulaStudio {} The resource limits/requests for nebula-studio. resources.nginx {} The resource limits/requests for nginx. persistent.storageClassName \"\" The name of storageClass. The default value will be used if not specified. persistent.size 5Gi The persistent volume size."},{"location":"nebula-studio/deploy-connect/st-ug-deploy/","title":"Deploy Studio","text":"<p>This topic describes how to deploy Studio locally by Docker, RPM, and tar package.</p> <p>Note</p> <p>You can also try some functions online in Studio.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#rpm-based_studio","title":"RPM-based Studio","text":""},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#prerequisites","title":"Prerequisites","text":"<p>Before you deploy RPM-based Studio, you must confirm that:</p> <ul> <li>The NebulaGraph services are deployed and started. For more information, see NebulaGraph Database Manual.</li> </ul> <ul> <li> <p>If your Linux distribution is CentOS, install <code>lsof</code> and Node.js of versions above v10.16.0+.</p> <p>Note</p> <p><code>node</code> and <code>npm</code> should be installed in <code>/usr/bin/</code> directory. Avoid the situation that the node command cannot be found during RPM installation.   For example, the default directory of nodejs12 is in <code>/opt/rh/rh-nodejs12</code>, you can use following commands to build soft link:</p> <pre><code>$ sudo ln -s /opt/rh/rh-nodejs12/root/usr/bin/node /usr/bin/node\n$ sudo ln -s /opt/rh/rh-nodejs12/root/usr/bin/npm /usr/bin/npm\n</code></pre> </li> </ul> <ul> <li> <p>Before the installation starts, the following ports are not occupied.</p> Port Description 7001 Web service provided by Studio. 8080 HTTP service provided by Nebula HTTP Gateway. </li> </ul>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#install","title":"Install","text":"<ol> <li> <p>Select and download the RPM package according to your needs. It is recommended to select the latest version. Common links are as follows:</p> Installation package Checksum Nebula version nebula-graph-studio-3.1.1-1.x86_64.rpm nebula-graph-studio-3.1.1-1.x86_64.rpm.sha256 v2.6.2 </li> <li> <p>Use <code>sudo rpm -i &lt;rpm&gt;</code> to install RPM package.</p> <p>For example, install Studio 3.1.1, use the following command:  <pre><code>sudo rpm -i nebula-graph-studio-3.1.1-1.x86_64.rpm\n</code></pre></p> <p>When the screen returns the following message, it means that the PRM-based Studio has been successfully started.</p> <pre><code>egg started on http://0.0.0.0:7001\nnohup: Add the output to \"nohup.out\"\n</code></pre> </li> <li> <p>When Docker-based Studio is started, use <code>http://ip address:7001</code> to get access to Studio.</p> <p>Note</p> <p>Run <code>ifconfig</code> or <code>ipconfig</code> to get the IP address of the machine where Docker-based Studio is running. On the machine running Docker-based Studio, you can use <code>http://localhost:7001</code> to get access to Studio.</p> <p>If you can see the Config Server page on the browser, Docker-based Studio is started successfully.</p> <p></p> </li> </ol>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#uninstall","title":"Uninstall","text":"<p>Users can uninstall Studio using the following command:</p> <pre><code>sudo rpm -e nebula-graph-studio-3.1.1-1.x86_64\n</code></pre>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#exception_handling","title":"Exception handling","text":"<p>If the automatic start fails during the installation process or you want to manually start or stop the service, use the following command:</p> <ul> <li>Start the service manually <pre><code>bash /usr/local/nebula-graph-studio/scripts/rpm/start.sh\n</code></pre></li> </ul> <ul> <li>Stop the service manually <pre><code>bash /usr/local/nebula-graph-studio/scripts/rpm/stop.sh\n</code></pre></li> </ul> <p>If you encounter an error <code>bind EADDRINUSE 0.0.0.0:7001</code> when starting the service, you can use the following command to check port 7001 usage. <pre><code>lsof -i:7001\n</code></pre></p> <p>If the port is occupied and the process on that port cannot be terminated, you can use the following command to change Studio service port and restart the service.</p> <pre><code> //Open the configuration file\n $ vi config/config.default.js\n\n //Change the port number\n ...\n     config.cluster = {\nlisten: {\nport: 7001, // Modify this port number and change it to any one currently available\n             hostname: '0.0.0.0',\n         },\n     };\n...\n\n //Restart npm\n $ npm run start\n</code></pre>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#tar-based_studio","title":"tar-based Studio","text":""},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#prerequisites_1","title":"Prerequisites","text":"<p>Before you deploy tar-based Studio , you must do a check of these:</p> <ul> <li>The NebulaGraph services are deployed and started. For more information, see NebulaGraph Database Manual.</li> </ul> <ul> <li> <p>The Linux distribution is CentOS, installed <code>lsof</code> and Node.js of version above v10.16.0+.</p> <p>Note</p> <p><code>node</code> and <code>npm</code> should be installed in <code>/usr/bin/</code> directory. Avoid the situation that the node command cannot be found during RPM installation.   For example, the default directory of nodejs12 is in <code>/opt/rh/rh-nodejs12</code>, you can use following commands to build soft link:</p> <pre><code>$ sudo ln -s /opt/rh/rh-nodejs12/root/usr/bin/node /usr/bin/node\n$ sudo ln -s /opt/rh/rh-nodejs12/root/usr/bin/npm /usr/bin/npm\n</code></pre> </li> </ul> <ul> <li> <p>Before the installation starts, the following ports are not occupied.</p> Port Description 7001 Web service provided by Studio 8080 Nebula-http-gateway, Client's HTTP service </li> </ul>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#install_1","title":"Install","text":"<ol> <li> <p>Select and download the tar package according to your needs. It is recommended to select the latest version. Common links are as follows:</p> Installation package Studio version nebula-graph-studio-3.1.1-1.x86_64.tar.gz 3.1.1 </li> <li> <p>Use <code>tar -xvf</code> to decompress the tar package.</p> <pre><code>tar -xvf nebula-graph-studio-3.1.1-1.x86_64.tar.gz\n</code></pre> </li> </ol>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#procedure","title":"Procedure","text":"<p>Note</p> <p>The root directory <code>nebula-graph-studio</code> has two installation packages: nebula-graph-studio and nebula-importer. You need to deploy and start the services separately on the same machine to complete the deployment of Studio.</p> <ol> <li> <p>Deploy and start nebula-http-gateway.</p> <pre><code>$ cd nebula-http-gateway\n$ nohup ./nebula-httpd &amp;\n</code></pre> </li> <li> <p>Deploy and start nebula-graph-studio.</p> <pre><code>$ cd nebula-graph-studio\n$ npm run start\n</code></pre> <p>Caution</p> <p>Studio 2.6.2 version is not dependent on nebula-importer, so the installation and deployment procedure is different from Studio v3.0.0.</p> </li> <li> <p>When tar-based Studio is started, use <code>http://ip address:7001</code> to get access to Studio.</p> <p>Note</p> <p>Run <code>ifconfig</code> or <code>ipconfig</code> to get the IP address of the machine where Docker-based Studio is running. On the machine running Docker-based Studio, you can use <code>http://localhost:7001</code> to get access to Studio.</p> <p>If you can see the Config Server page on the browser, Docker-based Studio is started successfully.</p> <p></p> </li> </ol>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#stop_service","title":"Stop Service","text":"<p>You can use <code>kill pid</code> to stop the service: <pre><code>$ kill $(lsof -t -i :8080) # stop nebula-http-gateway\n$ cd nebula-graph-studio\n$ npm run stop # stop nebula-graph-studio\n</code></pre></p>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#docker-based_studio","title":"Docker-based Studio","text":""},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#prerequisites_2","title":"Prerequisites","text":"<p>Before you deploy Docker-based Studio, you must do a check of these:</p> <ul> <li>The NebulaGraph services are deployed and started. For more information, see NebulaGraph Database Manual.</li> </ul> <ul> <li>On the machine where Studio will run, Docker Compose is installed and started. For more information, see Docker Compose Documentation.</li> </ul> <ul> <li> <p>Before the installation starts, the following ports are not occupied.</p> Port Description 7001 Web service provided by Studio 8080 Nebula-http-gateway, Client's HTTP service </li> </ul>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#procedure_1","title":"Procedure","text":"<p>To deploy and start Docker-based Studio, run the following commands. Here we use NebulaGraph v2.6.2 for demonstration:</p> <ol> <li> <p>Download the configuration files for the deployment.</p> Installation package NebulaGraph version nebula-graph-studio-v3.1.1.tar.gz v2.6.2 </li> <li> <p>Create the <code>nebula-graph-studio-v3</code> directory and decompress the installation package to the directory.</p> <pre><code>mkdir nebula-graph-studio-v3 &amp;&amp; tar -zxvf nebula-graph-studio-v3.gz -C nebula-graph-studio-v3\n</code></pre> </li> <li> <p>Change to the <code>nebula-graph-studio-v3</code> directory.    <pre><code>cd nebula-graph-studio-v3\n</code></pre></p> </li> <li> <p>Pull the Docker image of Studio.</p> <pre><code>docker-compose pull\n</code></pre> </li> <li> <p>Build and start Docker-based Studio. In this command, <code>-d</code> is to run the containers in the background.</p> <pre><code>docker-compose up -d\n</code></pre> <p>If these lines are returned, Docker-based Studio v3.x is deployed and started.</p> <pre><code>Creating docker_client_1   ... done\nCreating docker_web_1      ... done\nCreating docker_nginx_1    ... done\n</code></pre> </li> <li> <p>When Docker-based Studio is started, use <code>http://ip address:7001</code> to get access to Studio.</p> <p>Note</p> <p>Run <code>ifconfig</code> or <code>ipconfig</code> to get the IP address of the machine where Docker-based Studio is running. On the machine running Docker-based Studio, you can use <code>http://localhost:7001</code> to get access to Studio.</p> <p>If you can see the Config Server page on the browser, Docker-based Studio is started successfully.</p> <p></p> </li> </ol>"},{"location":"nebula-studio/deploy-connect/st-ug-deploy/#next_to_do","title":"Next to do","text":"<p>On the Config Server page, connect Docker-based Studio to NebulaGraph. For more information, see Connect to NebulaGraph.</p>"},{"location":"nebula-studio/deploy-connect/st-ug-reset-connection/","title":"Clear connection","text":""},{"location":"nebula-studio/deploy-connect/st-ug-reset-connection/#clear_connection","title":"Clear connection","text":"<p>If you want to reset NebulaGraph, you can clear the connection and reconfigure the database.</p> <p>When the Studio is still connected to a NebulaGraph database, you can choose setting &gt; clear connect at the toolbar. If the Config Server page is displayed on the browser, it means that Studio has successfully disconnected from the NebulaGraph database.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/","title":"Operate edge types","text":"<p>After a graph space is created in NebulaGraph, you can create edge types. With Studio, you can choose to use the Console page or the Schema page to create, retrieve, update, or delete edge types. This topic introduces how to use the Schema page to operate edge types in a graph space only.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/#studio_version","title":"Studio version","text":"<p>Studio of v3.1.1 or later versions supports this function. For more information, see check updates.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/#prerequisites","title":"Prerequisites","text":"<p>To operate an edge type on the Schema page of Studio, you must do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph.</li> <li>A graph space is created.</li> <li>Your account has the authority of GOD, ADMIN, or DBA.</li> </ul>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/#create_an_edge_type","title":"Create an edge type","text":"<p>To create an edge type on the Schema page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Schema tab.</p> </li> <li> <p>In the Graph Space List page, find a graph space and then click its name or click the button  in the Operations column.</p> </li> <li> <p>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</p> </li> <li> <p>Click the Edge Type tab and click the + Create button.</p> </li> <li> <p>On the Create page, do these settings:</p> <ul> <li>Name: Specify an appropriate name for the edge type. In this example, <code>serve</code> is used.</li> </ul> <ul> <li>(Optional) If necessary, under the name, click the Comment to input content.</li> </ul> <ul> <li> <p>(Optional) If necessary, in the upper left corner of the Define Properties panel, click the check box to expand the panel and do these settings:</p> <ul> <li>To define a property: Enter a property name, a data type, and a default value.</li> </ul> <ul> <li>To add multiple properties: Click the Add Property button and define more properties.</li> </ul> <ul> <li>To delete a defined property: Besides the Defaults column, click the button .</li> </ul> </li> </ul> <ul> <li>(Optional) If no index is set for the edge type, you can set the TTL configuration: In the upper left corner of the Set TTL panel, click the check box to expand the panel, and configure <code>TTL_COL</code> and <code>TTL_ DURATION</code>. For more information about both parameters, see TTL configuration.</li> </ul> </li> <li> <p>When the preceding settings are completed, in the Equivalent to the following nGQL statement panel, you can see the nGQL statement equivalent to these settings.</p> <p></p> </li> <li> <p>Confirm the settings and then click the + Create button. When the edge type is created successfully, the Define Properties panel shows all its properties on the list.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/#edit_an_edge_type","title":"Edit an edge type","text":"<p>To edit an edge type on the Schema page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Schema tab.</p> </li> <li> <p>In the Graph Space List page, find a graph space and then click its name or click the button  in the Operations column.</p> </li> <li> <p>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</p> </li> <li> <p>Click the Edge Type tab, find an edge type and then click the button  in the Operations column.</p> </li> <li> <p>On the Edit page, do these operations:</p> <ul> <li>To edit a Comment: Click Edit under the Name.</li> <li>To edit a property: On the Define Properties panel, find a property, click Edit, and then change the data type or the default value.</li> </ul> <ul> <li>To delete a property: On the Define Properties panel, find a property, click Delete.</li> </ul> <ul> <li>To add more properties: On the Define Properties panel, click the Add Property button to add a new property.</li> </ul> <ul> <li>To set the TTL configuration: In the upper left corner of the Set TTL panel, click the check box and then set TTL.</li> </ul> <ul> <li>To edit the TTL configuration: On the Set TTL panel, click Edit and then change the configuration of <code>TTL_COL</code> and <code>TTL_DURATION</code>.</li> </ul> <ul> <li>To delete the TTL configuration: When the Set TTL panel is expanded, in the upper left corner of the panel, click the check box to delete the configuration.</li> </ul> </li> <li> <p>When the configuration is done, in the Equivalent to the following nGQL statement panel, you can see the equivalent <code>ALTER EDGE</code> statement.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/#delete_an_edge_type","title":"Delete an Edge type","text":"<p>Danger</p> <p>Confirm the impact before deleting the Edge type. The deleted data cannot be restored if it is not backed up.</p> <p>To delete an edge type on the Schema page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Schema tab.</p> </li> <li> <p>In Graph Space List, find a graph space and then click its name or click the button  in the Operations column.</p> </li> <li> <p>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</p> </li> <li> <p>Click the Edge Type tab, find an edge type and then click the button  in the Operations column.</p> </li> <li> <p>Click OK to confirm in the pop-up dialog box.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-edge-type/#next_to_do","title":"Next to do","text":"<p>After the edge type is created, you can use the Console page to insert edge data one by one manually or use the Import page to bulk import edge data.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-index/","title":"Operate Indexes","text":"<p>You can create an index for a Tag and/or an Edge type. An index lets traversal start from vertices or edges with the same property and it can make a query more efficient. You can create two index types: Tag Index and Edge type Index. With Studio, you can use the Console page or the Schema page to create, retrieve, and delete indexes. This topic introduces how to use the Schema page to operate an index only.</p> <p>Note</p> <p>You can create an index when a Tag or an Edge Type is created. But an index can decrease the write speed during data import. We recommend that you import data firstly and then create and rebuild an index. For more information, see nGQL Manual.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-index/#studio_version","title":"Studio version","text":"<p>Studio of v3.1.1 or later versions supports this function. For more information, see check updates.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-index/#prerequisites","title":"Prerequisites","text":"<p>To operate an index on the Schema page of Studio, you must do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph.</li> <li>A graph Space, Tags, and Edge Types are created.</li> <li>Your account has the authority of GOD, ADMIN, or DBA.</li> </ul>"},{"location":"nebula-studio/manage-schema/st-ug-crud-index/#create_an_index","title":"Create an index","text":"<p>To create an index on the Schema page, follow these steps:</p> <ol> <li>In the toolbar, click the Schema tab.</li> <li>On the Graph Space List page, find a graph space, and then click its name or the button  in the Operations column.</li> <li>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</li> <li>Click the Index tab and then click the + Create button.</li> <li> <p>On the Create page, do these settings:</p> <ul> <li>Index Type: Choose to create an index for a tag or for an edge type. In this example, Edge Type is chosen.</li> </ul> <ul> <li>Name: Choose a tag name or an edge type name. In this example, follow is chosen.</li> </ul> <ul> <li>Index Name: Specify a name for the new index. In this example, follow_index is used.</li> </ul> <ul> <li> <p>Indexed Properties: Click Add, and then, in the dialog box, choose a property. If necessary, repeat this step to choose more properties. You can drag the properties to sort them. In this example, <code>degree</code> is chosen.</p> <p>Note</p> <p>The order of the indexed properties has an effect on the result of the <code>LOOKUP</code> statement. For more information, see nGQL Manual.</p> </li> </ul> <ul> <li>Comment: The remarks of a certain property or the index itself. The maximum length is 256 bytes. By default, there will be no comments on an index. But in this example, <code>follow_index</code> is used.</li> </ul> </li> <li> <p>When the settings are done, the Equivalent to the following nGQL statement panel shows the statement equivalent to the settings.  </p> </li> </ol> <p></p> <ol> <li>Confirm the settings and then click the + Create button. When an index is created, the index list shows the new index.</li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-index/#view_indexes","title":"View indexes","text":"<p>To view indexes on the Schema page, follow these steps:</p> <ol> <li>In the toolbar, click the Schema tab.</li> <li>In the graph space list, find a graph space, and then click its name or the button  in the Operations column.</li> <li>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</li> <li>Click the Index tab, in the upper left corner, choose an index type, Tag or Edge Type.</li> <li>In the list, find an index and click its row. All its details are shown in the expanded row.</li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-index/#delete_an_index","title":"Delete an index","text":"<p>To delete an index on Schema, follow these steps:</p> <ol> <li>In the toolbar, click the Schema tab.</li> <li>In the graph space list, find a graph space, and then click its name or the button  in the Operations column.</li> <li>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</li> <li>Click the Index tab, find an index and then the button  in the Operations column.</li> <li>Click OK to confirm in the pop-up dialog box.</li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-space/","title":"Operate graph spaces","text":"<p>When Studio is connected to NebulaGraph, you can create or delete a graph space. You can use the Console page or the Schema page to do these operations. This article only introduces how to use the Schema page to operate graph spaces in NebulaGraph.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-space/#studio_version","title":"Studio version","text":"<p>Studio of v3.1.1 or later versions supports this function. For more information, see check updates.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-space/#prerequisites","title":"Prerequisites","text":"<p>To operate a graph space on the Schema page of Studio, you must do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph.</li> <li>Your account has the authority of GOD. It means that:<ul> <li>If the authentication is enabled in NebulaGraph, you can use <code>root</code> and any password to sign in to Studio.</li> <li>If the authentication is disabled in NebulaGraph, you must use <code>root</code> and its password to sign in to Studio.</li> </ul> </li> </ul>"},{"location":"nebula-studio/manage-schema/st-ug-crud-space/#create_a_graph_space","title":"Create a graph space","text":"<p>To create a graph space on the Schema page, follow these steps:</p> <ol> <li>In the toolbar, click the Schema tab.</li> <li>On the Graph Space List page, click the + Create button.</li> <li> <p>On the Create page, do these settings:</p> <ul> <li>Name: Specify a name to the new graph space. In this example, <code>basketballplayer</code> is used. The name must be distinct in the database. The name cannot be used keywords or reserved keywords as identifiers. For more information, see keywords.</li> </ul> <ul> <li>Vid type: The data types of VIDs are restricted to <code>FIXED_STRING(&lt;N&gt;)</code> or <code>INT64</code>. A graph space can only select one VID type. In this example, <code>FIXED_STRING(32)</code> is used. For more information, see VID.</li> </ul> <ul> <li>Comment: The remarks of a certain property or the space itself. The maximum length is 256 bytes. By default, there will be no comments on a space. But in this example, <code>Statistics of basketball players</code> is used.</li> </ul> <ul> <li>Optional Parameters: Set the values of <code>partition_num</code> and <code>replica_factor</code> respectively. In this example, these parameters are set to <code>100</code> and <code>1</code> respectively. For more information, see <code>CREATE SPACE</code> syntax.</li> </ul> <p>In the Equivalent to the following nGQL statement panel, you can see the statement equivalent to the preceding settings.</p> <pre><code>CREATE SPACE basketballplayer (partition_num = 100, replica_factor = 1, vid_type = FIXED_STRING(32)) COMMENT = \"Statistics of basketball players\"\n</code></pre> </li> <li> <p>Confirm the settings and then click the + Create button. If the graph space is created successfully, you can see it on the graph space list.</p> </li> </ol> <p></p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-space/#delete_a_graph_space","title":"Delete a graph space","text":"<p>Danger</p> <p>Deleting the space will delete all the data in it, and the deleted data cannot be restored if it is not backed up.</p> <p>To delete a graph space on the Schema page, follow these steps:</p> <ol> <li>In the toolbar, click the Schema tab.</li> <li> <p>In the graph space list, find a graph space and then the button  in the Operations column.</p> <p> 3. On the dialog box, confirm the information and then click the OK button. When the graph space is deleted successfully, it is removed from the graph space list.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-space/#next_to_do","title":"Next to do","text":"<p>After a graph space is created, you can create or edit a schema, including:</p> <ul> <li>Operate tags</li> <li>Operate edge types</li> <li>Operate indexes</li> </ul>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/","title":"Operate tags","text":"<p>After a graph space is created in NebulaGraph, you can create tags. With Studio, you can use the Console page or the Schema page to create, retrieve, update, or delete tags. This topic introduces how to use the Schema page to operate tags in a graph space only.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/#studio_version","title":"Studio version","text":"<p>Studio of v3.1.1 or later versions supports this function. For more information, see check updates.</p>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/#prerequisites","title":"Prerequisites","text":"<p>To operate a tag on the Schema page of Studio, you must do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph.</li> <li>A graph space is created.</li> <li>Your account has the authority of GOD, ADMIN, or DBA.</li> </ul>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/#create_a_tag","title":"Create a tag","text":"<p>To create a tag on the Schema page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Schema tab.</p> </li> <li> <p>In the Graph Space List page, find a graph space, and then click its name or the button  in the Operations column.</p> </li> <li> <p>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</p> </li> <li> <p>Click the Tag tab and click the + Create button.</p> </li> <li> <p>On the Create page, do these settings:</p> <p>a. Name: Specify an appropriate name for the tag. In this example, <code>course</code> is specified.</p> <p>b. (Optional) If necessary, in the upper left corner of the Define Properties panel, click the check box to expand the panel and do these settings:</p> <p>- To define a property: Enter a property name, a data type, and a default value.</p> <p>- To add multiple properties: Click the Add Property button and define more properties.</p> <p>- To cancel a defined property: Besides the Defaults column, click the button .</p> <p>c. (Optional) If no index is set for the tag, you can set the TTL configuration: In the upper left corner of the Set TTL panel, click the check box to expand the panel and configure <code>TTL_COL</code> and <code>TTL_ DURATION</code>. For more information about both parameters, see TTL configuration.</p> </li> <li> <p>When the preceding settings are completed, in the Equivalent to the following nGQL statement panel, you can see the nGQL statement equivalent to these settings.</p> <p></p> </li> <li> <p>Confirm the settings and then click the + Create button. When the tag is created successfully, the Define Properties panel shows all its properties on the list.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/#edit_a_tag","title":"Edit a tag","text":"<p>To edit a tag on the Schema page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Schema tab.</p> </li> <li> <p>In the Graph Space List page, find a graph space, and then click its name or the button  in the Operations column.</p> </li> <li> <p>In Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</p> </li> <li> <p>Click the Tag tab, find a tag and then the button  in the Operations column.</p> </li> <li> <p>On the Edit page, do these settings:</p> <ul> <li>To edit a Comment: Click Edit under the Name.</li> </ul> <ul> <li>To edit a property: On the Define Properties panel, find a property, click Edit, and then change the data type or the default value.</li> </ul> <ul> <li>To delete a property: On the Define Properties panel, find a property and then click Delete.</li> </ul> <ul> <li>To add more properties: On the Define Properties panel, click the Add Property button to add a new property.</li> </ul> <ul> <li>To set the TTL configuration: In the upper left corner of the Set TTL panel, click the check box and then set the TTL configuration.</li> </ul> <ul> <li>To edit the TTL configuration: On the Set TTL panel, click Edit and then change the configuration of <code>TTL_COL</code> and <code>TTL_DURATION</code>.</li> </ul> <ul> <li>To delete the TTL configuration: When the Set TTL panel is expanded, in the upper left corner of the panel, click the check box to delete the configuration.</li> </ul> </li> <li> <p>When the configuration is done, in the Equivalent to the following nGQL statement panel, you can see the equivalent <code>ALTER TAG</code> statement.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/#delete_a_tag","title":"Delete a tag","text":"<p>Danger</p> <p>Confirm the impact before deleting the tag. The deleted data cannot be restored if it is not backed up.</p> <p>To delete a tag on the Schema page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Schema tab.</p> </li> <li> <p>In Graph Space List, find a graph space, and then click its name or the button  in the Operations column.</p> </li> <li> <p>In the Current Graph Space field, confirm the name of the graph space. If necessary, you can choose another name to change the graph space.</p> </li> <li> <p>Click the Tag tab, find a tag and then the button  in the Operations column.</p> </li> <li> <p>CLick OK.</p> </li> </ol>"},{"location":"nebula-studio/manage-schema/st-ug-crud-tag/#next_to_do","title":"Next to do","text":"<p>After the tag is created, you can use the Console page to insert vertex data one by one manually or use the Import page to bulk import vertex data.</p>"},{"location":"nebula-studio/quick-start/st-ug-create-schema/","title":"Create a schema","text":"<p>To batch import data into NebulaGraph, you must have a graph schema. You can create a schema on the Console page or on the Schema page of Studio.</p> <p>Note</p> <p>You can use nebula-console to create a schema. For more information, see NebulaGraph Manual and Get started with NebulaGraph.</p>"},{"location":"nebula-studio/quick-start/st-ug-create-schema/#prerequisites","title":"Prerequisites","text":"<p>To create a graph schema on Studio, you must do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph.</li> </ul> <ul> <li>Your account has the privilege of GOD, ADMIN, or DBA.</li> </ul> <ul> <li>The schema is designed.</li> </ul> <ul> <li>A graph space is created.</li> </ul> <p>Note</p> <p>If no graph space exists and your account has the GOD privilege, you can create a graph space on the Console page. For more information, see CREATE SPACE.</p>"},{"location":"nebula-studio/quick-start/st-ug-create-schema/#create_a_schema_with_schema","title":"Create a schema with Schema","text":"<p>To create a schema on the Schema page, follow these steps:</p> <ol> <li> <p>Create tags. For more information, see Operate tags.</p> </li> <li> <p>Create edge types. For more information, see Operate edge types.</p> </li> </ol>"},{"location":"nebula-studio/quick-start/st-ug-create-schema/#create_a_schema_with_console","title":"Create a schema with Console","text":"<p>To create a schema on the Console page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Console tab.</p> </li> <li> <p>In the Current Graph Space field, choose a graph space name. In this example, basketballplayer is used.</p> <p></p> </li> <li> <p>In the input box, enter these statements one by one and click the button .</p> <pre><code>// To create a tag named \"player\", with two property\nnebula&gt; CREATE TAG player(name string, age int);\n\n// To create a tag named \"team\", with one property\nnebula&gt; CREATE TAG team(name string);\n\n// To create an edge type named \"follow\", with one properties\nnebula&gt; CREATE EDGE follow(degree int);\n\n// To create an edge type named \"serve\", with two properties\nnebula&gt; CREATE EDGE serve(start_year int, end_year int);\n</code></pre> </li> </ol> <p>If the preceding statements are executed successfully, the schema is created. You can run the statements as follows to view the schema.</p> <pre><code>// To list all the tags in the current graph space\nnebula&gt; SHOW TAGS;\n\n// To list all the edge types in the current graph space\nnebula&gt; SHOW EDGES;\n\n// To view the definition of the tags and edge types\nDESCRIBE TAG player;\nDESCRIBE TAG team;\nDESCRIBE EDGE follow;\nDESCRIBE EDGE serve;\n</code></pre> <p>If the schema is created successfully, in the result window, you can see the definition of the tags and edge types.</p>"},{"location":"nebula-studio/quick-start/st-ug-create-schema/#next_to_do","title":"Next to do","text":"<p>When a schema is created, you can import data.</p>"},{"location":"nebula-studio/quick-start/st-ug-explore/","title":"Query graph data","text":"<p>When data is imported, you can use the Console page or the Explore page to query graph data.</p> <p>Note</p> <p>Users can also perform the following query operations online through Studio.</p> <p>For example, if you want to query the edge properties of the player named <code>player100</code> to the team named <code>team204</code>, you can perform these optional operations:</p> <ul> <li>On the Console tab: Run <code>FETCH PROP ON serve \"player100\" -&gt; \"team204\";</code>. The result window shows all the property information of this vertex. When the result returns, click the View Subgraph button and then you can view the vertex information in a visualized way. </li> </ul> <ul> <li>On the Explore tab: Click the Start with Vertices button. In the dialog box, enter player101 and then click the Add button. On the board, you can see the vertex. Move your mouse pointer on the vertex to see the vertex details, as shown in the preceding figure. </li> </ul>"},{"location":"nebula-studio/quick-start/st-ug-import-data/","title":"Import data","text":"<p>After CSV files of data and a schema are created, you can use the Import page to batch import vertex and edge data into NebulaGraph for graph exploration and data analysis.</p>"},{"location":"nebula-studio/quick-start/st-ug-import-data/#prerequisites","title":"Prerequisites","text":"<p>To batch import data, do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph.</li> </ul> <ul> <li>A schema is created.</li> </ul> <ul> <li>CSV files meet the demands of the Schema.</li> </ul> <ul> <li>Your account has privilege of GOD, ADMIN, DBA, or USER.</li> </ul>"},{"location":"nebula-studio/quick-start/st-ug-import-data/#procedure","title":"Procedure","text":"<p>To batch import data, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Import tab.</p> </li> <li> <p>On the Select Space page, choose a graph space name. In this example, basketballplayer is used. And then click the Next button.</p> </li> <li> <p>On the Upload Files page, click the Upload Files button and then choose CSV files. In this example, <code>edge_serve.csv</code>, <code>edge_follow.csv</code>, <code>vertex_player.csv</code>, and <code>vertex_team.csv</code> are chosen.</p> <p>Note</p> <p>You can choose multiple CSV files at the same time. The CSV file used in this article can be downloaded in the Design a schema.</p> </li> <li> <p>On the Select Files page, do a check of the file size and click Preview or Delete in the Operations column to make sure that all source data is correct. And then click the Next button.</p> </li> <li> <p>On the Map Vertices page, click the + Bind Datasource button, and in the dialog box, choose a CSV file. In this example, <code>vertex_player.csv</code> or <code>vertex_team.csv</code> is chosen.</p> </li> <li> <p>In the DataSource X tab, click the + Tag button.</p> </li> <li> <p>In the vertexId section, do these operations:</p> <p>a. In the CSV Index column, click Mapping. </p> <p>b. In the dialog box, choose a column from the CSV file. In this example, the only one cloumn of <code>vertex_player.csv</code> is chosen to generate VIDs representing players and the <code>playerID</code> column of <code>vertex_player.csv</code> is chosen to generate VIDs representing players.</p> <p>!!! Note</p> <pre><code>  In the same graph space, the VID is always unique and cannot be repeated. For VID information, see [VID](../../1.introduction/3.vid.md) \"Click to enter the NebulaGraph Manual\".\n</code></pre> </li> <li> <p>In the TAG 1 section, do these operations:    a. In the TAG drop-down list, choose a tag name. In this example, player is used for the <code>vertex_player.csv</code> file, and team is used for the <code>vertex_team.csv</code> file.  </p> <p>b. In the property list, click Mapping to choose a data column from the CSV file as the value of a property. In this example, for the player tag, choose Column 1 for the <code>age</code> property and set its type to int. And choose Column 2 for the <code>name</code> property and set its type to string.</p> <p> </p> </li> <li> <p>(Optional) If necessary, repeat Step 5 through Step 8 for more tags.  </p> </li> <li> <p>When the configuration is done, click the Next button.    When Config validation was successful prompts, data mapping for the vertices is successful.  </p> </li> <li> <p>On the Map Edges page, click the + Bind Datasource button, and in the dialog box, choose a CSV file. In this example, the <code>edge_follow.csv</code> file is chosen.</p> </li> <li> <p>In the Type drop-down list, choose an edge type name. In this example, follow is chosen.</p> </li> <li> <p>In the property list, click Mapping to choose a column from the <code>edge_follow.csv</code> file as values of a property for the edges. srcId and dstId are the VIDs of the source vertex and destination vertex of an edge. In this example, srcId must be set to the VIDs of the player and dstId must be set to the VIDs of another player. Rank is optional.</p> <p></p> </li> <li> <p>When the configuration is done, click the Next button.</p> </li> <li> <p>On the Import page, click the Start Import button. On the log window, you can see the import progress. The consumed time depends on the data volume. During data import, you can click the Stop Import button to stop data import. When the log window shows information as follows, the data import is done. </p> </li> </ol>"},{"location":"nebula-studio/quick-start/st-ug-import-data/#next_to_do","title":"Next to do","text":"<p>When the data are imported to v2.6.2, you can query graph data.</p>"},{"location":"nebula-studio/quick-start/st-ug-plan-schema/","title":"Design a schema","text":"<p>To manipulate graph data in NebulaGraph with Studio, you must have a graph schema. This article introduces how to design a graph schema for NebulaGraph.</p> <p>A graph schema for NebulaGraph must have these essential elements:</p> <ul> <li>Tags (namely vertex types) and their properties.</li> </ul> <ul> <li>Edge types and their properties.</li> </ul> <p>In this article, you can install the sample data set basketballplayer and use it to explore a pre-designed schema.</p> <p>This table gives all the essential elements of the schema.</p> Element Name Property name (Data type) Description Tag player - <code>name</code> (<code>string</code>) - <code>age</code> (<code>int</code>) Represents the player. Tag team - <code>name</code> (<code>string</code>) Represents the team. Edge type serve - <code>start_year</code> (<code>int</code>)  - <code>end_year</code> (<code>int</code>) Represent the players behavior.This behavior connects the player to the team, and the direction is from player to team. Edge type follow - <code>degree</code> (<code>int</code>) Represent the players behavior.This behavior connects the player to the player, and the direction is from a player to a player. <p>This figure shows the relationship (serve/follow) between a player and a team.</p> <p></p>"},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/","title":"Connecting to the database error","text":""},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/#problem_description","title":"Problem description","text":"<p>According to the connect Studio operation, it prompts failed.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/#possible_causes_and_solutions","title":"Possible causes and solutions","text":"<p>You can troubleshoot the problem by following the steps below.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/#step1_confirm_that_the_format_of_the_host_field_is_correct","title":"Step1: Confirm that the format of the Host field is correct","text":"<p>You must fill in the IP address (<code>graph_server_ip</code>) and port of the NebulaGraph database Graph service. If no changes are made, the port defaults to <code>9669</code>. Even if NebulaGraph and Studio are deployed on the current machine, you must use the local IP address instead of <code>127.0.0.1</code>, <code>localhost</code> or <code>0.0.0.0</code>.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/#step2_confirm_that_the_username_and_password_are_correct","title":"Step2: Confirm that the username and password are correct","text":"<p>If authentication is not enabled, you can use root and any password as the username and its password.</p> <p>If authentication is enabled and different users are created and assigned roles, users in different roles log in with their accounts and passwords.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/#step3_confirm_that_nebulagraph_service_is_normal","title":"Step3: Confirm that NebulaGraph service is normal","text":"<p>Check NebulaGraph service status. Regarding the operation of viewing services:</p> <ul> <li>If you compile and deploy NebulaGraph on a Linux server, refer to the NebulaGraph service.</li> </ul> <ul> <li>If you use NebulaGraph deployed by Docker Compose and RPM, refer to the NebulaGraph service status and ports.</li> </ul> <p>If the NebulaGraph service is normal, proceed to Step 4 to continue troubleshooting. Otherwise, please restart NebulaGraph service.</p> <p>Note</p> <p>If you used <code>docker-compose up -d</code> to satrt NebulaGraph before, you must run the <code>docker-compose down</code> to stop NebulaGraph.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-config-server-errors/#step4_confirm_the_network_connection_of_the_graph_service_is_normal","title":"Step4: Confirm the network connection of the Graph service is normal","text":"<p>Run a command (for example, telnet  9669) on the Studio machine to confirm whether NebulaGraph's Graph service network connection is normal. <p>If the connection fails, check according to the following steps:</p> <ul> <li>If Studio and NebulaGraph are on the same machine, check if the port is exposed.</li> </ul> <ul> <li>If Studio and NebulaGraph are not on the same machine, check the network configuration of the NebulaGraph server, such as firewall, gateway, and port.</li> </ul> <p>If you cannot connect to the NebulaGraph service after troubleshooting with the above steps, please go to the NebulaGraph forum for consultation.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/","title":"Cannot access to Studio","text":""},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/#problem_description","title":"Problem description","text":"<p>I follow the document description and visit <code>127.0.0.1:7001</code> or <code>0.0.0.0:7001</code> after starting Studio, why can\u2019t I open the page?</p>"},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/#possible_causes_and_solutions","title":"Possible causes and solutions","text":"<p>You can troubleshoot the problem by following the steps below.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/#step1_confirm_system_architecture","title":"Step1: Confirm system architecture","text":"<p>It is necessary to confirm whether the machine where the Studio service is deployed is of x86_64 architecture. Currently, Studio only supports x86_64 architecture.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/#step2_check_if_the_studio_service_starts_normally","title":"Step2: Check if the Studio service starts normally","text":"<p>Run <code>docker-compose ps</code> to check if the service has started normally.</p> <p>If the service is normal, the return result is as follows. Among them, the <code>State</code> column should all be displayed as <code>Up</code>.</p> <pre><code>      Name                          Command               State               Ports\n ------------------------------------------------------------------------------------------------------\n nebula-web-docker_client_1     ./nebula-go-api                  Up      0.0.0.0:32782-&gt;8080/tcp\n nebula-web-docker_importer_1   nebula-importer --port=569 ...   Up      0.0.0.0:32783-&gt;5699/tcp\n nebula-web-docker_nginx_1      /docker-entrypoint.sh ngin ...   Up      0.0.0.0:7001-&gt;7001/tcp, 80/tcp\n nebula-web-docker_web_1        docker-entrypoint.sh npm r ...   Up      0.0.0.0:32784-&gt;7001/tcp\n</code></pre> <p>If the above result is not returned, stop Studio and restart it first. For details, refer to Deploy Studio.</p> <p>Note</p> <p>If you used <code>docker-compose up -d</code> to satrt NebulaGraph before, you must run the <code>docker-compose down</code> to stop NebulaGraph.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/#step3_confirm_address","title":"Step3: Confirm address","text":"<p>If Studio and the browser are on the same machine, users can use <code>localhost:7001</code>, <code>127.0.0.1:7001</code> or <code>0.0.0.0:7001</code> in the browser to access Studio.</p> <p>If Studio and the browser are not on the same machine, you must enter <code>&lt;studio_server_ip&gt;:7001</code> in the browser. Among them, <code>studio_server_ip</code> refers to the IP address of the machine where the Studio service is deployed.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-connection-errors/#step4_confirm_network_connection","title":"Step4: Confirm network connection","text":"<p>Run <code>curl &lt;studio_server_ip&gt;:7001</code> -I to confirm if it is normal. If it returns <code>HTTP/1.1 200 OK</code>, it means that the network is connected normally.</p> <p>If the connection is refused, check according to the following steps:</p> <p>If the connection fails, check according to the following steps:</p> <ul> <li>If Studio and NebulaGraph are on the same machine, check if the port is exposed.</li> </ul> <ul> <li>If Studio and NebulaGraph are not on the same machine, check the network configuration of the NebulaGraph server, such as firewall, gateway, and port.</li> </ul> <p>If you cannot connect to the NebulaGraph service after troubleshooting with the above steps, please go to the NebulaGraph forum for consultation.</p>"},{"location":"nebula-studio/troubleshooting/st-ug-faq/","title":"FAQ","text":"<p>Why can't I use a function?</p> <p>If you find that a function cannot be used, it is recommended to troubleshoot the problem according to the following steps:</p> <ol> <li> <p>Confirm that NebulaGraph is the latest version. If you use Docker Compose to deploy the NebulaGraph database, it is recommended to run <code>docker-compose pull &amp;&amp; docker-compose up -d</code> to pull the latest Docker image and start the container.</p> </li> <li> <p>Confirm that Studio is the latest version. For more information, refer to check updates.</p> </li> <li> <p>Search the nebula forum, nebula and nebula-studio projects on the GitHub to confirm if there are already similar problems.</p> </li> <li> <p>If none of the above steps solve the problem, you can submit a problem on the forum.</p> </li> </ol>"},{"location":"nebula-studio/use-console/st-ug-console/","title":"Console","text":"<p>Studio console interface as shown in following.</p> <p></p> <p>The following table lists various functions on the console interface.</p> number function descriptions 1 toolbar Click the Console tab to enter the console page. 2 select a space Select a space in the Current Graph Space list.  descriptions: Studio does not support running the <code>USE &lt;space_name&gt;</code> statements directly in the input box. 3 input box After inputting the nGQL statements, click the  button to run the statement. You can input multiple statements and run them at the same time, separated by <code>;</code>. 4 clean input box Click  button to clear the content entered in the input box. 5 history list Click  button representing the statement record. In the statement running record list, click one of the statements, and the statement will be automatically entered in the input box. The list provides the record of the last 15 statements. 6 run After inputting the nGQL statement in the input box, click  button to indicate the operation to start running the statement. 7 statement running status After running the nGQL statement, the statement running status is displayed. If the statement runs successfully, the statement is displayed in green. If the statement fails, the statement is displayed in red. 8 result window Display the results of the statement execution. If the statement returns results, the results window will display the returned results in tabular form. 9 export CSV file After running the nGQL statement and return the result, click the Export CSV File button to export the result as a CSV file. 10 open in explore According to the running nGQL statement, the user can click the graph exploration function key to import the returned results into graph exploration for visual display, such as open in explore and view subgraphs."},{"location":"nebula-studio/use-console/st-ug-open-in-explore/","title":"Open in Explore","text":"<p>With the Open in Explore function, you can run nGQL statements on the Console page to query vertex or edge data and then view the result on the Explore page in a visualized way.</p>"},{"location":"nebula-studio/use-console/st-ug-open-in-explore/#supported_versions","title":"Supported versions","text":"<p>Studio of v3.1.1 or later versions supports this function. For more information, see check updates.</p>"},{"location":"nebula-studio/use-console/st-ug-open-in-explore/#prerequisites","title":"Prerequisites","text":"<p>To use the Open in Explore function, you must do a check of these:</p> <ul> <li>Studio is connected to NebulaGraph. For more information, see Connect to NebulaGraph.</li> </ul> <ul> <li>A dataset exists in the database. For more information, see Import data.</li> </ul>"},{"location":"nebula-studio/use-console/st-ug-open-in-explore/#query_and_visualize_edge_data","title":"Query and visualize edge data","text":"<p>To query edge data on the Console page and then view the result on the Explore page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Console tab.</p> </li> <li> <p>In the Current Graph Space field, choose a graph space name. In this example, basketballplayer is chosen.</p> </li> <li> <p>In the input box, enter an nGQL statement and click the button .  </p> <p>Note</p> <p>The query result must contain the VIDs of the source vertex and the destination vertex of an edge.</p> <p>Here is an nGQL statement example.</p> <pre><code>nebula&gt; GO FROM \"player102\" OVER serve YIELD src(edge),dst(edge);\n</code></pre> <p>In the query result, you can see the start year and end year of the service team for the player whose playerId is <code>palyer102</code>. As shown below.</p> <p></p> </li> <li> <p>Click the Open in Explore button.</p> </li> <li> <p>In the dialog box, configure as follows:    a. Click Edge Type.  </p> <p>b. In the Edge Type field, enter an edge type name. In this example, <code>serve</code> is used.  </p> <p>c. In the Src ID field, choose a column name from the result table representing the VIDs of the source vertices. In this example, <code>serve._src</code> is chosen.  </p> <p>d. In the Dst ID field, choose a column name from the result table representing the VIDs of the destination vertices. In this example, <code>serve._dst</code> is chosen.  </p> <p>e. (Optional) If the result table contains the ranking information of the edges, in the Rank field, choose a column name representing the <code>rank</code> of the edges. If no ranking information exists in the result, leave the Rank field blank.  </p> <p>f. When the configuration is done, click the Import button.  </p> <p></p> </li> <li> <p>If some data exists on the board of Explore, choose a method to insert data:</p> <ul> <li>Incremental Insertion: Click this button to add the result to the existing data on the board.</li> <li>Insert After Clear: Click this button to clear the existing data from the board and then add the data to the board.</li> </ul> </li> </ol> <p>When the data is inserted, you can view the visualized representation of the edge data.</p> <p></p>"},{"location":"nebula-studio/use-console/st-ug-open-in-explore/#query_and_visualize_vertex_data","title":"Query and visualize vertex data","text":"<p>To query vertex data on the Console page and then view the result on the Explore page, follow these steps:</p> <ol> <li> <p>In the toolbar, click the Console tab.</p> </li> <li> <p>In the Current Graph Space field, choose a graph space name. In this example, basketballplayer is chosen.</p> </li> <li> <p>In the input box, enter an nGQL statement and click the button .</p> <p>Note</p> <p>The query result must contain the VIDs of the vertices.</p> <p>Here is an nGQL statement example.</p> <pre><code>nebula&gt; FETCH PROP ON player \"player100\" YIELD properties(vertex).name;\n</code></pre> <p>The query result gives the information of the player whose <code>playerId</code> is <code>player100</code>, as shown in this figure.</p> <p></p> </li> <li> <p>Click the Open in Explore button.</p> </li> <li> <p>In the dialog box, configure as follows:    a. Click Vertex.  </p> <p>b. In the Vertex ID field, choose a column name from the result table representing the VIDs of the vertices. In this example, <code>VertexID</code> is chosen.  </p> <p>c. When the configuration is done, click the Import button.</p> <p> </p> </li> <li> <p>If some data exists on the board of Explore, choose a method to insert data:</p> <ul> <li>Incremental Insertion: Click this button to add the queried result to the existing data on the board.</li> </ul> <ul> <li>Insert After Clear: Click this button to clear the existing data from the board and then add the data.</li> </ul> </li> </ol> <p>When the data is inserted, you can view the visualized representation of the vertex data.</p>"},{"location":"nebula-studio/use-console/st-ug-open-in-explore/#next_to_do","title":"Next to do","text":"<p>On the Explore page, you can expand the board to explore and analyze graph data.</p>"},{"location":"nebula-studio/use-console/st-ug-visualize-subgraph/","title":"View subgraphs","text":"<p>With the View Subgraphs function, you can run a FIND SHORTEST | ALL PATH or a <code>GET SUBGRAPH</code> statement on the Console page and then view the result on the Explore page.</p>"},{"location":"nebula-studio/use-console/st-ug-visualize-subgraph/#studio_version","title":"Studio version","text":"<p>Studio of v3.1.1 supports this function. To update the version, see Check updates.</p>"},{"location":"nebula-studio/use-console/st-ug-visualize-subgraph/#prerequisites","title":"Prerequisites","text":"<p>To use the View Subgraphs function, you must do a check of these:</p> <ul> <li>The version of Studio is v3.1.1 or later.</li> </ul> <ul> <li>Studio is connected to NebulaGraph.</li> </ul> <ul> <li>A dataset exists in the database. In the example of this article, the basketballplayer dataset is used. For more information, see Import data.</li> </ul> <p>Note</p> <p>Users can view subgraphs online in Studio.</p>"},{"location":"nebula-studio/use-console/st-ug-visualize-subgraph/#procedure","title":"Procedure","text":"<p>To query the paths or subgraph on the Console page and then view them on the Explore page, follow these steps:</p> <ol> <li> <p>In the navigation bar, click the Console tab.</p> </li> <li> <p>In the Current Graph Space dropdown list, choose a graph space name. In this example, baskteballplayer is chosen.</p> </li> <li> <p>In the input box, enter a <code>FIND SHORTEST PATH</code>, <code>FIND ALL PATH</code>, or <code>GET SUBGRAPH</code> statement and click Run .</p> <p>Here is an nGQL statement example.</p> <pre><code>nebula&gt; FIND ALL PATH FROM \"player114\" to \"player100\" OVER follow;\n</code></pre> <p>Take the <code>FIND ALL PATH</code> for example, query the path information as shown in this figure.</p> <p></p> </li> <li> <p>Click the View Subgraphs button.</p> </li> <li> <p>(Optional) If some data exists on the board of Explore, choose a method to insert data:</p> <ul> <li>Incremental Insertion: Click this button to add the result to the existing data on the board.</li> </ul> <ul> <li>Insert After Clear: Click this button to clear the existing data from the board and then add the data to the board.</li> </ul> </li> </ol> <p>When the data is inserted, you can view the visualized representation of the paths.  Operations such as expanding vertices, moving the canvas, modifying the color and icon of the vertices, and displaying the properties of the vertices and edges on the page are supported.</p> <p></p>"},{"location":"nebula-studio/use-console/st-ug-visualize-subgraph/#next_to_do","title":"Next to do","text":"<p>On the Explore page, you can expand the graph to explore and analyze graph data.</p>"},{"location":"reuse/source_connect-to-nebula-graph/","title":"Source connect to nebula graph","text":"<p>NebulaGraph supports multiple types of clients, including a CLI client, a GUI client, and clients developed in popular programming languages. This topic provides an overview of NebulaGraph clients and basic instructions on how to use the native CLI client, Nebula Console.</p>"},{"location":"reuse/source_connect-to-nebula-graph/#nebulagraph_clients","title":"NebulaGraph clients","text":"<p>You can use supported clients or console to connect to NebulaGraph.</p>"},{"location":"reuse/source_connect-to-nebula-graph/#use_nebula_console_to_connect_to_nebulagraph","title":"Use Nebula Console to connect to NebulaGraph","text":""},{"location":"reuse/source_connect-to-nebula-graph/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have started the NebulaGraph services. For how to start the services, see Start and Stop NebulaGraph.</li> <li>The machine you plan to run Nebula Console on has network access to the NebulaGraph services.</li> </ul>"},{"location":"reuse/source_connect-to-nebula-graph/#steps","title":"Steps","text":"<ol> <li> <p>On the nebula-console page, select a Nebula Console version and click Assets.</p> <p>Note</p> <p>We recommend that you select the latest release.</p> <p></p> </li> <li> <p>In the Assets area, find the correct binary file for the machine where you want to run Nebula Console and download the file to the machine.</p> <p></p> </li> <li> <p>(Optional) Rename the binary file to <code>nebula-console</code> for convenience.</p> <p>Note</p> <p>For Windows, rename the file to <code>nebula-console.exe</code>.</p> </li> <li> <p>On the machine to run Nebula Console, grant the execute permission of the nebula-console binary file to the user.</p> <p>Note</p> <p>For Windows, skip this step.</p> <pre><code>$ chmod 111 nebula-console\n</code></pre> </li> <li> <p>In the command line interface, change the working directory to the one where the nebula-console binary file is stored.</p> </li> <li> <p>Run the following command to connect to NebulaGraph.</p> <ul> <li>For Linux or macOS:</li> </ul> <pre><code>$ ./nebula-console -addr &lt;ip&gt; -port &lt;port&gt; -u &lt;username&gt; -p &lt;password&gt;\n[-t 120] [-e \"nGQL_statement\" | -f filename.nGQL]\n</code></pre> <ul> <li>For Windows:</li> </ul> <pre><code>&gt; nebula-console.exe -addr &lt;ip&gt; -port &lt;port&gt; -u &lt;username&gt; -p &lt;password&gt;\n[-t 120] [-e \"nGQL_statement\" | -f filename.nGQL]\n</code></pre> <p>The description of the parameters is as follows.</p> Option Description <code>-h</code> Shows the help menu. <code>-addr</code> Sets the IP address of the graphd service. The default address is 127.0.0.1. <code>-port</code> Sets the port number of the graphd service. The default port number is 9669. <code>-u/-user</code> Sets the username of your NebulaGraph account. Before enabling authentication, you can use any existing username. The default username is <code>root</code>. <code>-p/-password</code> Sets the password of your NebulaGraph account. Before enabling authentication, you can use any characters as the password. <code>-t/-timeout</code> Sets an integer-type timeout threshold of the connection. The unit is second. The default value is 120. <code>-e/-eval</code> Sets a string-type nGQL statement. The nGQL statement is executed once the connection succeeds. The connection stops after the result is returned. <code>-f/-file</code> Sets the path of an nGQL file. The nGQL statements in the file are executed once the connection succeeds. You'll get the return messages and the connection stops then. </li> </ol> <p>You can find more details in the Nebula Console Repository.</p>"},{"location":"reuse/source_connect-to-nebula-graph/#nebula_console_commands","title":"Nebula Console commands","text":"<p>Nebula Console can export CSV file, DOT file, and import too.</p> <p>Note</p> <p>The commands are case insensitive.</p>"},{"location":"reuse/source_connect-to-nebula-graph/#export_a_csv_file","title":"Export a CSV file","text":"<p>CSV files save the return result of a executed command.</p> <p>Note</p> <ul> <li>A CSV file will be saved in the working directory, i.e., what linux command <code>pwd</code> show;</li> </ul> <ul> <li>This command only works for the next query statement.</li> </ul> <p>The command to export a csv file.</p> <pre><code>nebula&gt; :CSV &lt;file_name.csv&gt;\n</code></pre>"},{"location":"reuse/source_connect-to-nebula-graph/#export_a_dot_file","title":"Export a DOT file","text":"<p>DOT files save the return result of a executed command, and the result information is different from CSV files.</p> <p>Note</p> <ul> <li>A DOT file will be saved in the working directory, i.e., what linux command <code>pwd</code> show;</li> </ul> <ul> <li>You can copy the contents of DOT file, and paste in GraphvizOnline, to visualize the excution plan;</li> </ul> <ul> <li>This command only works for the next query statement.</li> </ul> <p>The command to export a DOT file.</p> <pre><code>nebula&gt; :dot &lt;file_name.dot&gt;\n</code></pre> <p>For example,</p> <pre><code>nebula&gt; :dot a.dot\nnebula&gt; PROFILE FORMAT=\"dot\" GO FROM \"player100\" OVER follow;\n</code></pre>"},{"location":"reuse/source_connect-to-nebula-graph/#importing_a_testing_dataset","title":"Importing a testing dataset","text":"<p>The testing dataset is named <code>nba</code>. Details about schema and data can be seen by commands <code>SHOW</code>.</p> <p>Using the following command to import the testing dataset,</p> <pre><code>nebula&gt; :play nba\n</code></pre>"},{"location":"reuse/source_connect-to-nebula-graph/#run_a_command_multiple_times","title":"Run a command multiple times","text":"<p>Sometimes, you want to run a command multiple times. Run the following command.</p> <pre><code>nebula&gt; :repeat N\n</code></pre> <p>For example,</p> <pre><code>nebula&gt; :repeat 3\nnebula&gt; GO FROM \"player100\" OVER follow;\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 2602/3214 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 583/849 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\n+-------------+\n| follow._dst |\n+-------------+\n| \"player101\" |\n| \"player125\" |\n+-------------+\nGot 2 rows (time spent 496/671 us)\n\nFri, 20 Aug 2021 06:36:05 UTC\n\nExecuted 3 times, (total time spent 3681/4734 us), (average time spent 1227/1578 us)\n</code></pre>"},{"location":"reuse/source_connect-to-nebula-graph/#sleep_to_wait","title":"Sleep to wait","text":"<p>Sleep N seconds.</p> <p>It is usually used when altering schema. Since schema is altered in async way, and take effects in the next heartbeat cycle.</p> <pre><code>nebula&gt; :sleep N\n</code></pre>"},{"location":"reuse/source_connect-to-nebula-graph/#disconnect_nebula_console_from_nebulagraph","title":"Disconnect Nebula Console from NebulaGraph","text":"<p>You can use <code>:EXIT</code> or <code>:QUIT</code> to disconnect from NebulaGraph. For convenience, Nebula Console supports using these commands in lower case without the colon (\":\"), such as <code>quit</code>.</p> <pre><code>nebula&gt; :QUIT\n\nBye root!\n</code></pre>"},{"location":"reuse/source_connect-to-nebula-graph/#faq","title":"FAQ","text":""},{"location":"reuse/source_connect-to-nebula-graph/#how_can_i_install_nebula_console_from_the_source_code","title":"How can I install Nebula Console from the source code","text":"<p>To download and compile the latest source code of Nebula Console, follow the instructions on the nebula console GitHub page.</p>"},{"location":"reuse/source_install-nebula-graph-by-rpm-or-deb/","title":"Source install nebula graph by rpm or deb","text":"<p>RPM and DEB are common package formats on Linux systems. This topic shows how to quickly install NebulaGraph with the RPM or DEB package.</p>"},{"location":"reuse/source_install-nebula-graph-by-rpm-or-deb/#prerequisites","title":"Prerequisites","text":"<p>Prepare the right resources.</p> <p>Note</p> <p>The console is not complied or packaged with NebulaGraph server binaries. You can install nebula-console by yourself.</p> <p>Enterpriseonly</p> <p>For the Enterprise Edition, please send an email to inquiry@vesoft.com.</p>"},{"location":"reuse/source_install-nebula-graph-by-rpm-or-deb/#download_the_package_from_cloud_service","title":"Download the package from cloud service","text":"<ul> <li>Download the released version.<p>URL: </p> <pre><code>//Centos 6 \nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el6.x86_64.rpm\n\n//Centos 7\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el7.x86_64.rpm\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.el8.x86_64.rpm\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1604.amd64.deb\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu1804.amd64.deb\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.io/package/&lt;release_version&gt;/nebula-graph-&lt;release_version&gt;.ubuntu2004.amd64.deb\n</code></pre> <p>For example, download release package 2.6.2 for <code>Centos 7.5</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.rpm\nwget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.el7.x86_64.rpm.sha256sum.txt\n</code></pre> <p>download release package <code>2.6.2</code> for <code>Ubuntu 1804</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.ubuntu1804.amd64.deb\nwget https://oss-cdn.nebula-graph.io/package/2.6.2/nebula-graph-2.6.2.ubuntu1804.amd64.deb.sha256sum.txt\n</code></pre> </li> </ul> <ul> <li> <p>Download the nightly version.</p> <p>Danger</p> <ul> <li>Nightly versions are usually used to test new features. Don't use it for production.</li> <li>Nightly versions may not be build successfully every night. And the names may change from day to day.</li> </ul> <p>URL: </p> <pre><code>//Centos 6 \nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el6.x86_64.rpm\n\n//Centos 7\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el7.x86_64.rpm\n\n//Centos 8\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.el8.x86_64.rpm\n\n//Ubuntu 1604\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu1604.amd64.deb\n\n//Ubuntu 1804\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu1804.amd64.deb\n\n//Ubuntu 2004\nhttps://oss-cdn.nebula-graph.io/package/v2-nightly/&lt;yyyy.mm.dd&gt;/nebula-graph-&lt;yyyy.mm.dd&gt;-nightly.ubuntu2004.amd64.deb\n</code></pre> <p>For example, download the <code>Centos 7.5</code> package developed and built in <code>2021.03.28</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.el7.x86_64.rpm\nwget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.el7.x86_64.rpm.sha256sum.txt\n</code></pre> <p>For example, download the <code>Ubuntu 1804</code> package developed and built in <code>2021.03.28</code>: </p> <pre><code>wget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.ubuntu1804.amd64.deb\nwget https://oss-cdn.nebula-graph.io/package/v2-nightly/2021.03.28/nebula-graph-2021.03.28-nightly.ubuntu1804.amd64.deb.sha256sum.txt\n</code></pre> </li> </ul>"},{"location":"reuse/source_install-nebula-graph-by-rpm-or-deb/#install_nebulagraph","title":"Install NebulaGraph","text":"<ul> <li> <p>Use the following syntax to install with an RPM package.</p> <pre><code>$ sudo rpm -ivh --prefix=&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> <p>For example, to install an RPM package in the default path for the 2.6.2 version.</p> <pre><code>sudo rpm -ivh nebula-graph-2.6.2.el7.x86_64.rpm\n</code></pre> </li> </ul> <ul> <li> <p>Use the following syntax to install with a DEB package.</p> <pre><code>$ sudo dpkg -i --instdir==&lt;installation_path&gt; &lt;package_name&gt;\n</code></pre> <p>For example, to install a DEB package in the default path for the 2.6.2 version.</p> <pre><code>sudo dpkg -i nebula-graph-2.6.2.ubuntu1804.amd64.deb\n</code></pre> <p>Note</p> <p>The default installation path is <code>/usr/local/nebula/</code>.</p> </li> </ul>"},{"location":"reuse/source_install-nebula-graph-by-rpm-or-deb/#whats_next","title":"What's next","text":"<ul> <li>(Enterprise Edition)Deploy license</li> <li>start NebulaGraph </li> <li>connect to NebulaGraph</li> </ul>"},{"location":"reuse/source_manage-service/","title":"Source manage service","text":"<p>You can use the <code>nebula.service</code> script to start, stop, restart, terminate, and check the NebulaGraph services. This topic takes starting, stopping and checking the NebulaGraph services for examples.</p> <p><code>nebula.service</code> is stored in the <code>/usr/local/nebula/</code> directory by default, which is also the default installation path of NebulaGraph. If you have customized the path, use the actual path in your environment.</p>"},{"location":"reuse/source_manage-service/#syntax","title":"Syntax","text":"<pre><code>$ sudo /usr/local/nebula/scripts/nebula.service [-v] [-c &lt;config_file_path&gt;]\n&lt;start|stop|restart|status|kill&gt;\n&lt;metad|graphd|storaged|all&gt;\n</code></pre> Parameter Description <code>-v</code> Display detailed debugging information. <code>-c</code> Specify the configuration file path. The default path is <code>/usr/local/nebula/etc/</code>. <code>start</code> Start the target services. <code>stop</code> Stop the target services. <code>restart</code> Restart the target services. <code>kill</code> Terminate the target services. <code>status</code> Check the status of the target services. <code>metad</code> Set the Meta Service as the target service. <code>graphd</code> Set the Graph Service as the target service. <code>storaged</code> Set the Storage Service as the target service. <code>all</code> Set all the NebulaGraph services as the target services."},{"location":"reuse/source_manage-service/#start_nebulagraph","title":"Start NebulaGraph","text":""},{"location":"reuse/source_manage-service/#in_non-container_environment","title":"In non-container environment","text":"<p>Run the following command to start NebulaGraph.</p> <pre><code>$ sudo /usr/local/nebula/scripts/nebula.service start all\n[INFO] Starting nebula-metad...\n[INFO] Done\n[INFO] Starting nebula-graphd...\n[INFO] Done\n[INFO] Starting nebula-storaged...\n[INFO] Done\n</code></pre>"},{"location":"reuse/source_manage-service/#in_docker_container_deployed_with_docker-compose","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to start NebulaGraph.</p> <pre><code>nebula-docker-compose]$ docker-compose up -d\nBuilding with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/\nCreating network \"nebula-docker-compose_nebula-net\" with the default driver\nCreating nebula-docker-compose_metad0_1 ... done\nCreating nebula-docker-compose_metad2_1 ... done\nCreating nebula-docker-compose_metad1_1 ... done\nCreating nebula-docker-compose_storaged2_1 ... done\nCreating nebula-docker-compose_graphd1_1   ... done\nCreating nebula-docker-compose_storaged1_1 ... done\nCreating nebula-docker-compose_storaged0_1 ... done\nCreating nebula-docker-compose_graphd2_1   ... done\nCreating nebula-docker-compose_graphd_1    ... done\n</code></pre>"},{"location":"reuse/source_manage-service/#stop_nebulagraph","title":"Stop NebulaGraph","text":"<p>Danger</p> <p>Don't run <code>kill -9</code> to forcibly terminate the processes, otherwise, there is a low probability of data loss.</p>"},{"location":"reuse/source_manage-service/#in_non-container_environment_1","title":"In non-container environment","text":"<p>Run the following command to stop NebulaGraph.</p> <pre><code>sudo /usr/local/nebula/scripts/nebula.service stop all\n[INFO] Stopping nebula-metad...\n[INFO] Done\n[INFO] Stopping nebula-graphd...\n[INFO] Done\n[INFO] Stopping nebula-storaged...\n[INFO] Done\n</code></pre>"},{"location":"reuse/source_manage-service/#in_docker_container_deployed_with_docker-compose_1","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to stop NebulaGraph.</p> <pre><code>nebula-docker-compose]$ docker-compose down\nStopping nebula-docker-compose_graphd_1    ... done\nStopping nebula-docker-compose_graphd2_1   ... done\nStopping nebula-docker-compose_storaged0_1 ... done\nStopping nebula-docker-compose_storaged1_1 ... done\nStopping nebula-docker-compose_graphd1_1   ... done\nStopping nebula-docker-compose_storaged2_1 ... done\nStopping nebula-docker-compose_metad1_1    ... done\nStopping nebula-docker-compose_metad2_1    ... done\nStopping nebula-docker-compose_metad0_1    ... done\nRemoving nebula-docker-compose_graphd_1    ... done\nRemoving nebula-docker-compose_graphd2_1   ... done\nRemoving nebula-docker-compose_storaged0_1 ... done\nRemoving nebula-docker-compose_storaged1_1 ... done\nRemoving nebula-docker-compose_graphd1_1   ... done\nRemoving nebula-docker-compose_storaged2_1 ... done\nRemoving nebula-docker-compose_metad1_1    ... done\nRemoving nebula-docker-compose_metad2_1    ... done\nRemoving nebula-docker-compose_metad0_1    ... done\nRemoving network nebula-docker-compose_nebula-net\n</code></pre> <p>If you are using a development or nightly version for testing and have compatibility issues, try to run <code>docker-compose down -v</code> to DELETE all data stored in NebulaGraph and import data again.</p>"},{"location":"reuse/source_manage-service/#check_the_service_status","title":"Check the service status","text":""},{"location":"reuse/source_manage-service/#in_non-container_environment_2","title":"In non-container environment","text":"<p>Run the following command to check the service status of NebulaGraph.</p> <pre><code>$ sudo /usr/local/nebula/scripts/nebula.service status all\n</code></pre> <ul> <li>NebulaGraph is running normally if the following information is returned.</li> </ul> <pre><code>[INFO] nebula-metad(3ba41bd): Running as 26601, Listening on 9559\n[INFO] nebula-graphd(3ba41bd): Running as 26644, Listening on 9669\n[INFO] nebula-storaged(3ba41bd): Running as 26709, Listening on 9779\n</code></pre> <ul> <li>If the return information is similar to the following one, there is a problem.</li> </ul> <pre><code>[INFO] nebula-metad(de03025): Running as 25600, Listening on 9559\n[INFO] nebula-graphd(de03025): Exited\n[INFO] nebula-storaged(de03025): Running as 25646, Listening on 9779\n</code></pre> <p>The NebulaGraph services consist of the Meta Service, Graph Service, and Storage Service. The configuration files for all three services are stored in the <code>/usr/local/nebula/etc/</code> directory by default. You can check the configuration files according to the return information to troubleshoot problems.</p> <p>You may also go to the NebulaGraph community for help.</p>"},{"location":"reuse/source_manage-service/#in_docker_container_deployed_with_docker-compose_2","title":"In docker container (deployed with docker-compose)","text":"<p>Run the following command in the <code>nebula-docker-compose/</code> directory to check the service status of NebulaGraph.</p> <pre><code>[nebula-docker-compose]$ docker-compose ps\nCONTAINER ID   IMAGE                               COMMAND                  CREATED          STATUS                    PORTS                                                                                                  NAMES\n2a6c56c405f5   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:49230-&gt;9669/tcp, 0.0.0.0:49229-&gt;19669/tcp, 0.0.0.0:49228-&gt;19670/tcp                            nebula-docker-compose_graphd2_1\n7042e0a8e83d   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49227-&gt;9779/tcp, 0.0.0.0:49226-&gt;19779/tcp, 0.0.0.0:49225-&gt;19780/tcp   nebula-docker-compose_storaged2_1\n18e3ea63ad65   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49219-&gt;9779/tcp, 0.0.0.0:49218-&gt;19779/tcp, 0.0.0.0:49217-&gt;19780/tcp   nebula-docker-compose_storaged0_1\n4dcabfe8677a   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:49224-&gt;9669/tcp, 0.0.0.0:49223-&gt;19669/tcp, 0.0.0.0:49222-&gt;19670/tcp                            nebula-docker-compose_graphd1_1\na74054c6ae25   vesoft/nebula-graphd:nightly     \"/usr/local/nebula/b\u2026\"   36 minutes ago   Up 36 minutes (healthy)   0.0.0.0:9669-&gt;9669/tcp, 0.0.0.0:49221-&gt;19669/tcp, 0.0.0.0:49220-&gt;19670/tcp                             nebula-docker-compose_graphd_1\n880025a3858c   vesoft/nebula-storaged:nightly   \"./bin/nebula-storag\u2026\"   36 minutes ago   Up 36 minutes (healthy)   9777-9778/tcp, 9780/tcp, 0.0.0.0:49216-&gt;9779/tcp, 0.0.0.0:49215-&gt;19779/tcp, 0.0.0.0:49214-&gt;19780/tcp   nebula-docker-compose_storaged1_1\n45736a32a23a   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49213-&gt;9559/tcp, 0.0.0.0:49212-&gt;19559/tcp, 0.0.0.0:49211-&gt;19560/tcp                  nebula-docker-compose_metad0_1\n3b2c90eb073e   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49207-&gt;9559/tcp, 0.0.0.0:49206-&gt;19559/tcp, 0.0.0.0:49205-&gt;19560/tcp                  nebula-docker-compose_metad2_1\n7bb31b7a5b3f   vesoft/nebula-metad:nightly      \"./bin/nebula-metad \u2026\"   36 minutes ago   Up 36 minutes (healthy)   9560/tcp, 0.0.0.0:49210-&gt;9559/tcp, 0.0.0.0:49209-&gt;19559/tcp, 0.0.0.0:49208-&gt;19560/tcp                  nebula-docker-compose_metad1_1\n</code></pre> <p>Use the <code>CONTAINER ID</code> to log in the container and troubleshoot.</p> <pre><code>nebula-docker-compose]$ docker exec -it 2a6c56c405f5 bash\n[root@2a6c56c405f5 nebula]#\n</code></pre>"},{"location":"reuse/source_manage-service/#whats_next","title":"What's next","text":"<p>Connect to NebulaGraph</p>"}]}